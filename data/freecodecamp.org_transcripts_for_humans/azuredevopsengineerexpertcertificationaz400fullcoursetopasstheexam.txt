With timestamps:

00:00 - hey this is Andrew Brown your favorite
00:01 - Cloud instructor bringing you another
00:03 - free Cloud certification course and this
00:05 - time it's the a400 this is specifically
00:08 - for the Azure devops engineer um and
00:12 - we're making this available on free Camp
00:14 - as always so the way we're going to get
00:17 - the certification is by doing labs in
00:19 - our own Azure account uh lecture content
00:22 - and as always we provide you a free
00:24 - practice exam and I want to tell you
00:26 - that our exam simulator has case studies
00:29 - which is the most important component
00:31 - when we're looking at these expert
00:33 - certifications with Azure um so if you
00:36 - want to support more free courses like
00:39 - this one the best way to do that is to
00:40 - purchase the additional study materials
00:43 - over on exampro doco that's where you
00:46 - get the cheat sheets additional practice
00:48 - exams uh the content is layered um and
00:51 - again it helps produce these courses if
00:54 - you don't know me I've taught a lot of
00:57 - courses here um I've taught ads Azure
01:00 - lots of azure uh gcp kubernetes
01:04 - terraform you name it I've taught it so
01:06 - you're in good hands and I will see you
01:09 - soon okay hey this is Andrew Brown I
01:11 - just wanted to tell you that in this
01:12 - video course I am utilizing my synthetic
01:15 - voice uh synthetic voices is when you
01:17 - utilize software that emulate your voice
01:20 - the reason why I utilize synthetic voice
01:23 - is a couple reasons this is when uh the
01:25 - real Andrew not the synthetic voice
01:27 - Andrew has lost his voice and this
01:30 - happens to me because I have muscle
01:31 - tension dysphonia and so if I use my
01:33 - voice a lot aggressively I can lose my
01:35 - voice and so I have to uh be careful
01:38 - when I'm recording a considerable amount
01:40 - of content and right now when this video
01:41 - is being made I am recording a lot of
01:43 - adus content and so you know I've ask my
01:46 - support team to just generate out my
01:47 - words and Stitch the video together and
01:50 - this the reason for that is that I don't
01:51 - want my content to go stale so when I
01:54 - create content it has to get shipped uh
01:56 - whether my voice is ready or not um so
01:59 - this is the case for the ac400 otherwise
02:02 - this course would just go stale and you
02:04 - wouldn't get it for like 6 months to a
02:06 - year but um you know that's the
02:09 - trade-off that we have when I'm a single
02:10 - content creator and I'm trying to get
02:11 - all this content out so I just want to
02:13 - point out that the content is made by me
02:15 - it's just utilizing a synthetic voice so
02:18 - it's not like it's somebody else doing
02:20 - 100% everything else otherwhere but
02:22 - there you go
02:25 - okay hey this is Andrew Brown from exam
02:28 - Pro and we'll be going over an
02:30 - introduction of the a400 certification
02:32 - the Azure devops Engineer Expert is an
02:34 - expert level Microsoft certification for
02:37 - the pre-requisites you must earn at
02:39 - least one of the following the Microsoft
02:41 - certified Azure administrator associate
02:44 - or the Microsoft certified Azure
02:46 - developer associate the key topics
02:48 - covered in this course design and
02:50 - Implement processes and Communications
02:52 - such as GitHub flow and Azure boards
02:54 - design and Implement traceability and
02:56 - flow of work configure collaboration and
02:59 - communication designed and Implement a
03:01 - source control strategy such as
03:03 - branching strategies pull request
03:04 - workflows design and Implement build and
03:07 - release pipelines design and Implement a
03:09 - package management strategy like GitHub
03:12 - packages develop a security and
03:14 - compliance plan and Implement an
03:16 - instrumentation strategy like Azure
03:18 - Monitor and log analytics so who is this
03:20 - certification for the certification is
03:23 - designed for individuals who are
03:24 - interested in learning how to design and
03:26 - Implement devops practices for
03:28 - continuous integration continuous
03:30 - delivery and infrastructure is codee you
03:32 - may consider this certification if you
03:34 - are new to devops and want to learn the
03:36 - fundamentals and benefits of devops
03:38 - practices you are a software developer
03:40 - systems administrator or IT professional
03:43 - you want to understand the capabilities
03:44 - of azure devops and GitHub including
03:46 - building pipelines implementing Source
03:48 - control strategies and managing security
03:50 - and compliance you are a senior devops
03:53 - engineer or in a related role who needs
03:55 - to reset or refresh your knowledge after
03:56 - working for multiple years so what's the
03:59 - Azure devops Engineer Expert road map
04:01 - like well the most common route that
04:04 - people take to reach the devops Engineer
04:05 - Expert is to start at the Azure
04:07 - fundamentals it's not mandatory but it
04:09 - helps build a solid foundation then you
04:11 - take the Azure developer associate for
04:13 - Designing building testing Azure
04:15 - applications and eventually take the
04:17 - Azure Dev Ops Engineer Expert another
04:20 - common path is to take the Azure
04:21 - administrator associate and then the
04:23 - Azure Solutions architect you can also
04:26 - take the Azure Solutions architect after
04:27 - the devops Engineer Expert to further
04:29 - enhance your Microsoft Azure skills and
04:31 - widen your career prospects other
04:34 - popular associate level certifications
04:36 - may include the aszure AI engineer Azure
04:39 - database administrator and the Azure
04:41 - security engineer and many more so
04:44 - that's a general outlook on the road map
04:46 - to Azure devops Engineer Expert how long
04:49 - this study to pass for beginners so if
04:51 - you've never used Microsoft Azure or any
04:53 - cloud provider have no prior experience
04:55 - with devops practices or no Tech
04:57 - background or experience you're looking
04:59 - it around over 50 hours you shouldn't
05:01 - take this exam if you're a beginner
05:03 - you'll need to pass the prerequisites
05:05 - and build a solid foundation if you're
05:07 - experience with Microsoft Azure or any
05:09 - Cloud providers have experience with
05:11 - devops practices and tools and have a
05:13 - strong background in technology you're
05:15 - looking at about 15 hours the average
05:18 - study time is about 25 hours you should
05:21 - dedicate around 50% of the time to
05:23 - lecture in labs and 50% of the time to
05:26 - practice exams we recommended to study
05:28 - around 1 to 2 hours a day for 20 days
05:31 - what does it take to pass the exam watch
05:34 - video lecture and memorize key
05:35 - information do handson labs and follow
05:38 - along within your own account do paid
05:40 - online practice exams that simulate the
05:42 - real exam sign up and redeem your free
05:44 - practice exam exam guide content outline
05:48 - the exam has a total of five domains
05:51 - each domain has its own waiting this
05:53 - determines how many questions in a
05:54 - domain that will show up skills measured
05:57 - design and Implement processes and
05:59 - communic ation design and Implement a
06:01 - source control strategy design and
06:04 - Implement build and release pipelines
06:06 - which consists of 50 to 55% of the
06:08 - course develop a security and compliance
06:10 - plan Implement an instrumentation
06:13 - strategy where do you take the exam you
06:16 - can take the exam at an inperson test
06:18 - center or online from the convenience of
06:19 - your own home you can use CER aort or
06:22 - Pearson view a proctor is a supervisor
06:25 - or person who monitors students during
06:27 - an
06:27 - examination the passing GR is about 700
06:30 - out of 1,000 you need to get around 70%
06:33 - to pass Microsoft uses scaled scoring
06:37 - there are about 50 to 55 questions you
06:39 - can afford to get roughly 12 to 14
06:41 - questions wrong there is no penalty for
06:44 - wrong questions form bet of questions
06:47 - multiple choice multiple answer drag and
06:50 - drop yes and no keep in mind that
06:52 - there's usually one labp with about
06:54 - eight questions that you do on the Azure
06:56 - portal and the exam is open book but you
06:58 - can only access the Microsoft
07:00 - documentation is the resource the exam
07:02 - duration is 2 hours you get about 2
07:05 - minutes per question exam time is 120
07:08 - Minutes C time is 150 minutes C time
07:11 - refers to the amount of that you should
07:13 - allocate for the exam it includes time
07:15 - to review instructions Show online
07:18 - Proctor your workspace read and accept
07:20 - NDA complete the exam provide feedback
07:23 - at the end the certification is valid
07:26 - for one year you can renew the
07:28 - certification for free Within 6 months
07:29 - or before the expiration date so that's
07:32 - an introduction to the Azure devops
07:34 - engineer expert
07:36 - [Music]
07:39 - certification hey this is Andrew Brown
07:41 - from exam Pro and we'll be going over a
07:43 - quick overview of the exam guide you can
07:45 - find the exam guide by searching for
07:47 - study guide for exam a400 on Google so
07:51 - as we scroll down it will show you the
07:52 - five domains covered and it'll be broken
07:54 - down into more sections I won't be able
07:56 - to go through all of it so I'll just go
07:58 - through some of the key topics that I
08:00 - think you should focus on for the exam
08:02 - design and Implement a structure for the
08:04 - flow of work including GitHub Flow
08:07 - Design and Implement integration for
08:09 - tracking work including GitHub projects
08:11 - Azure boards and repositories you need
08:14 - to know the flow of work such as cycle
08:16 - times time to recovery and lead
08:18 - time configure release documentation
08:21 - including release notes and API
08:24 - documentation design and Implement a
08:26 - strategy for managing large files
08:28 - including get large file storage and get
08:31 - fat recommend package management tools
08:34 - including GitHub packages registry and
08:36 - Azure
08:37 - artifacts design and Implement quality
08:39 - and release Gates including security and
08:43 - governance select a deployment
08:45 - automation solution including GitHub
08:47 - actions and Azure
08:49 - pipelines design a deployment strategy
08:52 - including blue green Canary ring
08:54 - Progressive exposure feature flags and a
08:56 - b
08:57 - testing Implement feature flag Flag by
08:59 - using azzure App configuration feature
09:02 - manager design and Implement desired
09:05 - State configuration for environments
09:06 - including Azure automation State
09:08 - configuration Azure resource manager
09:10 - bicep and Azure autom manage machine
09:14 - configuration Implement and manage
09:16 - GitHub authentication including GitHub
09:18 - apps G token and personal access tokens
09:22 - Implement and manage Secrets keys and
09:24 - certificates by using Azure key Vault
09:27 - automate container scanning including
09:29 - scanning container images and
09:30 - configuring an action to run codic L
09:32 - analysis in a
09:33 - container configure Azure Monitor and
09:36 - log analytics to integrate with devops
09:38 - tools configure collection of telemetry
09:40 - by using application insights VM
09:42 - insights container insights storage
09:45 - insights and network insights inspect
09:47 - distributed tracing by using application
09:50 - insights interrogate logs using basic
09:52 - custom query language queries so that's
09:55 - a quick overview of the exam guide for
09:57 - the a400
09:59 - [Music]
10:03 - hey this is Andrew Brown from exam Pro
10:05 - and we'll be starting off asking the
10:07 - most important question first what is
10:09 - devops devops is an approach that brings
10:11 - together software development and it
10:13 - operations with the goal to enhance the
10:15 - speed and reliability of software
10:17 - delivery it focuses on continuous
10:19 - Improvement Automation and collaboration
10:21 - between teams that were once siloed
10:23 - aiming to shorten the time from
10:24 - development to operation the process
10:27 - includes frequent code versions which
10:28 - allows for for incremental improvements
10:30 - to applications and systems the ultimate
10:33 - goal of devops is to create a culture
10:34 - and environment where building testing
10:36 - and releasing software can happen
10:38 - rapidly frequently and more reliably so
10:41 - why devops devops eliminates the
10:43 - inefficiencies miscommunications and
10:46 - delays that arise from the traditional
10:47 - gap between development and operations
10:49 - teams it creates a collaborative culture
10:51 - that accelerates and improves software
10:53 - delivery some of the key challenges
10:55 - addressed by devops include this
10:57 - communication and collaboration gaps
10:59 - enhances communication and collaboration
11:01 - reducing misunderstandings and
11:03 - accelerating the release process
11:05 - conflicting goals aligns the goals of
11:07 - Dev and Ops teams towards quick reliable
11:09 - and high-quality software delivery
11:12 - manual processes in Bottle X advocates
11:14 - for automation to decrease manual effort
11:16 - errors and delays and streamline
11:19 - processes automation leads to fewer
11:20 - errors shorter deployment times and
11:22 - improved software quality so what's the
11:25 - role of a devops engineer a devops
11:28 - engineer facilitat this collaboration in
11:30 - automation focusing on continuous
11:33 - integration and continuous delivery
11:35 - establishing pipelines that automate
11:36 - code integration testing and deployment
11:39 - ensuring rapid Reliable Software
11:41 - releases infrastructure is code managing
11:43 - and provisioning infrastructure through
11:45 - code to increase efficiency and
11:47 - consistency monitoring and operations
11:49 - implementing Monitoring Solutions to
11:51 - track application and infrastructure
11:52 - performance ensuring High availability
11:54 - and reliability transition to Cloud
11:57 - infrastructure many organizations are
11:59 - transitioning to Cloud infrastructure
12:01 - such as a WS Google cloud or Azure to
12:03 - cut costs and improve manageability
12:05 - offering intuitive tools for network and
12:07 - security settings but necessitating
12:09 - knowledge of platform specific features
12:12 - some of the tools and technologies that
12:14 - will be used in Dev Ops are Version
12:16 - Control such as get essential for
12:18 - managing code changes and facilitating
12:20 - team collaboration agile and lean
12:22 - techniques for planning Sprint isolation
12:24 - and capacity management containerization
12:27 - such as Docker enables scalable
12:29 - deployments with lightweight containers
12:30 - that are faster and simpler to configure
12:32 - than traditional virtual machines
12:34 - orchestration like kubernetes
12:36 - efficiently manages containerized
12:38 - applications that scale CI CD tools such
12:41 - as Jenkins and get lab CI automate the
12:43 - software delivery process from code
12:45 - integration to deployment IAC tools like
12:48 - terraform and anible automate the
12:50 - provisioning and management of
12:51 - infrastructure monitoring and logging
12:54 - such as Prometheus provides insights
12:55 - into application performance and
12:57 - operational health and public and hybrid
12:59 - Cloud streamline operations offering
13:01 - scalable infrastructure with iOS for
13:03 - Seamless app migration and platform as a
13:06 - service to enhance productivity through
13:07 - sophisticated tools some examples of
13:10 - devops Technologies across the different
13:12 - devops stages mainly related to
13:14 - Microsoft Azure include for planning we
13:17 - have Azure boards GitHub and alassian
13:19 - jira continuous integration Azure repos
13:22 - GitHub repos sodar queet selenium owp
13:26 - new get and npm continuous delivery
13:29 - Azure pipelines GI Hub actions bicep
13:31 - terraform Jenkins Red Hat anible chef
13:34 - and puppet operations Azure monitor
13:37 - Azure Automation and Microsoft powerbi
13:40 - and for collaboration and feedback
13:42 - there's Azure devops wikis GitHub wikis
13:44 - GitHub discussions Microsoft teams and
13:46 - slack overall devops revolutionizes it
13:50 - by merging development and operations
13:52 - enhancing delivery speed and fostering a
13:54 - culture of Rapid continuous innovation
13:57 - [Music]
14:01 - the next topic we'll be covering are the
14:03 - differences between devops and
14:04 - traditional it in terms of time devops
14:07 - teams spend onethird more time improving
14:09 - systems to avoid Tech issues than
14:11 - traditional it less time is needed for
14:13 - administrative tasks because devops uses
14:15 - more automated tools and helpful scripts
14:18 - this save time allows for a 33% increase
14:20 - in enhancing their Tech infrastructure
14:22 - they also have 15% more time for
14:24 - Learning and training boosting their
14:26 - skills for Speed and data Dev op groups
14:29 - are typically small and adaptable driven
14:31 - by creativity and speed one of the main
14:33 - goal of devops is agility aiming for
14:35 - Swift completion of tasks traditional it
14:38 - operations typically have less feedback
14:40 - data focusing only on the immediate task
14:43 - it operations often have to handle
14:45 - unexpected Downstream issues they didn't
14:47 - see coming cloud devops is more
14:49 - effective in delivering business
14:51 - applications due to its quick Pace
14:53 - traditional it must strive to keep up
14:55 - with the rapid changes and demands of
14:56 - the business World regard St ing
14:59 - recuperation and crunch time devops
15:01 - teams focus on Readiness for failures
15:03 - and have strategies like ongoing testing
15:05 - and realtime alerts these strategies
15:07 - mean they can address issues quickly and
15:09 - keep systems running smoothly
15:11 - traditional it may need more time to
15:13 - recover from setbacks because they might
15:15 - not of these proactive measures in place
15:17 - fast recovery and devops has often
15:19 - helped using automated systems and
15:20 - flexible infrastructure setups for
15:23 - software distribution devops teams take
15:26 - roughly 37 minutes to deploy software
15:29 - traditional it operations typically need
15:31 - about 85 minutes for the same task this
15:34 - indicates devops teams can release
15:35 - software more than twice as quickly as
15:37 - traditional it
15:39 - teams next we'll quickly go over a few
15:41 - key aspects that devops has an advantage
15:43 - over traditional it product reliability
15:46 - reduce likelihood of failure
15:48 - adaptability enhance flexibility and
15:50 - support Market responsiveness decrease
15:53 - time to Market team productivity greater
15:56 - efficiency in teams Vision clarity more
15:59 - defined product Vision within teams so
16:01 - that's an overview of devops versus
16:03 - traditional
16:08 - it the next topic will be covering is
16:11 - agile and Agile development agile is a
16:13 - philosophy and software development that
16:15 - emphasizes incremental progress
16:17 - collaboration and flexibility it
16:19 - revolves around the idea of breaking
16:21 - down large projects into smaller
16:22 - manageable sections called iterations or
16:24 - Sprints teams work in these short bursts
16:27 - to produce tangible results regularly
16:29 - allowing for frequent reassessment and
16:30 - adjustment this approach enables a quick
16:33 - response to change and promotes
16:34 - continuous Improvement both in the
16:36 - product and the process used to create
16:38 - it the term agile methodology refers to
16:40 - the specific Frameworks and practices
16:42 - that embody the agile philosophy such as
16:44 - scrum and campin these methodologies
16:47 - provide the structure and tools for
16:48 - teams to execute agile principles
16:50 - effectively they include techniques for
16:52 - planning and tracking progress such as
16:54 - standup meetings Sprints and visual
16:56 - boards all designed to enhance team
16:57 - coordination and project
16:59 - transparency Agile development
17:01 - encompasses various methods that follow
17:03 - the agile Manifesto core ideas it's
17:05 - about teams working together managing
17:07 - themselves and using practices that best
17:09 - suit their Project's needs to gradually
17:11 - improve their software in Agile
17:13 - development teams aim to produce fully
17:15 - working and highquality parts of the
17:17 - software at the end of every Sprint this
17:19 - means they must write code test it and
17:21 - make sure everything is of good quality
17:23 - within each Sprint short time frame the
17:25 - key success factors for Agile
17:27 - development teams include diligent
17:29 - backlog refinement integrating early and
17:31 - often and minimizing technical debt
17:35 - diligent backlog refinement this means
17:37 - organizing the list of upcoming work
17:39 - prioritizing the most important tasks
17:41 - and clarifying them product owners are
17:43 - key in preparing for future Sprints by
17:45 - providing clear goals integrating early
17:47 - and often by using continuous
17:49 - integration continuous delivery teams
17:51 - automate their workflows which speeds up
17:53 - coding testing and deployment this helps
17:55 - catch and fix problems early minimizing
17:58 - Tech technical debt just like unwanted
18:00 - financial debt technical debt happens
18:02 - when taking shortcuts which may later
18:04 - require code fixes it's important to
18:06 - find a good mix of adding new features
18:08 - and fixing these issues needing careful
18:09 - planning and discipline so that's an
18:12 - overview of agile and Agile
18:15 - [Music]
18:18 - development hey this is Andrew Brown
18:20 - from exam Pro and in this section we'll
18:22 - be going over two popular agile
18:24 - Frameworks or methodologies called scrum
18:26 - and camben scrum is an agile framework
18:29 - designed for managing complex projects
18:31 - by breaking them down into small
18:32 - manageable tasks completed in short
18:34 - phases called Sprints the key roles in
18:37 - scrum include a product owner guides
18:39 - what and why the team builds prioritizes
18:41 - the work backlog a scrum Master
18:44 - facilitates scrum processes supports
18:46 - team Improvement and removes obstacles
18:48 - and a development team Engineers the
18:50 - product ensuring its quality in scrum a
18:53 - team self- manages its Sprint tasks with
18:55 - daily standup meetings to ensure
18:57 - progress and address impediments they
18:59 - track work using a task board and a
19:00 - Sprint burndown chart and at the
19:02 - Sprint's end they showcase their
19:03 - increment in a review and identify
19:05 - improvements in a retrospective scrum
19:07 - short repeatable Cycles facilitate
19:09 - continuous learning and adaptation
19:11 - making it a practical framework for
19:13 - teams adopting agile
19:15 - principles on the other hand campin is
19:17 - an agile methodology focused on
19:19 - visualizing work limiting work in
19:21 - progress and maximizing efficiency Cam
19:23 - and boards are used to display work at
19:25 - various stages of the process using
19:27 - cards to represents tasks and their
19:29 - stages highlighting work in progress and
19:31 - facilitating team flexibility cumulative
19:34 - flow diagrams visually track a Project's
19:36 - workflow over time showing task
19:38 - distribution across stages the
19:39 - horizontal axis represents time and the
19:42 - vertical axis represents task volume
19:44 - with each color marking at different
19:45 - work stage cfds highlight Trends
19:48 - progress and bottlenecks parallel
19:50 - colored areas indicate balanced workflow
19:52 - bulges suggest bottleneck needing
19:54 - attention for smooth project
19:56 - continuation let's go over a quick
19:58 - comparison between scrum and cambon
20:01 - while broadly fitting Under the Umbrella
20:02 - of Agile development scrum and cin are
20:05 - quite different scrum focuses on fixed
20:07 - length Sprints while cin is a continuous
20:09 - flow model scrum has defined roles while
20:12 - cambon doesn't Define any team roles
20:14 - scrum uses velocity as a key metric
20:17 - while cin uses cycle time teams often
20:19 - blend scrum and cambon features to
20:21 - optimize their workflow they
20:23 - continuously refine their approach to
20:24 - find the best fit focusing on Simplicity
20:27 - and regular value delivery to us
20:29 - [Music]
20:33 - the next topic we'll be covering are
20:35 - some of the key flow metrics you'll need
20:36 - to know for devops processes and for the
20:39 - exam starting with velocity velocity and
20:41 - Azure devops is a metric that tracks the
20:43 - amount of work a team completes during a
20:45 - Sprint helping teams estimate how much
20:47 - work they can handle in future Sprints
20:49 - it's represented in a chart that
20:51 - visualizes work items completed over
20:53 - several Sprints offering insights into
20:55 - the team's work patterns efficiency and
20:57 - consistency by analyzing velocity teams
21:00 - can adjust their planning for better
21:01 - predictability and productivity
21:03 - consistent velocity metrics can help at
21:05 - identifying the impact of process
21:07 - changes and guiding strategic decisions
21:09 - to enhance overall team
21:11 - performance next we have Sprint burndown
21:14 - chart the Sprint burndown is a graph
21:16 - that plots the daily total of remaining
21:18 - work typically shown in hours the
21:20 - burndown chart provides a visual way of
21:22 - showing whether the team is on track to
21:23 - complete all the work by the end of the
21:25 - Sprint it also helps in identifying any
21:27 - bottlenecks or issues in the workflow
21:29 - that may need attention before the
21:30 - Sprints end moving on to lead time and
21:33 - cycle time the lead time and cycle time
21:36 - widgets indicate how long it takes for
21:38 - work to flow through your development
21:39 - pipeline lead time measures the total
21:41 - time elapse from the creation of work
21:43 - items to their completion cycle time
21:46 - measures the time it takes for your team
21:47 - to complete work items once they begin
21:49 - actively working on them the following
21:51 - diagram illustrates how lead time
21:53 - differs from cycle time lead time is
21:56 - calculated from work item creation to
21:57 - entering a completed State cycle time is
22:00 - calculated from first entering an in
22:02 - progress or result State category to
22:04 - entering a completed State category
22:06 - these measures help teams plan spot
22:08 - variations in efficiency and identify
22:10 - potential process issues the lower the
22:12 - lead in cycle times the faster the
22:14 - throughput your team has so these are
22:16 - some of the key flow metrics you'll need
22:18 - to know for the
22:20 - [Music]
22:23 - exam hey this is Andrew Brown from exam
22:26 - Pro and in this section we'll be
22:27 - covering Azure board boards Azure boards
22:29 - is a web-based service designed for
22:31 - planning tracking And discussing work
22:33 - throughout the development process
22:35 - supporting agile methodologies for a
22:36 - customizable and efficient workflow key
22:39 - hubs and Azure boards Azure boards
22:41 - include several key hubs each serving
22:43 - distinct project management needs work
22:46 - items Hub manage work items based on
22:48 - specific criteria boards Hub visualize
22:51 - workflow using cards ideal for cambon
22:53 - the backlogs Hub plan and organize work
22:56 - items including backlogs for project and
22:58 - portfol folio management Sprints Hub
23:00 - handle Sprint specific work items
23:02 - incorporating scrum practices queries
23:05 - Hub generate custom work item lists and
23:07 - perform bulk updates delivery plans Hub
23:10 - track cross team deliverables and
23:11 - dependencies in a calendar view
23:13 - analytics views Hub create powerbi
23:16 - reports for detailed project
23:18 - analysis hey benefits of azure boards
23:20 - include scalable Simplicity easy to
23:23 - start with predefined work item types
23:25 - scalable for growing teams visual tools
23:28 - VIs ual I progress with Canin boards
23:30 - scrum boards and delivery plans
23:32 - customization configure boards task
23:34 - boards and plans including custom Fields
23:37 - built-in communication capture real-time
23:40 - communication and decisions within work
23:41 - item forms cloud storage support for
23:44 - Rich Text inline images attachments and
23:47 - comprehensive change history efficient
23:49 - search and notifications tools for quick
23:51 - work item searching and customizable
23:53 - alerts dashboards and analytics access
23:56 - to dashboards and analytics service for
23:58 - for reporting integration and support
24:01 - GitHub and office integration connects
24:03 - with GitHub repositories and supports
24:05 - import export with Microsoft Office
24:08 - autonomous team support tailor to
24:10 - Independent teams integrates with
24:12 - Microsoft teams in slack and offers a
24:14 - variety of marketplace extensions so
24:17 - that's an overview of azure
24:22 - boards the next topic we'll cover is
24:25 - traceability traceability allows
24:27 - tracking connections and dependencies
24:29 - among different parts of a software
24:30 - system it helps teams grasp the effects
24:32 - of changes handle risks and comply with
24:35 - regulations defining and managing
24:37 - requirements a key part of traceability
24:39 - is documenting and overseeing
24:41 - requirements effectively Azure devop
24:43 - says tools like Azure boards for
24:44 - handling requirements and tracking their
24:46 - progress linking requirements to related
24:48 - items like tasks or bugs this tracking
24:51 - clarifies each requirements progress and
24:53 - its influence on the project Version
24:56 - Control and change management for Trace
24:58 - ility a solid Version Control System to
25:00 - monitor modifications to code in files
25:02 - is essential Azure Dev opsis get
25:04 - repositories let developers manage their
25:06 - work efficiently by using branches for
25:09 - features or releases you can track
25:10 - changes and understand their role in the
25:12 - Project's bigger
25:13 - picture building and release management
25:16 - traceability must include build and
25:18 - release processes Azure pipelines
25:20 - facilitates building testing and
25:22 - deploying apps linking build artifacts
25:24 - and code changes to specific tasks
25:26 - showing what changes made it into each
25:27 - build
25:28 - test management and quality assurance
25:31 - for software quality traceability is
25:33 - crucial tools like Azure test plan
25:35 - support detailed test management linking
25:37 - test cases to requirements or user stor
25:39 - shows how well the testing process
25:41 - covers the initial needs ensuring
25:43 - thorough validation auditing in
25:45 - compliance traceability also supports
25:47 - meeting standards and regulations Azure
25:50 - Dev ops's auditing features track and
25:51 - log changes providing details on who
25:53 - changed what and when supporting
25:55 - accountability and Regulatory Compliance
25:58 - overall by setting up a clear
25:59 - traceability system organizations can
26:02 - make sure that any changes during the
26:03 - software development process are
26:05 - properly tracked recorded and
26:08 - [Music]
26:11 - checked hey this is Andrew Brown from
26:14 - exampro and in this section we'll be
26:15 - going through how to get started with
26:17 - Azure devops and some of the basics of
26:19 - azure boards so the first thing you want
26:21 - to do is search for Azure devops on
26:23 - Google then you want to click on the
26:25 - link that leads you to the Azure devops
26:27 - page which is used the first link on
26:30 - this page you want to click on the TR
26:32 - for free button I'm assuming everyone
26:34 - already has a Microsoft account or
26:36 - Microsoft Azure account already set up
26:38 - otherwise you wouldn't be taking the a
26:39 - Z400 level expert certification if not
26:42 - you should create one before clicking
26:44 - here so we'll enter in our email and
26:46 - click on sign
26:49 - in enter in our
26:52 - password and enter in the authentication
26:54 - code if you have
26:56 - one now you'll want to sign up and
26:58 - create your own Azure devops
27:02 - organization I'll be hosting the
27:04 - projects in
27:06 - Canada I'll name the organization
27:08 - something like exam Pro one you can name
27:10 - this whatever you
27:13 - like also enter in the Capt is requested
27:16 - then press
27:22 - continue the first thing they want you
27:24 - to do is to create a project so we'll
27:27 - name this something like exam Pro test
27:29 - of course you can name this whatever you
27:31 - want such as your name or or project and
27:33 - so
27:35 - on so now we're on the main page of the
27:38 - exam Pro test project on Azure
27:40 - devops so here you can see the
27:43 - overview so we'll quickly go through
27:45 - some of the blades starting off with
27:48 - Azure
27:51 - boards then we have
27:56 - repos after that there's
27:59 - pipelines next is test
28:02 - plans and then there's
28:05 - artifacts we'll be going through most of
28:07 - these in the
28:08 - course so that's how to get started with
28:11 - Azure
28:12 - [Music]
28:16 - devops hey this is Andrew Brown from
28:18 - exam Pro and in this section we'll be
28:20 - covering how to create or add new users
28:21 - in your Azure devops
28:23 - organization the first thing you want to
28:25 - do is to go to organization settings
28:28 - after that you want to click on policies
28:30 - under the security
28:32 - category under the user policies you
28:35 - want to toggle and turn on external
28:36 - guest policies this will allow you to
28:38 - invite users from outside the
28:40 - organization to access and collaborate
28:42 - on your Azure devops projects and
28:44 - resources after that you want to click
28:46 - on users under the general category on
28:49 - the right side you want to click on ADD
28:51 - users here is where you can add new
28:53 - users or service principles so for
28:56 - example We'll add Cindy at exam Pro .
28:59 - Co we'll keep the access level to basic
29:02 - we'll want to add the user to the exam
29:04 - Pro test project we created
29:07 - earlier we can also set a role for the
29:09 - user such as project readers project
29:11 - contributors or project administrators
29:14 - but we'll leave it at project
29:15 - contributor for now then click on ADD
29:19 - after a short wait the user should be
29:20 - added to the organization the user is
29:22 - sent an invitation to join to org and
29:24 - they'll have to accept to join We'll add
29:27 - another user this time it'll be Peter
29:29 - exampro
29:32 - doco we can keep the access level at
29:35 - basic add the user to the exam Pro test
29:38 - project and this time we'll assign the
29:41 - user the project administrator's role
29:43 - then click on
29:44 - add another thing you can do is add
29:47 - members to a specific project so from
29:49 - the projects tab you can click on the
29:52 - project exam Pro
29:55 - test click on teams
29:58 - click into exam Pro
29:59 - test after that click on the ad button
30:03 - and we'll search for Peter exampro doco
30:06 - click on the user and then click on the
30:08 - save button
30:09 - below and there we go the user is now
30:12 - added to the exam Pro test project team
30:15 - so that's a general overview on how you
30:17 - add users to your organization in a
30:18 - specific
30:23 - project the next thing we'll be covering
30:25 - is how to create work items so so first
30:28 - you'll need to be at the boards Tab and
30:30 - then you'll need to click on work items
30:32 - on the top right here we'll click on new
30:34 - work item we have three options here
30:36 - there's epic issue and task epic is
30:39 - simply a large body of work that can be
30:41 - broken down into smaller more manageable
30:43 - pieces of work this is also known as
30:45 - user stories so we'll click on Epic as
30:48 - an example now we'll have to fill out
30:51 - some fields to define the work item so
30:54 - starting with the title we'll call it
30:55 - something like test new login feature
30:59 - right below it we can assign people to
31:00 - the item this can be one or many but
31:02 - we'll select only one for this example
31:04 - so let's choose Andrew Brown for the
31:07 - state we'll leave it at to-do for the
31:09 - area it's already set at exam Pro test
31:13 - the iteration is set to exam Pro test
31:15 - Sprint
31:17 - one we would want to give the work item
31:19 - a description to help understand what
31:20 - it's about for this example we can write
31:23 - something simple like conduct a series
31:25 - of tests on the new login features
31:29 - for the priority we can adjust the
31:31 - importance of the work item one being
31:33 - highest priority and four is the lowest
31:35 - we'll keep it at two so it's about
31:37 - medium
31:38 - priority we can set a start date so we
31:40 - can just use the current date as of this
31:42 - recording for the tags they already have
31:45 - some suggestions for us so we'll use
31:47 - testing login feature and security which
31:49 - matches the
31:52 - item we don't really need to set the
31:54 - link for this example so we'll click on
31:56 - the top right and hit save
32:00 - after that we can head back to the work
32:01 - items page and we should see the work
32:03 - item we just created with all the
32:05 - information we provided for it such as
32:06 - the title user assignment state area
32:09 - path and so
32:10 - on another thing we can do is click on
32:13 - boards this is an easier way to visually
32:15 - view the items so we have three columns
32:18 - that work items can be placed in to do
32:20 - doing and done which are all pretty
32:22 - self-explanatory on the top right here
32:24 - we can filter to epics or
32:26 - issues and and we can drag and drop the
32:29 - work item from to-do to doing and
32:30 - eventually we can place it and done when
32:32 - the item is
32:34 - complete so that's a general overview of
32:36 - how to create a work item in Azure
32:39 - [Music]
32:42 - boards hey this is Andrew Brown from
32:44 - exam Pro and in this section we'll
32:46 - quickly go over how to create a Sprint
32:49 - first on this page we have three work
32:51 - item examples that were created
32:53 - beforehand and we'll want to click on
32:55 - the Sprint tab on the board section here
32:57 - we don't have any Sprints created yet so
32:59 - we'll need to create a new Sprint by
33:01 - clicking on the top right we'll need to
33:03 - give the Sprint a name so let's just
33:05 - call it Sprint one and we'll need to
33:07 - identify a start and end date for the
33:09 - Sprint so we'll start it on Monday April
33:11 - 15th 2024 and end the Sprint on Monday
33:14 - April 22nd 2024 so that's one week
33:17 - length then click on
33:20 - create next we can click on the schedule
33:23 - work button from your product backlog or
33:24 - create new work
33:26 - items on the right we have our Sprint
33:28 - one and we can drag and drop the work
33:30 - items to include them in a Sprint so
33:33 - let's drag some of the work items
33:34 - created earlier into Sprint
33:39 - one we can also create new Sprints by
33:42 - clicking on the new Sprint button below
33:44 - Sprint one so for this Sprint we can
33:47 - call this Sprint two and for the date
33:48 - range we can set the start for Monday
33:50 - April 29th
33:52 - 2024 and end the Sprint on Monday May
33:55 - 6th
33:56 - 2024 then click on
33:59 - create we can do a quick refresh so
34:01 - Sprint two
34:03 - appears let's add one of the work items
34:05 - to Sprint
34:08 - two so if you click into Sprint
34:11 - one you can see that we added two of the
34:13 - work items on the backlog from
34:17 - earlier if you want to delete a Sprint
34:20 - you can go to Project settings on the
34:21 - bottom
34:22 - left under the board section click on
34:25 - Project configuration and as an example
34:28 - we'll delete Sprint 2 so we'll click on
34:30 - the three dots next to Sprint two and
34:32 - keeping it at exam Pro test is fine then
34:34 - we'll click on
34:38 - delete so after that we can go back to
34:40 - the backlogs or
34:44 - Sprints and we can simply add the other
34:46 - work item into Sprint
34:52 - one when we go to Sprint there are
34:54 - additional tabs such as taskboard
34:56 - backlog capacity and analytics we'll
35:00 - quickly go to capacity we can assign
35:02 - days off activity and capacity per day
35:05 - we'll just assign an activity for both
35:07 - of the users such as deployment and
35:10 - design and for the analytics tab there's
35:14 - the burndown trend that shows a visual
35:15 - graph of data such as the amount of work
35:17 - that has been completed in a project
35:19 - versus the total amount of work that was
35:21 - planned so that's pretty much a quick
35:23 - overview of how to create a Sprint and a
35:25 - few of its features
35:26 - [Music]
35:30 - the next thing we'll be covering is how
35:32 - to connect Azure boards to GitHub first
35:35 - you want to click on the project you're
35:36 - working on then on the bottom you want
35:39 - to click on Project settings and under
35:41 - the board section click on GitHub
35:43 - connections after that under the connect
35:46 - GitHub with Azure boards click on
35:47 - connect your GitHub account next thing
35:50 - you'll need to do is to log into your
35:51 - GitHub account so sign into account
35:53 - using your username or email address or
35:55 - password and click on side on
35:59 - after confirming the information click
36:01 - on authorize Azure
36:03 - boards now you'll need to select a
36:06 - GitHub repository that you may want to
36:07 - use with your Azure boards click save
36:10 - after choosing
36:11 - that then after confirming all of this
36:14 - information click on approve install and
36:21 - authorize you can choose to add more
36:23 - repositories or remove them you can
36:25 - remove connections as well you can also
36:28 - add new GitHub connections as well so
36:31 - that's a really quick and simple
36:32 - walkthrough of connecting Azure boards
36:34 - to
36:35 - [Music]
36:38 - GitHub hey this is Andrew Brown from
36:41 - exam Pro and in this section we'll be
36:43 - going through an overview of custom
36:44 - Azure boards dashboards centralize with
36:46 - custom dashboards custom dashboards and
36:49 - Azure boards are crucial for presenting
36:50 - a comprehensive overview of your project
36:52 - status and key metrics by tailoring
36:55 - these dashboards to highlight crucial
36:56 - data your team can streamline workflows
36:58 - and improve decision- making customize
37:01 - with widgets widgets are the heart of
37:03 - azure boards dashboards presenting
37:04 - diverse data from progress charts to
37:06 - work item queries select and tailor
37:08 - widgets that best display the team's
37:10 - critical information ensuring essential
37:12 - insights are readily accessible monitor
37:14 - backlogs with query widgets incorporate
37:17 - query widgets to filter and display work
37:19 - items based on defined criteria like
37:21 - outstanding tasks per team member this
37:23 - enables efficient task management and
37:25 - helps in setting clear priorities
37:27 - track progress with burndown charts use
37:30 - burndown chart widgets to graphically
37:32 - track project progress helping to
37:33 - identify any delays regular review of
37:36 - these charts keeps the team's progress
37:37 - aligned with project goals visualize
37:40 - performance with charts enrich your
37:42 - dashboard with charts that convey
37:43 - performance metrics such as bug Trends
37:45 - or team velocity providing a clear
37:47 - picture of the team's Dynamics and
37:49 - highlighting areas for improvement
37:51 - enhanced team engagement share
37:53 - dashboards with your team and
37:54 - stakeholders to offer a live view of the
37:56 - project status fost a culture of
37:58 - transparency and Collective
38:00 - accountability the image on the left
38:01 - shows an example of a dashboard
38:03 - customized to the way of the devops team
38:05 - or stakeholders this shows information
38:07 - such as the velocity Sprint burnd down
38:09 - backlogs completed and active work items
38:12 - and so on so that's an overview of
38:14 - custom Azure boards
38:20 - dashboards the next topic we'll be
38:22 - covering is Wiki for documentation Wiki
38:24 - offers a collaborative space for team
38:26 - members to compile and share crucial
38:28 - details about a devops project here's a
38:30 - simple guide to leveraging wikis for
38:32 - Effective project documentation start
38:34 - with an overview page Begin by setting
38:36 - up an overview page this should
38:38 - introduce the project its goals and the
38:40 - team working on it mention the
38:42 - Technologies tools and methods your
38:44 - project employs keeping it broad but
38:46 - informative detail project requirements
38:49 - dedicate pages to outline the Project's
38:51 - requirements break down what the project
38:53 - needs to do and how it should perform
38:55 - using clear and achievable language add
38:57 - user stories what needs to be true for
38:59 - the project to be considered complete
39:01 - and any other elements that rely on each
39:03 - other architecture and design
39:05 - documentation use the wiki to detail the
39:08 - project structure and design make a
39:10 - separate page for each part whether it's
39:11 - a component a larger section or a
39:13 - service to help visualize how these
39:16 - parts interact include diagrams like uml
39:18 - or system architecture sketches
39:20 - encourage team input get your team
39:22 - involved in the documentation process
39:25 - allowing everyone to edit and update
39:26 - Wiki pages not only promotes teamwork
39:28 - but also helps keep the information
39:30 - current make sure to use the wiki
39:32 - version tracking to monitor changes and
39:34 - roll back if
39:35 - needed so let's take a quick look at
39:38 - where this is in Azure devops so at the
39:40 - overview section we'll need to click on
39:42 - Wiki and we already created an example
39:44 - Wiki with proper documentation so this
39:47 - is what it'll pretty much look like
39:49 - using markdown we can click on the edit
39:51 - button on the top right this will allow
39:53 - you to edit the wiki to your
39:56 - fitting you can also create more than
39:58 - one Wiki if you
40:00 - want so we can name it like example Wiki
40:03 - 2 so that's an overview and guide to
40:06 - using Wiki for
40:11 - documentation the next thing will'll be
40:13 - covering our process diagrams for
40:15 - documentation process diagrams are
40:17 - visual guides that show the steps in a
40:19 - process making it easier to see how
40:21 - everything connects especially in devops
40:23 - projects here's a simplified guide on
40:25 - using them effectively pinpoint
40:27 - essential processes first identify the
40:30 - main processes in your devops project
40:32 - such as managing source code integrating
40:34 - changes continuously testing
40:36 - automatically deploying and monitoring
40:38 - break down these processes into smaller
40:40 - parts make flowcharts or bpmn diagrams
40:43 - which stands for business process model
40:45 - and notation use software like Microsoft
40:47 - Visio draw. or Lucid chart to create
40:50 - diagrams that map out the process these
40:53 - diagrams should clearly show where the
40:54 - process starts and ends include
40:56 - decision-making points and outline the
40:58 - steps in order these visual tools are
41:00 - effective for mapping out the workflow
41:02 - making complex processes easier to
41:04 - understand and follow on the right we
41:06 - have a process diagram or flowchart that
41:08 - outlines the customer support procedure
41:11 - it begins with a ticket submission
41:12 - followed by case assignment if during
41:15 - business hours the support team responds
41:17 - otherwise and on call technician is
41:19 - alerted at assign tickets prompt
41:21 - reminders while assigned ones are
41:23 - prioritized for review and resolution by
41:25 - the support team the process Cycles
41:27 - until issues are resolved culminating in
41:30 - ticket closure and a follow-up
41:32 - email detail what goes in and comes out
41:35 - for every step in your process note down
41:37 - what you need to start which are the
41:38 - inputs and what you expect to get out of
41:40 - it which are the outputs this might be
41:43 - Code test results deployment packages or
41:45 - anything else relevant it's important to
41:47 - show how each step is linked to the next
41:50 - clarify who does what make sure your
41:51 - diagrams indicate who is responsible for
41:53 - each step this removes confusion and
41:55 - makes sure everyone knows their
41:57 - responsibilities so that's a quick
41:59 - overview of process diagrams for
42:06 - documentation the next topic we'll be
42:08 - covering is configuring release
42:10 - documentation release documentation is a
42:12 - Cornerstone for the successful
42:13 - deployment of software releases within
42:15 - Azure Dev Ops focusing on the non-code
42:17 - aspects that Define the scope quality
42:19 - and functionality of the release here
42:22 - are the key elements of release
42:23 - documentation release notes these should
42:25 - highlight what's new what is issues have
42:27 - been resolved and any enhancements made
42:29 - as well as outline any modifications to
42:31 - settings and their effects on existing
42:33 - features installation guides provide
42:35 - clear detailed instructions for the
42:37 - setup process including a list of
42:39 - required software and system
42:40 - prerequisites and post installation
42:42 - actions configuration changes document
42:45 - updates to configuration settings
42:47 - clarifying any default settings and
42:49 - essential changes change log keep an
42:51 - accurate record of commits or work items
42:53 - in the release using a consistent
42:55 - tracking method roll back plan and have
42:57 - a clear predefined plan for reverting to
42:59 - an earlier software version if
43:01 - necessary creating release documentation
43:04 - in Azure Dev Ops Azure repos store your
43:07 - marked out or text files alongside your
43:09 - code Version Control your documentation
43:11 - for consistency and traceability Azure
43:14 - pipelines automate the generation of
43:16 - change logs and other documentation
43:18 - during the build and release processes
43:21 - artifacts attach generated documentation
43:23 - to specific builds or releases as
43:25 - downloadable artifacts Wiki utilize the
43:28 - built-in Wiki to share detailed guides
43:30 - and notes with the team and stakeholders
43:32 - on the right we have an example of a
43:34 - release notes entry in Azure devops
43:36 - which displays all of the key Elements
43:38 - shown earlier this includes the new
43:39 - features enhancements configuration
43:42 - changes node issues and roll back plan
43:45 - so that's an overview of configuring
43:46 - release
43:48 - [Music]
43:51 - documentation next while covering API
43:54 - documentation properly configured API
43:56 - document m mentation is essential for
43:58 - developers and stakeholders in
44:00 - understanding and interacting with
44:01 - software interfaces this guide
44:03 - highlights the key steps and best
44:05 - practices for creating and managing API
44:07 - documentation in Microsoft devop
44:09 - Solutions steps to generate API
44:11 - documentation generate documentation
44:14 - utilize Visual Studio to generate API
44:17 - documentation access this feature via
44:19 - the bill menu use tools like Swagger
44:21 - Azure API management or open API for
44:24 - automatic documentation generation from
44:26 - your codebase documenting endpoints
44:29 - clearly Define and describe each API
44:31 - endpoint detailing the purpose and
44:33 - functionality include information on
44:35 - request and response formats as well as
44:37 - any authentication requirements
44:39 - selecting formats and styles decide on
44:42 - your output format and style ensuring
44:44 - it's readable and accessible for your
44:45 - target audience integration and
44:47 - automation integrate documentation
44:50 - generation into your continuous
44:51 - integration and deployment pipelines
44:53 - within Azure Dev Ops on the right we
44:56 - have an example of an API
44:58 - documentation this API documentation
45:00 - details two endpoints for version 1 two
45:02 - 3 of a service the first endpoint is
45:05 - post API login which authenticates users
45:07 - and returns a token upon successful
45:09 - login it requires a username and
45:11 - password in the request body the second
45:13 - in point is get API users which
45:15 - retrieves a list of users both in points
45:18 - provide example responses indicating
45:20 - successful operations with a 200 okay
45:23 - status best practices for API
45:25 - documentation
45:27 - consistency use a consistent format for
45:29 - all API and points to make the
45:31 - documentation easy to follow Clarity
45:33 - ensure that descriptions are clear and
45:35 - concise avoiding ambiguity Version
45:38 - Control manage your API documentation
45:40 - within Azure repos for versioning and
45:42 - historical tracking regular updates keep
45:45 - the documentation current with every
45:46 - release deprecating outdated information
45:49 - prly feack mechanisms include a process
45:52 - for developers and users to provide
45:54 - feedback on the documentation for
45:56 - continuous Improvement
45:57 - by focusing on these elements your API
46:00 - documentation will be an invaluable
46:01 - resource for your team and stakeholders
46:03 - supporting the effective use and
46:05 - integration of your software's API so
46:08 - that's an overview of API
46:14 - documentation with the rise of devops
46:16 - and get stronghold inversion control the
46:18 - manual slog of updating docs is given
46:20 - way to automation now developers can
46:22 - create Dynamic documentation straight
46:24 - from their G history here's a guide on
46:26 - how how to automate documentation using
46:28 - Azure Dev op Solutions and its Azure
46:30 - pipelines feature three requisites a git
46:33 - repository hosted on platforms like
46:35 - GitHub or Azure repos an Azure devops
46:38 - account connected to this repository
46:40 - automating documentation with Azure
46:42 - pipelines step one set up your pipeline
46:45 - in Azure Dev Ops select pipelines from
46:47 - the project menu and click new pipeline
46:50 - take your code repositories platform in
46:52 - the repository itself choose the main
46:54 - branch as the source for your Docs
46:56 - tailor your pipeline settings pick the
46:58 - right agent and decide when this
47:00 - pipeline should run add tasks for
47:02 - building the code and another for
47:03 - generating
47:04 - docs step two build the code and insert
47:07 - a build task into your pipeline to
47:09 - compile your code this can be net core
47:12 - node.js Python and many more fine-tune
47:15 - this task to match your project this
47:16 - might mean different commands or scripts
47:18 - depending on what you're building
47:20 - confirm a successful build before moving
47:22 - on step three generate the documentation
47:25 - post build selected tool like docx
47:27 - tailored for net projects to parse your
47:30 - G history into documentation add a new
47:32 - task in your pipeline for docx set this
47:35 - up with the correct paths and
47:36 - configurations and Let It Craft your
47:39 - docs step four publish your work once
47:42 - your documentation is ready pick a spot
47:44 - to publish it this could be Azure blob
47:46 - storage an FTP server or Azure
47:48 - pipeline's own artifact storage add a
47:50 - publishing task to the pipeline and
47:52 - configure it with the necessary details
47:55 - deploy this task and see your document
47:57 - ation go live step five make it
47:59 - automatic to really put your feet up
48:01 - configure triggers and Azure pipelines
48:03 - to run your documentation job on
48:05 - autopilot you can set these to activate
48:07 - on new commits merges or even on a
48:09 - schedule once set your documentation
48:11 - updates as your code does no extra input
48:13 - needed so this is a simplified overview
48:16 - for automating get history documentation
48:18 - with Azure Dev
48:20 - [Music]
48:23 - Ops hey this is Andrew Brown from exam
48:26 - Pro and in this section we'll be going
48:27 - over what are web hooks web hooks are
48:30 - userdefined HTTP callbacks triggered by
48:32 - specific events like code pushes or
48:34 - comments on a blog when an event occurs
48:36 - The Source site makes an HTTP request to
48:39 - a configured URL this allows for
48:41 - automated actions such as data transfer
48:43 - notifications or initiating other
48:45 - workflows how web books work event
48:47 - occurs a specific event triggers the
48:49 - webook this event could be an update a
48:52 - deletion or some activity like a user
48:54 - action or system event http request the
48:57 - source site makes an HTTP request to the
48:59 - web books URL this request can be a post
49:02 - which is the most common get or any
49:04 - other HTTP method depending on what was
49:06 - configured action taken the server that
49:09 - receives the webbook does something with
49:10 - the information like updating a database
49:13 - notifying users or initiating other
49:15 - workflows some of the common uses of web
49:18 - hooks include automating workflows web
49:20 - hooks can automatically update a testing
49:22 - server deploy applications or update a
49:24 - backup notifications they can notify
49:27 - other systems or services in real time
49:29 - when events happen for example if
49:31 - someone posts a comment on a Blog a
49:33 - webook could automatically tweet the
49:35 - comment or send an email Integrations
49:37 - many services offer web hooks to
49:39 - integrate with other services without
49:40 - requiring a custom interface for example
49:43 - PayPal uses web hooks to notify your
49:45 - accounting software when you receive a
49:47 - payment advantages of web hooks
49:49 - efficiency web books offer a more
49:51 - efficient method for receiving data than
49:53 - continually pulling a service for
49:54 - updates they push data as a becomes
49:57 - available minimizing latency and
49:58 - reducing the amount of bandwidth used
50:01 - realtime processing web hooks can
50:03 - facilitate real-time data processing by
50:05 - triggering a reaction immediately after
50:07 - the event occurs so that's a quick
50:09 - overview of web
50:11 - [Music]
50:14 - hooks as we mentioned briefly earlier
50:16 - webs and Azure devops trigger HTTP
50:19 - notifications to a URL for events like
50:21 - code updates or build completions
50:23 - facilitating integration with other
50:25 - systems so let's go over some of the
50:27 - steps to configure notifications with
50:29 - web hooks select the event navigate to
50:32 - the project settings and then to the
50:33 - notifications tab as shown in the image
50:35 - on the right identify the event you want
50:38 - to track for instance if you're
50:40 - interested in when a bill completes you
50:41 - would select that event new subscription
50:44 - click on new subscription to create a
50:46 - new webook select the specific event you
50:48 - want such as build completes configure
50:51 - action define the action that should
50:53 - happen when the event occurs this
50:55 - typically involves sending a notific to
50:57 - an external
50:58 - service customize your webook you can
51:00 - customize what information you send
51:02 - along with the webook Azure devops
51:04 - allows you to send specific data related
51:06 - to the event authentication if needed if
51:09 - your inpoint requires authentication you
51:11 - will need to configure the appropriate
51:12 - headers or payload with authentication
51:14 - tokens or Keys test the subscription
51:17 - once configured it's crucial to test the
51:19 - webook to ensure it works as expected
51:21 - Azure devops typically allows you to
51:23 - test it through the interface Monitor
51:25 - and adjust after after setting up
51:27 - monitor the notifications and ensure
51:29 - they're firing correctly you might need
51:30 - to troubleshoot or adjust settings if
51:32 - you're not receiving the notifications
51:33 - as expected so that's a quick and
51:36 - general overview of how to configure
51:38 - notifications with web
51:40 - [Music]
51:43 - hooks hey this is Andrew Brown and we
51:45 - are taking a look at Version Control
51:47 - Systems which are designed to track
51:48 - changes or revisions to code and there's
51:51 - been a lot of software over the years
51:52 - that helped us do that we had CVS abers
51:54 - mercal and get so back uh in 1990s when
51:58 - we got
51:59 - CVS though even though we had it I don't
52:01 - think a lot of companies were using it
52:02 - it took some time to adopt if you ever
52:04 - heard of like Doom or Wolfenstein you'd
52:06 - be uh interested to learn they didn't
52:08 - use Version Control Systems and what
52:10 - they would do is they would literally
52:12 - copy files onto floppies and hope that
52:15 - they don't lose their files but of
52:17 - course a Version Control Systems makes
52:18 - it really easy to not worry about losing
52:21 - floppies or CDs or drives because they
52:24 - keep track of all the history then came
52:26 - sub version in 2000 but the real game
52:29 - Cher was in 2005 when we were introduced
52:31 - to a new type of version control system
52:34 - and we had Mercurial and get um but the
52:36 - key difference between the old ones and
52:38 - the new ones was the old ones were
52:39 - centralized and the new ones were
52:41 - decentralized and these decentralized
52:43 - ones became very popular for very
52:46 - specific reasons they had full local
52:48 - history and complete control of the repo
52:50 - locally they were straightforward and
52:52 - efficient for branching and merging
52:54 - which was a really big deal uh better
52:57 - performance improve fall tolerance
52:58 - flexible workflows work fully offline um
53:02 - and out of the two git was the one that
53:05 - won and there are reasons for that we'll
53:07 - talk about that when we look at version
53:08 - control services um but uh yeah git is
53:12 - the one that everybody is using today
53:14 - and that's why we are taking this course
53:16 - I just want to point out they going to
53:17 - come across a lot of terms that sound
53:19 - like trees tree trunk branches um the
53:23 - reason for this is that Version Control
53:25 - represents um uh the revisions or
53:28 - changes in a graph-like structure you
53:30 - can even say a dag um if you're familiar
53:33 - with that and so uh you know you'll see
53:36 - these terms and we're not talking about
53:37 - real trees we're talking about uh the
53:39 - components of a Version Control so there
53:42 - you
53:43 - [Music]
53:47 - go hey this is Angie Brown and we are
53:49 - taking a look at git so git is a
53:51 - distributed Version Control System a
53:54 - dvcs that's going to be hard to remember
53:57 - and it's created by lonus Toral if
54:00 - you've ever seen that name before you
54:02 - might know that lonus is the creator of
54:04 - the Linux kernel but he is also the
54:07 - creator of git and git right now resides
54:10 - with the Linux Foundation which I
54:11 - believe is a nonprofit set up by Linus
54:15 - as well or has some part to do with it
54:17 - where a lot of open- source projects
54:19 - reside um but you know I don't really
54:22 - want to focus on that I want to focus on
54:23 - the practicalities of git so the idea
54:25 - with Git is that each change of your
54:27 - code a git commit can be captured and
54:30 - tracked through the history of your
54:32 - project a git tree so I'm going to get
54:34 - my pen tool out here for just a second
54:37 - and so I just want to make this very
54:38 - clear so we have over here a file and a
54:42 - get commit can or a commit can be made
54:45 - up of multiple files with multiple
54:47 - changes in them and then they're
54:48 - represented over with a a a a message
54:51 - okay so here this is a single um git
54:55 - commit and it can have multiple files
54:57 - and uh files and changes in that single
54:59 - one and then that's your tree okay so
55:02 - hopefully that is clear if it's not
55:03 - don't worry we'll get Hands-On skills
55:05 - and we'll definitely be able to remember
55:06 - them later I want to take a look at a
55:08 - bunch of common get terms um and it
55:11 - doesn't matter if you remember these now
55:13 - but you will know what they are
55:15 - hopefully by the end of this course um
55:17 - and so there is this nice graphic here
55:19 - that is provided by Wikipedia that gives
55:22 - an idea of how all of these terms uh
55:24 - work together um but let's go quickly
55:27 - through them and see what we can make
55:29 - sense of so the first term is a
55:30 - repository this represents the logical
55:32 - container holding the codebase in fact
55:35 - you you could interchange the word
55:36 - codebase repository and mostly mean the
55:39 - same thing we have a Commit This
55:41 - represents a change of data in the local
55:43 - repository and so um that's pretty clear
55:47 - then we have the tree this represents
55:48 - the entire history of a of a repo so
55:50 - when you see tree just think of that
55:52 - graph we have remote uh this is a
55:54 - version of your project hosted else Ware
55:56 - used for exchanging commits uh some
55:59 - people might be a bit uh picky about
56:00 - this because they might say remote is
56:02 - actually a remote reference to
56:04 - repository so it's pointing it's a
56:06 - pointer but I'm just going to make it
56:08 - think that it's a remote uh repo it's
56:10 - just somewhere else and there uh there
56:12 - are branches so these are Divergent path
56:14 - to development allowing isolated changes
56:16 - you're absolutely going to know what
56:17 - branches are you're absolutely going to
56:18 - have to work with them quite a bit um
56:20 - there is a branch known as main it was
56:23 - formerly known as Master uh the word was
56:25 - changed because it was not a popular
56:27 - term anymore and so now main is the new
56:30 - name uh and this is usually the default
56:33 - Branch or the base
56:35 - Branch uh if that makes sense there too
56:38 - so we have clone this creates a complete
56:40 - local copy of a repository including its
56:42 - history so this will create like a
56:44 - little dogit folder um so it's not just
56:46 - the contents of the files but some
56:48 - configuration around the git repo we
56:51 - have checkout so this switches between
56:52 - different branches or commits in your
56:54 - repo we have poll so this downloads
56:56 - changes from a remote repository and
56:58 - merges them into your branch we have
57:00 - push this uploads your local repository
57:03 - changes to a remote repository we have
57:05 - fetch this downloads data from a remote
57:07 - repo without integrating it into your
57:09 - work um we have reset so undoes local
57:12 - changes without options to unstage
57:14 - revert commits we have merge this
57:17 - combines multiple commit histories into
57:19 - one we have staging files this prepares
57:22 - and organizes uh changes for commits
57:25 - it's not a command but like it's just
57:27 - where you would work with your files um
57:29 - in the example here I'm just going to
57:31 - get my pen tool out again it's kind of
57:33 - over here it has to relate with this up
57:35 - here as well and So within staging files
57:39 - we're going to have commits which we
57:40 - already talked about prior and then
57:42 - there's that add command so adding
57:44 - things that will get committed so
57:46 - hopefully that makes sense and we'll see
57:48 - you in the next one
57:49 - [Music]
57:52 - okay hey this is angre brown and we are
57:55 - taking a look at version control
57:56 - services and if you're thinking that we
57:58 - already covered this it looks that way
58:01 - but the other one was Version Control
58:02 - Systems this one is version control
58:04 - services and yes they have the same
58:06 - initialism which is confusing but it's
58:09 - very important to make that distinction
58:11 - because those are two separate things so
58:13 - version control services are fully
58:15 - managed cloud services that host your
58:17 - version controlled repositories these
58:19 - Services often have additional
58:21 - functionality going Beyond just being a
58:23 - remote host for your repos get is the
58:26 - most popular and often the only choice
58:28 - for a VCS and we often call these git
58:32 - only uh providers get providers um I
58:36 - need to also point out that some people
58:39 - call version control services Version
58:41 - Control Systems and vice versa and it
58:44 - just gets really confusing so I did my
58:46 - best to make that clear distinction
58:48 - between the two okay let's take a look
58:50 - at some vcs's so the first here is
58:53 - GitHub and it's owned by Microsoft it's
58:55 - the most popular VCS uh due to offering
58:59 - uh due to its ease of use offering and
59:01 - being around the longest at least forget
59:04 - um and they've always been very
59:06 - developer focused and super friendly uh
59:08 - GitHub is primarily where open source
59:10 - projects are hosted and offer Rich
59:11 - functionalities such as issue tracking
59:13 - automation pipelines and a host of other
59:15 - features I remember the day GitHub came
59:18 - out and I signed up for it because I was
59:20 - so done with using subversion then came
59:24 - along gitlab so gitlab was an emerging
59:26 - competitor to GitHub and at the time had
59:28 - unique features such as cicd Pipeline
59:30 - and improved security measures this is
59:33 - no longer the case as GitHub is now on
59:36 - par with gitlab um but yeah at one point
59:38 - a lot of people were looking at gitlab
59:40 - then there's bit bucket this one is
59:42 - owned by at laian you might have heard
59:44 - of laian before because they are uh the
59:46 - same company that makes jira and jira is
59:49 - the most commonly used project manager
59:53 - uh for um people in Tech so you know
59:57 - even though GitHub is really great for
59:59 - developers a lot of companies still use
60:01 - bitbucket and the interesting thing
60:02 - about bitbucket was that they originally
60:05 - hosted Mercurial so remember I said back
60:07 - in 2005 mercal and get came out well
60:11 - alatan adopted mercal GitHub adopted um
60:15 - git and git one and GitHub one and so
60:18 - what's really interesting is that
60:20 - bitbucket then eventually added git and
60:22 - then sunsetted Mercurial so everything
60:26 - basically is get now there is another
60:28 - provider called sourceforge they're one
60:30 - of the oldest places to host your source
60:32 - code they existed before GitHub um and
60:34 - they were the first uh to provide free
60:38 - of charge um uh get repository hosting
60:41 - to open- Source projects um the only
60:44 - thing about Source Forge is that they
60:46 - never really dominated because they just
60:50 - had so many ads and bad practices and so
60:53 - it just didn't work out for them they
60:54 - are still around and a lot of Open
60:56 - Source projects like to only host there
60:59 - they might mirror make a copy to other
61:01 - providers like GitHub um but for the
61:03 - most part everybody's on GitHub um but
61:06 - there you
61:07 - [Music]
61:11 - go hey this is Angie Brown we are taking
61:13 - a look at GitHub and this is a version
61:15 - controlled service that initially
61:17 - offered hosted manage remote get repos
61:20 - and is expanded to provide other
61:22 - offerings around hosted code bases if
61:24 - you go look up what GitHub calls
61:26 - themselves today they call themselves
61:28 - like an AI uh developer powered platform
61:32 - um it's really bizarre because they are
61:34 - basically a host for uh for get repos
61:38 - with extra stuff on top of it but I
61:40 - guess since AI is so popular they got to
61:41 - try right but let's take a look at all
61:43 - the functionality that they have so we
61:45 - have get repository hosting that is
61:47 - their main bread and butter we have
61:49 - project management tools issue tracking
61:51 - PLL requests and code reviews GitHub
61:53 - pages and wikis GitHub actions GitHub
61:56 - co-pilot GitHub code spaces GitHub
61:59 - Marketplace GitHub gists GitHub
62:02 - discussions collaboration features for
62:05 - organization organizations and teams API
62:08 - access development so GitHub development
62:10 - uh they have a GitHub CI they have
62:13 - sdks um we have security features like
62:15 - autod detecting credentials in repos
62:18 - they have education specific things or
62:20 - course automation like GitHub classroom
62:22 - and I'm sure they have more uh we're
62:25 - going to learn about all of these things
62:26 - because this is what the GitHub course
62:28 - is about to understand the full offering
62:30 - of GitHub and to make best use of it and
62:32 - just a fun fact is that GitHub was
62:34 - originally built in Ruby on Rails Ruby
62:37 - is my favorite language rails is my
62:38 - favorite framework so I've been uh uh on
62:41 - the the ride or the train since day one
62:44 - with GitHub um so I know it pretty well
62:46 - but let's jump into it
62:48 - [Music]
62:52 - okay hey this is angrew brown and in
62:54 - this fall along I want to show you how
62:56 - to create your own GitHub account every
62:59 - single developer on the planet should
63:01 - have a GitHub account because it's a
63:02 - great way to Showcase your work uh we'll
63:05 - talk about that later but you can see
63:06 - that I'm already logged in here so I
63:08 - already have a GitHub account and what
63:09 - I'm going to do is log out and I'm going
63:13 - to create a new one from scratch so here
63:15 - we can see uh we can have multiple ones
63:17 - um I'm going to just sign out of all of
63:19 - my accounts here and let's go ahead and
63:21 - create ourselves a new one so I'm not
63:23 - sure remember I told earli I told you
63:25 - they're like the leading AI power
63:26 - developer platform which is such a silly
63:28 - term but um let's go ahead and see if we
63:30 - can make a new one so just in case it's
63:31 - the future and they've changed this
63:32 - homepage I'm going to go up to sign up
63:35 - and I'm going to see if I can make an
63:38 - account if I can find an email that has
63:40 - not been used so far so I'm going to
63:42 - type Andre exam pro. if you're using
63:44 - Gmail so I can't use that one if you're
63:46 - using Gmail you can use like plus signs
63:48 - to um create multiple ones so like my
63:51 - really really personal email don't email
63:53 - me because I don't ever check this one
63:54 - is like omen gmail.com you'll learn that
63:57 - my username on GitHub is Omen King why
64:01 - it is that I don't want to talk about it
64:03 - it's like forever ago I made this
64:05 - account like so long ago and I really
64:07 - wish I could have got Andrew Brown as my
64:09 - username but that's not what it is and
64:11 - so I'm just going to go here and say alt
64:13 - okay so this is a trick with Gmail that
64:15 - you can do you can put a plus alt on it
64:17 - or uh maybe a minus I'm not sure but
64:20 - let's go ahead and see if that works and
64:22 - I need to create a password so I like to
64:24 - generate really strong passwords
64:26 - um you can use whatever you want I like
64:29 - to use hold on here I like to use this
64:32 - site which is
64:33 - the uh password generator plus password
64:37 - generator.net um I should make a
64:39 - disclaimer if this isn't insecure don't
64:41 - use it blah blah blah but I'm pretty
64:43 - sure it's fine so I'll ually go like 24
64:45 - and get a nice long password um and I'll
64:48 - just generate a few different ones off
64:49 - screen here and I'm going to enter that
64:51 - in okay so just generate out a few and
64:54 - I'm going to drop this in on here okay
64:57 - we're going to hit continue says it's
64:59 - strong that's good and then I got to
65:01 - choose my username so I probably can't
65:03 - get Andrew
65:05 - Brown and um so I need like another name
65:09 - I'm gonna try
65:11 - Dono not available that's like my game
65:14 - uh gamer uh tag on um steam so what's
65:19 - another one that I could have uh we'll
65:21 - just say Andrew Cloud can I get that one
65:24 - so hard we'll just say Andrew WC Brown
65:28 - can I get that there we go WC is my M
65:32 - middle initials it doesn't stand for
65:34 - water closet okay I know it looks like
65:36 - that we'll go ahead and hit continue I
65:38 - hit continue again and so now what I
65:41 - need to do is do this verification
65:42 - please solve this puzzle so we know
65:44 - you're a real
65:45 - person uh verify okay use the arrows to
65:49 - rotate the object to the face in the
65:52 - direction of the
65:54 - hand okay use the arrows so I think I
65:57 - have to make it face the same way match
65:59 - the
65:59 - angle okay uh this
66:03 - way
66:05 - okay there we
66:07 - go create my
66:10 - account and so now I need to open up
66:12 - that email just give me a moment okay
66:14 - all right so I've been waiting a few
66:15 - minutes and I haven't seen anything and
66:17 - I resent the code so maybe it doesn't
66:19 - like emails that have that plus in there
66:21 - it's totally possible so I might
66:23 - actually have to go ahead and create a
66:24 - new email which is quite the headache as
66:27 - I ran out of emails here unless I can
66:30 - think of another one you know what I
66:32 - think I have another idea I'm going to
66:35 - use uh a different one here so it looks
66:37 - like unverified can I change this I'm
66:41 - going to try um because you have an a
66:44 - privacy a privacy email uh will be used
66:48 - for account related
66:50 - stuff yeah I'm not really sure what's
66:52 - going on here I thought maybe my account
66:54 - even exists but it looks like it already
66:56 - does
66:59 - exist so what I'm going to do is I'm
67:01 - just going to add another one I can do
67:03 - Andrew maybe at teacher seat.com we'll
67:05 - try
67:08 - that oh it's already in use oh my
67:10 - goodness it's so hard to get an email
67:13 - out here okay let me just think about
67:15 - this for a second all right all right
67:17 - another thing I'm going to try is I'm
67:18 - going to try uh maybe Accounts at teer
67:22 - seat.com that's another one that I might
67:24 - be able to use
67:27 - okay and I going to change this over
67:29 - here and save
67:30 - it great
67:35 - and that should be my primary now
67:42 - right it really wants to send it to this
67:44 - one maybe what I can do is I can
67:47 - click oh looks like we have both okay so
67:49 - we have this one um please verify that
67:52 - I'm going to get rid of this one here
67:53 - because that one's not working I'm going
67:54 - to try Accounts at teacher city.com so
67:57 - that's in my Outlook so I'll go take a
67:58 - look there and see if I get it all right
68:01 - so this is working out totally fine so
68:03 - over here we have um the confirmation
68:05 - email so I can go ahead and just verify
68:07 - that email we can also just grab this
68:09 - link I kind of prefer using the link
68:11 - here um because that just gives me kind
68:13 - of a guarantee and we'll go here and now
68:15 - we are in so this is exciting um it's
68:18 - been a long time since I've made a new
68:19 - GitHub account so I'm not sure exactly
68:21 - what to expect but looks like we have
68:23 - some places we can start stting a new
68:24 - project collaborate with your team learn
68:27 - how to use GitHub hey I'm already doing
68:29 - that you don't need to do that GitHub
68:30 - let's go ahead and skip this for now and
68:32 - we should get back to our main dashboard
68:35 - so we are now in and we have an account
68:38 - that we can use um so yeah that's all I
68:41 - wanted to show you in this video uh but
68:44 - I'll see you in the next one okay
68:46 - [Music]
68:49 - ciao hey this is Angie Brown and this
68:51 - fall along I just want to show you that
68:53 - I'm going to be setting up multiple
68:54 - accounts to quickly switch between them
68:56 - um if you want to take full advantage of
69:00 - learning how to use GitHub you're going
69:01 - to need probably another account because
69:03 - you're going to have to have somebody
69:04 - else to work with so I already have my
69:06 - primary account I already showed you how
69:07 - to make an account so what I want you to
69:09 - do is make a secondary account I know
69:11 - it's a pain but go ahead and do that but
69:13 - what I'm going to do in this video is
69:14 - show you how you can log into both and
69:16 - switch between the two and I'm also
69:18 - going to set up a
69:20 - repository um that I'm going to put code
69:22 - examples in if we happen to put any in
69:24 - there so what I'm going to do is go up
69:25 - here at the top right corner I'm going
69:26 - to go add account and so this is going
69:28 - to allow me to log into my other account
69:30 - I can put in my username or my email so
69:32 - this one is um this is monsterbox
69:34 - pro.com that's my old my old company
69:37 - that's not been around for a long time
69:39 - but I've never updated it and the exam
69:41 - Pro email is on a another GitHub account
69:44 - but I'm going to go ahead and find the
69:45 - password so I can go log into this one
69:47 - so just give me a moment I'm just trying
69:49 - to find it here it is there is the
69:52 - password I'm going to paste it in here
69:55 - okay we'll hit sign
69:57 - in okay notice it says GitHub mobile so
69:59 - now it's my opportunity to show you
70:01 - GitHub mobile so what I'm doing is I'm
70:03 - opening up my phone and right away it
70:07 - pops up it says uh you know new signin
70:10 - request now it says reject or approve
70:12 - I'm going to hit approve it says
70:13 - authentication request was approved uh
70:15 - the first time I I had to do that I had
70:17 - to enter in like a code like two numbers
70:19 - but now from then on I just have to do
70:21 - that and it's very easy to uh to do that
70:23 - so if I want to switch between accounts
70:25 - we can go here and just switch between
70:26 - them uh freely so that is really easy
70:29 - and so what I want to do is go to exam
70:31 - Pro this is my other organization you'll
70:33 - learn about organizations in this um
70:36 - this here that didn't really help but
70:37 - what I want to do is create a new repo I
70:39 - can create a new one up here in green or
70:41 - I can go up here I never notice these up
70:43 - here but this is another place to do
70:44 - that anyway you're just watching you're
70:47 - not doing right now okay so I'm going to
70:49 - go ahead and hit new and in here I'm
70:51 - going to go to exam Pro I'm going to say
70:55 - um GitHub examples so this will be the
71:00 - um
71:01 - GitHub we'll say a repo
71:05 - containing GitHub examples for or Pro
71:09 - for programmatic examples for
71:12 - programmatic examples this will be
71:14 - public because I want you to have access
71:16 - to it I want to have a read me I'm going
71:17 - to create that repository and so this
71:19 - will crop up later in the course and
71:21 - you'll have to know where this this is
71:23 - but just remember that is but the key
71:24 - part of this video was how to log into
71:26 - another account um and be able to switch
71:29 - between them okay so we'll see you in
71:30 - the next one
71:32 - [Music]
71:35 - ciao all right so what I want to do in
71:37 - this fall along is set up a GitHub
71:40 - organization and the reason we want to
71:41 - do this is so that uh it's going to make
71:44 - it easier when we get to that section so
71:46 - what I'm going to do is go to the top
71:48 - right corner and I want to I can make
71:51 - this in either or account I'm going to
71:53 - make it in the alternate account cuz I
71:54 - already have a enough organizations in
71:56 - my main GitHub account and what I want
71:58 - to do is go over here to um maybe
72:03 - organizations and here it says you are
72:07 - not a member of an organization we could
72:08 - turn this account into an organization I
72:11 - don't want to do that or we can make a
72:12 - new org so I'm going to make a new org
72:15 - and notice right away it's going to hit
72:16 - us with some pricing so um you know
72:19 - teams gives you the uh full
72:20 - functionality we just want to have the
72:22 - free one uh which might have some
72:24 - limitations but um it should get us
72:27 - started if there's are things that we
72:28 - can't do um then I'll switch over to our
72:31 - paid one that I have in my account for
72:33 - the most part we should be able to do um
72:35 - pretty much everything as long as we're
72:36 - using a public GitHub um public GitHub
72:40 - repo so I'm going to go ahead and hit
72:42 - create a free
72:43 - organization and so I need some kind of
72:45 - name for this organization um
72:49 - so um I don't know but we'll just say uh
72:53 - GitHub
72:56 - Cloud Learners or
73:03 - journeyers okay notice that's going to
73:05 - be the name of
73:06 - it I say Accounts at teachers
73:11 - seat.com and this organization belongs
73:14 - to a personal account we could say uh
73:16 - business or institution but then we get
73:18 - a little bit more details there so I'm
73:20 - going to just stick it to normal and go
73:22 - to personal account then down below we
73:24 - need to solve our puzzle so we've seen
73:26 - this one before we'll rotate that out
73:28 - and we'll
73:29 - submit
73:31 - okay and you'll have to name your
73:33 - organization whatever you have to name
73:34 - it but that's what I'm calling mine you
73:36 - can put some numbers on the end here if
73:37 - that makes it easier you do like four
73:39 - five six seven or something because
73:40 - these are going to be unique names just
73:41 - like your your username going to go
73:43 - ahead and hit next and so now it says
73:46 - add organization members so we can go
73:47 - ahead and add some people so what I want
73:48 - to do is I want to add um Omen king so
73:53 - I'm going to go ahead and do that please
73:55 - don't add me all right add your own
73:58 - other account your two
73:59 - accounts okay we'll hit complete setup
74:02 - and so now this person has been invited
74:04 - I'm not sure if they're instantly added
74:07 - um not yet but I believe that I was yeah
74:12 - here's the invitation so we'll go here
74:14 - so the invite has been sent and we'll
74:17 - have to go look for that so I'm going to
74:18 - go over here and switch to my other
74:20 - account okay and so now what I'll do is
74:23 - I'll click up here and maybe it's up
74:26 - here my
74:28 - notifications
74:29 - no do I have invites
74:32 - here
74:35 - no and um maybe I got an email I'll
74:38 - check my
74:39 - email no email and this is something
74:42 - you'll learn about GitHub which is like
74:44 - invites are a pain and you always have
74:45 - to really figure it out so I'm just
74:48 - trying to think about where that or that
74:49 - could be um what we could try to do is
74:51 - type in the organization name which I
74:54 - thought we already did
74:56 - um
74:58 - so this one let's see my profile is
75:01 - this yeah so the organization is going
75:03 - to be what was it
75:05 - Cloud oh I don't even
75:08 - remember we'll switch back to the other
75:10 - one what a
75:11 - pain okay and we will look for that
75:15 - organization GitHub Cloud journe so I'm
75:18 - just going to copy this
75:20 - URL I want the um view organization I
75:23 - want to go to this page actually I'm
75:25 - going to copy it here I'm go switch
75:28 - back and I'll enter this
75:32 - in and so now notice that it's showing
75:34 - me where the invitation is so it says
75:36 - Andrew Brown invited you to join this
75:39 - organization view
75:41 - invitations okay and I I don't know if
75:44 - there is but I'm just going to double
75:45 - check here because a lot of times GitHub
75:46 - will have like invitations invitations
75:50 - they might have a page for it they don't
75:52 - GitHub if you're watching make a slin
75:55 - ation page so we can easily find them
75:56 - across them here so as you've been
75:58 - invited to GitHub Cloud jors ask for
76:01 - GitHub co-pilot seat optional I guess
76:03 - this is kind of an upsell they're like
76:04 - hey do you want to be able to use GitHub
76:07 - co-pilot but I'm going go ahead and join
76:09 - this organization and now I'm in there
76:11 - so there's two people in here again
76:13 - we'll come back to this later I'm the
76:15 - member this is the
76:16 - owner um and uh you know if your company
76:20 - is using GitHub they're likely going to
76:21 - be using using organization so it's good
76:23 - to get some knowledge on that but I'll
76:25 - see you in the next one
76:27 - [Music]
76:30 - ciao all right let's make sure we
76:33 - understand clearly the difference
76:34 - between git and GitHub I don't think
76:36 - it's that confusing but it is in the
76:38 - study guide or exam outline so I'm just
76:41 - trying to make content that they want us
76:42 - to know um so let's do a comparison and
76:45 - go through some things to make sure we
76:48 - understand the difference so git is a
76:50 - distributed Version Control System a
76:52 - dbcs and GitHub is a version control as
76:55 - a service I called it a Version Control
76:58 - service it can also be called a get
77:00 - provider or you can call it a version
77:01 - control as a service I'm just trying to
77:03 - get you exposure to all those different
77:04 - terms you could call what GitHub is for
77:07 - functionality for Git it manages source
77:10 - code history for GitHub it provides
77:12 - cloud storage for git repos of course it
77:15 - does more than that but that's its main
77:18 - functionality um for Access you're doing
77:20 - this via your local system installation
77:23 - or it's basically wherever it's
77:24 - installed the point is is that you're
77:26 - working on it on a machine on a server
77:28 - or some kind of compute uh and GitHub is
77:31 - access through a web interface because
77:34 - it is a cloud service for the scope
77:36 - we're talking about local repository
77:38 - management and then for GitHub we're
77:40 - actually talking about the online
77:41 - collaboration and remote hosting uh so
77:44 - anything that has to do with remote or
77:45 - things around the repo the git repo
77:48 - itself for collaboration it's for local
77:50 - changes requires manual sharing for
77:52 - GitHub it has integrated tools for
77:54 - collaboration ation like issues and PR
77:56 - and a lot of other features for usage
77:59 - you're going to be using this primarily
78:01 - by the command line interface there's
78:02 - definitely software out there that makes
78:04 - it a lot easier to use um we'll get into
78:07 - that but generally it's a command line
78:10 - tool that you're using for GitHub it has
78:12 - a graphical interface and it also has
78:14 - its own CLI tool but most people are
78:16 - interacting with it via the website okay
78:20 - so there you go ciao
78:22 - [Music]
78:26 - so a git repo or repository is your git
78:30 - repo think of your local one that you
78:32 - push Upstream to GitHub to be uh hosted
78:36 - remotely and GitHub allows you access to
78:39 - manage your repo uh with several
78:41 - functionalities so here is a screenshot
78:44 - of a GitHub repo this is when I ran a
78:45 - boot camp in
78:47 - 2023 uh and so let's talk about what is
78:50 - on this GitHub repo page I don't know
78:52 - what they want to call this page I just
78:53 - called the GitHub repo page for a
78:55 - specific repo um but you can view
78:57 - different branches view tags view commit
79:00 - history explore repo files view releases
79:04 - uh see codebase language breakdown view
79:07 - top level markdown files and so those
79:10 - top level files might be the readme the
79:12 - license uh security other things like
79:15 - that you can perform actions from this
79:17 - page or quickly to it such as pinning
79:20 - watching forking starring cloning so so
79:25 - uh a lot of stuff going on on this page
79:26 - and this is going to be we're going to
79:28 - be spending a lot of time
79:29 - or going from here to somewhere else but
79:33 - that is a GitHub repo so there you
79:35 - [Music]
79:38 - go all right in this follow along I just
79:40 - want to give you a tour of GitHub repos
79:43 - so that you have a a general Fami
79:46 - familiarity uh so that when we start
79:49 - diving in a bit deeper we understand
79:50 - what we're looking at so I'm on my
79:52 - dashboard I have a lot of different
79:54 - repositor
79:55 - um and so I can go here and find a
79:57 - repository I can search stuff and say
79:59 - like if I'm looking for my boot camp I
80:00 - can type in boot camp here and then make
80:02 - my way over here and find it um a lot of
80:05 - times when you are looking for stuff
80:06 - you're going to use the global search so
80:08 - up here you could do that as well and I
80:10 - could find my own repos or other repos
80:13 - um there are a lot of Open Source repos
80:15 - on GitHub and so um I know rails pretty
80:18 - well so I'll go ahead and type in rails
80:19 - and so we have this rails repo I'm going
80:22 - to go open this open this up and take a
80:24 - look and see what we can see because
80:26 - this is a very mature Li um uh GitHub
80:28 - repo and we'll make it very clear of all
80:30 - the functionality that's happening so
80:32 - notice we have our main area this is
80:34 - where all of our files are uh we can
80:36 - actually view any of these files so I
80:38 - can click into any of them so I can go
80:39 - into the gem file and it will show me
80:42 - the contents of the gem file what I like
80:44 - about uh GitHub is that when you click
80:46 - into here then you kind of get this file
80:48 - explorer and it's extremely powerful uh
80:51 - if I click this on the right hand side
80:52 - it will show me symbols that's not a
80:53 - very good example I might open up a ruby
80:55 - file to show you what I mean so I'm just
80:57 - looking for a ruby file here and so this
80:59 - will show you like places you could jump
81:01 - uh jump towards in your code um that's
81:05 - really nice you can see who did what by
81:07 - going to blame so we can see exactly
81:09 - what somebody's doing by the way I'm
81:11 - going really quick here it's not
81:13 - important for you to remember any of
81:14 - this I'm just giving you a tour of stuff
81:17 - so just relax and uh enjoy the
81:19 - information that we're learning here you
81:21 - don't have to write it down if I wanted
81:22 - to find a file really quickly in this
81:24 - repo I go here and type something in so
81:26 - maybe I'm looking for um something like
81:28 - View and so it's going to drop down and
81:31 - it has this fuzzy search if I want to
81:32 - find a ruby file I could type this in we
81:34 - have a lot of them here I believe
81:37 - there's a hotkey here so if I hit T if
81:38 - I'm over here and I hit T it will bring
81:41 - me over there I can switch branches
81:43 - really easily um does that let me add a
81:46 - file it's not my repo but if I add a
81:48 - file I'd have to create a fork um the
81:50 - search brings that up there but we'll go
81:52 - back over to code Okay so my point here
81:55 - is that you have all the files here and
81:57 - you can browse them um you can switch
81:59 - branches you can go and take a look at
82:01 - all of your branches you can take a look
82:02 - at all your tags you can star you can
82:05 - Fork you can watch here for code you
82:07 - could launch this up in code spaces
82:10 - which is a cloud developer environment I
82:12 - normally have um G pod install so if I
82:15 - hit refresh that button might show up
82:16 - here this button you will not have this
82:18 - button I installed this because it's
82:20 - like code spaces but
82:22 - different um on the the right hand side
82:25 - you get a bunch of information about the
82:26 - repo like stars watching Fork uh some of
82:30 - these probably are conditional cuz I
82:31 - don't remember seeing these on myos you
82:33 - have releases so maybe you are building
82:34 - up binaries like downloadable files that
82:38 - people can uh utilize so some people
82:40 - they will host all their code here and
82:42 - they'll build the binaries for quick
82:44 - downloads so that's somewhere else you
82:45 - can go to packages is probably similar
82:48 - to releases I don't I don't think I've
82:50 - ever used packages ever in my life uh
82:53 - let's go over here and take a look
82:54 - browse browsing all packages yeah I
82:56 - don't know what packages do we can see
82:59 - who's using it the contributors so
83:01 - people that are writing uh writing code
83:04 - um we have the languages so you can see
83:06 - this is mostly a
83:07 - ruby LI or um repo which makes sense
83:11 - because it's Ruby on Rails down below we
83:13 - get a preview of our readme file so that
83:16 - is in the top level directory they have
83:17 - a codes of conduct I imagine that is a
83:19 - markdown file here and as well the
83:21 - license file I'm sure that's in here as
83:23 - well the security policy as well um so
83:27 - yeah there's a lot going on in here and
83:29 - then there's all this stuff up here
83:30 - these are features on top of your
83:33 - repo so lots and lots and lots of stuff
83:36 - if we want to see our commits we can go
83:38 - here and click on commits and this is
83:40 - kind of like a tree it doesn't give you
83:42 - the full view because when you are
83:44 - looking at um when you're looking at a
83:48 - tree uh there's branches and stuff so
83:50 - we're missing that information here but
83:51 - the idea is you can go here and uh go to
83:54 - different branches and look at those
83:55 - commits and that's basically all I
83:57 - wanted to do here we'll get into it a
83:59 - lot deeper later on but that is your
84:01 - tour of GitHub repos
84:05 - [Music]
84:08 - ciao hey this is Angie Brown from exam
84:11 - Pro and we are taking a look at git
84:13 - commits so we're going to take a look at
84:15 - a series of git components uh in this
84:18 - course um it's not really a focus on git
84:22 - skills but more so GitHub but I want to
84:25 - make sure you still have some git skills
84:27 - so after we go through uh some of these
84:28 - things I'll then do like a really quick
84:30 - and dirty uh git uh command crash course
84:34 - okay so a git commit represents
84:36 - incremental changes to a codebase
84:38 - represented with a git tree so a graph
84:41 - at a specific time so here we can see
84:44 - that git tree um this is in GitHub so
84:48 - it's not the full representation when we
84:50 - go into um vs code we will we can see a
84:54 - better representation of it there are
84:56 - external tools for that but for the most
84:58 - part the idea is that you have um uh you
85:01 - have get commits that are over a
85:03 - historical period of time then we have
85:06 - our uh git commit here is one within uh
85:09 - GitHub that I clicked through and I
85:11 - looked at okay and from here a get
85:14 - commit contains additional modifications
85:16 - deletions of files additions and
85:18 - deletions of file contents and it's not
85:21 - the whole file themselves and this is a
85:25 - strategy to make the uh commits
85:28 - efficient because if you if you were to
85:30 - store full copies and every single
85:32 - commit your repo will get really big
85:35 - really fast I'm going to repeat that
85:36 - again and we'll talk about the contents
85:38 - of commit fils here just shortly uh each
85:41 - commit has a Shaw hash that acts as an
85:44 - ID so it looks something like this we
85:47 - can use this uh to check out very
85:50 - specific commits which is very useful I
85:52 - want to repeat get does not store the
85:55 - whole files in each commit but rather
85:57 - the state of changes this greatly
85:59 - reduces the file size so uh so for
86:03 - developers to the developer you it will
86:05 - look like a whole file but really when
86:07 - you store it in in uh your G tree it's
86:09 - not going to be like that um so what are
86:12 - the components of a get commit we talked
86:14 - a little bit about that but we have that
86:16 - commit hash that is a unique Shaw one
86:19 - hash identifier for the commit I don't
86:21 - know if it's really Shaw one because I'm
86:22 - not really familiar with all the
86:23 - different a Shaw but it's Shaw something
86:26 - uh we have the author information so we
86:27 - have name and email often you have to
86:30 - configure git to say what email you're
86:32 - utilizing the name so that's attached to
86:34 - the commit message U or the commit
86:36 - itself you have the commit message is is
86:38 - the description of uh the the Commit
86:41 - This is we're going to be spending a lot
86:42 - of time when you are making commits
86:44 - because you want to write good commit
86:45 - messages you have a timestamp so this is
86:48 - the date and time when the commit was
86:49 - made um you have the parent commit hash
86:52 - this is a Shaw and hash of the commit
86:54 - this commit is based on I don't really
86:57 - understand that because I've never had
86:58 - to bother with the parent one but it is
87:01 - something that's in there and the
87:02 - snapshot of the content a snapshot of
87:04 - the project at the time of the commit
87:06 - not the actual files but references to
87:09 - them and the changes that are occurring
87:11 - so if you had vs code open and we were
87:14 - taking a look at a um at uh changes that
87:18 - we have staged so they haven't been
87:20 - committed yet but you can see here we
87:22 - have uh the commit message it says
87:23 - remove old comments we have files
87:25 - changed that we plan on putting in the
87:28 - commit and you can see some deletions
87:31 - there on the right hand side we can have
87:32 - additions so hopefully it's very clear
87:34 - what a uh a git commit is you are going
87:38 - to need to know these basic commands and
87:41 - we will get a little bit practice again
87:44 - quick and dirty this is not a full-blown
87:46 - git course but it'll be enough to get
87:47 - you buy so that you can do the GitHub
87:49 - stuff so we have a bunch of stuff there
87:51 - like get add get remove get Comm message
87:53 - with the The Hyphen m flag to add a
87:55 - message hyphen a to automatically stage
87:58 - all track changes if you have a commit
88:01 - and you haven't pushed it up uh to your
88:03 - uh your remote repo you can amend it um
88:06 - you can create empty commits uh you can
88:09 - specify the author if you need to you
88:11 - can check out a very specific commit but
88:13 - yeah that is get commits in a nutshell
88:16 - and I'll see you in the next one
88:18 - [Music]
88:21 - ciao hey this is Angie Brown and we are
88:23 - taking taking a look at get Branch so
88:26 - get branch is a Divergence of the state
88:29 - of the repo there might be better uh
88:32 - descriptions than that but that's the
88:33 - way I think of it you can think of
88:35 - branches as being copies of a point in
88:37 - time that have been modified to be
88:39 - different and so what I want to do is
88:42 - Step you through what it would look like
88:44 - working with get branches and this is
88:46 - going to be a little bit messy and it
88:48 - doesn't matter if you can remember or
88:49 - make sense of all this because it will
88:51 - make more sense when we start working
88:52 - with it but do your best to follow along
88:54 - here so imagine we have a git repo in
88:57 - that git repo we have a main branch and
89:00 - basically all git repos have a main
89:03 - branch and that's pretty much the
89:04 - standard name for them now and we're
89:06 - going to also have a production Branch
89:08 - the main branch is where we're going to
89:10 - have code uh that features and bugs will
89:13 - be um rolled up into and then when we're
89:16 - ready to push it out for production it
89:18 - will go to the production branch and
89:20 - some cicd tool will push it out and
89:22 - automatically deploy it so um let's
89:25 - imagine we already have a commit in the
89:27 - main branch uh maybe there are previous
89:29 - versions in the production Branch we're
89:31 - not going to worry about it so uh you
89:33 - have developer a developer a needs to to
89:36 - work on a very specific feature they're
89:38 - going to open up a feature branch and in
89:40 - there they're going to put in some
89:41 - commits and they're working along uh
89:45 - meanwhile in the company somebody
89:47 - already has pushed some stuff into the
89:48 - main branch it's not ready to go in
89:50 - production but that commit is now out so
89:53 - what's important to note here is that
89:55 - feature Branch one is not aware of that
89:57 - new commit because things are happening
89:59 - asynchronous a in async manner in
90:02 - different branches and this is the
90:04 - challenge with get is that you have to
90:05 - deal with all this async stuff and make
90:08 - sure you bring those changes into yours
90:10 - deal with conflicts things like that now
90:13 - let's say we have developer B and
90:14 - developer B is working on feature Branch
90:16 - 2 and when they started on their on
90:19 - their um uh their feature they decided
90:23 - to branch from this point in time okay
90:26 - and so they start working on it and they
90:28 - get their feature uh done and um they
90:31 - get they talk to their um uh the
90:35 - director of engineering and and they
90:36 - make a poll request the poll request
90:38 - gets accepted it gets merged back into
90:41 - main okay and
90:42 - so developer a who's working on uh
90:46 - feature Branch one has all these changes
90:48 - that they still don't have so let's
90:50 - remember that they're going to have to
90:51 - deal with that at some point but anyway
90:54 - that feature got merged into Main and it
90:56 - looks like it's ready to go in
90:57 - production so it gets merged into
90:59 - production and so this particular commit
91:03 - contains get my pen out here contains
91:05 - all of this information right and it's
91:08 - all packed into here if that makes sense
91:12 - okay I'm just going to erase that here
91:14 - and so that gets P production and it
91:16 - gets tagged a lot of cicd systems will
91:19 - trigger when a tag is applied that's
91:21 - definitely how I do it but now coming
91:23 - back to developer a they're on feature
91:25 - Branch one and they have all the stuff
91:28 - um that they need to get their Branch up
91:30 - to date so what they'll do is they'll
91:32 - merge back in in their Direction I know
91:35 - it doesn't show a merge but they'll
91:37 - merge that information into feature
91:39 - Branch one so they are now up to date
91:42 - and they have now finished their feature
91:44 - by doing a bit extra work and so they've
91:46 - merged back into into the main branch
91:48 - and now their stuff is to be rolled out
91:49 - to production so it gets merged into
91:51 - production and then that gets Tagged so
91:54 - hopefully that gives you kind of an idea
91:56 - of uh this kind of workflow this should
91:59 - have really been like that uh and this
92:01 - actually has a very particular name it's
92:03 - called the GitHub flow now there are
92:05 - some variations of this so that's why I
92:07 - say very close to it because in case I'm
92:09 - wrong I want to have that buffer to say
92:11 - that well I didn't say this is exactly
92:13 - the GitHub workflow but this more or
92:15 - less is the GitHub workflow where you
92:17 - are creating branches feature branches
92:19 - merging it back into some other branch
92:21 - and then you have a branch for
92:23 - production uh you can have branches for
92:25 - all sorts of things you can have
92:26 - specific environment Branch branches
92:28 - like staging development production you
92:30 - can have specific branches to developers
92:32 - so like based on their names you could
92:34 - have branches per features branches per
92:36 - bugs it's going to be based on what your
92:38 - team wants to do all right uh there are
92:41 - definitely get Branch commands you
92:43 - should absolutely know and we will do
92:45 - again a quick quick and dirty crash
92:47 - course so you are familiar with it this
92:49 - is a extremely common pattern that
92:51 - you're going to find that you'll be
92:53 - doing which is is you'll be creating a
92:55 - new Branch for a feature you can be
92:57 - adding changes you're going to be
92:58 - pushing it Upstream we might do this via
93:01 - via's code using the git CLI we might be
93:04 - doing this using GitHub uh creating a
93:07 - branch from an issue but we'll
93:08 - definitely be doing this because this is
93:10 - something that happens a lot um in
93:13 - professional um uh teams is that they're
93:16 - creating feature branches so hopefully
93:18 - that makes sense and again if it doesn't
93:20 - wait till we go ahead and do it and then
93:21 - it will make more sense then okay
93:24 - [Music]
93:27 - ciao hey this is Angie Brown and we are
93:29 - taking a look at get repos so these
93:32 - represent the reference to a remote
93:34 - location where a copy of your repo is
93:36 - hosted so when I say remote get remote
93:40 - I'm saying remote reference or remote
93:42 - ref you might see those terms uh used
93:45 - all over the place uh you can have
93:48 - multiple remote entries uh or remote
93:50 - references for your git repo and the
93:53 - most common one you're going to see is
93:54 - called origin it's almost always uh
93:57 - there uh everybody seems to use it it
93:59 - indicates the central or golden repo
94:01 - everyone is working from and represents
94:03 - the source of Truth uh the remote
94:06 - entries or references are stored in your
94:08 - dogit config we don't really talk about
94:11 - this dogit folder in any of the slides
94:13 - but the dogit folder is how you know
94:17 - that your project is a uh has a a git
94:21 - repo in it because it needs that folder
94:24 - uh to initialize a get repo we'll look
94:26 - at that in the quick and dirty crash
94:28 - course um so in here in the config file
94:33 - you can see we have remote defined so
94:35 - this format of a file is called a toml
94:37 - file um so anytime you see those Square
94:40 - braces and then definitions that's
94:41 - usually a toml file but I'm just going
94:43 - to get my pen tool out here the idea
94:45 - here is we're saying we uh we have a
94:47 - remote named origin and the URL is
94:50 - pointing to our GitHub repo this part
94:54 - says how it should fetch I'm not going
94:56 - to get into that right now and then down
94:58 - below we can see we have some branches
95:00 - that we are tracking and they're
95:02 - pointing to remote origin and then they
95:04 - uh they're saying that we want to U
95:07 - merge um uh there so hopefully that is
95:10 - clear notice remote names can be
95:13 - referenced so we have origin up here and
95:16 - it's referencing this up here okay so
95:20 - I'm just going to clear my annotations
95:22 - here so this is a little bit more clear
95:23 - here and there are a bunch of get remote
95:26 - commands you should know I don't
95:28 - remember the most like the git remote ad
95:31 - I don't ever remember that one because
95:33 - often when you clone it's going to add
95:36 - them anyway and so usually you pull them
95:38 - from GitHub but you should know push you
95:40 - should know pull you should know fetch
95:43 - uh and when you are creating branches
95:44 - you should know um how to uh push
95:48 - upstream and we'll talk about upstream
95:50 - and downstream next okay
95:55 - [Music]
95:56 - all right let's talk about the concepts
95:57 - of upstream and downstream so imagine we
96:00 - have GitHub who is hosting our remote
96:03 - repository and then we have our local
96:05 - developer environment or Cloud developer
96:07 - environment uh this is local basically
96:10 - where we are doing our work and so they
96:12 - both have a main repo because we know
96:15 - that git is decentralized so we can have
96:17 - repos in more than one place we might
96:19 - already have some commits on the remote
96:22 - side but what's going to glue these two
96:24 - together is going to be the remote and
96:26 - so we set up a remote tracking Branch
96:30 - okay and and you'll see that term when
96:32 - you create uh and you push branches up
96:34 - because the idea is that it's tracking
96:37 - uh the origin is pointing to main so
96:39 - this is the way we track them uh we saw
96:41 - that was stored in theg getconfig so
96:44 - when we go ahead and we perform a poll
96:46 - from our local developer environment we
96:49 - call this Downstream we're pulling
96:51 - Downstream so a repo that pulls or
96:54 - clones from another repo and just
96:56 - understand this is relative to the
96:58 - direction or the perspective um of who's
97:01 - pulling so if the remote was pulling it
97:04 - would be Downstream it's it's anytime
97:06 - you're pulling it's always Downstream
97:08 - and now imagine we have commits we've
97:10 - been working locally we want to push
97:12 - those up to remote we would call that
97:15 - Upstream so this is when you are pushing
97:18 - changes so that's Upstream that's
97:20 - Downstream and when we have a remote
97:22 - reference it is a tracking Branch so
97:25 - there you go
97:27 - [Music]
97:30 - okay hey this is Andrew Brown we are
97:33 - taking a look at GitHub flow so this is
97:35 - a lightweight workflow for multiple
97:37 - developers working on a single repo
97:40 - there's a lot of variations on this uh
97:42 - so this is not a technically perfect
97:44 - description of it but there really isn't
97:46 - one and I want to show you a really old
97:49 - graphic um I don't know how old this is
97:52 - but I've seen this and older ones maybe
97:54 - all the way back to 2008 at least and I
97:57 - remember before GitHub flow because
98:00 - GitHub came or sorry G came out in 2005
98:02 - and it took a few years to gain adoption
98:05 - so for a long period for a few years we
98:08 - just had a mess of stuff and then
98:10 - somebody came up with this maybe it was
98:12 - GitHub I'm not sure but uh it's called
98:15 - the GitHub flow and um here we have a
98:18 - bunch of branches and it looks very
98:20 - similar to the one that I showed you in
98:22 - get branch it's a little bit different
98:24 - and so the big difference is that well
98:26 - first of all uh we don't call it Master
98:28 - anymore we call it main but my main was
98:31 - the develop branch and then I would call
98:33 - this Branch master I would have called
98:34 - it production because I think that makes
98:36 - more sense and a lot of people do that
98:38 - these days but when it first came out
98:40 - this is how we were doing it okay so
98:42 - understand this variation but the idea
98:44 - is that you have this one branch I call
98:46 - it main this is develop and it holds
98:49 - things that um that uh that hold feature
98:53 - br branches or hot fixes and everything
98:55 - it's basically like rolls everything up
98:56 - but it's not in production yet and so
98:58 - the idea is that when these things are
99:01 - ready for um production you can push
99:04 - them out into a release Branch a release
99:06 - Branch could be also called staging
99:09 - that's normally what we call uh today
99:12 - and this could be where it would roll
99:13 - out so once you push stuff here this
99:15 - could go out and execute a cicd pipeline
99:19 - and would set up a staging environment
99:21 - so that QA could be done on it or kind
99:23 - of load balancing could be done on it or
99:25 - stress testing um there and the idea is
99:29 - that as developers you would open up
99:31 - feature branches off of develop and as
99:33 - you complete them they would come back
99:34 - in here uh and they would get merged in
99:38 - and then when things were really ready
99:40 - you take it take it from uh release
99:42 - branches and push it out to your
99:44 - production branch which they're calling
99:46 - uh here uh Master if for whatever reason
99:49 - you had a serious problem you had to fix
99:51 - really quickly you could uh
99:54 - uh create a branch off a master into the
99:57 - hot fixes and then merge it back in
99:58 - skipping all the stuff down below uh you
100:01 - know again I wouldn't do it this way
100:04 - anymore I would be surprised if
100:05 - companies are sticking uh to this method
100:07 - but this is the original way I just
100:09 - wanted to show you that there is
100:10 - variation um and you know a lot of
100:13 - people do skip having a release branch
100:15 - and they'll just deploy often and into
100:18 - production so it's going to be really
100:20 - dependent on your team so here we'll
100:22 - just kind of Lo Loosely described GitHub
100:24 - flow you create a branch for each new
100:26 - task or feature create a new Branch off
100:28 - the main branch add commits make changes
100:31 - and commits commit them to your branch
100:33 - open a poll request start a discussion
100:35 - about your commits reviewing code in the
100:36 - poll request discuss a review share your
100:38 - poll request with teammates for feedback
100:41 - deploy test your changes in production
100:43 - environment um so yeah oh and the last
100:46 - thing would be merge so once your
100:47 - changes are verified merge them into the
100:49 - main Ranch so that's the general
100:50 - concepts of it and hopefully that makes
100:52 - sense and we will see you in the next
100:55 - [Music]
100:58 - one hey this is angrew brown and we are
101:00 - taking a look at the GitHub CLI so this
101:02 - is a command line interface to interact
101:04 - with your GitHub account you can quickly
101:06 - perform common GitHub actions without
101:08 - leaving your developer environment and
101:11 - uh if you uh went through the quick and
101:14 - dirty um get uh crash course then you
101:18 - definitely got some exposure to GitHub
101:19 - CLI but the idea is that you'd have to
101:21 - log in you can perform AC there so we
101:24 - have something like creating a repo
101:25 - creating an issue uh reviewing a PR
101:28 - there's a lot of uh CLI commands the
101:31 - good up CLI can be installed on Windows
101:32 - Linux or Mac OS um that's an example of
101:35 - using Brew to install if you have it for
101:38 - um uh Dev containers you can specify it
101:42 - as a feature to get installed so that is
101:44 - a very easy and quick way to have it uh
101:46 - installed there and just to give an idea
101:48 - of commands we have our core commands we
101:51 - have a lot of additional commands and
101:53 - then we have one specific to GitHub uh
101:56 - actions command so we're definitely
101:57 - going to get some exposure uh to GitHub
101:59 - CLI in this course but there you
102:03 - [Music]
102:06 - go all right so in this follow along I
102:08 - want to take a look at the GitHub CLI
102:10 - and see if we can do a few different
102:12 - things with it what I'm going to do is
102:13 - switch over to my other account um this
102:17 - is just my uh playaround account for for
102:19 - GitHub and we should already have a repo
102:21 - in here called GitHub examples and what
102:24 - I want to do is I want to um you know
102:27 - just do some things in the CLI so I need
102:29 - some kind of environment to work in and
102:31 - so what we'll do is launch up a code
102:33 - space uh we do have this older one
102:37 - um I think what I'll do is make a new
102:39 - one I don't think it really matters if
102:40 - we make an old or new one that other one
102:42 - is stopped so we'll open this one up and
102:44 - we'll see if the GitHub CLI is already
102:46 - pre-installed it could be pre-installed
102:48 - on this because I would think that if
102:50 - well if I was GitHub I would have it
102:52 - pre-installed so people start using my
102:53 - product right away but if it's not we'll
102:56 - definitely go ahead and take a look at
102:57 - how to install it we did install it
102:59 - manually locally um in the uh git crash
103:03 - course the quick and dirty crash course
103:05 - so uh you know if we don't have to show
103:07 - the install I'd rather skip that but
103:10 - we'll wait for this to spin up okay I
103:12 - have no idea why but that took a little
103:13 - bit time to spin up um you know our goal
103:15 - isn't to really make anything just to
103:17 - play around with the um the CLI here the
103:19 - Cod space is currently running in
103:20 - recovery mode due to configuration error
103:22 - I didn't do anything I I don't care it's
103:25 - um I mean it's a new environment why
103:28 - should it be
103:29 - recovering is there something it can't
103:33 - do yeah I'm not sure about this so what
103:35 - I'm going to do because I don't trust
103:37 - this
103:39 - workspace is um this one is running
103:43 - here I don't know we'll just see what we
103:46 - can do with it but it didn't pick up my
103:47 - settings when I told it to save it
103:49 - earlier so I don't know if it's because
103:51 - it's in recovery mode or not but for the
103:52 - time being I'm going to go ahead and
103:54 - change the theme so I'm not upset there
103:58 - we go that's a lot better and I want to
104:00 - see if we
104:01 - have um GH installed so it's not
104:05 - installed which is totally fine um so
104:08 - what I'm going to
104:09 - do
104:11 - is if we had this installed can we
104:13 - install through here sometimes you can
104:15 - install stuff through plugins
104:19 - right and so I'm just curious if we
104:21 - could do that there no okay so that's
104:22 - fine we'll go ahead and install this and
104:25 - I definitely know that Brew is installed
104:28 - or maybe it's not installed on this
104:29 - let's find out it is installed on git
104:31 - pod but I'm not sure about GitHub it's
104:33 - not okay so what we'll do is we'll look
104:34 - up the GitHub CLI and we'll go ahead and
104:37 - install it we already did this before
104:38 - but we'll do it again and what we're
104:40 - looking for is those install
104:42 - instructions and we want it for um Linux
104:46 - okay so we'll go over into here into
104:47 - Linux and we'll grab this on line
104:49 - command it looks like a lot but it's
104:51 - really just doing this update and this
104:53 - install like down here but it has to add
104:56 - the repo so it knows where to install it
104:58 - from but I'm gon to grab that big thing
105:00 - there and we're going to go ahead and
105:01 - paste that on in say allow and hit enter
105:05 - and um it failed it failed and I can't
105:09 - look at I can't see what I'm doing so
105:10 - I'm gonna bump up this font I do not
105:13 - like GitHub code spaces I'm so sorry I
105:16 - really like gpod and we're going to go
105:18 - here and say terminal
105:20 - font I'll try not to complain to much
105:23 - about it in the course but uh I can't
105:26 - promise anything I'm going to copy that
105:28 - again and we'll try this again it an
105:31 - enter no such file directory okay
105:36 - um yeah I don't know what you want so
105:39 - there's this line
105:41 - here
105:43 - okay maybe because gpg gpg isn't
105:47 - installed sometimes you don't have to do
105:49 - a gpg check but we might have to with
105:51 - this
105:53 - and
105:55 - um failure to right destination okay so
105:59 - if that's not working maybe what we
106:00 - could do in an easier way is we could
106:03 - just add it um to the
106:06 - uh uh to the that this file this code
106:09 - spaces file so we can just make a Dev
106:11 - container um and maybe that would be
106:13 - less of an issue so what I'll do is I
106:17 - want to add a Dev container um we'll go
106:19 - up to here Dev container
106:24 - like that we actually already have one
106:26 - from before and maybe we can just throw
106:28 - it in
106:29 - here so grab this maybe we do want to
106:32 - commit this maybe this is a good idea um
106:35 - and so I'll put this
106:37 - here and I need a comma there and so the
106:39 - idea here is that this should install
106:41 - the CLI into this environment and maybe
106:44 - the reason why this thing messed up was
106:46 - because it wasn't specifying any base
106:48 - image and that's why I got upset because
106:50 - when we did this in the tutorial earlier
106:53 - um it kind of complained or sorry like
106:55 - when we spun this up it complained but
106:57 - we didn't specify a base image so I'm
106:59 - going to look up what the base imag is
107:01 - for Dev
107:03 - container the base image for GitHub is
107:07 - and maybe that will help
107:10 - us if that doesn't help let's go let's
107:12 - go ask
107:16 - chbt log in let me in let me
107:20 - in come on I P for this let me
107:25 - in what is the what is the base image
107:30 - used for uh Dev
107:33 - container for GitHub code
107:39 - spaces let's see if that can figure it
107:41 - out it's probably just going to go to
107:43 - the um the documentation but um I don't
107:46 - remember where it is
107:51 - so if you don't specify one it will
107:54 - create in the default one okay that's
107:55 - what I would rather it do so I'm going
107:57 - to leave it alone and what I want to do
107:59 - is rebuild uh this environment because
108:01 - we've added this change before we do I
108:03 - need to commit this maybe so I'll just
108:04 - say um it should install the GitHub CLI
108:09 - go ahead and do
108:11 - that and I'll say
108:13 - okay so it should sync it up good and so
108:17 - let's see if we can find the rebuild I'm
108:19 - clicking up here rebuild that's no good
108:21 - we can open up the command pallet this
108:23 - way command pallet has all the commands
108:25 - for for vs code and there should
108:27 - probably be something for codes space so
108:28 - if I type in code spaces there's
108:30 - probably something here to rebuild there
108:31 - it is rebuild container so I'm going to
108:34 - go ahead and rebuild that container I'm
108:35 - going to go ahead and hit rebuild and so
108:37 - I'm hoping that we'll install the CLI
108:39 - and that avoids us having to install gpg
108:41 - or whatever it wants because that's a
108:43 - headache and I don't want to deal with
108:44 - that so see you back here when this
108:46 - finishes building okay all right we're
108:48 - in it says the code space is currently
108:50 - running in recovery mode due to a
108:51 - configuration please review the creation
108:53 - logs update your Dev container as needed
108:55 - or rebuild the container so clearly
108:57 - doesn't like something about my file I'm
109:00 - not really sure because there's not a
109:02 - whole lot in it um so we have command
109:06 - control shift p okay control shift p hey
109:11 - like learing learning right and uh we
109:13 - want to view creation blogs oh that's
109:15 - just to open up the uh command
109:18 - pallet view creation log
109:22 - and somewhere here it's messing up now I
109:25 - don't understand how it could be messing
109:26 - up because we literally have next to
109:27 - nothing in
109:30 - it
109:35 - um yeah this is supposed to be an easy
109:38 - easy GitHub CLI
109:43 - tutorial failed to C the container an
109:45 - error occurred unified containers error
109:48 - creating fail doesn't even tell us why
109:50 - it's just like nope it doesn't work
109:52 - maybe it's up here
109:56 - um no matching entries and P unable to
110:00 - find user Dev container okay maybe it's
110:03 - this okay let's take this out all right
110:06 - and uh that's probably the reason why
110:08 - okay
110:10 - so we'll save that okay we'll have to
110:15 - update that don't change remote
110:21 - user okay
110:24 - want Push to Main and I'm going to try
110:26 - to rebuild this
110:27 - again I'll open up the command pallet
110:29 - down here below just in case and I want
110:31 - to say
110:33 - rebuild
110:36 - um I want to do like a full rebuild
110:38 - let's do a full
110:40 - rebuild that's fine let's rebuild and
110:43 - we'll get it going this next one okay
110:45 - I'll see you back in a
110:47 - moment okay so I think that resolved the
110:49 - issue it took a while for that to
110:51 - rebuild but what I want to see if the C
110:53 - is in here so I'm going to type in GH
110:56 - and there it is okay great so that's the
110:57 - easy way to get in there as long as you
110:59 - don't make any mistakes in your Dev
111:01 - container uh Json or JS or Json Json
111:05 - file and so let's go ahead and see what
111:07 - kind of actions we can perform so what
111:08 - I'll do is go over and type in GitHub
111:10 - CLI and we'll take a look at the
111:12 - documentation and see that's not what I
111:15 - want I want the official documentation
111:17 - so we can see what kind of
111:19 - commands we can get here it is okay so
111:21 - here's all of our Comm comms and the
111:23 - question first is are we logged in
111:26 - because that's something we might need
111:27 - to do so let's go ahead and type in GH
111:30 - login oh sorry JH off login to log the
111:35 - CLI and we have two options we'll do
111:37 - github.com it says the value of the
111:40 - GitHub token environment is being used
111:42 - for authentication to uh okay so it
111:44 - sounds like we already are authenticated
111:46 - because of um GitHub code spaces and
111:50 - it's loading some kind of temporary um
111:53 - token in here something we could check
111:54 - here is to see if there actually is a
111:56 - token being set so I'm going to type in
111:57 - EnV grep and we'll type in
112:00 - GH and I don't see anything there but
112:03 - apparently it seems to think that it is
112:06 - ready to utilize so maybe what we could
112:08 - do is list out repos so I imagine if we
112:12 - go here there's probably something like
112:13 - list there is and we could try to list
112:15 - our repos let's go ahead and try that GH
112:19 - repo
112:20 - list and we have a repo that's that's
112:22 - actually a really nice display what else
112:24 - can we take a look at here
112:26 - um so again back over to the
112:30 - repo list our repo what if we go to view
112:34 - what would that do let's take a look G
112:38 - repo
112:40 - View and I was hoping that it would set
112:43 - it would select the current one but
112:46 - apparently it didn't but we can do uh GH
112:49 - repo set default
112:53 - and I got to type it right maybe it'll
112:56 - let us choose the repo so we don't have
112:57 - to goof around and so there it is we can
113:00 - choose one and apparently uh we have two
113:02 - exam Pro Co and the Andrew WC Brown
113:05 - curious that it's showing forked ones
113:07 - but this is the one I want because this
113:08 - is the count I'm in right now and so
113:10 - let's go ahead and type in GH repo
113:13 - View and so now we can see some stuff in
113:15 - here um not a lot of information it
113:18 - looks like it's kind of the information
113:20 - about maybe
113:22 - the description or stuff like that so I
113:26 - was hoping to see a little bit more
113:27 - there but that's okay let's go down here
113:30 - and see what else we can
113:31 - do um we could edit our
113:35 - repo like we could change features turn
113:38 - things on or
113:39 - off that's not that interesting
113:42 - something we might want to do is maybe
113:44 - we might want to uh maybe change our
113:46 - labels let's go ahead and try that out
113:49 - so I'm going to go here and say GH
113:51 - labels list
113:53 - um is it just label or labels
113:58 - label oh cool yeah we could see our
114:00 - codes can we add a new one in
114:03 - here uh we'll go to
114:06 - create so GH label so we try this one
114:09 - here copy it paste it
114:12 - in and there already is a bug so we
114:14 - can't have
114:15 - two so I'll go here and just say
114:19 - um Danger
114:24 - something really not
114:26 - right we'll hit enter and so it looks
114:28 - like we've created another label let's
114:30 - go ahead and hit up okay so that looks
114:32 - really good there bug isn't working good
114:36 - um if we wanted to create a new repo
114:39 - sometimes what they'll do is they'll um
114:42 - they'll create like a uh a wizard in
114:44 - here so if I typed in GH create repo and
114:47 - I said
114:49 - um GitHub
114:52 - we'll just we'll just do this I bet it
114:54 - will prompt
114:55 - us oh I got to type it right I seem to
114:58 - be typing everything wrong here today
114:59 - repo
115:00 - create and so it'll ask us some things
115:02 - like create a repo from a template
115:04 - repository make a new one so I could do
115:06 - this I say
115:08 - GitHub um
115:11 - repo GitHub CLI
115:15 - example and I'll just go ahead enter
115:17 - here I'll just make this one private I
115:19 - could add a readme file we could add a
115:22 - Gore we could say what we want the get
115:24 - ignore to be so maybe it's for
115:27 - C++ that let's add a license we could
115:29 - choose a POI
115:31 - 2.0 um we want to do this we'll say yes
115:35 - and it seems like it should have created
115:37 - but we get a resource not accessible by
115:39 - integration for 403 so I'm not 100% sure
115:42 - as to why we're getting that it could be
115:43 - a permissions issue because everything
115:45 - is based on um that token right and so
115:49 - maybe we have a personal access token
115:51 - that allows us to read but not right um
115:55 - and we got a 403 right so 403 error is
116:00 - for forbidden meaning we don't have
116:02 - access to do it so what I'm thinking is
116:04 - that we can probably create our own um
116:06 - personal access token and try to get
116:08 - around that so I'm going to go to
116:10 - settings here I'm going to go all the
116:11 - way down develop for settings and we're
116:13 - going to go into personal access tokens
116:15 - find grain tokens and we'll generate a
116:17 - new token again I don't know if this
116:18 - will work but I'm just going to try it
116:19 - so we'll just say um uh
116:22 - repo
116:28 - access right let us create a repo and
116:32 - I'm going to set this for tomorrow
116:35 - because I don't need it forever and if
116:39 - it's for all repos then that's a
116:41 - challenge right but then how would you
116:43 - create a
116:45 - token this is public repos so here it
116:48 - says this applies to current and future
116:49 - repos owned by this resource all all
116:51 - includes
116:52 - public repos read
116:55 - only so the other question is is it
116:57 - because we tried to make it a private
116:59 - repo but then why would it have it as an
117:00 - option if we can do that I mean we could
117:03 - also authenticate uh via SSH so I'm not
117:07 - sure so I guess that's where I'm not
117:10 - 100%
117:12 - sure so maybe we'll just say all repos
117:15 - here and we'll go to repo
117:18 - permissions and I'm looking specifically
117:20 - for repos
117:23 - contents
117:27 - no and carefully looking here to try to
117:30 - find
117:31 - that um account permissions
117:37 - maybe it feels closer to
117:40 - this type in
117:45 - repo uh let's see
117:48 - here so what does this one do
117:52 - interaction limits uh interaction limits
117:53 - on repos I don't think it's
117:56 - that and so I'm just carefully looking
117:59 - to figure
118:00 - out what functionality we would have to
118:06 - provide managing repository environments
118:10 - it could be this read
118:13 - write I would probably put this in just
118:15 - because that is the
118:18 - usual
118:21 - um oh repo creation it's up here so I
118:23 - don't think we need these other ones I'm
118:25 - going to leave them on because they're
118:26 - not that big of a
118:27 - deal um and this one says it's mandatory
118:30 - so sure we'll have that in there got it
118:31 - added in there I'm going to go ahead and
118:33 - generate this token and so now we have
118:35 - this token I'm going to copy it I'm
118:36 - going to go over to here I'm going to
118:38 - type in export GH token and I'm going to
118:41 - go ahead and paste this in and so the
118:43 - idea is that when we use the um uh the
118:48 - CLI it should pick up this as opposed to
118:50 - what what else is on here so I'm typing
118:52 - EnV hyphen grep because I want to make
118:55 - sure that this is actually set as our
118:56 - environment variable if you have other
118:58 - tabs open here it might not show up so
119:00 - just stay on the current tab we'll go
119:02 - ahead and try this again another reason
119:04 - why it might have not worked is because
119:06 - that name was already taken but I don't
119:07 - think so because it's scope based on our
119:09 - user so we'll go ahead and try this
119:11 - again from scratch so we say GitHub CLI
119:15 - example and then we'll say uh we'll put
119:18 - nothing in there we'll make it private
119:20 - and it was interesting there's a visib
119:22 - of internal I imagine that maybe that's
119:24 - for Enterprises we'll say yes yes and it
119:28 - doesn't matter I'll just choose that one
119:30 - we'll say yes doesn't matter I'll choose
119:33 - that one and we'll say yes let's see if
119:35 - it works now clone the repo locally yeah
119:39 - sure let's do that and so now it's
119:42 - working so whatever key whatever
119:44 - personal access token that is somehow
119:45 - being loaded in there did not have the
119:47 - correct permissions we were able to get
119:49 - around that so I don't really want this
119:51 - repo so I want to go ahead and delete it
119:54 - um let's go take a look and see what
119:55 - actions we have there we have delete so
119:58 - I'm going to hope that it just will like
120:00 - give me a wizard so I don't have to pick
120:01 - it so we'll say GH repo
120:04 - delete um and I don't want to delete our
120:07 - current one so I'm going to hit contrl C
120:09 - because that's totally not what I want
120:11 - and we'll go back over to here and we'll
120:13 - take a look and see what we can see for
120:16 - the uh repo I really wish they would
120:18 - list them up here maybe if we go to the
120:20 - getting started
120:22 - or available commands yeah that's a
120:24 - little bit
120:25 - easier it's not great but uh we'll go to
120:28 - repo here and we'll go to
120:30 - delete and we can put the repone name
120:33 - here so we'll go
120:35 - back over to uh GitHub here we'll go to
120:38 - our names this is going to be Andrew WC
120:43 - Brown and we should be able to see two
120:45 - repos in
120:47 - here there's our other one I'm going to
120:49 - grab that name
120:52 - and I'm going to go back over here and
120:53 - I'm going to say that so do I want to
120:56 - delete
120:57 - it so type the name again sure and we
121:01 - have to put in also uh the username in
121:04 - front of
121:07 - it we'll hit enter and that repo should
121:10 - be now deleted we'll go back over to
121:13 - here okay and it's deleted so that is in
121:16 - good shape so that's all good so I'm
121:19 - really happy with that I'm going to go
121:20 - ahead and stop this uh code code space
121:24 - I'm just going to delete
121:25 - it and you know I'm gonna delete the
121:27 - other one I'm just going to make sure I
121:28 - keep everything nice and clean and and
121:31 - not worry about overspend and what I
121:33 - want to do is just merge this into my
121:35 - other account again you don't have to do
121:37 - this you can just watch me do this but
121:39 - it's good to watch because this is
121:41 - something that people have to do a lot
121:43 - and actually what I should have done is
121:46 - I should have gone over here and I
121:47 - should have done it from here first so
121:49 - I'm going to go here and
121:52 - create a PR create create a new PR and
121:57 - we'll say create is going in the
121:59 - direction we want yes it is we'll hit
122:02 - create um fix Dev container we'll create
122:07 - that pull
122:08 - request good we'll switch back over to
122:11 - our other account and then I'm going to
122:13 - go into uh the same repo I'm going to
122:16 - accept it confirm it and we are in good
122:19 - shape I'll see you in the next one ciao
122:21 - [Music]
122:26 - a common strategy for authenticating uh
122:28 - to perform git operations on your remote
122:30 - GitHub repo is by using an SSH key uh
122:34 - you're definitely going to want to use
122:35 - this because it is a great way um to
122:38 - work with Git uh in your local developer
122:41 - environment it's definitely the way that
122:42 - I like to use it as opposed to using a
122:44 - personal access token but uh the way it
122:47 - works is you'll have to generate out
122:48 - your own SSH uh key using a command like
122:51 - s key gen for Linux there's probably
122:53 - different ways but that's the way that I
122:54 - know and specifically an RSA key I'm
122:57 - sure there's different kinds of keys
122:59 - that uh GitHub will take but that's the
123:01 - one that I know and so the idea here is
123:03 - that we have our computer our local
123:07 - computer and then we have the server
123:09 - which is a GitHub and the idea is that
123:11 - there will be a copy of the public and
123:13 - private key on your local computer and
123:15 - then on GitHub you'll store that private
123:17 - key and so the the process of
123:20 - authenticating and authorizing is going
123:22 - to go like this so the server checks to
123:24 - see if you have the same public key if
123:27 - you both have the same public key it's
123:28 - going to send you a challenge message
123:30 - that challenge message contains the
123:33 - public key uh encrypted and so it's
123:35 - going to send that on over and then uh
123:37 - the idea is that um the private key on
123:40 - the local computer will decrypt it and
123:42 - then it will be able once it decrypts
123:45 - that message it will then take the
123:46 - private key and do something there and
123:49 - then send back a well it won't do
123:51 - something it'll send back a signature um
123:54 - and then that signature will be sent to
123:55 - GitHub and then they'll verify it and
123:57 - that will establish that connection
123:59 - allowing you to use SSH keys to get
124:01 - clone or push or or things like that uh
124:05 - under your account settings SSH and gpg
124:07 - keys is where you'll be able to add the
124:09 - public keys so here you can see I have a
124:11 - couple SSH keys in one of my GitHub
124:13 - accounts and it's there under SSH and
124:15 - gpg keys and when you want to go use um
124:20 - or clone a a repo you're going to really
124:22 - want to use that SSH style address it
124:25 - will not not work with the htps one or
124:27 - the GitHub CLI one technically will work
124:30 - at the GitHub CLI one but that's what
124:32 - you're going to want to do there so
124:33 - there you
124:34 - [Music]
124:37 - go in this video I just want to show you
124:40 - quickly how to create SSH Keys we did
124:42 - cover that in the quick and dirty uh git
124:44 - crash course but it's good to do things
124:46 - more than once so that we really get
124:48 - good at them I'm going to open up a new
124:50 - environment here in code spaces
124:52 - and we'll get that spun up so I'll see
124:54 - you back here when this is ready okay
124:56 - all right so we have this environment
124:58 - spun up and it's just not remembering my
125:00 - uh settings whatsoever but you know
125:02 - that's just how things go and I'm going
125:05 - to make a new folder in here I'm just
125:06 - going to call it um SSH
125:10 - keys and I'm going to just go ahead and
125:12 - make a new read me file so normally what
125:14 - we'll use is
125:18 - the SSH
125:22 - keyin command I realize that's small I'm
125:23 - just going to jump it up like that and
125:26 - so we use T RSA to make an
125:29 - RSA um uh style key I would imagine that
125:33 - GitHub can support different kinds not
125:36 - that I know much about the different
125:37 - kinds let's go take a look here and see
125:39 - what we can see so that's from local I'm
125:41 - going to go ahead and delete that um
125:42 - because I don't need that right now if
125:44 - we go here you can see things like SSH
125:47 - RSA sha 2 something like that so so be
125:51 - interesting to generate something else
125:54 - out so
125:58 - ecd SSH key key gen
126:02 - ecd so I want to see if we can generate
126:04 - something that's a bit more
126:05 - secure I I assume it's more secure is a
126:08 - relatively new crypto cryptographic
126:12 - solution um it's been around for 5
126:15 - years okay so how do we make
126:18 - it and the way we make it it's probably
126:21 - by supplying this like that okay great
126:24 - so what I'll do is go back over
126:26 - here and we'll change it from RSA to
126:29 - this one and see what happens I've never
126:31 - done this before but I imagine it's
126:32 - super
126:34 - simple and I'm going to CD into the SSH
126:36 - directory I'm going to go ahead and hit
126:41 - enter say allow yes I want to paste
126:43 - we'll hit enter and see if it can do
126:45 - this and so we'll go ahead and hit
126:49 - enter um it will create it in the code
126:51 - space
126:52 - directory so I suppose that's
126:55 - fine and we'll do that and that and so
126:58 - then we're going to get that key and
127:00 - then the idea is that we can
127:03 - then go ahead here and then we could go
127:06 - and cat out the contents of
127:09 - it
127:14 - right all right and so we could copy
127:17 - this and it's actually a lot shorter
127:19 - that's actually really nice I like that
127:21 - and then we could go over here and then
127:23 - we could add it so just say uh Cloud
127:26 - developer environment for
127:28 - CDE and we can add that key now I want
127:31 - to point out that you can add keys to
127:32 - repo as well so we're not going to
127:34 - really test this to make sure it works I
127:35 - just wanted to generate out another one
127:37 - and show you that but what we'll do is
127:39 - we'll go over to our repo because I want
127:41 - to show you where that deploy Keys
127:42 - things is and if we're in a repo like
127:45 - this we can go to our settings and there
127:48 - should be deploy Keys down below and we
127:50 - could add a deploy key and it's the same
127:51 - process you just paste it on in you save
127:54 - what it's from uh you can say whether
127:56 - you want it to have right access and
127:57 - boom there you go but a lot of these um
128:00 - repos only need readon so especially if
128:03 - you're building you're just cloning the
128:04 - repo so you don't need that but that's
128:07 - all I wanted to show you so going to go
128:09 - ahead and Commit
128:11 - This okay so just say uh basic
128:15 - instructions for
128:17 - SSH okay so that's all good
128:21 - I'll say
128:23 - okay and then what I'm going to do is
128:25 - just switch into my other accounts and I
128:28 - probably can merge the other way too um
128:30 - if I try that so if we go here to PLL
128:35 - requests we go to new PLL request and I
128:38 - could probably try to grab from that
128:39 - other repo so I want to bring in from
128:42 - here from there yep I can do that and
128:44 - then I'm just basically allowing myself
128:46 - to pull the changes and without the
128:48 - other Andrew having to uh put it forward
128:53 - okay there we go and we are emerged I
128:55 - will see you in the next
128:58 - [Music]
129:01 - one so deploy Keys allow you to attach
129:05 - public Keys directly to a get repo and
129:08 - the use case for deploy kees are if
129:10 - you're using let's say a build server or
129:12 - a c cicd third party service that needs
129:15 - to clone the repo so they can perform a
129:17 - build or deploy or maybe single repo
129:20 - access so instead of using a shared key
129:22 - pair for the uh for multiple repos you
129:25 - have a single key pair for single git uh
129:27 - git repo and another reason would be to
129:29 - avoid using the personal access token um
129:32 - I'm going to tell you I've definitely
129:33 - used deploy Keys especially if you're
129:35 - not using GitHub actions and you're
129:36 - using third party cicd tools which is
129:39 - pretty common with GitHub um you will
129:42 - find yourself using deploy keys and I
129:43 - just want to make aware that's very
129:46 - similar to the other one with some
129:48 - advantages so you have to decide in your
129:49 - use case where you're going to want to
129:51 - use it but it's as simple as that
129:53 - [Music]
129:56 - okay hey this is Andrew Brown and we are
129:58 - taking a look at personal account access
130:01 - tokens or specifically personal access
130:03 - tokens or Pat which is an alternative
130:06 - way of using a password for
130:08 - authentication now Pats are not specific
130:10 - to GitHub but they do utilize them uh
130:13 - and the purpose of these tokens is to
130:16 - give you access to the API um when
130:20 - you're making direct calls or using the
130:22 - command line or using the SDK uh GitHub
130:24 - no longer supports the use uh of using a
130:27 - password directly with interacting with
130:29 - API they used to but now you have to use
130:31 - an access token uh if you're coming from
130:34 - like the adus world it's kind of like
130:35 - your access secret um so it's giving you
130:38 - that access uh there are two types of
130:40 - paths on um GitHub you have the classic
130:43 - token they're less secure and no longer
130:45 - recommended for use customers with
130:47 - Legacy systems may still be using the
130:49 - classic token like some of my apps
130:52 - uh then you have fine grain uh personal
130:53 - access tokens these Grant specific
130:56 - permissions they must have an expiry
130:58 - date uh you can only access specific
131:01 - repos um or if you want all repos it'll
131:04 - probably only be readon you can only
131:06 - access resources owned by a single user
131:08 - or organization you can find the stuff
131:10 - under the developer
131:12 - settings um there are a few use cases
131:14 - where we'll use uh Pats it would be like
131:16 - logging in using get clone for
131:19 - HPS and uh let's say we are using uh the
131:22 - GitHub CLI you could set a token or
131:25 - sorry a environment variable called GH
131:27 - token to be used uh for for the GitHub
131:31 - CLI for the to pick that up uh if you're
131:33 - using SDK you're going to be supplying
131:35 - your token I would imagine that the uh
131:38 - that these um sdks would pick up that
131:41 - environment variable as well but there
131:42 - you
131:43 - [Music]
131:47 - go hey everyone it's Andrew Brown and
131:49 - this fall along I want to take a look at
131:50 - personal access tokens yes we've already
131:52 - played around with them but let's play
131:54 - around with them a little bit more okay
131:56 - and so what I'm going to do is go over
131:57 - to my repo and I might already have a
132:00 - code space from before and it's already
132:02 - still active so I'm going to go ahead
132:03 - and open that to save myself some
132:04 - trouble if you have to launch a new one
132:06 - you can absolutely go ahead and do that
132:07 - remember to close your codes places so
132:09 - you are not using up your free tear
132:12 - usage uh you get so many hours per month
132:14 - I don't know what it is uh you can look
132:16 - it up if you want to know or we'll find
132:18 - out when we make it over to the uh code
132:20 - spaces section in the course um and so
132:22 - what I want to do here is I just want to
132:25 - uh work with personal access tokens now
132:27 - we might have one set from before so we
132:29 - going to take a look here and see what
132:30 - we have so going type in EnV grep G and
132:34 - see if there's anything set and there's
132:35 - nothing set here so that's great and
132:37 - what I want to do is go to the top left
132:39 - corner here go to settings and then down
132:42 - below we'll go to our developer settings
132:44 - and we have our personal access tokens
132:46 - we have fine grain tokens and token
132:48 - classic now something I would like to
132:50 - know I'm going to go ahead delete this
132:51 - one what I would like to know is can we
132:53 - generate them out from the GitHub CLI
132:55 - you think you wouldn't be able to
132:57 - because then you need permissions to
132:58 - have permissions but I'm going to take a
133:00 - look here and see what we have um
133:02 - because I'm just curious to see if it's
133:04 - actually there or not and so I'm going
133:05 - to just type in token and there is a
133:07 - token so it says this command outputs
133:10 - the authentication token for an account
133:12 - on a given GitHub
133:14 - host well that's really interesting so
133:17 - what would happen if we wrote that in so
133:19 - I'm going to type in GH author token and
133:21 - see what we get and we actually get a
133:23 - token back so I'm not sure if that means
133:27 - that
133:28 - um that's that token code but let's find
133:30 - out if it is by generating out a new
133:33 - token another thing I might wonder is
133:35 - like what permissions do we have I'm not
133:37 - sure if it would tell us I don't think
133:40 - so what's refresh refresh our token
133:43 - expand or fix the permission scope of
133:45 - the store
133:48 - credentials that's kind of interesting
133:52 - like you go out and request to have more
133:54 - permissions but I'm not sure exactly how
133:56 - that would work um but let's go ahead
133:59 - and generated a new token I'll just say
134:02 - um create issues and I'm going to set
134:05 - this for one
134:07 - day okay and we'll go down below and
134:10 - we're going to select it for a very
134:11 - specific repo this one here and I'm
134:14 - going to go to permissions and I'm
134:16 - looking for issues we'll say yes to
134:18 - issues read and write and we'll go ahead
134:21 - and generate that token and so we can
134:23 - see that's what this token looks like
134:24 - we're going to copy it bring it over
134:27 - here and I'm going to set it to this so
134:28 - I'll say GH
134:29 - token equals and then a double quotation
134:32 - paste it in enter and so now it should
134:34 - be set so if I type in E EnV grap uh
134:38 - GH we should see it there excellent so
134:41 - now let's type in Gs off token and see
134:43 - if we get a different value notice that
134:45 - this is the one we have now it shows
134:46 - that we're using a personal access token
134:48 - so this is getting load in loaded in by
134:50 - GitHub Hub how it's getting in there I
134:52 - don't know but this one looks exactly to
134:54 - be the
134:56 - same as this one let's go test and see
134:59 - if we can make an issue so go down below
135:02 - here and we will say create and I'll
135:05 - scroll down and grab an example so we'll
135:08 - do this and hopefully it'll just know to
135:09 - create it in the current repo enter and
135:13 - we need to set a default repo so we'll
135:14 - go ahead and do
135:16 - that I'll choose this one here and I'll
135:19 - try this again
135:22 - and so it's created
135:24 - it oh this repo has um issues disabled
135:29 - that's interesting so we'd have to go
135:31 - ahead and enable that so I'm going to go
135:33 - back to our repo here I'm going to go
135:35 - over to settings and we'll go down below
135:37 - and we'll turn on issues now we could do
135:39 - this via the CLI but it's just easy to
135:41 - checkbox that and we'll go back to our
135:43 - environment and we'll hit
135:45 - up and now it's created the issue so now
135:48 - the question is if I get rid of that
135:49 - token
135:51 - like I unet it uh what would happen so
135:53 - what I'll do is I'll just hit up till we
135:55 - get to that set and I'm just going to
135:56 - purposely set it blank okay and that way
136:00 - this shouldn't
136:02 - work and so now if I do GH list issues
136:07 - list I wonder if I can get a list of
136:08 - them now remember this repo is public so
136:12 - it's going to work because it's public
136:14 - but the question is can I delete the
136:16 - issue so I'm going to say
136:18 - delete and um it's expecting some args
136:22 - if I type help will tell me how this
136:25 - works the number of it that's perfect so
136:28 - the number is two so that's easy and I
136:31 - wonder if I could just put a two on
136:33 - this type two to confirm
136:37 - yes okay it deleted it now the thing is
136:39 - is that yes I was able to delete it but
136:42 - just understand that this thing has some
136:44 - base uh access underneath that original
136:46 - token and so it probably had permissions
136:48 - this one here to do that there's
136:51 - probably some things that this thing
136:52 - can't do and we learned that before
136:54 - which was that uh being able to create a
136:56 - repo um but uh you know if if I did this
136:59 - on Local Host I would assume that this
137:00 - would have not worked and that's totally
137:02 - fine I think that satisfies us for
137:05 - learning about uh personal access tokens
137:07 - I'm going to go back to our personal
137:08 - access token go ahead and delete it and
137:11 - we'll call this one done okay so I'm
137:15 - going to go ahead and go into personal
137:17 - access tokens and delete this and if you
137:21 - want you can stop and delete your code
137:23 - spaces I'll see you in the next one
137:26 - [Music]
137:30 - ciao let's quickly talk about read me
137:32 - files these are markdown files that
137:34 - provide documentation and structional
137:35 - information and a repo a GitHub repo
137:38 - that has a readme.md or readme and all
137:41 - caps or readme and all caps. MD in the
137:44 - projects route will be rendered on the
137:47 - homepage there's actually some other
137:48 - markdown files that will also be
137:50 - rendered there but it's really important
137:52 - to remember the read me one as it will
137:54 - probably come up as an exam question and
137:57 - they'll actually ask you like what uh
137:59 - where where should this be located it's
138:01 - always in the root that's what's going
138:02 - to render yeah I don't think it renders
138:04 - anything else but that one and they
138:06 - might kindy to trick you there um you do
138:08 - get this nice little table of contents
138:09 - on the right hand side so if you have uh
138:11 - headings it will figure that out for you
138:14 - there I remember that wasn't there
138:15 - before so that's really nice um but yeah
138:17 - it's as simple as that okay
138:23 - so GitHub wants you to know about basic
138:24 - repo navigation what that means I don't
138:27 - really know so I'm taking my best guest
138:29 - to show you what that is uh So within a
138:31 - GitHub repo you will have a navigation
138:33 - bar with various features of your GitHub
138:35 - repo and this is how you get to all the
138:37 - cool stuff and the main one is code this
138:39 - is where your codee's going to live um
138:41 - such as files folders things like that
138:44 - um we have issues that's for tracking
138:46 - problems it's basically a ticket tracker
138:48 - we have pull requests that's where we're
138:50 - going to be
138:51 - uh uh when we're managing collaboration
138:53 - with other uh developers and they want
138:55 - to bring changes into our repo it's our
138:57 - opportunity to uh check that work before
138:59 - it gets merged in we have actions that's
139:01 - for GitHub actions uh for projects
139:04 - that's for GitHub projects uh for wikis
139:06 - that's the wiki security is like a a
139:09 - list or a um a checklist of things that
139:12 - you should do I think it changes if you
139:14 - are looking at the context of a uh as a
139:18 - a user and you're not the owner of the
139:19 - repo you're going to see
139:21 - maybe the security policy or different
139:22 - information but if you are the owner
139:24 - you're going to have a checklist of
139:26 - things you should do and it basically
139:27 - mirrors kind of what's in the settings
139:29 - page under security so it's kind of
139:31 - weird that they do that but that's how
139:32 - they do it then we have insights this
139:34 - provides uh statistics mostly in the
139:37 - form of charts and graphs about the repo
139:40 - sometimes this information is public
139:41 - sometimes it's private then you have
139:42 - settings this is where you control all
139:44 - the settings for your repo um the other
139:47 - thing is that when you are using at
139:49 - least in the code section you can
139:51 - navigate around files so I showed you
139:53 - this in a a prior um follow along but
139:56 - the idea is you can search stuff you can
139:58 - see the contents of file you can comment
140:00 - on code per line so there you
140:04 - [Music]
140:08 - go so when you create a repo you can
140:10 - choose which owner you want it to be so
140:13 - right now I have it set as uh my
140:15 - personal account but you could drop that
140:17 - down and you could also choose an
140:19 - organization that you belong to
140:21 - repo names are scoped based on the
140:24 - account so you can have the same name uh
140:26 - for different organizations other people
140:28 - can have the same name if they're a
140:29 - different user so just understand that
140:31 - you can do that uh you need to choose an
140:34 - available GitHub name again based on
140:36 - that scope uh your repost can either be
140:38 - public or private um pretty
140:40 - self-explanatory you can quickly add a
140:43 - readme file a doet ignore and license
140:45 - it's very very important to remember
140:47 - those three because you might get an
140:48 - exam question asking about the three
140:50 - things that you can quickly and easily
140:52 - add if you're using the CLI you can add
140:54 - it uh this way or create one we did this
140:57 - earlier when we did the GitHub CLI kind
140:59 - of demonstration and we found out that
141:01 - repos require special additional
141:04 - permissions or personal access token
141:06 - permissions um that the GitHub Cod
141:08 - spaces would not allow you to do but
141:10 - yeah there you go that's a create a
141:12 - [Music]
141:15 - repo all right let's go ahead and create
141:18 - ourselves a repo I know we already know
141:20 - how to do this but it gives us an
141:21 - opportunity to talk a little bit more
141:24 - about uh some of the things that might
141:25 - appear on the exam you can create one up
141:27 - here in the top right corner and I have
141:30 - this double click problem so it's
141:31 - getting a bit confused I can go to this
141:32 - new green button that's usually what I
141:34 - do and we can have a new repo so I'm
141:35 - going to say my uh cool repo right we
141:39 - can provide a description um this repo
141:42 - is amazing and we can set it as public
141:44 - or private I'm going to stick with
141:47 - private for now and we'll add a read me
141:49 - we'll drop down get ignor we'll say
141:51 - maybe we're working with Ruby so we'll
141:52 - get that by default and we'll add a
141:54 - license like MIT we'll go ahead and
141:57 - create that repo um I want to point out
141:59 - that you have other things that are
142:01 - rendered here so that should be very
142:03 - clear um we have releases and packages
142:06 - which we should talk about at some point
142:08 - I'm going to leave this repo around if
142:09 - we want to play around with it um but uh
142:12 - yeah it's pretty clear how to create a
142:14 - repo it's not hard let's go take a look
142:16 - at a more popular repo like Ruby on
142:18 - Rails um so I'm just going to type this
142:20 - up here type in rails and we'll take a
142:22 - look and see what they have um so if we
142:24 - go into here you'll notice there are
142:27 - just more things we have codes of
142:28 - conduct right we have our MIT we have
142:31 - our security policy if we go up here to
142:34 - the security tab this is what we can see
142:37 - um so we have the security policy being
142:39 - rendered out here and then it's showing
142:41 - um possible uh exposures probably based
142:45 - on one of the scanners I'm not exactly
142:47 - sure which one is showing that um but
142:49 - that is that there if we go back to our
142:52 - own repo we might be able to take a look
142:54 - at security here hold
142:56 - on uh going back to wherever that one
143:01 - was we just made that repo it can be a
143:04 - little bit of pain to sometimes find
143:05 - your own repos I'm not sure why they
143:06 - never made that easier but just how it
143:08 - is and if we go down we can find myel
143:11 - repo here and there's this security Tab
143:14 - and notice that it's listing out uh
143:17 - things that you should do for your repo
143:19 - it's important to know what these are
143:21 - because um well if you have this uh the
143:26 - exam is going to probably ask you like
143:27 - what's what things can you access from
143:29 - here and this is just from the public
143:30 - repo if you have a private repo it's
143:32 - going to be different sorry this is
143:33 - private public can be different so let's
143:35 - just open this up and make a comparison
143:37 - and see what kind of difference there is
143:39 - here so if we go over to repo here and
143:41 - we go into this public one over here
143:45 - what options do we
143:47 - get so we get a lot more going on here
143:50 - so so notice that this is the private
143:53 - and that is the public probably because
143:55 - if you're if you had a paid version You'
143:57 - then get additional code scanning and
143:59 - secret scanning for public repos you
144:01 - automatically get that stuff I just want
144:03 - to point out that all this stuff is also
144:05 - under your settings under uh Security
144:07 - Options so they kind of just like repeat
144:10 - it there you know so it's just what they
144:13 - do but hopefully that makes sense and
144:15 - that's all I wanted to show you so I'll
144:16 - see you in the next one ciao
144:21 - [Music]
144:22 - let's talk about maintaining a repo now
144:24 - what's unusual about this slide content
144:27 - It's Not Unusual but it's the fact that
144:30 - in the outline they have a whole section
144:32 - for GitHub Administration and uh for
144:35 - whatever reason I have it over here as
144:36 - opposed into the other section because
144:38 - of the way the outline is designed so
144:41 - understand that I'm not going to cover
144:42 - that stuff in that other section because
144:44 - it's just repeated um but anyway let's
144:46 - continue on and look at maintaining repo
144:48 - so the first thing is your name so you
144:49 - can change the name of the repo if you
144:51 - do not like it as long as the name is
144:53 - available you can absolutely do that and
144:55 - a reminder that repo names are scoped
144:57 - based on personal or organizational
144:58 - accounts or organization accounts I I
145:01 - keep writing organizational but it means
145:03 - the same thing uh you can change the
145:05 - base Branch the default Branch uh you
145:07 - can rename it um just so you know Maine
145:10 - is the unspoken best practice for naming
145:12 - your base Branch everybody does it the
145:13 - old one was Master nobody calls it
145:15 - Master anymore um you can opt in and opt
145:19 - out of some features feates for your
145:20 - GitHub repo I say some as a catch all
145:23 - just in case there's features that do
145:24 - not show up or there's ones that are
145:26 - locked in um but that's pretty
145:28 - straightforward you just check a box and
145:30 - you might have to do some additional
145:31 - configuration then there's the danger
145:33 - zone which contains actions you need to
145:35 - think twice about because they cannot be
145:37 - undone if you make a big mistake and in
145:40 - the danger zone we have the ability to
145:42 - change the repo visibility um it's
145:44 - important to understand what happens
145:46 - when you make a a a repo from private to
145:49 - public the code will be visible to
145:51 - everyone who can visit at github.com
145:53 - anyone can Fork your repo all push rule
145:56 - sets will be disabled your changes will
145:59 - be published as activity now will this
146:02 - show up in the exam probably not I
146:03 - didn't see it but that is something to
146:05 - consider um you can disable Branch
146:07 - protection rules uh so Branch protection
146:09 - rules are strict workflow rules uh uh
146:12 - that dis like will do something like
146:14 - disallow someone from pushing to Main
146:16 - and uh you can temporarily disable them
146:19 - if you have to apply quick fixes and you
146:21 - can't work around those rules easily you
146:23 - can transfer ownership to somebody else
146:25 - and they'll become the owner of the repo
146:27 - you can archive the repo so it becomes
146:30 - read only you can delete the repo so
146:32 - there you
146:33 - [Music]
146:36 - go all right time for some repo
146:39 - maintenance uh so what we're going to do
146:42 - is I want to create a new repo I'm going
146:44 - to make it in my other account uh just
146:46 - because we're going to want to transfer
146:47 - from one to another but I'm going to go
146:49 - here and just say say um uh under here
146:53 - Omen King and I'm going say my cool repo
146:57 - 2 okay and I'm going to just make this
147:00 - private and I'm going to add a read me
147:02 - here um I'm going to go ahead and create
147:04 - this repo okay so now that this is REO
147:07 - created we can go over to our settings
147:08 - and let's say I didn't like the name two
147:10 - I need it to be three because we already
147:11 - have another one called two in the other
147:14 - account I'm going to rename that and it
147:16 - renames before we used to rename it used
147:18 - to take time now it's instantaneous
147:20 - which is really really great if we
147:22 - scroll on down here we could change the
147:24 - main branch we could change the name to
147:25 - main two um there are some uh
147:28 - limitations there because it's not
147:29 - showing all of our options as we don't
147:32 - have other branches apparently it
147:34 - doesn't create it instantaneously but it
147:36 - will change it in a bit of time there it
147:39 - is so I think it has taken effect if we
147:41 - go here and yeah it shows that it's been
147:44 - renamed so that sounds really good we're
147:46 - going to go back over to settings notice
147:49 - that we can check box and uh checkbox on
147:51 - and off features let's get rid of issues
147:53 - let's get rid of projects if we go over
147:56 - here to our code notice that they have
147:57 - vanished across the top so that is great
148:01 - we'll scroll on down um we have more
148:06 - abilities somewhere here in the danger
148:08 - zone so we can change our visibility it
148:10 - will give us a warning about it I'm not
148:12 - sure why it's making it so hard I'm
148:13 - going to make this public I'm going to
148:15 - say that I I accept the changes and
148:17 - we're going to make it public and then
148:19 - apparently I have to confirm so I'm
148:20 - going to get out my phone and it wants
148:22 - me to enter a number into my
148:27 - phone okay so 37 approve
148:31 - great and I'll wait a moment for it to
148:33 - take effect there we go so now it is
148:36 - public um we can disable our Branch
148:39 - rules so I'm going to go ahead and do
148:41 - that uh we can go ahead and transfer
148:44 - this repo I'm going to send it
148:47 - to um a specific person so this is going
148:50 - to
148:51 - be I want to send it
148:54 - to Andrew WC Brown which is the other me
148:59 - and then I got to type in the repo name
149:01 - so we'll go ahead and do that my cool
149:04 - repo 3 I
149:07 - understand okay so now it should be
149:10 - transferred
149:14 - um and I think the other person has to
149:16 - accept so I don't think it's
149:17 - instantaneous so if we go over here
149:22 - do I have the repo now if I go up here
149:24 - in my
149:25 - notifications how do I see the repo
149:32 - transfer I'm not sure I'm going to go
149:34 - check the email for this account and see
149:36 - if it shows up there okay all right so
149:38 - in my email we can see over here that uh
149:41 - there is a repo transfer link so I'm
149:43 - going to go ahead and click
149:44 - [Music]
149:47 - that GitHub repo templates is is a
149:50 - feature for public repos that allow
149:52 - other GitHub users to make a copy of the
149:54 - contents of the template repo to use as
149:56 - a starting point for their own repo and
149:58 - I believe it's only for public I haven't
150:00 - checked for private but I don't know why
150:02 - you'd want to use it for private we set
150:04 - a uh a repo as as a template by checking
150:08 - box on the template repository and then
150:11 - you'll have this option to use the
150:13 - template and when you click use this
150:15 - template it will then ask you to choose
150:17 - a new name and it'll say what do you
150:19 - want to include and then it'll show that
150:22 - that was generated from that other
150:24 - template I use these in my boot camps
150:26 - because I will create a starter project
150:28 - and then you will uh start from that
150:30 - template how are these how is this
150:32 - different from cloning or forking um the
150:34 - idea here is that um you're starting
150:37 - with a clean repo you're not having all
150:38 - the baggage of of stuff that comes with
150:41 - it it is a really clear a clean repo and
150:44 - so that's how you're going to go ahead
150:46 - and uh utilize it but that use case that
150:48 - I explained for which is like you know
150:51 - you want to have something like a
150:52 - project that people are going to start
150:54 - as a basis of that's where going to be
150:56 - using repo templates okay
150:58 - [Music]
151:01 - ciao hey it's Angie Brown and this fall
151:04 - along we'll go ahead and make a repo
151:06 - template so um we have
151:10 - here um let's go over here to our other
151:14 - repo trying to find
151:16 - it sometimes it's a bit hard to navigate
151:18 - repos there we go that's a bit better
151:20 - and so we have this my cool repo what I
151:21 - want to do is convert this repo into a
151:24 - public repo for now just so that we can
151:26 - utilize this feature I want to go to the
151:27 - top and see if we can make a template
151:29 - actually it looks like we can I'm really
151:31 - surprised because what would be the
151:32 - point if um it's private you know what I
151:36 - mean because we go here how's anyone
151:38 - going to click that button it doesn't
151:39 - make any sense so I really think that
151:41 - that is a public feature and notice I
151:43 - actually checkbox it on and it turned
151:45 - off so I think it
151:47 - is yeah it is nope okay it's on now
151:51 - all
151:52 - right I mean I guess you could use it to
151:55 - make your own from it so I guess my
151:58 - thought was it was always about other
151:59 - people using it but I guess you could
152:01 - make your own default template and use
152:03 - it for yourself so I guess it's not just
152:05 - a public feature but they're never going
152:06 - to ask you on the exam so I'm not going
152:08 - to fix the slides because of that let's
152:10 - go ahead and uh create a new repository
152:13 - from this template we'll just say my
152:15 - cool repo 2 and we'll make it private
152:19 - and also we can include other branches
152:21 - but I don't want anything else and there
152:23 - we go so now we have this uh repo that
152:26 - is making a copy of we'll give it a
152:28 - moment and here it is you can see it's
152:30 - generated from that one and there you go
152:34 - [Music]
152:38 - ciao so in GitHub you can clone a repo
152:43 - programmatically three different ways uh
152:46 - we have the first which is https uh you
152:48 - will have to supply a GitHub username
152:50 - and password on the Clone and you'll
152:53 - need to set uh get to cach the
152:55 - credentials if you don't want to keep
152:56 - entering them in I didn't write it in
152:58 - here but when it says password we're
153:01 - talking about the um personal access
153:04 - token because GitHub does not let you
153:06 - use passwords anymore um but in the
153:09 - documentation it kind of suggests that
153:10 - you can use a password because it says
153:13 - password protected oh not here but under
153:15 - here would it would it would say that um
153:17 - for SSH uh you can utilize that method
153:21 - you'll have to have an SSH key pair and
153:23 - you'll have to upload that to your
153:26 - GitHub account then we have the GitHub
153:28 - CLI um so we can do that as well this is
153:31 - going to use credentials uh when you do
153:34 - GitHub login it'll actually use either a
153:36 - personal access token or SSH we can also
153:38 - clone repos in the GitHub desktop and we
153:41 - can just download a zip it's not really
153:43 - cloning but we can download the contents
153:45 - of it um so that's pretty
153:48 - straightforward there sometimes you just
153:49 - want the the the codes repo um I want to
153:52 - point out that we did all this in the
153:55 - quick and dirty git and GitHub crash
153:58 - course so if you're wondering how to do
154:00 - these three make sure you have watched
154:03 - that video and you've done it all okay
154:05 - see you in the next one
154:07 - [Music]
154:10 - ciao you can add files to your GitHub
154:13 - repo directly via the GitHub UI if you
154:16 - drop down code you or sorry add file
154:18 - you'll have create new file upload files
154:21 - so it's great for both text and binary
154:23 - files um and uh the idea here is that
154:26 - when you uh go ahead and add a file if
154:28 - you need to have folders you can put a
154:30 - forward slash and it will end up
154:32 - creating as many folders as you want and
154:34 - then you put the name in and you just
154:36 - create that file there when adding
154:39 - multiple files that you also need to
154:40 - edit you can also quickly use
154:49 - in this course but uh there you
154:51 - [Music]
154:54 - go there are lots of ways of creating
154:57 - branches in GitHub and git um something
155:00 - that you should really know how to do is
155:02 - to use this single line command get
155:04 - checkout hyphen B to both create and
155:07 - check out or branch in one go you should
155:09 - absolutely know how to do get push
155:11 - hyphen U origin staging which is
155:15 - basically The Hyphen U is short for
155:17 - hyphen hyphen setup stream I know look
155:19 - like a single hyphen there but there's
155:21 - actually two uh for this flag you can
155:24 - create branches from issues um and then
155:27 - the branching issue will be Associated
155:29 - and linked you can directly create
155:30 - branches in the GitHub UI you can create
155:33 - branches in the GitHub desktop and I'm
155:35 - sure you can create branches in the
155:37 - GitHub CLI and uh yeah there you
155:40 - [Music]
155:44 - go hey it's Angie Brown and this fall
155:46 - along I want to create some branches
155:48 - nothing super difficult ult to do but um
155:50 - something that will take us just a
155:52 - moment I'm going to go ahead and use um
155:55 - our my cool repo and what I want to do
155:58 - here is I want to go ahead actually I
156:00 - want to clean these up I don't want to
156:01 - have a bunch of uh junk repos hanging
156:04 - around so actually I decided against
156:06 - that and I just want to keep things
156:08 - clean and keep with our single repo even
156:10 - if it is um public so I'm going to go
156:13 - ahead and typ my cool repo here and
156:16 - clean this up Andrew WC Brown
156:21 - or man gez Andrew WC
156:25 - brown brown my cool repo it's that auto
156:28 - complete that's messing it up there we
156:30 - go and I'm just going to go ahead and
156:32 - also get rid of this one and then we'll
156:35 - just be really focused on what we need
156:37 - to do at hand
156:38 - here just give me a moment
156:54 - there we go okay so now let's just go
156:56 - back to our GitHub examples and there
156:59 - are a few ways that we can create issues
157:02 - uh one is or sorry branches one way is
157:04 - to go to the branches Tab and I'm pretty
157:06 - sure we can just create them right here
157:07 - so I can go here and just say uh feature
157:11 - uh cool one okay and we can say what
157:15 - we're branching
157:16 - from so that's an example and and there
157:19 - it is uh another really useful way and
157:22 - something I really recommend is you
157:24 - create an issue and we'll and we'll make
157:27 - a test and create a branch from an
157:31 - issue okay and then what we can do is
157:34 - then go ahead and create a branch here
157:36 - in development in the bottom right
157:37 - corner no it's going to put the number
157:40 - in here that's a very common pattern is
157:43 - to have whatever your issued number is
157:46 - and then a a a short name for the Branch
157:50 - okay then saying like what should we do
157:52 - next code spaces locally I don't really
157:54 - want to do anything next I just want to
157:56 - um do nothing but I'll go ahead and hit
157:59 - create branch and so then it gives us
158:01 - like a button where we could click to go
158:03 - ahead and play around with it so that is
158:05 - something I do a lot when I teach boot
158:07 - camps I show this a lot this is a very
158:10 - common workflow and something you should
158:12 - absolutely remember uh that you can do
158:15 - um let's go ahead and launch up this in
158:20 - codee spaces so going to go here and we
158:23 - have this one here sure I'll launch up
158:26 - this old one sure why not and once this
158:29 - is launched up we'll take a look and
158:31 - learn how to use a very cool shorthand
158:34 - for um
158:37 - implementing uh checkout
158:40 - and creating a branch in one go okay so
158:43 - just back here when this is ready all
158:44 - right all right so this is back up and
158:46 - running and notice that we are currently
158:48 - in the main branch we can type in get
158:50 - Branch to get a list of
158:51 - branches and so what I want to do is I
158:54 - want to create myself a new Branch here
158:56 - and actually there are other branches
158:57 - it's just not showing them if we do get
158:59 - poll um it might show us those other
159:02 - branches there we go and now if we type
159:03 - in get
159:04 - Branch it still doesn't show them but
159:07 - that doesn't mean we can't check them
159:08 - out but uh our um our uh program is
159:13 - aware of it we might also be able to
159:14 - create branches within a git graph these
159:17 - were things that we installed earlier so
159:19 - they might have the option to do that
159:21 - here I'm not 100%
159:23 - sure see create Branch so we could do
159:26 - that as well I'm not going to do that
159:28 - but what I really want to show you is
159:30 - something that will show up in the exam
159:31 - I'm actually really surprised that it
159:33 - did but it is a really good thing to to
159:35 - um uh to know is that normally when you
159:38 - create a branch you'd have to type in
159:39 - get branch and I'd say my new Branch
159:43 - like this and then I'd have to do get
159:46 - check out my new
159:48 - Branch okay okay and so that's something
159:50 - you can
159:51 - do but what is more efficient you can go
159:55 - check out back to main is we can do that
159:57 - in one call we can see get checkout
159:59 - hyphen B for branch my new Branch 2 and
160:03 - that's going to create that branch and
160:06 - check it out so really make sure you
160:07 - remember this one because it will
160:08 - absolutely show up on your exam it's
160:10 - absolutely something you'll use every
160:11 - single day I strongly recommend it the
160:13 - last thing um I want to go over is just
160:15 - pushing to origin so what we can do is
160:18 - is set um Upstream but I think that U is
160:23 - a lot easier to do we say origin and we
160:24 - just say my new Branch here two and then
160:29 - that will push that Branch up there
160:31 - because you really want to know how to
160:32 - set that origin so that's all I really
160:34 - wanted to show you and um yeah we can
160:36 - just stop this environment so we'll go
160:38 - ahead to command pallet just say stop
160:41 - current code space and I'll see you in
160:44 - the next one okay ciao
160:46 - [Music]
160:50 - so GitHub releases allows you to create
160:53 - releases with release notes and linked
160:55 - assets such as zip sources or binaries
160:57 - for specific platforms so in a get repo
160:59 - you'll see releases and from there you
161:02 - can read about the release and see all
161:03 - the stuff that has changed and there
161:05 - might be the source code or binaries if
161:08 - you if this is something like um I'm
161:10 - trying to think of an example like let's
161:11 - say you like to play video games and
161:13 - there's an emulator uh for like the
161:15 - PlayStation uh they'll have like builds
161:17 - here for Windows Mac and um other things
161:20 - here uh maybe you make a video game in
161:23 - general you could distribute the binary
161:25 - here it's anything where you're
161:26 - Distributing the binaries or the sour
161:28 - source code but you're making very clear
161:29 - what has changed as a release um and
161:33 - often like when I'm having issues with
161:35 - something I will actually go through and
161:36 - re read the releases when let's say um
161:40 - like react router have you ever used
161:41 - react router Dom and they change
161:43 - versions I'm trying to understand like
161:44 - what compatibilities have changed what
161:46 - does not work anymore maybe I was
161:47 - experiencing a bug and if they do a good
161:49 - job with the documentation it will be in
161:51 - there so there you
161:53 - [Music]
161:56 - go hey everyone in this fall along I
161:59 - want to take a look at GitHub releases
162:01 - as it is a very useful feature to let
162:03 - people know about changes that are
162:04 - happening in your repo um so before we
162:07 - do let's go take a look at some other
162:10 - project that might have changes I'm
162:12 - trying to think of something interesting
162:13 - like maybe an
162:14 - emulator um so I'm just typing emulator
162:17 - in here I'm just looking for one here's
162:19 - a Nintendo switch emulator or maybe PS
162:21 - PS2 I'd rather do PS2 I feel like they
162:23 - might have good uh information about
162:25 - changes like PCS pcsx2 and on the right
162:29 - hand side you can see we have releases
162:31 - and if we open up the
162:33 - releases um they do not tell you much
162:36 - okay so that's not a great example so
162:39 - we'll go back to another one and we'll
162:41 - try another uh video game emulator maybe
162:44 - we can just try putting the word
162:47 - emulator you know and people can write
162:50 - whatever kind of releases they want this
162:51 - doesn't have
162:53 - releases uh we'll try the 3DS emulator
162:57 - this one doesn't have
162:59 - releases we
163:04 - have this one here do they have
163:06 - releases no well they do they do no just
163:10 - tags okay so I guess we're just going to
163:13 - not get really good ones here but I
163:15 - guess we could just go to rails cuz they
163:16 - seem to always have enough for us but I
163:19 - just wanted something that was written a
163:20 - little bit more uh nicer so you could
163:22 - see a good example of a release but here
163:24 - is one where um you know they're talking
163:26 - about different versions I feel like if
163:28 - there was a release for a specific uh
163:30 - tag
163:32 - version right that uh we get better
163:36 - information like when rails first came
163:37 - out like 700 probably would be a good
163:39 - one so I'm just scrolling through here I
163:41 - mean these are pretty good but again I
163:42 - just want to try to find a major release
163:44 - one is this this
163:47 - 1.0 seven I'm going just type in
163:52 - 7.0.0 might have to scroll a bit to get
163:54 - it to load
163:58 - 08 there must
164:00 - be where is it what it just skips over
164:04 - it okay well I mean 71 was pretty good
164:07 - so we'll go over back to
164:10 - 71 and uh yeah like here it's telling
164:13 - you about all the libraries and things
164:16 - that are Chang this one's a bit better
164:17 - because it's showing examples of things
164:19 - that have changed so you can put
164:20 - whatever you want to release and it's
164:21 - just to help communicate what the
164:22 - differences are because a lot of times
164:24 - you just don't know so we did do some
164:26 - tagging and that's a great opportunity
164:28 - for us to create our own release in our
164:30 - own repo so what I'm going to do is go
164:32 - back over to our home I'm going to find
164:34 - this repo that we have I'm going to go
164:36 - over to releases and we're going to
164:38 - create ourselves our own release and
164:40 - we'll just say version 1.0.0 ready for
164:44 - the
164:47 - world the the best GitHub example
164:52 - materials
164:53 - around my hands are cold if if you can't
164:56 - tell I'm
164:58 - uh sorry but I'm in like full snowsuit
165:02 - right now and I got the heater blowing
165:03 - so if you hear the heater I apologize
165:05 - but it's just how it is right now in my
165:07 - office anyway we you can choose a tag
165:10 - which is great and then um you can then
165:15 - attach the binary so the idea is we
165:17 - would download the zip and then reup
165:18 - loed again I'm not going to do that
165:20 - because that's pretty straightforward
165:21 - we'll go ahead and do that and so
165:22 - there's our release and that's all I
165:24 - really wanted to show you for releases
165:26 - apparently there's a compare button I
165:27 - didn't even know that so that might be
165:29 - kind of cool to do but um yeah there you
165:32 - [Music]
165:35 - go so GitHub packages is a platform for
165:38 - hosting and managing packages including
165:40 - containers and other dependencies and
165:42 - the things that it can uh host in terms
165:44 - of its package registry or repository is
165:47 - Javascript packages ruby gems Java Maven
165:50 - and Gradle packages net packages and
165:53 - Docker images and the last one I think
165:55 - is going to be the most common uh one
165:57 - that people can utilize um they have a
165:59 - free tier they have a pay tier so you
166:01 - can start using this right away and we
166:02 - will go give it a go um probably the
166:05 - easiest thing we could do would be to
166:07 - create a Docker uh container and then
166:09 - push it to GitHub packages so that's
166:11 - kind of the code that we'll have to go
166:13 - through we can make a simple hello world
166:14 - Docker file run it make sure we build it
166:17 - and uh GI up actions could be used to
166:19 - build and then publish I I wrote the
166:22 - word public but publish packages to
166:24 - GitHub pages so there you
166:27 - [Music]
166:30 - go hey this is Angie Brown and this fall
166:33 - along what I want to do is go ahead and
166:34 - create a GitHub package so what you're
166:36 - going to need to do is start up a code
166:38 - space I actually already have mine
166:39 - running I think by this point you
166:41 - probably know how to do that I just uh
166:43 - was working on the video earlier and I
166:45 - had to close out and restart so that's
166:46 - where we are now so anyway I'm going to
166:49 - make a new folder in here and this will
166:51 - be for uh pack GitHub GitHub packages
166:55 - okay and you're going to try to spell s
166:58 - if you hear a bit of noise in the
166:59 - background it's because I'm running the
167:01 - little space heater near my feet so my
167:02 - feet don't freeze I'm in full snowsuit
167:05 - right now okay but anyway what we'll do
167:08 - is we'll go
167:09 - into the package of directory and we'll
167:12 - make a new file and we'll call it Docker
167:16 - file okay and from here here um we want
167:20 - to
167:21 - create this little Docker image so we'll
167:25 - say
167:26 - Alpine uh latest this isn't a Docker
167:29 - course I'm not teaching all this but
167:31 - just follow along with me here or just
167:33 - copy paste it from my repo whichever you
167:34 - want to do
167:36 - Echo we'll say
167:38 - hello world okay so I'm going to go
167:41 - ahead and save that file and now what I
167:43 - want to do is go into that
167:45 - directory and build it
167:50 - so what I'll do is run Docker build
167:53 - hyphen T hello world
167:57 - period we'll build
168:01 - that
168:03 - okay and now we'll try to run it make
168:06 - sure it
168:10 - works there we go that works
168:14 - okay and so we're in good shape uh the
168:19 - other part here I would say is now that
168:20 - we have our Docker image built we want
168:22 - to now push that so I'm going to make a
168:25 - new read me file so I just have a little
168:26 - bit of room to work with
168:29 - here and there's a few things we need to
168:31 - do we need to set our username so I'm
168:33 - going to say username here I'm just
168:35 - going to set mine as what I am Andrew
168:37 - Brown WC Brown that's the account that I
168:40 - have
168:41 - here okay and I'm going to put export in
168:44 - front of
168:45 - it so I can export it
168:49 - and yeah I want allow pasting good and
168:51 - we'll hit enter it actually double
168:53 - pasted it so I got to be careful there I
168:56 - imagine this is a bit hard to read so
168:57 - I'm just going to bump up the font a
168:59 - bit and so that should be set the next
169:03 - thing is I'll need a personal access
169:04 - token so I'm going to go over here and
169:07 - we've done personal access tokens quite
169:08 - a bit in this course and we'll go down
169:11 - to developer settings and we'll make a
169:13 - new one and this one is going to well I
169:15 - guess we got to confirm with GitHub
169:16 - mobile first
169:19 - get my phone out
169:22 - here and uh it wants me to enter a code
169:28 - in one
169:31 - two okay this one's going to be for
169:36 - GitHub
169:39 - packages oh I'm not registering an app
169:42 - whoa whoa whoa whoa whoa let's go back
169:44 - personal access tokens there we go
169:46 - there's an old one I'm going to delete
169:47 - that and I'm going to generate out a new
169:49 - one we'll
169:50 - say uh GitHub
169:53 - packages I want this only to be for a
169:56 - day just in case I forget it and someone
169:57 - tries to take
169:59 - it and this is going to be
170:03 - for a specific
170:05 - repo so we'll go down
170:09 - here and say this
170:12 - repo and then for permissions I'm
170:15 - looking for
170:17 - packages packages
170:19 - it's under here
170:21 - maybe packages let's search for it
170:25 - packages it says we need a personal
170:27 - access
170:32 - [Music]
170:34 - token so I'm not seeing packages in here
170:37 - and this makes me think that we should
170:39 - probably use a traditional one I don't
170:40 - normally do this but because I cannot
170:42 - find it I'm going to use a classic
170:46 - token so that's what I'm going to do do
170:50 - um I'm going to go here I'm going to
170:51 - generate a new token really wants to
170:54 - make make a new one and just say GitHub
170:57 - packages and so it's really similar um
171:00 - very similar to the other
171:02 - one oh I want it to expire and I'm
171:05 - looking for
171:08 - packages here it is read and write
171:11 - packages delete packages so I'm not sure
171:13 - where that new one is in the new one
171:15 - maybe it's not and we just have to use
171:17 - the classic token we'll go ahead and
171:19 - generate that token out I now have this
171:21 - token I'm going to bring it on over to
171:23 - uh uh here and I want to set this as our
171:27 - environment variables I'm going to say
171:28 - GH token and we're going to paste that
171:32 - in okay and we'll copy this good I'll
171:36 - paste it in and hit enter so now that's
171:39 - set um I need to set the image
171:41 - name I'm just going to keep putting the
171:43 - GH under it image name just so it's a
171:45 - bit easier for me to find them when I
171:47 - want to find all the variables later
171:49 - hello world we'll go ahead and do
171:53 - that and copy that and paste it in hit
171:56 - enter uh I'm going to put export in
171:58 - front of that just in case that didn't
172:00 - work and then I'm going to do export my
172:04 - hands are really
172:06 - cold it's really cold in here uh I think
172:10 - it's
172:13 - like7 it's because my shed uh has a um
172:17 - oil furnace or gas yeah o furnace and I
172:19 - have to go drive out to um The the
172:22 - Reserve to get some gas and it's just
172:25 - really bad weather so I'm just trying to
172:27 - get this done so you folks can get this
172:29 - course as quickly as possible so we've
172:31 - exported those values so that's really
172:33 - good I want to make sure that they're
172:34 - set so I'm going to type in EnV GP G and
172:39 - there they are okay so now we need to
172:41 - write some code the first thing is we
172:43 - need to log into Docker and so Docker
172:45 - somehow talks to GitHub I'm not sure how
172:48 - that works but we'll just go ahead and
172:50 - work with it here so I'm going to say
172:51 - Docker login um we're going to say g c
172:54 - or say GHC so that's for GitHub
172:57 - container repository I'm assuming hyphen
173:00 - U and then we'll say GH username and
173:03 - then we'll say password STD in okay so
173:07 - that will pass the password that's what
173:08 - that pipe
173:09 - does and see if that works we'll hit
173:13 - enter uh doesn't know what that flag
173:17 - is H did I type it wrong I
173:22 - did and we'll copy that and we'll paste
173:24 - that there enter and so now we're logged
173:26 - in so that's step number one step number
173:28 - two is we need to tag our Docker
173:31 - container so we'll say uh Docker tag and
173:33 - I want my image name and then my
173:37 - version uh this will be GH version and
173:40 - this will
173:42 - be GH I mean we could just write it out
173:45 - if it's a bit simpler for everybody so
173:47 - we just say hello world one0 and then on
173:51 - the other side be
173:52 - GHC doio and then that would be our
173:56 - username so I could just type it in here
173:59 - it's up to you whether you want to use
174:00 - environment variables or not I'm just uh
174:03 - I just want it to work so I'm just going
174:04 - to write it out in full even though we
174:06 - made environment variables up here for
174:07 - this particular use case but that's okay
174:09 - one z z so the idea is we're going to
174:12 - tag um our Docker image we built is uh
174:17 - for 1.0 to map to here okay we'll go
174:20 - ahead and copy that hit
174:22 - enter um no such image I mean there is
174:25 - no tag called 1.0.0 on it we do Docker
174:29 - list or Docker
174:31 - images it's called latest so we'll
174:34 - change this to be
174:36 - latest we can make the other tag latest
174:38 - as well but I I'm going to make it 1.0.0
174:40 - I'm not sure why I'm just going to do
174:41 - that so how it's going to be we'll go
174:43 - ahead and enter and so now that's tagged
174:45 - and so now we should be able to push it
174:49 - GHC r.i slash say
174:54 - Andrew WC Brown for slash hello
175:00 - world colon
175:05 - 1.0.0 copy
175:08 - enter um so it says an image with the
175:12 - tag does not locally exist with that tag
175:16 - so maybe I tag tagged it wrong T HC R
175:20 - IO I spelled it wrong yeah we could have
175:23 - just copied this one here to get it all
175:26 - right hit enter and there it's pushing
175:28 - it okay so pretty
175:32 - straightforward uh we could have even
175:34 - done this we could said like uh
175:36 - export um tag
175:40 - name right and we could have done
175:45 - this right and then we could just done
175:48 - that
175:48 - that and we could have done that I'm
175:50 - just cleaning it up doing that uh post
175:54 - post refactor here and um here we could
175:57 - have just put these in as such so we
175:59 - could have done
176:03 - this and then this would have been
176:08 - GH uh image name and then this would
176:11 - have
176:12 - been GH
176:14 - version and so you get the idea there so
176:17 - that's pretty much it let's go take a
176:18 - look and see where this actually is I'm
176:20 - done with this personal access token so
176:21 - I want to delete it so nobody else is
176:24 - using it
176:26 - and um this revokes all personal access
176:28 - in class classic just in case I'm going
176:30 - to do this so I'm going to say Andrew WC
176:32 - Brown I think they're all revoked but
176:33 - just in case or not let's do that anyway
176:37 - and we'll go over here and we'll take a
176:39 - look at our profile because it might
176:40 - show up under packages here I'm not
176:43 - exactly sure how you set public packages
176:45 - oh there it is it's private all right
176:49 - and I'm not sure if it's specific to a
176:51 - repo link this package to a repository
176:54 - so I guess if we wanted to link it we
176:55 - would have had to apply a label and so I
176:59 - guess labels are what you think they are
177:01 - they're labels and that way we could
177:02 - associate it I'm not going to do that
177:03 - here today I think that's fine but I
177:05 - will copy this just in case anybody else
177:08 - wants to do
177:10 - that and
177:12 - um we'll go ahead and save our changes
177:27 - okay and this really doesn't want to
177:29 - push here today I'm not sure why get
177:33 - push what doesn't it
177:39 - like um oh push protection okay it
177:42 - detects something
177:44 - here oh is my token in here wow that's
177:48 - cool it actually detected it so that
177:49 - because we turned on security scanning
177:51 - earlier it would not let me do
177:54 - that that's awesome I wish we I I
177:57 - thought I was showing that earlier so
177:59 - don't show token actually what we have
178:01 - to do uh is we can't even just push the
178:03 - old one we have to amend uh the last one
178:06 - we had so if we go over
178:10 - here uh I'm going to have to go ahead
178:13 - and amend
178:16 - this so I'm trying to figure figure out
178:18 - if there's a way I can just quickly
178:21 - amend um I'm going to get rid of this
178:23 - change here first I'm just going to say
178:24 - discard this
178:26 - change and I'm going to type in get
178:28 - commit hyphen hyphen
178:31 - amend and so
178:33 - now uh what I should be able to do is go
178:36 - into here for all
178:38 - changes right and I should able just
178:41 - change
178:42 - it actually no that'll just amend the
178:44 - message sorry that's not going to do
178:46 - what we want
178:48 - uh what we actually need to do here
178:51 - is we out of amend mode I think we are
178:54 - yeah um I'm going to do get
178:58 - reset uh
179:00 - soft head Tilda one and what that will
179:03 - do is bring the changes back into here
179:05 - and so now I can go back and fix that
179:06 - but that's really good that uh I had the
179:08 - the secret scanner turned
179:10 - on do not commit your GitHub token but
179:13 - we did also delete it so it's less of a
179:14 - problem as well
179:18 - uh GitHub
179:21 - packages so just be really really
179:23 - careful with that stuff
179:26 - okay and there you
179:29 - go so I'll see you the next one okay
179:34 - [Music]
179:37 - ciao hey this is Angie Brown and we are
179:39 - taking a look at poll requests often
179:41 - abbreviated as PR and you'll see that a
179:44 - lot it's very common uh is a formal
179:47 - process to put forth changes that can be
179:49 - manually or automatically reviewed
179:51 - before it's accepted into your base
179:53 - Branch your main branch here so here are
179:56 - poll requests in GitHub and the benefits
179:59 - of poll requests is collaboration review
180:01 - or collaborative review so enhances code
180:04 - quality through team discussions and
180:05 - peer feedback CH it it tracks changes
180:09 - says change tracking but tracks changes
180:12 - provides a record of code changes and
180:14 - related discussions automated testing
180:16 - enables integration with tools for
180:18 - automated checks and tests controlled
180:20 - integration manages safe and reviewed
180:23 - merging of code changes open source
180:25 - friendly simplifies contributions and
180:27 - collaboration at open source projects I
180:30 - want to point out that PO request is not
180:32 - necessarily A get feature but a a
180:34 - workflow and GitHub has built a bunch of
180:37 - features around poll requests poll
180:39 - requests aren't unique to GitHub um it's
180:42 - just part of the workflow and and
180:43 - whatever they want to build around it
180:44 - they can build around it and that has to
180:46 - do with other tools that do the like
180:48 - jira and bitbucket or whatever other
180:51 - tools like git lab and stuff
180:53 - [Music]
180:56 - okay so we can create pull requests
180:59 - using the GitHub CLI uh that's one
181:02 - really cool way of doing it the other
181:03 - way is using uh the GitHub website so
181:06 - you go to the pull request tab in your
181:07 - repo you create a new pull request and
181:09 - there it is I'm sure you know by now how
181:12 - to create a pull request because it's
181:13 - almost impossible not to show you that
181:16 - 100 times over before we got to P
181:18 - requests here but that's how you create
181:19 - them one thing I want to point out is um
181:22 - uh that we have to set a base this is
181:24 - who we're going to merge into and ahead
181:26 - who uh the changes that we're going to
181:28 - pull into notice it says compare we'll
181:30 - talk about that in the next slide about
181:32 - base and compare
181:33 - [Music]
181:37 - okay so base and compare determines the
181:39 - direction of the merge for a PLL request
181:42 - and the idea is we have the base so is
181:46 - who you want to merge into this is
181:47 - usually the main branch or an
181:49 - environment specific Branch doesn't have
181:51 - to be main but usually main is base
181:53 - right um then we have compare this is
181:56 - what will be merg into base uh compare
181:58 - is choosing the head reference so notice
182:01 - before I called it head and if you look
182:03 - very closely it says choose the head
182:05 - reference so that's what compare is this
182:07 - is usually a bug or feature Branch
182:10 - another thing that I need to point out
182:11 - is that you can compare across Forks uh
182:14 - this is useful if you're trying to
182:15 - contribute to an open source project so
182:18 - you're going to have the option to Cho
182:20 - the base uh repository um and the HUD
182:23 - repository to different uh repos from
182:26 - different owners so there you
182:28 - [Music]
182:32 - go so a draft pull request on GitHub is
182:35 - a feature that allows you to open a poll
182:37 - request but Mark it as a work in
182:39 - progress uh the use cases for draft pull
182:41 - request would be indicating work in
182:43 - progress so communicates the poll
182:45 - request is not ready for review or
182:46 - merging preventing premature merging
182:48 - ensures incomplete work is not
182:50 - accidentally merged facilitating early
182:52 - feedback and collaboration so people can
182:54 - talk about it continuous integration
182:56 - testing so maybe you want to just run uh
182:59 - a test code because when you have a PLL
183:00 - request it's automatically going to
183:02 - start doing that transitioning to a
183:03 - ready state so easily switch from a
183:06 - draft to a ready for final review and
183:08 - merging organizing work and priorities
183:10 - help in managing and tracking ongoing
183:12 - work in large projects um draft requests
183:16 - draft pull request is a feature only for
183:18 - GitHub organization teams I believe you
183:20 - can use it in the uh free um free
183:23 - organizations that are public so we'll
183:25 - take a look and see if that's even
183:26 - possible uh if if I don't make a video
183:28 - then you know that it wasn't um there
183:30 - are two things you need to remember for
183:32 - this for the exam uh draft pull requests
183:35 - cannot be merged code owners are not
183:37 - automatically requested to review draft
183:39 - pull requests okay so remember those two
183:41 - things because they will show up on your
183:43 - exam ciao
183:48 - hey this is Andrew Brown and in this
183:50 - fall along I want to take a look and see
183:53 - if we are able to open up a draft PLL
183:55 - request in our GitHub organization free
183:58 - account that we created so what I'm
183:59 - going to do is make a new repo because
184:01 - we're going to need to need we're going
184:02 - to need to have one in our um our one
184:05 - here and actually you know what I'm
184:07 - going to do no no no I'm just going to
184:09 - uh I don't want to make it too
184:10 - complicated I'm just going to make a new
184:12 - repo so just say uh like fun repo we'll
184:16 - say fun repo
184:20 - okay and this can be public we're going
184:23 - to make it public so just in case we
184:25 - need to have that so we can have that
184:26 - functionality because a lot of times
184:28 - public allows us to have um that paid
184:31 - functionality for free so what I want to
184:33 - do is take a look here and create a new
184:35 - pull request and see if we have the
184:36 - option we don't have any code so we'll
184:39 - need to create ourselves a new Branch
184:41 - I'm going to just do that in here in the
184:43 - UI and we'll just say uh Dev and we'll
184:46 - create that branch and then from here
184:48 - we'll go over and I want to switch over
184:51 - to Dev and then I want to edit the read
184:55 - me here and I'm just going to put in
184:58 - some exclamation marks we're going to
184:59 - commit that change looks good to me and
185:02 - then we're going to make our way over to
185:03 - pull request and we'll make a new poll
185:04 - request and what I want to know is if I
185:06 - can make a draft pull request so we'll
185:09 - say create new pull request and we'll
185:12 - drop this down and there it is okay so
185:15 - that's all it takes to create a draft
185:16 - pull request if there are code owners
185:18 - assigned they can't touch it noce I
185:21 - cannot merge it I'm clicking like a
185:22 - maniac it's not going to happen and that
185:25 - is draft pull requests so there you
185:28 - [Music]
185:31 - go let's talk about linking activity
185:33 - within a poll request so you can link
185:35 - issues to a poll request so that the
185:37 - state of the poll request will
185:38 - automatically close the issue we
185:40 - actually already did this before we
185:42 - looked at issues during we looked at
185:43 - issues and we're looking at it again so
185:45 - the idea is that you go up to
185:46 - development on that cost
185:48 - and you choose um the issue or sorry the
185:51 - poll request and then they're linked
185:53 - okay so that will close it the other way
185:55 - is via those supported keywords so if
185:58 - you have any of those words you put in
186:00 - the comment of the actual poll request
186:03 - um then that will close it it says the
186:06 - poll request must be on the default
186:08 - Branch okay the PO poll request must be
186:12 - on the default Branch for it to work I
186:14 - don't know if that's true I mean it
186:16 - worked for me when we did it but but um
186:19 - however we did I guess it was on the
186:20 - default Branch but um uh anyway that's
186:25 - that I don't think there's any point of
186:26 - us showing this again because we've done
186:28 - it so many times but hopefully you know
186:30 - that you can do that and the direction
186:31 - to which it happens you're putting it in
186:33 - the uh body the description of the Polar
186:37 - Quest um so it links to the issue okay
186:40 - [Music]
186:44 - ciao let us take a look here at the
186:46 - different statuses a poll request can be
186:49 - surprisingly this isn't an exam question
186:51 - but it's something you should know so
186:52 - let's go through them all the first is
186:54 - open the default status when a pull
186:56 - request is created it's open for
186:57 - discussion review draft indicates the
186:59 - pull request is a work in progress and
187:02 - not ready for review closed the pull
187:04 - request has been closed without being
187:06 - merged this status is used when the
187:08 - proposed changes are no longer needed or
187:10 - if the branch has been rejected merged
187:13 - the pull request changes has been merged
187:14 - into the target Branch the status
187:16 - indicates a successful conclusion of the
187:18 - pull request process changes requested
187:20 - this status is used during the review
187:22 - process when a reviewer requests changes
187:25 - before the poll request can be merged
187:27 - review required indicates that the poll
187:29 - request requires a review before it can
187:31 - be merged this status is common in repos
187:34 - where uh reviews are mandatory part of
187:36 - the workflow approved the pull request
187:38 - has been reviewed and approved for
187:40 - merging by the required number of VI of
187:42 - reviewers conflict indicates that there
187:44 - are conflicts between the pull request
187:46 - branch and the target branch that needs
187:48 - to be res resolved before merging ready
187:50 - for review a poll request initially
187:52 - marked as draft can be changed to this
187:55 - status once it's ready for review so
187:57 - that gives you an idea of the
187:58 - functionality of it and you kind of
188:00 - figure this out as you are working with
188:02 - PO requests but there you
188:04 - [Music]
188:08 - go so the code owners file is a GitHub
188:11 - specific file that defines individuals
188:13 - or teams that are responsible for
188:15 - specific code in a repo and so the idea
188:17 - is that they have the syntax that's
188:18 - similar to get ignore and when a polar
188:21 - request is open that modifies any files
188:23 - matching a pattern in the code owner's
188:25 - file GitHub automatically re request a
188:28 - review from the specified code owner the
188:30 - code owner files go in either the root
188:33 - project root. GitHub folder or docs
188:35 - directory um and so yeah I think this is
188:38 - something that is a paid feature it
188:39 - probably could be in free if we're
188:42 - talking about um organizations teams or
188:45 - sorry like free organizations that have
188:47 - to take a look but yeah it is a very
188:49 - powerful feature
188:50 - [Music]
188:54 - okay so when you're merging a poll
188:56 - request there are a few options so we
188:58 - have this drop down where we can either
189:00 - create a merge this will bring all
189:01 - commits over into the repo we have
189:04 - squash emerge which will have one commit
189:06 - to be added we have rebase emerge which
189:08 - will be added and then do a rebase the
189:10 - third one is a more complex one so if
189:12 - you're not familiar with rebase you're
189:14 - probably going to be looking towards
189:15 - squash which is a good one the use case
189:17 - depends on your team's workflow they may
189:19 - prefer only a single commit uh added and
189:22 - so that's why you would want to have
189:24 - squash or rebase um but you do have a
189:26 - lot of options there for how you want to
189:28 - bring code in uh to your uh your base um
189:32 - your base
189:33 - [Music]
189:36 - there required reviewers is a way for
189:39 - you to explicitly say hey these people
189:42 - have to review this code otherwise it
189:44 - won't be accepted um and so you can
189:46 - assign or
189:47 - allow multiple required reviewers before
189:51 - code gets into a repo and a lot of times
189:53 - you can say it can't be the same person
189:55 - uh that submitted the code and it's not
189:57 - uncommon to have like four or five
189:59 - people that can be required reviewers
190:01 - and two or three have to um look it over
190:03 - before it gets accepted so here um I
190:06 - would be assigning myself and saying
190:08 - okay Omen King this this user has to um
190:12 - review the code and then from there as
190:15 - that user I would have to approve the
190:17 - changes and then from there it would
190:20 - change it to saying okay Omen king or
190:23 - Andrew Brown approv the changes and so
190:25 - now you'll be able to press that merge
190:27 - button okay so there you
190:29 - [Music]
190:32 - go hey this is Andrew Brown in this
190:35 - video I want to uh do a little bit more
190:37 - with P requests in terms of code reviews
190:41 - and maybe we could try to get that code
190:42 - owners file to work or um you know just
190:45 - things that we didn't get a chance to
190:46 - really get Hands-On with as we have made
190:49 - pull requests quite a bit but not from a
190:52 - reviewing kind of code proper way so
190:55 - what I want to do is I want to make my
190:56 - way over to our um uh our pretend
191:01 - organization and we're going to go ahead
191:02 - and create ourselves a new repo unless
191:04 - we already have one like the fun repo
191:06 - does that still exist it does so what
191:08 - we'll do is go ahead and use this one
191:10 - and what I want to
191:12 - do before we do anything else is I want
191:14 - to add um or make sure that the
191:17 - collaborator is added to this repo here
191:21 - and so I'm going to go ahead and add
191:22 - Omen King
191:26 - okay and there I am and I'm going to go
191:28 - ahead and say this person can maintain
191:30 - this repo all right and now they're part
191:32 - of this repo so they're there and the
191:35 - reason I was able to add that very
191:36 - quickly was because they were already
191:37 - part of of a team so or sorry they were
191:40 - already part of our organization so I
191:43 - didn't have to send an invite and
191:44 - confirm they're not external from that
191:46 - so that was very easy
191:48 - um the next thing I want to do is I want
191:50 - to go through and uh create a pull
191:54 - request it looks like we already have
191:56 - one here so if we already have one I'm
191:57 - not going to make a new one if you have
191:58 - to you make a new one but here it says
192:00 - this poll request oh this is that draft
192:02 - one right so we can't do anything with
192:04 - this one right now uh so I'm just going
192:06 - to close that poll request I'm going to
192:08 - go over
192:09 - here the poll request I'm going to try
192:11 - to make a new poll request because we
192:13 - still might
192:14 - have yes we do from earlier and I'm
192:16 - going to go ahead and that pull request
192:18 - okay and so we'll create that
192:21 - one and I want to say that this has to
192:23 - be reviewed by Omen King as soon as I do
192:26 - that notice we cannot proceed
192:30 - forward until that's uh ready and
192:34 - there's another here that says ready for
192:35 - review so this P request is still a work
192:37 - in progress so it's suggesting that this
192:40 - is a draft I guess I didn't notice but
192:42 - um it probably was still set to draft
192:45 - and so I ready for review
192:48 - okay so now uh Omen King should know
192:52 - that they need to approve it for this to
192:55 - work okay another thing that we could do
192:58 - is we could uh um require other things
193:01 - for approval so we could go ahead and
193:03 - add a Rule and Rule sets allow us to do
193:06 - that so there might be some things in
193:08 - here that we could set
193:13 - um require status checks to pass so that
193:15 - might be something that we might want to
193:16 - do
193:18 - and right now we don't actually have any
193:19 - status checks and so that's the reason
193:22 - why we can't we can't add that there so
193:25 - if I go
193:26 - back
193:28 - okay it would be nice to get some checks
193:30 - in here because that's the real value of
193:32 - pull request is having some kind of
193:33 - automation thing in here but I suppose
193:35 - we'd have to have like GitHub actions or
193:37 - something else so maybe we'll leave that
193:38 - for when we get to GitHub actions and
193:40 - integrate it there and we'll just
193:41 - continue on with the reviewers here so
193:44 - um I'm going to switch to my other
193:45 - account
193:49 - and I'm in this uh repon and saying oh I
193:51 - need to add a review so I can go here
193:54 - and let's say I don't like this change
193:55 - I'm G to go here and say request changes
193:57 - I don't like it make it
193:59 - better and so if I do
194:03 - this okay now it's saying in red hey you
194:07 - got to do something I like it's not
194:09 - allowed to go through um and by the way
194:11 - it show it still shows merge pull
194:14 - request and I really don't want this to
194:16 - show up
194:18 - unless I've accepted it so maybe there's
194:20 - a setting that we can do in here I
194:22 - thought it would been that rule set that
194:23 - we could do that maybe there's something
194:24 - else that we can do to protect
194:26 - it always suggest updating the pull
194:28 - request branch
194:30 - no operation options I might not be able
194:33 - to do it because I'm not the admin so
194:35 - I'm going to go back and switch over to
194:37 - this I'll go back to settings and what
194:40 - I'm looking for is the option to say it
194:43 - it
194:44 - requires uh reviewers or otherwise it
194:46 - can canot be
194:48 - merged um and so that's what I'm looking
194:51 - for right now maybe it's under uh
194:55 - rules could be Branch protection as well
194:58 - let's take a look here require a pull
195:00 - request before
195:06 - merging
195:08 - um I really thought that there would
195:10 - have been a rule for
195:12 - this the reason I think that is because
195:14 - I'm used to um
195:17 - I'm used
195:19 - to uh
195:21 - using jira and and bit bucket and and
195:23 - they'll let you do that so maybe I can't
195:26 - set that I'm not sure restrict
195:29 - creation yeah so I'm really surprised I
195:31 - can't find that maybe it's there but I
195:33 - can't find it and that's totally fine
195:35 - let's go ahead and
195:37 - pretend uh you know we're going to go
195:39 - fix this issue so we go here and it says
195:41 - I don't like it make it better so how
195:43 - can we um submit that fix right and the
195:47 - way we're going to do that is we'll
195:48 - actually have to go to this branch and
195:50 - change something so we'll go
195:53 - here and make sure we're in the correct
195:56 - branch and in here I'm just going to go
195:58 - ahead and change it
195:59 - again okay commit the change commit and
196:04 - so now if we go back to the pull request
196:06 - we should be able to update this pull
196:11 - request so I'm trying to do that
196:15 - here F's Chang
196:18 - normally what happens like and again
196:20 - it's because I'm thinking of jur and ATL
196:22 - scene is that you'd open another pull
196:23 - request and it would be the same one the
196:25 - same spot so I'm not sure if we can do
196:28 - that uh if I go Dev
196:31 - here because it's the same Branch right
196:34 - so if I do this it says view pull
196:38 - request how do I do
196:42 - this um
196:48 - and again it's because I'm expecting it
196:50 - to act like uh another piece of software
196:53 - and it's not doing what I think it's
196:55 - doing review changes I mean I could
196:58 - review my own that makes no sense review
196:59 - in code
197:00 - space so I guess the way it's going to
197:03 - work I really thought there'd be a back
197:05 - and forth there but I guess there's not
197:07 - is I suppose I would just have to go
197:09 - here and then approve
197:11 - it looks great okay so yeah I guess
197:14 - there's less process there than I
197:16 - thought
197:17 - and now that I'm happy with it I can go
197:18 - ahead and merge
197:20 - it so next question is can we make a
197:22 - code owner file and see how that
197:25 - works because I think that would be kind
197:27 - of unique to
197:31 - do sorry and so I believe that file is
197:34 - called code owners and uh what I'm going
197:37 - to
197:38 - do is I'm going to go ahead and create
197:41 - myself a new file here we'll say new
197:44 - file I'm going to say
197:48 - code
197:51 - owners and I'm just going to put an
197:53 - Aston here and just say omen King and so
197:56 - the idea is that
197:58 - anytime anything changes it should
198:01 - assign it to Omen king that's what I'm
198:04 - thinking anyway so what we'll do is
198:07 - we'll go ahead and commit these
198:11 - changes and we'll do this
198:15 - again okay
198:18 - and the idea is that if anything changes
198:20 - from that other person they they send a
198:22 - poll request I'm hoping that it's going
198:23 - to Auto assign now this might not work
198:26 - because it might be only a paid feature
198:27 - I don't know but we're going to try
198:29 - anyway so I'm going to go in the de
198:31 - branch and before I do anything I'm
198:34 - actually going to merge it the other way
198:36 - um I'm going to do that by opening
198:39 - up uh code spaces on dev and I'm just
198:42 - going to merge it back in into the
198:43 - direction because I'm not going to make
198:44 - a pull request that goes in the opposite
198:46 - direction I'm not going to do that that
198:47 - doesn't make sense P requests are
198:49 - supposed to go into your main branch
198:56 - right so I'm just giving this a moment
199:00 - here and what I want to do is do get
199:03 - whoops get merge
199:06 - main I'll do get pull I'll do get check
199:11 - out main get
199:14 - pull just in case
199:16 - we'll say get check out
199:19 - main get merge main get push saying it's
199:24 - all up to date I'm not sure if I I'm
199:26 - convinced so I'm going to double check
199:28 - uh it's not showing our tree here so
199:30 - let's say get
199:32 - graph I really wish it would persist
199:34 - changes but hey it's code
199:38 - spaces and I'll go back over to here do
199:42 - I have this
199:43 - now and show it shows that main is ahead
199:48 - of death so it's totally lying to me
199:50 - they're definitely not in sync I knew
199:53 - this was not the case oh you know what I
199:55 - merged when I was in main so that's
199:57 - probably why uh get check out um Dev get
200:01 - merge main it's always great to have
200:03 - this open so we can see I'm going to go
200:05 - sync those
200:06 - changes okay just in case that didn't I
200:09 - just get push just in case great that is
200:12 - in good shape I want to stop this
200:14 - environment stop
200:17 - good we're stopping
200:20 - it okay I'll go ahead and close that Tab
200:22 - out so now I have confidence that this
200:24 - code owners is in both I I just had a
200:26 - feeling I need to do that for some
200:28 - reason going to go ahead and just change
200:31 - this and we'll do
200:34 - that I'm going to go ahead and create a
200:36 - new pull request and I want to see
200:38 - whether it auto
200:40 - assigns we go here Dev create a pull
200:43 - request and look it auto assigned it so
200:46 - it says awaiting request a review from
200:48 - Omen King Omen King is a code owner Omen
200:50 - King will be requested when this pull
200:51 - request is created so that means the
200:53 - code owner file is working I don't need
200:54 - to create this pull request to know that
200:57 - and I think that's sufficient um the
200:59 - only last thing I would say is that you
201:01 - know people can comment directly on
201:03 - specific lines just remember that
201:04 - because they might ask you on the exam
201:06 - and that's about it we'll see you in the
201:07 - next one okay
201:08 - [Music]
201:12 - ciao hey everyone this is Angie Brown
201:14 - and this fall along I want to show you
201:16 - uh some of the more advanced options for
201:17 - poll requests um in terms of the merge
201:20 - options and why you'd use one over the
201:22 - other um so what I'm going to do is we
201:24 - going to go into our GitHub examples and
201:27 - in this case we do need to open up uh
201:30 - some kind of editor um I think we could
201:33 - get away with using
201:36 - github.io on my keyboard and that's
201:39 - going to open up the editor we're still
201:41 - going to need the repo open so I'm going
201:42 - to go here and wait for this to load and
201:45 - go to repo
201:47 - and so I I'm going to want to go over
201:49 - here for a moment I'm going to get rid
201:51 - of this um P request so we're not
201:53 - getting mixed up and um I really want to
201:56 - be
201:57 - on development and I actually don't even
202:00 - know if I'm on that so I'm actually
202:01 - going to just close this stuff out I
202:02 - might have mucked this up and we'll
202:04 - close this out because I need to be on
202:06 - the correct Branch for this to
202:08 - work
202:09 - and I mean we can do this and get up
202:12 - examples I'm going to do this in our
202:13 - other repo sorry I know I'm all over the
202:15 - place but I want to go back to our home
202:18 - and I want to go to our cool repo so I'm
202:21 - going to drop down our whoops our option
202:25 - here and I'm not sure why they don't
202:28 - never show those on the right hand side
202:29 - they really should we'll go here and I'm
202:31 - going to now um open po request and a
202:34 - new tab here and I'm going to go ahead
202:36 - and hit period And the reason why
202:39 - actually you know what we can't use uh
202:41 - GitHub Dev sorry we're going to have to
202:43 - open up code spaces because what I need
202:44 - is that visualization tool so we can see
202:47 - what we're doing so I'm going to go
202:48 - ahead and open up GitHub code spaces and
202:51 - we're going to have to wait a little
202:52 - while for this to start up unless it's
202:53 - already running that'd be really
202:55 - nice I'll be back here in just a second
202:58 - when it loads okay all right so now that
203:00 - is ready um we want to make this a
203:04 - little bit easier to look at so I'm
203:05 - going to
203:06 - switch my theme as per usual we'll go to
203:10 - uh a darker theme there we go and um the
203:12 - other thing that I want to do here is I
203:15 - want to switch out to the dev Branch so
203:17 - we say get check out Dev okay and
203:20 - another thing we're going to need is a
203:22 - tree so I'm going to go ahead and go to
203:23 - extensions here we'll say get graph
203:25 - because we need to make this really
203:26 - clear what's going on uh so I'm going to
203:29 - go here and install
203:32 - this
203:33 - okay and hopefully that installs nice
203:36 - and quick is it here not
203:39 - yet come on get graph
203:42 - install you can do get graph
203:46 - we want you there we go we want you here
203:48 - get graph so the idea is that I want to
203:50 - put a bunch of commits here and then
203:52 - we're going to merge them and see what
203:53 - it looks like when we do that and then
203:55 - we'll try a different merge option and
203:57 - we'll see how much cleaner it is uh
203:59 - doing that another way so what I want to
204:02 - do is I want to go ahead and modify this
204:05 - file save it and go get commit hyphen M
204:10 - change one and we're going to do ma to
204:13 - grab all of them in one go and then I
204:16 - want to get push okay and then we're
204:19 - going to do this again
204:21 - save and I'm going to just do a
204:24 - semicolon so I can just get through this
204:26 - a lot quicker so we'll do that
204:29 - again we'll do that
204:32 - again okay you're getting kind of the
204:34 - idea what's going on here we're kind of
204:37 - crazy people are not going to be happy
204:39 - with all of our
204:40 - commits okay great so now if we go back
204:43 - to our G
204:45 - graph here
204:47 - we got a bunch of changes I guess we
204:49 - should have incremented them it just
204:50 - says 1111 uh we can demend those like
204:55 - there's a way to rename them I don't
204:56 - really want to deal with that but let's
204:58 - just assume we didn't name it all dumb
205:00 - like that we made 1 2 3 4 5 six seven or
205:02 - for the next one we'll we'll just name
205:03 - it two so the idea is that what will
205:05 - happen the question is what will happen
205:07 - when we merge this in will we end up
205:08 - with one over here or all of these over
205:11 - here and that's what we're going to find
205:13 - out so we'll create a pull request we'll
205:16 - make a new pull request we will merge
205:19 - Dev to main we'll create that pull
205:21 - request I'm going to switch it back to
205:23 - normal we'll create that pull request
205:26 - we're going to ignore our reviewers
205:27 - we're going to just review it
205:30 - ourself and notice we're on Create and
205:32 - merge commit so we do this and what do
205:35 - we get we go back over to get graph and
205:39 - I'm going to go get fetch because
205:42 - that'll upgrate the graph without
205:43 - pulling anything and now notice that all
205:46 - of these
205:48 - commits um is up here
205:50 - now okay so that is there it didn't
205:54 - squash them all into one we still have
205:56 - all of the history of them
205:59 - okay so just to make this clear I'm
206:02 - going to just go get checkout main get
206:06 - pole get check out Dev get pull because
206:10 - I want to show you that they're all
206:11 - still
206:12 - there okay oh sorry get merge m
206:17 - get
206:19 - pull and
206:22 - refresh okay and I'll just do a get push
206:25 - for our Dev sorry but what I want to
206:28 - show you is that all of this history is
206:30 - still here it's not gone right it's all
206:32 - still here so hopefully that is clear I
206:35 - know it's not the best visual but I'm
206:36 - hoping that makes sense what I want to
206:38 - do now is I want to do a
206:41 - um I want to do a squash okay for the
206:45 - branch so I'm going to just
206:48 - make a new
206:52 - Branch get checkout Dev
206:56 - 2 and actually I'm going to do get
206:58 - checkout hyphen B Dev 2 and then we'll
207:00 - do get um because we want to push this
207:03 - Branch get push you origin Dev 2 and so
207:09 - now it's being remotely check tracked
207:10 - and I want to do something really
207:11 - similar to what we were doing before so
207:13 - I'm going to go here and for each one
207:14 - I'm going to remove a line okay we'll
207:16 - save
207:19 - it I'm looking for that one liner there
207:23 - we go and this will just be two this
207:24 - time two and we'll go here save that
207:28 - this will be two and we'll go ahead and
207:30 - save this and this will be two and we'll
207:33 - go ahead and save this and this will be
207:36 - two and we'll go ahead and save this and
207:38 - this will be
207:39 - two all right let's go back to our G
207:41 - graph we have a bunch of this stuff here
207:44 - let's go over here and make a new pull
207:47 - request this
207:49 - time we're going to Dev
207:51 - 2 and we're going to create that pull
207:53 - request and we're going to say create
207:55 - pull request and this time we're going
207:58 - to say merge pull request squash and
208:01 - merge squash and merge it's bringing all
208:04 - those commits in and now if we go back
208:06 - here and we
208:08 - refresh
208:11 - okay um we're going to refresh here
208:13 - again oh I got to go fetch get fetch
208:15 - that's so we don't see anything here get
208:18 - fetch we'll
208:20 - refresh and so notice now it doesn't
208:22 - show like a merge line coming into here
208:24 - what it's done it's taken all of this
208:27 - stuff and it's squashed it into a new
208:30 - commit and has it over here okay so it
208:33 - really depends on what you want do you
208:34 - want to keep all this history or do you
208:36 - want to kind of have this like over here
208:38 - and this has a completely separated
208:40 - commit here um it's really up to you how
208:43 - you want to do it I think this looks a
208:44 - lot cleaner um um but this is totally an
208:47 - option as well it's really what you want
208:49 - to do and I will see you uh in the next
208:52 - one so before I do that I'm just going
208:54 - to stop my
208:59 - workspace all right and see you later
209:03 - [Music]
209:06 - ciao poll request templates are similar
209:09 - to issue templates they will populate
209:11 - the PO request text area with the
209:12 - specified markdown template so they it
209:16 - is um I need to point out that uh it's
209:18 - in
209:20 - GitHub requestor template. MD that's
209:23 - what you want to use technically there
209:25 - is a folder called pull request template
209:27 - that you can use but I found that you
209:29 - really couldn't leverage it because
209:31 - there was no UI to select from it and
209:33 - the only way that you could do that was
209:35 - via this URL you generated with a query
209:37 - string so um I would suggest that you
209:40 - use pull request template MD and not use
209:43 - the folder uh and that's where it kind
209:45 - of feels like it's it's like uh where
209:48 - you have issue templates where they have
209:49 - that older version of it PO requests
209:52 - still feel like that old kind of version
209:53 - if that makes sense so there you
209:56 - [Music]
209:59 - go hey this is Andrew Brown from exam
210:02 - Pro and in this section we'll be
210:03 - covering authentication methods
210:06 - credentials are specific to a user's
210:07 - identity for example their individual
210:10 - username and password pin or biometric
210:12 - information every user including it
210:14 - administrators te teachers staff persons
210:17 - and students as credentials an
210:19 - authentication method is the way a user
210:21 - proves their identity to a system for
210:23 - example a user inputs their credentials
210:25 - in a sign in screen or via the Microsoft
210:27 - authenticator app in which they have set
210:29 - up their account authentication methods
210:32 - can also be broken down into categories
210:34 - or types such as signed authentication
210:37 - password reset authentication
210:39 - multifactor
210:41 - authentication authentication types
210:43 - authentication methods vary widely from
210:46 - traditional to Advanced common types
210:48 - include passwords and pins common but
210:50 - can be risky for security picture
210:53 - passwords and pattern locks offer
210:54 - memorability and simplicity biometric
210:57 - authentication facial fingerprint
210:59 - retinol provide secure unique user
211:02 - identification passwordless
211:03 - authentication emphasizes security and
211:06 - convenience by eliminating traditional
211:08 - passwords removing the hassle of
211:09 - memorization and mitigating threats like
211:11 - fishing some of Microsoft's methods
211:14 - include Windows hello for business uses
211:16 - Biometrics P for secure sign-ins and SSO
211:20 - Microsoft authenticator app enables
211:22 - phone verification with notifications
211:24 - and Biometrics pin F2 security key
211:28 - allows password free logins with
211:29 - external internal
211:31 - Keys password reset authentication
211:34 - self-service password reset with
211:35 - Microsoft enter ID lets users change
211:37 - their own passwords without help desk
211:39 - assistance cutting down on support costs
211:41 - and improving security and efficiency
211:44 - some of the key features include
211:46 - self-service users can change or reset
211:48 - their passwords without administrator or
211:49 - help desk assistance security
211:52 - enhancement sspr improves organizational
211:54 - security by allowing users to promptly
211:56 - address account lockouts or compromises
211:59 - compliance with password policies sspr
212:02 - enforces Microsoft enter password
212:04 - policies regarding complexity length
212:06 - expiration and character use ensuring
212:08 - standardized security measures across
212:10 - the
212:11 - board multiactor authentication MFA is a
212:15 - security measure that requires more than
212:16 - one piece of evidence to confirm your
212:18 - identity when logging into an account
212:20 - like a code from your phone in addition
212:21 - to your password some MFA methods
212:24 - include SMS text message a code sent to
212:27 - the user's phone phone voice call
212:30 - answering a call to confirm identity
212:32 - Microsoft authenticator app a code or
212:34 - biometric verification through the app
212:37 - and O aut hardware token using a
212:39 - physical token for
212:41 - authentication set up ooth for external
212:43 - Services oo is a protocol for for
212:45 - authorization that lets users give
212:47 - thirdparty services like GitHub or
212:49 - Jenkins permission to use their
212:50 - information without sharing their login
212:52 - details it ensures secure connections
212:55 - making authentication and permissions
212:57 - straightforward use personal access
212:59 - tokens personal access tokens provide a
213:01 - way for users to create special tokens
213:03 - to access devops tools they are
213:05 - especially handy for command line
213:07 - interactions or scripts needing direct
213:09 - access to these Services apply
213:11 - role-based Access Control rule-based
213:14 - Access Control sets up detailed access
213:16 - rules based on users roles and what
213:17 - they're allowed to do it makes sure
213:19 - people have just the right access they
213:21 - need for their work keeping sensitive
213:22 - information secure so that's an overview
213:25 - of the authentication and credential
213:31 - strategies the next topic we'll be
213:33 - covering is get lfs which stands for get
213:36 - large file storage and get fat
213:38 - developers sometimes struggle with
213:40 - handling big files in a get repository
213:42 - because it can make the repository work
213:43 - slower and use up too much space
213:46 - Microsoft has two tools to help with
213:47 - this git lfs and get fat git lfs is an
213:51 - open source extension for git that helps
213:53 - handle large files more efficiently it
213:55 - does this by using small text pointers
213:56 - in your git repository to represent the
213:58 - large files while keeping the real file
214:00 - content stored elsewhere this method
214:02 - keeps your repository from getting too
214:04 - large and slowing down to get started
214:06 - with G lfs you'll need to follow some of
214:08 - these steps install git lfs install go
214:12 - to the git lfs website download and
214:14 - install the version B based on your
214:16 - operating system configure use the
214:18 - command G lfs install to set up G lfs on
214:21 - your system setting up G lfs in your
214:23 - repository track large files decide
214:26 - which file types to manage as large
214:28 - files for example use get lfs track.
214:31 - mpp4 for MP4 files add attributes file
214:34 - add the dog attributes file to your repo
214:36 - with get add. attributes commit and push
214:39 - save the changes with Git commit Dash
214:41 - and configure git lfs and update the
214:43 - remote repository using git push
214:45 - managing large files add files run get
214:48 - ad dot or get ad file name to Stage
214:50 - large files commit and push use get
214:53 - commit dmad large file and get push to
214:55 - commit and send files to the remote repo
214:58 - so that's an overview on how to get
215:00 - started with G
215:02 - [Music]
215:05 - lfs get fat is another tool for managing
215:08 - large files and get repositories it's a
215:10 - python script that keeps large files
215:12 - separate from your git repository while
215:14 - maintaining references to those files
215:16 - within the repository let's take a look
215:18 - at how to get started with get fat
215:20 - setting up get fat install python make
215:23 - sure python is installed on your system
215:25 - install get fat install get fat using
215:27 - Pip with Pip install get fat
215:29 - initializing get fat in your repository
215:32 - initialize get fat run get fat in it in
215:34 - the root of your repository track files
215:37 - Define large file types in a dogit fat
215:39 - file for example to track MP4 files you
215:42 - might add asteris MP4 to the file commit
215:45 - dogit fat add the dogit fat file to your
215:48 - repo with get add. git fat and then
215:49 - commit it using get commit DM initialize
215:52 - git fat and track large files managing
215:54 - large files with get fat add large files
215:57 - use get fat add file to Stage large
215:59 - files for get fat commit and push commit
216:02 - with get commit Dash and add large file
216:04 - and upload with get Push Pull large
216:06 - files on a different machine after
216:08 - cloning run get fat pool to download the
216:10 - large files so that's an overview of how
216:13 - to get started with get fat
216:15 - [Music]
216:19 - git scaler is an extension that helps
216:21 - get efficiently manage large
216:22 - repositories addressing the slowness and
216:24 - space issues associated with downloading
216:26 - a repository's entire history and files
216:29 - git scaler solves this by allowing you
216:31 - to download only the files you need it
216:33 - works well with Git lfs to use git
216:35 - scaler you'll first need to set up your
216:37 - repository with G lfs that enable git
216:39 - scaler for specific file paths you're
216:41 - interested in configure git scaler for a
216:44 - specific path install G lfs install G
216:47 - lfs by following the steps provided in
216:49 - its official documentation initialize G
216:52 - lfs in your repository and your
216:53 - repositories directory run git lfs
216:56 - install create and configure.it
216:58 - attributes file in the root directory of
217:00 - your repository create a dogit
217:01 - attributes file to enable git scaler for
217:04 - files under the my/ large SL files
217:07 - directory add the following line to
217:09 - dogit attributes my/ llarge SL files
217:13 - asterisks filter equals diff equal lfs
217:16 - merge equal lfs D text this
217:19 - configuration tells get lfs to manage
217:21 - files in my large files using git scaler
217:23 - for efficient handling commit and push
217:26 - the dog attributes file commit the dogit
217:28 - attributes file to your repository with
217:30 - get add. attributes then git commit dasm
217:34 - configure git lfs and git scaler for
217:36 - specific paths push the changes to your
217:38 - remote repository get push so that's an
217:41 - overview of how to get started with get
217:43 - scaler
217:44 - [Music]
217:48 - cross repository sharing with get
217:50 - sharing code across different
217:51 - repositories is common for reusing code
217:54 - modularization or separating components
217:56 - of an application gate facilitates this
217:58 - with the following method sub modules
218:01 - git subm modules let you integrate a
218:03 - separate git repository within another
218:04 - repository's directory structure it's
218:07 - especially handy for incorporating a
218:08 - particular version of an external
218:10 - library or for sharing common libraries
218:12 - across various projects to add a subm
218:15 - module
218:16 - you'll need to use the command get subm
218:17 - module at repository URL path repository
218:21 - URL the get URL of the repository you
218:23 - want to add path the directory path
218:26 - within your main project where the subm
218:27 - module will be placed here's an example
218:30 - get subm module at https github.com
218:35 - example.
218:37 - externals some of the advantages of sub
218:39 - modules include manage shared code by
218:42 - referencing specific commits and keeps
218:44 - the main project separate from external
218:46 - dependencies note that using git sub
218:48 - modules requires managing updates
218:50 - individually and maintaining consistency
218:52 - across projects that share them overall
218:55 - by using subm modules you can
218:56 - efficiently manage cross repository code
218:58 - sharing and get while maintaining clear
219:00 - boundaries between different projects or
219:06 - components the next tool we'll be
219:08 - covering is get subtree git subtree is a
219:11 - tool that helps you include code from
219:13 - one repository into a specific folder of
219:15 - another repository it's a simpler
219:17 - alternative to subm modules which is
219:19 - another way to incorporate external code
219:21 - but can be a bit complex to handle with
219:23 - get subtree you can both bring an
219:25 - external code and send updates back to
219:26 - the original code Source if needed to
219:29 - add a subtree you use a command that
219:31 - looks like this get sub tree add--
219:33 - prefix equals folder name repository URL
219:36 - commit or Branch D- prefix equals folder
219:40 - name is where you specify the folder in
219:41 - your main project where you want to add
219:43 - the external code Repository URL is the
219:46 - web address of the external code you're
219:47 - adding and commit or branch is the
219:50 - specific version of the external code
219:51 - you ought to use which can be a commit
219:53 - ID or Branch name get subt Tre
219:55 - streamlines project workflow by
219:57 - integrating external code directly
219:59 - ensuring it's immediately accessible
220:01 - upon clothing without additional steps
220:03 - overall get subtree makes it easy to
220:05 - work with code share between different
220:07 - projects while it simplifies some of the
220:09 - issues found with sub modules updating
220:11 - the code from the original repository
220:12 - into your project can require a few
220:14 - extra steps
220:16 - [Music]
220:20 - the next topic we'll be covering is
220:21 - workflow hooks workflow hooks are
220:24 - essential tools in the Microsoft devops
220:26 - ecosystem designed to automate and
220:28 - refine development workflows leading to
220:29 - better efficiency and productivity
220:32 - workflow hooks Act is triggers for
220:33 - executing actions or scripts at specific
220:36 - points in a devops workflow crucial for
220:38 - maintaining code quality automated
220:40 - testing deployment and integrating
220:41 - external Services into the process in
220:44 - the context of build and release Cycles
220:46 - workflow hooks are particularly valuable
220:49 - they enable developers to automate tasks
220:50 - like unit testing documentation
220:52 - compilation or deployment to testing
220:54 - environments with each new build or
220:56 - release streamlining these
220:58 - processes Azure devop stands out and
221:01 - offering comprehensive tools and
221:02 - services for managing the devops life
221:04 - cycle including implementing workflow
221:06 - hooks through service hooks these
221:08 - service hooks allow for connecting your
221:09 - devops pipeline with external services
221:12 - or initiating custom actions in response
221:14 - to various events such as new bill
221:16 - completions work item updates or pull
221:18 - requests other tools and services for
221:21 - workflow hooks besides Azure Dev Ops
221:24 - Microsoft offers other tools and
221:25 - services for implementing workflow hooks
221:28 - including GitHub actions Azure logic
221:30 - apps and Azure functions the key to
221:32 - leveraging workflow hooks effectively is
221:34 - to identify the crucial events and
221:36 - actions within your workflow and use the
221:38 - appropriate tools for
221:40 - implementation here's a simplified
221:42 - step-by-step guide to creating a service
221:43 - hook in Azure Dev Ops for automating
221:45 - actions such as notifications after a
221:47 - successful build Access Project settings
221:50 - open your project in Azure devops and
221:52 - navigate to project settings at the
221:54 - bottom of the project sidebar open
221:56 - service hooks in the general section
221:58 - find and click on service hooks create
222:01 - subscription initiate the creation
222:03 - process by clicking the plus create
222:05 - subscription button select notification
222:07 - service pick the service for
222:09 - notifications like Microsoft teams or
222:11 - slack and set the event trigger to Bill
222:13 - completed set trigger filters customize
222:16 - the trigger filters by setting the build
222:18 - status to succeeded configure action
222:21 - details specify the notification message
222:23 - and destination such as the recipient
222:25 - Channel and slack or an email address
222:28 - finalize and test save the service hook
222:30 - with the Finish button and conduct a
222:31 - test to confirm it operates as expected
222:33 - after a build is successful so that's an
222:36 - overview of workflow
222:38 - [Music]
222:42 - hooks hey this is Andrew Brown from exam
222:44 - Pro and in this section we'll be
222:46 - covering the different types of Branch
222:48 - strategies starting with trunk based
222:50 - development or TBD TBD employs a single
222:53 - Central Branch known as the trunk or
222:54 - Master focusing on frequent small
222:56 - updates for continuous integration and
222:58 - stability steps to implement TBD why
223:02 - establish the trunk Define a single
223:03 - Branch also known as the trunk as the
223:05 - central code path two direct commits
223:08 - encourage team members to commit small
223:10 - changes directly to the trunk frequently
223:13 - three continuous integration per perform
223:15 - builds and tests on the trunk often to
223:17 - catch issues early for automate
223:19 - deployment set up automatic deployment
223:21 - to streamline updates here's an example
223:23 - of how you can create a trunk Branch
223:25 - using git git Branch trunk get checkout
223:29 - trunk another Branch strategy you can
223:31 - use as feature branches which enable
223:33 - developers to work independently on new
223:35 - features or fixes keeping changes
223:37 - separate from the main code until
223:38 - they're ready to merge this approach
223:40 - allows for focused development and
223:42 - testing of specific functionalities
223:43 - without disruption steps to use feature
223:46 - branches why create feature Branch
223:49 - initiate a new Branch for each feature
223:51 - or fix to naming conventions assign
223:54 - descriptive names reflecting each
223:55 - Branch's purpose three stay updated
223:58 - merge updates from the main branch
224:00 - periodically for thorough testing
224:03 - conduct extensive tests before merging
224:05 - back to the main branch here's an
224:07 - example of how you can create and switch
224:08 - to a feature Branch using get hit Branch
224:11 - Feature slne Feature get checkout
224:14 - feature SL new
224:15 - feature the last Branch strategy we'll
224:18 - be covering is release branches which
224:20 - help prepare and stabilize a codebase
224:21 - for a new release focusing on bud fixes
224:24 - and final adjustments they are created
224:26 - from the main branch enabling ongoing
224:28 - development while ensuring the upcoming
224:29 - releas is Thoroughly tested and Polished
224:32 - steps for managing release branches
224:35 - while create a release Branch start a
224:37 - branch from the main branch for new
224:38 - releases two Focus adjustments make all
224:41 - necessary tweaks and Bug fixes on this
224:43 - Branch three three ensure stability test
224:46 - thoroughly and maintain continuous
224:48 - integration four final merge merge the
224:51 - release Branch back into the main branch
224:53 - once ready here's an example of how you
224:55 - can create a release Branch using get
224:57 - get Branch relase sr-
225:00 - 1.0 get checkout relase
225:04 - sr-10 so that's a brief summary of the
225:06 - key branching strategies that will be
225:08 - covered on the Azure devops
225:13 - exam call I are critical for maintaining
225:16 - code quality and ensuring that changes
225:18 - meet certain standards before they are
225:19 - merged Branch policies in Microsoft
225:22 - devop Solutions or rules that govern how
225:24 - code is contributed to a repository they
225:26 - enforce certain conditions that must be
225:28 - met for poll requests to be merged
225:30 - ensuring that code is reviewed tested
225:32 - and linked to relevant project tasks key
225:35 - Branch policies to implement require
225:37 - approving reviews mandate that each poll
225:39 - request receives at least one approving
225:41 - review from designated reviewers before
225:43 - it can be completed this guarantees that
225:45 - all code changes are scrutinized by
225:47 - another developer promoting better code
225:49 - quality and reducing the risk of Errors
225:51 - link work items ensure that every poll
225:53 - request is associated with a
225:55 - corresponding work item this linkage
225:57 - provides traceability and accountability
225:59 - making it easier to track why changes
226:01 - were made in ensuring they align with
226:02 - the Project's goals build validation
226:05 - configure this policy to require that
226:07 - changes in a poll request successfully
226:09 - pass automated builds and tests this
226:11 - helps to identify any compilation issues
226:13 - or test failures early prevent
226:14 - preventing problematic code from
226:16 - reaching the production
226:17 - environment additional Branch policies
226:20 - for enhanced workflow en Force minimum
226:22 - review time set a minimum period that
226:24 - poll requests must remain open before
226:26 - they can be merged this policy prevents
226:28 - Rush reviews and ensures thorough
226:30 - evaluation requir task completion
226:33 - mandate the completion of specific tasks
226:35 - before merging such as addressing all
226:37 - code comments or updating necessary
226:39 - documentation this ensures that all
226:40 - critical aspects are handled before
226:42 - integration automate code for forting in
226:45 - style checks Implement tools like
226:47 - linters to automatically enforce coding
226:48 - standards this minimizes manual review
226:51 - efforts and maintains consistent code
226:53 - quality benefits of using Branch
226:55 - policies improve code quality automated
226:58 - checks and enforce review standards
227:00 - significantly reduce the risk of
227:01 - introducing bugs and errors better team
227:04 - collaboration requiring reviews and
227:06 - linking work items promotes effective
227:08 - collaboration and keeps team members
227:10 - aligned with project goals efficient
227:12 - workflow management automating parts of
227:14 - the review process accelerates the
227:16 - development cycle while upholding high
227:18 - quality standards so that's an overview
227:21 - of Branch
227:26 - policies the next topic we'll be
227:28 - covering is Branch Protections in Azure
227:29 - Dev Ops Branch protections provide an
227:32 - additional layer of security by
227:34 - enforcing rules on Branch manipulation
227:36 - preventing accidental modifications or
227:38 - unauthorized changes here are some of
227:41 - the key Branch protections to implement
227:43 - require a minimum number of reviewers
227:45 - set branches to require a specific
227:47 - number of reviewers for all changes this
227:49 - ensures multiple evaluations of the code
227:51 - which facilitates collaboration and
227:53 - reduces the risk of defects restrict who
227:56 - can push to the branch limit direct push
227:58 - access to protected branches allowing
228:00 - only authorized individuals or teams to
228:02 - make changes this control helps prevent
228:04 - unauthorized modifications and maintains
228:06 - code integrity and force merge checks
228:09 - specify criteria that must be met before
228:11 - merging a poll request these include
228:13 - build validation work item linking and
228:15 - Branch permissions compliance to ensure
228:17 - only approved changes merge P request
228:20 - workflow with Branch policies and
228:22 - protections here's how you can structure
228:24 - a typical pull request workflow using
228:26 - both Branch policies and protections
228:29 - create a feature Branch developers
228:31 - Branch off the main branch to work on
228:32 - new features or fixes Implement changes
228:35 - and create a poll request developers
228:37 - commit changes to their branch and open
228:39 - a pull request to merge them into the
228:40 - main branch assign reviewers and await
228:43 - feedback reviewers and inspect the code
228:45 - provide feedback and approve Branch
228:47 - policies and sheer pull requests need
228:49 - the required approvals to proceed
228:52 - address feedback and iterate developers
228:53 - respond to feedback update their code
228:56 - and Trigger the build validation process
228:58 - reviewers reassess the updated
229:00 - changes complete the pull request after
229:02 - security approvals and passing merge
229:04 - checks like work item linkage and build
229:06 - validation the pull request is completed
229:08 - and changes are merged so that's an
229:11 - overview of Branch protection in Azure
229:13 - Dev Ops
229:14 - [Music]
229:18 - hey this is Andrew Brown from exam Pro
229:20 - and in this section we'll be covering
229:22 - Azure pipelines Azure pipelines is a
229:25 - cloud service that automates the CI CD
229:27 - pipeline for software development
229:29 - offering support for multiple languages
229:31 - platforms and Cloud environments and
229:33 - integrating with a wide range of tools
229:34 - and services here are some of the key
229:37 - features of azure pipelines automation
229:39 - for CI CD Azure pipelines provides a
229:42 - fully featured continuous integration
229:44 - and continuous delivery service for
229:46 - applications platform and language
229:48 - agnostic supports any language platform
229:51 - and Cloud that integrates with Azure o
229:53 - and gcp extensibility offers integration
229:56 - with popular tools and services in the
229:58 - software development ecosystem supports
230:01 - open source and private projects
230:03 - available for projects hosted on GitHub
230:05 - and other platforms Rich integration
230:08 - integrates with GitHub checks and offers
230:09 - extensive reporting capabilities
230:12 - parallel jobs and environments allows
230:14 - running multiple jobs in parallel and
230:16 - deploying to multiple environments
230:17 - including kubernetes VMS and Azure
230:20 - Services next we'll take a look at
230:23 - defining your pipeline yaml syntax as
230:26 - your pipelines uses yaml syntax to
230:28 - Define build test and deployment tasks
230:31 - step-by-step process the documentation
230:33 - Guides Through the process of setting up
230:35 - your first pipeline including initiating
230:37 - builds packaging applications and
230:39 - deploying some of the key Concepts
230:41 - include pipelines a complete CI CD
230:44 - pipeline defined by stages jobs steps
230:47 - and tasks stages a way to organize jobs
230:50 - typically used to separate build test
230:52 - and deploy processes jobs and steps jobs
230:55 - group steps which are individual tasks
230:57 - like scripts or Azure pipeline tasks and
231:00 - tasks prepackaged scripts that perform
231:02 - actions in your
231:04 - pipeline moving on to supported
231:06 - languages and framework wide language
231:08 - support works with any language
231:10 - including net Java JavaScript node.js
231:13 - python PHP P Ruby C C++ and more
231:17 - framework and platform support supports
231:19 - Windows Linux and maos builds can deploy
231:22 - to various platforms including Azure
231:24 - kubernetes VMS and on premises servers
231:27 - extensibility Marketplace extensions a
231:30 - rich Marketplace of extensions to extend
231:32 - the functionality of azure pipelines
231:34 - custom tasks developers can create
231:36 - custom tasks to meet unique requirements
231:39 - pricing free tiers available offers free
231:42 - CI CD minutes to projects with
231:44 - additional minutes available for
231:45 - purchase pricing varies based on
231:47 - Parallel job needs and Cloud providers
231:50 - so that's an overview of azure
231:56 - pipelines the next topic we'll be
231:58 - covering is GitHub repos with Azure
232:00 - pipelines integrating GitHub
232:02 - repositories with Azure pipelines can
232:04 - significantly enhance the automation of
232:06 - build and release processes within a
232:07 - devops workflow this integration
232:10 - facilitates continuous integration and
232:11 - delivery promoting faster and more
232:13 - reliable applic a deployments here's how
232:16 - to structure the setup process step one
232:19 - create a new project in Azure devops
232:21 - create project click the new project
232:23 - button provide the necessary details for
232:26 - your project such as name and
232:27 - description and then click on the create
232:29 - button to finalize the project creation
232:32 - step two connect your GitHub repository
232:34 - to Azure pipelines access pipelines in
232:36 - your new Azure devops project navigate
232:38 - to the pipeline section initialize
232:41 - pipeline click on the new pipeline
232:43 - button select Source choose GitHub as
232:45 - the source for your pipeline you will
232:47 - need to authenticate and authorize aure
232:49 - pipelines to interact with your GitHub
232:51 - account configure pipeline select this
232:54 - specific Branch or repository to build
232:56 - and deploy customize the pipeline
232:58 - settings based on your application
233:00 - requirements activate after configuring
233:02 - click on the save and run button this
233:04 - action saves your pipeline configuration
233:06 - and triggers the initial
233:08 - build step three build and deploy your
233:11 - application build configuration as your
233:13 - pipelines will execute the build of your
233:15 - application according to the directives
233:17 - specified in your pipeline configuration
233:19 - file which is usually a yl file this may
233:22 - include tasks like compiling code
233:23 - running tests and packaging artifacts
233:26 - release tasks post build configure the
233:28 - pipeline to deploy your application to
233:30 - various environments such as staging or
233:32 - production this can involve deploying to
233:34 - services like Azure app service or Azure
233:36 - kubernets service deployment
233:38 - customization utilize features like
233:40 - environment variables secrets and
233:42 - approvals to tailor and secure your
233:44 - deployment
233:45 - process benefits of integrating GitHub
233:48 - with Azure pipelines continuous
233:50 - integration ensures that any changes in
233:52 - the connected GitHub repository trigger
233:54 - automatic builds keeping your
233:56 - application updated and validated after
233:58 - every commit code visibility enhances
234:01 - traceability by linking GitHub pull
234:02 - requests and commits directly to their
234:04 - respective build and release pipelines
234:07 - artifact management facilitates
234:09 - management and storage of build
234:10 - artifacts in Azure pipelines or with
234:12 - external services such as Azure
234:13 - artifacts and Docker Registries
234:16 - continuous delivery automates the
234:17 - deployment process across different
234:19 - environments minimizing manual
234:21 - intervention and promoting consistent
234:23 - releases release approvals implements
234:25 - controls and checks through configurable
234:27 - approvals before promoting bills to
234:29 - production environments so that's an
234:31 - overview of GitHub repos with Azure
234:38 - pipelines the next thing we'll be
234:40 - covering is configuring the permissions
234:41 - and Source control repo managing access
234:44 - ACC and security through permissions is
234:46 - critical in a devops environment to
234:47 - ensure that team members have
234:49 - appropriate access for their roles
234:51 - configuring repository level permissions
234:53 - one Access Project and as your devops
234:56 - navigate to your project and go to the
234:58 - repo section to repository settings
235:01 - select your repository and click on the
235:03 - settings tab then repositories in the
235:05 - submenu three modify security choose the
235:08 - repository you want to adjust and click
235:10 - on the security tab on the right for
235:12 - manage access at user users or groups to
235:15 - the predefined security groups or create
235:17 - new ones five set permissions use the ad
235:20 - button to Grant the appropriate
235:21 - permissions like read contribute and
235:23 - administer to selected users or groups
235:26 - Branch level permissions configuration
235:28 - widen repository access open your
235:31 - repository in Azure Dev ops two branches
235:34 - go to the branches Tab and choose the
235:35 - branch you need to configure three
235:38 - security settings click on security to
235:40 - manage permissions for that Branch for
235:42 - Define permissions assign permissions to
235:44 - groups or users overriding repository
235:47 - level permissions if necessary
235:49 - configuring file level permissions why
235:52 - locate file within the repository
235:54 - navigate to the specific file you want
235:55 - to manage two file permissions click the
235:58 - three dot icon next to the file and
236:00 - choose manage permissions three control
236:03 - access at groups or users and set the
236:05 - desired access levels just as you would
236:06 - at the repository or Branch level so
236:09 - that's an overview of configuring the
236:11 - permissions in Source control repo
236:13 - [Music]
236:17 - the next topic will be going over our
236:19 - tags and Source control repos tags and
236:21 - get serve as reference points to
236:23 - specific commits making it easier to
236:25 - manage and track different versions of
236:26 - code in a repository step one repository
236:30 - access log into Azure devops or another
236:32 - Microsoft devops Solutions platform
236:35 - verify you have the required repository
236:37 - permissions step two navigate to the
236:39 - repository after logging in locate the
236:42 - repositories or Source control tab on
236:44 - your dashboard this section contains all
236:46 - the repositories you have access to
236:48 - within the platform step three create a
236:50 - tag identify the commit in the
236:52 - repository that you wish to tag tags are
236:55 - useful for marking releases or important
236:57 - points in the Project's history select
236:59 - the desired commit from the commit
237:00 - history look for an option label create
237:03 - tag or add tag usually available in the
237:05 - commits context
237:06 - menu step four provide tag details in
237:10 - the tag creation dialogue enter the tag
237:13 - name a unique identif fire for the tag
237:15 - provide a description a brief note about
237:17 - what this tag represents add any
237:19 - annotations or other metadata if
237:21 - necessary step five save the tag confirm
237:25 - the details and save the tag this action
237:27 - attaches the tag to your specified
237:29 - commit marking it for future reference
237:31 - step six View and manage tags after
237:34 - creating a tag you can view and manage
237:36 - it through the repository interface
237:38 - access the tag section where all
237:40 - configured tags are listed here you can
237:42 - rename delete or reassign tags to
237:44 - different commits if required so that's
237:47 - an overview of tags and Source control
237:53 - repos the next thing we'll be covering
237:55 - is recovering data using git commands
237:58 - git is vital for Version Control and
237:59 - teamwork but sometimes mistakes occur
238:01 - leading to data loss or overwrites it's
238:04 - important to know how to restore data
238:05 - using get commands in these situations
238:08 - examining commit history check git log
238:10 - use the command git log to see a list of
238:12 - recent commits made in the Repository
238:14 - this log includes the commit hash author
238:16 - date and the commit message to find a
238:18 - specific commit or to filter the log by
238:20 - author date or content you can use git
238:23 - log author equals username git log since
238:26 - equals 2023
238:28 - 0401 git log GP equals keyword this
238:31 - helps in locating the exact commit hash
238:33 - of the changes you wish to restore
238:35 - revert a specific commit use get revert
238:37 - commit underscore hash to undo the
238:39 - changes made in a specific commit while
238:41 - preserving the history of changes this
238:43 - command creates a new commit that
238:44 - reverses the changes introduced by the
238:46 - specified commit it's a safe way to undo
238:49 - changes as it doesn't alter the existing
238:51 - history for example get revert 1 a23 C4
238:55 - recovering deleted commits use rlaw to
238:57 - recover lost commits if you've
238:59 - accidentally deleted or lost commits get
239:01 - reflog can be a lifesaver it shows a log
239:03 - of where you're head and Branch
239:05 - references have been which includes
239:06 - deleted or orphan commits you can find
239:08 - the commit hash of a loss commit and
239:10 - recover it by creating a new Branch from
239:12 - it hit reflog hit Branch restore Branch
239:16 - Commit This restores the deleted commit
239:18 - in a new branch called restore Branch
239:20 - allowing you to access the previously
239:21 - lost changes restoring deleted files
239:24 - restore deleted files if you've deleted
239:26 - a file and want to recover it from
239:28 - history use get checkout commit uncore
239:31 - file uncore path this command restores
239:34 - the file as it existed at the specified
239:36 - commit it's useful for quickly
239:38 - recovering loss work without affecting
239:39 - other changes in the repository so
239:42 - that's an overview of recovering data
239:44 - using get
239:48 - commands the next topic we'll be going
239:51 - over is purging data from Source control
239:53 - to optimize your Source control system
239:55 - within Microsoft devops environments
239:57 - regular purging of unnecessary data is
240:00 - crucial this helps in improving system
240:02 - performance and reducing clutter
240:04 - prerequisite checks communicate with
240:06 - Team ensure all team members are
240:08 - informed of The Purge to avoid any
240:09 - disruption backup data confirm that
240:12 - backups are in place for all critical
240:13 - dat data data replication check ensure
240:16 - essential data is replicated to
240:18 - Alternative repositories or backup
240:20 - systems Azure devops rest API for data
240:23 - purging automate with API use the Azure
240:25 - devops rest API for automated data
240:27 - deletion tasks delete files folders
240:30 - branches modify the delete API call is
240:33 - needed to Target and remove specific
240:34 - items from the
240:36 - repository manual get garbage collection
240:39 - trigger garbage collection run get GC in
240:41 - your local repository to start manual
240:43 - garbage collection non-production timing
240:46 - perform this operation when it won't
240:47 - interfere with development activities
240:50 - get history compression access
240:52 - repository settings in Azure Dev Ops go
240:54 - to the repository settings to find G
240:56 - configuration options enable compression
240:59 - check the option for compress kit
241:01 - history to optimize
241:02 - storage removing unnecessary branches
241:06 - local branch deletion use git Branch D
241:08 - Branch name to remove branches from your
241:09 - local machine Azure devops branch
241:12 - removal use the azure devops web
241:14 - interface to locate and delete old or
241:15 - unused branches implementing data
241:18 - retention policies Define policies set
241:21 - up rules for how long data should be
241:23 - retained in Azure Dev Ops automate
241:25 - purging configure automatic removal of
241:27 - age data to streamline repository
241:29 - maintenance so that's a brief summary of
241:31 - purging data from Source
241:34 - [Music]
241:37 - control hey this is Andrew Brown from
241:39 - exam Pro and in this section we'll be
241:41 - covering integrating pipelines with
241:43 - external starting with dependency
241:45 - scanning dependency scanning helps you
241:47 - track and manage the libraries and
241:49 - packages your codebase depends on this
241:51 - ensures that your applications use the
241:53 - appropriate versions of these
241:54 - dependencies minimizing the risk of
241:56 - compatibility problems select from
241:58 - various tools like oasp dependency check
242:01 - or retire. JS which help identify
242:03 - vulnerabilities and outdated libraries
242:05 - in your projects dependencies choose one
242:08 - that best fits your Project's
242:09 - requirements configure the pipeline
242:11 - integrate your selected dependency scan
242:14 - tool into Azure pipelines by setting up
242:15 - a task to run the scan before the build
242:17 - or deployment phases to identify
242:19 - vulnerabilities at the earliest analyze
242:22 - the results post scan analyze the
242:24 - results to identify and prioritize
242:26 - vulnerabilities or outdated dependencies
242:28 - highlighted in the scam report address
242:30 - these issues to maintain the health and
242:31 - security of your
242:33 - application detection process each
242:35 - change in the dependency graph or after
242:37 - code build initiates a new snapshot of
242:39 - your components vulnerable components
242:41 - are logged and displayed as alerts in
242:43 - the advanc security tab based on
242:45 - advisories from the GitHub advisory
242:47 - database these logs detail the severity
242:49 - component vulnerability title and cve
242:53 - managing alerts the advanced security
242:55 - tab serves as a central hub for viewing
242:57 - and managing dependency alerts it allows
242:59 - filtering by Branch Pipeline and
243:01 - severity and provides remediation steps
243:04 - alerts for dependency scans on PR
243:06 - branches are shown and any name changes
243:08 - to pipelines or branches might take up
243:10 - to a day to reflect in the results so
243:12 - that's an overview of dependent
243:18 - scanning the next topic we'll be
243:20 - covering is security scanning
243:22 - integrating security scanning tools into
243:24 - your pipelines is a critical step to
243:26 - identify and address security
243:27 - vulnerabilities in your code there are
243:29 - many security scanning tools available
243:31 - like sodar queet and Microsoft Defender
243:33 - for cloud these tools analyze your
243:35 - codebase for security flaws coding
243:37 - standards violations and potential
243:39 - vulnerabilities choose the tool that
243:41 - meets your Project's requirements sod
243:44 - queet is an open-source platform for
243:45 - continuous inspection of code quality it
243:48 - performs automatic reviews to detect
243:50 - bugs vulnerabilities and cod smells in
243:52 - your code Microsoft Defender for cloud
243:55 - formerly known as Microsoft Defender app
243:57 - offers Security Management and advanced
243:59 - threat Protection Services across hybrid
244:01 - Cloud
244:02 - workloads set up your pipeline
244:04 - incorporate the security scanning tool
244:06 - by adding the required tasks into your
244:08 - pipeline configuration for example in
244:10 - Azure pipelines you can add a task that
244:12 - triggers the security scan during the
244:14 - build phase automating the security
244:16 - audit evaluate scam results after the
244:19 - security scan is finished review the
244:21 - tools report it will highlight security
244:23 - gaps and code quality concerns address
244:25 - these items promptly giving priority to
244:27 - the most critical issues to fortify your
244:29 - codebases security posture so that's a
244:32 - quick overview of security
244:37 - scanning the next topic we'll be going
244:40 - over is code coverage code coverage
244:42 - measures the percentage of your codebase
244:44 - tested by automated tests revealing how
244:46 - much code is exercised during testing to
244:48 - ensure quality and detect uncovered
244:50 - areas select a code coverage tool select
244:53 - a tool like jaac for Java or Cobra to
244:55 - for net ensure it integrates well with
244:58 - your Tech stack and test Frameworks
245:00 - configure the pipeline incorporate your
245:02 - chosen tool into the pipeline to collect
245:04 - code coverage metrics during tests for
245:06 - example using Azure pipelines you can
245:09 - use a published code coverage task to
245:10 - generate reports in popular formats like
245:12 - Cobra or
245:14 - jaac analyze code coverage results
245:17 - review the coverage report post analysis
245:19 - to identify and improve areas with low
245:21 - test coverage enhancing your codes
245:23 - robustness accessing coverage artifacts
245:26 - publish code coverage artifacts can be
245:28 - viewed in the pipeline run summary under
245:30 - the summary tab offering a snapshot of
245:32 - test coverage for each build quality
245:34 - metrics enforcement code quality
245:37 - assurance leverage code coverage metrics
245:39 - to continuously elevate your Project's
245:41 - quality and verify the extent of testing
245:43 - for new code pull request integration
245:46 - Implement coverage data within pull
245:47 - requests to ensure thorough testing and
245:49 - preemptively fill testing voids before
245:51 - integration setting code coverage
245:53 - policies full versus diff coverage full
245:57 - coverage measures the total code basis
245:59 - test coverage ensuring overall quality
246:01 - diff coverage focuses on the code
246:03 - changes in pull requests ensuring new or
246:05 - altered lines are tested so that's an
246:08 - overview of code coverage
246:10 - [Music]
246:14 - the next topic we'll be covering are
246:16 - quality Gates a quality gate acts as a
246:18 - benchmark for code quality that must be
246:20 - met prior to release and ideally before
246:22 - the code is committed to Source control
246:24 - it ensures that only code that meets
246:25 - established standards progresses through
246:27 - the development pipeline features of
246:29 - quality Gates automated code analysis
246:32 - tools like sonar kuet are integrated
246:34 - into Azure pipelines to perform static
246:36 - code analysis identifying potential
246:38 - issues such as code smells
246:39 - vulnerabilities and bugs performance
246:42 - metrics code quality metrics including
246:44 - code coverage complexity and
246:46 - maintainability index are assessed
246:48 - compliance checks Gates ensure the code
246:50 - complies with security standards and
246:52 - governance policies before proceeding in
246:54 - the
246:55 - pipeline best practices for implementing
246:57 - quality Gates customization customize
247:00 - gate criteria to align with project
247:02 - demands and application type threshold
247:04 - setting set clear thresholds for code
247:06 - coverage to Define pass fail conditions
247:08 - for the gate such as minimum code
247:10 - coverage percentage feedback loop
247:13 - establish immediate feedback systems for
247:15 - developers upon gate failure for prompt
247:17 - issue resolution integrating quality
247:19 - gates with Azure pipelines hypine
247:22 - configuration integrate quality checks
247:24 - in your CI CD flow to control code
247:26 - progression using established metrics
247:28 - action on failure defined actions for
247:30 - when code fails to meet the quality
247:32 - Gates criteria which may include halting
247:34 - the pipeline triggering alerts or
247:35 - creating tasks for remediation
247:38 - visibility and reporting increased
247:39 - transparency through dashboards or
247:41 - reports showing gate outcomes for
247:42 - ongoing Cod based Health monitoring so
247:45 - that's an overview of quality
247:51 - Gates the next type of gates we'll be
247:53 - covering are security and governance
247:55 - Gates security gates are established to
247:57 - verify that code complies with security
247:59 - protocols and is free of vulnerabilities
248:01 - before being pushed to production static
248:04 - application security testing integrate a
248:06 - sast tool like sonar queet and white
248:08 - Source bolt into the build process to
248:10 - scan for security flaws this proactive
248:13 - approach to Tex issues early reducing
248:15 - the risk of vulnerabilities reaching the
248:17 - production environment Dynamic
248:19 - application security testing conduct D
248:22 - regularly on live applications to find
248:24 - security weaknesses use tools like Azure
248:27 - web application firewall to guard
248:29 - against common threats like xss and SQL
248:32 - injection governance gates are
248:34 - checkpoints to confirm that both code
248:35 - and deployment procedures are in line
248:37 - with company policies and Industry
248:39 - regulations policy definition and
248:41 - enforcement identify and set governance
248:44 - policies required by your organization
248:47 - apply these policies using tools such as
248:49 - Azure policy to automatically enforce
248:51 - them throughout the development cycle
248:53 - automated compliance verification build
248:55 - automated compliance checks into your CI
248:58 - CD Pipeline with Azure devops compliance
249:00 - or similar tools automating these checks
249:02 - ensures ongoing adherence to governance
249:04 - standards without manual oversight so
249:07 - that's an overview of security and
249:09 - governance Gates
249:10 - [Music]
249:14 - hey this is Andrew Brown from exam Pro
249:16 - and in this section we'll be going over
249:18 - what are pipelines in devops a pipeline
249:21 - is a key framework that structures the
249:23 - software delivery process through
249:24 - automated steps it ensures each phase of
249:26 - the software life cycle from integration
249:28 - to deployment is optimized for quick
249:30 - development reliable releases and
249:33 - scalability it encompasses several
249:35 - components and features components of
249:37 - devops pipelines while in source code
249:40 - repository the starting point where code
249:42 - is stored in Version Control
249:44 - two build server automates the
249:46 - compilation building and preliminary
249:48 - testing of code three test server runs
249:51 - various tests such as unit or
249:53 - integration to ensure code quality four
249:56 - deployment server manages the deployment
249:57 - of code to various environments such as
249:59 - staging or production five feedback and
250:03 - monitoring tools that provide feedback
250:04 - on deployment success and monitor
250:06 - application performance and production
250:09 - features of devops pipelines automation
250:12 - every stage from code commit to
250:13 - production is automated minimizing
250:15 - manual tasks and errors continuous
250:18 - integration and deployment ensures that
250:20 - changes to software are automatically
250:22 - tested and deployed improving speed and
250:24 - quality modularity each component
250:26 - functions independently but
250:28 - collaboratively allowing for easier
250:29 - troubleshooting and updates benefits of
250:32 - Dev Ops pipelines increased efficiency
250:35 - automation reduces the delivery Cycles
250:37 - enabling faster releases improved
250:40 - reliability continuous integration and
250:42 - testing diminish the chances of defects
250:44 - in production better scalability
250:46 - pipelines support scalable operations
250:48 - and management practices as
250:50 - organizational needs grow so that's an
250:53 - overview of
250:57 - pipelines the next topic we'll be
250:59 - covering is integrating automated
251:01 - testing into pipelines automated testing
251:04 - plays a vital role in ensuring the
251:06 - quality and reliability of software
251:07 - products by incorporating automated
251:09 - tests into the pipeline you can detect
251:11 - issues early in the development cycle
251:13 - streamline the release process and
251:15 - Achieve faster time to Market key steps
251:17 - for integration Define test strategy
251:20 - outline what types of tests such as unit
251:22 - integration UI will be automated and set
251:25 - the coverage criteria create test
251:27 - infrastructure use Azure Dev Ops for
251:29 - provisioning resources like VMS or
251:31 - containers or utilize Azure test plans
251:33 - for executing tests choose a test
251:35 - framework depending on your text stack
251:37 - select an appropriate framework like Ms
251:39 - test nunit or xunit write automated
251:42 - tests develop tests that address various
251:44 - functional and integration aspects of
251:46 - your application for example in a
251:48 - shopping cart application you could
251:50 - write a test to ensure items are added
251:52 - correctly the example shows a unit test
251:55 - in C using Ms test to verify that a
251:57 - product when added to a shopping cart is
251:59 - correctly included this test checks the
252:01 - functionality of the add to cart feature
252:03 - essential for e-commerce applications by
252:06 - asserting that the cart contains the
252:07 - added product Version Control manage
252:10 - your test scripts and cbase in a get
252:12 - repository using Azure Dev Ops for
252:14 - Integrations like pull requests and
252:15 - reviews configure CI pipeline set up a
252:18 - CI pipeline in Azure pipelines to
252:20 - automatically run tests upon commits
252:22 - helping identify issues early
252:24 - incorporate test reporting utilize Azure
252:27 - Dev Ops for detailed test reporting and
252:28 - tracking over time Implement CD pipeline
252:31 - after passing tests in CI deploy your
252:34 - application across different
252:35 - environments using a CD pipeline so
252:38 - that's an overview of automated tests
252:39 - into Pipelines
252:41 - [Music]
252:45 - the next topic we'll be covering our
252:46 - testing strategies local tests are
252:49 - written by developers to test individual
252:51 - components or modules before they are
252:53 - integrated into the larger system they
252:55 - ensure that each piece of code functions
252:57 - correctly in isolation there are various
252:59 - tools and Frameworks available for
253:00 - writing local tests such as Ms test
253:03 - nunit or xunit for example using Ms test
253:06 - you might test a method in a class that
253:08 - calculates the sum of two numbers the
253:10 - test checks whether the method Returns
253:12 - the correct result result when adding
253:13 - two integers unit tests focus on
253:16 - validating the functionality of
253:18 - individual methods or classes in
253:19 - isolation identifying bugs and ensuring
253:22 - code behaves as intended Microsoft devop
253:24 - solution supports Ms test and unit and
253:27 - executed for these tests unit tests are
253:29 - narrowly focused while local tests can
253:31 - be broader or refer to the environment
253:33 - in which a variety of tests are
253:35 - performed using nunit consider a test
253:37 - for a service that retrieves a list of
253:39 - items the test verifies that the list is
253:41 - not empty and contains the expect number
253:43 - of items integration tests assess the
253:46 - interaction between two or more
253:47 - components of the application to ensure
253:49 - they work together as expected these are
253:51 - important for catching issues that unit
253:53 - tests might miss using nunit an
253:55 - integration test could check the
253:57 - interaction between two Services where
253:59 - one service uses data provided by
254:01 - another load tests evaluate the
254:03 - performance of the system under a
254:05 - significant load which could be
254:06 - simulated users or transactions they
254:08 - help to identify the capacity limits and
254:10 - scalability of the application in the
254:13 - low test scenario in Azure Dev Ops you
254:15 - could simulate multiple users accessing
254:17 - a service to test its performance and
254:19 - capacity so that's an overview of the
254:21 - main types of testing
254:26 - strategies another type of testing is
254:28 - the UI testing UI testing is critical in
254:32 - Microsoft devops for ensuring that the
254:33 - user interface of applications functions
254:35 - correctly and meets desired requirements
254:38 - this testing confirms the UI
254:40 - functionality and behavior identifying
254:42 - early issues with user interactions
254:44 - layout responsiveness and data
254:46 - management bug detection regular UI
254:48 - testing identifies bugs and errors early
254:51 - improving user experience quality
254:53 - verification this testing confirms that
254:55 - the UI meets functional requirements and
254:57 - performs as expected under various
254:59 - conditions Microsoft offers several
255:02 - tools that streamline UI testing in
255:03 - devops environments first let's go over
255:06 - Microsoft test manager Microsoft test
255:09 - manager supports extensive UI testing
255:11 - with capabilities tailored for managing
255:13 - test cases and tracking their execution
255:15 - setting up Begin by creating a new test
255:18 - plan in Sweden MTM test cases add UI
255:21 - test cases to your Suite execution and
255:24 - Analysis use mtm's test Runner to
255:26 - perform the tests and review results
255:28 - including screen shots and videos
255:30 - another one is Visual Studio coded UI
255:33 - tests Visual Studio coded UI tests
255:35 - provide a code Centric approach to UI
255:37 - testing suitable for automation using C
255:40 - or visual basic.net create a test
255:43 - project start a new project and add a
255:44 - coded UI test record and enhance
255:47 - interact with your applications UI to
255:49 - record actions then add validation
255:51 - statements execution run your tests
255:54 - locally or integrate them into your
255:55 - devops pipeline for continuous testing
255:58 - selenium web driver with C selenium web
256:01 - driver is an open source framework ideal
256:03 - for automating web browsers and
256:05 - conducting cross-platform UI tests set
256:07 - up install selenium web driver via the
256:10 - new get package in your Visual Studio
256:12 - solution create and configure start a
256:14 - new C test project and set up selenium
256:16 - web driver develop and run tests write
256:19 - test methods to interact with the UI and
256:21 - execute them locally or within your
256:23 - devops pipeline so that's an overview of
256:25 - UI
256:27 - [Music]
256:31 - testing let's take a look at GitHub
256:33 - actions which is a cicd pipeline
256:35 - directly integrated with GitHub repos
256:37 - and GitHub actions allows you to
256:39 - automate running test Suites Building
256:41 - images specifically docker images
256:43 - compiling static sites deploying code to
256:45 - servers and more and we can access this
256:48 - all through the actions tab in your
256:51 - GitHub repo uh when you first use GitHub
256:54 - actions there are some templates that
256:55 - you can utilize and all these files are
256:58 - stored in your workflow directory in
257:00 - your GitHub folder as you can see
257:02 - there's this kind of yaml file that
257:04 - we're going to utilize it's going to be
257:06 - important that we remember some of the
257:07 - structure so I remember on the exam they
257:09 - wanted you to know that there was jobs
257:11 - on and steps uh you can have multiple
257:14 - workflows in a repo triggered by
257:16 - different events so when you run GitHub
257:19 - actions you'll get a history of workflow
257:21 - of runs where it will indicate if it was
257:22 - successful or failure how long it took
257:24 - to run so this is um for something
257:27 - probably for um some one of the boot
257:29 - camps that we ran as we used GitHub
257:31 - actions to build the site if you want to
257:34 - find the example repos because there are
257:36 - those little getting started but it's
257:37 - the same repo here at the starter
257:39 - workflows and you can get the yaml files
257:42 - and get started really quickly there are
257:44 - different types of triggers uh that you
257:47 - can use with GitHub actions that's going
257:48 - to go into that on area and GitHub
257:51 - there's about 35 GitHub actions I say
257:54 - plus because in case there are more that
257:56 - I'm not aware of I'm covering my bases
257:58 - there examples of common GitHub actions
258:01 - could be pushes pull requests issues
258:04 - releases schedule events and manual
258:07 - triggers the exam wants you to know that
258:09 - you can trigger based on these things so
258:11 - make sure you remember this short little
258:13 - list here
258:15 - [Music]
258:18 - okay hey this is Andrew Brown and in
258:20 - this follow along let's take a look at
258:22 - GitHub actions so what I want to do is
258:24 - go over to our organization I'm going to
258:27 - go to our fund repo and here we have a
258:30 - tab called actions where we can set up
258:32 - some GitHub actions now I don't use
258:34 - GitHub actions a whole lot maybe I will
258:36 - if I go ahead and do that GitHub action
258:38 - cert uh certification course but uh
258:41 - we'll just have to kind of work our way
258:42 - through through it it shouldn't be too
258:43 - hard so there's a lot of different
258:45 - things that we can utilize here I can
258:47 - set up terraform which is kind of cool
258:49 - uh we have deployment to AWS to Azure to
258:52 - Alibaba Cloud we have some security
258:55 - things that we can do here we have
258:56 - continuous integration automation a
258:59 - whole host of stuff and um you can even
259:02 - do static compilation which is pretty
259:05 - cool as well so we're going to have to
259:07 - make make a decision in terms of
259:09 - something that we want to use um I don't
259:12 - I think it's going to be deployment
259:14 - because that seems like a lot of work um
259:18 - so I'm trying to make a decision
259:20 - here what we could
259:24 - utilize build lint and test a rails
259:27 - application that seems pretty small or
259:29 - easy for me to do but maybe we should
259:31 - try to use one of these things down
259:33 - below um labels pull requests based on
259:36 - files change let's go ahead and see if
259:38 - we can utilize that so I hit the
259:39 - configure button and it's going to bring
259:41 - us into this action
259:43 - and I guess there's the marketplace
259:45 - where we can get uh more stuff I didn't
259:47 - even realize there was a Marketplace for
259:48 - this looks like we got some
259:50 - documentation here so customizing when
259:52 - workflows run based on trigger so here
259:54 - it says on push Branch so when we push
259:57 - to specific ones we can trigger
259:59 - different
260:00 - stuff okay so that's kind of cool let's
260:03 - take a look here and see if we can
260:04 - expand this and see what we're looking
260:06 - at so we have name labeler on pull
260:09 - request Target jobs and then we have
260:12 - labels so run as Ubuntu so probably
260:16 - start a container as an Ubuntu with
260:19 - permissions of contents to read and it
260:21 - can write pull requests and the step
260:23 - that we're going to have here it's going
260:24 - to use the actions labeler version 4 and
260:27 - with the repo token it's going to bring
260:28 - in that token so it has authorization to
260:30 - do so and we know about GitHub tokens um
260:33 - and I think I think we showed this uh
260:36 - for GitHub actions but not 100% sure so
260:40 - carefully reading here the whole point
260:42 - of this is to apply labelers and the
260:44 - basically the way it's going to do that
260:45 - is through these steps and so I'm
260:46 - assuming that this is kind of like a
260:48 - built-in step and if we go here and just
260:50 - type it in maybe we'll go find
260:52 - it yeah and so they're talking about
260:55 - actions
260:56 - here hold on
260:58 - here I guess it's just a repo so get
261:03 - documentation
261:06 - and oh okay it's called actions all
261:09 - right and so this whole
261:11 - repo trans
261:13 - actions all right and so it's coming
261:16 - from this one and so I'm just going to
261:18 - go into here and take a look at what
261:19 - this looks like so just zoom out for a
261:23 - second and it kind of explains maybe how
261:25 - it
261:27 - works um automatically labels new pull
261:29 - requests based on the paths of the files
261:31 - being changed on the branch the ability
261:33 - to apply labels based on names of
261:36 - branches and things like that the bug
261:37 - related to the issue so create a GitHub
261:41 - labeler yaml file this will list a uh a
261:44 - list of labels and config options to
261:46 - match and apply the label all right the
261:51 - match object allows control over the
261:53 - matching
261:54 - options you can specify the label to be
261:56 - applied based on the files that have
261:58 - been changed Etc like
262:02 - that and sounds a little bit
262:06 - complicated but at least down here it's
262:08 - like showing us uh the flow it's
262:09 - interesting that this one is showing
262:11 - version four we clearly there is a
262:13 - version five um there might have been
262:16 - warning up here saying that we should
262:18 - use it doesn't say that we have to use
262:21 - version five or
262:22 - four or we're first to use
262:25 - five um but let's see if we can figure
262:28 - this out so I'm going to go ahead and go
262:32 - down below and just look at the workflow
262:35 - a little bit more here and it looks
262:36 - pretty much the same the only difference
262:38 - is that this one's using version five
262:40 - it's not passing the width for the token
262:43 - so I'm not 100% sure if we actually
262:45 - really need to do that but I'm going to
262:46 - go ahead and go commit changes and we'll
262:48 - commit that there okay so now we have
262:52 - that here if we go to
262:53 - actions um we can see that we have
262:57 - labeler and it's only going to run
262:59 - what's going to trigger it let's go take
263:02 - a look
263:03 - here um if we want to know how it
263:06 - triggers we should just take a look at
263:07 - the code and
263:09 - whoops go back here and take a quick
263:11 - look so it says says pull pull request
263:14 - Target so we pull request Target what
263:18 - does that
263:20 - mean we'll go search it
263:24 - here um pull request Target so activity
263:28 - types assigned assigned
263:30 - labeled runs your workflow when activity
263:33 - on a PLL request in the workflows
263:36 - repository
263:38 - occurs when activity on a pull request
263:40 - in the workflow activity occurs so it's
263:42 - going to check on based on a lot of
263:45 - stuff so that's pretty broad but that
263:47 - seems fine looks like we could even
263:48 - narrow it down to very specific types
263:51 - okay so I mean that's is how we could
263:52 - play with
263:54 - triggers um and so basically when that
263:56 - triggers it's going to go ahead and then
263:59 - start up Ubuntu for some reason maybe
264:02 - that's what it has to use to run this
264:03 - code that we saw from over
264:06 - here okay and this looks like it's
264:08 - JavaScript or
264:10 - something and then we need that
264:13 - file so we need to make sense of what
264:16 - this is so the base match object is
264:18 - defined as this any glob to any
264:21 - file okay the key okay so what does this
264:25 - thing do automatically label new pull
264:27 - request based
264:29 - on the path of the files being changed
264:32 - on uh changed or the branch
264:38 - name okay well I'd rather just do that
264:41 - on the branch name so let's see if we
264:43 - can find that so it
264:47 - says change
264:51 - files give me a moment just to try to
264:53 - make sense of this and then I'll just
264:55 - save you the trouble of me struggling
264:56 - through it okay okay scrolling down
264:59 - we're getting better examples this is
265:00 - starting to make more sense it says add
265:02 - an any change label to any changes
265:05 - within the entire
265:07 - repository Okay add documentation label
265:10 - to any changes within the doc folder so
265:13 - maybe what we can do is give this one a
265:15 - go and uh we need to create a file
265:18 - what's this file need to be called
265:20 - GitHub laer yaml so we'll go here and
265:23 - I'm going to add a new
265:25 - file
265:27 - okay um add a
265:29 - file this will be
265:33 - label. yaml we'll double check make sure
265:36 - that is
265:38 - correct I've been known to make mistakes
265:40 - often
265:42 - and I'm going to paste that on in here
265:44 - and we're going to commit that change so
265:46 - now we have our labeler yaml I'm going
265:48 - to go take a look here and see if the
265:49 - action got triggered it did um it failed
265:54 - I mean there's nothing for it to check
265:55 - right now so no event triggers defined
265:58 - is on so not exactly sure what it's
266:01 - saying there but that's totally fine for
266:03 - now and what I need to do is I need to
266:06 - create a poll request I mean it
266:08 - shouldn't trigger unless we have a poll
266:09 - request right um but it did just
266:12 - happened now so I'm curious what would
266:14 - happen if I went ahead and just uh made
266:17 - any kind of
266:19 - change because it shouldn't really
266:20 - trigger unless it's a pull request we'll
266:23 - go here and go back to actions and it
266:26 - ran again so I'm really confused why is
266:28 - this running what it should only happen
266:30 - on a poll request
266:33 - Target um we'll open it up again here
266:37 - so no event trigger defin is on
266:43 - okay maybe there's something wrong with
266:45 - our our workflow
266:47 - file let's see what they say you can
266:51 - trigger all branches just by
266:54 - using remove the hyphen your workflow
266:56 - file seems fine have you checked all
266:59 - indentation so I mean we didn't make
267:01 - that file right it was generated for us
267:04 - let's go take a look and see what we can
267:06 - do about
267:08 - that we have label and labeler
267:12 - okay so this was the one that we
267:14 - wrote I mean everything looks fine here
267:18 - I'm going to open this up in codes
267:21 - spaces or not codes spaces we'll open
267:22 - this up in
267:43 - that
267:45 - um I don't know if we need this so I'm
267:49 - just going to take that out because the
267:50 - other one didn't have
267:51 - it okay can expand this yeah it still
267:54 - has this
267:56 - here
267:59 - and I'm not sure why this little red
268:01 - line is here maybe it's just superficial
268:02 - it's confused but this seems fine I'm
268:06 - going to go ahead and update this and
268:07 - say update action
268:12 - the other question is do I have this in
268:13 - the right
268:15 - folder
268:17 - because yeah it's in actions but labeler
268:20 - yaml labeler yaml isn't supposed to be
268:23 - in the actions folder so I think what's
268:25 - happening here is that it thinks I think
268:27 - I know what happened here um if we go
268:29 - back to our
268:31 - repo I think it thinks labeler is a an
268:34 - action yeah so I think it's just we put
268:36 - that in the wrong folder so I'm going to
268:38 - go back and open up
268:43 - and we're just going to move that back
268:44 - into the correct
268:46 - location okay so we're going to expand
268:48 - that and this labeler is going to go
268:50 - into the GitHub folder there we go going
268:54 - to go ahead and add this all and
268:57 - fix and we will commit and we will let
269:01 - that
269:02 - push and I'm going to go back over to
269:06 - here all right and if we go back over to
269:10 - actions oh uh this is not the repo we'll
269:13 - go back over to our organization into
269:15 - Fun repo it might have triggered one
269:17 - more time I don't
269:19 - know it has not so we are in good shape
269:22 - can we delete this run y we can let's
269:25 - just delete this up to clean up so we
269:26 - can see what we're
269:30 - doing and uh what I want to
269:33 - do is I want to trigger that uh polar
269:37 - request to get automatically labeled so
269:38 - we're going to need a label called
269:41 - documentation for for this to work so
269:43 - we're going to go here to labels and
269:44 - we'll make a new label there actually
269:46 - already is one called documentation I
269:48 - don't know if this is case sensitive so
269:49 - I'm just going to change it to Capital D
269:52 - so it just works for us and we're going
269:54 - to go over here to code and I need a new
269:58 - Branch so I'm going to go to
269:59 - Dev and in here I'm going to create
270:02 - myself
270:04 - a um a docs directory so I'm going to
270:07 - make a new folder
270:10 - here and what I'll do do is I'll make
270:14 - a new
270:17 - folder we'll call this
270:19 - docs and I'll say readme.md
270:26 - read me okay we'll save that we'll go
270:29 - ahead and Commit
270:32 - This and we're in a branch right yeah
270:34 - we're in a branch
270:35 - so commit we're like new docs directory
270:42 - and I know I spelled that wrong it's
270:44 - okay nobody's watching here today
270:46 - there's no grading going on if I ever
270:48 - grade you I'll poke you for that but
270:51 - right now it doesn't matter and I think
270:54 - that we made that in the dev Branch so
270:57 - we'll go over here and I want to go
270:59 - ahead and create a new pull request so
271:01 - want to make sure that folder is there
271:03 - pull requests new pull requests we'll
271:07 - drop down Dev we'll compare that over
271:09 - we'll say create pull request
271:12 - and the idea is that when we create this
271:13 - it should label it if this worked as
271:17 - expected um and so what I want to do is
271:19 - go over to actions and see if it
271:20 - triggered and it's running so it's
271:22 - queued it's going to think what to do it
271:25 - has to spin up compute so this is an
271:29 - instantaneous in progress good we're
271:32 - watching
271:35 - it label complete success we'll go to
271:38 - our pull
271:39 - request there we go look at that
271:43 - um and now we have a p a check that
271:45 - passed and we overo to our checks and it
271:48 - shows that it passes so you know before
271:51 - we talked about like Branch rules we
271:53 - could maybe tell it that it has to pass
271:56 - that before it could proceed not a
271:58 - really good example for this but we
271:59 - could try it and it's just an
272:01 - opportunity to show off this Branch
272:03 - protection rule stuff so I'm just
272:05 - looking here carefully for where that
272:07 - was uh it was like checks
272:12 - okay and I'm going to drop that
272:15 - down
272:17 - and still doesn't show up here so maybe
272:20 - that doesn't work as expected but I was
272:21 - hoping that maybe I could just choose
272:23 - that from
272:24 - there um because it's not like an
272:26 - upfront check it's like something that
272:27 - happens after you do that but anyway
272:29 - that's get up actions in a nutshell um
272:32 - it is very important that we understand
272:34 - how those files work so before I go I
272:36 - just want to uh pull up a link because
272:39 - there was something that really
272:39 - explained the structure of these files
272:42 - really well it was understanding GitHub
272:44 - actions okay so let this here learn
272:46 - GitHub actions understanding GitHub
272:48 - actions I think it was this one yeah and
272:50 - so this one really helps explain this
272:52 - workflow file so let's go through it
272:54 - really quickly and make sure we
272:56 - understand it
272:59 - so um first thing is the name so we're
273:01 - going to name it that's optional we have
273:03 - run name so the workflow uh runs that
273:06 - generated from the workflow I guess it's
273:09 - going to be like the Run name we have on
273:11 - so specify the trigger of this workflow
273:14 - so on triggers events jobs groups
273:17 - together all the jobs that
273:19 - run then we have steps groups together
273:22 - all the steps that run uh in the check
273:24 - bats version notice we didn't have these
273:27 - before runs on configures the run on the
273:29 - latest version of Ubuntu Linux Runner I
273:32 - imagine you could change this to other
273:33 - things uses the uses keyword specifies
273:35 - the step that will run uh
273:38 - here and of course we found out those
273:41 - are remote repos so that makes sense um
273:45 - and that's pretty much it so so steps
273:47 - jobs on remember those three on jobs and
273:51 - steps
273:52 - okay and that's pretty much it so I'll
273:55 - see you in the next one okay
273:57 - [Music]
274:00 - ciao hey this is Andrew Brown from exam
274:03 - Pro and in this section we'll be going
274:04 - over package management package
274:06 - management refers to a systematic
274:08 - approach to handling the installation
274:10 - upgrade configuration
274:12 - and removal of software packages within
274:14 - a computer system it simplifies the
274:16 - process of managing software
274:18 - applications and their dependencies
274:19 - ensuring consistency and efficiency
274:21 - across the development life cycle and
274:23 - system maintenance core functions and
274:25 - benefits automated handling automates
274:28 - the management of software applications
274:30 - reducing time and effort for
274:31 - installation upgrades and removal
274:34 - consistency across environments ensures
274:36 - uniform software management across
274:38 - various environments boosting efficiency
274:40 - and reliability
274:42 - dependency and configuration management
274:44 - automates management of dependencies and
274:46 - configurations ensuring compatibility
274:48 - and availability for stable performance
274:51 - scalability facilitates software
274:53 - management across multiple systems
274:55 - easing updates and
274:56 - rollbacks he components package a bundle
275:00 - containing software or libraries along
275:02 - with metadata that includes information
275:03 - like version dependencies and
275:05 - configuration details repository a
275:08 - centralized storage location where
275:10 - packages are hosted allowing users to
275:12 - search download and install packages
275:15 - package manager the tool that interfaces
275:17 - with repositories to manage the
275:18 - installation upgrading and removal of
275:20 - packages based on dependencies and
275:22 - version requirements some tools and
275:24 - examples include liux package managers
275:28 - dpkg such as Debian and auntu RPM such
275:31 - as red hat and Fedora language specific
275:34 - managers and PM for JavaScript tip for
275:37 - Python and Maven for Java so that's an
275:41 - overview of package
275:46 - management the next topic will be
275:48 - covering our package feeds at package
275:50 - feed is a repository hosting software
275:52 - packages such as libraries Frameworks
275:55 - modules along with Associated metadata
275:57 - it supports dependency management and
275:59 - various application scenarios through
276:01 - package versioning and organization
276:03 - types of package feeds public feeds
276:06 - hosted by thirdparty providers like
276:08 - net.org and pjs.com and accessible to
276:11 - the broader development Community
276:13 - private feeds internal repositories
276:15 - managed by organizations to store
276:16 - proprietary packages and control team
276:19 - access designing a package feed key
276:22 - considerations storage select from local
276:24 - file systems network attached storage or
276:27 - cloudbased Services organizational
276:29 - structure categorize packages by type
276:32 - purpose or technology versioning
276:34 - Implement a versioning strategy
276:36 - typically semantic versioning AIS
276:38 - control set up authentication and
276:40 - authorization me mechanisms for private
276:42 - feed security implementing a package
276:44 - feed tools and platforms Azure artifacts
276:48 - a fully managed Microsoft Azure service
276:50 - supporting new get npm mavin and python
276:52 - packages it simplifies the creation
276:55 - publication and management of package
276:57 - feeds GitHub packages supports various
277:00 - package formats integrates with GitHub
277:02 - repositories and allows direct package
277:04 - publishing ideal for open source
277:06 - projects package management tools tools
277:08 - like new get npm and mavin that offer
277:11 - capability ities to create in host feeds
277:12 - with command line or ID
277:14 - integration using Upstream sources
277:18 - functionality Upstream sources extend
277:20 - the range of available packages by
277:21 - linking additional feeds whether public
277:24 - private or both in Azure artifacts
277:26 - Upstream sources can include other Azure
277:28 - feeds package Registries or public feeds
277:31 - this ensures that the latest package
277:33 - versions are always available
277:35 - configuration configurable via the Azure
277:38 - devops portal or Azure CLI allowing
277:40 - Azure artifacts to Upstream sources for
277:42 - packages not present locally so that's
277:45 - an overview of package
277:47 - [Music]
277:50 - feeds let's take a look at dependency
277:53 - management dependency management
277:55 - automates the handling of software
277:56 - dependencies to ensure projects run
277:58 - smoothly with all necessary external
278:00 - libraries Frameworks and modules key
278:03 - components dependencies required
278:05 - external software components version
278:08 - specification defines compatible
278:10 - dependency versions dependency graph
278:12 - shows relationships among dependencies
278:15 - package repository Central hub for
278:17 - dependencies dependency resolver
278:19 - automates dependency resolution benefits
278:23 - streamline development automates
278:25 - environment setup by managing
278:26 - dependencies consistent builds ensures
278:29 - uniform dependency versions across all
278:31 - development stages reduce conflicts
278:33 - manages compatibility to prevent
278:35 - software component conflicts efficient
278:38 - upgrades manages dependency versions for
278:40 - easy updates
278:42 - implementation configuration files
278:44 - specify dependencies using files like
278:46 - package.json or pom.xml version locking
278:50 - uses lock files to maintain consistent
278:52 - dependency versions automated tooling
278:54 - tools like npm Maven and pip automate
278:57 - dependency management tasks let's take a
279:00 - look at a comparison between dependency
279:02 - versus package management purpose
279:04 - dependency management ensures
279:05 - compatibility and resolves dependencies
279:08 - while package management handles package
279:10 - life cycle so Fus dependency management
279:12 - targets component compatibility package
279:15 - management manages package storage and
279:17 - life cycle main function dependency
279:19 - management automates resolution package
279:21 - management oversees handling and
279:23 - distribution tools both uspm and mavin
279:26 - dependency management also uses pip
279:28 - while package management incorporates
279:30 - new get in others outcome dependency
279:33 - management maintains functionality
279:35 - package management streamlines processes
279:37 - usage scenario dependency management is
279:40 - essential for external Library Reliance
279:42 - package management is crucial for
279:44 - consistent management so that's an
279:46 - overview of dependency
279:51 - management the next thing we'll be
279:53 - covering is an overview of azure
279:54 - artifact Azure artifacts is a component
279:57 - of azure devop Services focused on
279:59 - package management and collaboration it
280:01 - supports sharing versioning and
280:03 - integrating packages into CI CD
280:05 - workflows some of the features that
280:07 - Azure artifacts provide are package
280:10 - management supports multiple package
280:12 - formats manages new get npm Maven Python
280:15 - and Universal packages all in one place
280:18 - Version Control offers tools for
280:20 - managing package versions and
280:21 - dependencies effectively integration and
280:24 - collaboration cic CD integration
280:26 - integrates with Azure devops pipelines
280:28 - for streamline package creation and
280:30 - deployment shared feeds allows package
280:32 - sharing within teams or the entire
280:34 - organization access control and security
280:37 - access control offers settings to
280:39 - control package access Main maintaining
280:41 - security within projects secure hosting
280:44 - provides a secure environment for
280:45 - hosting and accessing packages getting
280:48 - started with Azure artifacts and Azure
280:51 - subscription is required to use Azure
280:53 - artifacts creating a feed navigate to
280:55 - your Azure devops organization or
280:57 - project select artifacts from the top
281:00 - right menu then create feed enter the
281:02 - required information such as name and
281:04 - visibility options and create the feed
281:07 - after creating a feed you can publish
281:09 - packages like new get mpm and mavic but
281:11 - we'll need to do a few things before
281:13 - that so first we'll need to ensure you
281:15 - have the latest version of the Azure
281:16 - artifacts credential provider installed
281:19 - from the get the tools menu new get
281:21 - configuration file you need to add a net
281:23 - config file to your project in the same
281:25 - folder as your CS project or HL in file
281:28 - the configuration should specify the
281:30 - package source for Azure artifacts like
281:32 - the code shown here this will be
281:34 - provided for you depending on the
281:35 - package you pick publishing command to
281:38 - publish a package provide the package
281:39 - path an API key and the feed URL net.exe
281:43 - push Das Source exam Pro feed API ke a z
281:47 - package path replace package path with
281:49 - the actual path to the package you
281:51 - intend to publish so that's an overview
281:54 - of azure
281:58 - artifacts the next topic we'll be
282:00 - covering is new get and mpm new get is a
282:03 - popular package manager for net
282:05 - applications it allows you to easily
282:07 - manage dependencies and distribute
282:09 - packages within your projects create
282:11 - creating a new get package use the
282:12 - net.exe or net command line tool example
282:16 - using net navigate to your project
282:18 - directory and Run net pac--
282:21 - configuration release this generates a
282:23 - new get package from your project in the
282:25 - release configuration publishing new get
282:28 - packages you can publish to Azure
282:30 - artifacts GitHub packages or host your
282:32 - own new get feed using platforms like
282:34 - Azure devop server my get or pret for
282:36 - private distribution and PM is the
282:39 - default package manager for note. JS and
282:41 - JavaScript applications it provides a
282:44 - vast ecosystem of packages that
282:46 - developers can use within their projects
282:48 - creating an mpm package initialize a new
282:51 - project with npm in it follow the
282:53 - prompts to generate a package. JSO and
282:56 - file that includes your package metadata
282:58 - publishing npm packages to publish to
283:01 - the npm registry ensuring your package
283:03 - is available globally run npm publish
283:06 - this command uploads your package to the
283:08 - npm registry for Public Access so so
283:11 - that's a short and simplified overview
283:12 - of new get and
283:17 - npm the next thing we'll be covering are
283:20 - the main types of versioning versioning
283:22 - in devops refers to the practice of
283:24 - assigning unique versions to code or
283:25 - artifacts to track changes and maintain
283:27 - historical records versioning strategy
283:30 - options semantic versioning detailed
283:32 - structure indicating the nature of
283:34 - changes datebase versioning uses dates
283:37 - offering a chronological timeline of
283:39 - updates sequential version simple
283:41 - incrementation providing clear change
283:43 - order semantic versioning is a widely
283:46 - used method that helps manage changes in
283:48 - software libraries through three version
283:50 - components major minor and Patch major
283:53 - version increases indicate backward and
283:55 - compatible changes minor version
283:57 - increases are for Backward Compatible
283:59 - additions patch version increases apply
284:01 - to Backward Compatible bug fixes
284:03 - guidelines for semantic versioning
284:06 - initial release start with one for
284:08 - stable software major changes increment
284:11 - major version for breaking changes Miner
284:13 - editions increment Miner version for new
284:15 - features that maintain compatibility bug
284:18 - fixes increment patch version for
284:20 - stability improvements without new
284:21 - features or breaking changes datebase
284:24 - versioning uses the format YY yymmdd to
284:28 - reflect release dates offering a clear
284:30 - timeline of updates consistency maintain
284:33 - a standardized date format major changes
284:36 - Mark significant updates in the version
284:37 - name EG 2022 0114 Alpha
284:41 - combination with sver enhanced detail by
284:43 - combining with semantic versioning EG
284:46 - 2022 0114 alpha 1 2 3 sequential
284:51 - versioning assigns a unique sequential
284:53 - number to each version of a pipeline
284:54 - artifact starting with version one each
284:57 - update increments the version number
284:58 - progressively it's straightforward and
285:00 - clearly indicates the chronological
285:02 - order of changes so that's an overview
285:05 - of the main types of versioning
285:07 - [Music]
285:11 - hey this is Andrew Brown from exam Pro
285:13 - and in this section we'll be covering
285:14 - the key considerations when implementing
285:16 - an agency infrastructure designing an
285:18 - implementing an agent infrastructure is
285:20 - crucial for a successful devop solution
285:22 - key considerations include cost tool
285:25 - selection licenses conductivity and
285:27 - maintainability cost considerations
285:30 - Azure pipelines agents hosted by
285:32 - Microsoft cost effective build base on
285:34 - Parallel pipelines self-hosted agents
285:37 - more control but additional costs for
285:39 - Hardware maintenance and scalability
285:41 - tool selection Azure pipelines automates
285:44 - build test and deployment across
285:46 - platforms supports various languages
285:48 - containerization with Docker Visual
285:51 - Studio team Services predecessor of
285:53 - azure devops integrates with Azure
285:55 - pipelines features Source control work
285:57 - item management and project planning
286:00 - licenses Azure pipelines free tier with
286:02 - limited concurrent pipelines and
286:04 - duration paid tier for more scalability
286:07 - self-hosted agents requires licenses for
286:09 - the underlying operating system such as
286:11 - Windows server or Azure VMS connectivity
286:15 - Azure pipelines agents secure internet
286:17 - communication using https fetches source
286:19 - code executes tasks and reports results
286:23 - self-hosted agents network access to
286:25 - resources like Source control
286:26 - repositories artifact feeds and Target
286:28 - environments within your infrastructure
286:31 - maintainability aure pipelines agents
286:33 - automatically updated by Microsoft no
286:36 - manual effort required self-hosted
286:38 - agents regular updates needed for
286:40 - compatibility with guidance provided by
286:42 - Microsoft so that's an overview of
286:45 - implementing an agency
286:50 - infrastructure the next thing we'll be
286:52 - going through are pipeline trigger rules
286:54 - pipeline trigger rules Define conditions
286:56 - under which a pipeline is automatically
286:58 - triggered optimizing resource usage and
287:00 - reducing unnecessary builds and
287:02 - deployments Microsoft devop Solutions
287:05 - offer flexibility in designing custom
287:07 - trigger rules here are key scenarios
287:09 - branch-based trigger trigger a pipeline
287:11 - only when changes are made to a specific
287:13 - Branch this triggers the pipeline for
287:16 - changes in the main branch path-based
287:18 - trigger trigger a pipeline when changes
287:20 - occur within specific file paths this
287:22 - triggers the pipeline for changes in the
287:24 - SRC directory schedule base trigger run
287:27 - pipelines at scheduled intervals
287:29 - regardless of code changes this triggers
287:31 - the pipeline every day at midnight
287:34 - implementing pipeline trigger rules
287:36 - navigate to your project and Azure Dev
287:38 - Ops open the yaml file that defin finds
287:41 - your pipeline locate the trigger section
287:43 - within the yaml file Define the desired
287:46 - trigger rules based on the scenarios
287:47 - above or any custom rule save the yml
287:50 - file benefits of pipeline trigger rules
287:53 - reduce resource consumption minimizes
287:55 - unnecessary usage leading to cost
287:57 - savings and efficient resource
287:59 - utilization improved efficiency ensures
288:02 - actions are performed at the right time
288:03 - streamlining development and deployment
288:05 - processes enhanced control provides
288:08 - developers with control over pipeline
288:10 - execution improving management and
288:11 - coordination of development efforts so
288:14 - that's an overview of pipeline trigger
288:20 - rules the next topic we'll be covering
288:22 - are the types of pipelines classic
288:24 - pipelines provide a graphical interface
288:26 - for creating and configuring pipelines
288:28 - using a drag and drop approach this
288:30 - simplifies defining the stages of your
288:32 - pipeline such as build test and
288:34 - deployment steps to create a classic
288:36 - pipeline widen select pipelines from the
288:39 - left side menu two click new pipeline to
288:42 - start three choose the repository where
288:45 - your source code is located four select
288:48 - a pipeline template based on your
288:49 - application type such as aspn node.js
288:52 - and Java five customize the pipeline
288:56 - stages tasks and configurations add
288:58 - tasks like building the code running
289:00 - tests and deploying the application six
289:03 - save and run the pipeline yl pipelines
289:06 - offer a flexible code Centric approach
289:08 - to defining pipelines pipeline
289:10 - configurations are defined as code in
289:12 - yaml files which can be version
289:14 - controlled along with your source code
289:15 - for easier collaboration and consistency
289:17 - across environments creating a yl
289:20 - pipeline why select the pipelines option
289:23 - from the left side menu to click on the
289:26 - new pipeline button three choose the
289:29 - repository where your source code is
289:30 - located four select the yl option when
289:33 - prompted to choose the pipeline
289:35 - configuration style five create a yl
289:38 - file in your repository to Define your
289:40 - pipeline configuration the yaml file
289:43 - should contain stages jobs and tasks for
289:45 - your requirements for example as shown
289:47 - on the image on the right six save the
289:50 - yl file in your repository and commit
289:52 - the changes seven Azure devops will
289:55 - automatically detect the yaml file and
289:57 - create the pipeline base on the
289:59 - configuration defined in the yaml file
290:02 - pay to save and run the pipeline to see
290:03 - it in action so that's an overview of
290:06 - the types of Pipelines
290:08 - [Music]
290:12 - the failure rate of your pipeline
290:13 - indicates the number of failed builds or
290:15 - deployments over a specific period
290:17 - monitoring the failure rate helps you
290:18 - identify potential bottlenecks or issues
290:20 - in your pipeline Azure monitor can be
290:22 - used for this purpose Azure monitor
290:25 - provides comprehensive monitoring for
290:27 - Azure resources including pipelines it
290:29 - collects data on Pipeline failures and
290:31 - allows you to set up alerts based on
290:33 - specific failure thresholds these alerts
290:35 - help you address issues proactively
290:37 - maintaining pipeline Health
290:39 - configuration enable metrics and
290:41 - diagnostic logs metrics include success
290:43 - rate average duration and failure rate
290:46 - diagnostic logs capture detailed
290:48 - information about pipeline runs
290:50 - including errors and warnings here's an
290:52 - example of how you can enable Azure
290:54 - monitor for a
290:56 - pipeline duration monitoring monitoring
290:59 - the duration of your pipeline is crucial
291:01 - longer durations indicate performance
291:03 - issues that can impact overall
291:04 - efficiency Azure Dev Ops provides
291:06 - built-in capabilities for this Azure
291:09 - pipelines allows tracking the duration
291:10 - of individual pipeline runs identifying
291:13 - outliers and analyzing performance
291:14 - Trends over time use the Azure
291:17 - pipeline's rest API to retrieve the
291:18 - duration of pipeline runs custom scripts
291:21 - or Powershell can automate monitoring
291:23 - and Reporting here's an example of how
291:26 - you can retrieve the duration of
291:27 - pipeline runs using the Azure pipeline's
291:29 - rest
291:30 - API flaky tests monitoring flaky tests
291:33 - producing consistent results leading to
291:35 - false positives or false negatives
291:37 - monitoring and addressing flaky tests is
291:39 - essential for pipel
291:41 - reliability Azure Dev op supports
291:43 - various test Frameworks and provides
291:45 - tools to detect and monitor flaky tests
291:47 - Azure test plans can manage test cases
291:49 - track executions and identify flaky
291:52 - tests group test cases and test Suites
291:55 - schedule test runs and capture results
291:58 - analyze results to identify and Mark
292:00 - flaky tests built in reporting
292:02 - visualizes Trends and tracks
292:04 - improvements over time here is an
292:06 - example of how you can Mark a test case
292:08 - as flaky using Azure test plans
292:11 - so that's an overview of monitoring
292:13 - pipeline Health using various
292:15 - [Music]
292:18 - methods hey this is Andrew Brown from
292:21 - exampro and in this section we'll be
292:23 - covering Azure container instances Azure
292:25 - container instances allow you to launch
292:27 - containers without the need to worry
292:29 - about configuring or managing the
292:30 - underlying virtual machine Azure
292:32 - container instances is designed for
292:34 - isolated containers they are tailored
292:36 - for simple applications task Automation
292:38 - and tasks like build jobs containers can
292:41 - be provisioned within seconds whereas
292:43 - VMS can take several minutes containers
292:45 - are built per second whereas VMS are
292:47 - buil per hour providing potential cost
292:49 - savings containers have granular and
292:51 - custom sizing of vcpus memory and gpus
292:55 - whereas VM sizes are predetermined ACI
292:58 - can deploy both windows and Linux
292:59 - containers you can persist storage with
293:01 - Azure files for your ACI containers once
293:04 - deployed aciis are accessible via a
293:06 - fully qualified domain name like custom
293:08 - label. aure region . aure
293:11 - container. Azure provides quick start
293:13 - images to start launching example
293:15 - applications but you can also Source
293:17 - containers from Azure container registry
293:19 - Docker Hub or even privately hosted
293:21 - container
293:22 - registry container groups are collection
293:25 - of containers that get scheduled on the
293:26 - same host machine the containers in a
293:29 - container group share life cycle
293:31 - resources local network and storage
293:33 - volumes container groups are similar to
293:35 - a kubernetes pod multi-container groups
293:38 - currently support only Linux containers
293:41 - there are two ways to deploy a
293:42 - multi-container group to deploy a
293:44 - multi-container group you can use either
293:46 - a resource manager template if deploying
293:48 - additional Azure service resources or a
293:50 - yaml file for deployments involving only
293:52 - container instances overall Azure
293:55 - container instances simplify container
293:57 - deployment and scaling removing the
293:59 - complexities of infrastructure
294:05 - management the next topic we'll be going
294:07 - over our container restart policies a
294:10 - container restart policy specifies what
294:12 - a container should do when their process
294:13 - has completed these policies ensure that
294:16 - the container instances can handle
294:17 - different scenarios effectively based on
294:19 - the specific requirements of the
294:21 - application or task Azure container
294:23 - instances has three restart policy
294:25 - options always this policy ensures that
294:28 - the containers restart continuously
294:30 - regardless of whether they exit
294:31 - successfully or not it's useful for
294:33 - applications that need to be constantly
294:35 - available such as web servers never with
294:38 - this policy containers do not restart
294:40 - once they've completed their execution
294:42 - this is ideal for tasks that are
294:44 - designed to run once and then terminate
294:46 - such as batch jobs or scheduled tasks on
294:49 - failure containers will only restart if
294:51 - they stop due to an error or unexpected
294:53 - termination this ensures that if a
294:55 - container crashes or faces an unexpected
294:57 - error it will try to restart and
294:58 - continue its operations overall choosing
295:01 - the appropriate restart policy is vital
295:03 - for the stability and responsiveness of
295:05 - your applications
295:07 - [Music]
295:11 - the next topic we'll be covering our
295:13 - container environment variables
295:15 - environment variables are key value
295:17 - pairs that can be used to configure and
295:18 - manage the behavior of applications
295:20 - running inside containers environment
295:23 - variables allow you to pass
295:24 - configuration details to your containers
295:26 - which can be critical in guiding
295:27 - applications on how to connect to
295:29 - databases where to find certain
295:31 - resources or how to adjust their
295:32 - behavior based on the environment
295:33 - they're running in in Azure you can
295:36 - easily set up these environment
295:37 - variables for your containers using the
295:39 - Azure portal
295:40 - or poers shell secured environment
295:43 - variables by default environment
295:45 - variables are stored in plain text to
295:47 - address this Azure offers the option to
295:49 - secure your environment variables
295:51 - instead of storing them in plain text
295:53 - which could expose sensitive information
295:54 - if breached you can Leverage The secure
295:56 - environment variables flag so that's a
295:59 - quick overview of container environment
296:05 - variables the next topic we'll be
296:07 - covering is container troubleshooting
296:10 - troubleshooting containers in Azure
296:11 - involves a series of commands that help
296:13 - diagnose and resolve issues as container
296:16 - logs this command lets you fetch logs
296:18 - from your container these logs can
296:20 - provide insights into application
296:21 - behavior and possible errors as
296:23 - container attach if you need diagnostic
296:26 - data during container startup use this
296:28 - command it helps in understanding issues
296:30 - that might arise during the
296:31 - initialization phase of a container as
296:33 - container exec for a deeper dive into
296:35 - the Container this command starts an
296:37 - interactive session this is useful for
296:39 - live debugging and to inspect the
296:41 - container's current state as monitor
296:43 - metrics list this command gives you
296:45 - metrics related to your container such
296:47 - as CPU usage which can be essential for
296:49 - performance tuning or identifying bottle
296:51 - X so these are the commonly used
296:53 - commands for container
296:56 - [Music]
296:59 - troubleshooting hey this is Andrew Brown
297:01 - from exam Pro and we're going to take a
297:03 - look at Azure container instances so
297:05 - here it is so all we got to do is go to
297:07 - container instances we'll hit add and
297:09 - the nice thing is that Azure provides us
297:11 - with a Hello World one so it's very easy
297:13 - for us to get started um it's a Linux
297:15 - machine and it looks like it's pretty
297:18 - inexpensive there so we'll stick with
297:20 - that I'm going to create a new group
297:21 - here we're going to call it banana um
297:25 - and we'll name the container instance
297:27 - banana and East Us 2 seems fine to me
297:31 - you'll notice we're on a quick start
297:32 - image if we wanted we could use
297:34 - something from the docker Hub and
297:36 - provide our own link but we'll just
297:37 - stick with the quick uh start image for
297:39 - today okay we're going to go ahead and
297:42 - hit next to networking just to see what
297:44 - we have as options you can make it
297:46 - public or private we'll go to Advanced
297:49 - hold on here yep those are just the
297:50 - ports you can expose we'll go to advance
297:53 - and for the restart policy we can set on
297:55 - failure always or never we can pass in
297:57 - environment variables and I covered this
298:00 - a lot more in detail in the lecture
298:02 - content so we don't need to really dive
298:04 - deep into this um and we'll go ahead and
298:06 - create this
298:08 - instance and so we'll have to wait a
298:11 - little while here and I'll see you back
298:12 - in a moment okay and so after a short
298:14 - wait our container instance is ready
298:16 - we'll go to that resource there and take
298:19 - a look around so on the left hand side
298:21 - we can go to our containers and there we
298:23 - can see it running we can see the events
298:25 - down below of what's going on so you can
298:27 - see that it's pulled the image it
298:30 - successfully pulled it and it started
298:32 - the
298:33 - container some properties nothing
298:35 - interesting there the logs if we wanted
298:36 - to see stuff and if we wanted to connect
298:38 - to the instance we could also go here
298:40 - and hit connect which is kind of nice um
298:42 - I don't have any purpose to do that
298:44 - right now so and it's also not going to
298:46 - work the way we're doing it but I just
298:47 - wanted to show you you had those
298:49 - opportunities uh you can do identity so
298:52 - that means manage it with ro base access
298:54 - controls but what I want to see is
298:56 - actually this uh hello world working I'm
298:58 - assuming that must be a a hello page
299:01 - I've never looked at it before so we're
299:02 - going to go here grab the public IP
299:04 - address and paste it on in the top and
299:07 - there we go so we have deployed a
299:09 - instance onto Azure container instances
299:12 - or a container I should say so nothing
299:15 - super exciting to talk about here um but
299:17 - we do need to know the basics uh there
299:20 - um if we wanted to deploy other
299:22 - containers it's just the one there so
299:25 - that's all you really need to do um but
299:27 - yeah so yeah hopefully that uh gives you
299:30 - an idea there I'll just go back to the
299:31 - list here so we can see it and we'll go
299:33 - ahead and just uh delete that probably
299:35 - do it for the vi the resources on the
299:37 - left hand side like I always like to do
299:40 - uh and we will go into banana
299:42 - here and we will delete banana and there
299:46 - you
299:52 - go self-hosted agents and Azure devops
299:55 - allow you to customize the agent
299:56 - environment to meet specific needs
299:58 - unlike Microsoft hosted agents
300:00 - self-hosted agents run on your
300:02 - infrastructure giving you more control
300:03 - over the environment and the tools
300:05 - installed on the agents use cases custom
300:08 - environments for specialized soft
300:09 - software or configurations not available
300:11 - in Microsoft hosted agents sensitive
300:14 - data suitable for projects with
300:16 - stringent data security requirements
300:18 - keeping data within your network
300:20 - resource intensive builds useful when
300:21 - builds require significant computational
300:24 - resources or specific Hardware setups
300:26 - benefits customization tailor the
300:28 - environment to specific project needs
300:31 - cost efficiency reduce costs by
300:33 - utilizing existing infrastructure
300:35 - consistent configurations ensure
300:37 - consistent setups across agents through
300:39 - templates or contain anization
300:41 - scalability Scale based on workload by
300:43 - provisioning new agents configuring
300:45 - self-hosted agents with VM templates
300:48 - create a virtual machine with the
300:49 - necessary agent software save it as a
300:51 - template and use the template to
300:53 - provision additional agents for
300:54 - consistent and simplified scaling create
300:57 - and configure a VM set up a virtual
300:59 - machine with the necessary operating
301:00 - system and dependencies install and
301:03 - configure the Azure devops agent
301:04 - software create a VM template capture
301:07 - the VM as a template including the agent
301:09 - software at its configuration provision
301:12 - new agents use the template to quickly
301:13 - provision new agents ensuring each new
301:15 - VM has the same configuration and is
301:17 - ready to connect to Azure Dev Ops
301:20 - managing self-hosted agents with
301:22 - containerization containerization
301:24 - involves creating Docker images that
301:26 - include the necessary agent software and
301:28 - dependencies offering a flexible and
301:29 - scalable solution for managing
301:31 - self-hosted agents create a container
301:34 - image develop a Docker image with the
301:36 - required agent software and dependencies
301:38 - including configuration detail
301:40 - push to a container registry store the
301:42 - container image in a registry like Azure
301:44 - container registry or Docker Hub deploy
301:46 - and scale containers use container
301:48 - orchestration tools to deploy and manage
301:50 - agent containers scaling up or down
301:52 - based on workload demands so that's an
301:55 - overview of self-hosted
301:57 - [Music]
302:00 - Agents hey this is Andrew Brown from
302:03 - exam Pro and in this section we'll be
302:04 - covering the types of deployment
302:06 - strategies a successful deployment
302:08 - strategy is crucial for efficent
302:10 - software delivery and minimizing user
302:12 - impact Microsoft devop Solutions offers
302:14 - various deployment patterns and
302:16 - strategies for continuous delivery and
302:18 - high availability blue green deployment
302:20 - is a technique that reduces risk in
302:22 - downtime by running two identical
302:23 - environments these environments are
302:25 - called blue and green only one of the
302:28 - environments is live with the live
302:29 - environment serving all production
302:31 - traffic in blue green deployment blue is
302:34 - live and green is set up for the new
302:35 - release deploy and test the new version
302:37 - in green without affecting blue after
302:40 - testing switch traffic to Green making
302:42 - it live this minimizes downtime and
302:44 - allows for quick roll back to Blue if
302:46 - issues arise enhancing reliability and
302:48 - user experience so that's an overview of
302:51 - blue green
302:52 - [Music]
302:55 - deployment a canary release is a
302:58 - strategy where a new version is deployed
302:59 - to a small subset of users or
303:01 - infrastructure first this helps identify
303:04 - unforeseen issues under real conditions
303:05 - with limited impact by monitoring the
303:08 - initial deployments performance teams
303:10 - can decide whether to expand halt or
303:12 - roll back the update based on real world
303:14 - feedback this phase approach ensures a
303:16 - safer and more controlled rollout
303:18 - minimizing risks associated with new
303:20 - releases to execute a canary release
303:22 - feature toggles selective feature
303:25 - activation traffic routing manage user
303:27 - access to the new version deployment
303:29 - slots version management these
303:32 - techniques enable a gradual and
303:33 - monitored roll out allowing for
303:35 - adjustments based on user feedback and
303:37 - system performance this method enhances
303:39 - application stability and user
303:41 - experience by addressing potential
303:42 - issues before a full scale deployment so
303:45 - that's an overview of canary
303:50 - release ring deployment is a strategy
303:53 - where users or infrastructure components
303:54 - are divided into multiple groups called
303:56 - Rings each ring receives updates
303:58 - sequentially starting with the smallest
304:00 - group and gradually expanding to the
304:02 - entire user base this allows for
304:04 - iterative releases starting with an
304:06 - internal ring and progressively reaching
304:07 - a wider audience this controlled roll
304:09 - out facilitates early feedback from
304:11 - different user groups or components for
304:14 - example in a three-group production
304:15 - setup canaries voluntarily Test new
304:18 - features as soon as they are available
304:20 - early adopters voluntarily preview
304:22 - releases which are more refined than
304:24 - Canary versions users receive the final
304:27 - product after it has passed through
304:28 - canaries and early adopters this
304:31 - approach ensures a safer step-by-step
304:33 - roll out of new features or updates so
304:35 - that's the ring deployment strategy
304:38 - [Music]
304:42 - Progressive exposure is a deployment
304:43 - technique that gradually increases the
304:45 - number of users exposed to a new release
304:48 - initially a small percentage of user
304:50 - traffic is directed to the new release
304:51 - while its performance and behavior are
304:53 - monitored if the new release performs
304:55 - well without issues the traffic is
304:57 - gradually increased this approach helps
304:59 - identify potential issues early and
305:01 - minimizes user impact if problems arise
305:04 - continuous integration toe checkin
305:06 - developers check in code auto trigger CF
305:09 - pipeline triggers automatically build
305:11 - artifact code is built generating an
305:14 - artifact continuous deployment build
305:16 - version one approved and deployed to
305:18 - ring one for initial testing build
305:20 - version two approved and deployed to
305:22 - ring two for early adopters build
305:24 - version three approved and deployed to
305:26 - ring three production environment ring
305:29 - one Canary's Test new features Ring 2
305:32 - early adopter preview refined releases
305:35 - ring three all users receive the final
305:37 - product so that's the progressive
305:39 - exposure deployment
305:45 - strategy feature flags are conditional
305:47 - statements that let you control which
305:49 - features or functions are visible and
305:50 - available in your application using
305:53 - feature Flags you can enable or disable
305:55 - features dynamically without redeploying
305:57 - the application this allows for testing
305:59 - new features gradual rollouts or quick
306:01 - deactivation if issues arise feature
306:03 - Flags also offer the flexibility to
306:05 - Target specific user groups for testing
306:07 - or rolling out features new feature a
306:10 - new feature is introduced feature Flags
306:12 - toggle switches control the visibility
306:14 - of the feature enabled the feature is
306:17 - enabled for specific customer groups
306:19 - disabled the feature remains off for
306:21 - other customer groups customers
306:23 - different customer groups experience the
306:25 - feature base on the feature flag
306:27 - settings this allows control targeted
306:29 - rollouts and quick adjustments of
306:31 - feature availability without
306:32 - redeployment so that's an overview of
306:34 - the feature flag deployment strategy
306:37 - [Music]
306:41 - a b testing is a method to compare two
306:43 - versions of a feature or user interface
306:45 - to see which one performs better users
306:47 - are divided into two or more groups each
306:49 - group experiencing a different version
306:51 - data on user Behavior engagement and
306:53 - other metrics are collected this
306:55 - approach helps make data driven
306:56 - decisions and optimize feature usability
306:59 - before a full roll out to all users user
307:01 - groups users are divided into two groups
307:04 - version a and version B each group is
307:06 - shown a different version of a feature
307:07 - or user interface for performance
307:09 - comparison user behavior and performance
307:12 - metrics are collected and compared
307:14 - results the graph shows which version
307:16 - performs better based on the collected
307:17 - data this helps in making informed
307:19 - decisions about which version to
307:21 - implement for all users so that's an
307:23 - overview of a b
307:28 - testing Azure traffic manager operates
307:31 - at the DNS layer to quickly and
307:32 - efficiently direct incoming DNS requests
307:35 - based on the routing method of your
307:36 - choice routing methods performance rote
307:39 - traffic to nearby servers to reduce
307:41 - latency weighted distribute traffic
307:43 - based on predefined weights priority
307:46 - route to a primary in point with fail
307:48 - over to backups if needed Geographic
307:50 - Route traffic base on the user's
307:52 - location multivalue return multiple
307:54 - healthy in points and DNS responses
307:57 - subnet route based on the user's IP
307:59 - address uses latency reduction route to
308:02 - nearby servers to minimize latency
308:05 - failover switch traffic to backups if
308:07 - the primary system fails a B testing
308:10 - Route traffic to random VMS for testing
308:13 - in this scenario we have an example of
308:15 - weighted routing where traffic is split
308:16 - 80% to production and 20% to Beta
308:19 - environments so that's a quick overview
308:21 - of azure traffic
308:23 - [Music]
308:26 - manager hey this is Andrew Brown from
308:29 - exampro and in this section we'll be
308:31 - covering Azure app service Azure app
308:33 - service is an HTTP based platform for
308:36 - web apps re estall apis and mobile bin
308:39 - services is you can choose your
308:40 - programming language in Python Java or
308:42 - any other language and run it in either
308:44 - a Windows or Linux environment it is a
308:47 - platform is service so it's the Heroku
308:49 - equivalent for Azure Azure app service
308:51 - takes care of the following underlying
308:53 - infrastructure OS and language security
308:55 - patches load balancing Auto scaling and
308:58 - infrastructure management Azure app
309:00 - service makes it easy to implement
309:02 - common Integrations and features such as
309:04 - Azure Dev Ops for deployments GitHub and
309:06 - dockerhub package Management Systems
309:08 - easy to set up staging environments
309:10 - custom domains and attaching TLS or SSL
309:13 - certificates you pay based on an Azure
309:15 - app service plan shared tier includes
309:18 - free and shared options litex isn't
309:20 - supported here dedicated tier includes
309:22 - basic standard premium premium to
309:25 - premium 3 and there's isolated tier as
309:28 - your app service is versatile you can
309:30 - deploy single or multi-container Docker
309:33 - applications when you create your app
309:35 - you have to choose a unique name since
309:36 - it becomes a fully qualified domain
309:39 - overall Azure app service simplifies
309:41 - your web hosting needs ensuring you can
309:43 - focus on coding and let Azure do the
309:44 - heavy
309:49 - lifting let's delve into runtimes and
309:52 - Azure app service so what is a runtime
309:54 - environment a runtime environment refers
309:57 - to the software and settings needed for
309:58 - a program to run in a defined way at
310:00 - runtime a runtime generally means what
310:03 - programming language and libraries and
310:04 - framework you are using a runtime for
310:07 - Azure app services will be a predefined
310:09 - container that has your programming
310:10 - language and commonly Ed library for
310:12 - that language installed with Azure app
310:15 - Services you're presented with a range
310:16 - of run times to choose from including
310:19 - net. net core Java Ruby node.js PHP and
310:22 - python moreover Azure app Services
310:25 - generally supports multiple versions of
310:27 - each programming language for example
310:29 - for Ruby you might find versions 2.6 and
310:32 - 2.7 it's worth noting that cloud
310:34 - providers including Azure May phase out
310:37 - support for older versions over time
310:39 - this not only ensures that they're
310:40 - offering the latest and most efficient
310:42 - tools but also promotes better security
310:44 - practices among users pushing them to
310:46 - keep up with the latest patches so
310:48 - that's an overview of runtimes and Azure
310:50 - app
310:55 - service the next thing we'll be covering
310:57 - are custom containers and Azure app
310:58 - service Azure app service gives you the
311:01 - flexibility to use custom containers for
311:03 - both windows and Linux the primary
311:05 - reason you might opt for a custom
311:07 - container is to use a distinct runtime
311:08 - that is natively supported or to
311:10 - incorporate specific packages and
311:12 - software here's a straightforward
311:14 - process to get started with custom
311:16 - containers in Azure app service design
311:18 - your container Begin by creating a
311:20 - Docker container tailored to your needs
311:22 - on your local machine push to Azure once
311:24 - your container is ready push it to the
311:26 - Azure container registry this
311:28 - centralized repository ensures that your
311:30 - container is easily accessible within
311:31 - Azure deploy and go live finally deploy
311:35 - your container image directly to the
311:36 - Azure app service once deployed Azure
311:38 - takes care care of scaling maintenance
311:40 - and updates another advantage of custom
311:43 - containers in Azure app service is that
311:45 - they offer more granular control over
311:46 - your environment you can fine-tune
311:48 - performance security and other aspects
311:50 - of your application environment to suit
311:52 - your
311:56 - needs the next topic will be covering
311:59 - our deployment slots in Azure app
312:01 - service deployment slots allow you to
312:03 - create different environments of your
312:04 - web application Associated to a
312:06 - different host name this is useful when
312:08 - you require testing staging or QA
312:10 - environment alongside your production
312:12 - setup deployment slots let you swiftly
312:15 - replicate your production setting for
312:16 - various purposes ensuring consistent
312:18 - testing environments you can also swap
312:21 - environments this is useful for
312:23 - executing blue green deployments by
312:25 - using swap you can promote your staging
312:27 - environment to production with these you
312:30 - can promote our staging to production by
312:31 - swapping if something goes wrong you
312:33 - could swap them back this capability
312:35 - ensures minimal downtime and enhances
312:37 - the user experience since you can
312:38 - introduce changes in a controlled manner
312:40 - rolling them back if necessary in
312:43 - addition Azure ensures that when
312:44 - swapping the instances are warmed up
312:46 - before traffic is routed resulting in
312:48 - zero downtime so that's a quick overview
312:51 - of deployment
312:56 - slots the next topic we'll be covering
312:58 - is the app service environment in Azure
313:00 - app Service app service environment is
313:03 - an Azure app service feature that
313:04 - provides a fully isolated and dedicated
313:06 - environment for securely running app
313:08 - Service app apps at high scale this
313:10 - allow you to host windows and Linux web
313:12 - apps Docker containers mobile apps and
313:15 - functions app service environments are
313:17 - appropriate for application workloads
313:19 - that require very high scale isolation
313:21 - and secure network access and high
313:23 - memory utilization customers can create
313:26 - multiple ases within a single Azure
313:28 - region or across multiple Azure regions
313:30 - making ases ideal for horizontally
313:32 - scaling stateless application tiers in
313:34 - support of high requests per second
313:36 - workloads as's comes with its own
313:38 - pricing tier called the isolated tier
313:40 - ases can be used to configure security
313:43 - architecture apps running on ases can
313:45 - have their access gated by Upstream
313:47 - devices such as web application
313:49 - firewalls app service environments can
313:51 - be deployed into availability zones
313:53 - using Zone pinning there are two
313:55 - deployment types for an app service
313:56 - environment external ass and
313:59 - ilbs external ass exposes the ass hosted
314:02 - apps on an internet accessible IP
314:04 - address if the v-net is connected to
314:06 - your on premises Network apps and your
314:08 - ass also have access to resources there
314:10 - without additional configuration because
314:13 - the ass is within the v-net it can also
314:15 - access resources within the v-net
314:16 - without any additional
314:18 - configuration ilbs exposes the ass
314:21 - hosted apps on an IP address inside your
314:23 - v-net the internal and point is an
314:25 - internal load balancer so that's an
314:27 - overview of app service environment and
314:29 - Azure app
314:34 - service the next thing we'll be going
314:36 - over is deployment in Azure app service
314:39 - so what is deployment well it's the
314:41 - action of pushing changes or updates
314:42 - from a local environment or repository
314:44 - into a remote environment Azure app
314:47 - Services provides many ways to deploy
314:49 - your applications including run from
314:51 - package deploy zip reward deploy VI FTP
314:54 - deploy via Cloud sync such as Dropbox or
314:56 - one drive deploy continuously with
314:58 - GitHub bitbucket and Azure repos which
315:01 - using kudu and Azure pipelines deploy
315:03 - using a custom container CI CD pipeline
315:06 - deploy from local git deploy using
315:07 - GitHub actions deploy using GitHub
315:10 - actions containers and deploy with
315:12 - template run from a package is when the
315:14 - files in the package are not copied to
315:16 - the WW root directory instead the zip
315:19 - package itself gets mounted directly as
315:20 - the re only ww root directory all other
315:23 - deployment methods and app service have
315:25 - deployed to the following directory for
315:27 - Windows deol we use back slashes home
315:30 - site ww root for Linux we use for/ home
315:34 - site ww rout since the same directory is
315:37 - used by your app at runtime it's
315:39 - possible for deployment to fail because
315:41 - of file lock conflicts and for the app
315:43 - to behave unpredictably because some of
315:44 - the files are not yet
315:46 - updated zip and War file deployment uses
315:49 - the same kudu service that powers
315:50 - continuous integration based deployments
315:53 - kudu is the engine behind get
315:54 - deployments in Azure app service it's an
315:57 - open-source project that can also read
315:58 - outside of azure kudu supports the
316:01 - following functionality for zip file
316:03 - deployment deletion of files left over
316:05 - from a previous deployment option deter
316:07 - on the default build process process
316:09 - which includes package restore
316:11 - deployment customization including
316:12 - running deployment scripts deployment
316:14 - logs and a file size limit of 2,48
316:18 - megabytes you can deploy using Azure CLI
316:21 - Azure API via rest and Azure
316:23 - portal you can use file transfer
316:25 - protocol to upload files you will need
316:27 - your own FTP client you just drag and
316:30 - upload your files go to the deployment
316:32 - Center get the FTP credentials for your
316:35 - FTP client you can use Dropbox for one
316:38 - drive to deploy using a Cloud sync
316:40 - Dropbox is a third-party cloud storage
316:42 - service one drive is Microsoft's cloud
316:45 - storage service you go to deployment
316:47 - Center configure for Dropbox or one
316:49 - drive when you turn on sync it will
316:51 - create a folder in your Dropbox Cloud
316:53 - Drive one drive apps Azure web apps
316:56 - Dropbox apps Azure this will sync with
316:59 - your home site ww root so you just
317:02 - update files in that folder in summary
317:04 - Azure app service offers a range of
317:06 - deployment methods ensuring flexibility
317:08 - and easy for
317:13 - developers the next thing we'll be
317:15 - covering is the Azure app service plan
317:18 - Azure app service plan determines the
317:19 - region of the physical server where your
317:21 - web application will be hosted and
317:23 - defines the amount of storage RAM and
317:25 - CPU your application will use it offers
317:27 - several pricing tiers shareed tiers
317:30 - there are two shared tiers free and
317:32 - shared free tier provides this tier
317:34 - offers 1 gab of disk space supports up
317:36 - to 10 apps on a single shared instance
317:39 - provides no availability SLA and allows
317:41 - each app to compute quot of 60 minutes
317:43 - per day share tier provides hosting
317:46 - multiple apps up to 100 on a single
317:48 - shared instance no availability SLA is
317:50 - offered and each app gets a compute
317:52 - quote of 240 minutes per day it's worth
317:55 - noting that Linux based instances are
317:57 - supported in this
317:58 - tier dedicated tiers basic standard
318:01 - premium premium 2 Premium 3 basic offers
318:05 - more disk space unlimited apps three
318:07 - levels in this tier that offer varying
318:09 - amounts of compute power memory and disc
318:11 - storage standard allows scaling out to
318:14 - three dedicated instances guarantees
318:17 - 99.95% availability and also has three
318:20 - levels with varying resources premium
318:23 - provides the ability to scale up to 10
318:25 - dedicated instances and ensures
318:27 - 99.95% availability and it includes
318:30 - multiple Hardware level
318:32 - options isolated tier dedicated Azure
318:35 - virtual Network full Network and compute
318:37 - isolation scale to 100 instances and
318:40 - availability SLA of
318:43 - 99.95% so the Azure app service plan
318:46 - lets you tailor your hosting environment
318:47 - and budget to fit your application
318:51 - [Music]
318:54 - needs hey this is angrew Brown from exam
318:56 - Pro and we are going to be learning
318:58 - about Azure app services in this follow
319:00 - along uh and it's a service that's
319:02 - supposed to make it easy for you to
319:03 - deploy web applications I say supposed
319:05 - to because it really depends on your
319:07 - stack Azure has more synergies with
319:09 - other stacks and others so like if
319:11 - you're like me and you like Ruby on
319:13 - Rails you're going to find a lot of
319:14 - friction with rails and Linux but if
319:16 - you're using something like Windows
319:18 - servers or python orn net you're going
319:21 - to have a much easier time still really
319:22 - great service just wish they'd make it a
319:24 - bit more broad there but let's hop into
319:26 - it so before we can go use that service
319:28 - let's make sure that it's activated and
319:31 - so we'll go over here and we'll go to
319:34 - Azure subscription and then down below
319:36 - we're going to go to Resource provider
319:37 - now you think what you could do is just
319:40 - type in app Services uh and you'd be
319:42 - wrong because the the service is under a
319:45 - particular provider if you want to
319:47 - figure out what provider it is we can go
319:49 - um Azure resource
319:52 - providers and they have a page on
319:54 - documentation here that lists them all
319:57 - so if I search for Azure app
320:00 - Services it's under web and domain
320:02 - registration so we're going to make sure
320:04 - this is registered if we're using a
320:05 - custom domain which we are not today we
320:08 - need this one activated so going back
320:11 - here I will type in web and you can see
320:13 - it's registered so if yours is not
320:15 - registered go ahead and hit that I
320:17 - believe this by default is generally
320:19 - registered with new Azure accounts so I
320:22 - don't think that is an issue for you but
320:24 - we'll go back up here close these
320:26 - additional tabs and we will type in
320:27 - Azure app
320:30 - services and we will look for that
320:32 - service so there it is and we'll go
320:34 - ahead and hit
320:35 - add um and so I'm going to give it a new
320:38 - name I just made it a moment ago but I'm
320:41 - going to try again and try to use the
320:42 - same name so we're going to call this
320:46 - Voyager Great and then I'm going to go
320:48 - ahead and name this Voyager and I
320:50 - already know that that is taken so I'm
320:51 - going to type in Delta
320:53 - Flyer and these are fully qualified
320:56 - domains so they are unique with Azure
320:57 - app Services you can run a Docker
320:59 - container we're doing code this time
321:01 - around and what I like to use is a ruby
321:04 - um but again you know if I want to use
321:06 - the cicd I'm not going to be able to the
321:08 - deployment center with Ruby so that is
321:10 - not possible um and so we're going to go
321:12 - with python and run either a flask or
321:14 - ajango app I haven't decided yet I am in
321:17 - Canada so let's go to Canada east and uh
321:21 - down below here we have the plans
321:23 - generally the plans will tell you the
321:25 - cost underneath look you'll notice that
321:26 - it's loading but I just want to show you
321:28 - that there are some discrepancies in
321:30 - terms of pricing so if I was to go to
321:32 - Azure app Services
321:35 - pricing and we were to pull this up here
321:38 - we can kind of see the pricing
321:40 - here okay and if we scroll on down right
321:43 - now we're looking at a premium V2 uh and
321:47 - oh no I don't need help I'm okay you'll
321:49 - notice that it's 20 cents per hour so if
321:51 - I go here and do that times 730 because
321:54 - there's 730 hours in the year that's
321:57 - $146 I believe this is showing me in USD
322:00 - dollar yeah and in here it's showing me
322:04 - 103 Canadian which is lower um so it
322:08 - could be that because I'm running in a
322:09 - Canada east region it's the price is
322:12 - different but you could imagine that if
322:14 - I had this at this cost at uh what did
322:17 - we say here um at 146
322:21 - USD to CAD I'd actually be paying
322:25 - $182 so you got to watch out for that
322:27 - kind of stuff but I'm pretty sure this
322:29 - is what the cost is so just be aware
322:31 - that if you look stuff up in here it's
322:33 - not necessarily reflective so you got to
322:35 - do a little bit more work to figure that
322:36 - out uh if we wanted to go here uh we
322:39 - cannot choose the free tier when we're
322:40 - using Linux if we're using Windows I
322:42 - believe we can use it we're working with
322:44 - Linux today so that's just how it's
322:45 - going to be um for the B1 this is
322:48 - totally fine but we want to utilize
322:50 - deployment slots deployment slots is an
322:52 - advanced feature of uh the production
322:54 - version and that's the only way we're
322:56 - going to be able to use it here this is
322:57 - 20 cents per hour again so I don't want
323:00 - to be doing this for too long but I
323:02 - think what we'll do is before we do that
323:04 - we can just do an upgrade to Dev to prod
323:06 - so we can experience that I'm going to
323:08 - go and just choose B1 okay so go next um
323:13 - we do not need any application insights
323:15 - for the time being and it will not let
323:17 - us so it's okay we'll go next review and
323:21 - create and we'll go ahead and create
323:23 - this resource here and I will see you
323:26 - back when this is done so um our
323:30 - resource Now set up we'll go to Resource
323:32 - and now that we're in here you'll notice
323:34 - if we hit browse we're not going to see
323:36 - anything because we do not have anything
323:38 - deployed which makes sense right uh so
323:40 - we're going to actually have to go ahead
323:41 - and deploy something so we are going to
323:43 - make our way over to the deployment
323:46 - Center and uh it's just going to tell us
323:48 - that we have yet to configure anything
323:49 - and that's totally fine we're going to
323:51 - go to
323:52 - settings it'll give it a moment and so
323:55 - the thing is is that we're going to need
323:57 - something to deploy um I did not create
323:59 - an app but the great thing uh is in the
324:02 - Azure documentation they have a bunch of
324:04 - quick starts here all right and
324:06 - apparently they have one for Ruby as
324:07 - well but today we are looking at python
324:10 - uh and so they actually have an example
324:13 - repository for us here which is
324:16 - github.com asure samples python docs
324:19 - hello world and I mean I could go make a
324:21 - repo for you but we might as well just
324:22 - use the one that is already provided to
324:24 - us so I'm just going to pull this up to
324:27 - show you what's in it it's a very very
324:28 - simple application even if you don't
324:30 - know anything about building web apps
324:32 - I'm going to walk you through it really
324:33 - easily here okay so we're going to open
324:35 - up app.py so we are using flask if
324:38 - you've never heard of flask it is a very
324:40 - minimal python framework for creating
324:42 - web apps uh very uninspiring uh homepage
324:46 - here but it gets the job done it's going
324:48 - to create a default route for us which
324:51 - uh we have there we're going to call
324:53 - hello here and we're going to have hello
324:55 - world so that's all that's going on here
324:58 - very very simple and we have our
325:00 - requirements this is our package manager
325:02 - I don't know why python uses txt files
325:04 - it's very outdated to me but that's what
325:05 - they use and here we have flask
325:09 - all right so we're going to use that
325:11 - repo and it's a public repo so it should
325:13 - be very easy for us to connect so we'll
325:15 - drop down go to
325:18 - GitHub and uh the next thing we need to
325:20 - do is authorize GitHub all right so I
325:23 - ran into a bit of trouble there because
325:24 - I could not uh authenticate my uh GitHub
325:28 - account but you know what I just made
325:29 - another GitHub account so that made it a
325:31 - lot easier I'm going to go ahead here
325:33 - hit GitHub and we're going to try to
325:34 - authorize it and so now I'm logged into
325:37 - this new one called exam Pro Dev and
325:39 - we'll go ahead and authorize this
325:41 - application and we're now in good shape
325:44 - this repository doesn't have anything in
325:46 - it so um if I want to clone something I
325:49 - guess I'll probably have to Fork that
325:51 - repo so we'll give it a moment to
325:53 - authorize and while that's going I think
325:55 - that's what I'm going to do I'm going to
325:56 - go and uh Fork the example repo if I can
326:00 - find the link again here uh
326:04 - myself uh I believe
326:09 - it
326:10 - is that's still authorizing over there
326:12 - I'm still looking for it so it was like
326:15 - examples or something samples or
326:19 - examples all right so I found a way
326:21 - around the problem I just made a new uh
326:23 - GitHub account so that's all I had to do
326:25 - um and I just won't be using my primary
326:27 - account until I get my phone back but um
326:29 - so what we'll do is go hit connect I'll
326:31 - hit
326:32 - authorize and it didn't prompt me
326:34 - because it already connected to this new
326:36 - one called exam Pro Dev you might have
326:37 - to put your CR itial in here and it's
326:39 - going to ask me to select some things
326:41 - it's a new account so there are no
326:42 - organizations there are no repositories
326:44 - there are no branches totally brand new
326:47 - so what I'm going to need to do is get a
326:49 - repo in there so we'll just go ahead and
326:51 - Fork the Azure samples one so that is
326:54 - azure samples
326:57 - python docs hello
327:00 - world and if I type that right we're in
327:02 - good shape I'm going to go ahead and
327:04 - Fork this
327:06 - repository I'll say got it
327:09 - and then I'll move this off screen here
327:11 - this is now cloned you should see it
327:12 - cloned here and we'll go back here and
327:16 - this probably isn't live so there's no
327:19 - refresh button here so we'll have to hit
327:21 - discard and we will give this another go
327:24 - here and we will select our organization
327:27 - which is our name there is the
327:29 - repository uh should be main branch is
327:31 - kind of outdated I'm sorry but it's
327:33 - called Master that's what it is not my
327:35 - fault that's azure's fault okay
327:38 - um and I think that's it I don't know if
327:42 - we need a workflow configuration file I
327:44 - don't think
327:46 - so just going to double check here no I
327:49 - don't think so and uh what we'll do is
327:51 - we'll just go ahead and save
327:57 - that and so now we are set up for
328:00 - deployment
328:05 - [Music]
328:10 - all right so now that that's all hooked
328:11 - up if we were to go to browse we're
328:13 - actually still seeing the default page a
328:15 - deployment hasn't been triggered just
328:17 - yet uh so the way it works is it's using
328:19 - GitHub actions so if we click into our
328:22 - call it main branch I know they got the
328:23 - wrong name but uh we're going to click
328:25 - into our GitHub workflows and then below
328:27 - here we can see we have a yaml file uh
328:30 - and this is for GitHub actions
328:31 - integration here and so what it's doing
328:33 - is it's specifying the branch uh what
328:36 - how it's going to uh build going to run
328:38 - onto bunto latest the steps it's going
328:40 - to do it's going to check it out it's
328:42 - going to set up the python version it's
328:43 - going to build it it's going to do that
328:45 - stuff and so in order for this to um
328:49 - take action we'd actually have to go
328:51 - ahead and make some kind of manual
328:53 - change which we have yet to do so e so
328:56 - what we'll do is we'll go back to our
328:58 - main
329:00 - here and uh it should be as simple as uh
329:04 - just changing something here so it's not
329:07 - I'm not sure how it's supposed to know
329:08 - that it's supposed to be doing the hello
329:10 - we oh I guess yeah sorry so this means
329:12 - it's going to Route over to here um so
329:14 - I'm just going to make any kind of
329:15 - change here doesn't matter what it is
329:17 - just one space we'll go ahead and give
329:19 - it a
329:20 - commit and um if I go back to my latest
329:25 - commits we should see that I made that
329:26 - change there it is we'll go back over
329:28 - here and this should be
329:33 - deploying um so if we go over to logs
329:36 - here you can see one's in progress right
329:37 - now okay and so that's what we're
329:39 - waiting we're just going to see that
329:41 - finish there we could probably open the
329:42 - logs and get some more information there
329:44 - and so it just brings you back over to
329:46 - GitHub actions and so here's GitHub
329:48 - actions and it's performing the stuff
329:49 - here so we're just going to give it time
329:52 - here and I'll see you back in a moment
329:54 - so we didn't have to wait too long it
329:55 - only took 1 minute and 29 seconds if we
329:57 - go back over here um we might need to do
330:00 - a refresh and so we can see this is
330:02 - reflected over here and so if we go back
330:06 - to it doesn't really matter if we go to
330:07 - settings or here but I'm going to hit
330:08 - browse and see if my page is deployed it
330:10 - still is not so we do have a small
330:13 - little problem here and it's really
330:14 - going to just have to do with how the
330:16 - app is serve so that's what we need to
330:17 - figure out next all right so our app is
330:19 - not currently working and uh there's a
330:21 - few approaches we can take and the thing
330:23 - I can think right away is we should go
330:24 - in SSH into that instance if you scroll
330:27 - on down here from developer tools you
330:29 - can go to SSH and click this button and
330:31 - that's going to SSH you right into that
330:33 - machine right away you can also uh
330:36 - access SSH via the
330:38 - um CLI command so I believe it's
330:42 - like it's like a web
330:46 - app um SSH it'll do the exact same thing
330:50 - you do that from the cloud shell but
330:52 - that's not what we're doing today I give
330:54 - this an LS in here and we're in Linux we
330:56 - can see we have our app here and uh what
330:58 - I would do is I would see what's running
331:00 - so I I would do a puma uh or sorry not
331:03 - Puma PS Ox grep uh python and you can
331:08 - notice that we have a gunicorn that's
331:10 - running so that is where our python
331:12 - instances are running so you're not
331:14 - looking for flas you're looking for
331:15 - python here and if we wanted to make
331:18 - sure that was working we just type in
331:19 - curl Local
331:23 - Host um and so that is going to return
331:26 - up Port 80 so that tells me that because
331:28 - like curl just means like let's go look
331:30 - at that page um it should return some
331:32 - HTML like print out the HTML to us so
331:35 - that means the app is not running um so
331:37 - what you could do is run flask run and
331:39 - it's going to start
331:41 - on Port
331:43 - 5000 right so what I can
331:46 - do is I can go up uh back to my
331:50 - deployment Center
331:51 - here and I'm going to go get that link
331:55 - here and just ignore the fact that it's
331:57 - working uh it's it's not working right
331:59 - now I know for certain it's not um but
332:01 - if we do 5,000 that won't resolve
332:03 - because Port 5,000 isn't open so we
332:05 - can't really just uh put 5,000 in there
332:08 - and the default server here would be
332:10 - 5,000 so if I stop this and I specify
332:13 - Port
332:15 - 80
332:17 - right then this will start up the app on
332:19 - Port 80 and so now when you go
332:22 - here okay it will work uh this is not a
332:25 - great way because of course as soon as
332:27 - you kill it here uh technically the S
332:29 - should stop running um and so you'll run
332:31 - into that step uh so what we need to do
332:33 - is provide a configuration to gunicorn
332:37 - which is a python thing again it's not
332:38 - so important that you know how like what
332:40 - these things are but the idea is that
332:41 - you understand as administrator you want
332:43 - to make sure you have an app that runs
332:45 - after you do a deploy and so in this
332:47 - particular one we need a startup. txt uh
332:50 - and interestingly enough there is a
332:53 - example code by the same author of the
332:54 - other one we were looking at here I
332:56 - believe it's the same
332:57 - person or it might not be but uh they
333:00 - have a startup txt right and so in here
333:03 - you can see that it binds on Port 0000
333:05 - it starts up four workers starts up the
333:07 - app
333:08 - all right um and so that's something
333:10 - that we can go ahead and do so uh what I
333:14 - will do is I will go back to my GitHub
333:19 - repository that we have
333:21 - here and I can just go ahead and add a
333:24 - new file so I'm going to say
333:27 - um add a file create a new file here
333:31 - we'll call it startup.
333:33 - txt I'm going to copy this command here
333:36 - and paste it in there so gunicorn will
333:39 - bind the workers and startup on the app
333:42 - um startup app is being ran by uh
333:45 - something here so if I go back here I
333:46 - think they have a startup High here and
333:49 - that's all that it is doing um I think I
333:53 - want
333:54 - to I could do it this way I suppose let
333:57 - me just see here there's is a slightly
334:00 - different eh so they actually have like
334:02 - a full app going on
334:03 - here and I just want a very simple flask
334:06 - app so I think what I can
334:08 - do is put flask run
334:14 - here Port
334:16 - 80 and that should start up the app
334:19 - there I'm going to go ahead and commit
334:20 - that
334:21 - file okay and as since I commit that if
334:24 - I go back to my actions it created that
334:27 - startup file there so it should trigger
334:29 - a
334:30 - build it's queued
334:32 - up um and I'll just put this tab up here
334:36 - so we'll be back here in 2 seconds
334:38 - and if I give this a nice refresh yeah
334:40 - you can see it deploys in progress so uh
334:43 - this doesn't take too long we'll just
334:44 - wait close that there we'll just wait a
334:46 - few minutes we click logs it just opens
334:48 - it back up here and we'll see how that
334:50 - goes all right so uh your deploy may
334:52 - have finished there but the thing is is
334:53 - that we're not going to really know if
334:55 - uh a change has taken effect unless we
334:57 - actually go ahead and update our code so
334:59 - what I want you to do is go to your code
335:01 - tab go to your app.py we'll hit edit and
335:04 - I'm going to go ahead and change this to
335:06 - Vulcan
335:08 - and then we'll scroll on down hit commit
335:10 - changes and we'll make our way back over
335:13 - to our deployment Center and we'll give
335:15 - it a refresh here and we're just going
335:17 - to wait until this one is complete and
335:19 - we will double check to make sure that
335:20 - that is changed if it is not we will
335:22 - take action to fix that okay all right
335:25 - so we just waited a little while there
335:27 - for that deploy to happen and if we go
335:29 - to our website here it is taking effect
335:32 - so that's all we had to do to get it
335:33 - working so that's pretty good um so that
335:36 - is uh deployment
335:37 - [Music]
335:41 - so let's talk about deployment slots in
335:43 - order to utilize this feature we're
335:45 - going to actually have to upgrade our
335:47 - account because we cannot utilize them
335:49 - at this uh the basic plan here we got to
335:51 - go to standard or premium so let's go
335:53 - ahead and give that an
335:54 - upgrade uh so here's the B1 we're going
335:57 - to go to production here um and I
336:01 - think yeah we're going to have to choose
336:04 - this one here uh very expensive so the
336:07 - thing is we going to just upgrade it
336:08 - temporarily unless there's more options
336:09 - down below that are
336:12 - cheaper yeah these are the standard
336:14 - tiers let's go with this one here
336:17 - because it's only $80 again we're not
336:19 - going to be doing this for long but I
336:20 - want to show you how to do staging slots
336:22 - and auto scaling okay so we'll go ahead
336:24 - and apply that
336:26 - there and now it says that it's applied
336:29 - so if I go back to our app here and we
336:31 - click on deployment slots sometimes it
336:33 - doesn't show up right away if it doesn't
336:35 - that's not a big deal you just wait a
336:37 - bit but today it's super fast so we're
336:39 - going to go ahead and add a new slot
336:41 - we're going to call it uh staging we're
336:43 - going to deploy from our production
336:45 - Branch here and I'm going to go ahead
336:46 - and create that
336:51 - there and we'll just wait until that's
336:53 - done
336:55 - okay great so we waited a little bit
336:57 - there and uh our slot is created so I'm
337:00 - going to just hit close there and so now
337:03 - let's go take a look and see if we can
337:04 - actually see the application here so I
337:06 - just clicked into it I click browse and
337:08 - we're getting the default page so
337:09 - nothing is actually really deployed to
337:11 - it uh so how are we going to do that
337:14 - that's the the main question here um so
337:17 - what I'm going to do is I'm going to
337:19 - make my way over to the deployment
337:23 - Center and you can see that it's not
337:26 - configured for the slot so we are going
337:29 - to have to set it up all over again even
337:30 - though it copied over configuration
337:32 - settings it didn't copy over the code so
337:34 - we go to GitHub we'll choose our
337:36 - organization again I'm going to choose
337:38 - the repository we're going to choose
337:40 - that main branch again there we're going
337:42 - to let it add a workflow and notice that
337:44 - this time it's going to call it staging
337:45 - yaml so there'll be a separate workflow
337:47 - that gets created we're going to go
337:49 - ahead and save that
337:55 - there and what we can do is again click
337:57 - onto our Branch name there and if we
338:01 - click into our workflows we'll not now
338:03 - notice that we have a staging example
338:04 - it's the same thing um but it should be
338:07 - able to now deploy so the whole purpose
338:10 - of um these deployment branches is that
338:13 - it helps us uh we can deploy different
338:15 - versions of our apps but also um it's
338:17 - just a place where we can uh uh view
338:20 - things before we actually roll them out
338:22 - so we want to make sure 100% that they
338:23 - are working correctly um I don't think
338:26 - this will automatically push out let me
338:27 - just go to my actions to see if this is
338:29 - deploying notice that we have two
338:31 - workflows now we have staging here uh
338:33 - and yeah it looks like it's going to
338:34 - deploy here so we'll just wait a little
338:36 - bit um but maybe what we can do is try
338:39 - to have a a slightly different version
338:41 - uh for each one here okay uh but we'll
338:43 - just let that finish and I'll see you
338:44 - back in a
338:48 - moment all right so our deploy finished
338:51 - there so now if we go back to our
338:52 - website here we go browse we should see
338:55 - that application it says hello Vulcan
338:57 - and if we go and take out this we still
338:59 - have hello Vulcan so how can we have a
339:01 - uh a variant of this so that we can push
339:03 - out to that so what I'm going to do is
339:05 - I'm going to go back to my application
339:07 - here I'm going to go to code and I'm
339:08 - just going to make a minor change um I
339:12 - don't say also is that spelled right
339:15 - startup doesn't look correct to me um so
339:18 - maybe I'll go ahead and adjust that file
339:20 - but it doesn't seem to be affecting
339:21 - anything which is I'm a bit surpris
339:23 - there so what I'll do is I'm going to go
339:27 - and edit that file and give it the
339:29 - proper name can I rename this file yes I
339:32 - can so we'll call that startup
339:35 - file I thought we need that for deploy I
339:37 - guess it just works without it which is
339:38 - nice uh if we go back here I'm going to
339:41 - go and I actually just want to edit my
339:44 - um app here again and I'm going to go
339:47 - and edit this and we'll say um hello
339:53 - Andor or hello andorians
339:58 - maybe and so if I go back to my actions
340:00 - the question what is it deploying is it
340:01 - going to deploy the production or the
340:04 - staging and it looks like it's going
340:07 - going to
340:09 - do
340:10 - both looks like it's doing both here the
340:13 - one way we could tell is we can go to
340:14 - our logs here and we can see that um so
340:18 - we did to deploy so there's one change
340:20 - here uh if we go back to our main
340:22 - application and our deployment Center
340:26 - here and we go over to our
340:29 - logs you can see that they're both
340:31 - deploying so it doesn't seem like it's a
340:34 - great thing that that's how it works so
340:36 - the question is is then how would we um
340:39 - facilitate that deploy right how could
340:41 - we do that I suppose what we could do is
340:43 - just make a separate staging Branch um
340:46 - so if I go over to code
340:48 - here um I don't think we can just make
340:51 - branches through here so what I'm going
340:53 - to have to do is go ahead and oh I can
340:56 - create a branch right here so we'll just
340:57 - type in staging and we'll go create
340:59 - ourselves a new
341:02 - branch and now we are in this branch and
341:04 - what I'm going to do is go ahead and
341:06 - modify this and we're just going to call
341:08 - this
341:11 - um hello
341:14 - Klingons okay we'll go ahead and update
341:17 - that and so this should be a separate
341:18 - Branch so you think what we could do is
341:20 - go in and just change our settings so
341:22 - that it deploys from that one uh we'll
341:24 - go back to our deployment slots we'll
341:27 - click into staging
341:29 - here and we need to change our
341:32 - configuration settings um I think we
341:36 - could just do it from
341:38 - um here hold on here I could have swore
341:40 - it specified the branch if we go to
341:42 - deployment Center here I think it's set
341:44 - up on that other Branch there I think we
341:48 - just adjust it here so yeah I think we
341:49 - could just um adjust these
341:53 - settings um we can't discard them but
341:58 - maybe what we can do is just go in and
342:01 - modify that file so we will go into our
342:04 - code
342:05 - here and and uh we will go ahead and
342:09 - click into here go into staging and
342:12 - we'll just change what the branch is
342:14 - called so we'll just say
342:20 - staging and we'll hit start commit and
342:23 - we will save
342:24 - that and we'll see if it actually
342:26 - reflects those changes there so we will
342:28 - go here and hit
342:33 - refresh we'll see if it picks up staging
342:35 - now if we go to settings
342:38 - it's not picking it up so um I'm not
342:40 - sure I don't think perform a redeploy
342:43 - operation we don't want to redeploy so
342:45 - maybe what we'll do is just we'll have
342:46 - to do a disconnect here because it's
342:48 - collect it has the wrong one here so
342:50 - save workflow file
342:53 - um okay we'll just go ahead and delete
342:56 - it it's not a big deal we'll just have
342:57 - to make a new one
342:58 - here we'll go to GitHub we'll choose our
343:02 - uh organization again or repository our
343:05 - staging Branch this time around we'll
343:07 - let it add one see it says we use an
343:09 - available workflow so we could have kept
343:10 - it there and added it there um and we'll
343:13 - go ahead and save that so now we'll have
343:16 - two separate branches there and we'll
343:19 - give that some time to deploy because
343:21 - that will now trigger a deploy off the
343:22 - bat and so I'll see you back here in a
343:24 - moment all right so after a short little
343:26 - wait here it looks like our app is done
343:28 - deploying so we'll go over here we'll
343:29 - make sure that this is our staging
343:30 - server is good and we want to see that
343:33 - our production is different perfect so
343:35 - we now have a way to deploy to each one
343:37 - but imagine that we want to swap our
343:39 - traffic so we're happy with our staging
343:41 - server we want to roll that out to
343:43 - production and that's where we can uh do
343:45 - some swapping so what we'll do is click
343:47 - the swap button and we're going to say
343:49 - the source is the staging and this is
343:51 - our Target production and we're going to
343:52 - perform that swap uh right now we can't
343:55 - do a preview because we don't have a
343:57 - particular setting set that's okay and
344:00 - it's kind of showing if there are any
344:01 - changes so set of configuration changes
344:03 - we don't have any so that's totally fine
344:05 - as well we'll go ahead and hit
344:08 - Swap and that's going to swap those two
344:10 - I believe it's has has zero downtime so
344:13 - we will be in good shape if that happens
344:17 - there and we'll just give it a moment to
344:19 - do
344:22 - that great so after a short little wait
344:24 - there the swap is complete and so uh if
344:27 - you remember
344:28 - clearly this was our production right
344:31 - and so if I was to hit refresh it so now
344:33 - say Klingons and if I go to my staging
344:35 - server it should be the other way around
344:36 - right
344:38 - right good so now imagine that I want to
344:41 - just split the traffic uh that's
344:42 - something else that we can do um so
344:44 - notice over here we have these
344:45 - percentages here um not sure why it
344:48 - won't let me change
344:50 - those so maybe I'll have to look into
344:52 - that so I'll be back into so I'm not
344:54 - sure why it's not showing us that
344:55 - traffic slot there but what I'm going to
344:56 - do is just maybe try to trigger a deploy
344:59 - back into our staging and maybe that's
345:00 - what it wants to see um so what I'm
345:03 - going to do is go back to my code here
345:04 - we'll be in our staging Branch here I'm
345:06 - going to go ahead and uh edit this file
345:09 - here and we will just change this to
345:16 - borans and we will hit
345:19 - update and we will let that go ahead and
345:22 - deploy so if we go to actions here we
345:24 - can see that it is
345:25 - deploying um and we'll just give it some
345:27 - time okay so see you back here in a bit
345:30 - I mean the other reason could be that
345:31 - we're just not at the main level hold on
345:35 - here uh if we go back back here to
345:37 - deployment
345:38 - slots you know what I think it's just
345:40 - because I was clicked into here and then
345:42 - I was clicked into deployment slots that
345:44 - they're both gray out yeah it is so we
345:46 - can actually do that top level there
345:48 - doesn't hurt to do another deploy though
345:49 - so um we'll just wait for I'll wait for
345:51 - that deploy to finish and then we'll
345:53 - come here and uh adjust that there okay
345:57 - all right so let's take a look at uh
345:58 - doing some traffic switching here so
346:00 - right now we were to go to our
346:02 - production we have Klingons and if we
346:04 - were to uh go to our staging
346:11 - we have Boran so imagine that we only
346:14 - want 50% of that traffic to show up so
346:16 - what we can do is put in
346:17 - 50% and what I'm going to do is um do I
346:22 - hit enter here or oh sorry save up here
346:24 - there we go um and so what's going to
346:27 - happen is this should take effect I
346:29 - think right away yep uh and so now we
346:32 - have 50 50 50% chance of getting
346:34 - something else here um so I'm just going
346:36 - to keep on hitting enter here if that
346:38 - doesn't work we can try an incognito tab
346:41 - and there we go we got the opposite
346:43 - there and so this is serving up staging
346:45 - right uh and this is serving up
346:48 - production but they're both on the
346:49 - production URL so that's a way you can
346:51 - split the traffic so uh that's pretty
346:54 - much all I wanted to show you for
346:55 - deployment slots let's now talk about
346:57 - [Music]
347:01 - scaling all right so let's take a look
347:03 - into how we can uh do some scaling with
347:05 - our app service this is only available
347:07 - if you have Beyond standard and or
347:09 - standard and Beyond so standard and
347:11 - premium and Etc so if we just search for
347:13 - scale we have two options here we have
347:15 - scale up and scale out so scale up is
347:17 - pretty straightforward that just means
347:19 - to uh make our instance larger and so we
347:22 - already did that when we upgraded from
347:23 - our standard our our B1 over to our S1
347:27 - here right so if I was to go here and
347:29 - I'm not going to do that but if I was to
347:30 - do that an upgrade um that would be
347:33 - scaling up right and notice that we're
347:36 - talking about scaling so right now we're
347:37 - limited to 10 instances which is totally
347:39 - fine but now let's take a look at
347:41 - scaling out so if we go to scale out
347:44 - here and go to Custom Auto scale what we
347:47 - can do is we can Scale based on a metric
347:49 - so we can add or remove servers based on
347:52 - the demand of the current um web
347:54 - applications traffic so we only paying
347:56 - for servers when we need them and so we
347:58 - have a minimum of one a maximum of two
348:00 - that seems fine to me but we're going to
348:01 - add a rule here and I want to scale this
348:03 - on um the maximum time we're going to do
348:06 - it on CPU uh percentage I just want to
348:09 - have a very easy way to trigger this so
348:11 - we can see a scaling event in action
348:13 - here it has a maximum of 16% I might
348:16 - just lower that down even further will
348:18 - it let me type in there no so 16% is
348:21 - what it's going to have to be it's not a
348:22 - big deal but I am going to reduce it
348:24 - down to actually I think sorry I don't
348:26 - know why I was going here the the metric
348:28 - threshold to scale an action I'm going
348:30 - to put it at 10%
348:32 - sorry okay so here's that line and so we
348:36 - have uh and I I like how you can drag it
348:38 - but you can kind of have an idea that we
348:40 - have a high chance of having this um
348:42 - trigger I just want to do this so that
348:43 - we have a a good chance so if I was to
348:45 - put it here you can notice that it's
348:47 - very easy for us to spike our traffic
348:49 - and and cause a scaling event now I'm
348:51 - going to set the duration to 1 minute so
348:53 - we have a much higher chance of uh
348:55 - triggering that there okay set a
348:58 - duration less than 5 minutes May
349:00 - generate uh transient spikes yeah that's
349:02 - fair but I mean I just want to show you
349:05 - a trigger happen and we need a cool down
349:07 - time probably um and it's set to 5
349:09 - minutes that's totally fine we're going
349:10 - to add one and that looks fine to me I'm
349:14 - going to set this to maximum okay and so
349:16 - now we're very likely to trigger that
349:17 - there we'll go ahead and hit add that uh
349:20 - instance there and so now that we have
349:22 - that we're going to go ahead and save
349:35 - that and so now that that's there what
349:37 - we want to do is actually trigger a
349:40 - scaling event and so uh where we're
349:43 - going to see that is under the
349:44 - monitoring
349:48 - tab so if we go to
349:53 - monitoring and uh what we're going to do
349:55 - is go over to um it should be in sorry I
350:00 - forgot uh the place where we need to go
350:01 - take a look here is actually in the Run
350:03 - history here so if we go here and check
350:05 - 1 hour we can see how many instances are
350:07 - running uh and I think if I dial it back
350:09 - here it should show me over time as it
350:10 - changes we do have a scale up event that
350:13 - has happened which happened I guess four
350:15 - minutes ago um so I guess it gives you
350:18 - kind of an idea of how many instances
350:19 - are running which right now are two um
350:22 - so maybe our uh maybe our scaling event
350:25 - is not uh in the best uh use case there
350:28 - because it's happening too frequently so
350:29 - what I'm going to do is go ahead and
350:32 - modify that scaling rule um and so I'm
350:35 - just going to go back and click here and
350:37 - maybe we'll just make it so it is less
350:38 - aggressive so what I'm going to do is
350:41 - just change it so it's over the duration
350:43 - of five
350:43 - minutes and I'm going to just put it
350:46 - right above here so that it goes back to
350:48 - one
350:50 - okay and we'll go ahead and save
350:55 - that and so now if we go back to our run
350:57 - history here uh it still shows that it
351:00 - has um two as you can see here but I
351:03 - want to see this drop back down to one
351:05 - so it's going to check every 5 minutes
351:07 - or or within the span of 5 minutes so
351:09 - what I'm going to do is just uh wait
351:11 - here I'll see you back in a bit until we
351:13 - see a scaling action happens uh here
351:16 - okay yeah I'm just sitting here waiting
351:18 - for it to scale down and I don't see it
351:19 - going so it makes me think that I need
351:21 - to go ahead and set a scale uh scale
351:23 - down action let's take look at the one
351:25 - that we currently have uh so this one is
351:28 - set oh you can see it's still spiked we
351:30 - don't even have anything going on here
351:31 - but what I'm going to do is just be
351:32 - really aggressive here and I'm going to
351:34 - say when it's um
351:38 - 50%
351:42 - okay and so
351:44 - here we'll go back here and I'll save
351:47 - that and I just want to see if it scales
351:49 - down I shouldn't have to set a scale
351:51 - down action should just go Um and what
351:54 - I'm actually going to do is be a little
351:55 - bit more aggressive I know I'm setting a
351:57 - lot of stuff here but I'm going to just
351:59 - set it to duration of 1 minutes so we
352:01 - can see this a lot
352:04 - sooner and uh we will go back to our run
352:08 - history here and we'll see if we observe
352:10 - a scale down all right so um it's not
352:12 - scaling down here but uh I think it's
352:14 - probably because I need to scale out
352:16 - action so what we'll do is go ahead and
352:18 - add a new rule uh this thing if we go
352:21 - here and we just look at
352:25 - it
352:27 - um it's not going to decrease it unless
352:30 - we have a scale out action so I don't
352:33 - think it's necessary for us to set one
352:35 - here I think you get the idea
352:37 - um but that's for scaling so we're all
352:38 - done here with Azure app Services all we
352:40 - got to do is go ahead and go ahead and
352:42 - delete it so let's go ahead and delete
352:44 - our app here
352:46 - okay um so there's a few different ways
352:49 - we can do it I'm going to do it via
352:50 - resource groups um I believe we called
352:53 - it Voyager here so click into that and
352:57 - I'm going to go ahead and delete the
352:58 - resource
353:00 - Group and here is all the related
353:03 - services and so I will type in Voyager
353:07 - and there we
353:12 - go great and so yeah there we
353:15 - [Music]
353:19 - go hey this is Andrew Brown from exam
353:21 - Pro and we are looking at what is
353:23 - infrastructure as code and before we
353:24 - talk about that we need to talk about
353:26 - the problem with manual configuration so
353:28 - manually configuring your Cloud
353:30 - infrastructure allows you to easily
353:31 - start using new cloud service offerings
353:34 - to quickly prototype architectures
353:36 - however it comes with a few downsides so
353:38 - it's easy to misconfigure a service
353:40 - through human error it's hard to manage
353:42 - the expected state of the configuration
353:43 - for compliance it's hard to transfer
353:46 - configuration knowledge to other team
353:47 - members and so this is why uh
353:49 - infrastructure code is going to really
353:51 - help us out so um infrastructure is code
353:53 - commonly abbreviated to IAC and you'll
353:56 - see that a lot in this course allows you
353:58 - to write a configuration script to
354:00 - automate creating updating or destroying
354:02 - Cloud infrastructure notice I gave great
354:04 - emphasis on automate or aut ation
354:06 - because that is really key to um
354:09 - infrastructure's code I can also be
354:11 - thought of as a blueprint of your
354:13 - infrastructure I allows you to easily
354:15 - share version or inventory your Cloud
354:18 - infrastructure and just to kind of give
354:20 - you a visualization imagine you write a
354:22 - script and that's going to uh provision
354:24 - uh and uh launch a bunch of cloud
354:26 - services that are all interconnected
354:29 - [Music]
354:32 - okay hey this is Andrew Brown from exam
354:35 - Pro and we'll be going over Azure
354:36 - automation State configuration Azure
354:39 - automation State configuration lets you
354:41 - define and enforce the desired state of
354:43 - your Azure VMS uring consistency across
354:45 - multiple machines you can specify
354:47 - configuration details such as installed
354:49 - software Windows features registry
354:51 - settings and file contents so let's take
354:54 - a look at the example we have on the
354:56 - right configuration definition simple
354:59 - config the configuration named targeting
355:01 - the node MVM file creation ensures a
355:04 - file named hello.txt with the content
355:06 - hello azzure exists in the C drive Ure
355:09 - is equal to present by applying this
355:11 - configuration you ensure that any VM
355:13 - assigned to the MVM node will have the
355:15 - hello.txt file with the specified
355:17 - content this helps maintain a consistent
355:20 - and desired State across your Azure VMS
355:23 - so that's a quick overview of azure
355:24 - automation State
355:27 - [Music]
355:30 - configuration hey this is Andrew Brown
355:32 - from exam Pro and in this section we'll
355:34 - be covering Azure resource manager Azure
355:37 - resource manager is a service that
355:38 - allows you to manage Azure resources
355:40 - Azure resource manager is a collection
355:42 - of services in the Azure portal so you
355:44 - can't simply type in Azure resource
355:46 - manager in the search tab it is a
355:48 - management layer that allows you to
355:50 - create update or delete resources apply
355:53 - management features such as access
355:55 - controls locks or tags and write
355:57 - infrastructure is code using Json
355:59 - templates we will be examining the
356:01 - following key components that form the
356:03 - Azure resource manager layer we have
356:05 - subscription management groups resource
356:07 - groups resource providers resource locks
356:10 - Azure blueprints as well as resource
356:12 - tags Access Control role based access
356:14 - controls Azure policies and arm
356:17 - templates you can think of azure
356:19 - resource manager as a gatekeeper all of
356:21 - the requests flow through arm and it
356:23 - decides whether that requests can be
356:25 - performed on a resource such as the
356:26 - creation updating and deletion of a
356:28 - virtual machine and its arm's
356:30 - responsibility to authenticate and
356:31 - authorize these requests arm uses
356:34 - azure's role-based Access Control to to
356:36 - determine whether a user has the
356:37 - necessary permissions to carry out a
356:39 - request when a request is made arm
356:41 - checks the users assigned roles and the
356:43 - permissions associated with those roles
356:45 - if the user has the necessary
356:47 - permissions the request is allowed
356:49 - otherwise it is
356:50 - denied the next concept we'll go over is
356:53 - the scope for Azure resource manager
356:55 - we've briefly covered scope in Azure
356:57 - policy and Azure rbac but we'll go into
356:59 - more detail with them in the following
357:01 - sections for
357:02 - arm so scope is a boundary of control
357:05 - for Azure resources it is a way to
357:07 - govern your resource by placing
357:08 - resources within a logical grouping and
357:10 - applying logical restrictions in the
357:12 - form of rules management groups are a
357:15 - logical grouping of multiple
357:17 - subscriptions subscriptions Grant you
357:19 - access to Azure Services based on a
357:20 - billing and support agreement resource
357:23 - groups are a logical grouping of
357:24 - multiple resources and resources can be
357:27 - a specific Azure service such as Azure
357:29 - VMS so that's an overview of azure
357:31 - resource manager
357:34 - [Music]
357:38 - hey this is Andrew Brown from exam Pro
357:40 - and in this segment we'll be diving into
357:41 - arm templates so what exactly is
357:44 - infrastructure is code infrastructure as
357:46 - code is the process of managing and
357:48 - provisioning computer data centers such
357:50 - as those in Azure using machine readable
357:52 - definition files like JSO n files rather
357:55 - than depending on physical Hardware
357:57 - configuration or interactive
357:58 - configuration tools you write a script
358:00 - that will set up cloud services for you
358:03 - there are two main approaches to IAC
358:05 - decare erative here you describe your
358:07 - desired outcome and the system figures
358:09 - out how to achieve it imperative here
358:12 - you provide Specific Instructions
358:14 - detailing exactly how to reach the
358:15 - desired State arm templates or JSO n
358:18 - files that Define Azure resources you
358:20 - want to provision and Azure Services you
358:22 - want to configure with arm templates you
358:24 - can ensure a declarative approach
358:26 - meaning you merely Define your intended
358:28 - setup and the system handles the rest
358:31 - build remove or share entire
358:32 - architectures in minutes reduce
358:35 - configuration mistake
358:36 - and know exactly what you have defined
358:38 - for a stack to establish an architecture
358:40 - Baseline for
358:41 - compliance or over arm templates Empower
358:44 - you to establish an architecture
358:46 - Baseline for compliance achieve
358:48 - modularity break up your architecture in
358:50 - multiple files and reuse them ensure
358:53 - extensibility add Powershell and Bash
358:55 - scripts to your templates test using the
358:57 - arm template toolkit preview changes
359:00 - before you create infrastructure via
359:01 - template see what it will create
359:03 - built-in validation will only deploy
359:05 - your temp templ if it passes track
359:08 - deployments keep track of changes to
359:09 - architecture over time policy is code
359:12 - apply Azure policies to ensure you
359:14 - remain compliant use Microsoft
359:16 - blueprints which Forge a connection
359:18 - between a resource and its template
359:20 - integrate with CI CD pipelines utilize
359:24 - exportable code letting you capture the
359:25 - current state of resource groups and
359:27 - individual resources and benefit from
359:30 - Advanced authoring tools for instance
359:32 - Visual Studio code offers sophisticated
359:34 - features tailored for crafting arm
359:36 - templates so as you can see arm
359:38 - templates has quite a lot of
359:41 - [Music]
359:45 - uses okay so now what I want to do is
359:48 - cover infrastructure as code for Azure
359:51 - so there are two uh primary ways of
359:53 - doing infrastructures code we have arm
359:55 - templates the arm stands for Azure
359:57 - resource manager and the other one is
360:00 - azure biceps we're going to focus on the
360:02 - first one infrastructure as a code is
360:04 - the concept of
360:06 - um uh defining all your infrastructure
360:10 - as code uh and that might be confusing
360:13 - because that might sound like s the SDK
360:15 - or the CLI and uh it is confusing until
360:18 - you start working with it but the key
360:20 - difference is that when you use the CLI
360:22 - or the SDK uh to programmatically create
360:24 - resources they don't keep uh track of
360:27 - the State uh and so that is the key
360:29 - difference between that whereas if you
360:31 - ran a CLI command to create uh let's say
360:34 - a virtual machine
360:36 - and you ran it again with the same
360:38 - parameters and the same name it would
360:40 - attempt to create a second um virtual
360:43 - machine whereas with infrastructure is a
360:44 - code if it's already there it's going to
360:46 - either update it or say hey you can't
360:48 - update it there's already one that
360:50 - exists so the idea is that um uh it's
360:54 - different in that process or in that
360:55 - sense uh there is a word for it um I
360:58 - believe the word is EP poent I always
361:01 - have a hard time saying it but um that
361:02 - is the key difference between those
361:04 - programming methods and IC so what I
361:07 - want to show you is uh arm templates and
361:11 - um arm again stands for Azure resource
361:13 - manager it's part of resource groups so
361:17 - if we type in arm here we're not going
361:19 - to really get uh a service or anything
361:21 - like that we say Azure or Azure resource
361:25 - manager okay you're just not going to uh
361:27 - exactly get that because um it is it is
361:31 - something that's there but it really is
361:32 - talking about resource groups so when
361:35 - you deploy a resour group it will always
361:37 - create an arm template for you no matter
361:39 - if you do click Ops um you'll always get
361:42 - an arm template and this is something
361:43 - that very different from other providers
361:45 - so like when you use ads or
361:47 - gcp um when you launch a resource it
361:49 - doesn't necessarily will produce a a
361:52 - template for you but Azure is very
361:55 - unique in that sense that they will do
361:56 - that so what I want to do is I want to
361:59 - go ahead and uh explore some things with
362:02 - arm templates so you're very aware of
362:03 - how they work and I believe that uh
362:07 - there is a way to uh deploy if we type
362:09 - in template here there should be
362:10 - something like deploy a custom template
362:12 - whoops and that's how you would go about
362:14 - deploying a custom template and they
362:16 - actually already have some common
362:17 - templates here so maybe we can uh take a
362:19 - look at one as a quick start and try to
362:21 - understand uh what these templates look
362:23 - like another key difference between
362:25 - other cloud service providers is that
362:27 - it's not very common to write arm
362:28 - templates by hand um in fact it's very
362:31 - tedious and you would not necessarily
362:32 - want to do it as opposed to ads where
362:34 - you have cloud formation totally normal
362:36 - to do and that's why um having a layer
362:38 - on top of uh arm makes it so much easier
362:41 - like using again Azure bicep or ter form
362:44 - but let's go ahead and create a Linux
362:46 - virtual machine here and notice that I
362:49 - select the template and it has some
362:51 - options here so um what I want to show
362:54 - you here this looks like the usual
362:56 - process for setting up a um a virtual
362:59 - machine but if we go here we can edit
363:00 - the template and then it's going to
363:02 - allow us to see what this template looks
363:04 - like so arm templates this is what it
363:05 - look looks like and I believe that uh
363:08 - they're only Jason I kind of
363:10 - forget Let's go ask chat GPT so are arm
363:15 - templates uh in Azure only Jason or can
363:19 - they also be yaml the reason why I I
363:22 - don't remember is because I work with a
363:23 - lot of cloud service providers usually
363:25 - they'll provide both options um but
363:29 - generally uh I always remember that arm
363:32 - templates are only Jason so there is no
363:33 - yaml support uh for it but of course you
363:36 - could use yaml locally and then convert
363:38 - it over back to Json but anyway so if we
363:41 - look at this here we have some things we
363:43 - have a schema that describes what the
363:45 - format of this Json should be um we have
363:48 - some metadata which probably gets
363:49 - autogenerated or is additional U
363:51 - information to attach the template we uh
363:54 - we have parameters so these are going to
363:55 - be values that we're inputting that
363:57 - allow us to uh make our template
364:00 - reusable and if we scroll on down um
364:03 - yeah we got variables which is probably
364:07 - um the modification of
364:08 - parameters and then we have our
364:11 - resources down below here and you know
364:13 - again if you've seen cloud formation
364:15 - templates or uh deployment manager gcp
364:17 - deployment uh scripts these are going to
364:19 - look very very similar so we we Define
364:22 - the type for the resource uh we have a
364:24 - name for it then it has its properties
364:27 - uh and then it can depend on other
364:28 - resources to say what order uh they're
364:30 - performed in but anyway my point is is
364:33 - that uh this is a template and and we
364:36 - can go ahead and actually uh deploy this
364:38 - template but I'm not that interested in
364:40 - that part of it because this is not that
364:42 - exciting what's more exciting is what
364:44 - happens when you do click offs so I'm
364:45 - going to go over uh over here and uh
364:48 - deploy a virtual
364:51 - machine um yeah I I mean we could do
364:54 - virtual machine I'm just trying to think
364:56 - what's easier maybe we'll go ahead and
364:57 - actually do I've changed my mind we're
364:59 - going to actually go ahead and do uh
365:01 - storage accounts again I'm still in the
365:03 - free tier and I'm just trying to make
365:04 - things easy for you as well
365:06 - um and virtu virtual machines will spin
365:07 - up a lot of resources so maybe I don't
365:10 - want something that complicated uh for
365:12 - this example but what I want to do is I
365:14 - want to launch a virtual uh a storage
365:16 - account and then I want to see how we
365:18 - can look at the template and maybe we'll
365:21 - attempt to rein import the template and
365:23 - then delete the storage account and
365:24 - recreate it so I'll go here and I'm
365:26 - going to hit create and we're going to
365:28 - create ourselves a new Resource Group
365:30 - I'm going to call this Resource Group um
365:33 - o uh
365:36 - my uh arm RG so arm for Azure resource
365:42 - manager and today it's really thinking I
365:44 - don't know if I'm having internet issues
365:46 - here or if it's just really complaining
365:47 - or if Azure is slow azure's uh sometimes
365:51 - their UI is not always responsive and we
365:53 - have to give this a name of course we
365:55 - have to make sure this is very unique so
365:56 - I'm going to say my um storage account a
366:01 - bunch of numbers and then my
366:03 - initials and it probably has too many
366:05 - letters so it's complaining there we go
366:07 - and I'll just let it choose whatever
366:08 - region wants we'll have it on standard
366:10 - that's totally fine I'm going to go
366:11 - ahead and go to review where we can see
366:13 - all of our options looks fine to me
366:15 - we'll go down the bottom hit create and
366:17 - we'll give it a moment here to create so
366:21 - I'll be back in just a second all right
366:24 - so that deployment is complete and what
366:25 - I'm interested in is checking out uh the
366:27 - resource Group but notice that when
366:28 - we've deployed this we have our inputs
366:31 - it shows us what we've inputed and we
366:33 - looked at the uh parameters of a
366:35 - template before so it is creating
366:36 - literally an arm template and then
366:38 - inputting the parameters it's showing
366:40 - this the outputs of uh that arm template
366:43 - and then here's the template itself so
366:45 - every time you deploy Azure resources it
366:48 - is creating uh these IAC code for you
366:51 - and that is one of the greatest
366:53 - advantages of azure as much as I
366:55 - complain about Azure this is one of
366:56 - their really really good features and
366:58 - there's a few things you could do like
367:00 - it looks like we can add this to our
367:01 - library we can download this we can
367:03 - deploy it again let's go ahead I usually
367:05 - don't uh fiddle with these too much but
367:08 - we can um import this template and I can
367:10 - say uh my Resource Group but just
367:14 - remember you could have a lot of
367:15 - resources and really make that uh uh ret
367:17 - templated I'm going to choose the same
367:20 - um area here and this will just be
367:23 - version 1.0.0 down here I'm going to go
367:26 - to next it shows me the template next uh
367:29 - we can do some tagging I'm going to
367:30 - ignore that for now review and
367:32 - create and so now we have our own uh
367:35 - template so that's kind of cool um if we
367:38 - go back to here I'm not exactly sure
367:43 - where they oh we have to hit create
367:44 - maybe first it's not super clear but uh
367:48 - so that is now uh template has been
367:50 - saved but where did it save
367:51 - to uh just says it's a template
367:57 - spec it is really taking its time to
367:59 - load
368:00 - here okay and so we have our template
368:03 - here I'm not sure if we if we typed in
368:04 - templates here if they up here they I
368:06 - guess they show up under template specs
368:08 - uh we'll refresh this not sure why it
368:11 - doesn't show up we know that we created
368:13 - it and you know I've said this in other
368:15 - videos where Azure doesn't always
368:17 - propagate things right away and you have
368:19 - to wait so you have to have confidence
368:21 - and waiting for things to show up in
368:22 - Azure so even though it's not here I
368:25 - know I created one okay so we go over
368:28 - here it says template uh spec succeeded
368:30 - so it really really I think it would
368:31 - show up here um and I I really want to
368:34 - prove that it will will show up here
368:36 - eventually so what I'm going to do is
368:37 - just take a break and I'm going to give
368:39 - it like 10 15 minutes I'm going to give
368:40 - it a good chunk of time here and we'll
368:41 - come back and see if it appears um just
368:44 - to give you validation and confidence
368:46 - that patience always uh pays off here in
368:49 - Azure okay all right so I've waited a
368:51 - good chunk of time was just talking to
368:53 - Bo and um so I'm now I'm back and let's
368:55 - see if it is here we're going to give a
368:57 - refresh and look it's here so I told you
368:59 - you got to be really really patient with
369:00 - Azure it is really known for being slow
369:03 - for uh some particular resources
369:06 - and I when I say some I mean a lot so
369:08 - you know just have that patience there
369:10 - but anyway what I want to do is I'm
369:11 - going to open up another tab we're going
369:13 - to go back over every time I open that
369:15 - new tab and wants me to log in that's
369:17 - great um but what I want to do is go
369:19 - over to our resource groups and we're
369:22 - going to go into that new one that we
369:23 - created and what I want to do is I just
369:25 - want to delete this resource here um and
369:28 - I want to see what happens if we attempt
369:30 - to redeploy our uh template there I
369:33 - assume we're going to have to
369:35 - I mean we don't have to delete this one
369:37 - but um I just want to move it completely
369:39 - and just try utilizing an arm
369:42 - template so we'll give it a moment there
369:45 - and oh notice we have an upgrade button
369:47 - this is uh definitely new we might be
369:49 - going through our not sure why it's
369:52 - appearing all of a sudden I've actually
369:53 - never seen that button before so it's
369:54 - really
369:56 - interesting and nope I guess it's just
369:59 - maybe after a while they just kind of
370:00 - poke you and over here we're getting our
370:03 - prompt so um it looks like we're
370:04 - starting to get some spend and you know
370:06 - I said earlier that Azure is really good
370:07 - about telling us about um alerts and
370:10 - things like that much better than other
370:11 - providers um and so you know here it's
370:14 - showing in Canadian dollars that uh
370:16 - we've already uh consumed half our spend
370:19 - not sure how I did that because I
370:21 - haven't really done a whole lot but um
370:23 - what we'll do is we'll try to figure out
370:25 - where that that uh free spend has been
370:27 - going um still again that's a lot um so
370:31 - maybe it's overestimating that or I left
370:33 - something running maybe that c cluster
370:35 - is still running I don't think so let's
370:37 - go double
370:39 - check and but anyway I wanted that to
370:41 - happen so I could go back and show a
370:43 - video of of that kind of stuff because
370:45 - all we created is a couple virtual
370:46 - machines and some other things yeah we
370:49 - don't have anything else running that
370:51 - should be costing us spend but we'll go
370:53 - take a look there and see what we can
370:54 - figure out so anyway I'm going to go
370:56 - back here give this a
370:58 - refresh and um that resource is gone
371:01 - what's interesting is it also got rid of
371:03 - the template why did I get rid of the
371:06 - template that that was something we
371:07 - created separately and so I guess it was
371:10 - linked to the resource Group and so that
371:12 - kind of defeats the purpose of us
371:13 - uploading our arm template so that's a
371:17 - shame um I guess what we could do is we
371:20 - could go and
371:23 - um I don't know uh we could go and use
371:25 - the custom provider and launch a
371:27 - template but there's not much interest
371:29 - in that so uh I'm not really interested
371:32 - in doing
371:33 - that yeah I think we're pretty much done
371:35 - here I think we've we' proved the point
371:37 - that Azure is really good at producing
371:39 - These Arm templates you're not going to
371:40 - want to write them by hand um you can
371:43 - ask CH PT to do it but I again I would
371:45 - probably not do that myself but I think
371:47 - that satisfies this video for arm
371:49 - templates so we'll see you in the next
371:50 - one
371:51 - [Music]
371:55 - okay all right so we looked at uh
371:58 - utilizing arm templates and I think it'
372:00 - also be really great to look at Azure
372:02 - bicep um because that is a more
372:04 - productive way to write infrastructure
372:06 - as code um and honestly I really like
372:10 - Azure bicep I think it's really really
372:11 - cool uh so what I want to do is I want
372:13 - to go ahead and go over back to GitHub
372:16 - we looked at creating a GitHub or
372:18 - creating a repo in GitHub uh back in our
372:20 - SDK video that was a really messy video
372:22 - I'm really hoping that it's not as crazy
372:24 - as that one but I don't like editing out
372:26 - any of the challenges uh here because I
372:28 - want to give you uh the full idea of of
372:32 - what it looks like when trying to work
372:33 - through these things but I'm going to do
372:35 - is go over to GitHub and you should of
372:37 - course go ahead and create yourself a
372:38 - GitHub account has a free tier uh and
372:41 - once you have your GitHub account we'll
372:42 - make a new repo I'm going to uh drop
372:45 - down uh here and go to exam Pro and of
372:47 - course you'll just have one name here if
372:49 - I have multiple accounts so there's a
372:51 - lot for me to create stuff in and what
372:53 - I'm going to do is make a new repo
372:55 - called um Azure bicep example you can
372:59 - call yours whatever you like I'm going
373:01 - to make this public so that you can see
373:03 - the code uh you can make yours priv
373:05 - private if uh private is available to
373:07 - you there but I going to make it public
373:09 - because if you want to go find this repo
373:11 - at exampro here and copy it and work
373:13 - with it you can so we're going to go
373:15 - ahead and use codes spaces and code
373:16 - spaces does have uh free credit usage
373:19 - you could do this locally um on your
373:21 - local computer but you'd have to install
373:23 - a bunch of stuff uh I like using Cloud
373:25 - developer environments and Azure does
373:27 - not have one built into their portal um
373:30 - most other ones do but I think the
373:32 - reason why Azure doesn't is because uh
373:34 - Microsoft owns GitHub and so you could
373:36 - just go over here and use code spaces
373:38 - instead so this to me is like using
373:41 - Azure okay so we're going to go ahead
373:43 - and create a uh code spaces on Main here
373:46 - and understand as long as the code space
373:48 - is running we are consuming uh so if you
373:50 - want to stop it you could always go up
373:52 - to the command pallet here and we can
373:54 - just say uh stop
373:57 - or uh it's code
374:00 - spaces it should be there should be
374:02 - something here called
374:03 - stop um shut down
374:06 - down I did this the other uh the other
374:08 - day when we did did that yeah it is code
374:10 - spaces oops it's loading so it's it's
374:14 - bumping things out here but if we go
374:15 - code spaces there is an option to stop
374:18 - the current Works uh code space so I'm
374:20 - not doing that right now uh I want my
374:22 - theme to be dark so I'm going to go to
374:24 - this Cog down here go to themes go to
374:26 - color and we'll switch to um GitHub
374:32 - dark and we'll give it a moment to think
374:34 - because it's a bit slower loading I
374:36 - greatly greatly prefer git pod the
374:38 - reason I'm using Code spaces is because
374:41 - um the extensions are going to use the
374:43 - official ones with Microsoft and it's
374:46 - just going to be easier to show you this
374:47 - here in most other courses I use git
374:51 - pod um so anyway once that is loaded and
374:55 - we uh changed our theme if that matters
374:57 - to you uh we're going to want to do some
375:00 - Azure bicep stuff so on the left hand
375:02 - side I want you to go to extensions and
375:05 - we're going to search Azure bicep I
375:07 - don't use Azure bicep a lot but I
375:09 - definitely know how to use it when we
375:11 - need to so I know they have a really
375:13 - good extension for it and it's like it
375:16 - writes code for you it was it's the
375:18 - nicest experience I've ever had with a
375:20 - um an I uh
375:24 - tool and this is the thing because
375:26 - Microsoft um built Visual Studio code
375:29 - and you know their they own GitHub they
375:31 - can have really amazing synergies for
375:33 - developers um so a lot of times I find
375:36 - it easier to work in vs code and use
375:38 - their extensions to interact with Azure
375:40 - than it is to use Azure portal itself
375:42 - and there are specific services like
375:44 - Azure functions where you really have to
375:46 - use Visual Studio code so it's it's
375:48 - essential that you get used to using uh
375:50 - Visual Studio code whether it's local or
375:52 - in a cloud developer environment so I'm
375:53 - installing that this Azure bicep um
375:56 - extension and this thing will help us
375:58 - write a lot of uh code um uh and it has
376:02 - like templates and other stuff like that
376:04 - so that's what I want to uh take
376:06 - advantage of it um I don't remember the
376:09 - extension for Azure bicep file so we'll
376:11 - just go to the Azure bicep website I'm
376:13 - sure they'll have like a quick start and
376:15 - we'll work through it here
376:17 - together so I want to go here and I just
376:20 - want to know what the extension is it's
376:22 - bicep so that's what it is so we're
376:24 - going to go here and make a new file
376:25 - we're going to call it main.
376:30 - bicep and something we didn't do before
376:32 - and this is what I wanted to do in the
376:33 - SDK one but we didn't actually have a
376:35 - use for it is there's probably like an
376:37 - Azure um like kit Azure tools there we
376:40 - go and this is something you all might
376:41 - want to install a lot of these down
376:43 - below here see how there's like one for
376:45 - databases resources functions if you
376:47 - install tools it installs all these
376:49 - other ones you even have one for C tools
376:52 - and um it's possible that uh yeah see
376:55 - like this this one will autocomplete
376:57 - Azure commands it'll do all sorts of fun
376:59 - stuff even for Azure storage and
377:00 - everything there's something but the
377:02 - reason we want Azure tools is because we
377:04 - can Azure accounts and this will allow
377:06 - us to quickly log in to our Azure
377:10 - account remember before we typed in a
377:12 - login and then we had to get a device
377:14 - code and plug that in uh well if we have
377:16 - this installed uh we can just use the
377:18 - command pallet and log in very quickly
377:20 - and that's what I want to do here so I'm
377:21 - going to go to the bottom left corner
377:23 - I'm going to pull up command pallet and
377:24 - we'll try to do Azure
377:28 - signin now to be fair I mean this is not
377:31 - going to do much difference down here
377:33 - but I think it installed the um the C
377:36 - for us before we had to manually install
377:38 - it right so we'll go here and we're
377:40 - going to have to choose device code we
377:43 - have signed into Azure Cloud let's try
377:44 - this one first see if that
377:46 - works and then we're going to say uh
377:49 - just so you know Azure has different
377:51 - ones there's like Azure China Azure
377:53 - Germany Azure US Government so generally
377:55 - we always want to choose Azure unless
377:56 - you live in one of these other regions
377:58 - and you have to use that one and this is
378:00 - going to open up and we will sign in we
378:03 - can now close this window
378:05 - and I believe we are now logged into
378:08 - Azure also notice on the left hand side
378:09 - we have this little Azure icon here in
378:12 - the left hand side it will allow us to
378:14 - see our resources we can also sign in
378:15 - from here we should be signed in maybe
378:19 - it didn't work I'll try this one more
378:20 - time extension as your resources wants
378:23 - to sign in we'll say allow maybe it has
378:24 - to sign in separately I don't know we'll
378:27 - close
378:29 - this there we are so now we see our
378:31 - subscription we are in here which is
378:33 - great
378:34 - and we can see a bunch of our
378:36 - services um so you know if we had
378:38 - storage accounts and we do have some
378:40 - storage accounts we can see them here
378:41 - this one I think is for our uh Cloud
378:44 - shell that's why it starts with cs and
378:45 - it has a random number afterwards if we
378:47 - had virtual machines and other things we
378:49 - could see them here but yeah working
378:51 - with functions you often use them here
378:54 - um we could also probably right click
378:55 - this and create a resource and so here
378:58 - there's a lot of ways to uh uh create
379:00 - some stuff we create a resource Group
379:02 - and and some other particular things
379:05 - but uh yeah that's that's interesting I
379:06 - also wonder if like these are these are
379:08 - obviously uh things that were installed
379:10 - there could be other extensions that we
379:13 - didn't install like Azure uh machine
379:15 - learning service or other stuff that
379:17 - could end up showing up there on the
379:18 - left hand
379:19 - side so I'm just kind of scrolling
379:21 - through here and seeing what might not
379:22 - be installed so Azure container apps was
379:24 - not
379:25 - installed or maybe it was and it's these
379:27 - other ones that have these little
379:28 - install words on here but
379:31 - anyway enough about that let's stay on
379:34 - track here and let's write some Azure
379:35 - biceps so now that we have uh that
379:38 - installed we want to start writing it so
379:39 - I just need to see a little bit of code
379:41 - to get a reminder here um so yeah if we
379:44 - start typing it should start suggesting
379:46 - and that's is what we want to do is make
379:47 - a storage account so let's go ahead and
379:48 - start typing that in so I'm going to
379:50 - type in resource uh and so already
379:52 - notice that it is autocom completing and
379:55 - then uh let's just go check here so the
379:58 - next thing is going to be storage
380:01 - account and it should autocomplete
380:07 - so yeah I remember this being really
380:09 - good at Auto completing just give me two
380:10 - seconds and let's go figure that out one
380:12 - sec yeah so I'm looking at it here and
380:14 - it's supposed to just start
380:16 - autocompleting when we type so I'm not
380:19 - sure why it's not exactly doing that
380:22 - we'll go back here sometimes Visual
380:24 - Studio code doesn't do what we want it
380:25 - to do which is totally fine storage
380:31 - account and it's not really autocomp
380:34 - completing so I'm going to go ahead and
380:35 - save this for a
380:37 - second well there it's autocom
380:39 - completing so
380:42 - resource storage am I typing it wrong is
380:45 - it supposed to be uh with the resources
380:48 - no no it's this so it's really
380:50 - interesting that it's not autoc
380:51 - completing but we could just copy this
380:53 - in
380:54 - here
380:56 - okay I just wanted to show you how
380:57 - powerful it was cuz I was so impressed
380:59 - the first time I I saw it uh writing all
381:01 - the code for me which is um not what the
381:03 - other ones do that's for sure so we'll
381:05 - just paste this in here
381:09 - and I put a period
381:14 - here yeah I guess I was expecting a
381:16 - little bit more from it um but uh
381:18 - whatever I guess we'd have to work with
381:20 - it a bit more to find out again I don't
381:22 - work with it every single day but I am
381:24 - always very excited to use it um but you
381:26 - know the thing that I want to uh take a
381:29 - look at is let's look at where the
381:30 - actual reference documentation is and so
381:32 - we'll go to Resource reference here on
381:34 - the left left hand side and I'm really
381:36 - interested to
381:38 - see uh where everything is so if you
381:41 - know the resource type you can just type
381:43 - it here in the left hand side that's
381:45 - fine so we have all our resources here
381:46 - on the left and so we are trying to
381:48 - create a storage
381:49 - account so we can go over
381:52 - here and look for storage account so
381:56 - that be storage and storage
382:01 - accounts and so here it says to create
382:04 - create a uh to create a resource add the
382:07 - following to your Azure bicep so um just
382:10 - kind of getting familiar with it it
382:11 - looks like this is going to be its
382:12 - logical name and this is actually going
382:13 - to define the resource itself and these
382:15 - are all its
382:16 - properties and it looks like there are
382:18 - some that are required and some that are
382:20 - not so it looks like I
382:23 - think that if we can find this tab back
382:25 - I think we can name this whatever we
382:26 - want here this doesn't actually have to
382:28 - be called storage account so we can go
382:30 - here it's just a logical name that we
382:32 - reference within this resource so I can
382:34 - go here and say like storage account AB
382:36 - it shouldn't
382:38 - matter um what's really interesting up
382:40 - here is that it's going to looks like
382:42 - it's going to grab the resource Group ID
382:46 - and then what does it do here creates a
382:48 - deterministic hash based on the string
382:49 - so it uses the resource ID to make a
382:51 - random string and then it's going to say
382:53 - toy launch in the front of it so I don't
382:55 - want toy launch I'm just going to put in
382:56 - here bicep and so um I think we can do
383:00 - hyphens actually I don't think we can
383:03 - and so we should get in Azure storage
383:05 - account that's going to be bicep and
383:06 - some random value after this and then up
383:09 - here this is going to pull in the
383:11 - resource Group now what's interesting is
383:13 - we haven't created a resource Group it
383:15 - says return the current Resource Group
383:17 - scope so I'm not sure how this is going
383:18 - to work if we don't have an existing
383:20 - Resource Group but anyway we've written
383:22 - our Azure bicep and we probably want to
383:24 - go ahead and uh deploy this now so we
383:27 - could probably just type in bicep down
383:29 - below that's probably what the command
383:31 - is nope that's not what it is
383:35 - um maybe it's what is it I don't know so
383:38 - let's go over to um back over here for a
383:41 - second and let's see what the CLI
383:43 - commands
383:46 - are oh boy we'll say bicep
383:53 - CLI what is the commands just tell me
383:55 - what the commands are please we could
383:57 - use the command pallet because they're
383:59 - probably all there like if we're if we
384:01 - were to go into the command pallet and
384:03 - type in bicep
384:05 - like we get all those commands but I I
384:07 - really want to know what the um CLI
384:10 - commands are I really thought it would
384:11 - be bicep it is a z bicep of course so
384:14 - looks like we can do um a bicep and then
384:17 - just specify the template probably main
384:19 - is the default so if we do nothing it
384:22 - probably will pick that up I'm going to
384:23 - go ahead and type in that and so it's
384:26 - interesting we installed the extension
384:28 - and we were able to log in but we still
384:30 - don't actually have uh the CLI so it
384:32 - looks like we do actually have to
384:34 - install the Azure CLI in here which is
384:36 - fine it's always great to get more
384:38 - practice so we'll go ahead and type in
384:39 - Azure CLI install we'll go to the
384:42 - Microsoft learn website we will scroll
384:44 - to uh Linux we'll go to auntu Debian um
384:48 - because that's generally what get pod or
384:50 - code spaces or what have you will be
384:52 - using we'll go down look for that one
384:54 - liner and we'll copy it we'll go back
384:57 - over to um code spaces we'll paste this
384:59 - in hit enter and that'll go ahead and
385:01 - install the uh Azure CLI now we are
385:05 - logged in in this um uh invidual Studio
385:08 - code and it could be storing the same
385:10 - credential files wherever on the local
385:13 - machine um so maybe we don't have to
385:16 - necessarily log in twice it might be
385:19 - also interesting to see where that um
385:21 - that file is so maybe we can go ask chat
385:22 - gbt where does um where does okay so
385:29 - when you log into the Azure CLI where
385:33 - does store the
385:36 - credentials what folder and file on the
385:39 - Linux
385:41 - machine that's what we want to
385:48 - know and uh the only thing I don't like
385:50 - about chbt is that you can't go away
385:52 - from uh this tab while it's
385:55 - generating and then sometimes it just uh
385:58 - gets a bit slow but it goes out to the
385:59 - Internet so I think that's the reason
386:01 - why it's uh been slower than previous I
386:03 - like previous mod models where it wasn't
386:05 - out on the internet because it could
386:06 - generate out
386:08 - faster but
386:10 - uh yeah this one's hanging on me so
386:12 - let's
386:13 - go to 3.5 let's just ask this one I want
386:17 - it
386:19 - fast okay so it's saying it's in the
386:22 - Azure folder so that's something that we
386:23 - might want to take a quick look at the
386:25 - Azure CLI is installed I'm going to just
386:27 - type in a um
386:29 - account um account list and see if we
386:33 - can list our accounts
386:35 - okay so we are not logged in so us
386:38 - logging in here uh wherever it's storing
386:40 - it's definitely not storing in the same
386:42 - place but let's go take a look at that
386:43 - Azure profile directory so I'm going to
386:45 - bump up the font a bit I realize it's
386:47 - really small and I'm going to go ahead
386:49 - and say CD and then make a Tilda that is
386:53 - above your tab key and you have to press
386:55 - shift to make it it's called a Tilda
386:57 - it's like a little squiggly we'll do a
386:59 - for slash I'm going to do period for a
387:01 - hidden folder and we're start start
387:03 - typing Azure and so that folder is there
387:04 - we'll hit enter I'm going to do LS to
387:06 - list out the contents and we have stuff
387:08 - here I can do LS hyphen LA to list it in
387:11 - a nice beautiful list and uh if we don't
387:14 - want no that looks fine and so I'm kind
387:16 - of interested where it's storing uh that
387:19 - configuration probably in the config
387:21 - directory so I'm going to just CD into
387:26 - config uh oh maybe it's not a folder I
387:31 - thought that was a folder it is not a
387:33 - folder Okay so let's do cat to print out
387:35 - the
387:36 - contents cat stands for C Cate I think
387:40 - and so that doesn't store it does a does
387:44 - the a Json file have it NOP that doesn't
387:46 - have it but to be fair we haven't logged
387:49 - in yet so maybe the file will appear
387:50 - after we log in so that's okay what I'm
387:53 - going to do is go ahead and type in a
387:55 - login and we'll say use device code
387:57 - because I believe that's the flag we
387:59 - have to use and we'll go ahead and copy
388:02 - this link we'll go to the top here and
388:04 - paste it in to one of our available tabs
388:07 - if we have to go back and uh provide
388:10 - this
388:12 - code and we'll go click next and we'll
388:15 - click on our account we'll say continue
388:18 - we'll go back over to here and we'll
388:20 - give it a moment to think there we go we
388:23 - are logged in so now what I want to do
388:24 - is type in LS and looks like there's
388:27 - more stuff there it looks like there is
388:30 - and did we have this before uh
388:35 - um let's see here 1 two 3 four five six
388:38 - seven 8 nine 10 1 two 3 four 5 6 7 8 9
388:43 - 10 11 12 yeah there's definitely more
388:45 - stuff here um the new thing that's here
388:47 - is Cloud's config so I'm just going to
388:49 - cat that let's see what's in there so Le
388:52 - tells us this is our default
388:54 - subscription so we at least know where
388:55 - that's coming from let's cat the config
388:57 - let's see if anything's Chang in there
388:58 - that's the same let's cat a Jason
389:03 - Json there's still nothing in
389:05 - there so it'd be really nice to know
389:08 - exactly where it is normally other ones
389:10 - will tell you exactly where they are uh
389:13 - and you can literally open them up and
389:14 - see see the information there I guess we
389:17 - could also just cat out the session no
389:20 - nothing so anyway it is stored
389:23 - somewhere where it is I don't know does
389:25 - it really matter no but it's nice to
389:28 - know exactly where it is so that uh
389:29 - let's say you wanted to delete it off
389:31 - your computer or something but it's
389:33 - stored somewhere where anyway um we are
389:36 - we should now be logged into Azure so
389:38 - we'll go ahead and type in Azure a bicep
389:41 - I still feel like it should have told us
389:42 - the commands even if we weren't logged
389:44 - in and I was hoping that it would print
389:47 - us out the sub commands let's try to do
389:49 - help and see if it actually does that
389:51 - okay so it does you just have to give it
389:52 - the help flag and so we have a few
389:54 - options we can do build a bicep
389:56 - file um build the bicep pramp file
390:02 - decompile so like we already have an arm
390:04 - template we could turn it back into a
390:05 - bicep file that sounds really cool I
390:07 - like that idea format a bicep file you
390:10 - know if there's something wrong with it
390:11 - it could tell us as the format's correct
390:12 - install uh the bicep CLI which I thought
390:16 - it already was installed let's go ahead
390:17 - and try that first because maybe that's
390:20 - why I couldn't just type in
390:21 - bicep okay so now what happens if I type
390:24 - in
390:24 - bicep no so why did I install it if it
390:28 - was already like that um bicep I'm
390:33 - hitting tab autocomplete to see if
390:34 - anything's there bicep
390:37 - CLI well whatever I mean we kind of
390:41 - still already have it so that's totally
390:42 - fine so we'll go ahead and type in bicep
390:44 - a uh uh a bicep
390:49 - build and it wants a file totally fine
390:52 - so we're going to give it a file U build
390:55 - the file build a file and print all of
390:56 - its outputs to SD
390:58 - out I don't think it matters if we print
391:00 - them out so before we do that I just did
391:03 - control C to uh break that we need to
391:05 - get back to our main folders I'm doing
391:07 - CD dot dot and I'm doing
391:12 - LS where is this
391:14 - folder CD for uh Aster for uh forward
391:18 - slash I'm so used to using git pod I
391:20 - can't remember where uh this directory
391:22 - is I'm just going to scroll up here and
391:24 - take a look it is workspaces okay so to
391:27 - get back to this
391:28 - folder okay we're going to go to cd/
391:31 - workspaces I'm hitting tab to
391:33 - autocomplete
391:34 - and then this one's called Azure
391:36 - bicep
391:38 - um is really not autoc comp completing
391:40 - here today oh I spelled Azure wrong okay
391:43 - that explains that I'll go fix that in
391:46 - the um the git pod I'll just rename it
391:49 - but now we're back into here so um
391:51 - typing clear so we're going to go Azure
391:54 - bicep file and we're going to provide it
391:57 - main TF or I'm thinking terraform bicep
392:00 - we'll hit enter and so that's going to
392:01 - go ahead and build it um is misspelled
392:05 - or does not recognize is not recognized
392:08 - by the
392:09 - system um okay we'll type in LS I mean
392:13 - it's right there let's go back and and
392:15 - take a look at the documentation and see
392:17 - what it wants sometimes it might want um
392:21 - uh like the file information but I don't
392:23 - think so it just shows main
392:26 - bicep I'll copy this command
392:35 - oh I forgot the word build up here
392:37 - that's why so um it looks like it's now
392:40 - built and so we now have a main Json
392:42 - we'll take a look here and it's
392:44 - generated us an arm
392:46 - template at least that's what it looks
392:49 - like yep that's what it is so that looks
392:52 - pretty good um I'm noticing
392:54 - that yeah we have parameters up here so
392:58 - now we can go ahead and deploy
393:02 - this so builds it
393:06 - see here uh we can build our build pram
393:08 - file not interested in that generate
393:11 - prams and install the commands to your
393:17 - CLI oh publish maybe that's it the
393:20 - publish command adds a module to the
393:22 - registry the Azure container registry
393:24 - exists I'm not sure if that's useful I
393:27 - think that's if we want to reuse a
393:28 - template for later kind of like how we
393:30 - had those template specs I think
393:37 - okay so if as your bicep just generates
393:40 - out the files I'd imagine that we just
393:43 - probably deployed the regular way using
393:44 - arm templates so I'll be back in just a
393:46 - moment most other I tools like they'll
393:48 - let you build end deploy but maybe Azure
393:51 - bicep just compiles out templates just
393:53 - give me a moment yeah so I just quickly
393:56 - asked um chat gbt and yes it did confirm
393:59 - it I my suspicions were correct AZ your
394:01 - bicep is just draining out the resource
394:03 - template and it looks like we're going
394:04 - to have to deploy it the regular uh or
394:06 - oldfashioned way here um so now here's a
394:10 - question could we actually use um Visual
394:13 - Studio code to deploy this so if I right
394:15 - click
394:16 - this um could we deploy somewhere with
394:20 - this so that's what I'm really curious
394:24 - about let me go find all right so I
394:28 - believe there's a few ways we can do
394:29 - this of course we could go and just
394:31 - deploy the uh the fashion way by using
394:34 - this a deployment group um I was looking
394:37 - around myself and I just typed in bicep
394:40 - here and I also noticed that they had
394:42 - um uh a deploy step so maybe it can do a
394:46 - direct deploy not maybe not through the
394:48 - CLI but maybe it can do it through
394:49 - Visual St the code there should be one
394:51 - for arm templates in here it's not
394:54 - showing up I mean chat gbt seems to
394:56 - think that it can but maybe there is a
394:58 - another extension we're missing so let's
395:00 - type in uh azure
395:04 - so we have Azure tools is there one for
395:10 - developer um let's go back here and take
395:13 - a
395:14 - look so there's one here it says Azure
395:17 - resource manager oh it's an extens well
395:20 - I thought that'd be installed ready then
395:22 - that would be a really useful one to
395:23 - have here so we'll say Azure resource
395:25 - manager I thought it was there but I
395:27 - didn't see it on the side so this seems
395:28 - like a really good plugin this is
395:30 - probably something I'd want to have
395:31 - let's go ahead and install this one 1.5
395:33 - million views yeah I believe so it's by
395:36 - Microsoft I'm surprised it doesn't get
395:37 - installed with the tools oh it's in
395:39 - preview okay so I imagine when this is
395:43 - out of preview I bet when you install
395:45 - Azure tools it will uh be installed
395:47 - there now I've said previously if
395:49 - there's a preview tool you should try to
395:50 - avoid it because it might not be there
395:52 - in the future um this one I think we can
395:56 - kind of get away with utilizing it it
395:57 - might be the future and it's no longer
395:59 - in preview so we'll go over back over to
396:03 - here
396:04 - and do we have any changes
396:07 - here no but if we go into our Command
396:10 - pallet let's type in arm deploy
396:14 - now it was saying that uh that something
396:18 - we could do aure resource
396:23 - manager uh install this
396:29 - extension type in arm deploy in our
396:32 - Command pallet did
396:38 - that yeah so it doesn't show up so you
396:41 - know preview feature uh chbt might be
396:44 - telling us something else we are using
396:46 - 3.5 so it might not be telling us the
396:48 - full truth there and I don't really see
396:51 - any changes on here so I guess we're not
396:53 - going to worry about that but I would
396:55 - like to try the um the bicep deploy so
396:57 - we'll type in just deploy
396:59 - here and scroll on down we we have
397:03 - deploy bicep file let's see what happens
397:05 - if we do that and
397:08 - so please enter the name of the
397:10 - deployment sure we have to name the
397:12 - deployment good um create a resource
397:15 - Group because remember that we didn't
397:16 - specify Resource Group so we'll have to
397:18 - create one on the Fly here so let's do
397:19 - that we'll call this my bicep RG RG for
397:24 - Resource Group it's now going to go
397:27 - ahead and deploy that it says deploy
397:29 - failed uh provider description does not
397:32 - have the resource type resource
397:36 - groups
397:38 - okay that is something I was not
397:41 - expecting let's
397:43 - go let's go ask Chacha BT and try to
397:46 - save us some
397:52 - time says check your bicep template file
397:55 - ensure that you have defined the
397:56 - resources correctly that is not
397:58 - useful um maybe it's because it's not
398:01 - registered so maybe when we use the CL
398:04 - uh when we use the the UI it will
398:06 - automatically register things when we
398:08 - use it but we create resource groups all
398:10 - the time so it's kind of surprising if
398:12 - that wouldn't be registered so we'll go
398:13 - over to our
398:15 - subscription and I'm just going to
398:16 - double check this here but I'm not sure
398:18 - if it's going to make a difference we'll
398:20 - go over to
398:23 - our yeah we're in our
398:26 - subscription I'm looking
398:28 - for
398:32 - providers there it is resource providers
398:34 - sometimes there's like another extra um
398:37 - blade they call these blades over here
398:38 - by the way and so I was getting a bit
398:40 - confused and so Chachi BT is
398:45 - suggesting maybe resources is not
398:48 - registered which to me seems
398:50 - crazy oh it is it's right there uh so
398:53 - I'm not exactly sure what it's
398:55 - complaining about the other thing is
398:56 - that maybe as your BP isn't logged in so
399:00 - I mean that seems like a possible option
399:02 - so maybe we'll just go stick with uh the
399:04 - usual way which is using the Azure um
399:08 - the this Azure deploy method so I'm
399:10 - going to scroll back up here and we have
399:11 - this command now we did install in here
399:15 - uh in extensions or I think it it came
399:17 - installed was the Azure CLI and what
399:20 - that will do is it when we write it out
399:22 - Azure CLI commands I believe it will
399:24 - autocomplete for
399:26 - us so here's scrapbooks for developing
399:28 - running commands with a CLI create an
399:30 - Azure CLI files and use the following
399:32 - features oh okay okay so there's
399:34 - actually a thing called an Azure CLI
399:36 - file that's new to
399:38 - me um but what we'll do is we'll go
399:40 - ahead and we'll just say um new file so
399:43 - we just say
399:45 - commands and I'll just put that there
399:48 - rename that like that that's what it's
399:50 - saying to do and so you'll say uh deploy
399:54 - an arm
399:57 - template and we'll go back over here and
400:01 - we'll see if it starts to autocomplete
400:02 - so we have a uh
400:05 - deploy it's not really completing
400:07 - correctly as just demonstrated we'll go
400:10 - back over here and take a look at that
400:12 - again
400:15 - so yeah this one says demo. asli they're
400:18 - making a
400:20 - comment so intellisense for commands and
400:23 - their arguments s and
400:25 - commands scrapbooks for uh developing
400:28 - running commands in the Azure
400:30 - CLI okay then work properly please maybe
400:35 - it's not
400:36 - installed oh we have to install it sorry
400:39 - I thought we already had it installed
400:40 - that's why so we'll go back over here
400:43 - and so now our common is showing up so
400:45 - we'll type a
400:48 - deployment
400:49 - um I mean we probably want to create
400:53 - right it will have to have a name so
400:55 - we'll just say my RG my
401:01 - bicep um deployment
401:04 - they'll probably have to have a location
401:05 - so let's just
401:08 - say probably should place it in the same
401:10 - place as this one this does not have a
401:12 - particular location so probably default
401:14 - to wherever the resource Group is yep so
401:17 - we say um it's East us there we go
401:22 - there's probably something else we need
401:24 - I'm not really sure let's go back and
401:26 - see what chat GPT was asking for uh the
401:28 - template of course
401:35 - um we'll say
401:37 - template and it technically is a
401:40 - file so we'll go here and say main J
401:44 - Json and by the way we could bring these
401:46 - down onto new lines with this backlash
401:48 - that allows us to have multiple lines in
401:51 - our bash
401:53 - terminal okay and it also probably wants
401:56 - the resource groups so we'll go here and
401:57 - type in
401:59 - resource it can't do multi-line
402:05 - it is not autocomp
402:07 - completing
402:09 - anymore Resource Group maybe we just hit
402:11 - the limit of it
402:19 - there uh so I I assume that it could
402:21 - handle multi-line but I guess when we're
402:23 - doing multi-line then uh the Intel sense
402:26 - the auto completion is it can't handle
402:28 - it so we'll go back over to here and I
402:30 - just forgot what we called that Resource
402:32 - Group we actually did did create one uh
402:34 - but Azure bicep did fail the deploy
402:36 - because of some kind of permissions or
402:38 - settings so I just want to go quickly
402:40 - find that name again notice that
402:43 - sometimes in Azure you have to be
402:45 - patient super super super common uh to
402:49 - wait around for Azure um because of
402:51 - propagations in their UI super
402:54 - common my internet's totally fine it's
402:57 - it's Azure and it's back here says an
402:59 - error occurred when trying to fetch
403:00 - resources additional details from the
403:02 - underlying API might be help helpful are
403:04 - we having an issue with
403:06 - service so sometimes that happens so we
403:09 - could like uh Microsoft status
403:12 - page sometimes that happens and I got to
403:14 - walk away come back to my
403:20 - computer but uh maybe it's not because
403:22 - my internet seems to be funny
403:26 - so but if that's the case
403:29 - then oh yeah it's me I'll be back in a
403:32 - moment okay
403:33 - all right so uh my internet should be
403:35 - back here I'm just reopening my
403:38 - connection here to my code spaces and
403:41 - I'm going to go back over to here and
403:43 - we'll give it a refresh and so I guess
403:46 - that Resource Group did not create so we
403:48 - do definitely have to create a resource
403:49 - Group first otherwise it's not going to
403:51 - know what to deploy
403:53 - into and I'm hoping that this uh
403:56 - reconnects or it's still
403:58 - running so but uh what I'll do here
404:01 - while we're waiting is I'm going to
404:02 - create a new res group I'm going to call
404:04 - this one my
404:06 - bicep
404:08 - RG and we'll go ahead and review and
404:11 - create and we'll go ahead and create
404:13 - that we'll go back over to our other tab
404:16 - here I would really like it to reopen
404:18 - here I'm not sure what it's doing to
404:20 - figure this out going to go at the top
404:22 - just type in
404:33 - it seems real mucked up here so I'm G
404:36 - have to go
404:37 - back and we'll just have to type in
404:39 - bicep
404:41 - here it's under exam Pro so I'll drop
404:44 - that down of course you'll only have one
404:47 - so we'll go into here and let's see if I
404:48 - can find that that previously working
404:50 - code space environment so it's here it
404:52 - is active I'm going to go back and say
404:55 - open in the browser notice you can
404:57 - launch this IND Visual Studio code
404:58 - locally or if you want to use Jupiter
405:00 - Labs let's say you're doing something
405:01 - with a or something or machine learning
405:04 - you could do that so this should open
405:06 - back up our environment there we go
405:09 - that's
405:11 - great and um so we created that new
405:14 - Resource Group that's called this here
405:15 - so I'm going to go ahead and copy that
405:17 - and I'm going to paste it into here
405:19 - sometimes it's good to put double
405:20 - quotations around these things I'm not
405:21 - doing that unless that gives us problems
405:23 - so I think this is everything we need we
405:25 - need to know um the resource Group uh
405:28 - it's probably recommended to provide it
405:30 - a name we'll have our location and our
405:33 - template file so I'm going to go ahead
405:34 - and copy this and fingers cross this
405:36 - works uh of course we didn't really look
405:38 - anything up um oh this one says a
405:41 - deployment group create so maybe we
405:43 - should make sure that's
405:45 - correct but it did autocomplete create
405:48 - so
405:50 - maybe maybe that's okay well wait why is
405:54 - one deployment group wouldn't that
405:55 - create hold on we can hover over here
405:57 - and get some stuff manage the AER
405:58 - resource template uh deployment at the
406:00 - resource Group okay
406:05 - oh that's really cool if you hover over
406:06 - it tells you everything
406:09 - there well what happens if I take this
406:11 - name out then does this still
406:14 - complete starts a deployment at the
406:16 - subscription scope so maybe both both
406:19 - Works let's just see what happens it's
406:21 - really nice that it shows everything
406:23 - like that I really like that we'll go
406:24 - ahead and paste that in we'll hit
406:27 - enter and um it's showing we're missing
406:31 - an argument Resource Group argument
406:33 - it doesn't like that
406:38 - one starts a deployment creates a
406:41 - deployment the resource
406:46 - Group okay so here we have a create and
406:49 - then we have starts a deployment the
406:51 - subscription scope creates a deployment
406:53 - at the resource Group from a local file
406:54 - template so it looks like if we already
406:57 - have one maybe this one would have
406:58 - created a resource Group for us so what
407:00 - we're going to do is take this one out
407:02 - as I really thought we needed to have it
407:03 - but I'm going to go and see what happens
407:05 - if we do
407:07 - this the template resource location at
407:10 - line 12 uh line 17 is not is invalid the
407:13 - template function Resource Group is not
407:15 - expected at this
407:17 - location um okay it's it's not there I
407:19 - didn't put it in the
407:21 - template
407:23 - so okay well what I'm going to do is
407:26 - undo and type in group so I guess you
407:29 - got to be really careful when entering
407:30 - stuff in because it's going to give you
407:32 - some trouble and this one looks a little
407:34 - bit more normal with the group create so
407:36 - we have template file Resource Group I
407:38 - don't know if it needs a
407:40 - name so maybe I'll just take the name
407:43 - out and then we'll try this
407:46 - one and we'll hit
407:50 - enter
407:53 - and unrecognized arguments no
407:58 - location well I mean this one has it and
408:01 - this one doesn't okay we'll take the
408:03 - location out we'll try this well I guess
408:05 - we don't have to specify a location
408:07 - because we've already created the
408:08 - resource Group that's why so we'll try
408:10 - this
408:11 - again making a lot of trouble
408:14 - here but it's a good way to learn this
408:16 - is how you should learn and this is this
408:17 - is what Cloud's like just goofing around
408:20 - till get till we get it to work and then
408:22 - hopefully it's it's the right way um so
408:25 - this is going to go ahead and run and
408:27 - we'll wait here I'm not going to make
408:28 - you uh watch watch it here I'll be back
408:31 - uh here in a moment okay all right after
408:34 - a little bit of waiting um our terminal
408:36 - has produced some stuff for us so it's
408:38 - suggesting it probably created the
408:39 - resource so we're in good shape let's go
408:41 - back over to Azure and we're going to go
408:43 - into our bicep RG and we now have our
408:47 - resource so we've success successfully
408:49 - used um Azure biceps so let's go ahead
408:51 - and delete this Resource Group we are
408:53 - all done here um we're going to go ahead
408:56 - and commit what we have so that uh any
408:58 - future folks that are trying to do the
408:59 - same thing as us can just go get that
409:00 - code base uh good stuff here go ahead
409:04 - hit commit sync the changes we'll say
409:06 - okay that will push the changes
409:09 - excellent and I'm going to want to stop
409:11 - this workspace we'll open up the command
409:12 - pallet we'll say
409:15 - stop uh so say code spaces stop code
409:20 - spaces stop current workspace there we
409:22 - go and that will stop the current
409:24 - workspace so that is all good right
409:27 - there um and I'm going to fix the name
409:30 - here because it really should be named
409:32 - correctly so that you can easily find it
409:34 - in the
409:36 - future just be more patient and make
409:38 - sure you don't make mistakes and try to
409:39 - fix them the best you can but yeah that
409:41 - is azure bicep and we'll see you in the
409:44 - next one
409:46 - [Music]
409:49 - okay hey this is Andrew Brown from exam
409:52 - Pro in this segment we'll delve deep
409:54 - into Azure key Vault a pivotal tool to
409:56 - ensure the security of your Cloud
409:58 - applications and services Azure key
410:00 - helps you Safeguard cryptographic keys
410:02 - and other Secrets used by Cloud apps and
410:04 - services Azure key VA focuses on three
410:07 - things certificate management this
410:10 - feature allows for easy provision
410:11 - management and deployment of both public
410:13 - and private SSL certificates these
410:15 - certificates can be used with Azure and
410:17 - internally connected resources Key
410:19 - Management this enables the creation and
410:22 - control of encryption Keys used to
410:23 - encrypt your data Secrets management
410:26 - here you have a secure space to store
410:28 - and tightly control access to tokens
410:30 - passwords certificates API keys and
410:32 - other Secrets note that certificates
410:35 - contain a key pair which is a
410:36 - combination of a key and a secret this
410:38 - should not be confused with key
410:40 - management and secrets management which
410:41 - are distinct
410:43 - functionalities moving forward let's
410:45 - talk about hsms or Hardware security
410:48 - modules these are dedicated Hardware
410:50 - devices specifically designed to
410:51 - securely store encryption Keys when it
410:54 - comes to adhering to standards we
410:56 - reference the federal information
410:57 - processing standard or fips this is a
411:00 - guideline recognized by the US and
411:01 - Canadian government that specifies the
411:03 - security requirements for cryptographic
411:05 - modules that protect sensitive
411:07 - information in line with fips we have
411:09 - two levels of compliance for hsms fips
411:12 - 104 diminus 2 level two compliant this
411:15 - compliance level is for multi-tenant
411:16 - hsms where multiple customers are
411:18 - virtually isolated on a single HSM fips
411:22 - 104 minutus 2 level 3 compliant this
411:24 - level on the other hand pertains to
411:26 - single tenant hsms where One customer
411:28 - utilizes a dedicated HSM in essence as
411:31 - your key vault is an indispensable tool
411:33 - for ensuring that your cloud data
411:35 - remains both accessible and secure
411:37 - whether you're working with certificates
411:38 - encryption keys or various Secrets Azure
411:41 - key Vault has you
411:43 - [Music]
411:46 - covered all right let's dive into the
411:49 - core of azure key Vault The Vault itself
411:51 - a vault is where your secrets and keys
411:53 - reside safeguarded either by software or
411:55 - by hsms validated to the standards of
411:57 - fips 1004 toin 2 level two Azure key
412:00 - vaults provides two types of containers
412:03 - vaults these containers support both
412:05 - software and HSM back Keys HSM pools
412:08 - these are specialized containers solely
412:10 - for HSM back keys to activate your HSM
412:13 - you will need to provide a minimum of
412:15 - three RSA key pairs up to a maximum of
412:18 - 10 and specify the minimum number of
412:20 - keys required to decrypt the security
412:22 - domain called a quorum you do not choose
412:25 - the container on creation you just
412:26 - choose between standard and premium when
412:28 - you choose premium and create enough RSA
412:30 - key pairs you will begin to use a HSM
412:33 - pools diving a bit into technicalities
412:36 - Azure key Vault rest API is used for
412:38 - programmatically managing Azure key
412:39 - Vault resources allowing you to perform
412:42 - operations such as create a key or
412:44 - secret import a key or secret revoke a
412:47 - key or secret delete a key or secret
412:50 - authorize user or apps to access its
412:51 - keys or secrets and monitor and manage
412:54 - key usage Azure key Vault rest API
412:57 - supports three different types of
412:58 - authentication managed identities and
413:01 - identity managed by a a d recommended as
413:03 - best practice service principle and
413:06 - certificate this method uses a
413:07 - certificate for authentication Service
413:10 - principle and secret a combination of a
413:12 - user identity and a secret key one
413:15 - feature to note is the soft delete
413:17 - functionality soft delete allows you to
413:19 - recover or permanently delete a key
413:20 - vault in secrets for the duration of the
413:22 - retention period this feature is enabled
413:24 - by default on creation mandatory
413:27 - retention period prevents the permanent
413:29 - deletion of key vaults or Secrets prior
413:31 - to the retention period elaps
413:33 - furthermore enabling Purge protection
413:35 - safeguards your secrets from being
413:36 - prematurely purged either by users or by
413:39 - Microsoft bolstering the security of
413:41 - your
413:43 - [Music]
413:46 - Vault next up on our agenda is breaking
413:48 - down the pricing of azure key Vault
413:50 - knowing how your bill for this service
413:52 - can help you make informed decisions and
413:54 - optimize your costs Azure key Vault
413:56 - offers two pricing tiers standard and
413:58 - premium the notable distinction between
414:00 - the two is that while both tiers support
414:02 - software protected Keys only the premium
414:04 - tier allows for HSM protected Keys
414:07 - here's a closer look at the pricing
414:09 - tiers first 250 Keys regardless of
414:12 - whether you're on the standard or
414:13 - premium tier you'll be built $5 per key
414:15 - every month
414:18 - 25115 Keys the price drops to $2.50 per
414:22 - key monthly again consistent across both
414:24 - tiers 1501 to 4,000 Keys the cost
414:27 - further reduces to 90 cents for each key
414:29 - every month 4,000 1 plus keys for larger
414:33 - key volumes Beyond this point you'll be
414:34 - charged at a rate of 40 cents per key
414:36 - per month Secrets operations both tiers
414:39 - are priced at three cents for every
414:41 - 10,000 transactions involving Secrets
414:44 - certificate operations exclusive to the
414:46 - premium tier each certificate renewal
414:48 - request is build at $3 managed Azure
414:51 - storage account key rotation this
414:53 - service only available in the premium
414:54 - tier is priced at $1 per renewal HSM
414:58 - protected Keys specifically for HSM
415:00 - protected Keys the pricing is further
415:02 - broken down based on the key types for
415:05 - RSA 2048-bit Keys the cost is $1 per key
415:08 - per month along with an additional
415:09 - charge of 3 cents per 10,000
415:11 - transactions for RSA 3072 bit and
415:14 - 4096-bit keys as well as ECC Keys the
415:17 - first 250 keys are priced at $5 per key
415:20 - per month so that's an overview of the
415:23 - pricing model for Azure key
415:29 - Vault the next topic we'll be covering
415:32 - is double encryption for Azure key Vault
415:34 - before we dive in let's quickly recap
415:36 - infrastructure encryption for storage
415:38 - accounts by default Azure ensures that
415:40 - your storage account data is encrypted
415:42 - when it's at rest infrastructure
415:43 - encryption adds a second layer of
415:45 - encryption to your storage accounts data
415:47 - now let's jump into Azure diss double
415:49 - encryption double encryption is
415:51 - precisely what it sounds like it's where
415:53 - two or more independent layers of
415:55 - encryption are enabled to protect
415:56 - against compromises of any one layer of
415:58 - encryption this strategy ensures that
416:01 - even if one encryption layer is
416:02 - compromised the data remains protected
416:04 - by the other Microsoft has a two-layered
416:07 - approach both for data at rest and data
416:09 - in transit for data at rest disk
416:12 - encryption this is achieved using
416:13 - customer managed keys and infrastructure
416:16 - encryption this uses platform managed
416:18 - Keys strengthening the base layer and
416:20 - for data in Transit Transit encryption
416:23 - using transport layer security 1.2 to
416:25 - safeguard data as it travels through
416:27 - networks and an additional layer of
416:29 - encryption provided at the
416:30 - infrastructure layer so that's a quick
416:33 - overview of double encryption for Azure
416:35 - key
416:39 - vault in this section we'll go into
416:42 - detail on the keys and Azure key Vault
416:44 - when it comes to creating a key in Azure
416:46 - you have three primary choices generate
416:49 - Azure will generate the key for you
416:51 - import import an existing RSA key that
416:53 - you already possess and restore backup
416:55 - restore a key from backup for Keys
416:58 - generated by Azure you can use either
417:00 - RSA or EC RSA or rivest shamier Adelman
417:04 - this supports key sizes of 2048 3072 and
417:07 - 4096 bits EC or elliptic curve
417:10 - cryptography here you can select from
417:13 - p256 P 384 p521 or p256 k for Keys
417:19 - generated by Azure you can set an
417:21 - activation and expiration date
417:23 - additionally you're not bound to a
417:24 - static version of a key you can create
417:26 - new versions of keys you can also
417:29 - download backups of keys but remember
417:31 - that backups can only be restored within
417:33 - the same Azure subscription and within
417:35 - Azure key Vault when you have a premium
417:37 - Vault you'll key options for HSM you can
417:40 - generate either an RSA or EC
417:42 - specifically for HSM or import an RSA
417:45 - key for HSM as shown in the
417:47 - example now let's talk about Key
417:50 - Management types Microsoft managed key
417:52 - or Keys managed by Microsoft they do not
417:55 - appear in your Vault and in most cases
417:56 - are used by default for many Azure
417:59 - services customer managed key are Keys
418:01 - you create in aure key Vault you need to
418:03 - select a key from a vault for various
418:05 - Services sometimes customer manage means
418:08 - that the customer has imported
418:09 - cryptographic material and any generated
418:11 - or imported keys are considered cmk and
418:13 - Azure in order to use a key an Azure
418:16 - service needs an identity established
418:17 - with an Azure ad for permission to
418:19 - access the key from The Vault
418:21 - Additionally you have the option to
418:23 - implement infrastructure encryption
418:25 - while Azure already encrypt storage
418:26 - account data at Rest by default opting
418:28 - for infrastructure encryption adds a
418:30 - second layer of security for ifying your
418:32 - storage accounts data even
418:38 - further the next topic we'll be covering
418:40 - our secrets in Azure key Vault Azure key
418:43 - Vault Secrets provide Secure Storage of
418:45 - generic Secrets such as passwords and
418:47 - database connection strings key Vault AP
418:50 - has accept and return secret values as
418:52 - strings internally key Vault stores and
418:54 - manages Secrets as sequences of octets
418:57 - with each secret having a maximum size
418:59 - of 25k bytes the key Vault service does
419:02 - doesn't provide semantics for Secrets it
419:04 - accepts the data encrypts it stores it
419:06 - and returns a secret identifier for
419:08 - highly sensitive data clients should
419:10 - consider additional layers of protection
419:12 - for data for example encrypting your
419:14 - data using a separate protection key
419:16 - before storing it in the key Vault heal
419:19 - also supports a content type field for
419:21 - Secrets allowing clients to specify the
419:23 - content type of a secret to assist in
419:25 - interpreting the secret data when it's
419:27 - retrieved note that the maximum length
419:29 - of this field is 255 characters
419:32 - every secret stored in your key vault is
419:34 - encrypted key vault encrypt Secrets at
419:36 - rest with a hierarchy of encryption Keys
419:39 - all keys in that hierarchy are protected
419:41 - by modules that are fips 104in 2
419:43 - compliant the encryption Leaf key is
419:45 - unique to each key Vault while the root
419:47 - key is unique to the entire security
419:49 - world the protection level may vary
419:51 - between regions for example chid uses
419:54 - fips 1004 diminus 2 level one and all
419:57 - other regions use level two are higher
419:59 - diving into secret attributes we have X
420:02 - this is the expiration time after which
420:04 - the secret data should not be retrieved
420:06 - NBF not before default value is now this
420:10 - defines the time before which the secret
420:11 - data should not be retrieved enable this
420:14 - tells us whether the secret data can be
420:16 - retrieved or not with its default set to
420:18 - True additionally there are readon
420:20 - attributes for created an update in
420:23 - order to access Secrets within your
420:24 - application code you can would use the
420:26 - Azure SDK for example we have a net
420:28 - example in this image here another
420:31 - option is is to use tools like Azure CLI
420:34 - so that about covers the important
420:36 - details of secrets in Azure key
420:39 - [Music]
420:43 - Vault hey this is Andrew Brown from exam
420:45 - Pro and in this fall along we're going
420:47 - to be learning all about Azure Vault so
420:50 - let's get to it so what I want you to do
420:52 - is go on the top here and type in key
420:55 - Vault and here we'll have to go ahead
420:57 - and create ourselves a new Vault and so
420:59 - from there we're going to create a new
421:01 - Resource Group I'm going to call this
421:03 - Resource Group my example
421:05 - Vault and then we will make a vault key
421:08 - here so I'll say My Vault example which
421:12 - is kind of funny because this one's
421:13 - slightly different so you've seen I've
421:14 - done this before so I'm going to do my
421:15 - example vault as the name here and for
421:20 - the region Us East is fine for pricing
421:22 - we'll keep it at standard soft delete is
421:25 - enabled um and then there's the option
421:27 - for Purge protection so we are going to
421:31 - enable Purge protection and uh this is
421:34 - going to play into other follow alongs
421:36 - we'll explain that as it goes but Purge
421:38 - protection does not allow you to uh
421:40 - Purge things uh easily once it's enabled
421:43 - so what we'll do is go ahead and review
421:46 - and
421:47 - create and we'll go ahead and go review
421:55 - create and we'll give it a moment here
422:02 - and we'll just wait till it's done
422:03 - deploying okay all right so after a
422:05 - short little wait our vault is created
422:08 - and so what I want you is go to the
422:09 - resource and we're going to be using
422:11 - this Vault a little bit in some of the
422:13 - Fall alongs and in some cases not so
422:15 - much okay
422:34 - [Music]
422:38 - hey this is Andrew Brown and this fall
422:40 - along we're going to be doing some
422:41 - things with uh keys with an Azure key
422:43 - Vault so what I want you to do is make
422:44 - your way over to the Keys blade on the
422:46 - left hand side here we're going to
422:47 - generate or slimport a new key we're
422:50 - going to choose the generate option in
422:53 - terms of naming we're going to call this
422:55 - my dis
422:57 - key and we are going to choose RSA 2048
423:00 - that seems totally fine to me everything
423:02 - else seems okay so we'll go ahead and
423:04 - create that key so we'll give it a
423:07 - moment to create doesn't take too long
423:09 - and then what we're going to do is go on
423:11 - the left hand side to I am access
423:13 - controls and what we're want going to
423:16 - want to do is add a new Ro assignment so
423:18 - we can go ahead and start using this uh
423:21 - key so what I want you to do is go and
423:25 - look for key Vault administrator which
423:28 - is here and we'll go ahead and hit next
423:30 - and then for our uh user we will choose
423:34 - ourself so under user I'm going to
423:36 - select the members I'm looking for the
423:38 - account I'm using there I am and your
423:39 - brown go ahead and select that there and
423:43 - so that is all we need to assign it so
423:46 - that we can actually uh work with that
423:48 - key so I think a good idea is to use a
423:52 - key uh to encrypt a disk so what we'll
423:55 - do is make our way over to dis
423:57 - encryption sets because before you can
423:59 - encrypt a dis you need to have an
424:00 - encryption set so we'll go ahead and
424:02 - create ourselves a new encryption set
424:05 - we'll call we'll use the uh sorry the
424:07 - same um resource Crypt so it's very easy
424:10 - cleanup afterwards we'll call this my
424:13 - disk encrypt set here and in terms of
424:18 - the encryption type we're going to use
424:19 - double encryption because that's much
424:21 - better you have two keys that encrypted
424:23 - so that's a lot better we are going to
424:25 - choose our vault so we have my example
424:28 - Vault there's only one option here and
424:30 - in terms of of the key we'll select my
424:33 - dis key terms of the version uh we'll
424:35 - select the current version we'll go
424:37 - ahead and hit review
424:40 - create and then we will go and create
424:43 - that and we'll give it a moment to
424:45 - create that encryption set shouldn't
424:47 - take too long here and after a short
424:49 - little wait uh our resource should be
424:51 - deployed only it took about a minute for
424:52 - me and if we go here it's going to have
424:54 - this message up here it's very small but
424:55 - it says to associate disk image snapshot
424:57 - this dis encryption set you must Grant
424:59 - permissions to key Vault so all we have
425:00 - to do is click that
425:02 - alert and will grant permissions and so
425:04 - now we are able uh to use that key um or
425:08 - like to to we're going to have the
425:10 - permissions issues is solve so what
425:11 - we'll do is go to type and create a new
425:13 - disk and so we can apply this key to
425:16 - that encryption so we go ahead and
425:17 - create we're going to choose the same
425:20 - Resource Group here I'm going to call
425:22 - this my example Vault and um or sorry my
425:27 - example uh dis so that's a little bit
425:29 - more clear than uh that and for the
425:32 - availability Zone doesn't matter for the
425:34 - source type um it doesn't matter as well
425:37 - in terms of the size we want this to be
425:40 - cheap we're not really using this for
425:42 - real so we'll use standard HDD and we'll
425:45 - say okay in terms of encryption this is
425:48 - where things get fun we go to double
425:49 - encryption we choose our key here we'll
425:52 - go ahead review and
425:55 - create and we'll just give it a moment
425:58 - for that to oh we'll hit create and
426:00 - we'll have to wait a little while here
426:01 - for that create that resource so we'll
426:03 - just wait until that is created okay and
426:06 - after a very short while the dis is
426:08 - ready so we'll go to that resource we'll
426:09 - go to the encryption tab to see that
426:11 - encryption is applied so that's all it
426:13 - takes to use a key to encrypt a disk so
426:17 - we are going to still use some of these
426:18 - accounts there's no clean up yet we go
426:20 - back here and I'll see you in the next
426:24 - [Music]
426:28 - one hey this is Andrew Brown and this
426:30 - fall along we're learn about backup and
426:32 - restore key so what I want you to do is
426:34 - go back into the uh Resource Group that
426:37 - we just recently created and we're going
426:40 - to make our way over to keys so I'm just
426:42 - or sorry we got to get into the Vault
426:44 - first then we'll go over to keys and the
426:46 - idea is that we have this key here and
426:48 - so um you can see that we have this
426:50 - current version so you can add
426:52 - additional versions but what's going to
426:53 - happen if we try to back this up so when
426:56 - you back this up you're going to get
426:57 - this file here and if you open up this
426:59 - file it's going to look like a bunch of
427:01 - gobbly goo so I'm just going to try to
427:02 - open it here um I have it up off screen
427:05 - here so I'm just trying to open it up
427:07 - within uh Visual Studio code so I'm just
427:08 - going to open up visual studio code
427:10 - again doing this offc screen here just
427:13 - give me a
427:14 - moment all right and so this is the file
427:17 - um that we encrypted uh and you take a
427:19 - look here and it's it's doesn't look
427:23 - like anything but the idea is that it is
427:25 - our backup of our key so that we can
427:27 - repport
427:29 - that and just taking a look at the key
427:31 - name this is what it looks like so it
427:33 - says my example Vault my dis key then
427:35 - there's this um uh date and that's key
427:37 - backup so just recognize that's the
427:39 - format and the date is very useful to
427:41 - indicate when you backed it up so let's
427:43 - go ahead and delete this key because the
427:44 - idea is we want to uh restore that
427:47 - backup and so we have deleted that key
427:51 - there and uh what we're going to do is
427:53 - we're going to attempt a Resto so I'm
427:56 - going to go ahead and go
428:04 - occurred while restoring the key the key
428:06 - you're trying to restore already exists
428:08 - why would it throw that error we've
428:10 - clearly deleted it and the reason why is
428:13 - that we have Purge protection on we did
428:15 - that in the um first uh first part when
428:19 - we set up this actual Vault here I'm
428:21 - going to just see if we can find the
428:22 - settings wherever that Purge protection
428:24 - is I'm trying to remember where it is
428:26 - Purge protection is enabled so we can go
428:28 - here and once you enable it you cannot
428:30 - turn it off it's going to retain it for
428:32 - a certain amount of days um and so all
428:34 - you can do is soft delete keys so this
428:38 - key is not actually delete yet if you go
428:40 - to manage deleted Keys you can see the
428:42 - key is over here and if you try to click
428:44 - on Purge it is disabled because we
428:46 - cannot remove the key because we have
428:49 - Purge protection on but we can recover
428:50 - the key so we'll go ahead and
428:52 - recover uh and so that will allow us to
428:56 - recover the
429:00 - key and if we refresh here it's going to
429:03 - take a little bit time for that key to
429:05 - restore so we'll just have to uh wait a
429:07 - little bit and then it will show
429:10 - up here's one other thing I wanted to
429:12 - show you was under policies because you
429:15 - know um if you go under where's policies
429:18 - here um or access policies if you look
429:22 - under our user here and we look at the
429:24 - key permissions um there is an option to
429:27 - purge and we don't actually have that uh
429:29 - turned on right now but if we were to
429:31 - save this and we were to still go to
429:33 - that Purge option it would still say the
429:35 - same thing so even if you have Purge
429:36 - permissions it does not matter if Purge
429:38 - protections turned on it still will not
429:40 - let you purge but you would need a
429:41 - combination of those in order to uh you
429:44 - know be able to do things there so to
429:47 - really show you how to do that recovery
429:49 - I think what we should do I'm just going
429:50 - to delete our old key here because we
429:52 - don't care about it but we are going to
429:55 - well I guess we could try to import it
429:56 - into the other ones I'm just going to
429:57 - undo that for a second but we are going
430:00 - to go ahead and create ourselves another
430:03 - Vault so I'm going to go and type in
430:06 - Vault at the top here and we're going to
430:08 - be a little bit more careful when we
430:09 - create this Vault so we'll go here and
430:12 - we will choose um my example Vault I'm
430:16 - going to say My Vault no
430:21 - protect and the pricing tier will be
430:23 - standard one day we're going to leave it
430:26 - or well seven is the lowest and we'll
430:28 - say disable Purge protection because we
430:30 - don't want to have that
430:32 - enabled and we'll see if we can import
430:34 - the key into another Vault I'm not sure
430:36 - if we can do that worst case we'll make
430:37 - a new key download the key reupload it
430:39 - but I'm just curious what would happen
430:41 - if we tried to upload the same key as
430:43 - it's still in another Vault I'm not
430:45 - exactly
430:48 - sure all right so this deployment is
430:50 - successful I'm going to go to this
430:51 - resource I'm going to go ahead to go to
430:53 - create and we're going to restore from
430:55 - backup and we're going to take this key
430:57 - and see if we can actually import it
430:58 - here so it looks like we can take a key
431:00 - and it can exist in multiple vaults I'm
431:02 - going to go ahead and delete this key
431:05 - and we're going to say are you sure you
431:07 - want to delete this key I'm going to say
431:09 - yes and if we go to manage
431:12 - Keys We refresh it takes a little bit of
431:14 - time here so we'll just wait a moment
431:16 - for this to uh
431:18 - prist and after a short little wait like
431:21 - about 2 minutes I refresh and the key is
431:22 - here so if I go here you'll notice the
431:24 - purges option is still not available we
431:26 - can obviously recover um but we don't
431:29 - have Purge um protection on so if we go
431:32 - to access policies over here and we'll
431:34 - go ahead and scroll down and select
431:35 - Purge and save our changes we can then
431:38 - go back to Keys we'll give it a moment
431:40 - to save we go back to Keys we'll refresh
431:43 - it we'll manage our keys and we'll go
431:45 - ahead and Purge it and that will
431:47 - permanently Purge it there so that's all
431:49 - it takes uh to do that so there you
431:54 - [Music]
431:57 - go hey Andre Brown and we are talking
432:00 - about encrypted Secret so encrypted
432:02 - secrets are variables that allow you to
432:03 - pass sensitive information to your
432:05 - GitHub action workflows secrets are
432:07 - access via the secrets context so that's
432:10 - secret St and then whatever you want
432:12 - your secret is and it has a few
432:14 - different levels we have the
432:15 - organizational level the repo level and
432:17 - the environment level what you need to
432:19 - understand is that the lower the level
432:21 - the more it overrides the ones from the
432:22 - top level so if you have a secret called
432:25 - hello at the organization level and one
432:27 - at the environment level called hello
432:29 - the one at the environment level value
432:30 - will overtake secret names can only
432:33 - contain alpha numeric characters
432:34 - underscores no spaces so that example
432:37 - there would be the the case you can't
432:40 - prefix it with GitHub in all caps with
432:42 - an
432:43 - underscore names must start with numbers
432:46 - sorry I felt like a rumble in my office
432:48 - and that's why I paused uh I think there
432:50 - was just a big train that went by anyway
432:52 - sorry about that um H there we go names
432:56 - are case insensitive names must be
432:58 - unique at the level they are created at
433:01 - people don't know I live right beside a
433:02 - train station and my office is in a shed
433:07 - uh behind my house and the idea is that
433:09 - I have multiple layers to avoid from the
433:11 - train but sometimes there's nothing you
433:13 - can do about it uh but anyway so we have
433:15 - passing Secrets as input so you can pass
433:17 - Secrets as inputs by using Secrets
433:19 - context so that is an example there um
433:23 - but I mean like the point is is that you
433:25 - know you could interpolate whatever you
433:27 - want there to pass it into a custom
433:29 - action and we'll talk about custom
433:30 - actions another video you can pass
433:32 - Secrets as Nars so that is another way
433:34 - that you could uh do that and why would
433:37 - you do um inputs versus Nars it just
433:40 - really depends on uh your use case so
433:43 - maybe you have something that is uh a
433:46 - program you're using and it can only use
433:48 - narss whereas uh with Secrets it's okay
433:51 - to do that on left hand side because of
433:53 - the the way it works but I just want to
433:56 - point out here we did this in another
433:57 - video but if you want to make that an
433:59 - Nar you'd have to map it like that I
434:01 - think we did that for something earlier
434:03 - but uh hopefully you know what that is
434:05 - so about how you set a secret so you can
434:07 - use the uh GitHub CLI so we have a GH
434:11 - secret set which is probably how we're
434:13 - going to do it then we have GH secret
434:15 - set for a specific environment or at the
434:17 - org level so depending on how you do a
434:19 - flag it's going to be different the
434:21 - default apparently is repository and you
434:23 - can also specify the repo which we have
434:25 - here you could do that up here as well
434:27 - if you want to uh but there you go
434:33 - [Music]
434:34 - hey this is Andrew Brown we are taking a
434:35 - look at the GitHub token secret so the
434:38 - start of each workflow job GitHub
434:40 - automatically creates a unique GitHub
434:42 - token secret to use in your workflow you
434:44 - can use the GitHub token to authenticate
434:47 - uh in the workflow job uh sounds a bit
434:50 - repetitive there but let's take a look
434:52 - here and see what we're talking about so
434:53 - I'm going get my pen tool out so it's
434:54 - very clear um and what I want you to see
434:57 - is that we can say secrets. GitHub token
434:59 - and we can get that GitHub token I also
435:02 - believe that we can do dollar sign
435:03 - GitHub token for uh environment
435:05 - variables and it will show up as well um
435:07 - if not we can just map it over as we are
435:09 - doing here if you notice here we're
435:10 - doing that um when you enable GitHub
435:13 - actions GitHub installs a GitHub app on
435:15 - your repository the GitHub token secret
435:18 - is a GitHub app installation access
435:20 - token so hopefully that is clear you can
435:22 - also use it with the rest API so here's
435:24 - another example and notice we are
435:26 - calling Secrets GitHub token with uh
435:28 - this way of interpolating that um so
435:31 - there you
435:33 - [Music]
435:36 - go hey this is Andrew Brown from exam
435:39 - Pro and in this section we'll be
435:41 - covering Azure monitor so Azure monitor
435:44 - is a comprehensive solution for
435:45 - collecting analyzing and acting on
435:47 - Telemetry from your cloud and on
435:49 - premises environments it serves as the
435:51 - backbone for gaining insight into the
435:52 - performance and health of your
435:54 - applications infrastructure and even the
435:56 - network he features visual dashboards A
435:59 - visual representation of your data smart
436:02 - alerts intelligent notifications based
436:04 - on specific conditions automated actions
436:07 - set automation based on certain triggers
436:10 - log monitoring track and analyze event
436:12 - logs many Azure Services by default are
436:15 - already sending Telemetry data to Azure
436:17 - monitor what is observability it's the
436:20 - ability to measure and understand how
436:22 - internal systems work in order to answer
436:24 - questions regarding performance
436:25 - tolerance security and faults with a
436:27 - system or application to obtain
436:30 - observability you need to use metrics
436:32 - logs and traces you have to use them
436:34 - together using them in isolation does
436:36 - not gain you observability metrics a
436:39 - number that is measured over a period of
436:41 - time for example if we measured the CPU
436:43 - usage and aggregated it over a period of
436:45 - time we could have an average CPU metric
436:48 - logs a text file where each line
436:50 - contains event data about what happened
436:52 - at a certain time traces a history of
436:55 - request that travels through multiple
436:57 - apps or services so we can pinpoint
436:58 - performance or failure look like they
437:01 - should have called it the Triforce of
437:03 - observability the sources of common
437:05 - monitoring data to populate data stores
437:07 - order by highest to lowest application
437:10 - operating system Azure resources Azure
437:13 - subscription Azure tenant custom sources
437:16 - the two fundamental data stores are
437:18 - metrics and logs Azure monitor
437:22 - functionalities insights this can be for
437:24 - applications containers VMS or other
437:26 - Monitoring Solutions visualize using
437:29 - dashboards views power RBI and workbooks
437:32 - you can create Rich visual presentations
437:33 - of your data Analyze This involves
437:36 - delving deep into metrics analytics and
437:38 - log analytics respond Based on data
437:41 - Azure monitor can alert you or even
437:42 - autoscale resources integrate extend the
437:45 - capabilities by using logic apps or
437:47 - export API for more flexibility overall
437:50 - Azure monitor is a comprehensive
437:52 - solution vital for ensuring that your
437:54 - applications and services run optimally
437:56 - and any issues are detected and dealt
437:57 - with properly
437:59 - [Music]
438:03 - the next topic we'll be covering are the
438:05 - various sources from which Azure monitor
438:07 - collects data application code Azure
438:10 - monitors application insights offers
438:11 - robust metrics about the performance and
438:13 - functionality of your applications and
438:15 - code you'll get performance traces
438:17 - application logs and even user Telemetry
438:20 - you'll need to install instrumentation
438:22 - package in your application to collect
438:24 - data for application insights
438:26 - availability tests measure your
438:28 - application's responsiveness from
438:29 - different locations on the public
438:31 - internet this helps in assessing the
438:33 - reliability and uptime of your services
438:35 - nric descriptive data regarding your
438:38 - applications performance operation and
438:40 - custom metrics log store operational
438:43 - data about your application including
438:44 - page views application requests
438:47 - exceptions and traces you can send
438:49 - application data to Azure storage for
438:51 - archiving view the details of
438:53 - availability test stored and debug
438:55 - snapshot data that is captured for a
438:57 - subset of exceptions is stored in Azure
438:59 - storage log analytics agent is installed
439:02 - for comprehensive monitoring dependency
439:05 - agent collects discovered data about
439:07 - processes running on the virtual machine
439:08 - and external process dependencies agents
439:11 - can be installed on the OS for VMS
439:13 - running in Azure on premises or other
439:15 - Cloud providers Diagnostics extension
439:18 - collect performance counters and store
439:20 - them in metrics application insights
439:22 - logs collect logs and performance
439:24 - counters from the compute resources
439:26 - supporting your application allowing
439:27 - them to be analyzed alongside other
439:29 - application data the Azure Diagnostics
439:32 - extension always writes to an Azure
439:33 - storage account while Azure monitor for
439:35 - VMS uses the log analytics agent to
439:37 - store Health State information in a
439:39 - custom location the Diagnostics
439:42 - extension can also stream data to other
439:44 - locations using aent hubs resource logs
439:47 - provide insights into the internal
439:48 - operation of an Azure resource and are
439:50 - automatically created however you must
439:52 - create a diagnostic setting to specify a
439:54 - destination for each resource platform
439:57 - metrics will write to the Azure monitor
439:59 - metrics database with no configuration
440:02 - you can access platform metrics from
440:03 - metrics Explorer for trending and other
440:06 - analyzes use log analytics copy platform
440:09 - metrics to logs send resource logs to
440:12 - Azure storage for archiving stream
440:14 - metrics to other locations using aent
440:17 - hubs Azure subscription this includes
440:19 - Telemetry related to the health and
440:21 - operation of your Azure subscription
440:23 - Azure service Health provides
440:25 - information about the health of the
440:26 - Azure services and your subscription
440:28 - that your application and resources rely
440:30 - on
440:31 - Telemetry related to your Azure tenant
440:33 - is collected from tenant wide services
440:35 - such as Azure active directory Azure
440:37 - active directory reporting contains the
440:39 - history of sign and activity and audit
440:41 - trail of changes made within a
440:43 - particular tenant for resources that
440:45 - cannot be monitored using the other data
440:47 - sources write this data to either
440:49 - metrics or logs using an Azure monitor
440:51 - API this will allow you to collect log
440:53 - data from any rest client and store it
440:55 - in log analytics in the Azure monitor
440:57 - metrics database
440:59 - [Music]
441:03 - Azure monitor is integral to maintaining
441:05 - the health and performance of your
441:06 - applications and resources collecting
441:08 - two fundamental types of data logs and
441:10 - metrics Azure monitor logs collects and
441:13 - organizes log in performance data from a
441:15 - variety of monitored resources data
441:18 - consolidation logs can be pulled from
441:20 - diverse sources such as platform logs
441:22 - from Azure services log and performance
441:24 - data from Agents on Virtual machines and
441:26 - usage and performance data from
441:28 - applications workspaces all these logs
441:30 - are organized into workspaces providing
441:33 - a centralized repository for in-depth
441:35 - analysis query language Azure monitor
441:38 - logs offers a sophisticated query
441:39 - language which can quickly analyze
441:41 - millions of Records making it an ideal
441:43 - choice for complex data analytics log
441:46 - analytics you can interactively work
441:48 - with log queries and their results using
441:49 - azure's log Analytics tool in contrast
441:53 - Azure monitor metrics collects numeric
441:55 - data and organizes it into a Time series
441:57 - database here's why that's important
441:59 - numeric dat data metrics are numerical
442:01 - values captured at regular intervals
442:04 - they are a snapshot that describes a
442:05 - particular aspect of a system at a
442:07 - specific Moment In Time lightweight
442:10 - metrics are designed to be lightweight
442:11 - allowing for near realtime data analysis
442:14 - this makes them particularly useful for
442:15 - alerting and the rapid detection of
442:17 - issues metrics Explorer the metrics
442:20 - Explorer tool allows for interactive
442:22 - analysis of metric data providing a more
442:24 - immediate understanding of your system's
442:25 - performance and health
442:28 - [Music]
442:32 - the next topic we'll cover are the data
442:33 - retention and archive policies of azure
442:35 - monitor logs this is an important aspect
442:38 - of your monitoring strategy as it allows
442:40 - you to control how long your data
442:41 - remains stored and accessible by default
442:44 - in the Azure portal you can set this
442:46 - retention time anywhere from 30 to 730
442:48 - days for the whole workspace if you want
442:51 - you can also specify different storage
442:53 - durations for certain tables within your
442:55 - workspace letting you manage different
442:56 - types of data as needed this gives you
442:59 - the flexibility to meet any business or
443:01 - regulatory rules about data storage
443:03 - however note that to tweak these
443:05 - retention settings you have to be on the
443:07 - PID tier of azure monitor logs to set
443:10 - retention and archive policy by table
443:12 - why navigate to the Azure portal and go
443:15 - to the log analytics workspace where the
443:16 - data is stored two under the settings
443:19 - section select usage and estimated cost
443:22 - three then select data retention for in
443:26 - the data retention blade you can modify
443:28 - the retention period for each table by
443:30 - default fault it is set to 31 days but
443:32 - you can extend it up to 730 days five
443:35 - for archiving data you can use Azure
443:37 - data Explorer which lets you retain data
443:39 - beyond the 2-year limit and gives you a
443:41 - highly scalable analytic service so
443:44 - that's an overview of the data retention
443:46 - and archive policies of azure monitor
443:48 - logs you'll most likely encounter a
443:50 - question related to this on the exam so
443:52 - be sure to know
443:54 - [Music]
443:57 - this hey this is Andrew Brown from exam
444:00 - Pro and in this section we'll be
444:02 - covering Azure log analytics so log
444:04 - analytics is a tool in the Azure portal
444:06 - used to edit and run log queries with
444:08 - data in Azure monitor logs log analytics
444:11 - processes data from various sources and
444:13 - transforms it into actionable insights
444:16 - it ingests data from Azure monitor
444:18 - windows and Linux agents Azure services
444:20 - and other sources once the data is
444:22 - collected you can use log analytics
444:24 - query language to retrieve consolidate
444:26 - and analyze the data log analytics uses
444:29 - a query language
444:31 - kql now we'll go over some of the
444:33 - benefits of log analytics centralized
444:36 - log management collect and analyze data
444:38 - from multiple sources both on premises
444:40 - and in the cloud in a centralized
444:42 - location powerful analytics utilize the
444:44 - custo query language to run Advanced
444:46 - analytics on large amounts of fast
444:48 - streaming data in real time custom
444:50 - dashboards create custom dashboards and
444:52 - visualizations to display real time data
444:55 - and Trends integration seamless
444:57 - integration with other Azure services
444:59 - and Microsoft solution Solutions such as
445:01 - powerbi and Azure Automation and
445:03 - alerting set up alerts based on specific
445:05 - criteria to proactively identify and
445:07 - respond to potential issues before they
445:09 - affect your
445:10 - users log analytics workspace is a
445:13 - unique environment for Azure monitor log
445:15 - data each workspace has its own data
445:17 - repository and configuration and data
445:20 - sources and solutions are configured to
445:21 - store their data in a particular
445:24 - workspace so that's an overview of azure
445:26 - log Analytics
445:28 - [Music]
445:33 - the log analytics agent is a lightweight
445:35 - agent that can be installed on Windows
445:36 - and Linux machines to collect and send
445:38 - log data to Azure monitor it provides a
445:41 - way to centralize logs from various
445:42 - sources and enables the analysis of the
445:44 - data using tools like Azure monitor logs
445:47 - Azure dashboards and Azure monitor
445:49 - workbooks the agent can collect logs
445:51 - from various sources including Windows
445:53 - event logs custom logs performance
445:55 - counters and CIS log it supports both
445:58 - agent-based and agentless data
446:00 - collection ction and can be configured
446:01 - to collect data from on premises and
446:03 - cloud-based
446:04 - environments the log analytics agent is
446:06 - set up to monitor certain Windows event
446:08 - logs like security system or application
446:11 - logs the data from these logs is then
446:13 - gathered and sent to log analytics for
446:15 - analysis using queries and
446:17 - visualizations the log analytics agent
446:19 - is set up to monitor CIS log servers or
446:21 - network devices it collects data from
446:24 - these sources and sends it to log
446:25 - analytics allowing for detailed analysis
446:27 - and troubleshooting both methods for
446:29 - colle cting log data allow for
446:31 - centralized management and Analysis of
446:33 - log data from multiple sources which can
446:35 - help to improve visibility and
446:36 - streamline troubleshooting and issue
446:38 - resolution you can expect to see a
446:41 - question related to log analytics agents
446:43 - and choosing either Windows event logs
446:44 - for a Windows agent or CIS loock for
446:47 - Linux agent on the
446:53 - exam the next topic will be covering our
446:55 - application insights application
446:58 - insights is an application performance
447:00 - Management Service and it's a subservice
447:02 - of azure monitor APM is all about the
447:04 - monitoring and management of performance
447:06 - and availability of software apps it
447:08 - strives to detect and diagnose complex
447:10 - application performance problems to
447:12 - maintain an expected level of service so
447:15 - why use application insights automatic
447:17 - detection of performance anomalies
447:19 - application insights automatically
447:21 - identifies performance anomalies in your
447:23 - system powerful analytics tools it comes
447:26 - with robust analytics tools to help you
447:28 - diagnose issues and understand what
447:29 - users do with your app continuous
447:32 - Improvement it is designed to help you
447:33 - continuously improve performance and
447:35 - usability of your applications platform
447:38 - agnostic it works for apps on net
447:40 - node.js Java and python hosted on
447:43 - premises hybrid or any public Cloud
447:46 - devops integration it can be integrated
447:48 - into your devops process and mobile app
447:51 - monitoring it can monitor and analyze
447:52 - Telemetry from mobile apps by
447:54 - integrating with visual studio app
447:56 - center to use application insights you
447:59 - need to instrument your application this
448:01 - involves installing the instrument
448:03 - package or enabling application insights
448:05 - using the application insights agents
448:07 - were supported there are many ways to
448:09 - view your Telemetry data apps can be
448:12 - instrumented from anywhere when you set
448:14 - up application insights monitoring for
448:16 - your web app you create an application
448:17 - insights resource in Microsoft Azure you
448:20 - open this resource in the Azure portal
448:22 - in order to see and analyze the
448:23 - Telemetry collected from your app the
448:26 - resource is identified by an
448:27 - instrumentation
448:29 - key what does application insights
448:31 - monitor request rates response times and
448:34 - failure rates dependency rates response
448:37 - times and failure rates exceptions page
448:40 - views and low performance aex calls user
448:42 - and session counts performance counters
448:45 - post Diagnostics diagnostic Trace logs
448:48 - and custom events and
448:50 - metrics where do I see my Telemetry
448:53 - smart detection and manual alerts
448:55 - application map profiler usage analysis
448:58 - diagnostic search for in data metric
449:01 - Explorer for aurated data dashboards
449:03 - live stream metrics analytics Visual
449:06 - Studio
449:07 - ET overall application insights is a
449:10 - comprehensive APM service that offers
449:12 - automatic detection of performance
449:14 - anomalies powerful analytics tools and
449:16 - is designed to help you continuously
449:18 - improve performance and
449:21 - [Music]
449:24 - usability in this segment we'll delve
449:26 - into the topic of application insights
449:28 - instrumentation so what is
449:30 - instrumentation in simple terms it's a
449:32 - way to make your application smarter by
449:34 - adding a few lines of code or in some
449:36 - cases none at all you can monitor how
449:38 - your app performs and where it might be
449:40 - running into issues you instrument your
449:42 - application by adding the Azure
449:44 - application insights SDK and
449:45 - implementing traces in the case of a
449:48 - node.js application you can install the
449:50 - Azure application insights SDK using mpm
449:53 - with the following command and PM
449:55 - install application insights hyphen save
449:57 - application insights this is the name of
449:59 - the package you are installing which is
450:01 - azure SDK for application insights pyth
450:04 - and save this flag saves the package as
450:06 - a dependency in your package.json n file
450:09 - here this piece of code lets you
450:11 - configure what you want to
450:12 - collect Azure supports the following
450:15 - languages net Java python node.js
450:19 - JavaScript Auto instrumentation allows
450:21 - you to enable application monitoring
450:23 - with application insights without
450:25 - changing your code this table shows
450:27 - which Azure Services support application
450:29 - ins sites and in what programming
450:31 - languages the services range from Azure
450:33 - app service on Windows and Linux to
450:35 - Azure functions Azure spring Cloud Azure
450:37 - kubernetes service and more GA General
450:41 - availability meaning it's fully
450:42 - supported and ready to use public
450:44 - preview still being tested but you can
450:46 - use it not supported you can't use
450:49 - application insights here through agent
450:51 - you need to install a special piece of
450:53 - software to use this service o NBD on by
450:56 - default meaning the feature is
450:57 - automatically enabled through extension
451:00 - available but needs an extension to work
451:02 - we won't go through the entire table but
451:04 - we'll give a few examples for
451:06 - applications written in.net and hosted
451:08 - on Azure app service on Windows
451:10 - application insights is generally
451:12 - available and enabled by default for
451:14 - applications written in Python and
451:16 - hosted on Azure functions application
451:18 - insights is available and enabled by
451:20 - default but for dependencies monitoring
451:22 - you will need to use an extension so
451:25 - that's an overview of application
451:26 - insights instrumentation
451:29 - [Music]
451:33 - hey this is Andrew Brown from exampro
451:36 - and in this section we'll be covering
451:37 - Microsoft Sentinel formerly known as
451:39 - Azure Sentinel Microsoft Sentinel is a
451:42 - scalable Cloud native solution that
451:44 - encompasses two key
451:45 - functionalities security information
451:47 - event management this is all about
451:49 - collecting and analyzing security
451:51 - related data to provide real-time
451:53 - analysis of security alerts generated by
451:55 - applications and network Hardware
451:57 - security orchestration automated
451:59 - response
452:00 - this refers to the collection of tools
452:02 - that enable an organization to Define
452:04 - standardize measure and automate
452:05 - responses to security events Microsoft
452:08 - Sentinel delivers intelligent security
452:10 - analytics and threat intelligence across
452:12 - the Enterprise providing a single
452:14 - solution for alert detection threat
452:17 - visibility proactive hunting and threat
452:20 - response with Microsoft Sentinel you can
452:23 - collect data Cloud scale across all
452:25 - users devices applications and
452:27 - infrastructure both on premises and in
452:29 - multiple cloud clouds detect previously
452:31 - undetected threats and minimize false
452:33 - positives using Microsoft's analytics
452:35 - and unparalleled threat
452:37 - intelligence investigate threats with
452:39 - artificial intelligence and hunt for
452:41 - suspicious activities at scale tapping
452:43 - into years of cyber security work at
452:45 - Microsoft respond to incidents rapidly
452:48 - with built-in orchestration in
452:49 - automation of common
452:50 - tasks Microsoft Sentinel comes with a
452:53 - number of connectors for Microsoft
452:55 - Solutions such as Microsoft 365 defender
452:59 - office 3 365 Azure ad or Microsoft enter
453:03 - ID Microsoft Defender for identity and
453:06 - Microsoft Defender for cloud apps you
453:08 - can use common event formats CIS logit
453:11 - rest API Windows event logs common event
453:15 - format and trusted automated the
453:17 - exchange of indicator
453:19 - information one notable feature of
453:21 - Microsoft Sentinel is the ability to
453:23 - create Azure monitor workbooks workbooks
453:26 - provide a flexible canvas for data
453:28 - analysis and the creation of rich visual
453:30 - reports within the Azure portal they
453:32 - allow you to tap into multiple data
453:34 - sources from across Azure and combine
453:35 - them into unified interactive
453:37 - experiences it tells a story about the
453:40 - performance and availability about your
453:41 - applications and services workbooks are
453:44 - temporary workspaces to define a
453:46 - document like format with visualization
453:48 - intertwined to help investigate and
453:49 - discuss
453:51 - performance Microsoft Sentinel uses
453:53 - analytics to correlate alerts into
453:55 - incidents incidents are groups of
453:57 - related alerts that together create an
453:59 - actionable possible threat that you can
454:01 - investigate and
454:02 - resolve Microsoft Sentinels Automation
454:05 - and orchestration solution provides a
454:06 - highly extensible architecture that
454:08 - enables scalable automation as new
454:10 - technologies and threats emerge built on
454:13 - the foundation of azure logic apps
454:15 - includes 200 plus connectors for
454:18 - services Microsoft Sentinel also offers
454:21 - deep investigation tools that help you
454:22 - to understand the scope and find the
454:24 - root cause of a potential security
454:26 - threat you can choose an entity on the
454:27 - interactive graph to ask interest in
454:29 - questions for a specific entity and
454:31 - drill down into that entity and its
454:32 - connections to get to the root cause of
454:34 - the
454:35 - threat additionally Microsoft Sentinels
454:38 - powerful hunting search and query tools
454:40 - based on the miter framework enable you
454:42 - to proactively hunt for security threats
454:44 - across your organization's data sources
454:46 - before an alert is
454:47 - triggered after you discover which
454:49 - hunting query provides high value
454:51 - insights into possible attacks you can
454:53 - also create custom detection rules based
454:55 - on your query and service those insights
454:57 - as alerts to your security incident
454:59 - responders
455:00 - while hunting you can create bookmarks
455:02 - for interesting events enabling you to
455:04 - return to them later share them with
455:05 - others and group them with other
455:07 - correlating events to create a
455:08 - compelling incident for
455:10 - investigation lastly let's talk about
455:12 - pricing Microsoft Sentinel has two
455:14 - different pricing models capacity
455:17 - reservations this involves being build a
455:19 - fixed fee base on the selected tier
455:21 - enabling a predictable total cost for
455:22 - Microsoft Sentinal pay as you go with
455:25 - this option Bill per gigabyte for the
455:27 - volume of data ingested for analysis in
455:29 - Microsoft Sentinel and stored in the
455:30 - Azure monitor log analytics
455:33 - workspace and there you have it a
455:35 - comprehensive look at Microsoft Sentinel
455:37 - a robust seam and Source solution that
455:39 - can help protect your organization's
455:40 - infrastructure applications and
455:44 - [Music]
455:47 - data let's take a closer look at custo
455:50 - and it's query language so Azure monor
455:53 - logs is based off of the Azure data
455:55 - Explorer and Along came with it is the
455:57 - custo query language also known as kql
456:01 - and this is the way we're going to uh
456:04 - filter and uh sort and do things with
456:06 - our logs so custo is based on a
456:09 - relational database management system
456:11 - and it supports entities such as
456:13 - database tables and columns as also has
456:15 - this thing called clusters and uh kql
456:18 - actually has a lot of utility in Azure
456:20 - because it's not just in monitor logs
456:23 - and data Explorer you can use it in log
456:25 - analytics log alert rules workbooks
456:28 - dashboards
456:29 - logic apps Powershell Azure monitor log
456:33 - API so it's definitely something you're
456:34 - going to be using across the board in
456:36 - Azure and so they have some basic
456:38 - operators um uh or they have lots of
456:41 - operators that you can use so you can do
456:42 - calculated columns searching and
456:44 - filterings on rows Group by agates join
456:47 - functions and we're going to be looking
456:48 - at a lot of the operators in more detail
456:50 - after this slide here uh but anyway uh
456:53 - the queries execute in the context of a
456:55 - custo database that is attached to a
456:57 - custo cluster and we will we'll talk
456:59 - about clusters database tables and
457:01 - columns up
457:03 - [Music]
457:06 - next let's take a look at what makes up
457:09 - um something for custo and so we have a
457:11 - bunch of entities here clusters database
457:13 - tables columns and functions and so I
457:14 - have this nice visual to help us uh kind
457:17 - of see how they all work together so at
457:19 - the top we have clusters and these are
457:20 - entities that hold multiple databases
457:23 - you can also have multiple clusters um
457:25 - but it's just not being shown there in
457:26 - that graphic then you have the databases
457:29 - themselves these are named entities that
457:30 - hold tables and store functions you have
457:32 - tables these are named entities that
457:34 - hold data and a table has an ordered set
457:36 - of columns and zero or more rows of data
457:39 - each row holding one data value for each
457:41 - of the columns of the table then there
457:43 - are the columns themselves and these are
457:45 - named identities that have a scalar data
457:47 - type columns are referen in the query
457:49 - relative to the tabular data stream and
457:51 - that is the context of the specific op
457:53 - operator referencing them then we have
457:55 - stored functions and these are named
457:56 - entities that allow reuse of custo
457:58 - queries or query Parts uh and then you
458:01 - got these external tables and these are
458:03 - tables that uh live outside of your
458:05 - cluster uh I think that they're uh
458:07 - you're referencing them from uh storage
458:09 - accounts and they're in Blob storage so
458:11 - they I think they could be like CSV
458:13 - files and stuff like that but these
458:15 - external tables are used for exporting
458:16 - data from custo to external storage so
458:18 - storage uh storage accounts as for
458:21 - quering external data without ingesting
458:22 - it actually into custo so hopefully that
458:25 - gives you an idea the lay of the Land
458:27 - There

Cleaned transcript:

hey this is Andrew Brown your favorite Cloud instructor bringing you another free Cloud certification course and this time it's the a400 this is specifically for the Azure devops engineer um and we're making this available on free Camp as always so the way we're going to get the certification is by doing labs in our own Azure account uh lecture content and as always we provide you a free practice exam and I want to tell you that our exam simulator has case studies which is the most important component when we're looking at these expert certifications with Azure um so if you want to support more free courses like this one the best way to do that is to purchase the additional study materials over on exampro doco that's where you get the cheat sheets additional practice exams uh the content is layered um and again it helps produce these courses if you don't know me I've taught a lot of courses here um I've taught ads Azure lots of azure uh gcp kubernetes terraform you name it I've taught it so you're in good hands and I will see you soon okay hey this is Andrew Brown I just wanted to tell you that in this video course I am utilizing my synthetic voice uh synthetic voices is when you utilize software that emulate your voice the reason why I utilize synthetic voice is a couple reasons this is when uh the real Andrew not the synthetic voice Andrew has lost his voice and this happens to me because I have muscle tension dysphonia and so if I use my voice a lot aggressively I can lose my voice and so I have to uh be careful when I'm recording a considerable amount of content and right now when this video is being made I am recording a lot of adus content and so you know I've ask my support team to just generate out my words and Stitch the video together and this the reason for that is that I don't want my content to go stale so when I create content it has to get shipped uh whether my voice is ready or not um so this is the case for the ac400 otherwise this course would just go stale and you wouldn't get it for like 6 months to a year but um you know that's the tradeoff that we have when I'm a single content creator and I'm trying to get all this content out so I just want to point out that the content is made by me it's just utilizing a synthetic voice so it's not like it's somebody else doing 100% everything else otherwhere but there you go okay hey this is Andrew Brown from exam Pro and we'll be going over an introduction of the a400 certification the Azure devops Engineer Expert is an expert level Microsoft certification for the prerequisites you must earn at least one of the following the Microsoft certified Azure administrator associate or the Microsoft certified Azure developer associate the key topics covered in this course design and Implement processes and Communications such as GitHub flow and Azure boards design and Implement traceability and flow of work configure collaboration and communication designed and Implement a source control strategy such as branching strategies pull request workflows design and Implement build and release pipelines design and Implement a package management strategy like GitHub packages develop a security and compliance plan and Implement an instrumentation strategy like Azure Monitor and log analytics so who is this certification for the certification is designed for individuals who are interested in learning how to design and Implement devops practices for continuous integration continuous delivery and infrastructure is codee you may consider this certification if you are new to devops and want to learn the fundamentals and benefits of devops practices you are a software developer systems administrator or IT professional you want to understand the capabilities of azure devops and GitHub including building pipelines implementing Source control strategies and managing security and compliance you are a senior devops engineer or in a related role who needs to reset or refresh your knowledge after working for multiple years so what's the Azure devops Engineer Expert road map like well the most common route that people take to reach the devops Engineer Expert is to start at the Azure fundamentals it's not mandatory but it helps build a solid foundation then you take the Azure developer associate for Designing building testing Azure applications and eventually take the Azure Dev Ops Engineer Expert another common path is to take the Azure administrator associate and then the Azure Solutions architect you can also take the Azure Solutions architect after the devops Engineer Expert to further enhance your Microsoft Azure skills and widen your career prospects other popular associate level certifications may include the aszure AI engineer Azure database administrator and the Azure security engineer and many more so that's a general outlook on the road map to Azure devops Engineer Expert how long this study to pass for beginners so if you've never used Microsoft Azure or any cloud provider have no prior experience with devops practices or no Tech background or experience you're looking it around over 50 hours you shouldn't take this exam if you're a beginner you'll need to pass the prerequisites and build a solid foundation if you're experience with Microsoft Azure or any Cloud providers have experience with devops practices and tools and have a strong background in technology you're looking at about 15 hours the average study time is about 25 hours you should dedicate around 50% of the time to lecture in labs and 50% of the time to practice exams we recommended to study around 1 to 2 hours a day for 20 days what does it take to pass the exam watch video lecture and memorize key information do handson labs and follow along within your own account do paid online practice exams that simulate the real exam sign up and redeem your free practice exam exam guide content outline the exam has a total of five domains each domain has its own waiting this determines how many questions in a domain that will show up skills measured design and Implement processes and communic ation design and Implement a source control strategy design and Implement build and release pipelines which consists of 50 to 55% of the course develop a security and compliance plan Implement an instrumentation strategy where do you take the exam you can take the exam at an inperson test center or online from the convenience of your own home you can use CER aort or Pearson view a proctor is a supervisor or person who monitors students during an examination the passing GR is about 700 out of 1,000 you need to get around 70% to pass Microsoft uses scaled scoring there are about 50 to 55 questions you can afford to get roughly 12 to 14 questions wrong there is no penalty for wrong questions form bet of questions multiple choice multiple answer drag and drop yes and no keep in mind that there's usually one labp with about eight questions that you do on the Azure portal and the exam is open book but you can only access the Microsoft documentation is the resource the exam duration is 2 hours you get about 2 minutes per question exam time is 120 Minutes C time is 150 minutes C time refers to the amount of that you should allocate for the exam it includes time to review instructions Show online Proctor your workspace read and accept NDA complete the exam provide feedback at the end the certification is valid for one year you can renew the certification for free Within 6 months or before the expiration date so that's an introduction to the Azure devops engineer expert certification hey this is Andrew Brown from exam Pro and we'll be going over a quick overview of the exam guide you can find the exam guide by searching for study guide for exam a400 on Google so as we scroll down it will show you the five domains covered and it'll be broken down into more sections I won't be able to go through all of it so I'll just go through some of the key topics that I think you should focus on for the exam design and Implement a structure for the flow of work including GitHub Flow Design and Implement integration for tracking work including GitHub projects Azure boards and repositories you need to know the flow of work such as cycle times time to recovery and lead time configure release documentation including release notes and API documentation design and Implement a strategy for managing large files including get large file storage and get fat recommend package management tools including GitHub packages registry and Azure artifacts design and Implement quality and release Gates including security and governance select a deployment automation solution including GitHub actions and Azure pipelines design a deployment strategy including blue green Canary ring Progressive exposure feature flags and a b testing Implement feature flag Flag by using azzure App configuration feature manager design and Implement desired State configuration for environments including Azure automation State configuration Azure resource manager bicep and Azure autom manage machine configuration Implement and manage GitHub authentication including GitHub apps G token and personal access tokens Implement and manage Secrets keys and certificates by using Azure key Vault automate container scanning including scanning container images and configuring an action to run codic L analysis in a container configure Azure Monitor and log analytics to integrate with devops tools configure collection of telemetry by using application insights VM insights container insights storage insights and network insights inspect distributed tracing by using application insights interrogate logs using basic custom query language queries so that's a quick overview of the exam guide for the a400 hey this is Andrew Brown from exam Pro and we'll be starting off asking the most important question first what is devops devops is an approach that brings together software development and it operations with the goal to enhance the speed and reliability of software delivery it focuses on continuous Improvement Automation and collaboration between teams that were once siloed aiming to shorten the time from development to operation the process includes frequent code versions which allows for for incremental improvements to applications and systems the ultimate goal of devops is to create a culture and environment where building testing and releasing software can happen rapidly frequently and more reliably so why devops devops eliminates the inefficiencies miscommunications and delays that arise from the traditional gap between development and operations teams it creates a collaborative culture that accelerates and improves software delivery some of the key challenges addressed by devops include this communication and collaboration gaps enhances communication and collaboration reducing misunderstandings and accelerating the release process conflicting goals aligns the goals of Dev and Ops teams towards quick reliable and highquality software delivery manual processes in Bottle X advocates for automation to decrease manual effort errors and delays and streamline processes automation leads to fewer errors shorter deployment times and improved software quality so what's the role of a devops engineer a devops engineer facilitat this collaboration in automation focusing on continuous integration and continuous delivery establishing pipelines that automate code integration testing and deployment ensuring rapid Reliable Software releases infrastructure is code managing and provisioning infrastructure through code to increase efficiency and consistency monitoring and operations implementing Monitoring Solutions to track application and infrastructure performance ensuring High availability and reliability transition to Cloud infrastructure many organizations are transitioning to Cloud infrastructure such as a WS Google cloud or Azure to cut costs and improve manageability offering intuitive tools for network and security settings but necessitating knowledge of platform specific features some of the tools and technologies that will be used in Dev Ops are Version Control such as get essential for managing code changes and facilitating team collaboration agile and lean techniques for planning Sprint isolation and capacity management containerization such as Docker enables scalable deployments with lightweight containers that are faster and simpler to configure than traditional virtual machines orchestration like kubernetes efficiently manages containerized applications that scale CI CD tools such as Jenkins and get lab CI automate the software delivery process from code integration to deployment IAC tools like terraform and anible automate the provisioning and management of infrastructure monitoring and logging such as Prometheus provides insights into application performance and operational health and public and hybrid Cloud streamline operations offering scalable infrastructure with iOS for Seamless app migration and platform as a service to enhance productivity through sophisticated tools some examples of devops Technologies across the different devops stages mainly related to Microsoft Azure include for planning we have Azure boards GitHub and alassian jira continuous integration Azure repos GitHub repos sodar queet selenium owp new get and npm continuous delivery Azure pipelines GI Hub actions bicep terraform Jenkins Red Hat anible chef and puppet operations Azure monitor Azure Automation and Microsoft powerbi and for collaboration and feedback there's Azure devops wikis GitHub wikis GitHub discussions Microsoft teams and slack overall devops revolutionizes it by merging development and operations enhancing delivery speed and fostering a culture of Rapid continuous innovation the next topic we'll be covering are the differences between devops and traditional it in terms of time devops teams spend onethird more time improving systems to avoid Tech issues than traditional it less time is needed for administrative tasks because devops uses more automated tools and helpful scripts this save time allows for a 33% increase in enhancing their Tech infrastructure they also have 15% more time for Learning and training boosting their skills for Speed and data Dev op groups are typically small and adaptable driven by creativity and speed one of the main goal of devops is agility aiming for Swift completion of tasks traditional it operations typically have less feedback data focusing only on the immediate task it operations often have to handle unexpected Downstream issues they didn't see coming cloud devops is more effective in delivering business applications due to its quick Pace traditional it must strive to keep up with the rapid changes and demands of the business World regard St ing recuperation and crunch time devops teams focus on Readiness for failures and have strategies like ongoing testing and realtime alerts these strategies mean they can address issues quickly and keep systems running smoothly traditional it may need more time to recover from setbacks because they might not of these proactive measures in place fast recovery and devops has often helped using automated systems and flexible infrastructure setups for software distribution devops teams take roughly 37 minutes to deploy software traditional it operations typically need about 85 minutes for the same task this indicates devops teams can release software more than twice as quickly as traditional it teams next we'll quickly go over a few key aspects that devops has an advantage over traditional it product reliability reduce likelihood of failure adaptability enhance flexibility and support Market responsiveness decrease time to Market team productivity greater efficiency in teams Vision clarity more defined product Vision within teams so that's an overview of devops versus traditional it the next topic will be covering is agile and Agile development agile is a philosophy and software development that emphasizes incremental progress collaboration and flexibility it revolves around the idea of breaking down large projects into smaller manageable sections called iterations or Sprints teams work in these short bursts to produce tangible results regularly allowing for frequent reassessment and adjustment this approach enables a quick response to change and promotes continuous Improvement both in the product and the process used to create it the term agile methodology refers to the specific Frameworks and practices that embody the agile philosophy such as scrum and campin these methodologies provide the structure and tools for teams to execute agile principles effectively they include techniques for planning and tracking progress such as standup meetings Sprints and visual boards all designed to enhance team coordination and project transparency Agile development encompasses various methods that follow the agile Manifesto core ideas it's about teams working together managing themselves and using practices that best suit their Project's needs to gradually improve their software in Agile development teams aim to produce fully working and highquality parts of the software at the end of every Sprint this means they must write code test it and make sure everything is of good quality within each Sprint short time frame the key success factors for Agile development teams include diligent backlog refinement integrating early and often and minimizing technical debt diligent backlog refinement this means organizing the list of upcoming work prioritizing the most important tasks and clarifying them product owners are key in preparing for future Sprints by providing clear goals integrating early and often by using continuous integration continuous delivery teams automate their workflows which speeds up coding testing and deployment this helps catch and fix problems early minimizing Tech technical debt just like unwanted financial debt technical debt happens when taking shortcuts which may later require code fixes it's important to find a good mix of adding new features and fixing these issues needing careful planning and discipline so that's an overview of agile and Agile development hey this is Andrew Brown from exam Pro and in this section we'll be going over two popular agile Frameworks or methodologies called scrum and camben scrum is an agile framework designed for managing complex projects by breaking them down into small manageable tasks completed in short phases called Sprints the key roles in scrum include a product owner guides what and why the team builds prioritizes the work backlog a scrum Master facilitates scrum processes supports team Improvement and removes obstacles and a development team Engineers the product ensuring its quality in scrum a team self manages its Sprint tasks with daily standup meetings to ensure progress and address impediments they track work using a task board and a Sprint burndown chart and at the Sprint's end they showcase their increment in a review and identify improvements in a retrospective scrum short repeatable Cycles facilitate continuous learning and adaptation making it a practical framework for teams adopting agile principles on the other hand campin is an agile methodology focused on visualizing work limiting work in progress and maximizing efficiency Cam and boards are used to display work at various stages of the process using cards to represents tasks and their stages highlighting work in progress and facilitating team flexibility cumulative flow diagrams visually track a Project's workflow over time showing task distribution across stages the horizontal axis represents time and the vertical axis represents task volume with each color marking at different work stage cfds highlight Trends progress and bottlenecks parallel colored areas indicate balanced workflow bulges suggest bottleneck needing attention for smooth project continuation let's go over a quick comparison between scrum and cambon while broadly fitting Under the Umbrella of Agile development scrum and cin are quite different scrum focuses on fixed length Sprints while cin is a continuous flow model scrum has defined roles while cambon doesn't Define any team roles scrum uses velocity as a key metric while cin uses cycle time teams often blend scrum and cambon features to optimize their workflow they continuously refine their approach to find the best fit focusing on Simplicity and regular value delivery to us the next topic we'll be covering are some of the key flow metrics you'll need to know for devops processes and for the exam starting with velocity velocity and Azure devops is a metric that tracks the amount of work a team completes during a Sprint helping teams estimate how much work they can handle in future Sprints it's represented in a chart that visualizes work items completed over several Sprints offering insights into the team's work patterns efficiency and consistency by analyzing velocity teams can adjust their planning for better predictability and productivity consistent velocity metrics can help at identifying the impact of process changes and guiding strategic decisions to enhance overall team performance next we have Sprint burndown chart the Sprint burndown is a graph that plots the daily total of remaining work typically shown in hours the burndown chart provides a visual way of showing whether the team is on track to complete all the work by the end of the Sprint it also helps in identifying any bottlenecks or issues in the workflow that may need attention before the Sprints end moving on to lead time and cycle time the lead time and cycle time widgets indicate how long it takes for work to flow through your development pipeline lead time measures the total time elapse from the creation of work items to their completion cycle time measures the time it takes for your team to complete work items once they begin actively working on them the following diagram illustrates how lead time differs from cycle time lead time is calculated from work item creation to entering a completed State cycle time is calculated from first entering an in progress or result State category to entering a completed State category these measures help teams plan spot variations in efficiency and identify potential process issues the lower the lead in cycle times the faster the throughput your team has so these are some of the key flow metrics you'll need to know for the exam hey this is Andrew Brown from exam Pro and in this section we'll be covering Azure board boards Azure boards is a webbased service designed for planning tracking And discussing work throughout the development process supporting agile methodologies for a customizable and efficient workflow key hubs and Azure boards Azure boards include several key hubs each serving distinct project management needs work items Hub manage work items based on specific criteria boards Hub visualize workflow using cards ideal for cambon the backlogs Hub plan and organize work items including backlogs for project and portfol folio management Sprints Hub handle Sprint specific work items incorporating scrum practices queries Hub generate custom work item lists and perform bulk updates delivery plans Hub track cross team deliverables and dependencies in a calendar view analytics views Hub create powerbi reports for detailed project analysis hey benefits of azure boards include scalable Simplicity easy to start with predefined work item types scalable for growing teams visual tools VIs ual I progress with Canin boards scrum boards and delivery plans customization configure boards task boards and plans including custom Fields builtin communication capture realtime communication and decisions within work item forms cloud storage support for Rich Text inline images attachments and comprehensive change history efficient search and notifications tools for quick work item searching and customizable alerts dashboards and analytics access to dashboards and analytics service for for reporting integration and support GitHub and office integration connects with GitHub repositories and supports import export with Microsoft Office autonomous team support tailor to Independent teams integrates with Microsoft teams in slack and offers a variety of marketplace extensions so that's an overview of azure boards the next topic we'll cover is traceability traceability allows tracking connections and dependencies among different parts of a software system it helps teams grasp the effects of changes handle risks and comply with regulations defining and managing requirements a key part of traceability is documenting and overseeing requirements effectively Azure devop says tools like Azure boards for handling requirements and tracking their progress linking requirements to related items like tasks or bugs this tracking clarifies each requirements progress and its influence on the project Version Control and change management for Trace ility a solid Version Control System to monitor modifications to code in files is essential Azure Dev opsis get repositories let developers manage their work efficiently by using branches for features or releases you can track changes and understand their role in the Project's bigger picture building and release management traceability must include build and release processes Azure pipelines facilitates building testing and deploying apps linking build artifacts and code changes to specific tasks showing what changes made it into each build test management and quality assurance for software quality traceability is crucial tools like Azure test plan support detailed test management linking test cases to requirements or user stor shows how well the testing process covers the initial needs ensuring thorough validation auditing in compliance traceability also supports meeting standards and regulations Azure Dev ops's auditing features track and log changes providing details on who changed what and when supporting accountability and Regulatory Compliance overall by setting up a clear traceability system organizations can make sure that any changes during the software development process are properly tracked recorded and checked hey this is Andrew Brown from exampro and in this section we'll be going through how to get started with Azure devops and some of the basics of azure boards so the first thing you want to do is search for Azure devops on Google then you want to click on the link that leads you to the Azure devops page which is used the first link on this page you want to click on the TR for free button I'm assuming everyone already has a Microsoft account or Microsoft Azure account already set up otherwise you wouldn't be taking the a Z400 level expert certification if not you should create one before clicking here so we'll enter in our email and click on sign in enter in our password and enter in the authentication code if you have one now you'll want to sign up and create your own Azure devops organization I'll be hosting the projects in Canada I'll name the organization something like exam Pro one you can name this whatever you like also enter in the Capt is requested then press continue the first thing they want you to do is to create a project so we'll name this something like exam Pro test of course you can name this whatever you want such as your name or or project and so on so now we're on the main page of the exam Pro test project on Azure devops so here you can see the overview so we'll quickly go through some of the blades starting off with Azure boards then we have repos after that there's pipelines next is test plans and then there's artifacts we'll be going through most of these in the course so that's how to get started with Azure devops hey this is Andrew Brown from exam Pro and in this section we'll be covering how to create or add new users in your Azure devops organization the first thing you want to do is to go to organization settings after that you want to click on policies under the security category under the user policies you want to toggle and turn on external guest policies this will allow you to invite users from outside the organization to access and collaborate on your Azure devops projects and resources after that you want to click on users under the general category on the right side you want to click on ADD users here is where you can add new users or service principles so for example We'll add Cindy at exam Pro . Co we'll keep the access level to basic we'll want to add the user to the exam Pro test project we created earlier we can also set a role for the user such as project readers project contributors or project administrators but we'll leave it at project contributor for now then click on ADD after a short wait the user should be added to the organization the user is sent an invitation to join to org and they'll have to accept to join We'll add another user this time it'll be Peter exampro doco we can keep the access level at basic add the user to the exam Pro test project and this time we'll assign the user the project administrator's role then click on add another thing you can do is add members to a specific project so from the projects tab you can click on the project exam Pro test click on teams click into exam Pro test after that click on the ad button and we'll search for Peter exampro doco click on the user and then click on the save button below and there we go the user is now added to the exam Pro test project team so that's a general overview on how you add users to your organization in a specific project the next thing we'll be covering is how to create work items so so first you'll need to be at the boards Tab and then you'll need to click on work items on the top right here we'll click on new work item we have three options here there's epic issue and task epic is simply a large body of work that can be broken down into smaller more manageable pieces of work this is also known as user stories so we'll click on Epic as an example now we'll have to fill out some fields to define the work item so starting with the title we'll call it something like test new login feature right below it we can assign people to the item this can be one or many but we'll select only one for this example so let's choose Andrew Brown for the state we'll leave it at todo for the area it's already set at exam Pro test the iteration is set to exam Pro test Sprint one we would want to give the work item a description to help understand what it's about for this example we can write something simple like conduct a series of tests on the new login features for the priority we can adjust the importance of the work item one being highest priority and four is the lowest we'll keep it at two so it's about medium priority we can set a start date so we can just use the current date as of this recording for the tags they already have some suggestions for us so we'll use testing login feature and security which matches the item we don't really need to set the link for this example so we'll click on the top right and hit save after that we can head back to the work items page and we should see the work item we just created with all the information we provided for it such as the title user assignment state area path and so on another thing we can do is click on boards this is an easier way to visually view the items so we have three columns that work items can be placed in to do doing and done which are all pretty selfexplanatory on the top right here we can filter to epics or issues and and we can drag and drop the work item from todo to doing and eventually we can place it and done when the item is complete so that's a general overview of how to create a work item in Azure boards hey this is Andrew Brown from exam Pro and in this section we'll quickly go over how to create a Sprint first on this page we have three work item examples that were created beforehand and we'll want to click on the Sprint tab on the board section here we don't have any Sprints created yet so we'll need to create a new Sprint by clicking on the top right we'll need to give the Sprint a name so let's just call it Sprint one and we'll need to identify a start and end date for the Sprint so we'll start it on Monday April 15th 2024 and end the Sprint on Monday April 22nd 2024 so that's one week length then click on create next we can click on the schedule work button from your product backlog or create new work items on the right we have our Sprint one and we can drag and drop the work items to include them in a Sprint so let's drag some of the work items created earlier into Sprint one we can also create new Sprints by clicking on the new Sprint button below Sprint one so for this Sprint we can call this Sprint two and for the date range we can set the start for Monday April 29th 2024 and end the Sprint on Monday May 6th 2024 then click on create we can do a quick refresh so Sprint two appears let's add one of the work items to Sprint two so if you click into Sprint one you can see that we added two of the work items on the backlog from earlier if you want to delete a Sprint you can go to Project settings on the bottom left under the board section click on Project configuration and as an example we'll delete Sprint 2 so we'll click on the three dots next to Sprint two and keeping it at exam Pro test is fine then we'll click on delete so after that we can go back to the backlogs or Sprints and we can simply add the other work item into Sprint one when we go to Sprint there are additional tabs such as taskboard backlog capacity and analytics we'll quickly go to capacity we can assign days off activity and capacity per day we'll just assign an activity for both of the users such as deployment and design and for the analytics tab there's the burndown trend that shows a visual graph of data such as the amount of work that has been completed in a project versus the total amount of work that was planned so that's pretty much a quick overview of how to create a Sprint and a few of its features the next thing we'll be covering is how to connect Azure boards to GitHub first you want to click on the project you're working on then on the bottom you want to click on Project settings and under the board section click on GitHub connections after that under the connect GitHub with Azure boards click on connect your GitHub account next thing you'll need to do is to log into your GitHub account so sign into account using your username or email address or password and click on side on after confirming the information click on authorize Azure boards now you'll need to select a GitHub repository that you may want to use with your Azure boards click save after choosing that then after confirming all of this information click on approve install and authorize you can choose to add more repositories or remove them you can remove connections as well you can also add new GitHub connections as well so that's a really quick and simple walkthrough of connecting Azure boards to GitHub hey this is Andrew Brown from exam Pro and in this section we'll be going through an overview of custom Azure boards dashboards centralize with custom dashboards custom dashboards and Azure boards are crucial for presenting a comprehensive overview of your project status and key metrics by tailoring these dashboards to highlight crucial data your team can streamline workflows and improve decision making customize with widgets widgets are the heart of azure boards dashboards presenting diverse data from progress charts to work item queries select and tailor widgets that best display the team's critical information ensuring essential insights are readily accessible monitor backlogs with query widgets incorporate query widgets to filter and display work items based on defined criteria like outstanding tasks per team member this enables efficient task management and helps in setting clear priorities track progress with burndown charts use burndown chart widgets to graphically track project progress helping to identify any delays regular review of these charts keeps the team's progress aligned with project goals visualize performance with charts enrich your dashboard with charts that convey performance metrics such as bug Trends or team velocity providing a clear picture of the team's Dynamics and highlighting areas for improvement enhanced team engagement share dashboards with your team and stakeholders to offer a live view of the project status fost a culture of transparency and Collective accountability the image on the left shows an example of a dashboard customized to the way of the devops team or stakeholders this shows information such as the velocity Sprint burnd down backlogs completed and active work items and so on so that's an overview of custom Azure boards dashboards the next topic we'll be covering is Wiki for documentation Wiki offers a collaborative space for team members to compile and share crucial details about a devops project here's a simple guide to leveraging wikis for Effective project documentation start with an overview page Begin by setting up an overview page this should introduce the project its goals and the team working on it mention the Technologies tools and methods your project employs keeping it broad but informative detail project requirements dedicate pages to outline the Project's requirements break down what the project needs to do and how it should perform using clear and achievable language add user stories what needs to be true for the project to be considered complete and any other elements that rely on each other architecture and design documentation use the wiki to detail the project structure and design make a separate page for each part whether it's a component a larger section or a service to help visualize how these parts interact include diagrams like uml or system architecture sketches encourage team input get your team involved in the documentation process allowing everyone to edit and update Wiki pages not only promotes teamwork but also helps keep the information current make sure to use the wiki version tracking to monitor changes and roll back if needed so let's take a quick look at where this is in Azure devops so at the overview section we'll need to click on Wiki and we already created an example Wiki with proper documentation so this is what it'll pretty much look like using markdown we can click on the edit button on the top right this will allow you to edit the wiki to your fitting you can also create more than one Wiki if you want so we can name it like example Wiki 2 so that's an overview and guide to using Wiki for documentation the next thing will'll be covering our process diagrams for documentation process diagrams are visual guides that show the steps in a process making it easier to see how everything connects especially in devops projects here's a simplified guide on using them effectively pinpoint essential processes first identify the main processes in your devops project such as managing source code integrating changes continuously testing automatically deploying and monitoring break down these processes into smaller parts make flowcharts or bpmn diagrams which stands for business process model and notation use software like Microsoft Visio draw. or Lucid chart to create diagrams that map out the process these diagrams should clearly show where the process starts and ends include decisionmaking points and outline the steps in order these visual tools are effective for mapping out the workflow making complex processes easier to understand and follow on the right we have a process diagram or flowchart that outlines the customer support procedure it begins with a ticket submission followed by case assignment if during business hours the support team responds otherwise and on call technician is alerted at assign tickets prompt reminders while assigned ones are prioritized for review and resolution by the support team the process Cycles until issues are resolved culminating in ticket closure and a followup email detail what goes in and comes out for every step in your process note down what you need to start which are the inputs and what you expect to get out of it which are the outputs this might be Code test results deployment packages or anything else relevant it's important to show how each step is linked to the next clarify who does what make sure your diagrams indicate who is responsible for each step this removes confusion and makes sure everyone knows their responsibilities so that's a quick overview of process diagrams for documentation the next topic we'll be covering is configuring release documentation release documentation is a Cornerstone for the successful deployment of software releases within Azure Dev Ops focusing on the noncode aspects that Define the scope quality and functionality of the release here are the key elements of release documentation release notes these should highlight what's new what is issues have been resolved and any enhancements made as well as outline any modifications to settings and their effects on existing features installation guides provide clear detailed instructions for the setup process including a list of required software and system prerequisites and post installation actions configuration changes document updates to configuration settings clarifying any default settings and essential changes change log keep an accurate record of commits or work items in the release using a consistent tracking method roll back plan and have a clear predefined plan for reverting to an earlier software version if necessary creating release documentation in Azure Dev Ops Azure repos store your marked out or text files alongside your code Version Control your documentation for consistency and traceability Azure pipelines automate the generation of change logs and other documentation during the build and release processes artifacts attach generated documentation to specific builds or releases as downloadable artifacts Wiki utilize the builtin Wiki to share detailed guides and notes with the team and stakeholders on the right we have an example of a release notes entry in Azure devops which displays all of the key Elements shown earlier this includes the new features enhancements configuration changes node issues and roll back plan so that's an overview of configuring release documentation next while covering API documentation properly configured API document m mentation is essential for developers and stakeholders in understanding and interacting with software interfaces this guide highlights the key steps and best practices for creating and managing API documentation in Microsoft devop Solutions steps to generate API documentation generate documentation utilize Visual Studio to generate API documentation access this feature via the bill menu use tools like Swagger Azure API management or open API for automatic documentation generation from your codebase documenting endpoints clearly Define and describe each API endpoint detailing the purpose and functionality include information on request and response formats as well as any authentication requirements selecting formats and styles decide on your output format and style ensuring it's readable and accessible for your target audience integration and automation integrate documentation generation into your continuous integration and deployment pipelines within Azure Dev Ops on the right we have an example of an API documentation this API documentation details two endpoints for version 1 two 3 of a service the first endpoint is post API login which authenticates users and returns a token upon successful login it requires a username and password in the request body the second in point is get API users which retrieves a list of users both in points provide example responses indicating successful operations with a 200 okay status best practices for API documentation consistency use a consistent format for all API and points to make the documentation easy to follow Clarity ensure that descriptions are clear and concise avoiding ambiguity Version Control manage your API documentation within Azure repos for versioning and historical tracking regular updates keep the documentation current with every release deprecating outdated information prly feack mechanisms include a process for developers and users to provide feedback on the documentation for continuous Improvement by focusing on these elements your API documentation will be an invaluable resource for your team and stakeholders supporting the effective use and integration of your software's API so that's an overview of API documentation with the rise of devops and get stronghold inversion control the manual slog of updating docs is given way to automation now developers can create Dynamic documentation straight from their G history here's a guide on how how to automate documentation using Azure Dev op Solutions and its Azure pipelines feature three requisites a git repository hosted on platforms like GitHub or Azure repos an Azure devops account connected to this repository automating documentation with Azure pipelines step one set up your pipeline in Azure Dev Ops select pipelines from the project menu and click new pipeline take your code repositories platform in the repository itself choose the main branch as the source for your Docs tailor your pipeline settings pick the right agent and decide when this pipeline should run add tasks for building the code and another for generating docs step two build the code and insert a build task into your pipeline to compile your code this can be net core node.js Python and many more finetune this task to match your project this might mean different commands or scripts depending on what you're building confirm a successful build before moving on step three generate the documentation post build selected tool like docx tailored for net projects to parse your G history into documentation add a new task in your pipeline for docx set this up with the correct paths and configurations and Let It Craft your docs step four publish your work once your documentation is ready pick a spot to publish it this could be Azure blob storage an FTP server or Azure pipeline's own artifact storage add a publishing task to the pipeline and configure it with the necessary details deploy this task and see your document ation go live step five make it automatic to really put your feet up configure triggers and Azure pipelines to run your documentation job on autopilot you can set these to activate on new commits merges or even on a schedule once set your documentation updates as your code does no extra input needed so this is a simplified overview for automating get history documentation with Azure Dev Ops hey this is Andrew Brown from exam Pro and in this section we'll be going over what are web hooks web hooks are userdefined HTTP callbacks triggered by specific events like code pushes or comments on a blog when an event occurs The Source site makes an HTTP request to a configured URL this allows for automated actions such as data transfer notifications or initiating other workflows how web books work event occurs a specific event triggers the webook this event could be an update a deletion or some activity like a user action or system event http request the source site makes an HTTP request to the web books URL this request can be a post which is the most common get or any other HTTP method depending on what was configured action taken the server that receives the webbook does something with the information like updating a database notifying users or initiating other workflows some of the common uses of web hooks include automating workflows web hooks can automatically update a testing server deploy applications or update a backup notifications they can notify other systems or services in real time when events happen for example if someone posts a comment on a Blog a webook could automatically tweet the comment or send an email Integrations many services offer web hooks to integrate with other services without requiring a custom interface for example PayPal uses web hooks to notify your accounting software when you receive a payment advantages of web hooks efficiency web books offer a more efficient method for receiving data than continually pulling a service for updates they push data as a becomes available minimizing latency and reducing the amount of bandwidth used realtime processing web hooks can facilitate realtime data processing by triggering a reaction immediately after the event occurs so that's a quick overview of web hooks as we mentioned briefly earlier webs and Azure devops trigger HTTP notifications to a URL for events like code updates or build completions facilitating integration with other systems so let's go over some of the steps to configure notifications with web hooks select the event navigate to the project settings and then to the notifications tab as shown in the image on the right identify the event you want to track for instance if you're interested in when a bill completes you would select that event new subscription click on new subscription to create a new webook select the specific event you want such as build completes configure action define the action that should happen when the event occurs this typically involves sending a notific to an external service customize your webook you can customize what information you send along with the webook Azure devops allows you to send specific data related to the event authentication if needed if your inpoint requires authentication you will need to configure the appropriate headers or payload with authentication tokens or Keys test the subscription once configured it's crucial to test the webook to ensure it works as expected Azure devops typically allows you to test it through the interface Monitor and adjust after after setting up monitor the notifications and ensure they're firing correctly you might need to troubleshoot or adjust settings if you're not receiving the notifications as expected so that's a quick and general overview of how to configure notifications with web hooks hey this is Andrew Brown and we are taking a look at Version Control Systems which are designed to track changes or revisions to code and there's been a lot of software over the years that helped us do that we had CVS abers mercal and get so back uh in 1990s when we got CVS though even though we had it I don't think a lot of companies were using it it took some time to adopt if you ever heard of like Doom or Wolfenstein you'd be uh interested to learn they didn't use Version Control Systems and what they would do is they would literally copy files onto floppies and hope that they don't lose their files but of course a Version Control Systems makes it really easy to not worry about losing floppies or CDs or drives because they keep track of all the history then came sub version in 2000 but the real game Cher was in 2005 when we were introduced to a new type of version control system and we had Mercurial and get um but the key difference between the old ones and the new ones was the old ones were centralized and the new ones were decentralized and these decentralized ones became very popular for very specific reasons they had full local history and complete control of the repo locally they were straightforward and efficient for branching and merging which was a really big deal uh better performance improve fall tolerance flexible workflows work fully offline um and out of the two git was the one that won and there are reasons for that we'll talk about that when we look at version control services um but uh yeah git is the one that everybody is using today and that's why we are taking this course I just want to point out they going to come across a lot of terms that sound like trees tree trunk branches um the reason for this is that Version Control represents um uh the revisions or changes in a graphlike structure you can even say a dag um if you're familiar with that and so uh you know you'll see these terms and we're not talking about real trees we're talking about uh the components of a Version Control so there you go hey this is Angie Brown and we are taking a look at git so git is a distributed Version Control System a dvcs that's going to be hard to remember and it's created by lonus Toral if you've ever seen that name before you might know that lonus is the creator of the Linux kernel but he is also the creator of git and git right now resides with the Linux Foundation which I believe is a nonprofit set up by Linus as well or has some part to do with it where a lot of open source projects reside um but you know I don't really want to focus on that I want to focus on the practicalities of git so the idea with Git is that each change of your code a git commit can be captured and tracked through the history of your project a git tree so I'm going to get my pen tool out here for just a second and so I just want to make this very clear so we have over here a file and a get commit can or a commit can be made up of multiple files with multiple changes in them and then they're represented over with a a a a message okay so here this is a single um git commit and it can have multiple files and uh files and changes in that single one and then that's your tree okay so hopefully that is clear if it's not don't worry we'll get HandsOn skills and we'll definitely be able to remember them later I want to take a look at a bunch of common get terms um and it doesn't matter if you remember these now but you will know what they are hopefully by the end of this course um and so there is this nice graphic here that is provided by Wikipedia that gives an idea of how all of these terms uh work together um but let's go quickly through them and see what we can make sense of so the first term is a repository this represents the logical container holding the codebase in fact you you could interchange the word codebase repository and mostly mean the same thing we have a Commit This represents a change of data in the local repository and so um that's pretty clear then we have the tree this represents the entire history of a of a repo so when you see tree just think of that graph we have remote uh this is a version of your project hosted else Ware used for exchanging commits uh some people might be a bit uh picky about this because they might say remote is actually a remote reference to repository so it's pointing it's a pointer but I'm just going to make it think that it's a remote uh repo it's just somewhere else and there uh there are branches so these are Divergent path to development allowing isolated changes you're absolutely going to know what branches are you're absolutely going to have to work with them quite a bit um there is a branch known as main it was formerly known as Master uh the word was changed because it was not a popular term anymore and so now main is the new name uh and this is usually the default Branch or the base Branch uh if that makes sense there too so we have clone this creates a complete local copy of a repository including its history so this will create like a little dogit folder um so it's not just the contents of the files but some configuration around the git repo we have checkout so this switches between different branches or commits in your repo we have poll so this downloads changes from a remote repository and merges them into your branch we have push this uploads your local repository changes to a remote repository we have fetch this downloads data from a remote repo without integrating it into your work um we have reset so undoes local changes without options to unstage revert commits we have merge this combines multiple commit histories into one we have staging files this prepares and organizes uh changes for commits it's not a command but like it's just where you would work with your files um in the example here I'm just going to get my pen tool out again it's kind of over here it has to relate with this up here as well and So within staging files we're going to have commits which we already talked about prior and then there's that add command so adding things that will get committed so hopefully that makes sense and we'll see you in the next one okay hey this is angre brown and we are taking a look at version control services and if you're thinking that we already covered this it looks that way but the other one was Version Control Systems this one is version control services and yes they have the same initialism which is confusing but it's very important to make that distinction because those are two separate things so version control services are fully managed cloud services that host your version controlled repositories these Services often have additional functionality going Beyond just being a remote host for your repos get is the most popular and often the only choice for a VCS and we often call these git only uh providers get providers um I need to also point out that some people call version control services Version Control Systems and vice versa and it just gets really confusing so I did my best to make that clear distinction between the two okay let's take a look at some vcs's so the first here is GitHub and it's owned by Microsoft it's the most popular VCS uh due to offering uh due to its ease of use offering and being around the longest at least forget um and they've always been very developer focused and super friendly uh GitHub is primarily where open source projects are hosted and offer Rich functionalities such as issue tracking automation pipelines and a host of other features I remember the day GitHub came out and I signed up for it because I was so done with using subversion then came along gitlab so gitlab was an emerging competitor to GitHub and at the time had unique features such as cicd Pipeline and improved security measures this is no longer the case as GitHub is now on par with gitlab um but yeah at one point a lot of people were looking at gitlab then there's bit bucket this one is owned by at laian you might have heard of laian before because they are uh the same company that makes jira and jira is the most commonly used project manager uh for um people in Tech so you know even though GitHub is really great for developers a lot of companies still use bitbucket and the interesting thing about bitbucket was that they originally hosted Mercurial so remember I said back in 2005 mercal and get came out well alatan adopted mercal GitHub adopted um git and git one and GitHub one and so what's really interesting is that bitbucket then eventually added git and then sunsetted Mercurial so everything basically is get now there is another provider called sourceforge they're one of the oldest places to host your source code they existed before GitHub um and they were the first uh to provide free of charge um uh get repository hosting to open Source projects um the only thing about Source Forge is that they never really dominated because they just had so many ads and bad practices and so it just didn't work out for them they are still around and a lot of Open Source projects like to only host there they might mirror make a copy to other providers like GitHub um but for the most part everybody's on GitHub um but there you go hey this is Angie Brown we are taking a look at GitHub and this is a version controlled service that initially offered hosted manage remote get repos and is expanded to provide other offerings around hosted code bases if you go look up what GitHub calls themselves today they call themselves like an AI uh developer powered platform um it's really bizarre because they are basically a host for uh for get repos with extra stuff on top of it but I guess since AI is so popular they got to try right but let's take a look at all the functionality that they have so we have get repository hosting that is their main bread and butter we have project management tools issue tracking PLL requests and code reviews GitHub pages and wikis GitHub actions GitHub copilot GitHub code spaces GitHub Marketplace GitHub gists GitHub discussions collaboration features for organization organizations and teams API access development so GitHub development uh they have a GitHub CI they have sdks um we have security features like autod detecting credentials in repos they have education specific things or course automation like GitHub classroom and I'm sure they have more uh we're going to learn about all of these things because this is what the GitHub course is about to understand the full offering of GitHub and to make best use of it and just a fun fact is that GitHub was originally built in Ruby on Rails Ruby is my favorite language rails is my favorite framework so I've been uh uh on the the ride or the train since day one with GitHub um so I know it pretty well but let's jump into it okay hey this is angrew brown and in this fall along I want to show you how to create your own GitHub account every single developer on the planet should have a GitHub account because it's a great way to Showcase your work uh we'll talk about that later but you can see that I'm already logged in here so I already have a GitHub account and what I'm going to do is log out and I'm going to create a new one from scratch so here we can see uh we can have multiple ones um I'm going to just sign out of all of my accounts here and let's go ahead and create ourselves a new one so I'm not sure remember I told earli I told you they're like the leading AI power developer platform which is such a silly term but um let's go ahead and see if we can make a new one so just in case it's the future and they've changed this homepage I'm going to go up to sign up and I'm going to see if I can make an account if I can find an email that has not been used so far so I'm going to type Andre exam pro. if you're using Gmail so I can't use that one if you're using Gmail you can use like plus signs to um create multiple ones so like my really really personal email don't email me because I don't ever check this one is like omen gmail.com you'll learn that my username on GitHub is Omen King why it is that I don't want to talk about it it's like forever ago I made this account like so long ago and I really wish I could have got Andrew Brown as my username but that's not what it is and so I'm just going to go here and say alt okay so this is a trick with Gmail that you can do you can put a plus alt on it or uh maybe a minus I'm not sure but let's go ahead and see if that works and I need to create a password so I like to generate really strong passwords um you can use whatever you want I like to use hold on here I like to use this site which is the uh password generator plus password generator.net um I should make a disclaimer if this isn't insecure don't use it blah blah blah but I'm pretty sure it's fine so I'll ually go like 24 and get a nice long password um and I'll just generate a few different ones off screen here and I'm going to enter that in okay so just generate out a few and I'm going to drop this in on here okay we're going to hit continue says it's strong that's good and then I got to choose my username so I probably can't get Andrew Brown and um so I need like another name I'm gonna try Dono not available that's like my game uh gamer uh tag on um steam so what's another one that I could have uh we'll just say Andrew Cloud can I get that one so hard we'll just say Andrew WC Brown can I get that there we go WC is my M middle initials it doesn't stand for water closet okay I know it looks like that we'll go ahead and hit continue I hit continue again and so now what I need to do is do this verification please solve this puzzle so we know you're a real person uh verify okay use the arrows to rotate the object to the face in the direction of the hand okay use the arrows so I think I have to make it face the same way match the angle okay uh this way okay there we go create my account and so now I need to open up that email just give me a moment okay all right so I've been waiting a few minutes and I haven't seen anything and I resent the code so maybe it doesn't like emails that have that plus in there it's totally possible so I might actually have to go ahead and create a new email which is quite the headache as I ran out of emails here unless I can think of another one you know what I think I have another idea I'm going to use uh a different one here so it looks like unverified can I change this I'm going to try um because you have an a privacy a privacy email uh will be used for account related stuff yeah I'm not really sure what's going on here I thought maybe my account even exists but it looks like it already does exist so what I'm going to do is I'm just going to add another one I can do Andrew maybe at teacher seat.com we'll try that oh it's already in use oh my goodness it's so hard to get an email out here okay let me just think about this for a second all right all right another thing I'm going to try is I'm going to try uh maybe Accounts at teer seat.com that's another one that I might be able to use okay and I going to change this over here and save it great and that should be my primary now right it really wants to send it to this one maybe what I can do is I can click oh looks like we have both okay so we have this one um please verify that I'm going to get rid of this one here because that one's not working I'm going to try Accounts at teacher city.com so that's in my Outlook so I'll go take a look there and see if I get it all right so this is working out totally fine so over here we have um the confirmation email so I can go ahead and just verify that email we can also just grab this link I kind of prefer using the link here um because that just gives me kind of a guarantee and we'll go here and now we are in so this is exciting um it's been a long time since I've made a new GitHub account so I'm not sure exactly what to expect but looks like we have some places we can start stting a new project collaborate with your team learn how to use GitHub hey I'm already doing that you don't need to do that GitHub let's go ahead and skip this for now and we should get back to our main dashboard so we are now in and we have an account that we can use um so yeah that's all I wanted to show you in this video uh but I'll see you in the next one okay ciao hey this is Angie Brown and this fall along I just want to show you that I'm going to be setting up multiple accounts to quickly switch between them um if you want to take full advantage of learning how to use GitHub you're going to need probably another account because you're going to have to have somebody else to work with so I already have my primary account I already showed you how to make an account so what I want you to do is make a secondary account I know it's a pain but go ahead and do that but what I'm going to do in this video is show you how you can log into both and switch between the two and I'm also going to set up a repository um that I'm going to put code examples in if we happen to put any in there so what I'm going to do is go up here at the top right corner I'm going to go add account and so this is going to allow me to log into my other account I can put in my username or my email so this one is um this is monsterbox pro.com that's my old my old company that's not been around for a long time but I've never updated it and the exam Pro email is on a another GitHub account but I'm going to go ahead and find the password so I can go log into this one so just give me a moment I'm just trying to find it here it is there is the password I'm going to paste it in here okay we'll hit sign in okay notice it says GitHub mobile so now it's my opportunity to show you GitHub mobile so what I'm doing is I'm opening up my phone and right away it pops up it says uh you know new signin request now it says reject or approve I'm going to hit approve it says authentication request was approved uh the first time I I had to do that I had to enter in like a code like two numbers but now from then on I just have to do that and it's very easy to uh to do that so if I want to switch between accounts we can go here and just switch between them uh freely so that is really easy and so what I want to do is go to exam Pro this is my other organization you'll learn about organizations in this um this here that didn't really help but what I want to do is create a new repo I can create a new one up here in green or I can go up here I never notice these up here but this is another place to do that anyway you're just watching you're not doing right now okay so I'm going to go ahead and hit new and in here I'm going to go to exam Pro I'm going to say um GitHub examples so this will be the um GitHub we'll say a repo containing GitHub examples for or Pro for programmatic examples for programmatic examples this will be public because I want you to have access to it I want to have a read me I'm going to create that repository and so this will crop up later in the course and you'll have to know where this this is but just remember that is but the key part of this video was how to log into another account um and be able to switch between them okay so we'll see you in the next one ciao all right so what I want to do in this fall along is set up a GitHub organization and the reason we want to do this is so that uh it's going to make it easier when we get to that section so what I'm going to do is go to the top right corner and I want to I can make this in either or account I'm going to make it in the alternate account cuz I already have a enough organizations in my main GitHub account and what I want to do is go over here to um maybe organizations and here it says you are not a member of an organization we could turn this account into an organization I don't want to do that or we can make a new org so I'm going to make a new org and notice right away it's going to hit us with some pricing so um you know teams gives you the uh full functionality we just want to have the free one uh which might have some limitations but um it should get us started if there's are things that we can't do um then I'll switch over to our paid one that I have in my account for the most part we should be able to do um pretty much everything as long as we're using a public GitHub um public GitHub repo so I'm going to go ahead and hit create a free organization and so I need some kind of name for this organization um so um I don't know but we'll just say uh GitHub Cloud Learners or journeyers okay notice that's going to be the name of it I say Accounts at teachers seat.com and this organization belongs to a personal account we could say uh business or institution but then we get a little bit more details there so I'm going to just stick it to normal and go to personal account then down below we need to solve our puzzle so we've seen this one before we'll rotate that out and we'll submit okay and you'll have to name your organization whatever you have to name it but that's what I'm calling mine you can put some numbers on the end here if that makes it easier you do like four five six seven or something because these are going to be unique names just like your your username going to go ahead and hit next and so now it says add organization members so we can go ahead and add some people so what I want to do is I want to add um Omen king so I'm going to go ahead and do that please don't add me all right add your own other account your two accounts okay we'll hit complete setup and so now this person has been invited I'm not sure if they're instantly added um not yet but I believe that I was yeah here's the invitation so we'll go here so the invite has been sent and we'll have to go look for that so I'm going to go over here and switch to my other account okay and so now what I'll do is I'll click up here and maybe it's up here my notifications no do I have invites here no and um maybe I got an email I'll check my email no email and this is something you'll learn about GitHub which is like invites are a pain and you always have to really figure it out so I'm just trying to think about where that or that could be um what we could try to do is type in the organization name which I thought we already did um so this one let's see my profile is this yeah so the organization is going to be what was it Cloud oh I don't even remember we'll switch back to the other one what a pain okay and we will look for that organization GitHub Cloud journe so I'm just going to copy this URL I want the um view organization I want to go to this page actually I'm going to copy it here I'm go switch back and I'll enter this in and so now notice that it's showing me where the invitation is so it says Andrew Brown invited you to join this organization view invitations okay and I I don't know if there is but I'm just going to double check here because a lot of times GitHub will have like invitations invitations they might have a page for it they don't GitHub if you're watching make a slin ation page so we can easily find them across them here so as you've been invited to GitHub Cloud jors ask for GitHub copilot seat optional I guess this is kind of an upsell they're like hey do you want to be able to use GitHub copilot but I'm going go ahead and join this organization and now I'm in there so there's two people in here again we'll come back to this later I'm the member this is the owner um and uh you know if your company is using GitHub they're likely going to be using using organization so it's good to get some knowledge on that but I'll see you in the next one ciao all right let's make sure we understand clearly the difference between git and GitHub I don't think it's that confusing but it is in the study guide or exam outline so I'm just trying to make content that they want us to know um so let's do a comparison and go through some things to make sure we understand the difference so git is a distributed Version Control System a dbcs and GitHub is a version control as a service I called it a Version Control service it can also be called a get provider or you can call it a version control as a service I'm just trying to get you exposure to all those different terms you could call what GitHub is for functionality for Git it manages source code history for GitHub it provides cloud storage for git repos of course it does more than that but that's its main functionality um for Access you're doing this via your local system installation or it's basically wherever it's installed the point is is that you're working on it on a machine on a server or some kind of compute uh and GitHub is access through a web interface because it is a cloud service for the scope we're talking about local repository management and then for GitHub we're actually talking about the online collaboration and remote hosting uh so anything that has to do with remote or things around the repo the git repo itself for collaboration it's for local changes requires manual sharing for GitHub it has integrated tools for collaboration ation like issues and PR and a lot of other features for usage you're going to be using this primarily by the command line interface there's definitely software out there that makes it a lot easier to use um we'll get into that but generally it's a command line tool that you're using for GitHub it has a graphical interface and it also has its own CLI tool but most people are interacting with it via the website okay so there you go ciao so a git repo or repository is your git repo think of your local one that you push Upstream to GitHub to be uh hosted remotely and GitHub allows you access to manage your repo uh with several functionalities so here is a screenshot of a GitHub repo this is when I ran a boot camp in 2023 uh and so let's talk about what is on this GitHub repo page I don't know what they want to call this page I just called the GitHub repo page for a specific repo um but you can view different branches view tags view commit history explore repo files view releases uh see codebase language breakdown view top level markdown files and so those top level files might be the readme the license uh security other things like that you can perform actions from this page or quickly to it such as pinning watching forking starring cloning so so uh a lot of stuff going on on this page and this is going to be we're going to be spending a lot of time or going from here to somewhere else but that is a GitHub repo so there you go all right in this follow along I just want to give you a tour of GitHub repos so that you have a a general Fami familiarity uh so that when we start diving in a bit deeper we understand what we're looking at so I'm on my dashboard I have a lot of different repositor um and so I can go here and find a repository I can search stuff and say like if I'm looking for my boot camp I can type in boot camp here and then make my way over here and find it um a lot of times when you are looking for stuff you're going to use the global search so up here you could do that as well and I could find my own repos or other repos um there are a lot of Open Source repos on GitHub and so um I know rails pretty well so I'll go ahead and type in rails and so we have this rails repo I'm going to go open this open this up and take a look and see what we can see because this is a very mature Li um uh GitHub repo and we'll make it very clear of all the functionality that's happening so notice we have our main area this is where all of our files are uh we can actually view any of these files so I can click into any of them so I can go into the gem file and it will show me the contents of the gem file what I like about uh GitHub is that when you click into here then you kind of get this file explorer and it's extremely powerful uh if I click this on the right hand side it will show me symbols that's not a very good example I might open up a ruby file to show you what I mean so I'm just looking for a ruby file here and so this will show you like places you could jump uh jump towards in your code um that's really nice you can see who did what by going to blame so we can see exactly what somebody's doing by the way I'm going really quick here it's not important for you to remember any of this I'm just giving you a tour of stuff so just relax and uh enjoy the information that we're learning here you don't have to write it down if I wanted to find a file really quickly in this repo I go here and type something in so maybe I'm looking for um something like View and so it's going to drop down and it has this fuzzy search if I want to find a ruby file I could type this in we have a lot of them here I believe there's a hotkey here so if I hit T if I'm over here and I hit T it will bring me over there I can switch branches really easily um does that let me add a file it's not my repo but if I add a file I'd have to create a fork um the search brings that up there but we'll go back over to code Okay so my point here is that you have all the files here and you can browse them um you can switch branches you can go and take a look at all of your branches you can take a look at all your tags you can star you can Fork you can watch here for code you could launch this up in code spaces which is a cloud developer environment I normally have um G pod install so if I hit refresh that button might show up here this button you will not have this button I installed this because it's like code spaces but different um on the the right hand side you get a bunch of information about the repo like stars watching Fork uh some of these probably are conditional cuz I don't remember seeing these on myos you have releases so maybe you are building up binaries like downloadable files that people can uh utilize so some people they will host all their code here and they'll build the binaries for quick downloads so that's somewhere else you can go to packages is probably similar to releases I don't I don't think I've ever used packages ever in my life uh let's go over here and take a look browse browsing all packages yeah I don't know what packages do we can see who's using it the contributors so people that are writing uh writing code um we have the languages so you can see this is mostly a ruby LI or um repo which makes sense because it's Ruby on Rails down below we get a preview of our readme file so that is in the top level directory they have a codes of conduct I imagine that is a markdown file here and as well the license file I'm sure that's in here as well the security policy as well um so yeah there's a lot going on in here and then there's all this stuff up here these are features on top of your repo so lots and lots and lots of stuff if we want to see our commits we can go here and click on commits and this is kind of like a tree it doesn't give you the full view because when you are looking at um when you're looking at a tree uh there's branches and stuff so we're missing that information here but the idea is you can go here and uh go to different branches and look at those commits and that's basically all I wanted to do here we'll get into it a lot deeper later on but that is your tour of GitHub repos ciao hey this is Angie Brown from exam Pro and we are taking a look at git commits so we're going to take a look at a series of git components uh in this course um it's not really a focus on git skills but more so GitHub but I want to make sure you still have some git skills so after we go through uh some of these things I'll then do like a really quick and dirty uh git uh command crash course okay so a git commit represents incremental changes to a codebase represented with a git tree so a graph at a specific time so here we can see that git tree um this is in GitHub so it's not the full representation when we go into um vs code we will we can see a better representation of it there are external tools for that but for the most part the idea is that you have um uh you have get commits that are over a historical period of time then we have our uh git commit here is one within uh GitHub that I clicked through and I looked at okay and from here a get commit contains additional modifications deletions of files additions and deletions of file contents and it's not the whole file themselves and this is a strategy to make the uh commits efficient because if you if you were to store full copies and every single commit your repo will get really big really fast I'm going to repeat that again and we'll talk about the contents of commit fils here just shortly uh each commit has a Shaw hash that acts as an ID so it looks something like this we can use this uh to check out very specific commits which is very useful I want to repeat get does not store the whole files in each commit but rather the state of changes this greatly reduces the file size so uh so for developers to the developer you it will look like a whole file but really when you store it in in uh your G tree it's not going to be like that um so what are the components of a get commit we talked a little bit about that but we have that commit hash that is a unique Shaw one hash identifier for the commit I don't know if it's really Shaw one because I'm not really familiar with all the different a Shaw but it's Shaw something uh we have the author information so we have name and email often you have to configure git to say what email you're utilizing the name so that's attached to the commit message U or the commit itself you have the commit message is is the description of uh the the Commit This is we're going to be spending a lot of time when you are making commits because you want to write good commit messages you have a timestamp so this is the date and time when the commit was made um you have the parent commit hash this is a Shaw and hash of the commit this commit is based on I don't really understand that because I've never had to bother with the parent one but it is something that's in there and the snapshot of the content a snapshot of the project at the time of the commit not the actual files but references to them and the changes that are occurring so if you had vs code open and we were taking a look at a um at uh changes that we have staged so they haven't been committed yet but you can see here we have uh the commit message it says remove old comments we have files changed that we plan on putting in the commit and you can see some deletions there on the right hand side we can have additions so hopefully it's very clear what a uh a git commit is you are going to need to know these basic commands and we will get a little bit practice again quick and dirty this is not a fullblown git course but it'll be enough to get you buy so that you can do the GitHub stuff so we have a bunch of stuff there like get add get remove get Comm message with the The Hyphen m flag to add a message hyphen a to automatically stage all track changes if you have a commit and you haven't pushed it up uh to your uh your remote repo you can amend it um you can create empty commits uh you can specify the author if you need to you can check out a very specific commit but yeah that is get commits in a nutshell and I'll see you in the next one ciao hey this is Angie Brown and we are taking taking a look at get Branch so get branch is a Divergence of the state of the repo there might be better uh descriptions than that but that's the way I think of it you can think of branches as being copies of a point in time that have been modified to be different and so what I want to do is Step you through what it would look like working with get branches and this is going to be a little bit messy and it doesn't matter if you can remember or make sense of all this because it will make more sense when we start working with it but do your best to follow along here so imagine we have a git repo in that git repo we have a main branch and basically all git repos have a main branch and that's pretty much the standard name for them now and we're going to also have a production Branch the main branch is where we're going to have code uh that features and bugs will be um rolled up into and then when we're ready to push it out for production it will go to the production branch and some cicd tool will push it out and automatically deploy it so um let's imagine we already have a commit in the main branch uh maybe there are previous versions in the production Branch we're not going to worry about it so uh you have developer a developer a needs to to work on a very specific feature they're going to open up a feature branch and in there they're going to put in some commits and they're working along uh meanwhile in the company somebody already has pushed some stuff into the main branch it's not ready to go in production but that commit is now out so what's important to note here is that feature Branch one is not aware of that new commit because things are happening asynchronous a in async manner in different branches and this is the challenge with get is that you have to deal with all this async stuff and make sure you bring those changes into yours deal with conflicts things like that now let's say we have developer B and developer B is working on feature Branch 2 and when they started on their on their um uh their feature they decided to branch from this point in time okay and so they start working on it and they get their feature uh done and um they get they talk to their um uh the director of engineering and and they make a poll request the poll request gets accepted it gets merged back into main okay and so developer a who's working on uh feature Branch one has all these changes that they still don't have so let's remember that they're going to have to deal with that at some point but anyway that feature got merged into Main and it looks like it's ready to go in production so it gets merged into production and so this particular commit contains get my pen out here contains all of this information right and it's all packed into here if that makes sense okay I'm just going to erase that here and so that gets P production and it gets tagged a lot of cicd systems will trigger when a tag is applied that's definitely how I do it but now coming back to developer a they're on feature Branch one and they have all the stuff um that they need to get their Branch up to date so what they'll do is they'll merge back in in their Direction I know it doesn't show a merge but they'll merge that information into feature Branch one so they are now up to date and they have now finished their feature by doing a bit extra work and so they've merged back into into the main branch and now their stuff is to be rolled out to production so it gets merged into production and then that gets Tagged so hopefully that gives you kind of an idea of uh this kind of workflow this should have really been like that uh and this actually has a very particular name it's called the GitHub flow now there are some variations of this so that's why I say very close to it because in case I'm wrong I want to have that buffer to say that well I didn't say this is exactly the GitHub workflow but this more or less is the GitHub workflow where you are creating branches feature branches merging it back into some other branch and then you have a branch for production uh you can have branches for all sorts of things you can have specific environment Branch branches like staging development production you can have specific branches to developers so like based on their names you could have branches per features branches per bugs it's going to be based on what your team wants to do all right uh there are definitely get Branch commands you should absolutely know and we will do again a quick quick and dirty crash course so you are familiar with it this is a extremely common pattern that you're going to find that you'll be doing which is is you'll be creating a new Branch for a feature you can be adding changes you're going to be pushing it Upstream we might do this via via's code using the git CLI we might be doing this using GitHub uh creating a branch from an issue but we'll definitely be doing this because this is something that happens a lot um in professional um uh teams is that they're creating feature branches so hopefully that makes sense and again if it doesn't wait till we go ahead and do it and then it will make more sense then okay ciao hey this is Angie Brown and we are taking a look at get repos so these represent the reference to a remote location where a copy of your repo is hosted so when I say remote get remote I'm saying remote reference or remote ref you might see those terms uh used all over the place uh you can have multiple remote entries uh or remote references for your git repo and the most common one you're going to see is called origin it's almost always uh there uh everybody seems to use it it indicates the central or golden repo everyone is working from and represents the source of Truth uh the remote entries or references are stored in your dogit config we don't really talk about this dogit folder in any of the slides but the dogit folder is how you know that your project is a uh has a a git repo in it because it needs that folder uh to initialize a get repo we'll look at that in the quick and dirty crash course um so in here in the config file you can see we have remote defined so this format of a file is called a toml file um so anytime you see those Square braces and then definitions that's usually a toml file but I'm just going to get my pen tool out here the idea here is we're saying we uh we have a remote named origin and the URL is pointing to our GitHub repo this part says how it should fetch I'm not going to get into that right now and then down below we can see we have some branches that we are tracking and they're pointing to remote origin and then they uh they're saying that we want to U merge um uh there so hopefully that is clear notice remote names can be referenced so we have origin up here and it's referencing this up here okay so I'm just going to clear my annotations here so this is a little bit more clear here and there are a bunch of get remote commands you should know I don't remember the most like the git remote ad I don't ever remember that one because often when you clone it's going to add them anyway and so usually you pull them from GitHub but you should know push you should know pull you should know fetch uh and when you are creating branches you should know um how to uh push upstream and we'll talk about upstream and downstream next okay all right let's talk about the concepts of upstream and downstream so imagine we have GitHub who is hosting our remote repository and then we have our local developer environment or Cloud developer environment uh this is local basically where we are doing our work and so they both have a main repo because we know that git is decentralized so we can have repos in more than one place we might already have some commits on the remote side but what's going to glue these two together is going to be the remote and so we set up a remote tracking Branch okay and and you'll see that term when you create uh and you push branches up because the idea is that it's tracking uh the origin is pointing to main so this is the way we track them uh we saw that was stored in theg getconfig so when we go ahead and we perform a poll from our local developer environment we call this Downstream we're pulling Downstream so a repo that pulls or clones from another repo and just understand this is relative to the direction or the perspective um of who's pulling so if the remote was pulling it would be Downstream it's it's anytime you're pulling it's always Downstream and now imagine we have commits we've been working locally we want to push those up to remote we would call that Upstream so this is when you are pushing changes so that's Upstream that's Downstream and when we have a remote reference it is a tracking Branch so there you go okay hey this is Andrew Brown we are taking a look at GitHub flow so this is a lightweight workflow for multiple developers working on a single repo there's a lot of variations on this uh so this is not a technically perfect description of it but there really isn't one and I want to show you a really old graphic um I don't know how old this is but I've seen this and older ones maybe all the way back to 2008 at least and I remember before GitHub flow because GitHub came or sorry G came out in 2005 and it took a few years to gain adoption so for a long period for a few years we just had a mess of stuff and then somebody came up with this maybe it was GitHub I'm not sure but uh it's called the GitHub flow and um here we have a bunch of branches and it looks very similar to the one that I showed you in get branch it's a little bit different and so the big difference is that well first of all uh we don't call it Master anymore we call it main but my main was the develop branch and then I would call this Branch master I would have called it production because I think that makes more sense and a lot of people do that these days but when it first came out this is how we were doing it okay so understand this variation but the idea is that you have this one branch I call it main this is develop and it holds things that um that uh that hold feature br branches or hot fixes and everything it's basically like rolls everything up but it's not in production yet and so the idea is that when these things are ready for um production you can push them out into a release Branch a release Branch could be also called staging that's normally what we call uh today and this could be where it would roll out so once you push stuff here this could go out and execute a cicd pipeline and would set up a staging environment so that QA could be done on it or kind of load balancing could be done on it or stress testing um there and the idea is that as developers you would open up feature branches off of develop and as you complete them they would come back in here uh and they would get merged in and then when things were really ready you take it take it from uh release branches and push it out to your production branch which they're calling uh here uh Master if for whatever reason you had a serious problem you had to fix really quickly you could uh uh create a branch off a master into the hot fixes and then merge it back in skipping all the stuff down below uh you know again I wouldn't do it this way anymore I would be surprised if companies are sticking uh to this method but this is the original way I just wanted to show you that there is variation um and you know a lot of people do skip having a release branch and they'll just deploy often and into production so it's going to be really dependent on your team so here we'll just kind of Lo Loosely described GitHub flow you create a branch for each new task or feature create a new Branch off the main branch add commits make changes and commits commit them to your branch open a poll request start a discussion about your commits reviewing code in the poll request discuss a review share your poll request with teammates for feedback deploy test your changes in production environment um so yeah oh and the last thing would be merge so once your changes are verified merge them into the main Ranch so that's the general concepts of it and hopefully that makes sense and we will see you in the next one hey this is angrew brown and we are taking a look at the GitHub CLI so this is a command line interface to interact with your GitHub account you can quickly perform common GitHub actions without leaving your developer environment and uh if you uh went through the quick and dirty um get uh crash course then you definitely got some exposure to GitHub CLI but the idea is that you'd have to log in you can perform AC there so we have something like creating a repo creating an issue uh reviewing a PR there's a lot of uh CLI commands the good up CLI can be installed on Windows Linux or Mac OS um that's an example of using Brew to install if you have it for um uh Dev containers you can specify it as a feature to get installed so that is a very easy and quick way to have it uh installed there and just to give an idea of commands we have our core commands we have a lot of additional commands and then we have one specific to GitHub uh actions command so we're definitely going to get some exposure uh to GitHub CLI in this course but there you go all right so in this follow along I want to take a look at the GitHub CLI and see if we can do a few different things with it what I'm going to do is switch over to my other account um this is just my uh playaround account for for GitHub and we should already have a repo in here called GitHub examples and what I want to do is I want to um you know just do some things in the CLI so I need some kind of environment to work in and so what we'll do is launch up a code space uh we do have this older one um I think what I'll do is make a new one I don't think it really matters if we make an old or new one that other one is stopped so we'll open this one up and we'll see if the GitHub CLI is already preinstalled it could be preinstalled on this because I would think that if well if I was GitHub I would have it preinstalled so people start using my product right away but if it's not we'll definitely go ahead and take a look at how to install it we did install it manually locally um in the uh git crash course the quick and dirty crash course so uh you know if we don't have to show the install I'd rather skip that but we'll wait for this to spin up okay I have no idea why but that took a little bit time to spin up um you know our goal isn't to really make anything just to play around with the um the CLI here the Cod space is currently running in recovery mode due to configuration error I didn't do anything I I don't care it's um I mean it's a new environment why should it be recovering is there something it can't do yeah I'm not sure about this so what I'm going to do because I don't trust this workspace is um this one is running here I don't know we'll just see what we can do with it but it didn't pick up my settings when I told it to save it earlier so I don't know if it's because it's in recovery mode or not but for the time being I'm going to go ahead and change the theme so I'm not upset there we go that's a lot better and I want to see if we have um GH installed so it's not installed which is totally fine um so what I'm going to do is if we had this installed can we install through here sometimes you can install stuff through plugins right and so I'm just curious if we could do that there no okay so that's fine we'll go ahead and install this and I definitely know that Brew is installed or maybe it's not installed on this let's find out it is installed on git pod but I'm not sure about GitHub it's not okay so what we'll do is we'll look up the GitHub CLI and we'll go ahead and install it we already did this before but we'll do it again and what we're looking for is those install instructions and we want it for um Linux okay so we'll go over into here into Linux and we'll grab this on line command it looks like a lot but it's really just doing this update and this install like down here but it has to add the repo so it knows where to install it from but I'm gon to grab that big thing there and we're going to go ahead and paste that on in say allow and hit enter and um it failed it failed and I can't look at I can't see what I'm doing so I'm gonna bump up this font I do not like GitHub code spaces I'm so sorry I really like gpod and we're going to go here and say terminal font I'll try not to complain to much about it in the course but uh I can't promise anything I'm going to copy that again and we'll try this again it an enter no such file directory okay um yeah I don't know what you want so there's this line here okay maybe because gpg gpg isn't installed sometimes you don't have to do a gpg check but we might have to with this and um failure to right destination okay so if that's not working maybe what we could do in an easier way is we could just add it um to the uh uh to the that this file this code spaces file so we can just make a Dev container um and maybe that would be less of an issue so what I'll do is I want to add a Dev container um we'll go up to here Dev container like that we actually already have one from before and maybe we can just throw it in here so grab this maybe we do want to commit this maybe this is a good idea um and so I'll put this here and I need a comma there and so the idea here is that this should install the CLI into this environment and maybe the reason why this thing messed up was because it wasn't specifying any base image and that's why I got upset because when we did this in the tutorial earlier um it kind of complained or sorry like when we spun this up it complained but we didn't specify a base image so I'm going to look up what the base imag is for Dev container the base image for GitHub is and maybe that will help us if that doesn't help let's go let's go ask chbt log in let me in let me in come on I P for this let me in what is the what is the base image used for uh Dev container for GitHub code spaces let's see if that can figure it out it's probably just going to go to the um the documentation but um I don't remember where it is so if you don't specify one it will create in the default one okay that's what I would rather it do so I'm going to leave it alone and what I want to do is rebuild uh this environment because we've added this change before we do I need to commit this maybe so I'll just say um it should install the GitHub CLI go ahead and do that and I'll say okay so it should sync it up good and so let's see if we can find the rebuild I'm clicking up here rebuild that's no good we can open up the command pallet this way command pallet has all the commands for for vs code and there should probably be something for codes space so if I type in code spaces there's probably something here to rebuild there it is rebuild container so I'm going to go ahead and rebuild that container I'm going to go ahead and hit rebuild and so I'm hoping that we'll install the CLI and that avoids us having to install gpg or whatever it wants because that's a headache and I don't want to deal with that so see you back here when this finishes building okay all right we're in it says the code space is currently running in recovery mode due to a configuration please review the creation logs update your Dev container as needed or rebuild the container so clearly doesn't like something about my file I'm not really sure because there's not a whole lot in it um so we have command control shift p okay control shift p hey like learing learning right and uh we want to view creation blogs oh that's just to open up the uh command pallet view creation log and somewhere here it's messing up now I don't understand how it could be messing up because we literally have next to nothing in it um yeah this is supposed to be an easy easy GitHub CLI tutorial failed to C the container an error occurred unified containers error creating fail doesn't even tell us why it's just like nope it doesn't work maybe it's up here um no matching entries and P unable to find user Dev container okay maybe it's this okay let's take this out all right and uh that's probably the reason why okay so we'll save that okay we'll have to update that don't change remote user okay want Push to Main and I'm going to try to rebuild this again I'll open up the command pallet down here below just in case and I want to say rebuild um I want to do like a full rebuild let's do a full rebuild that's fine let's rebuild and we'll get it going this next one okay I'll see you back in a moment okay so I think that resolved the issue it took a while for that to rebuild but what I want to see if the C is in here so I'm going to type in GH and there it is okay great so that's the easy way to get in there as long as you don't make any mistakes in your Dev container uh Json or JS or Json Json file and so let's go ahead and see what kind of actions we can perform so what I'll do is go over and type in GitHub CLI and we'll take a look at the documentation and see that's not what I want I want the official documentation so we can see what kind of commands we can get here it is okay so here's all of our Comm comms and the question first is are we logged in because that's something we might need to do so let's go ahead and type in GH login oh sorry JH off login to log the CLI and we have two options we'll do github.com it says the value of the GitHub token environment is being used for authentication to uh okay so it sounds like we already are authenticated because of um GitHub code spaces and it's loading some kind of temporary um token in here something we could check here is to see if there actually is a token being set so I'm going to type in EnV grep and we'll type in GH and I don't see anything there but apparently it seems to think that it is ready to utilize so maybe what we could do is list out repos so I imagine if we go here there's probably something like list there is and we could try to list our repos let's go ahead and try that GH repo list and we have a repo that's that's actually a really nice display what else can we take a look at here um so again back over to the repo list our repo what if we go to view what would that do let's take a look G repo View and I was hoping that it would set it would select the current one but apparently it didn't but we can do uh GH repo set default and I got to type it right maybe it'll let us choose the repo so we don't have to goof around and so there it is we can choose one and apparently uh we have two exam Pro Co and the Andrew WC Brown curious that it's showing forked ones but this is the one I want because this is the count I'm in right now and so let's go ahead and type in GH repo View and so now we can see some stuff in here um not a lot of information it looks like it's kind of the information about maybe the description or stuff like that so I was hoping to see a little bit more there but that's okay let's go down here and see what else we can do um we could edit our repo like we could change features turn things on or off that's not that interesting something we might want to do is maybe we might want to uh maybe change our labels let's go ahead and try that out so I'm going to go here and say GH labels list um is it just label or labels label oh cool yeah we could see our codes can we add a new one in here uh we'll go to create so GH label so we try this one here copy it paste it in and there already is a bug so we can't have two so I'll go here and just say um Danger something really not right we'll hit enter and so it looks like we've created another label let's go ahead and hit up okay so that looks really good there bug isn't working good um if we wanted to create a new repo sometimes what they'll do is they'll um they'll create like a uh a wizard in here so if I typed in GH create repo and I said um GitHub we'll just we'll just do this I bet it will prompt us oh I got to type it right I seem to be typing everything wrong here today repo create and so it'll ask us some things like create a repo from a template repository make a new one so I could do this I say GitHub um repo GitHub CLI example and I'll just go ahead enter here I'll just make this one private I could add a readme file we could add a Gore we could say what we want the get ignore to be so maybe it's for C++ that let's add a license we could choose a POI 2.0 um we want to do this we'll say yes and it seems like it should have created but we get a resource not accessible by integration for 403 so I'm not 100% sure as to why we're getting that it could be a permissions issue because everything is based on um that token right and so maybe we have a personal access token that allows us to read but not right um and we got a 403 right so 403 error is for forbidden meaning we don't have access to do it so what I'm thinking is that we can probably create our own um personal access token and try to get around that so I'm going to go to settings here I'm going to go all the way down develop for settings and we're going to go into personal access tokens find grain tokens and we'll generate a new token again I don't know if this will work but I'm just going to try it so we'll just say um uh repo access right let us create a repo and I'm going to set this for tomorrow because I don't need it forever and if it's for all repos then that's a challenge right but then how would you create a token this is public repos so here it says this applies to current and future repos owned by this resource all all includes public repos read only so the other question is is it because we tried to make it a private repo but then why would it have it as an option if we can do that I mean we could also authenticate uh via SSH so I'm not sure so I guess that's where I'm not 100% sure so maybe we'll just say all repos here and we'll go to repo permissions and I'm looking specifically for repos contents no and carefully looking here to try to find that um account permissions maybe it feels closer to this type in repo uh let's see here so what does this one do interaction limits uh interaction limits on repos I don't think it's that and so I'm just carefully looking to figure out what functionality we would have to provide managing repository environments it could be this read write I would probably put this in just because that is the usual um oh repo creation it's up here so I don't think we need these other ones I'm going to leave them on because they're not that big of a deal um and this one says it's mandatory so sure we'll have that in there got it added in there I'm going to go ahead and generate this token and so now we have this token I'm going to copy it I'm going to go over to here I'm going to type in export GH token and I'm going to go ahead and paste this in and so the idea is that when we use the um uh the CLI it should pick up this as opposed to what what else is on here so I'm typing EnV hyphen grep because I want to make sure that this is actually set as our environment variable if you have other tabs open here it might not show up so just stay on the current tab we'll go ahead and try this again another reason why it might have not worked is because that name was already taken but I don't think so because it's scope based on our user so we'll go ahead and try this again from scratch so we say GitHub CLI example and then we'll say uh we'll put nothing in there we'll make it private and it was interesting there's a visib of internal I imagine that maybe that's for Enterprises we'll say yes yes and it doesn't matter I'll just choose that one we'll say yes doesn't matter I'll choose that one and we'll say yes let's see if it works now clone the repo locally yeah sure let's do that and so now it's working so whatever key whatever personal access token that is somehow being loaded in there did not have the correct permissions we were able to get around that so I don't really want this repo so I want to go ahead and delete it um let's go take a look and see what actions we have there we have delete so I'm going to hope that it just will like give me a wizard so I don't have to pick it so we'll say GH repo delete um and I don't want to delete our current one so I'm going to hit contrl C because that's totally not what I want and we'll go back over to here and we'll take a look and see what we can see for the uh repo I really wish they would list them up here maybe if we go to the getting started or available commands yeah that's a little bit easier it's not great but uh we'll go to repo here and we'll go to delete and we can put the repone name here so we'll go back over to uh GitHub here we'll go to our names this is going to be Andrew WC Brown and we should be able to see two repos in here there's our other one I'm going to grab that name and I'm going to go back over here and I'm going to say that so do I want to delete it so type the name again sure and we have to put in also uh the username in front of it we'll hit enter and that repo should be now deleted we'll go back over to here okay and it's deleted so that is in good shape so that's all good so I'm really happy with that I'm going to go ahead and stop this uh code code space I'm just going to delete it and you know I'm gonna delete the other one I'm just going to make sure I keep everything nice and clean and and not worry about overspend and what I want to do is just merge this into my other account again you don't have to do this you can just watch me do this but it's good to watch because this is something that people have to do a lot and actually what I should have done is I should have gone over here and I should have done it from here first so I'm going to go here and create a PR create create a new PR and we'll say create is going in the direction we want yes it is we'll hit create um fix Dev container we'll create that pull request good we'll switch back over to our other account and then I'm going to go into uh the same repo I'm going to accept it confirm it and we are in good shape I'll see you in the next one ciao a common strategy for authenticating uh to perform git operations on your remote GitHub repo is by using an SSH key uh you're definitely going to want to use this because it is a great way um to work with Git uh in your local developer environment it's definitely the way that I like to use it as opposed to using a personal access token but uh the way it works is you'll have to generate out your own SSH uh key using a command like s key gen for Linux there's probably different ways but that's the way that I know and specifically an RSA key I'm sure there's different kinds of keys that uh GitHub will take but that's the one that I know and so the idea here is that we have our computer our local computer and then we have the server which is a GitHub and the idea is that there will be a copy of the public and private key on your local computer and then on GitHub you'll store that private key and so the the process of authenticating and authorizing is going to go like this so the server checks to see if you have the same public key if you both have the same public key it's going to send you a challenge message that challenge message contains the public key uh encrypted and so it's going to send that on over and then uh the idea is that um the private key on the local computer will decrypt it and then it will be able once it decrypts that message it will then take the private key and do something there and then send back a well it won't do something it'll send back a signature um and then that signature will be sent to GitHub and then they'll verify it and that will establish that connection allowing you to use SSH keys to get clone or push or or things like that uh under your account settings SSH and gpg keys is where you'll be able to add the public keys so here you can see I have a couple SSH keys in one of my GitHub accounts and it's there under SSH and gpg keys and when you want to go use um or clone a a repo you're going to really want to use that SSH style address it will not not work with the htps one or the GitHub CLI one technically will work at the GitHub CLI one but that's what you're going to want to do there so there you go in this video I just want to show you quickly how to create SSH Keys we did cover that in the quick and dirty uh git crash course but it's good to do things more than once so that we really get good at them I'm going to open up a new environment here in code spaces and we'll get that spun up so I'll see you back here when this is ready okay all right so we have this environment spun up and it's just not remembering my uh settings whatsoever but you know that's just how things go and I'm going to make a new folder in here I'm just going to call it um SSH keys and I'm going to just go ahead and make a new read me file so normally what we'll use is the SSH keyin command I realize that's small I'm just going to jump it up like that and so we use T RSA to make an RSA um uh style key I would imagine that GitHub can support different kinds not that I know much about the different kinds let's go take a look here and see what we can see so that's from local I'm going to go ahead and delete that um because I don't need that right now if we go here you can see things like SSH RSA sha 2 something like that so so be interesting to generate something else out so ecd SSH key key gen ecd so I want to see if we can generate something that's a bit more secure I I assume it's more secure is a relatively new crypto cryptographic solution um it's been around for 5 years okay so how do we make it and the way we make it it's probably by supplying this like that okay great so what I'll do is go back over here and we'll change it from RSA to this one and see what happens I've never done this before but I imagine it's super simple and I'm going to CD into the SSH directory I'm going to go ahead and hit enter say allow yes I want to paste we'll hit enter and see if it can do this and so we'll go ahead and hit enter um it will create it in the code space directory so I suppose that's fine and we'll do that and that and so then we're going to get that key and then the idea is that we can then go ahead here and then we could go and cat out the contents of it right all right and so we could copy this and it's actually a lot shorter that's actually really nice I like that and then we could go over here and then we could add it so just say uh Cloud developer environment for CDE and we can add that key now I want to point out that you can add keys to repo as well so we're not going to really test this to make sure it works I just wanted to generate out another one and show you that but what we'll do is we'll go over to our repo because I want to show you where that deploy Keys things is and if we're in a repo like this we can go to our settings and there should be deploy Keys down below and we could add a deploy key and it's the same process you just paste it on in you save what it's from uh you can say whether you want it to have right access and boom there you go but a lot of these um repos only need readon so especially if you're building you're just cloning the repo so you don't need that but that's all I wanted to show you so going to go ahead and Commit This okay so just say uh basic instructions for SSH okay so that's all good I'll say okay and then what I'm going to do is just switch into my other accounts and I probably can merge the other way too um if I try that so if we go here to PLL requests we go to new PLL request and I could probably try to grab from that other repo so I want to bring in from here from there yep I can do that and then I'm just basically allowing myself to pull the changes and without the other Andrew having to uh put it forward okay there we go and we are emerged I will see you in the next one so deploy Keys allow you to attach public Keys directly to a get repo and the use case for deploy kees are if you're using let's say a build server or a c cicd third party service that needs to clone the repo so they can perform a build or deploy or maybe single repo access so instead of using a shared key pair for the uh for multiple repos you have a single key pair for single git uh git repo and another reason would be to avoid using the personal access token um I'm going to tell you I've definitely used deploy Keys especially if you're not using GitHub actions and you're using third party cicd tools which is pretty common with GitHub um you will find yourself using deploy keys and I just want to make aware that's very similar to the other one with some advantages so you have to decide in your use case where you're going to want to use it but it's as simple as that okay hey this is Andrew Brown and we are taking a look at personal account access tokens or specifically personal access tokens or Pat which is an alternative way of using a password for authentication now Pats are not specific to GitHub but they do utilize them uh and the purpose of these tokens is to give you access to the API um when you're making direct calls or using the command line or using the SDK uh GitHub no longer supports the use uh of using a password directly with interacting with API they used to but now you have to use an access token uh if you're coming from like the adus world it's kind of like your access secret um so it's giving you that access uh there are two types of paths on um GitHub you have the classic token they're less secure and no longer recommended for use customers with Legacy systems may still be using the classic token like some of my apps uh then you have fine grain uh personal access tokens these Grant specific permissions they must have an expiry date uh you can only access specific repos um or if you want all repos it'll probably only be readon you can only access resources owned by a single user or organization you can find the stuff under the developer settings um there are a few use cases where we'll use uh Pats it would be like logging in using get clone for HPS and uh let's say we are using uh the GitHub CLI you could set a token or sorry a environment variable called GH token to be used uh for for the GitHub CLI for the to pick that up uh if you're using SDK you're going to be supplying your token I would imagine that the uh that these um sdks would pick up that environment variable as well but there you go hey everyone it's Andrew Brown and this fall along I want to take a look at personal access tokens yes we've already played around with them but let's play around with them a little bit more okay and so what I'm going to do is go over to my repo and I might already have a code space from before and it's already still active so I'm going to go ahead and open that to save myself some trouble if you have to launch a new one you can absolutely go ahead and do that remember to close your codes places so you are not using up your free tear usage uh you get so many hours per month I don't know what it is uh you can look it up if you want to know or we'll find out when we make it over to the uh code spaces section in the course um and so what I want to do here is I just want to uh work with personal access tokens now we might have one set from before so we going to take a look here and see what we have so going type in EnV grep G and see if there's anything set and there's nothing set here so that's great and what I want to do is go to the top left corner here go to settings and then down below we'll go to our developer settings and we have our personal access tokens we have fine grain tokens and token classic now something I would like to know I'm going to go ahead delete this one what I would like to know is can we generate them out from the GitHub CLI you think you wouldn't be able to because then you need permissions to have permissions but I'm going to take a look here and see what we have um because I'm just curious to see if it's actually there or not and so I'm going to just type in token and there is a token so it says this command outputs the authentication token for an account on a given GitHub host well that's really interesting so what would happen if we wrote that in so I'm going to type in GH author token and see what we get and we actually get a token back so I'm not sure if that means that um that's that token code but let's find out if it is by generating out a new token another thing I might wonder is like what permissions do we have I'm not sure if it would tell us I don't think so what's refresh refresh our token expand or fix the permission scope of the store credentials that's kind of interesting like you go out and request to have more permissions but I'm not sure exactly how that would work um but let's go ahead and generated a new token I'll just say um create issues and I'm going to set this for one day okay and we'll go down below and we're going to select it for a very specific repo this one here and I'm going to go to permissions and I'm looking for issues we'll say yes to issues read and write and we'll go ahead and generate that token and so we can see that's what this token looks like we're going to copy it bring it over here and I'm going to set it to this so I'll say GH token equals and then a double quotation paste it in enter and so now it should be set so if I type in E EnV grap uh GH we should see it there excellent so now let's type in Gs off token and see if we get a different value notice that this is the one we have now it shows that we're using a personal access token so this is getting load in loaded in by GitHub Hub how it's getting in there I don't know but this one looks exactly to be the same as this one let's go test and see if we can make an issue so go down below here and we will say create and I'll scroll down and grab an example so we'll do this and hopefully it'll just know to create it in the current repo enter and we need to set a default repo so we'll go ahead and do that I'll choose this one here and I'll try this again and so it's created it oh this repo has um issues disabled that's interesting so we'd have to go ahead and enable that so I'm going to go back to our repo here I'm going to go over to settings and we'll go down below and we'll turn on issues now we could do this via the CLI but it's just easy to checkbox that and we'll go back to our environment and we'll hit up and now it's created the issue so now the question is if I get rid of that token like I unet it uh what would happen so what I'll do is I'll just hit up till we get to that set and I'm just going to purposely set it blank okay and that way this shouldn't work and so now if I do GH list issues list I wonder if I can get a list of them now remember this repo is public so it's going to work because it's public but the question is can I delete the issue so I'm going to say delete and um it's expecting some args if I type help will tell me how this works the number of it that's perfect so the number is two so that's easy and I wonder if I could just put a two on this type two to confirm yes okay it deleted it now the thing is is that yes I was able to delete it but just understand that this thing has some base uh access underneath that original token and so it probably had permissions this one here to do that there's probably some things that this thing can't do and we learned that before which was that uh being able to create a repo um but uh you know if if I did this on Local Host I would assume that this would have not worked and that's totally fine I think that satisfies us for learning about uh personal access tokens I'm going to go back to our personal access token go ahead and delete it and we'll call this one done okay so I'm going to go ahead and go into personal access tokens and delete this and if you want you can stop and delete your code spaces I'll see you in the next one ciao let's quickly talk about read me files these are markdown files that provide documentation and structional information and a repo a GitHub repo that has a readme.md or readme and all caps or readme and all caps. MD in the projects route will be rendered on the homepage there's actually some other markdown files that will also be rendered there but it's really important to remember the read me one as it will probably come up as an exam question and they'll actually ask you like what uh where where should this be located it's always in the root that's what's going to render yeah I don't think it renders anything else but that one and they might kindy to trick you there um you do get this nice little table of contents on the right hand side so if you have uh headings it will figure that out for you there I remember that wasn't there before so that's really nice um but yeah it's as simple as that okay so GitHub wants you to know about basic repo navigation what that means I don't really know so I'm taking my best guest to show you what that is uh So within a GitHub repo you will have a navigation bar with various features of your GitHub repo and this is how you get to all the cool stuff and the main one is code this is where your codee's going to live um such as files folders things like that um we have issues that's for tracking problems it's basically a ticket tracker we have pull requests that's where we're going to be uh uh when we're managing collaboration with other uh developers and they want to bring changes into our repo it's our opportunity to uh check that work before it gets merged in we have actions that's for GitHub actions uh for projects that's for GitHub projects uh for wikis that's the wiki security is like a a list or a um a checklist of things that you should do I think it changes if you are looking at the context of a uh as a a user and you're not the owner of the repo you're going to see maybe the security policy or different information but if you are the owner you're going to have a checklist of things you should do and it basically mirrors kind of what's in the settings page under security so it's kind of weird that they do that but that's how they do it then we have insights this provides uh statistics mostly in the form of charts and graphs about the repo sometimes this information is public sometimes it's private then you have settings this is where you control all the settings for your repo um the other thing is that when you are using at least in the code section you can navigate around files so I showed you this in a a prior um follow along but the idea is you can search stuff you can see the contents of file you can comment on code per line so there you go so when you create a repo you can choose which owner you want it to be so right now I have it set as uh my personal account but you could drop that down and you could also choose an organization that you belong to repo names are scoped based on the account so you can have the same name uh for different organizations other people can have the same name if they're a different user so just understand that you can do that uh you need to choose an available GitHub name again based on that scope uh your repost can either be public or private um pretty selfexplanatory you can quickly add a readme file a doet ignore and license it's very very important to remember those three because you might get an exam question asking about the three things that you can quickly and easily add if you're using the CLI you can add it uh this way or create one we did this earlier when we did the GitHub CLI kind of demonstration and we found out that repos require special additional permissions or personal access token permissions um that the GitHub Cod spaces would not allow you to do but yeah there you go that's a create a repo all right let's go ahead and create ourselves a repo I know we already know how to do this but it gives us an opportunity to talk a little bit more about uh some of the things that might appear on the exam you can create one up here in the top right corner and I have this double click problem so it's getting a bit confused I can go to this new green button that's usually what I do and we can have a new repo so I'm going to say my uh cool repo right we can provide a description um this repo is amazing and we can set it as public or private I'm going to stick with private for now and we'll add a read me we'll drop down get ignor we'll say maybe we're working with Ruby so we'll get that by default and we'll add a license like MIT we'll go ahead and create that repo um I want to point out that you have other things that are rendered here so that should be very clear um we have releases and packages which we should talk about at some point I'm going to leave this repo around if we want to play around with it um but uh yeah it's pretty clear how to create a repo it's not hard let's go take a look at a more popular repo like Ruby on Rails um so I'm just going to type this up here type in rails and we'll take a look and see what they have um so if we go into here you'll notice there are just more things we have codes of conduct right we have our MIT we have our security policy if we go up here to the security tab this is what we can see um so we have the security policy being rendered out here and then it's showing um possible uh exposures probably based on one of the scanners I'm not exactly sure which one is showing that um but that is that there if we go back to our own repo we might be able to take a look at security here hold on uh going back to wherever that one was we just made that repo it can be a little bit of pain to sometimes find your own repos I'm not sure why they never made that easier but just how it is and if we go down we can find myel repo here and there's this security Tab and notice that it's listing out uh things that you should do for your repo it's important to know what these are because um well if you have this uh the exam is going to probably ask you like what's what things can you access from here and this is just from the public repo if you have a private repo it's going to be different sorry this is private public can be different so let's just open this up and make a comparison and see what kind of difference there is here so if we go over to repo here and we go into this public one over here what options do we get so we get a lot more going on here so so notice that this is the private and that is the public probably because if you're if you had a paid version You' then get additional code scanning and secret scanning for public repos you automatically get that stuff I just want to point out that all this stuff is also under your settings under uh Security Options so they kind of just like repeat it there you know so it's just what they do but hopefully that makes sense and that's all I wanted to show you so I'll see you in the next one ciao let's talk about maintaining a repo now what's unusual about this slide content It's Not Unusual but it's the fact that in the outline they have a whole section for GitHub Administration and uh for whatever reason I have it over here as opposed into the other section because of the way the outline is designed so understand that I'm not going to cover that stuff in that other section because it's just repeated um but anyway let's continue on and look at maintaining repo so the first thing is your name so you can change the name of the repo if you do not like it as long as the name is available you can absolutely do that and a reminder that repo names are scoped based on personal or organizational accounts or organization accounts I I keep writing organizational but it means the same thing uh you can change the base Branch the default Branch uh you can rename it um just so you know Maine is the unspoken best practice for naming your base Branch everybody does it the old one was Master nobody calls it Master anymore um you can opt in and opt out of some features feates for your GitHub repo I say some as a catch all just in case there's features that do not show up or there's ones that are locked in um but that's pretty straightforward you just check a box and you might have to do some additional configuration then there's the danger zone which contains actions you need to think twice about because they cannot be undone if you make a big mistake and in the danger zone we have the ability to change the repo visibility um it's important to understand what happens when you make a a a repo from private to public the code will be visible to everyone who can visit at github.com anyone can Fork your repo all push rule sets will be disabled your changes will be published as activity now will this show up in the exam probably not I didn't see it but that is something to consider um you can disable Branch protection rules uh so Branch protection rules are strict workflow rules uh uh that dis like will do something like disallow someone from pushing to Main and uh you can temporarily disable them if you have to apply quick fixes and you can't work around those rules easily you can transfer ownership to somebody else and they'll become the owner of the repo you can archive the repo so it becomes read only you can delete the repo so there you go all right time for some repo maintenance uh so what we're going to do is I want to create a new repo I'm going to make it in my other account uh just because we're going to want to transfer from one to another but I'm going to go here and just say say um uh under here Omen King and I'm going say my cool repo 2 okay and I'm going to just make this private and I'm going to add a read me here um I'm going to go ahead and create this repo okay so now that this is REO created we can go over to our settings and let's say I didn't like the name two I need it to be three because we already have another one called two in the other account I'm going to rename that and it renames before we used to rename it used to take time now it's instantaneous which is really really great if we scroll on down here we could change the main branch we could change the name to main two um there are some uh limitations there because it's not showing all of our options as we don't have other branches apparently it doesn't create it instantaneously but it will change it in a bit of time there it is so I think it has taken effect if we go here and yeah it shows that it's been renamed so that sounds really good we're going to go back over to settings notice that we can check box and uh checkbox on and off features let's get rid of issues let's get rid of projects if we go over here to our code notice that they have vanished across the top so that is great we'll scroll on down um we have more abilities somewhere here in the danger zone so we can change our visibility it will give us a warning about it I'm not sure why it's making it so hard I'm going to make this public I'm going to say that I I accept the changes and we're going to make it public and then apparently I have to confirm so I'm going to get out my phone and it wants me to enter a number into my phone okay so 37 approve great and I'll wait a moment for it to take effect there we go so now it is public um we can disable our Branch rules so I'm going to go ahead and do that uh we can go ahead and transfer this repo I'm going to send it to um a specific person so this is going to be I want to send it to Andrew WC Brown which is the other me and then I got to type in the repo name so we'll go ahead and do that my cool repo 3 I understand okay so now it should be transferred um and I think the other person has to accept so I don't think it's instantaneous so if we go over here do I have the repo now if I go up here in my notifications how do I see the repo transfer I'm not sure I'm going to go check the email for this account and see if it shows up there okay all right so in my email we can see over here that uh there is a repo transfer link so I'm going to go ahead and click that GitHub repo templates is is a feature for public repos that allow other GitHub users to make a copy of the contents of the template repo to use as a starting point for their own repo and I believe it's only for public I haven't checked for private but I don't know why you'd want to use it for private we set a uh a repo as as a template by checking box on the template repository and then you'll have this option to use the template and when you click use this template it will then ask you to choose a new name and it'll say what do you want to include and then it'll show that that was generated from that other template I use these in my boot camps because I will create a starter project and then you will uh start from that template how are these how is this different from cloning or forking um the idea here is that um you're starting with a clean repo you're not having all the baggage of of stuff that comes with it it is a really clear a clean repo and so that's how you're going to go ahead and uh utilize it but that use case that I explained for which is like you know you want to have something like a project that people are going to start as a basis of that's where going to be using repo templates okay ciao hey it's Angie Brown and this fall along we'll go ahead and make a repo template so um we have here um let's go over here to our other repo trying to find it sometimes it's a bit hard to navigate repos there we go that's a bit better and so we have this my cool repo what I want to do is convert this repo into a public repo for now just so that we can utilize this feature I want to go to the top and see if we can make a template actually it looks like we can I'm really surprised because what would be the point if um it's private you know what I mean because we go here how's anyone going to click that button it doesn't make any sense so I really think that that is a public feature and notice I actually checkbox it on and it turned off so I think it is yeah it is nope okay it's on now all right I mean I guess you could use it to make your own from it so I guess my thought was it was always about other people using it but I guess you could make your own default template and use it for yourself so I guess it's not just a public feature but they're never going to ask you on the exam so I'm not going to fix the slides because of that let's go ahead and uh create a new repository from this template we'll just say my cool repo 2 and we'll make it private and also we can include other branches but I don't want anything else and there we go so now we have this uh repo that is making a copy of we'll give it a moment and here it is you can see it's generated from that one and there you go ciao so in GitHub you can clone a repo programmatically three different ways uh we have the first which is https uh you will have to supply a GitHub username and password on the Clone and you'll need to set uh get to cach the credentials if you don't want to keep entering them in I didn't write it in here but when it says password we're talking about the um personal access token because GitHub does not let you use passwords anymore um but in the documentation it kind of suggests that you can use a password because it says password protected oh not here but under here would it would it would say that um for SSH uh you can utilize that method you'll have to have an SSH key pair and you'll have to upload that to your GitHub account then we have the GitHub CLI um so we can do that as well this is going to use credentials uh when you do GitHub login it'll actually use either a personal access token or SSH we can also clone repos in the GitHub desktop and we can just download a zip it's not really cloning but we can download the contents of it um so that's pretty straightforward there sometimes you just want the the the codes repo um I want to point out that we did all this in the quick and dirty git and GitHub crash course so if you're wondering how to do these three make sure you have watched that video and you've done it all okay see you in the next one ciao you can add files to your GitHub repo directly via the GitHub UI if you drop down code you or sorry add file you'll have create new file upload files so it's great for both text and binary files um and uh the idea here is that when you uh go ahead and add a file if you need to have folders you can put a forward slash and it will end up creating as many folders as you want and then you put the name in and you just create that file there when adding multiple files that you also need to edit you can also quickly use in this course but uh there you go there are lots of ways of creating branches in GitHub and git um something that you should really know how to do is to use this single line command get checkout hyphen B to both create and check out or branch in one go you should absolutely know how to do get push hyphen U origin staging which is basically The Hyphen U is short for hyphen hyphen setup stream I know look like a single hyphen there but there's actually two uh for this flag you can create branches from issues um and then the branching issue will be Associated and linked you can directly create branches in the GitHub UI you can create branches in the GitHub desktop and I'm sure you can create branches in the GitHub CLI and uh yeah there you go hey it's Angie Brown and this fall along I want to create some branches nothing super difficult ult to do but um something that will take us just a moment I'm going to go ahead and use um our my cool repo and what I want to do here is I want to go ahead actually I want to clean these up I don't want to have a bunch of uh junk repos hanging around so actually I decided against that and I just want to keep things clean and keep with our single repo even if it is um public so I'm going to go ahead and typ my cool repo here and clean this up Andrew WC Brown or man gez Andrew WC brown brown my cool repo it's that auto complete that's messing it up there we go and I'm just going to go ahead and also get rid of this one and then we'll just be really focused on what we need to do at hand here just give me a moment there we go okay so now let's just go back to our GitHub examples and there are a few ways that we can create issues uh one is or sorry branches one way is to go to the branches Tab and I'm pretty sure we can just create them right here so I can go here and just say uh feature uh cool one okay and we can say what we're branching from so that's an example and and there it is uh another really useful way and something I really recommend is you create an issue and we'll and we'll make a test and create a branch from an issue okay and then what we can do is then go ahead and create a branch here in development in the bottom right corner no it's going to put the number in here that's a very common pattern is to have whatever your issued number is and then a a a short name for the Branch okay then saying like what should we do next code spaces locally I don't really want to do anything next I just want to um do nothing but I'll go ahead and hit create branch and so then it gives us like a button where we could click to go ahead and play around with it so that is something I do a lot when I teach boot camps I show this a lot this is a very common workflow and something you should absolutely remember uh that you can do um let's go ahead and launch up this in codee spaces so going to go here and we have this one here sure I'll launch up this old one sure why not and once this is launched up we'll take a look and learn how to use a very cool shorthand for um implementing uh checkout and creating a branch in one go okay so just back here when this is ready all right all right so this is back up and running and notice that we are currently in the main branch we can type in get Branch to get a list of branches and so what I want to do is I want to create myself a new Branch here and actually there are other branches it's just not showing them if we do get poll um it might show us those other branches there we go and now if we type in get Branch it still doesn't show them but that doesn't mean we can't check them out but uh our um our uh program is aware of it we might also be able to create branches within a git graph these were things that we installed earlier so they might have the option to do that here I'm not 100% sure see create Branch so we could do that as well I'm not going to do that but what I really want to show you is something that will show up in the exam I'm actually really surprised that it did but it is a really good thing to to um uh to know is that normally when you create a branch you'd have to type in get branch and I'd say my new Branch like this and then I'd have to do get check out my new Branch okay okay and so that's something you can do but what is more efficient you can go check out back to main is we can do that in one call we can see get checkout hyphen B for branch my new Branch 2 and that's going to create that branch and check it out so really make sure you remember this one because it will absolutely show up on your exam it's absolutely something you'll use every single day I strongly recommend it the last thing um I want to go over is just pushing to origin so what we can do is is set um Upstream but I think that U is a lot easier to do we say origin and we just say my new Branch here two and then that will push that Branch up there because you really want to know how to set that origin so that's all I really wanted to show you and um yeah we can just stop this environment so we'll go ahead to command pallet just say stop current code space and I'll see you in the next one okay ciao so GitHub releases allows you to create releases with release notes and linked assets such as zip sources or binaries for specific platforms so in a get repo you'll see releases and from there you can read about the release and see all the stuff that has changed and there might be the source code or binaries if you if this is something like um I'm trying to think of an example like let's say you like to play video games and there's an emulator uh for like the PlayStation uh they'll have like builds here for Windows Mac and um other things here uh maybe you make a video game in general you could distribute the binary here it's anything where you're Distributing the binaries or the sour source code but you're making very clear what has changed as a release um and often like when I'm having issues with something I will actually go through and re read the releases when let's say um like react router have you ever used react router Dom and they change versions I'm trying to understand like what compatibilities have changed what does not work anymore maybe I was experiencing a bug and if they do a good job with the documentation it will be in there so there you go hey everyone in this fall along I want to take a look at GitHub releases as it is a very useful feature to let people know about changes that are happening in your repo um so before we do let's go take a look at some other project that might have changes I'm trying to think of something interesting like maybe an emulator um so I'm just typing emulator in here I'm just looking for one here's a Nintendo switch emulator or maybe PS PS2 I'd rather do PS2 I feel like they might have good uh information about changes like PCS pcsx2 and on the right hand side you can see we have releases and if we open up the releases um they do not tell you much okay so that's not a great example so we'll go back to another one and we'll try another uh video game emulator maybe we can just try putting the word emulator you know and people can write whatever kind of releases they want this doesn't have releases uh we'll try the 3DS emulator this one doesn't have releases we have this one here do they have releases no well they do they do no just tags okay so I guess we're just going to not get really good ones here but I guess we could just go to rails cuz they seem to always have enough for us but I just wanted something that was written a little bit more uh nicer so you could see a good example of a release but here is one where um you know they're talking about different versions I feel like if there was a release for a specific uh tag version right that uh we get better information like when rails first came out like 700 probably would be a good one so I'm just scrolling through here I mean these are pretty good but again I just want to try to find a major release one is this this 1.0 seven I'm going just type in 7.0.0 might have to scroll a bit to get it to load 08 there must be where is it what it just skips over it okay well I mean 71 was pretty good so we'll go over back to 71 and uh yeah like here it's telling you about all the libraries and things that are Chang this one's a bit better because it's showing examples of things that have changed so you can put whatever you want to release and it's just to help communicate what the differences are because a lot of times you just don't know so we did do some tagging and that's a great opportunity for us to create our own release in our own repo so what I'm going to do is go back over to our home I'm going to find this repo that we have I'm going to go over to releases and we're going to create ourselves our own release and we'll just say version 1.0.0 ready for the world the the best GitHub example materials around my hands are cold if if you can't tell I'm uh sorry but I'm in like full snowsuit right now and I got the heater blowing so if you hear the heater I apologize but it's just how it is right now in my office anyway we you can choose a tag which is great and then um you can then attach the binary so the idea is we would download the zip and then reup loed again I'm not going to do that because that's pretty straightforward we'll go ahead and do that and so there's our release and that's all I really wanted to show you for releases apparently there's a compare button I didn't even know that so that might be kind of cool to do but um yeah there you go so GitHub packages is a platform for hosting and managing packages including containers and other dependencies and the things that it can uh host in terms of its package registry or repository is Javascript packages ruby gems Java Maven and Gradle packages net packages and Docker images and the last one I think is going to be the most common uh one that people can utilize um they have a free tier they have a pay tier so you can start using this right away and we will go give it a go um probably the easiest thing we could do would be to create a Docker uh container and then push it to GitHub packages so that's kind of the code that we'll have to go through we can make a simple hello world Docker file run it make sure we build it and uh GI up actions could be used to build and then publish I I wrote the word public but publish packages to GitHub pages so there you go hey this is Angie Brown and this fall along what I want to do is go ahead and create a GitHub package so what you're going to need to do is start up a code space I actually already have mine running I think by this point you probably know how to do that I just uh was working on the video earlier and I had to close out and restart so that's where we are now so anyway I'm going to make a new folder in here and this will be for uh pack GitHub GitHub packages okay and you're going to try to spell s if you hear a bit of noise in the background it's because I'm running the little space heater near my feet so my feet don't freeze I'm in full snowsuit right now okay but anyway what we'll do is we'll go into the package of directory and we'll make a new file and we'll call it Docker file okay and from here here um we want to create this little Docker image so we'll say Alpine uh latest this isn't a Docker course I'm not teaching all this but just follow along with me here or just copy paste it from my repo whichever you want to do Echo we'll say hello world okay so I'm going to go ahead and save that file and now what I want to do is go into that directory and build it so what I'll do is run Docker build hyphen T hello world period we'll build that okay and now we'll try to run it make sure it works there we go that works okay and so we're in good shape uh the other part here I would say is now that we have our Docker image built we want to now push that so I'm going to make a new read me file so I just have a little bit of room to work with here and there's a few things we need to do we need to set our username so I'm going to say username here I'm just going to set mine as what I am Andrew Brown WC Brown that's the account that I have here okay and I'm going to put export in front of it so I can export it and yeah I want allow pasting good and we'll hit enter it actually double pasted it so I got to be careful there I imagine this is a bit hard to read so I'm just going to bump up the font a bit and so that should be set the next thing is I'll need a personal access token so I'm going to go over here and we've done personal access tokens quite a bit in this course and we'll go down to developer settings and we'll make a new one and this one is going to well I guess we got to confirm with GitHub mobile first get my phone out here and uh it wants me to enter a code in one two okay this one's going to be for GitHub packages oh I'm not registering an app whoa whoa whoa whoa whoa let's go back personal access tokens there we go there's an old one I'm going to delete that and I'm going to generate out a new one we'll say uh GitHub packages I want this only to be for a day just in case I forget it and someone tries to take it and this is going to be for a specific repo so we'll go down here and say this repo and then for permissions I'm looking for packages packages it's under here maybe packages let's search for it packages it says we need a personal access token so I'm not seeing packages in here and this makes me think that we should probably use a traditional one I don't normally do this but because I cannot find it I'm going to use a classic token so that's what I'm going to do do um I'm going to go here I'm going to generate a new token really wants to make make a new one and just say GitHub packages and so it's really similar um very similar to the other one oh I want it to expire and I'm looking for packages here it is read and write packages delete packages so I'm not sure where that new one is in the new one maybe it's not and we just have to use the classic token we'll go ahead and generate that token out I now have this token I'm going to bring it on over to uh uh here and I want to set this as our environment variables I'm going to say GH token and we're going to paste that in okay and we'll copy this good I'll paste it in and hit enter so now that's set um I need to set the image name I'm just going to keep putting the GH under it image name just so it's a bit easier for me to find them when I want to find all the variables later hello world we'll go ahead and do that and copy that and paste it in hit enter uh I'm going to put export in front of that just in case that didn't work and then I'm going to do export my hands are really cold it's really cold in here uh I think it's like7 it's because my shed uh has a um oil furnace or gas yeah o furnace and I have to go drive out to um The the Reserve to get some gas and it's just really bad weather so I'm just trying to get this done so you folks can get this course as quickly as possible so we've exported those values so that's really good I want to make sure that they're set so I'm going to type in EnV GP G and there they are okay so now we need to write some code the first thing is we need to log into Docker and so Docker somehow talks to GitHub I'm not sure how that works but we'll just go ahead and work with it here so I'm going to say Docker login um we're going to say g c or say GHC so that's for GitHub container repository I'm assuming hyphen U and then we'll say GH username and then we'll say password STD in okay so that will pass the password that's what that pipe does and see if that works we'll hit enter uh doesn't know what that flag is H did I type it wrong I did and we'll copy that and we'll paste that there enter and so now we're logged in so that's step number one step number two is we need to tag our Docker container so we'll say uh Docker tag and I want my image name and then my version uh this will be GH version and this will be GH I mean we could just write it out if it's a bit simpler for everybody so we just say hello world one0 and then on the other side be GHC doio and then that would be our username so I could just type it in here it's up to you whether you want to use environment variables or not I'm just uh I just want it to work so I'm just going to write it out in full even though we made environment variables up here for this particular use case but that's okay one z z so the idea is we're going to tag um our Docker image we built is uh for 1.0 to map to here okay we'll go ahead and copy that hit enter um no such image I mean there is no tag called 1.0.0 on it we do Docker list or Docker images it's called latest so we'll change this to be latest we can make the other tag latest as well but I I'm going to make it 1.0.0 I'm not sure why I'm just going to do that so how it's going to be we'll go ahead and enter and so now that's tagged and so now we should be able to push it GHC r.i slash say Andrew WC Brown for slash hello world colon 1.0.0 copy enter um so it says an image with the tag does not locally exist with that tag so maybe I tag tagged it wrong T HC R IO I spelled it wrong yeah we could have just copied this one here to get it all right hit enter and there it's pushing it okay so pretty straightforward uh we could have even done this we could said like uh export um tag name right and we could have done this right and then we could just done that that and we could have done that I'm just cleaning it up doing that uh post post refactor here and um here we could have just put these in as such so we could have done this and then this would have been GH uh image name and then this would have been GH version and so you get the idea there so that's pretty much it let's go take a look and see where this actually is I'm done with this personal access token so I want to delete it so nobody else is using it and um this revokes all personal access in class classic just in case I'm going to do this so I'm going to say Andrew WC Brown I think they're all revoked but just in case or not let's do that anyway and we'll go over here and we'll take a look at our profile because it might show up under packages here I'm not exactly sure how you set public packages oh there it is it's private all right and I'm not sure if it's specific to a repo link this package to a repository so I guess if we wanted to link it we would have had to apply a label and so I guess labels are what you think they are they're labels and that way we could associate it I'm not going to do that here today I think that's fine but I will copy this just in case anybody else wants to do that and um we'll go ahead and save our changes okay and this really doesn't want to push here today I'm not sure why get push what doesn't it like um oh push protection okay it detects something here oh is my token in here wow that's cool it actually detected it so that because we turned on security scanning earlier it would not let me do that that's awesome I wish we I I thought I was showing that earlier so don't show token actually what we have to do uh is we can't even just push the old one we have to amend uh the last one we had so if we go over here uh I'm going to have to go ahead and amend this so I'm trying to figure figure out if there's a way I can just quickly amend um I'm going to get rid of this change here first I'm just going to say discard this change and I'm going to type in get commit hyphen hyphen amend and so now uh what I should be able to do is go into here for all changes right and I should able just change it actually no that'll just amend the message sorry that's not going to do what we want uh what we actually need to do here is we out of amend mode I think we are yeah um I'm going to do get reset uh soft head Tilda one and what that will do is bring the changes back into here and so now I can go back and fix that but that's really good that uh I had the the secret scanner turned on do not commit your GitHub token but we did also delete it so it's less of a problem as well uh GitHub packages so just be really really careful with that stuff okay and there you go so I'll see you the next one okay ciao hey this is Angie Brown and we are taking a look at poll requests often abbreviated as PR and you'll see that a lot it's very common uh is a formal process to put forth changes that can be manually or automatically reviewed before it's accepted into your base Branch your main branch here so here are poll requests in GitHub and the benefits of poll requests is collaboration review or collaborative review so enhances code quality through team discussions and peer feedback CH it it tracks changes says change tracking but tracks changes provides a record of code changes and related discussions automated testing enables integration with tools for automated checks and tests controlled integration manages safe and reviewed merging of code changes open source friendly simplifies contributions and collaboration at open source projects I want to point out that PO request is not necessarily A get feature but a a workflow and GitHub has built a bunch of features around poll requests poll requests aren't unique to GitHub um it's just part of the workflow and and whatever they want to build around it they can build around it and that has to do with other tools that do the like jira and bitbucket or whatever other tools like git lab and stuff okay so we can create pull requests using the GitHub CLI uh that's one really cool way of doing it the other way is using uh the GitHub website so you go to the pull request tab in your repo you create a new pull request and there it is I'm sure you know by now how to create a pull request because it's almost impossible not to show you that 100 times over before we got to P requests here but that's how you create them one thing I want to point out is um uh that we have to set a base this is who we're going to merge into and ahead who uh the changes that we're going to pull into notice it says compare we'll talk about that in the next slide about base and compare okay so base and compare determines the direction of the merge for a PLL request and the idea is we have the base so is who you want to merge into this is usually the main branch or an environment specific Branch doesn't have to be main but usually main is base right um then we have compare this is what will be merg into base uh compare is choosing the head reference so notice before I called it head and if you look very closely it says choose the head reference so that's what compare is this is usually a bug or feature Branch another thing that I need to point out is that you can compare across Forks uh this is useful if you're trying to contribute to an open source project so you're going to have the option to Cho the base uh repository um and the HUD repository to different uh repos from different owners so there you go so a draft pull request on GitHub is a feature that allows you to open a poll request but Mark it as a work in progress uh the use cases for draft pull request would be indicating work in progress so communicates the poll request is not ready for review or merging preventing premature merging ensures incomplete work is not accidentally merged facilitating early feedback and collaboration so people can talk about it continuous integration testing so maybe you want to just run uh a test code because when you have a PLL request it's automatically going to start doing that transitioning to a ready state so easily switch from a draft to a ready for final review and merging organizing work and priorities help in managing and tracking ongoing work in large projects um draft requests draft pull request is a feature only for GitHub organization teams I believe you can use it in the uh free um free organizations that are public so we'll take a look and see if that's even possible uh if if I don't make a video then you know that it wasn't um there are two things you need to remember for this for the exam uh draft pull requests cannot be merged code owners are not automatically requested to review draft pull requests okay so remember those two things because they will show up on your exam ciao hey this is Andrew Brown and in this fall along I want to take a look and see if we are able to open up a draft PLL request in our GitHub organization free account that we created so what I'm going to do is make a new repo because we're going to need to need we're going to need to have one in our um our one here and actually you know what I'm going to do no no no I'm just going to uh I don't want to make it too complicated I'm just going to make a new repo so just say uh like fun repo we'll say fun repo okay and this can be public we're going to make it public so just in case we need to have that so we can have that functionality because a lot of times public allows us to have um that paid functionality for free so what I want to do is take a look here and create a new pull request and see if we have the option we don't have any code so we'll need to create ourselves a new Branch I'm going to just do that in here in the UI and we'll just say uh Dev and we'll create that branch and then from here we'll go over and I want to switch over to Dev and then I want to edit the read me here and I'm just going to put in some exclamation marks we're going to commit that change looks good to me and then we're going to make our way over to pull request and we'll make a new poll request and what I want to know is if I can make a draft pull request so we'll say create new pull request and we'll drop this down and there it is okay so that's all it takes to create a draft pull request if there are code owners assigned they can't touch it noce I cannot merge it I'm clicking like a maniac it's not going to happen and that is draft pull requests so there you go let's talk about linking activity within a poll request so you can link issues to a poll request so that the state of the poll request will automatically close the issue we actually already did this before we looked at issues during we looked at issues and we're looking at it again so the idea is that you go up to development on that cost and you choose um the issue or sorry the poll request and then they're linked okay so that will close it the other way is via those supported keywords so if you have any of those words you put in the comment of the actual poll request um then that will close it it says the poll request must be on the default Branch okay the PO poll request must be on the default Branch for it to work I don't know if that's true I mean it worked for me when we did it but but um however we did I guess it was on the default Branch but um uh anyway that's that I don't think there's any point of us showing this again because we've done it so many times but hopefully you know that you can do that and the direction to which it happens you're putting it in the uh body the description of the Polar Quest um so it links to the issue okay ciao let us take a look here at the different statuses a poll request can be surprisingly this isn't an exam question but it's something you should know so let's go through them all the first is open the default status when a pull request is created it's open for discussion review draft indicates the pull request is a work in progress and not ready for review closed the pull request has been closed without being merged this status is used when the proposed changes are no longer needed or if the branch has been rejected merged the pull request changes has been merged into the target Branch the status indicates a successful conclusion of the pull request process changes requested this status is used during the review process when a reviewer requests changes before the poll request can be merged review required indicates that the poll request requires a review before it can be merged this status is common in repos where uh reviews are mandatory part of the workflow approved the pull request has been reviewed and approved for merging by the required number of VI of reviewers conflict indicates that there are conflicts between the pull request branch and the target branch that needs to be res resolved before merging ready for review a poll request initially marked as draft can be changed to this status once it's ready for review so that gives you an idea of the functionality of it and you kind of figure this out as you are working with PO requests but there you go so the code owners file is a GitHub specific file that defines individuals or teams that are responsible for specific code in a repo and so the idea is that they have the syntax that's similar to get ignore and when a polar request is open that modifies any files matching a pattern in the code owner's file GitHub automatically re request a review from the specified code owner the code owner files go in either the root project root. GitHub folder or docs directory um and so yeah I think this is something that is a paid feature it probably could be in free if we're talking about um organizations teams or sorry like free organizations that have to take a look but yeah it is a very powerful feature okay so when you're merging a poll request there are a few options so we have this drop down where we can either create a merge this will bring all commits over into the repo we have squash emerge which will have one commit to be added we have rebase emerge which will be added and then do a rebase the third one is a more complex one so if you're not familiar with rebase you're probably going to be looking towards squash which is a good one the use case depends on your team's workflow they may prefer only a single commit uh added and so that's why you would want to have squash or rebase um but you do have a lot of options there for how you want to bring code in uh to your uh your base um your base there required reviewers is a way for you to explicitly say hey these people have to review this code otherwise it won't be accepted um and so you can assign or allow multiple required reviewers before code gets into a repo and a lot of times you can say it can't be the same person uh that submitted the code and it's not uncommon to have like four or five people that can be required reviewers and two or three have to um look it over before it gets accepted so here um I would be assigning myself and saying okay Omen King this this user has to um review the code and then from there as that user I would have to approve the changes and then from there it would change it to saying okay Omen king or Andrew Brown approv the changes and so now you'll be able to press that merge button okay so there you go hey this is Andrew Brown in this video I want to uh do a little bit more with P requests in terms of code reviews and maybe we could try to get that code owners file to work or um you know just things that we didn't get a chance to really get HandsOn with as we have made pull requests quite a bit but not from a reviewing kind of code proper way so what I want to do is I want to make my way over to our um uh our pretend organization and we're going to go ahead and create ourselves a new repo unless we already have one like the fun repo does that still exist it does so what we'll do is go ahead and use this one and what I want to do before we do anything else is I want to add um or make sure that the collaborator is added to this repo here and so I'm going to go ahead and add Omen King okay and there I am and I'm going to go ahead and say this person can maintain this repo all right and now they're part of this repo so they're there and the reason I was able to add that very quickly was because they were already part of of a team so or sorry they were already part of our organization so I didn't have to send an invite and confirm they're not external from that so that was very easy um the next thing I want to do is I want to go through and uh create a pull request it looks like we already have one here so if we already have one I'm not going to make a new one if you have to you make a new one but here it says this poll request oh this is that draft one right so we can't do anything with this one right now uh so I'm just going to close that poll request I'm going to go over here the poll request I'm going to try to make a new poll request because we still might have yes we do from earlier and I'm going to go ahead and that pull request okay and so we'll create that one and I want to say that this has to be reviewed by Omen King as soon as I do that notice we cannot proceed forward until that's uh ready and there's another here that says ready for review so this P request is still a work in progress so it's suggesting that this is a draft I guess I didn't notice but um it probably was still set to draft and so I ready for review okay so now uh Omen King should know that they need to approve it for this to work okay another thing that we could do is we could uh um require other things for approval so we could go ahead and add a Rule and Rule sets allow us to do that so there might be some things in here that we could set um require status checks to pass so that might be something that we might want to do and right now we don't actually have any status checks and so that's the reason why we can't we can't add that there so if I go back okay it would be nice to get some checks in here because that's the real value of pull request is having some kind of automation thing in here but I suppose we'd have to have like GitHub actions or something else so maybe we'll leave that for when we get to GitHub actions and integrate it there and we'll just continue on with the reviewers here so um I'm going to switch to my other account and I'm in this uh repon and saying oh I need to add a review so I can go here and let's say I don't like this change I'm G to go here and say request changes I don't like it make it better and so if I do this okay now it's saying in red hey you got to do something I like it's not allowed to go through um and by the way it show it still shows merge pull request and I really don't want this to show up unless I've accepted it so maybe there's a setting that we can do in here I thought it would been that rule set that we could do that maybe there's something else that we can do to protect it always suggest updating the pull request branch no operation options I might not be able to do it because I'm not the admin so I'm going to go back and switch over to this I'll go back to settings and what I'm looking for is the option to say it it requires uh reviewers or otherwise it can canot be merged um and so that's what I'm looking for right now maybe it's under uh rules could be Branch protection as well let's take a look here require a pull request before merging um I really thought that there would have been a rule for this the reason I think that is because I'm used to um I'm used to uh using jira and and bit bucket and and they'll let you do that so maybe I can't set that I'm not sure restrict creation yeah so I'm really surprised I can't find that maybe it's there but I can't find it and that's totally fine let's go ahead and pretend uh you know we're going to go fix this issue so we go here and it says I don't like it make it better so how can we um submit that fix right and the way we're going to do that is we'll actually have to go to this branch and change something so we'll go here and make sure we're in the correct branch and in here I'm just going to go ahead and change it again okay commit the change commit and so now if we go back to the pull request we should be able to update this pull request so I'm trying to do that here F's Chang normally what happens like and again it's because I'm thinking of jur and ATL scene is that you'd open another pull request and it would be the same one the same spot so I'm not sure if we can do that uh if I go Dev here because it's the same Branch right so if I do this it says view pull request how do I do this um and again it's because I'm expecting it to act like uh another piece of software and it's not doing what I think it's doing review changes I mean I could review my own that makes no sense review in code space so I guess the way it's going to work I really thought there'd be a back and forth there but I guess there's not is I suppose I would just have to go here and then approve it looks great okay so yeah I guess there's less process there than I thought and now that I'm happy with it I can go ahead and merge it so next question is can we make a code owner file and see how that works because I think that would be kind of unique to do sorry and so I believe that file is called code owners and uh what I'm going to do is I'm going to go ahead and create myself a new file here we'll say new file I'm going to say code owners and I'm just going to put an Aston here and just say omen King and so the idea is that anytime anything changes it should assign it to Omen king that's what I'm thinking anyway so what we'll do is we'll go ahead and commit these changes and we'll do this again okay and the idea is that if anything changes from that other person they they send a poll request I'm hoping that it's going to Auto assign now this might not work because it might be only a paid feature I don't know but we're going to try anyway so I'm going to go in the de branch and before I do anything I'm actually going to merge it the other way um I'm going to do that by opening up uh code spaces on dev and I'm just going to merge it back in into the direction because I'm not going to make a pull request that goes in the opposite direction I'm not going to do that that doesn't make sense P requests are supposed to go into your main branch right so I'm just giving this a moment here and what I want to do is do get whoops get merge main I'll do get pull I'll do get check out main get pull just in case we'll say get check out main get merge main get push saying it's all up to date I'm not sure if I I'm convinced so I'm going to double check uh it's not showing our tree here so let's say get graph I really wish it would persist changes but hey it's code spaces and I'll go back over to here do I have this now and show it shows that main is ahead of death so it's totally lying to me they're definitely not in sync I knew this was not the case oh you know what I merged when I was in main so that's probably why uh get check out um Dev get merge main it's always great to have this open so we can see I'm going to go sync those changes okay just in case that didn't I just get push just in case great that is in good shape I want to stop this environment stop good we're stopping it okay I'll go ahead and close that Tab out so now I have confidence that this code owners is in both I I just had a feeling I need to do that for some reason going to go ahead and just change this and we'll do that I'm going to go ahead and create a new pull request and I want to see whether it auto assigns we go here Dev create a pull request and look it auto assigned it so it says awaiting request a review from Omen King Omen King is a code owner Omen King will be requested when this pull request is created so that means the code owner file is working I don't need to create this pull request to know that and I think that's sufficient um the only last thing I would say is that you know people can comment directly on specific lines just remember that because they might ask you on the exam and that's about it we'll see you in the next one okay ciao hey everyone this is Angie Brown and this fall along I want to show you uh some of the more advanced options for poll requests um in terms of the merge options and why you'd use one over the other um so what I'm going to do is we going to go into our GitHub examples and in this case we do need to open up uh some kind of editor um I think we could get away with using github.io on my keyboard and that's going to open up the editor we're still going to need the repo open so I'm going to go here and wait for this to load and go to repo and so I I'm going to want to go over here for a moment I'm going to get rid of this um P request so we're not getting mixed up and um I really want to be on development and I actually don't even know if I'm on that so I'm actually going to just close this stuff out I might have mucked this up and we'll close this out because I need to be on the correct Branch for this to work and I mean we can do this and get up examples I'm going to do this in our other repo sorry I know I'm all over the place but I want to go back to our home and I want to go to our cool repo so I'm going to drop down our whoops our option here and I'm not sure why they don't never show those on the right hand side they really should we'll go here and I'm going to now um open po request and a new tab here and I'm going to go ahead and hit period And the reason why actually you know what we can't use uh GitHub Dev sorry we're going to have to open up code spaces because what I need is that visualization tool so we can see what we're doing so I'm going to go ahead and open up GitHub code spaces and we're going to have to wait a little while for this to start up unless it's already running that'd be really nice I'll be back here in just a second when it loads okay all right so now that is ready um we want to make this a little bit easier to look at so I'm going to switch my theme as per usual we'll go to uh a darker theme there we go and um the other thing that I want to do here is I want to switch out to the dev Branch so we say get check out Dev okay and another thing we're going to need is a tree so I'm going to go ahead and go to extensions here we'll say get graph because we need to make this really clear what's going on uh so I'm going to go here and install this okay and hopefully that installs nice and quick is it here not yet come on get graph install you can do get graph we want you there we go we want you here get graph so the idea is that I want to put a bunch of commits here and then we're going to merge them and see what it looks like when we do that and then we'll try a different merge option and we'll see how much cleaner it is uh doing that another way so what I want to do is I want to go ahead and modify this file save it and go get commit hyphen M change one and we're going to do ma to grab all of them in one go and then I want to get push okay and then we're going to do this again save and I'm going to just do a semicolon so I can just get through this a lot quicker so we'll do that again we'll do that again okay you're getting kind of the idea what's going on here we're kind of crazy people are not going to be happy with all of our commits okay great so now if we go back to our G graph here we got a bunch of changes I guess we should have incremented them it just says 1111 uh we can demend those like there's a way to rename them I don't really want to deal with that but let's just assume we didn't name it all dumb like that we made 1 2 3 4 5 six seven or for the next one we'll we'll just name it two so the idea is that what will happen the question is what will happen when we merge this in will we end up with one over here or all of these over here and that's what we're going to find out so we'll create a pull request we'll make a new pull request we will merge Dev to main we'll create that pull request I'm going to switch it back to normal we'll create that pull request we're going to ignore our reviewers we're going to just review it ourself and notice we're on Create and merge commit so we do this and what do we get we go back over to get graph and I'm going to go get fetch because that'll upgrate the graph without pulling anything and now notice that all of these commits um is up here now okay so that is there it didn't squash them all into one we still have all of the history of them okay so just to make this clear I'm going to just go get checkout main get pole get check out Dev get pull because I want to show you that they're all still there okay oh sorry get merge m get pull and refresh okay and I'll just do a get push for our Dev sorry but what I want to show you is that all of this history is still here it's not gone right it's all still here so hopefully that is clear I know it's not the best visual but I'm hoping that makes sense what I want to do now is I want to do a um I want to do a squash okay for the branch so I'm going to just make a new Branch get checkout Dev 2 and actually I'm going to do get checkout hyphen B Dev 2 and then we'll do get um because we want to push this Branch get push you origin Dev 2 and so now it's being remotely check tracked and I want to do something really similar to what we were doing before so I'm going to go here and for each one I'm going to remove a line okay we'll save it I'm looking for that one liner there we go and this will just be two this time two and we'll go here save that this will be two and we'll go ahead and save this and this will be two and we'll go ahead and save this and this will be two and we'll go ahead and save this and this will be two all right let's go back to our G graph we have a bunch of this stuff here let's go over here and make a new pull request this time we're going to Dev 2 and we're going to create that pull request and we're going to say create pull request and this time we're going to say merge pull request squash and merge squash and merge it's bringing all those commits in and now if we go back here and we refresh okay um we're going to refresh here again oh I got to go fetch get fetch that's so we don't see anything here get fetch we'll refresh and so notice now it doesn't show like a merge line coming into here what it's done it's taken all of this stuff and it's squashed it into a new commit and has it over here okay so it really depends on what you want do you want to keep all this history or do you want to kind of have this like over here and this has a completely separated commit here um it's really up to you how you want to do it I think this looks a lot cleaner um um but this is totally an option as well it's really what you want to do and I will see you uh in the next one so before I do that I'm just going to stop my workspace all right and see you later ciao poll request templates are similar to issue templates they will populate the PO request text area with the specified markdown template so they it is um I need to point out that uh it's in GitHub requestor template. MD that's what you want to use technically there is a folder called pull request template that you can use but I found that you really couldn't leverage it because there was no UI to select from it and the only way that you could do that was via this URL you generated with a query string so um I would suggest that you use pull request template MD and not use the folder uh and that's where it kind of feels like it's it's like uh where you have issue templates where they have that older version of it PO requests still feel like that old kind of version if that makes sense so there you go hey this is Andrew Brown from exam Pro and in this section we'll be covering authentication methods credentials are specific to a user's identity for example their individual username and password pin or biometric information every user including it administrators te teachers staff persons and students as credentials an authentication method is the way a user proves their identity to a system for example a user inputs their credentials in a sign in screen or via the Microsoft authenticator app in which they have set up their account authentication methods can also be broken down into categories or types such as signed authentication password reset authentication multifactor authentication authentication types authentication methods vary widely from traditional to Advanced common types include passwords and pins common but can be risky for security picture passwords and pattern locks offer memorability and simplicity biometric authentication facial fingerprint retinol provide secure unique user identification passwordless authentication emphasizes security and convenience by eliminating traditional passwords removing the hassle of memorization and mitigating threats like fishing some of Microsoft's methods include Windows hello for business uses Biometrics P for secure signins and SSO Microsoft authenticator app enables phone verification with notifications and Biometrics pin F2 security key allows password free logins with external internal Keys password reset authentication selfservice password reset with Microsoft enter ID lets users change their own passwords without help desk assistance cutting down on support costs and improving security and efficiency some of the key features include selfservice users can change or reset their passwords without administrator or help desk assistance security enhancement sspr improves organizational security by allowing users to promptly address account lockouts or compromises compliance with password policies sspr enforces Microsoft enter password policies regarding complexity length expiration and character use ensuring standardized security measures across the board multiactor authentication MFA is a security measure that requires more than one piece of evidence to confirm your identity when logging into an account like a code from your phone in addition to your password some MFA methods include SMS text message a code sent to the user's phone phone voice call answering a call to confirm identity Microsoft authenticator app a code or biometric verification through the app and O aut hardware token using a physical token for authentication set up ooth for external Services oo is a protocol for for authorization that lets users give thirdparty services like GitHub or Jenkins permission to use their information without sharing their login details it ensures secure connections making authentication and permissions straightforward use personal access tokens personal access tokens provide a way for users to create special tokens to access devops tools they are especially handy for command line interactions or scripts needing direct access to these Services apply rolebased Access Control rulebased Access Control sets up detailed access rules based on users roles and what they're allowed to do it makes sure people have just the right access they need for their work keeping sensitive information secure so that's an overview of the authentication and credential strategies the next topic we'll be covering is get lfs which stands for get large file storage and get fat developers sometimes struggle with handling big files in a get repository because it can make the repository work slower and use up too much space Microsoft has two tools to help with this git lfs and get fat git lfs is an open source extension for git that helps handle large files more efficiently it does this by using small text pointers in your git repository to represent the large files while keeping the real file content stored elsewhere this method keeps your repository from getting too large and slowing down to get started with G lfs you'll need to follow some of these steps install git lfs install go to the git lfs website download and install the version B based on your operating system configure use the command G lfs install to set up G lfs on your system setting up G lfs in your repository track large files decide which file types to manage as large files for example use get lfs track. mpp4 for MP4 files add attributes file add the dog attributes file to your repo with get add. attributes commit and push save the changes with Git commit Dash and configure git lfs and update the remote repository using git push managing large files add files run get ad dot or get ad file name to Stage large files commit and push use get commit dmad large file and get push to commit and send files to the remote repo so that's an overview on how to get started with G lfs get fat is another tool for managing large files and get repositories it's a python script that keeps large files separate from your git repository while maintaining references to those files within the repository let's take a look at how to get started with get fat setting up get fat install python make sure python is installed on your system install get fat install get fat using Pip with Pip install get fat initializing get fat in your repository initialize get fat run get fat in it in the root of your repository track files Define large file types in a dogit fat file for example to track MP4 files you might add asteris MP4 to the file commit dogit fat add the dogit fat file to your repo with get add. git fat and then commit it using get commit DM initialize git fat and track large files managing large files with get fat add large files use get fat add file to Stage large files for get fat commit and push commit with get commit Dash and add large file and upload with get Push Pull large files on a different machine after cloning run get fat pool to download the large files so that's an overview of how to get started with get fat git scaler is an extension that helps get efficiently manage large repositories addressing the slowness and space issues associated with downloading a repository's entire history and files git scaler solves this by allowing you to download only the files you need it works well with Git lfs to use git scaler you'll first need to set up your repository with G lfs that enable git scaler for specific file paths you're interested in configure git scaler for a specific path install G lfs install G lfs by following the steps provided in its official documentation initialize G lfs in your repository and your repositories directory run git lfs install create and configure.it attributes file in the root directory of your repository create a dogit attributes file to enable git scaler for files under the my/ large SL files directory add the following line to dogit attributes my/ llarge SL files asterisks filter equals diff equal lfs merge equal lfs D text this configuration tells get lfs to manage files in my large files using git scaler for efficient handling commit and push the dog attributes file commit the dogit attributes file to your repository with get add. attributes then git commit dasm configure git lfs and git scaler for specific paths push the changes to your remote repository get push so that's an overview of how to get started with get scaler cross repository sharing with get sharing code across different repositories is common for reusing code modularization or separating components of an application gate facilitates this with the following method sub modules git subm modules let you integrate a separate git repository within another repository's directory structure it's especially handy for incorporating a particular version of an external library or for sharing common libraries across various projects to add a subm module you'll need to use the command get subm module at repository URL path repository URL the get URL of the repository you want to add path the directory path within your main project where the subm module will be placed here's an example get subm module at https github.com example. externals some of the advantages of sub modules include manage shared code by referencing specific commits and keeps the main project separate from external dependencies note that using git sub modules requires managing updates individually and maintaining consistency across projects that share them overall by using subm modules you can efficiently manage cross repository code sharing and get while maintaining clear boundaries between different projects or components the next tool we'll be covering is get subtree git subtree is a tool that helps you include code from one repository into a specific folder of another repository it's a simpler alternative to subm modules which is another way to incorporate external code but can be a bit complex to handle with get subtree you can both bring an external code and send updates back to the original code Source if needed to add a subtree you use a command that looks like this get sub tree add prefix equals folder name repository URL commit or Branch D prefix equals folder name is where you specify the folder in your main project where you want to add the external code Repository URL is the web address of the external code you're adding and commit or branch is the specific version of the external code you ought to use which can be a commit ID or Branch name get subt Tre streamlines project workflow by integrating external code directly ensuring it's immediately accessible upon clothing without additional steps overall get subtree makes it easy to work with code share between different projects while it simplifies some of the issues found with sub modules updating the code from the original repository into your project can require a few extra steps the next topic we'll be covering is workflow hooks workflow hooks are essential tools in the Microsoft devops ecosystem designed to automate and refine development workflows leading to better efficiency and productivity workflow hooks Act is triggers for executing actions or scripts at specific points in a devops workflow crucial for maintaining code quality automated testing deployment and integrating external Services into the process in the context of build and release Cycles workflow hooks are particularly valuable they enable developers to automate tasks like unit testing documentation compilation or deployment to testing environments with each new build or release streamlining these processes Azure devop stands out and offering comprehensive tools and services for managing the devops life cycle including implementing workflow hooks through service hooks these service hooks allow for connecting your devops pipeline with external services or initiating custom actions in response to various events such as new bill completions work item updates or pull requests other tools and services for workflow hooks besides Azure Dev Ops Microsoft offers other tools and services for implementing workflow hooks including GitHub actions Azure logic apps and Azure functions the key to leveraging workflow hooks effectively is to identify the crucial events and actions within your workflow and use the appropriate tools for implementation here's a simplified stepbystep guide to creating a service hook in Azure Dev Ops for automating actions such as notifications after a successful build Access Project settings open your project in Azure devops and navigate to project settings at the bottom of the project sidebar open service hooks in the general section find and click on service hooks create subscription initiate the creation process by clicking the plus create subscription button select notification service pick the service for notifications like Microsoft teams or slack and set the event trigger to Bill completed set trigger filters customize the trigger filters by setting the build status to succeeded configure action details specify the notification message and destination such as the recipient Channel and slack or an email address finalize and test save the service hook with the Finish button and conduct a test to confirm it operates as expected after a build is successful so that's an overview of workflow hooks hey this is Andrew Brown from exam Pro and in this section we'll be covering the different types of Branch strategies starting with trunk based development or TBD TBD employs a single Central Branch known as the trunk or Master focusing on frequent small updates for continuous integration and stability steps to implement TBD why establish the trunk Define a single Branch also known as the trunk as the central code path two direct commits encourage team members to commit small changes directly to the trunk frequently three continuous integration per perform builds and tests on the trunk often to catch issues early for automate deployment set up automatic deployment to streamline updates here's an example of how you can create a trunk Branch using git git Branch trunk get checkout trunk another Branch strategy you can use as feature branches which enable developers to work independently on new features or fixes keeping changes separate from the main code until they're ready to merge this approach allows for focused development and testing of specific functionalities without disruption steps to use feature branches why create feature Branch initiate a new Branch for each feature or fix to naming conventions assign descriptive names reflecting each Branch's purpose three stay updated merge updates from the main branch periodically for thorough testing conduct extensive tests before merging back to the main branch here's an example of how you can create and switch to a feature Branch using get hit Branch Feature slne Feature get checkout feature SL new feature the last Branch strategy we'll be covering is release branches which help prepare and stabilize a codebase for a new release focusing on bud fixes and final adjustments they are created from the main branch enabling ongoing development while ensuring the upcoming releas is Thoroughly tested and Polished steps for managing release branches while create a release Branch start a branch from the main branch for new releases two Focus adjustments make all necessary tweaks and Bug fixes on this Branch three three ensure stability test thoroughly and maintain continuous integration four final merge merge the release Branch back into the main branch once ready here's an example of how you can create a release Branch using get get Branch relase sr 1.0 get checkout relase sr10 so that's a brief summary of the key branching strategies that will be covered on the Azure devops exam call I are critical for maintaining code quality and ensuring that changes meet certain standards before they are merged Branch policies in Microsoft devop Solutions or rules that govern how code is contributed to a repository they enforce certain conditions that must be met for poll requests to be merged ensuring that code is reviewed tested and linked to relevant project tasks key Branch policies to implement require approving reviews mandate that each poll request receives at least one approving review from designated reviewers before it can be completed this guarantees that all code changes are scrutinized by another developer promoting better code quality and reducing the risk of Errors link work items ensure that every poll request is associated with a corresponding work item this linkage provides traceability and accountability making it easier to track why changes were made in ensuring they align with the Project's goals build validation configure this policy to require that changes in a poll request successfully pass automated builds and tests this helps to identify any compilation issues or test failures early prevent preventing problematic code from reaching the production environment additional Branch policies for enhanced workflow en Force minimum review time set a minimum period that poll requests must remain open before they can be merged this policy prevents Rush reviews and ensures thorough evaluation requir task completion mandate the completion of specific tasks before merging such as addressing all code comments or updating necessary documentation this ensures that all critical aspects are handled before integration automate code for forting in style checks Implement tools like linters to automatically enforce coding standards this minimizes manual review efforts and maintains consistent code quality benefits of using Branch policies improve code quality automated checks and enforce review standards significantly reduce the risk of introducing bugs and errors better team collaboration requiring reviews and linking work items promotes effective collaboration and keeps team members aligned with project goals efficient workflow management automating parts of the review process accelerates the development cycle while upholding high quality standards so that's an overview of Branch policies the next topic we'll be covering is Branch Protections in Azure Dev Ops Branch protections provide an additional layer of security by enforcing rules on Branch manipulation preventing accidental modifications or unauthorized changes here are some of the key Branch protections to implement require a minimum number of reviewers set branches to require a specific number of reviewers for all changes this ensures multiple evaluations of the code which facilitates collaboration and reduces the risk of defects restrict who can push to the branch limit direct push access to protected branches allowing only authorized individuals or teams to make changes this control helps prevent unauthorized modifications and maintains code integrity and force merge checks specify criteria that must be met before merging a poll request these include build validation work item linking and Branch permissions compliance to ensure only approved changes merge P request workflow with Branch policies and protections here's how you can structure a typical pull request workflow using both Branch policies and protections create a feature Branch developers Branch off the main branch to work on new features or fixes Implement changes and create a poll request developers commit changes to their branch and open a pull request to merge them into the main branch assign reviewers and await feedback reviewers and inspect the code provide feedback and approve Branch policies and sheer pull requests need the required approvals to proceed address feedback and iterate developers respond to feedback update their code and Trigger the build validation process reviewers reassess the updated changes complete the pull request after security approvals and passing merge checks like work item linkage and build validation the pull request is completed and changes are merged so that's an overview of Branch protection in Azure Dev Ops hey this is Andrew Brown from exam Pro and in this section we'll be covering Azure pipelines Azure pipelines is a cloud service that automates the CI CD pipeline for software development offering support for multiple languages platforms and Cloud environments and integrating with a wide range of tools and services here are some of the key features of azure pipelines automation for CI CD Azure pipelines provides a fully featured continuous integration and continuous delivery service for applications platform and language agnostic supports any language platform and Cloud that integrates with Azure o and gcp extensibility offers integration with popular tools and services in the software development ecosystem supports open source and private projects available for projects hosted on GitHub and other platforms Rich integration integrates with GitHub checks and offers extensive reporting capabilities parallel jobs and environments allows running multiple jobs in parallel and deploying to multiple environments including kubernetes VMS and Azure Services next we'll take a look at defining your pipeline yaml syntax as your pipelines uses yaml syntax to Define build test and deployment tasks stepbystep process the documentation Guides Through the process of setting up your first pipeline including initiating builds packaging applications and deploying some of the key Concepts include pipelines a complete CI CD pipeline defined by stages jobs steps and tasks stages a way to organize jobs typically used to separate build test and deploy processes jobs and steps jobs group steps which are individual tasks like scripts or Azure pipeline tasks and tasks prepackaged scripts that perform actions in your pipeline moving on to supported languages and framework wide language support works with any language including net Java JavaScript node.js python PHP P Ruby C C++ and more framework and platform support supports Windows Linux and maos builds can deploy to various platforms including Azure kubernetes VMS and on premises servers extensibility Marketplace extensions a rich Marketplace of extensions to extend the functionality of azure pipelines custom tasks developers can create custom tasks to meet unique requirements pricing free tiers available offers free CI CD minutes to projects with additional minutes available for purchase pricing varies based on Parallel job needs and Cloud providers so that's an overview of azure pipelines the next topic we'll be covering is GitHub repos with Azure pipelines integrating GitHub repositories with Azure pipelines can significantly enhance the automation of build and release processes within a devops workflow this integration facilitates continuous integration and delivery promoting faster and more reliable applic a deployments here's how to structure the setup process step one create a new project in Azure devops create project click the new project button provide the necessary details for your project such as name and description and then click on the create button to finalize the project creation step two connect your GitHub repository to Azure pipelines access pipelines in your new Azure devops project navigate to the pipeline section initialize pipeline click on the new pipeline button select Source choose GitHub as the source for your pipeline you will need to authenticate and authorize aure pipelines to interact with your GitHub account configure pipeline select this specific Branch or repository to build and deploy customize the pipeline settings based on your application requirements activate after configuring click on the save and run button this action saves your pipeline configuration and triggers the initial build step three build and deploy your application build configuration as your pipelines will execute the build of your application according to the directives specified in your pipeline configuration file which is usually a yl file this may include tasks like compiling code running tests and packaging artifacts release tasks post build configure the pipeline to deploy your application to various environments such as staging or production this can involve deploying to services like Azure app service or Azure kubernets service deployment customization utilize features like environment variables secrets and approvals to tailor and secure your deployment process benefits of integrating GitHub with Azure pipelines continuous integration ensures that any changes in the connected GitHub repository trigger automatic builds keeping your application updated and validated after every commit code visibility enhances traceability by linking GitHub pull requests and commits directly to their respective build and release pipelines artifact management facilitates management and storage of build artifacts in Azure pipelines or with external services such as Azure artifacts and Docker Registries continuous delivery automates the deployment process across different environments minimizing manual intervention and promoting consistent releases release approvals implements controls and checks through configurable approvals before promoting bills to production environments so that's an overview of GitHub repos with Azure pipelines the next thing we'll be covering is configuring the permissions and Source control repo managing access ACC and security through permissions is critical in a devops environment to ensure that team members have appropriate access for their roles configuring repository level permissions one Access Project and as your devops navigate to your project and go to the repo section to repository settings select your repository and click on the settings tab then repositories in the submenu three modify security choose the repository you want to adjust and click on the security tab on the right for manage access at user users or groups to the predefined security groups or create new ones five set permissions use the ad button to Grant the appropriate permissions like read contribute and administer to selected users or groups Branch level permissions configuration widen repository access open your repository in Azure Dev ops two branches go to the branches Tab and choose the branch you need to configure three security settings click on security to manage permissions for that Branch for Define permissions assign permissions to groups or users overriding repository level permissions if necessary configuring file level permissions why locate file within the repository navigate to the specific file you want to manage two file permissions click the three dot icon next to the file and choose manage permissions three control access at groups or users and set the desired access levels just as you would at the repository or Branch level so that's an overview of configuring the permissions in Source control repo the next topic will be going over our tags and Source control repos tags and get serve as reference points to specific commits making it easier to manage and track different versions of code in a repository step one repository access log into Azure devops or another Microsoft devops Solutions platform verify you have the required repository permissions step two navigate to the repository after logging in locate the repositories or Source control tab on your dashboard this section contains all the repositories you have access to within the platform step three create a tag identify the commit in the repository that you wish to tag tags are useful for marking releases or important points in the Project's history select the desired commit from the commit history look for an option label create tag or add tag usually available in the commits context menu step four provide tag details in the tag creation dialogue enter the tag name a unique identif fire for the tag provide a description a brief note about what this tag represents add any annotations or other metadata if necessary step five save the tag confirm the details and save the tag this action attaches the tag to your specified commit marking it for future reference step six View and manage tags after creating a tag you can view and manage it through the repository interface access the tag section where all configured tags are listed here you can rename delete or reassign tags to different commits if required so that's an overview of tags and Source control repos the next thing we'll be covering is recovering data using git commands git is vital for Version Control and teamwork but sometimes mistakes occur leading to data loss or overwrites it's important to know how to restore data using get commands in these situations examining commit history check git log use the command git log to see a list of recent commits made in the Repository this log includes the commit hash author date and the commit message to find a specific commit or to filter the log by author date or content you can use git log author equals username git log since equals 2023 0401 git log GP equals keyword this helps in locating the exact commit hash of the changes you wish to restore revert a specific commit use get revert commit underscore hash to undo the changes made in a specific commit while preserving the history of changes this command creates a new commit that reverses the changes introduced by the specified commit it's a safe way to undo changes as it doesn't alter the existing history for example get revert 1 a23 C4 recovering deleted commits use rlaw to recover lost commits if you've accidentally deleted or lost commits get reflog can be a lifesaver it shows a log of where you're head and Branch references have been which includes deleted or orphan commits you can find the commit hash of a loss commit and recover it by creating a new Branch from it hit reflog hit Branch restore Branch Commit This restores the deleted commit in a new branch called restore Branch allowing you to access the previously lost changes restoring deleted files restore deleted files if you've deleted a file and want to recover it from history use get checkout commit uncore file uncore path this command restores the file as it existed at the specified commit it's useful for quickly recovering loss work without affecting other changes in the repository so that's an overview of recovering data using get commands the next topic we'll be going over is purging data from Source control to optimize your Source control system within Microsoft devops environments regular purging of unnecessary data is crucial this helps in improving system performance and reducing clutter prerequisite checks communicate with Team ensure all team members are informed of The Purge to avoid any disruption backup data confirm that backups are in place for all critical dat data data replication check ensure essential data is replicated to Alternative repositories or backup systems Azure devops rest API for data purging automate with API use the Azure devops rest API for automated data deletion tasks delete files folders branches modify the delete API call is needed to Target and remove specific items from the repository manual get garbage collection trigger garbage collection run get GC in your local repository to start manual garbage collection nonproduction timing perform this operation when it won't interfere with development activities get history compression access repository settings in Azure Dev Ops go to the repository settings to find G configuration options enable compression check the option for compress kit history to optimize storage removing unnecessary branches local branch deletion use git Branch D Branch name to remove branches from your local machine Azure devops branch removal use the azure devops web interface to locate and delete old or unused branches implementing data retention policies Define policies set up rules for how long data should be retained in Azure Dev Ops automate purging configure automatic removal of age data to streamline repository maintenance so that's a brief summary of purging data from Source control hey this is Andrew Brown from exam Pro and in this section we'll be covering integrating pipelines with external starting with dependency scanning dependency scanning helps you track and manage the libraries and packages your codebase depends on this ensures that your applications use the appropriate versions of these dependencies minimizing the risk of compatibility problems select from various tools like oasp dependency check or retire. JS which help identify vulnerabilities and outdated libraries in your projects dependencies choose one that best fits your Project's requirements configure the pipeline integrate your selected dependency scan tool into Azure pipelines by setting up a task to run the scan before the build or deployment phases to identify vulnerabilities at the earliest analyze the results post scan analyze the results to identify and prioritize vulnerabilities or outdated dependencies highlighted in the scam report address these issues to maintain the health and security of your application detection process each change in the dependency graph or after code build initiates a new snapshot of your components vulnerable components are logged and displayed as alerts in the advanc security tab based on advisories from the GitHub advisory database these logs detail the severity component vulnerability title and cve managing alerts the advanced security tab serves as a central hub for viewing and managing dependency alerts it allows filtering by Branch Pipeline and severity and provides remediation steps alerts for dependency scans on PR branches are shown and any name changes to pipelines or branches might take up to a day to reflect in the results so that's an overview of dependent scanning the next topic we'll be covering is security scanning integrating security scanning tools into your pipelines is a critical step to identify and address security vulnerabilities in your code there are many security scanning tools available like sodar queet and Microsoft Defender for cloud these tools analyze your codebase for security flaws coding standards violations and potential vulnerabilities choose the tool that meets your Project's requirements sod queet is an opensource platform for continuous inspection of code quality it performs automatic reviews to detect bugs vulnerabilities and cod smells in your code Microsoft Defender for cloud formerly known as Microsoft Defender app offers Security Management and advanced threat Protection Services across hybrid Cloud workloads set up your pipeline incorporate the security scanning tool by adding the required tasks into your pipeline configuration for example in Azure pipelines you can add a task that triggers the security scan during the build phase automating the security audit evaluate scam results after the security scan is finished review the tools report it will highlight security gaps and code quality concerns address these items promptly giving priority to the most critical issues to fortify your codebases security posture so that's a quick overview of security scanning the next topic we'll be going over is code coverage code coverage measures the percentage of your codebase tested by automated tests revealing how much code is exercised during testing to ensure quality and detect uncovered areas select a code coverage tool select a tool like jaac for Java or Cobra to for net ensure it integrates well with your Tech stack and test Frameworks configure the pipeline incorporate your chosen tool into the pipeline to collect code coverage metrics during tests for example using Azure pipelines you can use a published code coverage task to generate reports in popular formats like Cobra or jaac analyze code coverage results review the coverage report post analysis to identify and improve areas with low test coverage enhancing your codes robustness accessing coverage artifacts publish code coverage artifacts can be viewed in the pipeline run summary under the summary tab offering a snapshot of test coverage for each build quality metrics enforcement code quality assurance leverage code coverage metrics to continuously elevate your Project's quality and verify the extent of testing for new code pull request integration Implement coverage data within pull requests to ensure thorough testing and preemptively fill testing voids before integration setting code coverage policies full versus diff coverage full coverage measures the total code basis test coverage ensuring overall quality diff coverage focuses on the code changes in pull requests ensuring new or altered lines are tested so that's an overview of code coverage the next topic we'll be covering are quality Gates a quality gate acts as a benchmark for code quality that must be met prior to release and ideally before the code is committed to Source control it ensures that only code that meets established standards progresses through the development pipeline features of quality Gates automated code analysis tools like sonar kuet are integrated into Azure pipelines to perform static code analysis identifying potential issues such as code smells vulnerabilities and bugs performance metrics code quality metrics including code coverage complexity and maintainability index are assessed compliance checks Gates ensure the code complies with security standards and governance policies before proceeding in the pipeline best practices for implementing quality Gates customization customize gate criteria to align with project demands and application type threshold setting set clear thresholds for code coverage to Define pass fail conditions for the gate such as minimum code coverage percentage feedback loop establish immediate feedback systems for developers upon gate failure for prompt issue resolution integrating quality gates with Azure pipelines hypine configuration integrate quality checks in your CI CD flow to control code progression using established metrics action on failure defined actions for when code fails to meet the quality Gates criteria which may include halting the pipeline triggering alerts or creating tasks for remediation visibility and reporting increased transparency through dashboards or reports showing gate outcomes for ongoing Cod based Health monitoring so that's an overview of quality Gates the next type of gates we'll be covering are security and governance Gates security gates are established to verify that code complies with security protocols and is free of vulnerabilities before being pushed to production static application security testing integrate a sast tool like sonar queet and white Source bolt into the build process to scan for security flaws this proactive approach to Tex issues early reducing the risk of vulnerabilities reaching the production environment Dynamic application security testing conduct D regularly on live applications to find security weaknesses use tools like Azure web application firewall to guard against common threats like xss and SQL injection governance gates are checkpoints to confirm that both code and deployment procedures are in line with company policies and Industry regulations policy definition and enforcement identify and set governance policies required by your organization apply these policies using tools such as Azure policy to automatically enforce them throughout the development cycle automated compliance verification build automated compliance checks into your CI CD Pipeline with Azure devops compliance or similar tools automating these checks ensures ongoing adherence to governance standards without manual oversight so that's an overview of security and governance Gates hey this is Andrew Brown from exam Pro and in this section we'll be going over what are pipelines in devops a pipeline is a key framework that structures the software delivery process through automated steps it ensures each phase of the software life cycle from integration to deployment is optimized for quick development reliable releases and scalability it encompasses several components and features components of devops pipelines while in source code repository the starting point where code is stored in Version Control two build server automates the compilation building and preliminary testing of code three test server runs various tests such as unit or integration to ensure code quality four deployment server manages the deployment of code to various environments such as staging or production five feedback and monitoring tools that provide feedback on deployment success and monitor application performance and production features of devops pipelines automation every stage from code commit to production is automated minimizing manual tasks and errors continuous integration and deployment ensures that changes to software are automatically tested and deployed improving speed and quality modularity each component functions independently but collaboratively allowing for easier troubleshooting and updates benefits of Dev Ops pipelines increased efficiency automation reduces the delivery Cycles enabling faster releases improved reliability continuous integration and testing diminish the chances of defects in production better scalability pipelines support scalable operations and management practices as organizational needs grow so that's an overview of pipelines the next topic we'll be covering is integrating automated testing into pipelines automated testing plays a vital role in ensuring the quality and reliability of software products by incorporating automated tests into the pipeline you can detect issues early in the development cycle streamline the release process and Achieve faster time to Market key steps for integration Define test strategy outline what types of tests such as unit integration UI will be automated and set the coverage criteria create test infrastructure use Azure Dev Ops for provisioning resources like VMS or containers or utilize Azure test plans for executing tests choose a test framework depending on your text stack select an appropriate framework like Ms test nunit or xunit write automated tests develop tests that address various functional and integration aspects of your application for example in a shopping cart application you could write a test to ensure items are added correctly the example shows a unit test in C using Ms test to verify that a product when added to a shopping cart is correctly included this test checks the functionality of the add to cart feature essential for ecommerce applications by asserting that the cart contains the added product Version Control manage your test scripts and cbase in a get repository using Azure Dev Ops for Integrations like pull requests and reviews configure CI pipeline set up a CI pipeline in Azure pipelines to automatically run tests upon commits helping identify issues early incorporate test reporting utilize Azure Dev Ops for detailed test reporting and tracking over time Implement CD pipeline after passing tests in CI deploy your application across different environments using a CD pipeline so that's an overview of automated tests into Pipelines the next topic we'll be covering our testing strategies local tests are written by developers to test individual components or modules before they are integrated into the larger system they ensure that each piece of code functions correctly in isolation there are various tools and Frameworks available for writing local tests such as Ms test nunit or xunit for example using Ms test you might test a method in a class that calculates the sum of two numbers the test checks whether the method Returns the correct result result when adding two integers unit tests focus on validating the functionality of individual methods or classes in isolation identifying bugs and ensuring code behaves as intended Microsoft devop solution supports Ms test and unit and executed for these tests unit tests are narrowly focused while local tests can be broader or refer to the environment in which a variety of tests are performed using nunit consider a test for a service that retrieves a list of items the test verifies that the list is not empty and contains the expect number of items integration tests assess the interaction between two or more components of the application to ensure they work together as expected these are important for catching issues that unit tests might miss using nunit an integration test could check the interaction between two Services where one service uses data provided by another load tests evaluate the performance of the system under a significant load which could be simulated users or transactions they help to identify the capacity limits and scalability of the application in the low test scenario in Azure Dev Ops you could simulate multiple users accessing a service to test its performance and capacity so that's an overview of the main types of testing strategies another type of testing is the UI testing UI testing is critical in Microsoft devops for ensuring that the user interface of applications functions correctly and meets desired requirements this testing confirms the UI functionality and behavior identifying early issues with user interactions layout responsiveness and data management bug detection regular UI testing identifies bugs and errors early improving user experience quality verification this testing confirms that the UI meets functional requirements and performs as expected under various conditions Microsoft offers several tools that streamline UI testing in devops environments first let's go over Microsoft test manager Microsoft test manager supports extensive UI testing with capabilities tailored for managing test cases and tracking their execution setting up Begin by creating a new test plan in Sweden MTM test cases add UI test cases to your Suite execution and Analysis use mtm's test Runner to perform the tests and review results including screen shots and videos another one is Visual Studio coded UI tests Visual Studio coded UI tests provide a code Centric approach to UI testing suitable for automation using C or visual basic.net create a test project start a new project and add a coded UI test record and enhance interact with your applications UI to record actions then add validation statements execution run your tests locally or integrate them into your devops pipeline for continuous testing selenium web driver with C selenium web driver is an open source framework ideal for automating web browsers and conducting crossplatform UI tests set up install selenium web driver via the new get package in your Visual Studio solution create and configure start a new C test project and set up selenium web driver develop and run tests write test methods to interact with the UI and execute them locally or within your devops pipeline so that's an overview of UI testing let's take a look at GitHub actions which is a cicd pipeline directly integrated with GitHub repos and GitHub actions allows you to automate running test Suites Building images specifically docker images compiling static sites deploying code to servers and more and we can access this all through the actions tab in your GitHub repo uh when you first use GitHub actions there are some templates that you can utilize and all these files are stored in your workflow directory in your GitHub folder as you can see there's this kind of yaml file that we're going to utilize it's going to be important that we remember some of the structure so I remember on the exam they wanted you to know that there was jobs on and steps uh you can have multiple workflows in a repo triggered by different events so when you run GitHub actions you'll get a history of workflow of runs where it will indicate if it was successful or failure how long it took to run so this is um for something probably for um some one of the boot camps that we ran as we used GitHub actions to build the site if you want to find the example repos because there are those little getting started but it's the same repo here at the starter workflows and you can get the yaml files and get started really quickly there are different types of triggers uh that you can use with GitHub actions that's going to go into that on area and GitHub there's about 35 GitHub actions I say plus because in case there are more that I'm not aware of I'm covering my bases there examples of common GitHub actions could be pushes pull requests issues releases schedule events and manual triggers the exam wants you to know that you can trigger based on these things so make sure you remember this short little list here okay hey this is Andrew Brown and in this follow along let's take a look at GitHub actions so what I want to do is go over to our organization I'm going to go to our fund repo and here we have a tab called actions where we can set up some GitHub actions now I don't use GitHub actions a whole lot maybe I will if I go ahead and do that GitHub action cert uh certification course but uh we'll just have to kind of work our way through through it it shouldn't be too hard so there's a lot of different things that we can utilize here I can set up terraform which is kind of cool uh we have deployment to AWS to Azure to Alibaba Cloud we have some security things that we can do here we have continuous integration automation a whole host of stuff and um you can even do static compilation which is pretty cool as well so we're going to have to make make a decision in terms of something that we want to use um I don't I think it's going to be deployment because that seems like a lot of work um so I'm trying to make a decision here what we could utilize build lint and test a rails application that seems pretty small or easy for me to do but maybe we should try to use one of these things down below um labels pull requests based on files change let's go ahead and see if we can utilize that so I hit the configure button and it's going to bring us into this action and I guess there's the marketplace where we can get uh more stuff I didn't even realize there was a Marketplace for this looks like we got some documentation here so customizing when workflows run based on trigger so here it says on push Branch so when we push to specific ones we can trigger different stuff okay so that's kind of cool let's take a look here and see if we can expand this and see what we're looking at so we have name labeler on pull request Target jobs and then we have labels so run as Ubuntu so probably start a container as an Ubuntu with permissions of contents to read and it can write pull requests and the step that we're going to have here it's going to use the actions labeler version 4 and with the repo token it's going to bring in that token so it has authorization to do so and we know about GitHub tokens um and I think I think we showed this uh for GitHub actions but not 100% sure so carefully reading here the whole point of this is to apply labelers and the basically the way it's going to do that is through these steps and so I'm assuming that this is kind of like a builtin step and if we go here and just type it in maybe we'll go find it yeah and so they're talking about actions here hold on here I guess it's just a repo so get documentation and oh okay it's called actions all right and so this whole repo trans actions all right and so it's coming from this one and so I'm just going to go into here and take a look at what this looks like so just zoom out for a second and it kind of explains maybe how it works um automatically labels new pull requests based on the paths of the files being changed on the branch the ability to apply labels based on names of branches and things like that the bug related to the issue so create a GitHub labeler yaml file this will list a uh a list of labels and config options to match and apply the label all right the match object allows control over the matching options you can specify the label to be applied based on the files that have been changed Etc like that and sounds a little bit complicated but at least down here it's like showing us uh the flow it's interesting that this one is showing version four we clearly there is a version five um there might have been warning up here saying that we should use it doesn't say that we have to use version five or four or we're first to use five um but let's see if we can figure this out so I'm going to go ahead and go down below and just look at the workflow a little bit more here and it looks pretty much the same the only difference is that this one's using version five it's not passing the width for the token so I'm not 100% sure if we actually really need to do that but I'm going to go ahead and go commit changes and we'll commit that there okay so now we have that here if we go to actions um we can see that we have labeler and it's only going to run what's going to trigger it let's go take a look here um if we want to know how it triggers we should just take a look at the code and whoops go back here and take a quick look so it says says pull pull request Target so we pull request Target what does that mean we'll go search it here um pull request Target so activity types assigned assigned labeled runs your workflow when activity on a PLL request in the workflows repository occurs when activity on a pull request in the workflow activity occurs so it's going to check on based on a lot of stuff so that's pretty broad but that seems fine looks like we could even narrow it down to very specific types okay so I mean that's is how we could play with triggers um and so basically when that triggers it's going to go ahead and then start up Ubuntu for some reason maybe that's what it has to use to run this code that we saw from over here okay and this looks like it's JavaScript or something and then we need that file so we need to make sense of what this is so the base match object is defined as this any glob to any file okay the key okay so what does this thing do automatically label new pull request based on the path of the files being changed on uh changed or the branch name okay well I'd rather just do that on the branch name so let's see if we can find that so it says change files give me a moment just to try to make sense of this and then I'll just save you the trouble of me struggling through it okay okay scrolling down we're getting better examples this is starting to make more sense it says add an any change label to any changes within the entire repository Okay add documentation label to any changes within the doc folder so maybe what we can do is give this one a go and uh we need to create a file what's this file need to be called GitHub laer yaml so we'll go here and I'm going to add a new file okay um add a file this will be label. yaml we'll double check make sure that is correct I've been known to make mistakes often and I'm going to paste that on in here and we're going to commit that change so now we have our labeler yaml I'm going to go take a look here and see if the action got triggered it did um it failed I mean there's nothing for it to check right now so no event triggers defined is on so not exactly sure what it's saying there but that's totally fine for now and what I need to do is I need to create a poll request I mean it shouldn't trigger unless we have a poll request right um but it did just happened now so I'm curious what would happen if I went ahead and just uh made any kind of change because it shouldn't really trigger unless it's a pull request we'll go here and go back to actions and it ran again so I'm really confused why is this running what it should only happen on a poll request Target um we'll open it up again here so no event trigger defin is on okay maybe there's something wrong with our our workflow file let's see what they say you can trigger all branches just by using remove the hyphen your workflow file seems fine have you checked all indentation so I mean we didn't make that file right it was generated for us let's go take a look and see what we can do about that we have label and labeler okay so this was the one that we wrote I mean everything looks fine here I'm going to open this up in codes spaces or not codes spaces we'll open this up in that um I don't know if we need this so I'm just going to take that out because the other one didn't have it okay can expand this yeah it still has this here and I'm not sure why this little red line is here maybe it's just superficial it's confused but this seems fine I'm going to go ahead and update this and say update action the other question is do I have this in the right folder because yeah it's in actions but labeler yaml labeler yaml isn't supposed to be in the actions folder so I think what's happening here is that it thinks I think I know what happened here um if we go back to our repo I think it thinks labeler is a an action yeah so I think it's just we put that in the wrong folder so I'm going to go back and open up and we're just going to move that back into the correct location okay so we're going to expand that and this labeler is going to go into the GitHub folder there we go going to go ahead and add this all and fix and we will commit and we will let that push and I'm going to go back over to here all right and if we go back over to actions oh uh this is not the repo we'll go back over to our organization into Fun repo it might have triggered one more time I don't know it has not so we are in good shape can we delete this run y we can let's just delete this up to clean up so we can see what we're doing and uh what I want to do is I want to trigger that uh polar request to get automatically labeled so we're going to need a label called documentation for for this to work so we're going to go here to labels and we'll make a new label there actually already is one called documentation I don't know if this is case sensitive so I'm just going to change it to Capital D so it just works for us and we're going to go over here to code and I need a new Branch so I'm going to go to Dev and in here I'm going to create myself a um a docs directory so I'm going to make a new folder here and what I'll do do is I'll make a new folder we'll call this docs and I'll say readme.md read me okay we'll save that we'll go ahead and Commit This and we're in a branch right yeah we're in a branch so commit we're like new docs directory and I know I spelled that wrong it's okay nobody's watching here today there's no grading going on if I ever grade you I'll poke you for that but right now it doesn't matter and I think that we made that in the dev Branch so we'll go over here and I want to go ahead and create a new pull request so want to make sure that folder is there pull requests new pull requests we'll drop down Dev we'll compare that over we'll say create pull request and the idea is that when we create this it should label it if this worked as expected um and so what I want to do is go over to actions and see if it triggered and it's running so it's queued it's going to think what to do it has to spin up compute so this is an instantaneous in progress good we're watching it label complete success we'll go to our pull request there we go look at that um and now we have a p a check that passed and we overo to our checks and it shows that it passes so you know before we talked about like Branch rules we could maybe tell it that it has to pass that before it could proceed not a really good example for this but we could try it and it's just an opportunity to show off this Branch protection rule stuff so I'm just looking here carefully for where that was uh it was like checks okay and I'm going to drop that down and still doesn't show up here so maybe that doesn't work as expected but I was hoping that maybe I could just choose that from there um because it's not like an upfront check it's like something that happens after you do that but anyway that's get up actions in a nutshell um it is very important that we understand how those files work so before I go I just want to uh pull up a link because there was something that really explained the structure of these files really well it was understanding GitHub actions okay so let this here learn GitHub actions understanding GitHub actions I think it was this one yeah and so this one really helps explain this workflow file so let's go through it really quickly and make sure we understand it so um first thing is the name so we're going to name it that's optional we have run name so the workflow uh runs that generated from the workflow I guess it's going to be like the Run name we have on so specify the trigger of this workflow so on triggers events jobs groups together all the jobs that run then we have steps groups together all the steps that run uh in the check bats version notice we didn't have these before runs on configures the run on the latest version of Ubuntu Linux Runner I imagine you could change this to other things uses the uses keyword specifies the step that will run uh here and of course we found out those are remote repos so that makes sense um and that's pretty much it so so steps jobs on remember those three on jobs and steps okay and that's pretty much it so I'll see you in the next one okay ciao hey this is Andrew Brown from exam Pro and in this section we'll be going over package management package management refers to a systematic approach to handling the installation upgrade configuration and removal of software packages within a computer system it simplifies the process of managing software applications and their dependencies ensuring consistency and efficiency across the development life cycle and system maintenance core functions and benefits automated handling automates the management of software applications reducing time and effort for installation upgrades and removal consistency across environments ensures uniform software management across various environments boosting efficiency and reliability dependency and configuration management automates management of dependencies and configurations ensuring compatibility and availability for stable performance scalability facilitates software management across multiple systems easing updates and rollbacks he components package a bundle containing software or libraries along with metadata that includes information like version dependencies and configuration details repository a centralized storage location where packages are hosted allowing users to search download and install packages package manager the tool that interfaces with repositories to manage the installation upgrading and removal of packages based on dependencies and version requirements some tools and examples include liux package managers dpkg such as Debian and auntu RPM such as red hat and Fedora language specific managers and PM for JavaScript tip for Python and Maven for Java so that's an overview of package management the next topic will be covering our package feeds at package feed is a repository hosting software packages such as libraries Frameworks modules along with Associated metadata it supports dependency management and various application scenarios through package versioning and organization types of package feeds public feeds hosted by thirdparty providers like net.org and pjs.com and accessible to the broader development Community private feeds internal repositories managed by organizations to store proprietary packages and control team access designing a package feed key considerations storage select from local file systems network attached storage or cloudbased Services organizational structure categorize packages by type purpose or technology versioning Implement a versioning strategy typically semantic versioning AIS control set up authentication and authorization me mechanisms for private feed security implementing a package feed tools and platforms Azure artifacts a fully managed Microsoft Azure service supporting new get npm mavin and python packages it simplifies the creation publication and management of package feeds GitHub packages supports various package formats integrates with GitHub repositories and allows direct package publishing ideal for open source projects package management tools tools like new get npm and mavin that offer capability ities to create in host feeds with command line or ID integration using Upstream sources functionality Upstream sources extend the range of available packages by linking additional feeds whether public private or both in Azure artifacts Upstream sources can include other Azure feeds package Registries or public feeds this ensures that the latest package versions are always available configuration configurable via the Azure devops portal or Azure CLI allowing Azure artifacts to Upstream sources for packages not present locally so that's an overview of package feeds let's take a look at dependency management dependency management automates the handling of software dependencies to ensure projects run smoothly with all necessary external libraries Frameworks and modules key components dependencies required external software components version specification defines compatible dependency versions dependency graph shows relationships among dependencies package repository Central hub for dependencies dependency resolver automates dependency resolution benefits streamline development automates environment setup by managing dependencies consistent builds ensures uniform dependency versions across all development stages reduce conflicts manages compatibility to prevent software component conflicts efficient upgrades manages dependency versions for easy updates implementation configuration files specify dependencies using files like package.json or pom.xml version locking uses lock files to maintain consistent dependency versions automated tooling tools like npm Maven and pip automate dependency management tasks let's take a look at a comparison between dependency versus package management purpose dependency management ensures compatibility and resolves dependencies while package management handles package life cycle so Fus dependency management targets component compatibility package management manages package storage and life cycle main function dependency management automates resolution package management oversees handling and distribution tools both uspm and mavin dependency management also uses pip while package management incorporates new get in others outcome dependency management maintains functionality package management streamlines processes usage scenario dependency management is essential for external Library Reliance package management is crucial for consistent management so that's an overview of dependency management the next thing we'll be covering is an overview of azure artifact Azure artifacts is a component of azure devop Services focused on package management and collaboration it supports sharing versioning and integrating packages into CI CD workflows some of the features that Azure artifacts provide are package management supports multiple package formats manages new get npm Maven Python and Universal packages all in one place Version Control offers tools for managing package versions and dependencies effectively integration and collaboration cic CD integration integrates with Azure devops pipelines for streamline package creation and deployment shared feeds allows package sharing within teams or the entire organization access control and security access control offers settings to control package access Main maintaining security within projects secure hosting provides a secure environment for hosting and accessing packages getting started with Azure artifacts and Azure subscription is required to use Azure artifacts creating a feed navigate to your Azure devops organization or project select artifacts from the top right menu then create feed enter the required information such as name and visibility options and create the feed after creating a feed you can publish packages like new get mpm and mavic but we'll need to do a few things before that so first we'll need to ensure you have the latest version of the Azure artifacts credential provider installed from the get the tools menu new get configuration file you need to add a net config file to your project in the same folder as your CS project or HL in file the configuration should specify the package source for Azure artifacts like the code shown here this will be provided for you depending on the package you pick publishing command to publish a package provide the package path an API key and the feed URL net.exe push Das Source exam Pro feed API ke a z package path replace package path with the actual path to the package you intend to publish so that's an overview of azure artifacts the next topic we'll be covering is new get and mpm new get is a popular package manager for net applications it allows you to easily manage dependencies and distribute packages within your projects create creating a new get package use the net.exe or net command line tool example using net navigate to your project directory and Run net pac configuration release this generates a new get package from your project in the release configuration publishing new get packages you can publish to Azure artifacts GitHub packages or host your own new get feed using platforms like Azure devop server my get or pret for private distribution and PM is the default package manager for note. JS and JavaScript applications it provides a vast ecosystem of packages that developers can use within their projects creating an mpm package initialize a new project with npm in it follow the prompts to generate a package. JSO and file that includes your package metadata publishing npm packages to publish to the npm registry ensuring your package is available globally run npm publish this command uploads your package to the npm registry for Public Access so so that's a short and simplified overview of new get and npm the next thing we'll be covering are the main types of versioning versioning in devops refers to the practice of assigning unique versions to code or artifacts to track changes and maintain historical records versioning strategy options semantic versioning detailed structure indicating the nature of changes datebase versioning uses dates offering a chronological timeline of updates sequential version simple incrementation providing clear change order semantic versioning is a widely used method that helps manage changes in software libraries through three version components major minor and Patch major version increases indicate backward and compatible changes minor version increases are for Backward Compatible additions patch version increases apply to Backward Compatible bug fixes guidelines for semantic versioning initial release start with one for stable software major changes increment major version for breaking changes Miner editions increment Miner version for new features that maintain compatibility bug fixes increment patch version for stability improvements without new features or breaking changes datebase versioning uses the format YY yymmdd to reflect release dates offering a clear timeline of updates consistency maintain a standardized date format major changes Mark significant updates in the version name EG 2022 0114 Alpha combination with sver enhanced detail by combining with semantic versioning EG 2022 0114 alpha 1 2 3 sequential versioning assigns a unique sequential number to each version of a pipeline artifact starting with version one each update increments the version number progressively it's straightforward and clearly indicates the chronological order of changes so that's an overview of the main types of versioning hey this is Andrew Brown from exam Pro and in this section we'll be covering the key considerations when implementing an agency infrastructure designing an implementing an agent infrastructure is crucial for a successful devop solution key considerations include cost tool selection licenses conductivity and maintainability cost considerations Azure pipelines agents hosted by Microsoft cost effective build base on Parallel pipelines selfhosted agents more control but additional costs for Hardware maintenance and scalability tool selection Azure pipelines automates build test and deployment across platforms supports various languages containerization with Docker Visual Studio team Services predecessor of azure devops integrates with Azure pipelines features Source control work item management and project planning licenses Azure pipelines free tier with limited concurrent pipelines and duration paid tier for more scalability selfhosted agents requires licenses for the underlying operating system such as Windows server or Azure VMS connectivity Azure pipelines agents secure internet communication using https fetches source code executes tasks and reports results selfhosted agents network access to resources like Source control repositories artifact feeds and Target environments within your infrastructure maintainability aure pipelines agents automatically updated by Microsoft no manual effort required selfhosted agents regular updates needed for compatibility with guidance provided by Microsoft so that's an overview of implementing an agency infrastructure the next thing we'll be going through are pipeline trigger rules pipeline trigger rules Define conditions under which a pipeline is automatically triggered optimizing resource usage and reducing unnecessary builds and deployments Microsoft devop Solutions offer flexibility in designing custom trigger rules here are key scenarios branchbased trigger trigger a pipeline only when changes are made to a specific Branch this triggers the pipeline for changes in the main branch pathbased trigger trigger a pipeline when changes occur within specific file paths this triggers the pipeline for changes in the SRC directory schedule base trigger run pipelines at scheduled intervals regardless of code changes this triggers the pipeline every day at midnight implementing pipeline trigger rules navigate to your project and Azure Dev Ops open the yaml file that defin finds your pipeline locate the trigger section within the yaml file Define the desired trigger rules based on the scenarios above or any custom rule save the yml file benefits of pipeline trigger rules reduce resource consumption minimizes unnecessary usage leading to cost savings and efficient resource utilization improved efficiency ensures actions are performed at the right time streamlining development and deployment processes enhanced control provides developers with control over pipeline execution improving management and coordination of development efforts so that's an overview of pipeline trigger rules the next topic we'll be covering are the types of pipelines classic pipelines provide a graphical interface for creating and configuring pipelines using a drag and drop approach this simplifies defining the stages of your pipeline such as build test and deployment steps to create a classic pipeline widen select pipelines from the left side menu two click new pipeline to start three choose the repository where your source code is located four select a pipeline template based on your application type such as aspn node.js and Java five customize the pipeline stages tasks and configurations add tasks like building the code running tests and deploying the application six save and run the pipeline yl pipelines offer a flexible code Centric approach to defining pipelines pipeline configurations are defined as code in yaml files which can be version controlled along with your source code for easier collaboration and consistency across environments creating a yl pipeline why select the pipelines option from the left side menu to click on the new pipeline button three choose the repository where your source code is located four select the yl option when prompted to choose the pipeline configuration style five create a yl file in your repository to Define your pipeline configuration the yaml file should contain stages jobs and tasks for your requirements for example as shown on the image on the right six save the yl file in your repository and commit the changes seven Azure devops will automatically detect the yaml file and create the pipeline base on the configuration defined in the yaml file pay to save and run the pipeline to see it in action so that's an overview of the types of Pipelines the failure rate of your pipeline indicates the number of failed builds or deployments over a specific period monitoring the failure rate helps you identify potential bottlenecks or issues in your pipeline Azure monitor can be used for this purpose Azure monitor provides comprehensive monitoring for Azure resources including pipelines it collects data on Pipeline failures and allows you to set up alerts based on specific failure thresholds these alerts help you address issues proactively maintaining pipeline Health configuration enable metrics and diagnostic logs metrics include success rate average duration and failure rate diagnostic logs capture detailed information about pipeline runs including errors and warnings here's an example of how you can enable Azure monitor for a pipeline duration monitoring monitoring the duration of your pipeline is crucial longer durations indicate performance issues that can impact overall efficiency Azure Dev Ops provides builtin capabilities for this Azure pipelines allows tracking the duration of individual pipeline runs identifying outliers and analyzing performance Trends over time use the Azure pipeline's rest API to retrieve the duration of pipeline runs custom scripts or Powershell can automate monitoring and Reporting here's an example of how you can retrieve the duration of pipeline runs using the Azure pipeline's rest API flaky tests monitoring flaky tests producing consistent results leading to false positives or false negatives monitoring and addressing flaky tests is essential for pipel reliability Azure Dev op supports various test Frameworks and provides tools to detect and monitor flaky tests Azure test plans can manage test cases track executions and identify flaky tests group test cases and test Suites schedule test runs and capture results analyze results to identify and Mark flaky tests built in reporting visualizes Trends and tracks improvements over time here is an example of how you can Mark a test case as flaky using Azure test plans so that's an overview of monitoring pipeline Health using various methods hey this is Andrew Brown from exampro and in this section we'll be covering Azure container instances Azure container instances allow you to launch containers without the need to worry about configuring or managing the underlying virtual machine Azure container instances is designed for isolated containers they are tailored for simple applications task Automation and tasks like build jobs containers can be provisioned within seconds whereas VMS can take several minutes containers are built per second whereas VMS are buil per hour providing potential cost savings containers have granular and custom sizing of vcpus memory and gpus whereas VM sizes are predetermined ACI can deploy both windows and Linux containers you can persist storage with Azure files for your ACI containers once deployed aciis are accessible via a fully qualified domain name like custom label. aure region . aure container. Azure provides quick start images to start launching example applications but you can also Source containers from Azure container registry Docker Hub or even privately hosted container registry container groups are collection of containers that get scheduled on the same host machine the containers in a container group share life cycle resources local network and storage volumes container groups are similar to a kubernetes pod multicontainer groups currently support only Linux containers there are two ways to deploy a multicontainer group to deploy a multicontainer group you can use either a resource manager template if deploying additional Azure service resources or a yaml file for deployments involving only container instances overall Azure container instances simplify container deployment and scaling removing the complexities of infrastructure management the next topic we'll be going over our container restart policies a container restart policy specifies what a container should do when their process has completed these policies ensure that the container instances can handle different scenarios effectively based on the specific requirements of the application or task Azure container instances has three restart policy options always this policy ensures that the containers restart continuously regardless of whether they exit successfully or not it's useful for applications that need to be constantly available such as web servers never with this policy containers do not restart once they've completed their execution this is ideal for tasks that are designed to run once and then terminate such as batch jobs or scheduled tasks on failure containers will only restart if they stop due to an error or unexpected termination this ensures that if a container crashes or faces an unexpected error it will try to restart and continue its operations overall choosing the appropriate restart policy is vital for the stability and responsiveness of your applications the next topic we'll be covering our container environment variables environment variables are key value pairs that can be used to configure and manage the behavior of applications running inside containers environment variables allow you to pass configuration details to your containers which can be critical in guiding applications on how to connect to databases where to find certain resources or how to adjust their behavior based on the environment they're running in in Azure you can easily set up these environment variables for your containers using the Azure portal or poers shell secured environment variables by default environment variables are stored in plain text to address this Azure offers the option to secure your environment variables instead of storing them in plain text which could expose sensitive information if breached you can Leverage The secure environment variables flag so that's a quick overview of container environment variables the next topic we'll be covering is container troubleshooting troubleshooting containers in Azure involves a series of commands that help diagnose and resolve issues as container logs this command lets you fetch logs from your container these logs can provide insights into application behavior and possible errors as container attach if you need diagnostic data during container startup use this command it helps in understanding issues that might arise during the initialization phase of a container as container exec for a deeper dive into the Container this command starts an interactive session this is useful for live debugging and to inspect the container's current state as monitor metrics list this command gives you metrics related to your container such as CPU usage which can be essential for performance tuning or identifying bottle X so these are the commonly used commands for container troubleshooting hey this is Andrew Brown from exam Pro and we're going to take a look at Azure container instances so here it is so all we got to do is go to container instances we'll hit add and the nice thing is that Azure provides us with a Hello World one so it's very easy for us to get started um it's a Linux machine and it looks like it's pretty inexpensive there so we'll stick with that I'm going to create a new group here we're going to call it banana um and we'll name the container instance banana and East Us 2 seems fine to me you'll notice we're on a quick start image if we wanted we could use something from the docker Hub and provide our own link but we'll just stick with the quick uh start image for today okay we're going to go ahead and hit next to networking just to see what we have as options you can make it public or private we'll go to Advanced hold on here yep those are just the ports you can expose we'll go to advance and for the restart policy we can set on failure always or never we can pass in environment variables and I covered this a lot more in detail in the lecture content so we don't need to really dive deep into this um and we'll go ahead and create this instance and so we'll have to wait a little while here and I'll see you back in a moment okay and so after a short wait our container instance is ready we'll go to that resource there and take a look around so on the left hand side we can go to our containers and there we can see it running we can see the events down below of what's going on so you can see that it's pulled the image it successfully pulled it and it started the container some properties nothing interesting there the logs if we wanted to see stuff and if we wanted to connect to the instance we could also go here and hit connect which is kind of nice um I don't have any purpose to do that right now so and it's also not going to work the way we're doing it but I just wanted to show you you had those opportunities uh you can do identity so that means manage it with ro base access controls but what I want to see is actually this uh hello world working I'm assuming that must be a a hello page I've never looked at it before so we're going to go here grab the public IP address and paste it on in the top and there we go so we have deployed a instance onto Azure container instances or a container I should say so nothing super exciting to talk about here um but we do need to know the basics uh there um if we wanted to deploy other containers it's just the one there so that's all you really need to do um but yeah so yeah hopefully that uh gives you an idea there I'll just go back to the list here so we can see it and we'll go ahead and just uh delete that probably do it for the vi the resources on the left hand side like I always like to do uh and we will go into banana here and we will delete banana and there you go selfhosted agents and Azure devops allow you to customize the agent environment to meet specific needs unlike Microsoft hosted agents selfhosted agents run on your infrastructure giving you more control over the environment and the tools installed on the agents use cases custom environments for specialized soft software or configurations not available in Microsoft hosted agents sensitive data suitable for projects with stringent data security requirements keeping data within your network resource intensive builds useful when builds require significant computational resources or specific Hardware setups benefits customization tailor the environment to specific project needs cost efficiency reduce costs by utilizing existing infrastructure consistent configurations ensure consistent setups across agents through templates or contain anization scalability Scale based on workload by provisioning new agents configuring selfhosted agents with VM templates create a virtual machine with the necessary agent software save it as a template and use the template to provision additional agents for consistent and simplified scaling create and configure a VM set up a virtual machine with the necessary operating system and dependencies install and configure the Azure devops agent software create a VM template capture the VM as a template including the agent software at its configuration provision new agents use the template to quickly provision new agents ensuring each new VM has the same configuration and is ready to connect to Azure Dev Ops managing selfhosted agents with containerization containerization involves creating Docker images that include the necessary agent software and dependencies offering a flexible and scalable solution for managing selfhosted agents create a container image develop a Docker image with the required agent software and dependencies including configuration detail push to a container registry store the container image in a registry like Azure container registry or Docker Hub deploy and scale containers use container orchestration tools to deploy and manage agent containers scaling up or down based on workload demands so that's an overview of selfhosted Agents hey this is Andrew Brown from exam Pro and in this section we'll be covering the types of deployment strategies a successful deployment strategy is crucial for efficent software delivery and minimizing user impact Microsoft devop Solutions offers various deployment patterns and strategies for continuous delivery and high availability blue green deployment is a technique that reduces risk in downtime by running two identical environments these environments are called blue and green only one of the environments is live with the live environment serving all production traffic in blue green deployment blue is live and green is set up for the new release deploy and test the new version in green without affecting blue after testing switch traffic to Green making it live this minimizes downtime and allows for quick roll back to Blue if issues arise enhancing reliability and user experience so that's an overview of blue green deployment a canary release is a strategy where a new version is deployed to a small subset of users or infrastructure first this helps identify unforeseen issues under real conditions with limited impact by monitoring the initial deployments performance teams can decide whether to expand halt or roll back the update based on real world feedback this phase approach ensures a safer and more controlled rollout minimizing risks associated with new releases to execute a canary release feature toggles selective feature activation traffic routing manage user access to the new version deployment slots version management these techniques enable a gradual and monitored roll out allowing for adjustments based on user feedback and system performance this method enhances application stability and user experience by addressing potential issues before a full scale deployment so that's an overview of canary release ring deployment is a strategy where users or infrastructure components are divided into multiple groups called Rings each ring receives updates sequentially starting with the smallest group and gradually expanding to the entire user base this allows for iterative releases starting with an internal ring and progressively reaching a wider audience this controlled roll out facilitates early feedback from different user groups or components for example in a threegroup production setup canaries voluntarily Test new features as soon as they are available early adopters voluntarily preview releases which are more refined than Canary versions users receive the final product after it has passed through canaries and early adopters this approach ensures a safer stepbystep roll out of new features or updates so that's the ring deployment strategy Progressive exposure is a deployment technique that gradually increases the number of users exposed to a new release initially a small percentage of user traffic is directed to the new release while its performance and behavior are monitored if the new release performs well without issues the traffic is gradually increased this approach helps identify potential issues early and minimizes user impact if problems arise continuous integration toe checkin developers check in code auto trigger CF pipeline triggers automatically build artifact code is built generating an artifact continuous deployment build version one approved and deployed to ring one for initial testing build version two approved and deployed to ring two for early adopters build version three approved and deployed to ring three production environment ring one Canary's Test new features Ring 2 early adopter preview refined releases ring three all users receive the final product so that's the progressive exposure deployment strategy feature flags are conditional statements that let you control which features or functions are visible and available in your application using feature Flags you can enable or disable features dynamically without redeploying the application this allows for testing new features gradual rollouts or quick deactivation if issues arise feature Flags also offer the flexibility to Target specific user groups for testing or rolling out features new feature a new feature is introduced feature Flags toggle switches control the visibility of the feature enabled the feature is enabled for specific customer groups disabled the feature remains off for other customer groups customers different customer groups experience the feature base on the feature flag settings this allows control targeted rollouts and quick adjustments of feature availability without redeployment so that's an overview of the feature flag deployment strategy a b testing is a method to compare two versions of a feature or user interface to see which one performs better users are divided into two or more groups each group experiencing a different version data on user Behavior engagement and other metrics are collected this approach helps make data driven decisions and optimize feature usability before a full roll out to all users user groups users are divided into two groups version a and version B each group is shown a different version of a feature or user interface for performance comparison user behavior and performance metrics are collected and compared results the graph shows which version performs better based on the collected data this helps in making informed decisions about which version to implement for all users so that's an overview of a b testing Azure traffic manager operates at the DNS layer to quickly and efficiently direct incoming DNS requests based on the routing method of your choice routing methods performance rote traffic to nearby servers to reduce latency weighted distribute traffic based on predefined weights priority route to a primary in point with fail over to backups if needed Geographic Route traffic base on the user's location multivalue return multiple healthy in points and DNS responses subnet route based on the user's IP address uses latency reduction route to nearby servers to minimize latency failover switch traffic to backups if the primary system fails a B testing Route traffic to random VMS for testing in this scenario we have an example of weighted routing where traffic is split 80% to production and 20% to Beta environments so that's a quick overview of azure traffic manager hey this is Andrew Brown from exampro and in this section we'll be covering Azure app service Azure app service is an HTTP based platform for web apps re estall apis and mobile bin services is you can choose your programming language in Python Java or any other language and run it in either a Windows or Linux environment it is a platform is service so it's the Heroku equivalent for Azure Azure app service takes care of the following underlying infrastructure OS and language security patches load balancing Auto scaling and infrastructure management Azure app service makes it easy to implement common Integrations and features such as Azure Dev Ops for deployments GitHub and dockerhub package Management Systems easy to set up staging environments custom domains and attaching TLS or SSL certificates you pay based on an Azure app service plan shared tier includes free and shared options litex isn't supported here dedicated tier includes basic standard premium premium to premium 3 and there's isolated tier as your app service is versatile you can deploy single or multicontainer Docker applications when you create your app you have to choose a unique name since it becomes a fully qualified domain overall Azure app service simplifies your web hosting needs ensuring you can focus on coding and let Azure do the heavy lifting let's delve into runtimes and Azure app service so what is a runtime environment a runtime environment refers to the software and settings needed for a program to run in a defined way at runtime a runtime generally means what programming language and libraries and framework you are using a runtime for Azure app services will be a predefined container that has your programming language and commonly Ed library for that language installed with Azure app Services you're presented with a range of run times to choose from including net. net core Java Ruby node.js PHP and python moreover Azure app Services generally supports multiple versions of each programming language for example for Ruby you might find versions 2.6 and 2.7 it's worth noting that cloud providers including Azure May phase out support for older versions over time this not only ensures that they're offering the latest and most efficient tools but also promotes better security practices among users pushing them to keep up with the latest patches so that's an overview of runtimes and Azure app service the next thing we'll be covering are custom containers and Azure app service Azure app service gives you the flexibility to use custom containers for both windows and Linux the primary reason you might opt for a custom container is to use a distinct runtime that is natively supported or to incorporate specific packages and software here's a straightforward process to get started with custom containers in Azure app service design your container Begin by creating a Docker container tailored to your needs on your local machine push to Azure once your container is ready push it to the Azure container registry this centralized repository ensures that your container is easily accessible within Azure deploy and go live finally deploy your container image directly to the Azure app service once deployed Azure takes care care of scaling maintenance and updates another advantage of custom containers in Azure app service is that they offer more granular control over your environment you can finetune performance security and other aspects of your application environment to suit your needs the next topic will be covering our deployment slots in Azure app service deployment slots allow you to create different environments of your web application Associated to a different host name this is useful when you require testing staging or QA environment alongside your production setup deployment slots let you swiftly replicate your production setting for various purposes ensuring consistent testing environments you can also swap environments this is useful for executing blue green deployments by using swap you can promote your staging environment to production with these you can promote our staging to production by swapping if something goes wrong you could swap them back this capability ensures minimal downtime and enhances the user experience since you can introduce changes in a controlled manner rolling them back if necessary in addition Azure ensures that when swapping the instances are warmed up before traffic is routed resulting in zero downtime so that's a quick overview of deployment slots the next topic we'll be covering is the app service environment in Azure app Service app service environment is an Azure app service feature that provides a fully isolated and dedicated environment for securely running app Service app apps at high scale this allow you to host windows and Linux web apps Docker containers mobile apps and functions app service environments are appropriate for application workloads that require very high scale isolation and secure network access and high memory utilization customers can create multiple ases within a single Azure region or across multiple Azure regions making ases ideal for horizontally scaling stateless application tiers in support of high requests per second workloads as's comes with its own pricing tier called the isolated tier ases can be used to configure security architecture apps running on ases can have their access gated by Upstream devices such as web application firewalls app service environments can be deployed into availability zones using Zone pinning there are two deployment types for an app service environment external ass and ilbs external ass exposes the ass hosted apps on an internet accessible IP address if the vnet is connected to your on premises Network apps and your ass also have access to resources there without additional configuration because the ass is within the vnet it can also access resources within the vnet without any additional configuration ilbs exposes the ass hosted apps on an IP address inside your vnet the internal and point is an internal load balancer so that's an overview of app service environment and Azure app service the next thing we'll be going over is deployment in Azure app service so what is deployment well it's the action of pushing changes or updates from a local environment or repository into a remote environment Azure app Services provides many ways to deploy your applications including run from package deploy zip reward deploy VI FTP deploy via Cloud sync such as Dropbox or one drive deploy continuously with GitHub bitbucket and Azure repos which using kudu and Azure pipelines deploy using a custom container CI CD pipeline deploy from local git deploy using GitHub actions deploy using GitHub actions containers and deploy with template run from a package is when the files in the package are not copied to the WW root directory instead the zip package itself gets mounted directly as the re only ww root directory all other deployment methods and app service have deployed to the following directory for Windows deol we use back slashes home site ww root for Linux we use for/ home site ww rout since the same directory is used by your app at runtime it's possible for deployment to fail because of file lock conflicts and for the app to behave unpredictably because some of the files are not yet updated zip and War file deployment uses the same kudu service that powers continuous integration based deployments kudu is the engine behind get deployments in Azure app service it's an opensource project that can also read outside of azure kudu supports the following functionality for zip file deployment deletion of files left over from a previous deployment option deter on the default build process process which includes package restore deployment customization including running deployment scripts deployment logs and a file size limit of 2,48 megabytes you can deploy using Azure CLI Azure API via rest and Azure portal you can use file transfer protocol to upload files you will need your own FTP client you just drag and upload your files go to the deployment Center get the FTP credentials for your FTP client you can use Dropbox for one drive to deploy using a Cloud sync Dropbox is a thirdparty cloud storage service one drive is Microsoft's cloud storage service you go to deployment Center configure for Dropbox or one drive when you turn on sync it will create a folder in your Dropbox Cloud Drive one drive apps Azure web apps Dropbox apps Azure this will sync with your home site ww root so you just update files in that folder in summary Azure app service offers a range of deployment methods ensuring flexibility and easy for developers the next thing we'll be covering is the Azure app service plan Azure app service plan determines the region of the physical server where your web application will be hosted and defines the amount of storage RAM and CPU your application will use it offers several pricing tiers shareed tiers there are two shared tiers free and shared free tier provides this tier offers 1 gab of disk space supports up to 10 apps on a single shared instance provides no availability SLA and allows each app to compute quot of 60 minutes per day share tier provides hosting multiple apps up to 100 on a single shared instance no availability SLA is offered and each app gets a compute quote of 240 minutes per day it's worth noting that Linux based instances are supported in this tier dedicated tiers basic standard premium premium 2 Premium 3 basic offers more disk space unlimited apps three levels in this tier that offer varying amounts of compute power memory and disc storage standard allows scaling out to three dedicated instances guarantees 99.95% availability and also has three levels with varying resources premium provides the ability to scale up to 10 dedicated instances and ensures 99.95% availability and it includes multiple Hardware level options isolated tier dedicated Azure virtual Network full Network and compute isolation scale to 100 instances and availability SLA of 99.95% so the Azure app service plan lets you tailor your hosting environment and budget to fit your application needs hey this is angrew Brown from exam Pro and we are going to be learning about Azure app services in this follow along uh and it's a service that's supposed to make it easy for you to deploy web applications I say supposed to because it really depends on your stack Azure has more synergies with other stacks and others so like if you're like me and you like Ruby on Rails you're going to find a lot of friction with rails and Linux but if you're using something like Windows servers or python orn net you're going to have a much easier time still really great service just wish they'd make it a bit more broad there but let's hop into it so before we can go use that service let's make sure that it's activated and so we'll go over here and we'll go to Azure subscription and then down below we're going to go to Resource provider now you think what you could do is just type in app Services uh and you'd be wrong because the the service is under a particular provider if you want to figure out what provider it is we can go um Azure resource providers and they have a page on documentation here that lists them all so if I search for Azure app Services it's under web and domain registration so we're going to make sure this is registered if we're using a custom domain which we are not today we need this one activated so going back here I will type in web and you can see it's registered so if yours is not registered go ahead and hit that I believe this by default is generally registered with new Azure accounts so I don't think that is an issue for you but we'll go back up here close these additional tabs and we will type in Azure app services and we will look for that service so there it is and we'll go ahead and hit add um and so I'm going to give it a new name I just made it a moment ago but I'm going to try again and try to use the same name so we're going to call this Voyager Great and then I'm going to go ahead and name this Voyager and I already know that that is taken so I'm going to type in Delta Flyer and these are fully qualified domains so they are unique with Azure app Services you can run a Docker container we're doing code this time around and what I like to use is a ruby um but again you know if I want to use the cicd I'm not going to be able to the deployment center with Ruby so that is not possible um and so we're going to go with python and run either a flask or ajango app I haven't decided yet I am in Canada so let's go to Canada east and uh down below here we have the plans generally the plans will tell you the cost underneath look you'll notice that it's loading but I just want to show you that there are some discrepancies in terms of pricing so if I was to go to Azure app Services pricing and we were to pull this up here we can kind of see the pricing here okay and if we scroll on down right now we're looking at a premium V2 uh and oh no I don't need help I'm okay you'll notice that it's 20 cents per hour so if I go here and do that times 730 because there's 730 hours in the year that's $146 I believe this is showing me in USD dollar yeah and in here it's showing me 103 Canadian which is lower um so it could be that because I'm running in a Canada east region it's the price is different but you could imagine that if I had this at this cost at uh what did we say here um at 146 USD to CAD I'd actually be paying $182 so you got to watch out for that kind of stuff but I'm pretty sure this is what the cost is so just be aware that if you look stuff up in here it's not necessarily reflective so you got to do a little bit more work to figure that out uh if we wanted to go here uh we cannot choose the free tier when we're using Linux if we're using Windows I believe we can use it we're working with Linux today so that's just how it's going to be um for the B1 this is totally fine but we want to utilize deployment slots deployment slots is an advanced feature of uh the production version and that's the only way we're going to be able to use it here this is 20 cents per hour again so I don't want to be doing this for too long but I think what we'll do is before we do that we can just do an upgrade to Dev to prod so we can experience that I'm going to go and just choose B1 okay so go next um we do not need any application insights for the time being and it will not let us so it's okay we'll go next review and create and we'll go ahead and create this resource here and I will see you back when this is done so um our resource Now set up we'll go to Resource and now that we're in here you'll notice if we hit browse we're not going to see anything because we do not have anything deployed which makes sense right uh so we're going to actually have to go ahead and deploy something so we are going to make our way over to the deployment Center and uh it's just going to tell us that we have yet to configure anything and that's totally fine we're going to go to settings it'll give it a moment and so the thing is is that we're going to need something to deploy um I did not create an app but the great thing uh is in the Azure documentation they have a bunch of quick starts here all right and apparently they have one for Ruby as well but today we are looking at python uh and so they actually have an example repository for us here which is github.com asure samples python docs hello world and I mean I could go make a repo for you but we might as well just use the one that is already provided to us so I'm just going to pull this up to show you what's in it it's a very very simple application even if you don't know anything about building web apps I'm going to walk you through it really easily here okay so we're going to open up app.py so we are using flask if you've never heard of flask it is a very minimal python framework for creating web apps uh very uninspiring uh homepage here but it gets the job done it's going to create a default route for us which uh we have there we're going to call hello here and we're going to have hello world so that's all that's going on here very very simple and we have our requirements this is our package manager I don't know why python uses txt files it's very outdated to me but that's what they use and here we have flask all right so we're going to use that repo and it's a public repo so it should be very easy for us to connect so we'll drop down go to GitHub and uh the next thing we need to do is authorize GitHub all right so I ran into a bit of trouble there because I could not uh authenticate my uh GitHub account but you know what I just made another GitHub account so that made it a lot easier I'm going to go ahead here hit GitHub and we're going to try to authorize it and so now I'm logged into this new one called exam Pro Dev and we'll go ahead and authorize this application and we're now in good shape this repository doesn't have anything in it so um if I want to clone something I guess I'll probably have to Fork that repo so we'll give it a moment to authorize and while that's going I think that's what I'm going to do I'm going to go and uh Fork the example repo if I can find the link again here uh myself uh I believe it is that's still authorizing over there I'm still looking for it so it was like examples or something samples or examples all right so I found a way around the problem I just made a new uh GitHub account so that's all I had to do um and I just won't be using my primary account until I get my phone back but um so what we'll do is go hit connect I'll hit authorize and it didn't prompt me because it already connected to this new one called exam Pro Dev you might have to put your CR itial in here and it's going to ask me to select some things it's a new account so there are no organizations there are no repositories there are no branches totally brand new so what I'm going to need to do is get a repo in there so we'll just go ahead and Fork the Azure samples one so that is azure samples python docs hello world and if I type that right we're in good shape I'm going to go ahead and Fork this repository I'll say got it and then I'll move this off screen here this is now cloned you should see it cloned here and we'll go back here and this probably isn't live so there's no refresh button here so we'll have to hit discard and we will give this another go here and we will select our organization which is our name there is the repository uh should be main branch is kind of outdated I'm sorry but it's called Master that's what it is not my fault that's azure's fault okay um and I think that's it I don't know if we need a workflow configuration file I don't think so just going to double check here no I don't think so and uh what we'll do is we'll just go ahead and save that and so now we are set up for deployment all right so now that that's all hooked up if we were to go to browse we're actually still seeing the default page a deployment hasn't been triggered just yet uh so the way it works is it's using GitHub actions so if we click into our call it main branch I know they got the wrong name but uh we're going to click into our GitHub workflows and then below here we can see we have a yaml file uh and this is for GitHub actions integration here and so what it's doing is it's specifying the branch uh what how it's going to uh build going to run onto bunto latest the steps it's going to do it's going to check it out it's going to set up the python version it's going to build it it's going to do that stuff and so in order for this to um take action we'd actually have to go ahead and make some kind of manual change which we have yet to do so e so what we'll do is we'll go back to our main here and uh it should be as simple as uh just changing something here so it's not I'm not sure how it's supposed to know that it's supposed to be doing the hello we oh I guess yeah sorry so this means it's going to Route over to here um so I'm just going to make any kind of change here doesn't matter what it is just one space we'll go ahead and give it a commit and um if I go back to my latest commits we should see that I made that change there it is we'll go back over here and this should be deploying um so if we go over to logs here you can see one's in progress right now okay and so that's what we're waiting we're just going to see that finish there we could probably open the logs and get some more information there and so it just brings you back over to GitHub actions and so here's GitHub actions and it's performing the stuff here so we're just going to give it time here and I'll see you back in a moment so we didn't have to wait too long it only took 1 minute and 29 seconds if we go back over here um we might need to do a refresh and so we can see this is reflected over here and so if we go back to it doesn't really matter if we go to settings or here but I'm going to hit browse and see if my page is deployed it still is not so we do have a small little problem here and it's really going to just have to do with how the app is serve so that's what we need to figure out next all right so our app is not currently working and uh there's a few approaches we can take and the thing I can think right away is we should go in SSH into that instance if you scroll on down here from developer tools you can go to SSH and click this button and that's going to SSH you right into that machine right away you can also uh access SSH via the um CLI command so I believe it's like it's like a web app um SSH it'll do the exact same thing you do that from the cloud shell but that's not what we're doing today I give this an LS in here and we're in Linux we can see we have our app here and uh what I would do is I would see what's running so I I would do a puma uh or sorry not Puma PS Ox grep uh python and you can notice that we have a gunicorn that's running so that is where our python instances are running so you're not looking for flas you're looking for python here and if we wanted to make sure that was working we just type in curl Local Host um and so that is going to return up Port 80 so that tells me that because like curl just means like let's go look at that page um it should return some HTML like print out the HTML to us so that means the app is not running um so what you could do is run flask run and it's going to start on Port 5000 right so what I can do is I can go up uh back to my deployment Center here and I'm going to go get that link here and just ignore the fact that it's working uh it's it's not working right now I know for certain it's not um but if we do 5,000 that won't resolve because Port 5,000 isn't open so we can't really just uh put 5,000 in there and the default server here would be 5,000 so if I stop this and I specify Port 80 right then this will start up the app on Port 80 and so now when you go here okay it will work uh this is not a great way because of course as soon as you kill it here uh technically the S should stop running um and so you'll run into that step uh so what we need to do is provide a configuration to gunicorn which is a python thing again it's not so important that you know how like what these things are but the idea is that you understand as administrator you want to make sure you have an app that runs after you do a deploy and so in this particular one we need a startup. txt uh and interestingly enough there is a example code by the same author of the other one we were looking at here I believe it's the same person or it might not be but uh they have a startup txt right and so in here you can see that it binds on Port 0000 it starts up four workers starts up the app all right um and so that's something that we can go ahead and do so uh what I will do is I will go back to my GitHub repository that we have here and I can just go ahead and add a new file so I'm going to say um add a file create a new file here we'll call it startup. txt I'm going to copy this command here and paste it in there so gunicorn will bind the workers and startup on the app um startup app is being ran by uh something here so if I go back here I think they have a startup High here and that's all that it is doing um I think I want to I could do it this way I suppose let me just see here there's is a slightly different eh so they actually have like a full app going on here and I just want a very simple flask app so I think what I can do is put flask run here Port 80 and that should start up the app there I'm going to go ahead and commit that file okay and as since I commit that if I go back to my actions it created that startup file there so it should trigger a build it's queued up um and I'll just put this tab up here so we'll be back here in 2 seconds and if I give this a nice refresh yeah you can see it deploys in progress so uh this doesn't take too long we'll just wait close that there we'll just wait a few minutes we click logs it just opens it back up here and we'll see how that goes all right so uh your deploy may have finished there but the thing is is that we're not going to really know if uh a change has taken effect unless we actually go ahead and update our code so what I want you to do is go to your code tab go to your app.py we'll hit edit and I'm going to go ahead and change this to Vulcan and then we'll scroll on down hit commit changes and we'll make our way back over to our deployment Center and we'll give it a refresh here and we're just going to wait until this one is complete and we will double check to make sure that that is changed if it is not we will take action to fix that okay all right so we just waited a little while there for that deploy to happen and if we go to our website here it is taking effect so that's all we had to do to get it working so that's pretty good um so that is uh deployment so let's talk about deployment slots in order to utilize this feature we're going to actually have to upgrade our account because we cannot utilize them at this uh the basic plan here we got to go to standard or premium so let's go ahead and give that an upgrade uh so here's the B1 we're going to go to production here um and I think yeah we're going to have to choose this one here uh very expensive so the thing is we going to just upgrade it temporarily unless there's more options down below that are cheaper yeah these are the standard tiers let's go with this one here because it's only $80 again we're not going to be doing this for long but I want to show you how to do staging slots and auto scaling okay so we'll go ahead and apply that there and now it says that it's applied so if I go back to our app here and we click on deployment slots sometimes it doesn't show up right away if it doesn't that's not a big deal you just wait a bit but today it's super fast so we're going to go ahead and add a new slot we're going to call it uh staging we're going to deploy from our production Branch here and I'm going to go ahead and create that there and we'll just wait until that's done okay great so we waited a little bit there and uh our slot is created so I'm going to just hit close there and so now let's go take a look and see if we can actually see the application here so I just clicked into it I click browse and we're getting the default page so nothing is actually really deployed to it uh so how are we going to do that that's the the main question here um so what I'm going to do is I'm going to make my way over to the deployment Center and you can see that it's not configured for the slot so we are going to have to set it up all over again even though it copied over configuration settings it didn't copy over the code so we go to GitHub we'll choose our organization again I'm going to choose the repository we're going to choose that main branch again there we're going to let it add a workflow and notice that this time it's going to call it staging yaml so there'll be a separate workflow that gets created we're going to go ahead and save that there and what we can do is again click onto our Branch name there and if we click into our workflows we'll not now notice that we have a staging example it's the same thing um but it should be able to now deploy so the whole purpose of um these deployment branches is that it helps us uh we can deploy different versions of our apps but also um it's just a place where we can uh uh view things before we actually roll them out so we want to make sure 100% that they are working correctly um I don't think this will automatically push out let me just go to my actions to see if this is deploying notice that we have two workflows now we have staging here uh and yeah it looks like it's going to deploy here so we'll just wait a little bit um but maybe what we can do is try to have a a slightly different version uh for each one here okay uh but we'll just let that finish and I'll see you back in a moment all right so our deploy finished there so now if we go back to our website here we go browse we should see that application it says hello Vulcan and if we go and take out this we still have hello Vulcan so how can we have a uh a variant of this so that we can push out to that so what I'm going to do is I'm going to go back to my application here I'm going to go to code and I'm just going to make a minor change um I don't say also is that spelled right startup doesn't look correct to me um so maybe I'll go ahead and adjust that file but it doesn't seem to be affecting anything which is I'm a bit surpris there so what I'll do is I'm going to go and edit that file and give it the proper name can I rename this file yes I can so we'll call that startup file I thought we need that for deploy I guess it just works without it which is nice uh if we go back here I'm going to go and I actually just want to edit my um app here again and I'm going to go and edit this and we'll say um hello Andor or hello andorians maybe and so if I go back to my actions the question what is it deploying is it going to deploy the production or the staging and it looks like it's going going to do both looks like it's doing both here the one way we could tell is we can go to our logs here and we can see that um so we did to deploy so there's one change here uh if we go back to our main application and our deployment Center here and we go over to our logs you can see that they're both deploying so it doesn't seem like it's a great thing that that's how it works so the question is is then how would we um facilitate that deploy right how could we do that I suppose what we could do is just make a separate staging Branch um so if I go over to code here um I don't think we can just make branches through here so what I'm going to have to do is go ahead and oh I can create a branch right here so we'll just type in staging and we'll go create ourselves a new branch and now we are in this branch and what I'm going to do is go ahead and modify this and we're just going to call this um hello Klingons okay we'll go ahead and update that and so this should be a separate Branch so you think what we could do is go in and just change our settings so that it deploys from that one uh we'll go back to our deployment slots we'll click into staging here and we need to change our configuration settings um I think we could just do it from um here hold on here I could have swore it specified the branch if we go to deployment Center here I think it's set up on that other Branch there I think we just adjust it here so yeah I think we could just um adjust these settings um we can't discard them but maybe what we can do is just go in and modify that file so we will go into our code here and and uh we will go ahead and click into here go into staging and we'll just change what the branch is called so we'll just say staging and we'll hit start commit and we will save that and we'll see if it actually reflects those changes there so we will go here and hit refresh we'll see if it picks up staging now if we go to settings it's not picking it up so um I'm not sure I don't think perform a redeploy operation we don't want to redeploy so maybe what we'll do is just we'll have to do a disconnect here because it's collect it has the wrong one here so save workflow file um okay we'll just go ahead and delete it it's not a big deal we'll just have to make a new one here we'll go to GitHub we'll choose our uh organization again or repository our staging Branch this time around we'll let it add one see it says we use an available workflow so we could have kept it there and added it there um and we'll go ahead and save that so now we'll have two separate branches there and we'll give that some time to deploy because that will now trigger a deploy off the bat and so I'll see you back here in a moment all right so after a short little wait here it looks like our app is done deploying so we'll go over here we'll make sure that this is our staging server is good and we want to see that our production is different perfect so we now have a way to deploy to each one but imagine that we want to swap our traffic so we're happy with our staging server we want to roll that out to production and that's where we can uh do some swapping so what we'll do is click the swap button and we're going to say the source is the staging and this is our Target production and we're going to perform that swap uh right now we can't do a preview because we don't have a particular setting set that's okay and it's kind of showing if there are any changes so set of configuration changes we don't have any so that's totally fine as well we'll go ahead and hit Swap and that's going to swap those two I believe it's has has zero downtime so we will be in good shape if that happens there and we'll just give it a moment to do that great so after a short little wait there the swap is complete and so uh if you remember clearly this was our production right and so if I was to hit refresh it so now say Klingons and if I go to my staging server it should be the other way around right right good so now imagine that I want to just split the traffic uh that's something else that we can do um so notice over here we have these percentages here um not sure why it won't let me change those so maybe I'll have to look into that so I'll be back into so I'm not sure why it's not showing us that traffic slot there but what I'm going to do is just maybe try to trigger a deploy back into our staging and maybe that's what it wants to see um so what I'm going to do is go back to my code here we'll be in our staging Branch here I'm going to go ahead and uh edit this file here and we will just change this to borans and we will hit update and we will let that go ahead and deploy so if we go to actions here we can see that it is deploying um and we'll just give it some time okay so see you back here in a bit I mean the other reason could be that we're just not at the main level hold on here uh if we go back back here to deployment slots you know what I think it's just because I was clicked into here and then I was clicked into deployment slots that they're both gray out yeah it is so we can actually do that top level there doesn't hurt to do another deploy though so um we'll just wait for I'll wait for that deploy to finish and then we'll come here and uh adjust that there okay all right so let's take a look at uh doing some traffic switching here so right now we were to go to our production we have Klingons and if we were to uh go to our staging we have Boran so imagine that we only want 50% of that traffic to show up so what we can do is put in 50% and what I'm going to do is um do I hit enter here or oh sorry save up here there we go um and so what's going to happen is this should take effect I think right away yep uh and so now we have 50 50 50% chance of getting something else here um so I'm just going to keep on hitting enter here if that doesn't work we can try an incognito tab and there we go we got the opposite there and so this is serving up staging right uh and this is serving up production but they're both on the production URL so that's a way you can split the traffic so uh that's pretty much all I wanted to show you for deployment slots let's now talk about scaling all right so let's take a look into how we can uh do some scaling with our app service this is only available if you have Beyond standard and or standard and Beyond so standard and premium and Etc so if we just search for scale we have two options here we have scale up and scale out so scale up is pretty straightforward that just means to uh make our instance larger and so we already did that when we upgraded from our standard our our B1 over to our S1 here right so if I was to go here and I'm not going to do that but if I was to do that an upgrade um that would be scaling up right and notice that we're talking about scaling so right now we're limited to 10 instances which is totally fine but now let's take a look at scaling out so if we go to scale out here and go to Custom Auto scale what we can do is we can Scale based on a metric so we can add or remove servers based on the demand of the current um web applications traffic so we only paying for servers when we need them and so we have a minimum of one a maximum of two that seems fine to me but we're going to add a rule here and I want to scale this on um the maximum time we're going to do it on CPU uh percentage I just want to have a very easy way to trigger this so we can see a scaling event in action here it has a maximum of 16% I might just lower that down even further will it let me type in there no so 16% is what it's going to have to be it's not a big deal but I am going to reduce it down to actually I think sorry I don't know why I was going here the the metric threshold to scale an action I'm going to put it at 10% sorry okay so here's that line and so we have uh and I I like how you can drag it but you can kind of have an idea that we have a high chance of having this um trigger I just want to do this so that we have a a good chance so if I was to put it here you can notice that it's very easy for us to spike our traffic and and cause a scaling event now I'm going to set the duration to 1 minute so we have a much higher chance of uh triggering that there okay set a duration less than 5 minutes May generate uh transient spikes yeah that's fair but I mean I just want to show you a trigger happen and we need a cool down time probably um and it's set to 5 minutes that's totally fine we're going to add one and that looks fine to me I'm going to set this to maximum okay and so now we're very likely to trigger that there we'll go ahead and hit add that uh instance there and so now that we have that we're going to go ahead and save that and so now that that's there what we want to do is actually trigger a scaling event and so uh where we're going to see that is under the monitoring tab so if we go to monitoring and uh what we're going to do is go over to um it should be in sorry I forgot uh the place where we need to go take a look here is actually in the Run history here so if we go here and check 1 hour we can see how many instances are running uh and I think if I dial it back here it should show me over time as it changes we do have a scale up event that has happened which happened I guess four minutes ago um so I guess it gives you kind of an idea of how many instances are running which right now are two um so maybe our uh maybe our scaling event is not uh in the best uh use case there because it's happening too frequently so what I'm going to do is go ahead and modify that scaling rule um and so I'm just going to go back and click here and maybe we'll just make it so it is less aggressive so what I'm going to do is just change it so it's over the duration of five minutes and I'm going to just put it right above here so that it goes back to one okay and we'll go ahead and save that and so now if we go back to our run history here uh it still shows that it has um two as you can see here but I want to see this drop back down to one so it's going to check every 5 minutes or or within the span of 5 minutes so what I'm going to do is just uh wait here I'll see you back in a bit until we see a scaling action happens uh here okay yeah I'm just sitting here waiting for it to scale down and I don't see it going so it makes me think that I need to go ahead and set a scale uh scale down action let's take look at the one that we currently have uh so this one is set oh you can see it's still spiked we don't even have anything going on here but what I'm going to do is just be really aggressive here and I'm going to say when it's um 50% okay and so here we'll go back here and I'll save that and I just want to see if it scales down I shouldn't have to set a scale down action should just go Um and what I'm actually going to do is be a little bit more aggressive I know I'm setting a lot of stuff here but I'm going to just set it to duration of 1 minutes so we can see this a lot sooner and uh we will go back to our run history here and we'll see if we observe a scale down all right so um it's not scaling down here but uh I think it's probably because I need to scale out action so what we'll do is go ahead and add a new rule uh this thing if we go here and we just look at it um it's not going to decrease it unless we have a scale out action so I don't think it's necessary for us to set one here I think you get the idea um but that's for scaling so we're all done here with Azure app Services all we got to do is go ahead and go ahead and delete it so let's go ahead and delete our app here okay um so there's a few different ways we can do it I'm going to do it via resource groups um I believe we called it Voyager here so click into that and I'm going to go ahead and delete the resource Group and here is all the related services and so I will type in Voyager and there we go great and so yeah there we go hey this is Andrew Brown from exam Pro and we are looking at what is infrastructure as code and before we talk about that we need to talk about the problem with manual configuration so manually configuring your Cloud infrastructure allows you to easily start using new cloud service offerings to quickly prototype architectures however it comes with a few downsides so it's easy to misconfigure a service through human error it's hard to manage the expected state of the configuration for compliance it's hard to transfer configuration knowledge to other team members and so this is why uh infrastructure code is going to really help us out so um infrastructure is code commonly abbreviated to IAC and you'll see that a lot in this course allows you to write a configuration script to automate creating updating or destroying Cloud infrastructure notice I gave great emphasis on automate or aut ation because that is really key to um infrastructure's code I can also be thought of as a blueprint of your infrastructure I allows you to easily share version or inventory your Cloud infrastructure and just to kind of give you a visualization imagine you write a script and that's going to uh provision uh and uh launch a bunch of cloud services that are all interconnected okay hey this is Andrew Brown from exam Pro and we'll be going over Azure automation State configuration Azure automation State configuration lets you define and enforce the desired state of your Azure VMS uring consistency across multiple machines you can specify configuration details such as installed software Windows features registry settings and file contents so let's take a look at the example we have on the right configuration definition simple config the configuration named targeting the node MVM file creation ensures a file named hello.txt with the content hello azzure exists in the C drive Ure is equal to present by applying this configuration you ensure that any VM assigned to the MVM node will have the hello.txt file with the specified content this helps maintain a consistent and desired State across your Azure VMS so that's a quick overview of azure automation State configuration hey this is Andrew Brown from exam Pro and in this section we'll be covering Azure resource manager Azure resource manager is a service that allows you to manage Azure resources Azure resource manager is a collection of services in the Azure portal so you can't simply type in Azure resource manager in the search tab it is a management layer that allows you to create update or delete resources apply management features such as access controls locks or tags and write infrastructure is code using Json templates we will be examining the following key components that form the Azure resource manager layer we have subscription management groups resource groups resource providers resource locks Azure blueprints as well as resource tags Access Control role based access controls Azure policies and arm templates you can think of azure resource manager as a gatekeeper all of the requests flow through arm and it decides whether that requests can be performed on a resource such as the creation updating and deletion of a virtual machine and its arm's responsibility to authenticate and authorize these requests arm uses azure's rolebased Access Control to to determine whether a user has the necessary permissions to carry out a request when a request is made arm checks the users assigned roles and the permissions associated with those roles if the user has the necessary permissions the request is allowed otherwise it is denied the next concept we'll go over is the scope for Azure resource manager we've briefly covered scope in Azure policy and Azure rbac but we'll go into more detail with them in the following sections for arm so scope is a boundary of control for Azure resources it is a way to govern your resource by placing resources within a logical grouping and applying logical restrictions in the form of rules management groups are a logical grouping of multiple subscriptions subscriptions Grant you access to Azure Services based on a billing and support agreement resource groups are a logical grouping of multiple resources and resources can be a specific Azure service such as Azure VMS so that's an overview of azure resource manager hey this is Andrew Brown from exam Pro and in this segment we'll be diving into arm templates so what exactly is infrastructure is code infrastructure as code is the process of managing and provisioning computer data centers such as those in Azure using machine readable definition files like JSO n files rather than depending on physical Hardware configuration or interactive configuration tools you write a script that will set up cloud services for you there are two main approaches to IAC decare erative here you describe your desired outcome and the system figures out how to achieve it imperative here you provide Specific Instructions detailing exactly how to reach the desired State arm templates or JSO n files that Define Azure resources you want to provision and Azure Services you want to configure with arm templates you can ensure a declarative approach meaning you merely Define your intended setup and the system handles the rest build remove or share entire architectures in minutes reduce configuration mistake and know exactly what you have defined for a stack to establish an architecture Baseline for compliance or over arm templates Empower you to establish an architecture Baseline for compliance achieve modularity break up your architecture in multiple files and reuse them ensure extensibility add Powershell and Bash scripts to your templates test using the arm template toolkit preview changes before you create infrastructure via template see what it will create builtin validation will only deploy your temp templ if it passes track deployments keep track of changes to architecture over time policy is code apply Azure policies to ensure you remain compliant use Microsoft blueprints which Forge a connection between a resource and its template integrate with CI CD pipelines utilize exportable code letting you capture the current state of resource groups and individual resources and benefit from Advanced authoring tools for instance Visual Studio code offers sophisticated features tailored for crafting arm templates so as you can see arm templates has quite a lot of uses okay so now what I want to do is cover infrastructure as code for Azure so there are two uh primary ways of doing infrastructures code we have arm templates the arm stands for Azure resource manager and the other one is azure biceps we're going to focus on the first one infrastructure as a code is the concept of um uh defining all your infrastructure as code uh and that might be confusing because that might sound like s the SDK or the CLI and uh it is confusing until you start working with it but the key difference is that when you use the CLI or the SDK uh to programmatically create resources they don't keep uh track of the State uh and so that is the key difference between that whereas if you ran a CLI command to create uh let's say a virtual machine and you ran it again with the same parameters and the same name it would attempt to create a second um virtual machine whereas with infrastructure is a code if it's already there it's going to either update it or say hey you can't update it there's already one that exists so the idea is that um uh it's different in that process or in that sense uh there is a word for it um I believe the word is EP poent I always have a hard time saying it but um that is the key difference between those programming methods and IC so what I want to show you is uh arm templates and um arm again stands for Azure resource manager it's part of resource groups so if we type in arm here we're not going to really get uh a service or anything like that we say Azure or Azure resource manager okay you're just not going to uh exactly get that because um it is it is something that's there but it really is talking about resource groups so when you deploy a resour group it will always create an arm template for you no matter if you do click Ops um you'll always get an arm template and this is something that very different from other providers so like when you use ads or gcp um when you launch a resource it doesn't necessarily will produce a a template for you but Azure is very unique in that sense that they will do that so what I want to do is I want to go ahead and uh explore some things with arm templates so you're very aware of how they work and I believe that uh there is a way to uh deploy if we type in template here there should be something like deploy a custom template whoops and that's how you would go about deploying a custom template and they actually already have some common templates here so maybe we can uh take a look at one as a quick start and try to understand uh what these templates look like another key difference between other cloud service providers is that it's not very common to write arm templates by hand um in fact it's very tedious and you would not necessarily want to do it as opposed to ads where you have cloud formation totally normal to do and that's why um having a layer on top of uh arm makes it so much easier like using again Azure bicep or ter form but let's go ahead and create a Linux virtual machine here and notice that I select the template and it has some options here so um what I want to show you here this looks like the usual process for setting up a um a virtual machine but if we go here we can edit the template and then it's going to allow us to see what this template looks like so arm templates this is what it look looks like and I believe that uh they're only Jason I kind of forget Let's go ask chat GPT so are arm templates uh in Azure only Jason or can they also be yaml the reason why I I don't remember is because I work with a lot of cloud service providers usually they'll provide both options um but generally uh I always remember that arm templates are only Jason so there is no yaml support uh for it but of course you could use yaml locally and then convert it over back to Json but anyway so if we look at this here we have some things we have a schema that describes what the format of this Json should be um we have some metadata which probably gets autogenerated or is additional U information to attach the template we uh we have parameters so these are going to be values that we're inputting that allow us to uh make our template reusable and if we scroll on down um yeah we got variables which is probably um the modification of parameters and then we have our resources down below here and you know again if you've seen cloud formation templates or uh deployment manager gcp deployment uh scripts these are going to look very very similar so we we Define the type for the resource uh we have a name for it then it has its properties uh and then it can depend on other resources to say what order uh they're performed in but anyway my point is is that uh this is a template and and we can go ahead and actually uh deploy this template but I'm not that interested in that part of it because this is not that exciting what's more exciting is what happens when you do click offs so I'm going to go over uh over here and uh deploy a virtual machine um yeah I I mean we could do virtual machine I'm just trying to think what's easier maybe we'll go ahead and actually do I've changed my mind we're going to actually go ahead and do uh storage accounts again I'm still in the free tier and I'm just trying to make things easy for you as well um and virtu virtual machines will spin up a lot of resources so maybe I don't want something that complicated uh for this example but what I want to do is I want to launch a virtual uh a storage account and then I want to see how we can look at the template and maybe we'll attempt to rein import the template and then delete the storage account and recreate it so I'll go here and I'm going to hit create and we're going to create ourselves a new Resource Group I'm going to call this Resource Group um o uh my uh arm RG so arm for Azure resource manager and today it's really thinking I don't know if I'm having internet issues here or if it's just really complaining or if Azure is slow azure's uh sometimes their UI is not always responsive and we have to give this a name of course we have to make sure this is very unique so I'm going to say my um storage account a bunch of numbers and then my initials and it probably has too many letters so it's complaining there we go and I'll just let it choose whatever region wants we'll have it on standard that's totally fine I'm going to go ahead and go to review where we can see all of our options looks fine to me we'll go down the bottom hit create and we'll give it a moment here to create so I'll be back in just a second all right so that deployment is complete and what I'm interested in is checking out uh the resource Group but notice that when we've deployed this we have our inputs it shows us what we've inputed and we looked at the uh parameters of a template before so it is creating literally an arm template and then inputting the parameters it's showing this the outputs of uh that arm template and then here's the template itself so every time you deploy Azure resources it is creating uh these IAC code for you and that is one of the greatest advantages of azure as much as I complain about Azure this is one of their really really good features and there's a few things you could do like it looks like we can add this to our library we can download this we can deploy it again let's go ahead I usually don't uh fiddle with these too much but we can um import this template and I can say uh my Resource Group but just remember you could have a lot of resources and really make that uh uh ret templated I'm going to choose the same um area here and this will just be version 1.0.0 down here I'm going to go to next it shows me the template next uh we can do some tagging I'm going to ignore that for now review and create and so now we have our own uh template so that's kind of cool um if we go back to here I'm not exactly sure where they oh we have to hit create maybe first it's not super clear but uh so that is now uh template has been saved but where did it save to uh just says it's a template spec it is really taking its time to load here okay and so we have our template here I'm not sure if we if we typed in templates here if they up here they I guess they show up under template specs uh we'll refresh this not sure why it doesn't show up we know that we created it and you know I've said this in other videos where Azure doesn't always propagate things right away and you have to wait so you have to have confidence and waiting for things to show up in Azure so even though it's not here I know I created one okay so we go over here it says template uh spec succeeded so it really really I think it would show up here um and I I really want to prove that it will will show up here eventually so what I'm going to do is just take a break and I'm going to give it like 10 15 minutes I'm going to give it a good chunk of time here and we'll come back and see if it appears um just to give you validation and confidence that patience always uh pays off here in Azure okay all right so I've waited a good chunk of time was just talking to Bo and um so I'm now I'm back and let's see if it is here we're going to give a refresh and look it's here so I told you you got to be really really patient with Azure it is really known for being slow for uh some particular resources and I when I say some I mean a lot so you know just have that patience there but anyway what I want to do is I'm going to open up another tab we're going to go back over every time I open that new tab and wants me to log in that's great um but what I want to do is go over to our resource groups and we're going to go into that new one that we created and what I want to do is I just want to delete this resource here um and I want to see what happens if we attempt to redeploy our uh template there I assume we're going to have to I mean we don't have to delete this one but um I just want to move it completely and just try utilizing an arm template so we'll give it a moment there and oh notice we have an upgrade button this is uh definitely new we might be going through our not sure why it's appearing all of a sudden I've actually never seen that button before so it's really interesting and nope I guess it's just maybe after a while they just kind of poke you and over here we're getting our prompt so um it looks like we're starting to get some spend and you know I said earlier that Azure is really good about telling us about um alerts and things like that much better than other providers um and so you know here it's showing in Canadian dollars that uh we've already uh consumed half our spend not sure how I did that because I haven't really done a whole lot but um what we'll do is we'll try to figure out where that that uh free spend has been going um still again that's a lot um so maybe it's overestimating that or I left something running maybe that c cluster is still running I don't think so let's go double check and but anyway I wanted that to happen so I could go back and show a video of of that kind of stuff because all we created is a couple virtual machines and some other things yeah we don't have anything else running that should be costing us spend but we'll go take a look there and see what we can figure out so anyway I'm going to go back here give this a refresh and um that resource is gone what's interesting is it also got rid of the template why did I get rid of the template that that was something we created separately and so I guess it was linked to the resource Group and so that kind of defeats the purpose of us uploading our arm template so that's a shame um I guess what we could do is we could go and um I don't know uh we could go and use the custom provider and launch a template but there's not much interest in that so uh I'm not really interested in doing that yeah I think we're pretty much done here I think we've we' proved the point that Azure is really good at producing These Arm templates you're not going to want to write them by hand um you can ask CH PT to do it but I again I would probably not do that myself but I think that satisfies this video for arm templates so we'll see you in the next one okay all right so we looked at uh utilizing arm templates and I think it' also be really great to look at Azure bicep um because that is a more productive way to write infrastructure as code um and honestly I really like Azure bicep I think it's really really cool uh so what I want to do is I want to go ahead and go over back to GitHub we looked at creating a GitHub or creating a repo in GitHub uh back in our SDK video that was a really messy video I'm really hoping that it's not as crazy as that one but I don't like editing out any of the challenges uh here because I want to give you uh the full idea of of what it looks like when trying to work through these things but I'm going to do is go over to GitHub and you should of course go ahead and create yourself a GitHub account has a free tier uh and once you have your GitHub account we'll make a new repo I'm going to uh drop down uh here and go to exam Pro and of course you'll just have one name here if I have multiple accounts so there's a lot for me to create stuff in and what I'm going to do is make a new repo called um Azure bicep example you can call yours whatever you like I'm going to make this public so that you can see the code uh you can make yours priv private if uh private is available to you there but I going to make it public because if you want to go find this repo at exampro here and copy it and work with it you can so we're going to go ahead and use codes spaces and code spaces does have uh free credit usage you could do this locally um on your local computer but you'd have to install a bunch of stuff uh I like using Cloud developer environments and Azure does not have one built into their portal um most other ones do but I think the reason why Azure doesn't is because uh Microsoft owns GitHub and so you could just go over here and use code spaces instead so this to me is like using Azure okay so we're going to go ahead and create a uh code spaces on Main here and understand as long as the code space is running we are consuming uh so if you want to stop it you could always go up to the command pallet here and we can just say uh stop or uh it's code spaces it should be there should be something here called stop um shut down down I did this the other uh the other day when we did did that yeah it is code spaces oops it's loading so it's it's bumping things out here but if we go code spaces there is an option to stop the current Works uh code space so I'm not doing that right now uh I want my theme to be dark so I'm going to go to this Cog down here go to themes go to color and we'll switch to um GitHub dark and we'll give it a moment to think because it's a bit slower loading I greatly greatly prefer git pod the reason I'm using Code spaces is because um the extensions are going to use the official ones with Microsoft and it's just going to be easier to show you this here in most other courses I use git pod um so anyway once that is loaded and we uh changed our theme if that matters to you uh we're going to want to do some Azure bicep stuff so on the left hand side I want you to go to extensions and we're going to search Azure bicep I don't use Azure bicep a lot but I definitely know how to use it when we need to so I know they have a really good extension for it and it's like it writes code for you it was it's the nicest experience I've ever had with a um an I uh tool and this is the thing because Microsoft um built Visual Studio code and you know their they own GitHub they can have really amazing synergies for developers um so a lot of times I find it easier to work in vs code and use their extensions to interact with Azure than it is to use Azure portal itself and there are specific services like Azure functions where you really have to use Visual Studio code so it's it's essential that you get used to using uh Visual Studio code whether it's local or in a cloud developer environment so I'm installing that this Azure bicep um extension and this thing will help us write a lot of uh code um uh and it has like templates and other stuff like that so that's what I want to uh take advantage of it um I don't remember the extension for Azure bicep file so we'll just go to the Azure bicep website I'm sure they'll have like a quick start and we'll work through it here together so I want to go here and I just want to know what the extension is it's bicep so that's what it is so we're going to go here and make a new file we're going to call it main. bicep and something we didn't do before and this is what I wanted to do in the SDK one but we didn't actually have a use for it is there's probably like an Azure um like kit Azure tools there we go and this is something you all might want to install a lot of these down below here see how there's like one for databases resources functions if you install tools it installs all these other ones you even have one for C tools and um it's possible that uh yeah see like this this one will autocomplete Azure commands it'll do all sorts of fun stuff even for Azure storage and everything there's something but the reason we want Azure tools is because we can Azure accounts and this will allow us to quickly log in to our Azure account remember before we typed in a login and then we had to get a device code and plug that in uh well if we have this installed uh we can just use the command pallet and log in very quickly and that's what I want to do here so I'm going to go to the bottom left corner I'm going to pull up command pallet and we'll try to do Azure signin now to be fair I mean this is not going to do much difference down here but I think it installed the um the C for us before we had to manually install it right so we'll go here and we're going to have to choose device code we have signed into Azure Cloud let's try this one first see if that works and then we're going to say uh just so you know Azure has different ones there's like Azure China Azure Germany Azure US Government so generally we always want to choose Azure unless you live in one of these other regions and you have to use that one and this is going to open up and we will sign in we can now close this window and I believe we are now logged into Azure also notice on the left hand side we have this little Azure icon here in the left hand side it will allow us to see our resources we can also sign in from here we should be signed in maybe it didn't work I'll try this one more time extension as your resources wants to sign in we'll say allow maybe it has to sign in separately I don't know we'll close this there we are so now we see our subscription we are in here which is great and we can see a bunch of our services um so you know if we had storage accounts and we do have some storage accounts we can see them here this one I think is for our uh Cloud shell that's why it starts with cs and it has a random number afterwards if we had virtual machines and other things we could see them here but yeah working with functions you often use them here um we could also probably right click this and create a resource and so here there's a lot of ways to uh uh create some stuff we create a resource Group and and some other particular things but uh yeah that's that's interesting I also wonder if like these are these are obviously uh things that were installed there could be other extensions that we didn't install like Azure uh machine learning service or other stuff that could end up showing up there on the left hand side so I'm just kind of scrolling through here and seeing what might not be installed so Azure container apps was not installed or maybe it was and it's these other ones that have these little install words on here but anyway enough about that let's stay on track here and let's write some Azure biceps so now that we have uh that installed we want to start writing it so I just need to see a little bit of code to get a reminder here um so yeah if we start typing it should start suggesting and that's is what we want to do is make a storage account so let's go ahead and start typing that in so I'm going to type in resource uh and so already notice that it is autocom completing and then uh let's just go check here so the next thing is going to be storage account and it should autocomplete so yeah I remember this being really good at Auto completing just give me two seconds and let's go figure that out one sec yeah so I'm looking at it here and it's supposed to just start autocompleting when we type so I'm not sure why it's not exactly doing that we'll go back here sometimes Visual Studio code doesn't do what we want it to do which is totally fine storage account and it's not really autocomp completing so I'm going to go ahead and save this for a second well there it's autocom completing so resource storage am I typing it wrong is it supposed to be uh with the resources no no it's this so it's really interesting that it's not autoc completing but we could just copy this in here okay I just wanted to show you how powerful it was cuz I was so impressed the first time I I saw it uh writing all the code for me which is um not what the other ones do that's for sure so we'll just paste this in here and I put a period here yeah I guess I was expecting a little bit more from it um but uh whatever I guess we'd have to work with it a bit more to find out again I don't work with it every single day but I am always very excited to use it um but you know the thing that I want to uh take a look at is let's look at where the actual reference documentation is and so we'll go to Resource reference here on the left left hand side and I'm really interested to see uh where everything is so if you know the resource type you can just type it here in the left hand side that's fine so we have all our resources here on the left and so we are trying to create a storage account so we can go over here and look for storage account so that be storage and storage accounts and so here it says to create create a uh to create a resource add the following to your Azure bicep so um just kind of getting familiar with it it looks like this is going to be its logical name and this is actually going to define the resource itself and these are all its properties and it looks like there are some that are required and some that are not so it looks like I think that if we can find this tab back I think we can name this whatever we want here this doesn't actually have to be called storage account so we can go here it's just a logical name that we reference within this resource so I can go here and say like storage account AB it shouldn't matter um what's really interesting up here is that it's going to looks like it's going to grab the resource Group ID and then what does it do here creates a deterministic hash based on the string so it uses the resource ID to make a random string and then it's going to say toy launch in the front of it so I don't want toy launch I'm just going to put in here bicep and so um I think we can do hyphens actually I don't think we can and so we should get in Azure storage account that's going to be bicep and some random value after this and then up here this is going to pull in the resource Group now what's interesting is we haven't created a resource Group it says return the current Resource Group scope so I'm not sure how this is going to work if we don't have an existing Resource Group but anyway we've written our Azure bicep and we probably want to go ahead and uh deploy this now so we could probably just type in bicep down below that's probably what the command is nope that's not what it is um maybe it's what is it I don't know so let's go over to um back over here for a second and let's see what the CLI commands are oh boy we'll say bicep CLI what is the commands just tell me what the commands are please we could use the command pallet because they're probably all there like if we're if we were to go into the command pallet and type in bicep like we get all those commands but I I really want to know what the um CLI commands are I really thought it would be bicep it is a z bicep of course so looks like we can do um a bicep and then just specify the template probably main is the default so if we do nothing it probably will pick that up I'm going to go ahead and type in that and so it's interesting we installed the extension and we were able to log in but we still don't actually have uh the CLI so it looks like we do actually have to install the Azure CLI in here which is fine it's always great to get more practice so we'll go ahead and type in Azure CLI install we'll go to the Microsoft learn website we will scroll to uh Linux we'll go to auntu Debian um because that's generally what get pod or code spaces or what have you will be using we'll go down look for that one liner and we'll copy it we'll go back over to um code spaces we'll paste this in hit enter and that'll go ahead and install the uh Azure CLI now we are logged in in this um uh invidual Studio code and it could be storing the same credential files wherever on the local machine um so maybe we don't have to necessarily log in twice it might be also interesting to see where that um that file is so maybe we can go ask chat gbt where does um where does okay so when you log into the Azure CLI where does store the credentials what folder and file on the Linux machine that's what we want to know and uh the only thing I don't like about chbt is that you can't go away from uh this tab while it's generating and then sometimes it just uh gets a bit slow but it goes out to the Internet so I think that's the reason why it's uh been slower than previous I like previous mod models where it wasn't out on the internet because it could generate out faster but uh yeah this one's hanging on me so let's go to 3.5 let's just ask this one I want it fast okay so it's saying it's in the Azure folder so that's something that we might want to take a quick look at the Azure CLI is installed I'm going to just type in a um account um account list and see if we can list our accounts okay so we are not logged in so us logging in here uh wherever it's storing it's definitely not storing in the same place but let's go take a look at that Azure profile directory so I'm going to bump up the font a bit I realize it's really small and I'm going to go ahead and say CD and then make a Tilda that is above your tab key and you have to press shift to make it it's called a Tilda it's like a little squiggly we'll do a for slash I'm going to do period for a hidden folder and we're start start typing Azure and so that folder is there we'll hit enter I'm going to do LS to list out the contents and we have stuff here I can do LS hyphen LA to list it in a nice beautiful list and uh if we don't want no that looks fine and so I'm kind of interested where it's storing uh that configuration probably in the config directory so I'm going to just CD into config uh oh maybe it's not a folder I thought that was a folder it is not a folder Okay so let's do cat to print out the contents cat stands for C Cate I think and so that doesn't store it does a does the a Json file have it NOP that doesn't have it but to be fair we haven't logged in yet so maybe the file will appear after we log in so that's okay what I'm going to do is go ahead and type in a login and we'll say use device code because I believe that's the flag we have to use and we'll go ahead and copy this link we'll go to the top here and paste it in to one of our available tabs if we have to go back and uh provide this code and we'll go click next and we'll click on our account we'll say continue we'll go back over to here and we'll give it a moment to think there we go we are logged in so now what I want to do is type in LS and looks like there's more stuff there it looks like there is and did we have this before uh um let's see here 1 two 3 four five six seven 8 nine 10 1 two 3 four 5 6 7 8 9 10 11 12 yeah there's definitely more stuff here um the new thing that's here is Cloud's config so I'm just going to cat that let's see what's in there so Le tells us this is our default subscription so we at least know where that's coming from let's cat the config let's see if anything's Chang in there that's the same let's cat a Jason Json there's still nothing in there so it'd be really nice to know exactly where it is normally other ones will tell you exactly where they are uh and you can literally open them up and see see the information there I guess we could also just cat out the session no nothing so anyway it is stored somewhere where it is I don't know does it really matter no but it's nice to know exactly where it is so that uh let's say you wanted to delete it off your computer or something but it's stored somewhere where anyway um we are we should now be logged into Azure so we'll go ahead and type in Azure a bicep I still feel like it should have told us the commands even if we weren't logged in and I was hoping that it would print us out the sub commands let's try to do help and see if it actually does that okay so it does you just have to give it the help flag and so we have a few options we can do build a bicep file um build the bicep pramp file decompile so like we already have an arm template we could turn it back into a bicep file that sounds really cool I like that idea format a bicep file you know if there's something wrong with it it could tell us as the format's correct install uh the bicep CLI which I thought it already was installed let's go ahead and try that first because maybe that's why I couldn't just type in bicep okay so now what happens if I type in bicep no so why did I install it if it was already like that um bicep I'm hitting tab autocomplete to see if anything's there bicep CLI well whatever I mean we kind of still already have it so that's totally fine so we'll go ahead and type in bicep a uh uh a bicep build and it wants a file totally fine so we're going to give it a file U build the file build a file and print all of its outputs to SD out I don't think it matters if we print them out so before we do that I just did control C to uh break that we need to get back to our main folders I'm doing CD dot dot and I'm doing LS where is this folder CD for uh Aster for uh forward slash I'm so used to using git pod I can't remember where uh this directory is I'm just going to scroll up here and take a look it is workspaces okay so to get back to this folder okay we're going to go to cd/ workspaces I'm hitting tab to autocomplete and then this one's called Azure bicep um is really not autoc comp completing here today oh I spelled Azure wrong okay that explains that I'll go fix that in the um the git pod I'll just rename it but now we're back into here so um typing clear so we're going to go Azure bicep file and we're going to provide it main TF or I'm thinking terraform bicep we'll hit enter and so that's going to go ahead and build it um is misspelled or does not recognize is not recognized by the system um okay we'll type in LS I mean it's right there let's go back and and take a look at the documentation and see what it wants sometimes it might want um uh like the file information but I don't think so it just shows main bicep I'll copy this command oh I forgot the word build up here that's why so um it looks like it's now built and so we now have a main Json we'll take a look here and it's generated us an arm template at least that's what it looks like yep that's what it is so that looks pretty good um I'm noticing that yeah we have parameters up here so now we can go ahead and deploy this so builds it see here uh we can build our build pram file not interested in that generate prams and install the commands to your CLI oh publish maybe that's it the publish command adds a module to the registry the Azure container registry exists I'm not sure if that's useful I think that's if we want to reuse a template for later kind of like how we had those template specs I think okay so if as your bicep just generates out the files I'd imagine that we just probably deployed the regular way using arm templates so I'll be back in just a moment most other I tools like they'll let you build end deploy but maybe Azure bicep just compiles out templates just give me a moment yeah so I just quickly asked um chat gbt and yes it did confirm it I my suspicions were correct AZ your bicep is just draining out the resource template and it looks like we're going to have to deploy it the regular uh or oldfashioned way here um so now here's a question could we actually use um Visual Studio code to deploy this so if I right click this um could we deploy somewhere with this so that's what I'm really curious about let me go find all right so I believe there's a few ways we can do this of course we could go and just deploy the uh the fashion way by using this a deployment group um I was looking around myself and I just typed in bicep here and I also noticed that they had um uh a deploy step so maybe it can do a direct deploy not maybe not through the CLI but maybe it can do it through Visual St the code there should be one for arm templates in here it's not showing up I mean chat gbt seems to think that it can but maybe there is a another extension we're missing so let's type in uh azure so we have Azure tools is there one for developer um let's go back here and take a look so there's one here it says Azure resource manager oh it's an extens well I thought that'd be installed ready then that would be a really useful one to have here so we'll say Azure resource manager I thought it was there but I didn't see it on the side so this seems like a really good plugin this is probably something I'd want to have let's go ahead and install this one 1.5 million views yeah I believe so it's by Microsoft I'm surprised it doesn't get installed with the tools oh it's in preview okay so I imagine when this is out of preview I bet when you install Azure tools it will uh be installed there now I've said previously if there's a preview tool you should try to avoid it because it might not be there in the future um this one I think we can kind of get away with utilizing it it might be the future and it's no longer in preview so we'll go over back over to here and do we have any changes here no but if we go into our Command pallet let's type in arm deploy now it was saying that uh that something we could do aure resource manager uh install this extension type in arm deploy in our Command pallet did that yeah so it doesn't show up so you know preview feature uh chbt might be telling us something else we are using 3.5 so it might not be telling us the full truth there and I don't really see any changes on here so I guess we're not going to worry about that but I would like to try the um the bicep deploy so we'll type in just deploy here and scroll on down we we have deploy bicep file let's see what happens if we do that and so please enter the name of the deployment sure we have to name the deployment good um create a resource Group because remember that we didn't specify Resource Group so we'll have to create one on the Fly here so let's do that we'll call this my bicep RG RG for Resource Group it's now going to go ahead and deploy that it says deploy failed uh provider description does not have the resource type resource groups okay that is something I was not expecting let's go let's go ask Chacha BT and try to save us some time says check your bicep template file ensure that you have defined the resources correctly that is not useful um maybe it's because it's not registered so maybe when we use the CL uh when we use the the UI it will automatically register things when we use it but we create resource groups all the time so it's kind of surprising if that wouldn't be registered so we'll go over to our subscription and I'm just going to double check this here but I'm not sure if it's going to make a difference we'll go over to our yeah we're in our subscription I'm looking for providers there it is resource providers sometimes there's like another extra um blade they call these blades over here by the way and so I was getting a bit confused and so Chachi BT is suggesting maybe resources is not registered which to me seems crazy oh it is it's right there uh so I'm not exactly sure what it's complaining about the other thing is that maybe as your BP isn't logged in so I mean that seems like a possible option so maybe we'll just go stick with uh the usual way which is using the Azure um the this Azure deploy method so I'm going to scroll back up here and we have this command now we did install in here uh in extensions or I think it it came installed was the Azure CLI and what that will do is it when we write it out Azure CLI commands I believe it will autocomplete for us so here's scrapbooks for developing running commands with a CLI create an Azure CLI files and use the following features oh okay okay so there's actually a thing called an Azure CLI file that's new to me um but what we'll do is we'll go ahead and we'll just say um new file so we just say commands and I'll just put that there rename that like that that's what it's saying to do and so you'll say uh deploy an arm template and we'll go back over here and we'll see if it starts to autocomplete so we have a uh deploy it's not really completing correctly as just demonstrated we'll go back over here and take a look at that again so yeah this one says demo. asli they're making a comment so intellisense for commands and their arguments s and commands scrapbooks for uh developing running commands in the Azure CLI okay then work properly please maybe it's not installed oh we have to install it sorry I thought we already had it installed that's why so we'll go back over here and so now our common is showing up so we'll type a deployment um I mean we probably want to create right it will have to have a name so we'll just say my RG my bicep um deployment they'll probably have to have a location so let's just say probably should place it in the same place as this one this does not have a particular location so probably default to wherever the resource Group is yep so we say um it's East us there we go there's probably something else we need I'm not really sure let's go back and see what chat GPT was asking for uh the template of course um we'll say template and it technically is a file so we'll go here and say main J Json and by the way we could bring these down onto new lines with this backlash that allows us to have multiple lines in our bash terminal okay and it also probably wants the resource groups so we'll go here and type in resource it can't do multiline it is not autocomp completing anymore Resource Group maybe we just hit the limit of it there uh so I I assume that it could handle multiline but I guess when we're doing multiline then uh the Intel sense the auto completion is it can't handle it so we'll go back over to here and I just forgot what we called that Resource Group we actually did did create one uh but Azure bicep did fail the deploy because of some kind of permissions or settings so I just want to go quickly find that name again notice that sometimes in Azure you have to be patient super super super common uh to wait around for Azure um because of propagations in their UI super common my internet's totally fine it's it's Azure and it's back here says an error occurred when trying to fetch resources additional details from the underlying API might be help helpful are we having an issue with service so sometimes that happens so we could like uh Microsoft status page sometimes that happens and I got to walk away come back to my computer but uh maybe it's not because my internet seems to be funny so but if that's the case then oh yeah it's me I'll be back in a moment okay all right so uh my internet should be back here I'm just reopening my connection here to my code spaces and I'm going to go back over to here and we'll give it a refresh and so I guess that Resource Group did not create so we do definitely have to create a resource Group first otherwise it's not going to know what to deploy into and I'm hoping that this uh reconnects or it's still running so but uh what I'll do here while we're waiting is I'm going to create a new res group I'm going to call this one my bicep RG and we'll go ahead and review and create and we'll go ahead and create that we'll go back over to our other tab here I would really like it to reopen here I'm not sure what it's doing to figure this out going to go at the top just type in it seems real mucked up here so I'm G have to go back and we'll just have to type in bicep here it's under exam Pro so I'll drop that down of course you'll only have one so we'll go into here and let's see if I can find that that previously working code space environment so it's here it is active I'm going to go back and say open in the browser notice you can launch this IND Visual Studio code locally or if you want to use Jupiter Labs let's say you're doing something with a or something or machine learning you could do that so this should open back up our environment there we go that's great and um so we created that new Resource Group that's called this here so I'm going to go ahead and copy that and I'm going to paste it into here sometimes it's good to put double quotations around these things I'm not doing that unless that gives us problems so I think this is everything we need we need to know um the resource Group uh it's probably recommended to provide it a name we'll have our location and our template file so I'm going to go ahead and copy this and fingers cross this works uh of course we didn't really look anything up um oh this one says a deployment group create so maybe we should make sure that's correct but it did autocomplete create so maybe maybe that's okay well wait why is one deployment group wouldn't that create hold on we can hover over here and get some stuff manage the AER resource template uh deployment at the resource Group okay oh that's really cool if you hover over it tells you everything there well what happens if I take this name out then does this still complete starts a deployment at the subscription scope so maybe both both Works let's just see what happens it's really nice that it shows everything like that I really like that we'll go ahead and paste that in we'll hit enter and um it's showing we're missing an argument Resource Group argument it doesn't like that one starts a deployment creates a deployment the resource Group okay so here we have a create and then we have starts a deployment the subscription scope creates a deployment at the resource Group from a local file template so it looks like if we already have one maybe this one would have created a resource Group for us so what we're going to do is take this one out as I really thought we needed to have it but I'm going to go and see what happens if we do this the template resource location at line 12 uh line 17 is not is invalid the template function Resource Group is not expected at this location um okay it's it's not there I didn't put it in the template so okay well what I'm going to do is undo and type in group so I guess you got to be really careful when entering stuff in because it's going to give you some trouble and this one looks a little bit more normal with the group create so we have template file Resource Group I don't know if it needs a name so maybe I'll just take the name out and then we'll try this one and we'll hit enter and unrecognized arguments no location well I mean this one has it and this one doesn't okay we'll take the location out we'll try this well I guess we don't have to specify a location because we've already created the resource Group that's why so we'll try this again making a lot of trouble here but it's a good way to learn this is how you should learn and this is this is what Cloud's like just goofing around till get till we get it to work and then hopefully it's it's the right way um so this is going to go ahead and run and we'll wait here I'm not going to make you uh watch watch it here I'll be back uh here in a moment okay all right after a little bit of waiting um our terminal has produced some stuff for us so it's suggesting it probably created the resource so we're in good shape let's go back over to Azure and we're going to go into our bicep RG and we now have our resource so we've success successfully used um Azure biceps so let's go ahead and delete this Resource Group we are all done here um we're going to go ahead and commit what we have so that uh any future folks that are trying to do the same thing as us can just go get that code base uh good stuff here go ahead hit commit sync the changes we'll say okay that will push the changes excellent and I'm going to want to stop this workspace we'll open up the command pallet we'll say stop uh so say code spaces stop code spaces stop current workspace there we go and that will stop the current workspace so that is all good right there um and I'm going to fix the name here because it really should be named correctly so that you can easily find it in the future just be more patient and make sure you don't make mistakes and try to fix them the best you can but yeah that is azure bicep and we'll see you in the next one okay hey this is Andrew Brown from exam Pro in this segment we'll delve deep into Azure key Vault a pivotal tool to ensure the security of your Cloud applications and services Azure key helps you Safeguard cryptographic keys and other Secrets used by Cloud apps and services Azure key VA focuses on three things certificate management this feature allows for easy provision management and deployment of both public and private SSL certificates these certificates can be used with Azure and internally connected resources Key Management this enables the creation and control of encryption Keys used to encrypt your data Secrets management here you have a secure space to store and tightly control access to tokens passwords certificates API keys and other Secrets note that certificates contain a key pair which is a combination of a key and a secret this should not be confused with key management and secrets management which are distinct functionalities moving forward let's talk about hsms or Hardware security modules these are dedicated Hardware devices specifically designed to securely store encryption Keys when it comes to adhering to standards we reference the federal information processing standard or fips this is a guideline recognized by the US and Canadian government that specifies the security requirements for cryptographic modules that protect sensitive information in line with fips we have two levels of compliance for hsms fips 104 diminus 2 level two compliant this compliance level is for multitenant hsms where multiple customers are virtually isolated on a single HSM fips 104 minutus 2 level 3 compliant this level on the other hand pertains to single tenant hsms where One customer utilizes a dedicated HSM in essence as your key vault is an indispensable tool for ensuring that your cloud data remains both accessible and secure whether you're working with certificates encryption keys or various Secrets Azure key Vault has you covered all right let's dive into the core of azure key Vault The Vault itself a vault is where your secrets and keys reside safeguarded either by software or by hsms validated to the standards of fips 1004 toin 2 level two Azure key vaults provides two types of containers vaults these containers support both software and HSM back Keys HSM pools these are specialized containers solely for HSM back keys to activate your HSM you will need to provide a minimum of three RSA key pairs up to a maximum of 10 and specify the minimum number of keys required to decrypt the security domain called a quorum you do not choose the container on creation you just choose between standard and premium when you choose premium and create enough RSA key pairs you will begin to use a HSM pools diving a bit into technicalities Azure key Vault rest API is used for programmatically managing Azure key Vault resources allowing you to perform operations such as create a key or secret import a key or secret revoke a key or secret delete a key or secret authorize user or apps to access its keys or secrets and monitor and manage key usage Azure key Vault rest API supports three different types of authentication managed identities and identity managed by a a d recommended as best practice service principle and certificate this method uses a certificate for authentication Service principle and secret a combination of a user identity and a secret key one feature to note is the soft delete functionality soft delete allows you to recover or permanently delete a key vault in secrets for the duration of the retention period this feature is enabled by default on creation mandatory retention period prevents the permanent deletion of key vaults or Secrets prior to the retention period elaps furthermore enabling Purge protection safeguards your secrets from being prematurely purged either by users or by Microsoft bolstering the security of your Vault next up on our agenda is breaking down the pricing of azure key Vault knowing how your bill for this service can help you make informed decisions and optimize your costs Azure key Vault offers two pricing tiers standard and premium the notable distinction between the two is that while both tiers support software protected Keys only the premium tier allows for HSM protected Keys here's a closer look at the pricing tiers first 250 Keys regardless of whether you're on the standard or premium tier you'll be built $5 per key every month 25115 Keys the price drops to $2.50 per key monthly again consistent across both tiers 1501 to 4,000 Keys the cost further reduces to 90 cents for each key every month 4,000 1 plus keys for larger key volumes Beyond this point you'll be charged at a rate of 40 cents per key per month Secrets operations both tiers are priced at three cents for every 10,000 transactions involving Secrets certificate operations exclusive to the premium tier each certificate renewal request is build at $3 managed Azure storage account key rotation this service only available in the premium tier is priced at $1 per renewal HSM protected Keys specifically for HSM protected Keys the pricing is further broken down based on the key types for RSA 2048bit Keys the cost is $1 per key per month along with an additional charge of 3 cents per 10,000 transactions for RSA 3072 bit and 4096bit keys as well as ECC Keys the first 250 keys are priced at $5 per key per month so that's an overview of the pricing model for Azure key Vault the next topic we'll be covering is double encryption for Azure key Vault before we dive in let's quickly recap infrastructure encryption for storage accounts by default Azure ensures that your storage account data is encrypted when it's at rest infrastructure encryption adds a second layer of encryption to your storage accounts data now let's jump into Azure diss double encryption double encryption is precisely what it sounds like it's where two or more independent layers of encryption are enabled to protect against compromises of any one layer of encryption this strategy ensures that even if one encryption layer is compromised the data remains protected by the other Microsoft has a twolayered approach both for data at rest and data in transit for data at rest disk encryption this is achieved using customer managed keys and infrastructure encryption this uses platform managed Keys strengthening the base layer and for data in Transit Transit encryption using transport layer security 1.2 to safeguard data as it travels through networks and an additional layer of encryption provided at the infrastructure layer so that's a quick overview of double encryption for Azure key vault in this section we'll go into detail on the keys and Azure key Vault when it comes to creating a key in Azure you have three primary choices generate Azure will generate the key for you import import an existing RSA key that you already possess and restore backup restore a key from backup for Keys generated by Azure you can use either RSA or EC RSA or rivest shamier Adelman this supports key sizes of 2048 3072 and 4096 bits EC or elliptic curve cryptography here you can select from p256 P 384 p521 or p256 k for Keys generated by Azure you can set an activation and expiration date additionally you're not bound to a static version of a key you can create new versions of keys you can also download backups of keys but remember that backups can only be restored within the same Azure subscription and within Azure key Vault when you have a premium Vault you'll key options for HSM you can generate either an RSA or EC specifically for HSM or import an RSA key for HSM as shown in the example now let's talk about Key Management types Microsoft managed key or Keys managed by Microsoft they do not appear in your Vault and in most cases are used by default for many Azure services customer managed key are Keys you create in aure key Vault you need to select a key from a vault for various Services sometimes customer manage means that the customer has imported cryptographic material and any generated or imported keys are considered cmk and Azure in order to use a key an Azure service needs an identity established with an Azure ad for permission to access the key from The Vault Additionally you have the option to implement infrastructure encryption while Azure already encrypt storage account data at Rest by default opting for infrastructure encryption adds a second layer of security for ifying your storage accounts data even further the next topic we'll be covering our secrets in Azure key Vault Azure key Vault Secrets provide Secure Storage of generic Secrets such as passwords and database connection strings key Vault AP has accept and return secret values as strings internally key Vault stores and manages Secrets as sequences of octets with each secret having a maximum size of 25k bytes the key Vault service does doesn't provide semantics for Secrets it accepts the data encrypts it stores it and returns a secret identifier for highly sensitive data clients should consider additional layers of protection for data for example encrypting your data using a separate protection key before storing it in the key Vault heal also supports a content type field for Secrets allowing clients to specify the content type of a secret to assist in interpreting the secret data when it's retrieved note that the maximum length of this field is 255 characters every secret stored in your key vault is encrypted key vault encrypt Secrets at rest with a hierarchy of encryption Keys all keys in that hierarchy are protected by modules that are fips 104in 2 compliant the encryption Leaf key is unique to each key Vault while the root key is unique to the entire security world the protection level may vary between regions for example chid uses fips 1004 diminus 2 level one and all other regions use level two are higher diving into secret attributes we have X this is the expiration time after which the secret data should not be retrieved NBF not before default value is now this defines the time before which the secret data should not be retrieved enable this tells us whether the secret data can be retrieved or not with its default set to True additionally there are readon attributes for created an update in order to access Secrets within your application code you can would use the Azure SDK for example we have a net example in this image here another option is is to use tools like Azure CLI so that about covers the important details of secrets in Azure key Vault hey this is Andrew Brown from exam Pro and in this fall along we're going to be learning all about Azure Vault so let's get to it so what I want you to do is go on the top here and type in key Vault and here we'll have to go ahead and create ourselves a new Vault and so from there we're going to create a new Resource Group I'm going to call this Resource Group my example Vault and then we will make a vault key here so I'll say My Vault example which is kind of funny because this one's slightly different so you've seen I've done this before so I'm going to do my example vault as the name here and for the region Us East is fine for pricing we'll keep it at standard soft delete is enabled um and then there's the option for Purge protection so we are going to enable Purge protection and uh this is going to play into other follow alongs we'll explain that as it goes but Purge protection does not allow you to uh Purge things uh easily once it's enabled so what we'll do is go ahead and review and create and we'll go ahead and go review create and we'll give it a moment here and we'll just wait till it's done deploying okay all right so after a short little wait our vault is created and so what I want you is go to the resource and we're going to be using this Vault a little bit in some of the Fall alongs and in some cases not so much okay hey this is Andrew Brown and this fall along we're going to be doing some things with uh keys with an Azure key Vault so what I want you to do is make your way over to the Keys blade on the left hand side here we're going to generate or slimport a new key we're going to choose the generate option in terms of naming we're going to call this my dis key and we are going to choose RSA 2048 that seems totally fine to me everything else seems okay so we'll go ahead and create that key so we'll give it a moment to create doesn't take too long and then what we're going to do is go on the left hand side to I am access controls and what we're want going to want to do is add a new Ro assignment so we can go ahead and start using this uh key so what I want you to do is go and look for key Vault administrator which is here and we'll go ahead and hit next and then for our uh user we will choose ourself so under user I'm going to select the members I'm looking for the account I'm using there I am and your brown go ahead and select that there and so that is all we need to assign it so that we can actually uh work with that key so I think a good idea is to use a key uh to encrypt a disk so what we'll do is make our way over to dis encryption sets because before you can encrypt a dis you need to have an encryption set so we'll go ahead and create ourselves a new encryption set we'll call we'll use the uh sorry the same um resource Crypt so it's very easy cleanup afterwards we'll call this my disk encrypt set here and in terms of the encryption type we're going to use double encryption because that's much better you have two keys that encrypted so that's a lot better we are going to choose our vault so we have my example Vault there's only one option here and in terms of of the key we'll select my dis key terms of the version uh we'll select the current version we'll go ahead and hit review create and then we will go and create that and we'll give it a moment to create that encryption set shouldn't take too long here and after a short little wait uh our resource should be deployed only it took about a minute for me and if we go here it's going to have this message up here it's very small but it says to associate disk image snapshot this dis encryption set you must Grant permissions to key Vault so all we have to do is click that alert and will grant permissions and so now we are able uh to use that key um or like to to we're going to have the permissions issues is solve so what we'll do is go to type and create a new disk and so we can apply this key to that encryption so we go ahead and create we're going to choose the same Resource Group here I'm going to call this my example Vault and um or sorry my example uh dis so that's a little bit more clear than uh that and for the availability Zone doesn't matter for the source type um it doesn't matter as well in terms of the size we want this to be cheap we're not really using this for real so we'll use standard HDD and we'll say okay in terms of encryption this is where things get fun we go to double encryption we choose our key here we'll go ahead review and create and we'll just give it a moment for that to oh we'll hit create and we'll have to wait a little while here for that create that resource so we'll just wait until that is created okay and after a very short while the dis is ready so we'll go to that resource we'll go to the encryption tab to see that encryption is applied so that's all it takes to use a key to encrypt a disk so we are going to still use some of these accounts there's no clean up yet we go back here and I'll see you in the next one hey this is Andrew Brown and this fall along we're learn about backup and restore key so what I want you to do is go back into the uh Resource Group that we just recently created and we're going to make our way over to keys so I'm just or sorry we got to get into the Vault first then we'll go over to keys and the idea is that we have this key here and so um you can see that we have this current version so you can add additional versions but what's going to happen if we try to back this up so when you back this up you're going to get this file here and if you open up this file it's going to look like a bunch of gobbly goo so I'm just going to try to open it here um I have it up off screen here so I'm just trying to open it up within uh Visual Studio code so I'm just going to open up visual studio code again doing this offc screen here just give me a moment all right and so this is the file um that we encrypted uh and you take a look here and it's it's doesn't look like anything but the idea is that it is our backup of our key so that we can repport that and just taking a look at the key name this is what it looks like so it says my example Vault my dis key then there's this um uh date and that's key backup so just recognize that's the format and the date is very useful to indicate when you backed it up so let's go ahead and delete this key because the idea is we want to uh restore that backup and so we have deleted that key there and uh what we're going to do is we're going to attempt a Resto so I'm going to go ahead and go occurred while restoring the key the key you're trying to restore already exists why would it throw that error we've clearly deleted it and the reason why is that we have Purge protection on we did that in the um first uh first part when we set up this actual Vault here I'm going to just see if we can find the settings wherever that Purge protection is I'm trying to remember where it is Purge protection is enabled so we can go here and once you enable it you cannot turn it off it's going to retain it for a certain amount of days um and so all you can do is soft delete keys so this key is not actually delete yet if you go to manage deleted Keys you can see the key is over here and if you try to click on Purge it is disabled because we cannot remove the key because we have Purge protection on but we can recover the key so we'll go ahead and recover uh and so that will allow us to recover the key and if we refresh here it's going to take a little bit time for that key to restore so we'll just have to uh wait a little bit and then it will show up here's one other thing I wanted to show you was under policies because you know um if you go under where's policies here um or access policies if you look under our user here and we look at the key permissions um there is an option to purge and we don't actually have that uh turned on right now but if we were to save this and we were to still go to that Purge option it would still say the same thing so even if you have Purge permissions it does not matter if Purge protections turned on it still will not let you purge but you would need a combination of those in order to uh you know be able to do things there so to really show you how to do that recovery I think what we should do I'm just going to delete our old key here because we don't care about it but we are going to well I guess we could try to import it into the other ones I'm just going to undo that for a second but we are going to go ahead and create ourselves another Vault so I'm going to go and type in Vault at the top here and we're going to be a little bit more careful when we create this Vault so we'll go here and we will choose um my example Vault I'm going to say My Vault no protect and the pricing tier will be standard one day we're going to leave it or well seven is the lowest and we'll say disable Purge protection because we don't want to have that enabled and we'll see if we can import the key into another Vault I'm not sure if we can do that worst case we'll make a new key download the key reupload it but I'm just curious what would happen if we tried to upload the same key as it's still in another Vault I'm not exactly sure all right so this deployment is successful I'm going to go to this resource I'm going to go ahead to go to create and we're going to restore from backup and we're going to take this key and see if we can actually import it here so it looks like we can take a key and it can exist in multiple vaults I'm going to go ahead and delete this key and we're going to say are you sure you want to delete this key I'm going to say yes and if we go to manage Keys We refresh it takes a little bit of time here so we'll just wait a moment for this to uh prist and after a short little wait like about 2 minutes I refresh and the key is here so if I go here you'll notice the purges option is still not available we can obviously recover um but we don't have Purge um protection on so if we go to access policies over here and we'll go ahead and scroll down and select Purge and save our changes we can then go back to Keys we'll give it a moment to save we go back to Keys we'll refresh it we'll manage our keys and we'll go ahead and Purge it and that will permanently Purge it there so that's all it takes uh to do that so there you go hey Andre Brown and we are talking about encrypted Secret so encrypted secrets are variables that allow you to pass sensitive information to your GitHub action workflows secrets are access via the secrets context so that's secret St and then whatever you want your secret is and it has a few different levels we have the organizational level the repo level and the environment level what you need to understand is that the lower the level the more it overrides the ones from the top level so if you have a secret called hello at the organization level and one at the environment level called hello the one at the environment level value will overtake secret names can only contain alpha numeric characters underscores no spaces so that example there would be the the case you can't prefix it with GitHub in all caps with an underscore names must start with numbers sorry I felt like a rumble in my office and that's why I paused uh I think there was just a big train that went by anyway sorry about that um H there we go names are case insensitive names must be unique at the level they are created at people don't know I live right beside a train station and my office is in a shed uh behind my house and the idea is that I have multiple layers to avoid from the train but sometimes there's nothing you can do about it uh but anyway so we have passing Secrets as input so you can pass Secrets as inputs by using Secrets context so that is an example there um but I mean like the point is is that you know you could interpolate whatever you want there to pass it into a custom action and we'll talk about custom actions another video you can pass Secrets as Nars so that is another way that you could uh do that and why would you do um inputs versus Nars it just really depends on uh your use case so maybe you have something that is uh a program you're using and it can only use narss whereas uh with Secrets it's okay to do that on left hand side because of the the way it works but I just want to point out here we did this in another video but if you want to make that an Nar you'd have to map it like that I think we did that for something earlier but uh hopefully you know what that is so about how you set a secret so you can use the uh GitHub CLI so we have a GH secret set which is probably how we're going to do it then we have GH secret set for a specific environment or at the org level so depending on how you do a flag it's going to be different the default apparently is repository and you can also specify the repo which we have here you could do that up here as well if you want to uh but there you go hey this is Andrew Brown we are taking a look at the GitHub token secret so the start of each workflow job GitHub automatically creates a unique GitHub token secret to use in your workflow you can use the GitHub token to authenticate uh in the workflow job uh sounds a bit repetitive there but let's take a look here and see what we're talking about so I'm going get my pen tool out so it's very clear um and what I want you to see is that we can say secrets. GitHub token and we can get that GitHub token I also believe that we can do dollar sign GitHub token for uh environment variables and it will show up as well um if not we can just map it over as we are doing here if you notice here we're doing that um when you enable GitHub actions GitHub installs a GitHub app on your repository the GitHub token secret is a GitHub app installation access token so hopefully that is clear you can also use it with the rest API so here's another example and notice we are calling Secrets GitHub token with uh this way of interpolating that um so there you go hey this is Andrew Brown from exam Pro and in this section we'll be covering Azure monitor so Azure monitor is a comprehensive solution for collecting analyzing and acting on Telemetry from your cloud and on premises environments it serves as the backbone for gaining insight into the performance and health of your applications infrastructure and even the network he features visual dashboards A visual representation of your data smart alerts intelligent notifications based on specific conditions automated actions set automation based on certain triggers log monitoring track and analyze event logs many Azure Services by default are already sending Telemetry data to Azure monitor what is observability it's the ability to measure and understand how internal systems work in order to answer questions regarding performance tolerance security and faults with a system or application to obtain observability you need to use metrics logs and traces you have to use them together using them in isolation does not gain you observability metrics a number that is measured over a period of time for example if we measured the CPU usage and aggregated it over a period of time we could have an average CPU metric logs a text file where each line contains event data about what happened at a certain time traces a history of request that travels through multiple apps or services so we can pinpoint performance or failure look like they should have called it the Triforce of observability the sources of common monitoring data to populate data stores order by highest to lowest application operating system Azure resources Azure subscription Azure tenant custom sources the two fundamental data stores are metrics and logs Azure monitor functionalities insights this can be for applications containers VMS or other Monitoring Solutions visualize using dashboards views power RBI and workbooks you can create Rich visual presentations of your data Analyze This involves delving deep into metrics analytics and log analytics respond Based on data Azure monitor can alert you or even autoscale resources integrate extend the capabilities by using logic apps or export API for more flexibility overall Azure monitor is a comprehensive solution vital for ensuring that your applications and services run optimally and any issues are detected and dealt with properly the next topic we'll be covering are the various sources from which Azure monitor collects data application code Azure monitors application insights offers robust metrics about the performance and functionality of your applications and code you'll get performance traces application logs and even user Telemetry you'll need to install instrumentation package in your application to collect data for application insights availability tests measure your application's responsiveness from different locations on the public internet this helps in assessing the reliability and uptime of your services nric descriptive data regarding your applications performance operation and custom metrics log store operational data about your application including page views application requests exceptions and traces you can send application data to Azure storage for archiving view the details of availability test stored and debug snapshot data that is captured for a subset of exceptions is stored in Azure storage log analytics agent is installed for comprehensive monitoring dependency agent collects discovered data about processes running on the virtual machine and external process dependencies agents can be installed on the OS for VMS running in Azure on premises or other Cloud providers Diagnostics extension collect performance counters and store them in metrics application insights logs collect logs and performance counters from the compute resources supporting your application allowing them to be analyzed alongside other application data the Azure Diagnostics extension always writes to an Azure storage account while Azure monitor for VMS uses the log analytics agent to store Health State information in a custom location the Diagnostics extension can also stream data to other locations using aent hubs resource logs provide insights into the internal operation of an Azure resource and are automatically created however you must create a diagnostic setting to specify a destination for each resource platform metrics will write to the Azure monitor metrics database with no configuration you can access platform metrics from metrics Explorer for trending and other analyzes use log analytics copy platform metrics to logs send resource logs to Azure storage for archiving stream metrics to other locations using aent hubs Azure subscription this includes Telemetry related to the health and operation of your Azure subscription Azure service Health provides information about the health of the Azure services and your subscription that your application and resources rely on Telemetry related to your Azure tenant is collected from tenant wide services such as Azure active directory Azure active directory reporting contains the history of sign and activity and audit trail of changes made within a particular tenant for resources that cannot be monitored using the other data sources write this data to either metrics or logs using an Azure monitor API this will allow you to collect log data from any rest client and store it in log analytics in the Azure monitor metrics database Azure monitor is integral to maintaining the health and performance of your applications and resources collecting two fundamental types of data logs and metrics Azure monitor logs collects and organizes log in performance data from a variety of monitored resources data consolidation logs can be pulled from diverse sources such as platform logs from Azure services log and performance data from Agents on Virtual machines and usage and performance data from applications workspaces all these logs are organized into workspaces providing a centralized repository for indepth analysis query language Azure monitor logs offers a sophisticated query language which can quickly analyze millions of Records making it an ideal choice for complex data analytics log analytics you can interactively work with log queries and their results using azure's log Analytics tool in contrast Azure monitor metrics collects numeric data and organizes it into a Time series database here's why that's important numeric dat data metrics are numerical values captured at regular intervals they are a snapshot that describes a particular aspect of a system at a specific Moment In Time lightweight metrics are designed to be lightweight allowing for near realtime data analysis this makes them particularly useful for alerting and the rapid detection of issues metrics Explorer the metrics Explorer tool allows for interactive analysis of metric data providing a more immediate understanding of your system's performance and health the next topic we'll cover are the data retention and archive policies of azure monitor logs this is an important aspect of your monitoring strategy as it allows you to control how long your data remains stored and accessible by default in the Azure portal you can set this retention time anywhere from 30 to 730 days for the whole workspace if you want you can also specify different storage durations for certain tables within your workspace letting you manage different types of data as needed this gives you the flexibility to meet any business or regulatory rules about data storage however note that to tweak these retention settings you have to be on the PID tier of azure monitor logs to set retention and archive policy by table why navigate to the Azure portal and go to the log analytics workspace where the data is stored two under the settings section select usage and estimated cost three then select data retention for in the data retention blade you can modify the retention period for each table by default fault it is set to 31 days but you can extend it up to 730 days five for archiving data you can use Azure data Explorer which lets you retain data beyond the 2year limit and gives you a highly scalable analytic service so that's an overview of the data retention and archive policies of azure monitor logs you'll most likely encounter a question related to this on the exam so be sure to know this hey this is Andrew Brown from exam Pro and in this section we'll be covering Azure log analytics so log analytics is a tool in the Azure portal used to edit and run log queries with data in Azure monitor logs log analytics processes data from various sources and transforms it into actionable insights it ingests data from Azure monitor windows and Linux agents Azure services and other sources once the data is collected you can use log analytics query language to retrieve consolidate and analyze the data log analytics uses a query language kql now we'll go over some of the benefits of log analytics centralized log management collect and analyze data from multiple sources both on premises and in the cloud in a centralized location powerful analytics utilize the custo query language to run Advanced analytics on large amounts of fast streaming data in real time custom dashboards create custom dashboards and visualizations to display real time data and Trends integration seamless integration with other Azure services and Microsoft solution Solutions such as powerbi and Azure Automation and alerting set up alerts based on specific criteria to proactively identify and respond to potential issues before they affect your users log analytics workspace is a unique environment for Azure monitor log data each workspace has its own data repository and configuration and data sources and solutions are configured to store their data in a particular workspace so that's an overview of azure log Analytics the log analytics agent is a lightweight agent that can be installed on Windows and Linux machines to collect and send log data to Azure monitor it provides a way to centralize logs from various sources and enables the analysis of the data using tools like Azure monitor logs Azure dashboards and Azure monitor workbooks the agent can collect logs from various sources including Windows event logs custom logs performance counters and CIS log it supports both agentbased and agentless data collection ction and can be configured to collect data from on premises and cloudbased environments the log analytics agent is set up to monitor certain Windows event logs like security system or application logs the data from these logs is then gathered and sent to log analytics for analysis using queries and visualizations the log analytics agent is set up to monitor CIS log servers or network devices it collects data from these sources and sends it to log analytics allowing for detailed analysis and troubleshooting both methods for colle cting log data allow for centralized management and Analysis of log data from multiple sources which can help to improve visibility and streamline troubleshooting and issue resolution you can expect to see a question related to log analytics agents and choosing either Windows event logs for a Windows agent or CIS loock for Linux agent on the exam the next topic will be covering our application insights application insights is an application performance Management Service and it's a subservice of azure monitor APM is all about the monitoring and management of performance and availability of software apps it strives to detect and diagnose complex application performance problems to maintain an expected level of service so why use application insights automatic detection of performance anomalies application insights automatically identifies performance anomalies in your system powerful analytics tools it comes with robust analytics tools to help you diagnose issues and understand what users do with your app continuous Improvement it is designed to help you continuously improve performance and usability of your applications platform agnostic it works for apps on net node.js Java and python hosted on premises hybrid or any public Cloud devops integration it can be integrated into your devops process and mobile app monitoring it can monitor and analyze Telemetry from mobile apps by integrating with visual studio app center to use application insights you need to instrument your application this involves installing the instrument package or enabling application insights using the application insights agents were supported there are many ways to view your Telemetry data apps can be instrumented from anywhere when you set up application insights monitoring for your web app you create an application insights resource in Microsoft Azure you open this resource in the Azure portal in order to see and analyze the Telemetry collected from your app the resource is identified by an instrumentation key what does application insights monitor request rates response times and failure rates dependency rates response times and failure rates exceptions page views and low performance aex calls user and session counts performance counters post Diagnostics diagnostic Trace logs and custom events and metrics where do I see my Telemetry smart detection and manual alerts application map profiler usage analysis diagnostic search for in data metric Explorer for aurated data dashboards live stream metrics analytics Visual Studio ET overall application insights is a comprehensive APM service that offers automatic detection of performance anomalies powerful analytics tools and is designed to help you continuously improve performance and usability in this segment we'll delve into the topic of application insights instrumentation so what is instrumentation in simple terms it's a way to make your application smarter by adding a few lines of code or in some cases none at all you can monitor how your app performs and where it might be running into issues you instrument your application by adding the Azure application insights SDK and implementing traces in the case of a node.js application you can install the Azure application insights SDK using mpm with the following command and PM install application insights hyphen save application insights this is the name of the package you are installing which is azure SDK for application insights pyth and save this flag saves the package as a dependency in your package.json n file here this piece of code lets you configure what you want to collect Azure supports the following languages net Java python node.js JavaScript Auto instrumentation allows you to enable application monitoring with application insights without changing your code this table shows which Azure Services support application ins sites and in what programming languages the services range from Azure app service on Windows and Linux to Azure functions Azure spring Cloud Azure kubernetes service and more GA General availability meaning it's fully supported and ready to use public preview still being tested but you can use it not supported you can't use application insights here through agent you need to install a special piece of software to use this service o NBD on by default meaning the feature is automatically enabled through extension available but needs an extension to work we won't go through the entire table but we'll give a few examples for applications written in.net and hosted on Azure app service on Windows application insights is generally available and enabled by default for applications written in Python and hosted on Azure functions application insights is available and enabled by default but for dependencies monitoring you will need to use an extension so that's an overview of application insights instrumentation hey this is Andrew Brown from exampro and in this section we'll be covering Microsoft Sentinel formerly known as Azure Sentinel Microsoft Sentinel is a scalable Cloud native solution that encompasses two key functionalities security information event management this is all about collecting and analyzing security related data to provide realtime analysis of security alerts generated by applications and network Hardware security orchestration automated response this refers to the collection of tools that enable an organization to Define standardize measure and automate responses to security events Microsoft Sentinel delivers intelligent security analytics and threat intelligence across the Enterprise providing a single solution for alert detection threat visibility proactive hunting and threat response with Microsoft Sentinel you can collect data Cloud scale across all users devices applications and infrastructure both on premises and in multiple cloud clouds detect previously undetected threats and minimize false positives using Microsoft's analytics and unparalleled threat intelligence investigate threats with artificial intelligence and hunt for suspicious activities at scale tapping into years of cyber security work at Microsoft respond to incidents rapidly with builtin orchestration in automation of common tasks Microsoft Sentinel comes with a number of connectors for Microsoft Solutions such as Microsoft 365 defender office 3 365 Azure ad or Microsoft enter ID Microsoft Defender for identity and Microsoft Defender for cloud apps you can use common event formats CIS logit rest API Windows event logs common event format and trusted automated the exchange of indicator information one notable feature of Microsoft Sentinel is the ability to create Azure monitor workbooks workbooks provide a flexible canvas for data analysis and the creation of rich visual reports within the Azure portal they allow you to tap into multiple data sources from across Azure and combine them into unified interactive experiences it tells a story about the performance and availability about your applications and services workbooks are temporary workspaces to define a document like format with visualization intertwined to help investigate and discuss performance Microsoft Sentinel uses analytics to correlate alerts into incidents incidents are groups of related alerts that together create an actionable possible threat that you can investigate and resolve Microsoft Sentinels Automation and orchestration solution provides a highly extensible architecture that enables scalable automation as new technologies and threats emerge built on the foundation of azure logic apps includes 200 plus connectors for services Microsoft Sentinel also offers deep investigation tools that help you to understand the scope and find the root cause of a potential security threat you can choose an entity on the interactive graph to ask interest in questions for a specific entity and drill down into that entity and its connections to get to the root cause of the threat additionally Microsoft Sentinels powerful hunting search and query tools based on the miter framework enable you to proactively hunt for security threats across your organization's data sources before an alert is triggered after you discover which hunting query provides high value insights into possible attacks you can also create custom detection rules based on your query and service those insights as alerts to your security incident responders while hunting you can create bookmarks for interesting events enabling you to return to them later share them with others and group them with other correlating events to create a compelling incident for investigation lastly let's talk about pricing Microsoft Sentinel has two different pricing models capacity reservations this involves being build a fixed fee base on the selected tier enabling a predictable total cost for Microsoft Sentinal pay as you go with this option Bill per gigabyte for the volume of data ingested for analysis in Microsoft Sentinel and stored in the Azure monitor log analytics workspace and there you have it a comprehensive look at Microsoft Sentinel a robust seam and Source solution that can help protect your organization's infrastructure applications and data let's take a closer look at custo and it's query language so Azure monor logs is based off of the Azure data Explorer and Along came with it is the custo query language also known as kql and this is the way we're going to uh filter and uh sort and do things with our logs so custo is based on a relational database management system and it supports entities such as database tables and columns as also has this thing called clusters and uh kql actually has a lot of utility in Azure because it's not just in monitor logs and data Explorer you can use it in log analytics log alert rules workbooks dashboards logic apps Powershell Azure monitor log API so it's definitely something you're going to be using across the board in Azure and so they have some basic operators um uh or they have lots of operators that you can use so you can do calculated columns searching and filterings on rows Group by agates join functions and we're going to be looking at a lot of the operators in more detail after this slide here uh but anyway uh the queries execute in the context of a custo database that is attached to a custo cluster and we will we'll talk about clusters database tables and columns up next let's take a look at what makes up um something for custo and so we have a bunch of entities here clusters database tables columns and functions and so I have this nice visual to help us uh kind of see how they all work together so at the top we have clusters and these are entities that hold multiple databases you can also have multiple clusters um but it's just not being shown there in that graphic then you have the databases themselves these are named entities that hold tables and store functions you have tables these are named entities that hold data and a table has an ordered set of columns and zero or more rows of data each row holding one data value for each of the columns of the table then there are the columns themselves and these are named identities that have a scalar data type columns are referen in the query relative to the tabular data stream and that is the context of the specific op operator referencing them then we have stored functions and these are named entities that allow reuse of custo queries or query Parts uh and then you got these external tables and these are tables that uh live outside of your cluster uh I think that they're uh you're referencing them from uh storage accounts and they're in Blob storage so they I think they could be like CSV files and stuff like that but these external tables are used for exporting data from custo to external storage so storage uh storage accounts as for quering external data without ingesting it actually into custo so hopefully that gives you an idea the lay of the Land There
