With timestamps:

00:00 - one practical use case for artificial
00:02 - intelligence is healthcare imaging if
00:04 - you're interested in the fields of
00:05 - machine learning or artificial
00:07 - intelligence this is a great course for
00:09 - you mohammed who is a computer vision
00:11 - phd student will teach you how to use
00:14 - pytorch and monae for automatic liver
00:16 - segmentation my name is mustard amin i
00:19 - am a research assistant and phd student
00:22 - in computer vision today i am presenting
00:25 - to you my course about liver
00:27 - segmentation using monae and pytorch
00:31 - by this course we'll start by defining
00:34 - what is unit
00:35 - then we will talk about how to prepare
00:38 - our data
00:40 - we'll start by downloading them
00:41 - preparing them and doing the pre-process
00:44 - then as i told you during the
00:46 - pre-processing to data and applying all
00:48 - the transforms that we need to do for
00:50 - medical imaging using monae
00:53 - then we will talk about all the
00:55 - installations that we need to do from
00:57 - one eye by torch cuda dnn etc etc so
01:01 - we'll talk about all the packages that
01:02 - we need from the python packages into
01:05 - the other softwares okay
01:07 - then we will talk about what are the
01:09 - common problems or errors that you may
01:12 - face using one eye for medical imaging
01:14 - of course
01:16 - then we'll talk about the training part
01:18 - which which script that we will use how
01:21 - does it work extra etc
01:23 - then after that we will talk about the
01:25 - testing parts after finishing the
01:27 - training we will analyze our data not
01:29 - data but we will analyze our model and
01:32 - we will pass some testing
01:34 - passions and see what our model is
01:37 - giving us if it is going great or not
01:39 - and i will give you some advices how to
01:42 - fix or how to make your accuracy better
01:44 - if it doesn't
01:46 - go go well at the end
01:48 - and after that at the end i will show
01:51 - you how you can just clone the github
01:52 - repository if you understand everything
01:55 - i will say in this course you can just
01:58 - clone the github repository and try
02:00 - using the scripts so i will show you how
02:02 - you can clone it how to install the
02:04 - different packages and how to use all
02:06 - the scripts that i am providing you in
02:09 - this github repository
02:14 - a little bit about unit so unite is a
02:17 - deep learning architecture for semantic
02:19 - segmentation it was created first for
02:23 - biomedical imaging so when you if you
02:25 - are interested you can read the uh
02:28 - the
02:29 - uh paper so in their paper you will see
02:31 - that this architect architecture was
02:34 - created for biomedical imaging and
02:36 - because it is a great architecture and
02:38 - it has a good accuracy they started
02:40 - using it for the other image
02:42 - segmentation tasks so now let's talk a
02:44 - little bit about something else and
02:46 - we'll go back to the architecture after
02:48 - now maybe some of you die doesn't know
02:51 - what is the difference between image
02:52 - classification object detection or image
02:56 - segmentation
02:57 - so the image classification as you can
02:59 - see it is what is the easiest task in
03:02 - deep learning so image segmentation
03:05 - means the image classification sorry
03:07 - means that if you have an object in an
03:09 - image so you just need to know if there
03:12 - is no there is that specific object in
03:14 - the image or not so in this case we have
03:16 - a cat in the image so the output of your
03:20 - model or classification model will be a
03:23 - problem probability that means that you
03:26 - have a cat or not with a probability
03:28 - from zero to one
03:30 - more closer to one means that this
03:32 - object exists in the image but that's
03:35 - all what you need to do this object
03:37 - exists or not
03:39 - then there is the object detection which
03:41 - means that you need to create or to draw
03:44 - a bounded box in the image or localize
03:47 - the objects in the image not only saying
03:50 - that this image contains a cat but you
03:53 - need to draw a bonding box which means
03:55 - we need to localize it in the image so
03:57 - this is the object detection
03:59 - then the image segmentation
04:02 - means that you need to draw a mask in
04:05 - the image to refer to all the pixels
04:08 - that has
04:09 - that have the
04:11 - same
04:12 - object so in our case we need to specify
04:15 - which pixels
04:16 - have the uh the object which is the cat
04:20 - so in that in this case we need to draw
04:23 - all this mask to refer to the cut in the
04:26 - image so this is the image segmentation
04:29 - then in the ms segmentation there are
04:32 - two types that is
04:34 - here the first type is the
04:37 - image segmentation which is semantic
04:39 - segmentation and the second one is the
04:41 - instance segmentation
04:43 - now here in the left you can see this is
04:45 - the in semantic segmentation means that
04:48 - you need only two segments how many
04:51 - classes you have which means here we
04:53 - have only two classes we have the class
04:56 - person here and the class background so
04:59 - that's all what you need to do in
05:00 - instance instant segmentation you don't
05:03 - care about how many people you have or
05:05 - how many other objects you have in your
05:07 - image you don't you don't care about
05:09 - that you need only two segments
05:12 - the classes that you have here we have
05:14 - class person class background but in the
05:17 - instance segmentation
05:19 - don't only you need to create to segment
05:21 - the classes but you need to specify how
05:24 - many uh
05:26 - objects or how many people here we have
05:28 - in that image so in this case we have
05:30 - person one two three
05:32 - and so far which means that you need to
05:34 - segment the person and say this is a
05:36 - person one this is person two etc etc so
05:40 - if you have two three or more than that
05:43 - classes so and in each class you have
05:46 - more than one object in the image so you
05:48 - need to specify this is the object one
05:50 - from the class x this is the
05:53 - object two from the class from the same
05:56 - class which is class x etc etc so unit
05:59 - is an architecture to do semantic
06:00 - segmentation which means it will do only
06:03 - this type of segmentation it doesn't do
06:06 - this type you can see faster mask
06:09 - mask faster cnn to do instant
06:11 - segmentation but you net you can use it
06:13 - only for
06:15 - semantic segmentation and that's all
06:17 - what we need in our project we need to
06:19 - do a
06:20 - liver segmentation so we need to know
06:22 - what is the liver and what is the other
06:23 - part of the body which is the background
06:25 - so we don't need to have there is no two
06:28 - levels in the same person or something
06:29 - like that so that's all what we need
06:32 - segment the liver and the background so
06:34 - we will for that we will use a unit here
06:38 - now let's talk a little bit about the
06:39 - architecture the architecture is in the
06:41 - shape u for that it is called unit for
06:44 - this shape okay now units you need to
06:47 - know that unix is one of the easiest
06:49 - architectures in deep learning there is
06:51 - nothing hidden or there is nothing
06:53 - difficult on it you can see that there
06:54 - is only or there are only convolution
06:58 - layers and followed by a max pooling
07:01 - convolution layers max pooling
07:03 - convolution layers max pooling and here
07:05 - it will do up convolutions and max
07:07 - pulling up convolutions etc but why
07:11 - they are doing this because unit is
07:14 - divided into two parts there is first
07:16 - part called the encoder which is this
07:19 - one here the down we can we can we can
07:22 - call it the down blocks or the down part
07:24 - here for us which is called the encoder
07:26 - so we don't care about the names but
07:29 - this part here is going down which is
07:31 - the encoder so if you if you look
07:34 - clearly to this part it is looking like
07:36 - a normal image classification
07:39 - architecture okay there is nothing new
07:42 - that is only here
07:44 - convolution blocks because this one is
07:46 - called the convolution block but it is
07:48 - convolution layered followed by max
07:50 - pooling convolution layers max pooling
07:52 - and each output of these these
07:54 - convolution blocks there is a real
07:56 - function so
07:58 - if you understand what is happening here
08:00 - you can see that this is a normal image
08:03 - classification architecture
08:05 - and here this is the final output that
08:07 - we can put it we can pass it by a
08:09 - softmax layer or something to see the
08:11 - output but this is not what we need here
08:14 - we said that our output that we need we
08:17 - need it to be a mask with the same width
08:19 - and height of the input image so that we
08:22 - can specify specify each pixel
08:25 - uh and its class which means pixel one
08:28 - goes to class zero or class background
08:30 - or class
08:31 - lever or something like that for that we
08:33 - need to do this part which is called the
08:36 - decoder so this decoder we take the
08:38 - feature that we have extracted in this
08:41 - encoder part and use them here to build
08:44 - the output image so that you will have
08:47 - each pixel instead of having only one
08:50 - pro
08:51 - one probability for all the image no you
08:54 - will have a probability for each pixel
08:57 - so that you can classify each pixel how
08:59 - many uh
09:00 - uh to which class it goes for us we call
09:03 - this pixel probability not a normal
09:06 - image probability or something like that
09:08 - now let's take an example about how does
09:10 - the output of unit look like
09:13 - here is for example this is one or this
09:15 - is the output that i used for my project
09:17 - which was the tumor segmentation in the
09:20 - whole body
09:21 - so i took just this example to show you
09:23 - how does it look
09:24 - now this is the input mask which is the
09:27 - label or the ground rules you can call
09:29 - it as you like so this is the input mask
09:32 - i didn't have the time not time but i
09:34 - didn't have the space to put the image
09:36 - as well but i think this is enough to
09:37 - see so this is the mask that you have
09:40 - now
09:41 - these are the two outputs of not it is
09:45 - one output with two channels of
09:47 - the unis so if you have this output here
09:50 - or this output channels differs from how
09:53 - many classes you have so if you have two
09:56 - classes so you will have two channels
09:58 - you have three classes you will have
10:00 - three channels etc etc each channel will
10:03 - have the pixel probability for a
10:05 - specific class so in my case i had two
10:08 - channels the background
10:10 - two classes sorry the background class
10:13 - and the foreground class which has the
10:15 - tumor and in our project here we will
10:17 - have two
10:18 - classes the first class is the
10:20 - background the second class will be the
10:22 - level so this was the my outputs this is
10:25 - one of my
10:26 - passions
10:28 - so these are
10:29 - these are the channels for one output
10:33 - this one refers this is the output zero
10:35 - this is out this is the channel zero
10:37 - this is the channel one so this one
10:39 - refers to the background and this one
10:41 - refers to the foreground which is the
10:43 - tumor
10:45 - now the values that you see here more
10:48 - value more the color closer to the
10:51 - yellow means that the value of these
10:53 - pixels here is closer to the value one
10:57 - which because we said we have pixel
10:59 - probabilities which means differs from
11:01 - zero to one so more we have the value
11:04 - yellow more we have the uh
11:06 - the
11:07 - that's pixel goes to the class zero
11:09 - which is the class background and more
11:12 - the value goes to the purple here means
11:15 - that the value is closer to zero so if
11:18 - the value is closer to zero so means
11:20 - that these pixels doesn't go to the
11:22 - class zero which is the class background
11:25 - and here same thing for this part but
11:28 - this channel is the channel for the
11:29 - foreground which means for the pixel 4d
11:33 - for the
11:34 - i forget the name this channel is for
11:36 - the tumors so these
11:39 - values here you can see that they are
11:40 - closer to the yellow means that these
11:43 - pixels
11:44 - contain a
11:47 - a tumor and all these pixels doesn't
11:49 - contain tumor which means these pixels
11:51 - are background and same thing for here
11:54 - so you can use only one of these
11:56 - channels to specify your your predicted
11:58 - or your final prediction or you can use
12:01 - all both of them and use a arg max
12:04 - or you can use a softmax or anything you
12:07 - want to apply or only a simple threshold
12:11 - and get the final output so that's what
12:13 - we will do in uh
12:15 - in the
12:17 - in this course so but these all these
12:19 - parts will be will come later after
12:21 - doing the training and etc but just i am
12:24 - showing you how does the output of unit
12:26 - looks like so you will have this is the
12:29 - label you will have two channels or how
12:32 - many classes you have in our course we
12:34 - will have same thing two classes the
12:36 - background and level so you will have
12:39 - pixel probabilities of each color of
12:41 - each pixel and using arc mugs or a
12:43 - simple threshold you can specif you can
12:45 - get your final binary mask which is like
12:48 - this this values are one these values
12:52 - are zero so this is a binary mask or
12:54 - force and two you can use as anything
12:57 - you want depends to
12:58 - how you are uh
13:00 - doing the threshold or something like
13:01 - that because if you will do a normal
13:03 - threshold so you have force and two if
13:05 - you are using a normal arg max so you
13:08 - have zero and one but it is the same
13:11 - thing you don't need to care about that
13:13 - now that's it and thank you for this
13:15 - part and now let's do some installation
13:25 - now let's talk a little bit about the
13:27 - software that we need in our project we
13:30 - need only two these four softwares which
13:34 - are we need python vs code 3d slicer and
13:38 - etg snap i am not talking about the
13:40 - dependencies like python dependencies
13:42 - that we need like your monae et cetera
13:45 - but all these dependencies will not talk
13:48 - about them now but we'll install only
13:50 - the the software that we need the first
13:53 - one is python as you know because we'll
13:55 - execute our code using pytorch and monae
13:59 - and of course using python not plus or
14:01 - other programming language
14:03 - then we need the
14:05 - text editor where we will need to write
14:07 - our code for that we need to install
14:10 - vs code so this is my choice and you can
14:12 - use any text editor you want but my
14:16 - preference i preferably need to use
14:19 - vs code but if you want or if you prefer
14:23 - using another one or maybe you you want
14:25 - to use jupyter notebook or something
14:27 - like that it depends to you and it
14:29 - doesn't change anything just i am
14:31 - showing you what i will use this in this
14:33 - course so you can follow me if you want
14:37 - then we will use 3d slicer so this 3d
14:40 - slicer we will use only to
14:42 - display our data and we use it as well
14:46 - for something else we may need a
14:48 - conversion that cannot be done using
14:51 - python but we will talk about this in
14:54 - the image in the processing or in the
14:56 - pre-processing part but for that we will
14:59 - need this this 3d slicer software after
15:03 - that we will install it snap because we
15:06 - will need this type of software maybe we
15:08 - will not use it in this course but maybe
15:11 - you will use it because we can i will
15:14 - show you how you can do the segmentation
15:16 - or correct the segmentation using this
15:18 - bt case now because i don't know if you
15:20 - will use the same data set that i will
15:22 - use or maybe you will use your custom
15:25 - dataset so for that case maybe you don't
15:27 - know how to segment or how to correct
15:30 - your segmentation for that we'll use
15:32 - this atk snap software and of course i
15:34 - will show you how we can use it for now
15:37 - i have all these softwares installed in
15:39 - my computer but i will show you how you
15:41 - can do it by your own now let's go here
15:45 - we said that we need to install python
15:47 - first so we have
15:50 - python.org
15:51 - then slash
15:53 - downloads as you can see here this is
15:55 - the latest version which is 3.10
15:58 - if you want to use this one it's
16:00 - different to you if you want to use
16:02 - another version so you can just click on
16:04 - windows and all these
16:07 - all these
16:08 - versions they are here but don't worry
16:10 - about this maybe
16:12 - i will show you in the following videos
16:14 - when we start coding and when we start
16:17 - installing dependencies we will i will
16:20 - show you that sometimes we need to
16:21 - create a virtual environment and where
16:24 - we will install a specific version of
16:26 - python in that specific virtual
16:28 - environment but at first we will install
16:31 - one of these versions and maybe you need
16:33 - to install the 3.10 doesn't matter
16:36 - because maybe we'll use it only for some
16:38 - pre-process not even pre-processing but
16:40 - we used for preparing the data because
16:43 - we will have for we will pass by three
16:45 - or four phases before doing training
16:47 - because there is pre-process but before
16:49 - the pre-process we need to do something
16:51 - with this data because you know that
16:53 - medical imaging are very very hard to
16:56 - use or to treat for that we need to do
16:58 - some preparation after that we'll do the
17:01 - play process because these are two
17:02 - different processes for that i am saying
17:05 - prepare and play process because uh i am
17:08 - saying i am i i want to say that there
17:10 - are there are two different types okay
17:13 - so if you if you want to install for
17:16 - example python 3.10 just click on this
17:19 - or you can just go here in downloads and
17:22 - download python 3.10 and just save it
17:25 - anywhere you want like this
17:28 - and it will be downloaded of course
17:33 - my internet connection is a little bit
17:35 - slow for that i need to wait a little
17:37 - bit so just you need to execute this
17:40 - command and follow all these steps i
17:43 - don't want to do it because i have
17:44 - already python i have a lot of versions
17:46 - of python installed on my pc for that i
17:49 - will not do this here but you can see
17:51 - that you just need to here because
17:54 - in my case i have already python so i
17:55 - need to install it then install it again
17:58 - but for you you will have only a button
17:59 - to say install and follow up all the
18:01 - steps and it will be installed so i will
18:04 - cancel this yes
18:06 - then here we said that you need to
18:08 - install python here is after that you
18:10 - install it now it is done now we need to
18:13 - install this text editor which is vs
18:15 - code and of course i have it already as
18:17 - you can see in my pc but i will show you
18:19 - just how you can download it and maybe
18:22 - try to install it so vs code download
18:25 - like this
18:26 - and you go here to code that vs code
18:28 - studio and there is order is this link
18:31 - both of them are official so you just
18:33 - need to click here now we have windows
18:36 - and it depends to how many which
18:38 - operating system you have so in my case
18:41 - i am using windows so you can just go
18:43 - here windows and windows 10 and click on
18:47 - download here or it will
18:50 - start the download by itself but if it
18:52 - doesn't start you can just click here on
18:54 - download okay
18:56 - now
18:57 - you need just to install the to to
18:59 - download this one maybe it will take
19:01 - time because as i told you my internet
19:03 - is slow these days
19:04 - so just download this and install it and
19:08 - follow the steps as you will do with
19:10 - python and it is very easy to install as
19:13 - any other software i will just cancel
19:16 - here
19:18 - now after
19:19 - sorry after that we
19:22 - don't need this for now
19:23 - now
19:24 - after installing this vs code
19:27 - let's
19:28 - talk about 3d slicer tree slicer is
19:31 - the same thing it is a free software
19:33 - that you can find here
19:35 - 3d
19:36 - slicer
19:39 - slicer download like this
19:42 - and this is the 3d slicer download just
19:45 - check which operating system you want
19:47 - just take the stable
19:49 - release don't take this one so just
19:52 - choose windows mac os or linux and for
19:56 - my case i am using windows so i need to
19:58 - download and install this one but but
20:01 - but as i told you i have already the
20:03 - software so i will not go and install it
20:06 - again especially my internet connection
20:08 - is slow but you get the point download
20:12 - this and install it step by step it is
20:14 - free and easy
20:15 - then after
20:17 - installing 3d slicer here because i told
20:20 - you that we will need it for some
20:22 - preparation of our data and
20:24 - visualization of course as well
20:26 - then we have the etk snap that we will
20:28 - use for segmentation by the way you can
20:31 - use etk snap for
20:33 - segmentation but
20:35 - sorry you can use 3d slicer for
20:37 - segmentation but i found this little bit
20:40 - difficult because you will see that etk
20:43 - snap is easy very easy it is old but it
20:46 - is very easy to do the segmentation than
20:48 - using 3d slicer but if you have already
20:51 - used 3d slicer for segmentation so you
20:54 - don't need to follow me doing this with
20:56 - etk snap okay so i am telling you with
20:58 - my experience i tried to use 3d slicer
21:01 - and i tried to use other softwares for
21:03 - segmentation but the easiest one was
21:06 - atk's not for me for that i am
21:07 - presenting you just need to etk snap
21:10 - okay
21:12 - and i cannot use use et case now for the
21:15 - uh some preparation for that i need 3d
21:18 - slicers so each one has a specific
21:21 - advantages and disadvantages okay now
21:24 - let's search for atk's not
21:27 - like here we have
21:31 - now
21:32 - we have this or we can just click on
21:34 - download
21:35 - downloads here
21:37 - you can see even the uh web page is too
21:41 - old but it is a good software okay so
21:44 - you can just choose for example windows
21:46 - or and all these versions you will take
21:49 - the latest one okay
21:50 - now you can use for windows mac os linux
21:54 - or something like that the best to you
21:56 - and your operating system so for me of
21:58 - course i would use this one but
22:00 - i told you i have it already on my pc so
22:03 - i will not take the time to download it
22:06 - and install it again so that's all what
22:09 - we will need for our
22:11 - course i am talking about the software
22:14 - we go back after to talk about the
22:17 - dependencies but for now you need to
22:19 - install python vs code i will leave all
22:21 - the links in the description so you need
22:23 - to install python vs code 3d slicer and
22:27 - etk snap and aft after installing this
22:30 - we'll
22:30 - go back and we'll continue doing our
22:33 - course
22:39 - now let's talk about the data set i will
22:41 - show you how you can find some public
22:44 - data sets otherwise if you have already
22:46 - data set in your projects then you can
22:48 - use it but if you don't have and if you
22:51 - maybe you are trying to do this
22:53 - segmentation
22:54 - just to improve your skills for that
22:57 - case in this case i will show you how
22:58 - you can find some public data set so the
23:01 - first source that i will show you that
23:04 - it was helpful for me and it contains a
23:06 - lot of data
23:07 - is the decathlon data set so this
23:10 - digital data set
23:12 - as you can see here there is
23:15 - i think nine tasks we will go here that
23:18 - is papers data there is more things but
23:21 - what we we are
23:23 - interested in is only the data set so we
23:25 - just click here in the
23:28 - guest data and you remember with me you
23:30 - just write the card long data set you
23:32 - will get the first link here but i will
23:35 - leave all the links in the description
23:36 - don't worry about that
23:37 - but when you click here
23:40 - go to get data and it will open
23:43 - the google drive here and you can see
23:45 - that all these tasks as there is 10
23:48 - tasks as you can see here so all these
23:51 - tasks means that all these are group of
23:54 - data
23:56 - which means it is really
23:58 - you will find the volumes with the
24:00 - segmentation so everything is ready just
24:02 - need to download it and use it but
24:05 - here you can see that there is brain
24:07 - tumor there is heart there is liver as
24:10 - you can see here there is hippocampus
24:12 - there is pro proscad prost sorry
24:15 - prostate and there are all these things
24:18 - that is lung etc etc and
24:21 - this one as you can see here this task
24:23 - nine which is the spleen which was used
24:25 - by monae
24:27 - so if you go to my website here for
24:30 - example i will choose it because our
24:33 - course is based on moonlight as you
24:35 - remember so if you go here in monae and
24:38 - you see the
24:40 - project that they are doing here for
24:42 - example we go to
24:44 - github and
24:46 - most of the projects and most of the
24:49 - tutorials that they are using here you
24:50 - will find that they are using this
24:53 - data set and we see that the because i
24:56 - found this
24:57 - decathlon data set from monae website so
25:00 - when you go here you will find this
25:03 - spleen data maybe you want to
25:06 - to try it
25:07 - i don't know but in our project we'll
25:09 - use the liver segment the liver
25:11 - segmentation so but i am not using this
25:13 - one you can download this one and it
25:15 - depends to you and what you want to try
25:17 - okay so for me i found the data set from
25:21 - cargill i will show you as well there
25:23 - how you can find that and i i'm sure
25:25 - that there are other data sets but for
25:28 - now you can find the best ones here in
25:31 - this website
25:33 - and in kaggle i will show you the data
25:35 - set that i will use in this project
25:39 - if you go here in cargo go to datasets
25:42 - maybe you you need to if you want to
25:44 - search in general you can write just
25:47 - healthcare images or healthcare datasets
25:49 - or medical imaging and found all the
25:51 - tasks that they have otherwise if you
25:54 - are searching for the exact data that i
25:56 - am using or i will use in this course is
25:59 - lever segmentation so just write level
26:02 - segmentation like this
26:05 - so here you will get all these results
26:07 - but these are the the because i am
26:10 - saying these because there is this first
26:12 - part and the second part of the data
26:14 - that i used in my project in discord so
26:17 - if i will open this and this in the
26:20 - other another tab
26:22 - you go here and you found all the these
26:24 - segmentations
26:26 - and these are the volume segmentations
26:28 - are the labels and these are the volumes
26:30 - and you can see that they are not
26:32 - completed
26:33 - for that there is the second part that
26:35 - you will find the other volumes of the
26:38 - first one here so you can download this
26:41 - i have them so i will not download them
26:44 - but you can download this
26:46 - if you want to use the exact data that i
26:48 - am using so you can download this first
26:50 - part and second part put them in the
26:52 - same same folder or something and we'll
26:55 - go to them later
26:58 - now
26:59 - after that you choose your data sets
27:01 - it can be this one this one or other
27:04 - task but what i want you to know is
27:08 - while using
27:09 - monae
27:10 - framework you need to have data set with
27:12 - the extension nifty so
27:15 - it should be and i i dot and i or
27:20 - compressed nifties but you need to have
27:23 - the base the base
27:25 - extension nifty for that reason you need
27:28 - to search for data that has nifty or or
27:31 - you can search for data that can be
27:32 - converted into nifty for example it can
27:34 - be an ldd or an rd or it can be dcom or
27:38 - any data that can be converted into
27:40 - nifty otherwise you cannot use these
27:44 - kinds of data with
27:46 - one eye for why i am saying this because
27:48 - if you are using simple 2d segmentation
27:52 - you can use anything you want and you
27:54 - don't need one line because i am using
27:56 - monae especially for the pre-process
27:59 - part because
28:01 - you can't find a good framework that
28:04 - help you to do pre-processing as the 3d
28:07 - volumes in medical imaging
28:10 - i couldn't find something better than
28:12 - one eye for that i am using because mona
28:14 - is great thing they are not paying me to
28:16 - say this but it is a great framework for
28:19 - medical imaging they have some problems
28:21 - and some things that they need to fix i
28:24 - will talk about them in some
28:26 - in the future lectures or future minutes
28:28 - but before for now i am saying that it
28:31 - is great framework but
28:33 - some improvements does need to be done
28:35 - we will talk about them later so
28:38 - i if you you need to put this in your
28:40 - mind when you want to use mona you need
28:43 - to have nifty files if you don't have a
28:46 - specific niche device you need to find
28:48 - data that can be converted into nifties
28:51 - so how you can convert this data into
28:53 - nifty this is another question so
28:56 - some of the the some of the extensions
28:59 - can be converted using python for
29:01 - example like the dcom images if you have
29:04 - series of decode because a nifty file is
29:07 - a series of decomps because the decom
29:09 - here i will show you an example
29:12 - this one as you can see here this is all
29:15 - these decons that's that goes to one
29:18 - passion so all these d comes each d com
29:21 - is one slice of a ct scan when we
29:25 - combine them all these d comes together
29:28 - we get one volume that one volume is one
29:31 - nifty file because when you take one
29:34 - nifty file and put it into the slicer or
29:36 - any other software to visualize it you
29:38 - will see that it it contains a lot of
29:41 - slices so each slice is a decom file
29:44 - that's what you need to know i don't
29:45 - know if you know that but i am just
29:47 - saying that
29:48 - so
29:49 - as i studio try to find nifty files or
29:52 - files that can be converted into nifties
29:55 - now you get this data if you want to
29:58 - convert them for example if you want to
30:00 - if you have dcoms like these and you
30:02 - want to convert them into nifty you can
30:04 - use 3d slicer but i think that for this
30:08 - kind because there is a
30:10 - python uh
30:12 - the patent package that
30:14 - does help you to do this conversion for
30:16 - that we don't need to use this there is
30:18 - d come to a nifty package that you can
30:20 - use it install it using pip install but
30:23 - don't worry about it we will do this
30:25 - later because now i am just talking in
30:27 - theory but we will do the code to do
30:30 - this conversion after for now i am just
30:33 - telling you that you can do this
30:34 - conversion using tv slicer but i don't
30:36 - recommend you because it will take time
30:38 - to upload or to load the data and save
30:42 - it so don't think about this for now
30:44 - but if you have for example nld images
30:47 - or something like that for that case
30:49 - maybe you cannot convert them using
30:51 - python for that you need to pass by this
30:54 - software here
30:56 - now let me tell you something
30:58 - how you can convert data using this i i
31:01 - will just show you how i i did that so
31:05 - what you can do because i had a problem
31:07 - when i was doing some segmentations i
31:10 - couldn't save them as nifties so i had
31:12 - segmentation or labels they were in
31:15 - energy extension for us i needed to
31:17 - convert them into uh
31:19 - into the nifty for that i passed by this
31:23 - software
31:24 - so now let's take for example this is a
31:26 - nifty file we don't need to convert it
31:28 - but just to show you how you can do that
31:30 - imagine with me this is an nrd file to
31:33 - open it just
31:35 - pass it and put it here in the in your
31:37 - software and drag and drop it in the
31:40 - software and click ok and it will be
31:42 - opened as a volume here and if i will
31:45 - scroll with the mouse you can see here i
31:48 - am passing by all the cuts or all the
31:51 - slides which are already decompiled okay
31:55 - so that's what i was talking about when
31:57 - i am scrolling this here i am passing by
32:00 - all the decon files that have been
32:03 - combined to create one nifty file now
32:06 - imagine with me this was a nrd file for
32:09 - example now i want to convert it into an
32:11 - ec what you can do just put it here drag
32:14 - it and drag it and drop it here it will
32:17 - be opened or you can just open it here
32:19 - file open etc
32:21 - now to convert it click on save
32:24 - now just
32:26 - don't take this one and check your file
32:28 - here you need to see because this one is
32:30 - the project you don't need to uh
32:32 - to save it so just save your file here
32:36 - if you have multiple files you can drag
32:39 - them all together here and they will you
32:42 - wish you they will show you all the
32:44 - files here that you have been opened and
32:46 - you
32:47 - with one click you convert them all at
32:49 - the same time okay so here let's say
32:52 - that this was a nrd file
32:55 - so here you can see that there is the
32:57 - there are all these
32:59 - kinds of files and led like this one for
33:02 - example if imagine with me our file was
33:04 - energy now you want to easy to
33:07 - save it as a nifty file so just click
33:10 - here search for nifty it will be here so
33:13 - there is this one nifty this one the
33:16 - same thing but this one is complete
33:17 - compressed i recommend you to use
33:19 - compressed so that you will save some of
33:21 - your memory you don't need to worry
33:23 - about
33:25 - compressed files when you use monai
33:27 - because it will know how to i will show
33:29 - you how to do that because you don't
33:32 - need to worry about that so i recommend
33:34 - you to save them as nifty which means
33:36 - nii dot gz which is compressed so click
33:41 - here
33:42 - and click on save or you can choose the
33:44 - directory when you where you want to
33:46 - save your file then click on save and it
33:49 - will save your file if you have multiple
33:51 - files
33:52 - just change them all here in the place
33:55 - of nld puts
33:57 - nifty and change them all and click on
33:59 - save it will save them all together in
34:01 - the same
34:02 - repository that you want so that was how
34:05 - to convert
34:07 - any file i am not saying any but you
34:10 - need to see here you have there is nld
34:12 - meter image all this kind of files so if
34:16 - you have data set with this extensions
34:19 - and for that and you want to use monae
34:21 - so you need to convert them into nifties
34:23 - so you need to pass them by this
34:25 - software for example and change them
34:27 - maybe
34:28 - maybe you have some extension that
34:29 - doesn't exist here so you need to search
34:32 - another software or maybe there is a
34:34 - python script that does that
34:36 - so that's my recommendation but if you
34:39 - find directly nifty files of or if you
34:41 - will use directly the data set that i
34:44 - used here like this one and this one
34:47 - in this case you don't need to convert
34:49 - anything because they are already
34:50 - nifty's okay
34:52 - so that was about the data set and in
34:54 - the next uh
34:56 - in the next lecture on next minute we'll
34:58 - start doing some pre-process to our data
35:01 - and there is something we need to talk
35:03 - about before doing the pre-process but
35:06 - don't worry we'll go step by step until
35:08 - the end of this project
35:14 - now let's start preparing our data as i
35:17 - told you in the last parts of this
35:19 - course i said that there are two
35:21 - different parts there is the preparation
35:24 - of the data and there is the pre-process
35:26 - i am calling them this because there is
35:28 - the preparation that we will do manually
35:30 - and it will we will do it in another
35:33 - with
35:34 - script without doing the pre-process
35:36 - because the pre-process we need to do it
35:38 - directly before the training so
35:40 - before doing that we need to clean the
35:42 - data because
35:44 - medical imaging are a little bit
35:46 - confused we can't use them directly to
35:49 - our model or our segmentation or
35:51 - anything like that because if we use
35:54 - them directly we will have some problems
35:56 - and will not have good accuracy and even
35:58 - we cannot fix our problem and we cannot
36:01 - even know where is the problem there so
36:04 - for that reason we need to do some
36:05 - preparation to our data before starting
36:08 - the pre-process or the training or
36:10 - anything uh that we will do later on
36:14 - so
36:15 - as i told you there is the data here in
36:17 - the catalog data set and there is in
36:19 - kaggle
36:20 - let's go here and and i will show you
36:22 - that we will use this
36:24 - this card this decathlon data set i i
36:27 - have already downloaded prepare it and
36:30 - everything i have done but i will show
36:32 - you only with two or three passes to
36:34 - show you how does it
36:35 - work and
36:37 - so that you will have an idea how to
36:39 - pre-process your own data okay
36:41 - because if i will do the pre-process or
36:43 - the preparation of all the data
36:46 - it will take time but we don't need that
36:48 - because when you understand how to do it
36:50 - for one or two passions you can do it
36:52 - for all the buttons and don't worry
36:54 - about the code i will provide you
36:56 - everything
36:57 - uh that will use here in this tutorials
37:00 - so don't worry about that now as i told
37:03 - you you can you go you go here to get
37:06 - data and it will open this one and as i
37:08 - showed you we are doing lever
37:10 - segmentation so this is the details that
37:12 - you need to download as you can do just
37:14 - like this click with your right
37:16 - right hand and click here in download
37:18 - and it will be downloaded and you can
37:21 - use it directly okay
37:22 - now after that you will download this
37:25 - data it will look like something like
37:27 - this
37:29 - and after that you decompress it it will
37:31 - be something like this and when you
37:33 - enter you will find all these files we
37:35 - don't need them you can do it delete
37:37 - them but you will find three different
37:39 - folders this one is image tier which
37:43 - means image images for the training and
37:46 - this one are images for the testing and
37:49 - this last one is labels for the training
37:52 - which means you can see that there are
37:54 - labels only for the training images
37:56 - there is no labels for the testing
37:58 - images so in that
38:00 - in this case it is easy to understand
38:01 - what is delivered but in some cases it
38:03 - is not easy but for now we will not in
38:06 - this course will not need
38:08 - this training you can leave it here but
38:10 - we will not need it because at the end
38:12 - of our training we need a label so that
38:15 - we can compare the label with the images
38:18 - that we have with the output that our
38:20 - model will predict so in this case we'll
38:22 - take only the images training images and
38:25 - testing and training labels and we'll
38:28 - take few passions from
38:31 - from the training maybe we'll take 10 or
38:33 - 20 because we have here you will find
38:35 - that you have 130 these are only because
38:39 - it is
38:40 - redo it here after the completion but in
38:43 - reality there are only 130 passing so if
38:46 - you take 10 or 30 passes for the
38:49 - validation or for the testing so
38:52 - not all of the because validation is
38:54 - different than testing so because in our
38:55 - case we do training and testing will not
38:57 - do validation because when you go to
39:00 - monae
39:01 - tutorials you will find that they are
39:03 - using the word validation validation but
39:06 - i am not sure that this was the
39:08 - validation because
39:10 - because it is true that they will use
39:12 - that data during the training but it is
39:15 - not validation because they will not
39:17 - affect the training or the model they
39:19 - used only to calculate metrics and to uh
39:22 - to yes to test their
39:25 - model for that case we cannot call them
39:27 - validation they are testing data set not
39:29 - validation for that because actually we
39:32 - will not we will use almost the same
39:34 - code
39:35 - i am talking about the preprocess and
39:37 - the training we use almost the same code
39:40 - provided by monae but we will do some
39:42 - changes for example i will not use the
39:44 - word validation i will use testing etc
39:47 - etc but we will go to this uh real back
39:49 - to do this to go to this later but now
39:53 - as i do you will when you will download
39:56 - the data you will find or you will find
39:58 - all these passions but as i told you i
40:00 - will not do the process for all the
40:02 - passes because it will take time and
40:03 - memory and i have already this data so
40:06 - what i did i just took two end here of
40:10 - course the the images with the
40:14 - labels so what you need to do is just to
40:18 - uh
40:19 - follow me how i will do this uh process
40:22 - for two patients and after that i will
40:25 - show you how you can do it for more uh
40:27 - you will know how to do it for all your
40:29 - passions but there is something that i
40:32 - need to talk to tell you about is here
40:35 - in monae you will see that they are
40:37 - using something because when you want to
40:40 - train your data or your uh images here
40:43 - in
40:44 - medical imaging there are two ways to do
40:46 - it because we have images with 512
40:50 - by 512 i am talking about the width and
40:52 - the height and the number of slices in
40:54 - different difference sometimes you will
40:56 - find 20 sometimes you will find 50
40:58 - sometimes you will find 500 it differs
41:01 - from it differs from your uh
41:04 - task and your data set okay
41:06 - so in that case we cannot use directly
41:08 - the data because we need to create the
41:11 - same
41:12 - dimensions of each input so that will
41:15 - not get the model confused so when we
41:17 - will fix the width and height for five
41:20 - and five twelve by five twelve
41:22 - and for example slices by 100 so we we
41:25 - need to get all the pacings or all the
41:28 - inputs with this same
41:30 - dimensions for that when you see in
41:33 - monae's tutorials you will find that
41:36 - they are doing some crops so that they
41:39 - can get the same dimensions but that
41:42 - method work for some cases but it
41:44 - doesn't work for others
41:46 - and i tested that method in this lever
41:49 - segmentation it and it doesn't give a
41:51 - good result okay for those i will not
41:54 - use it but i will show you just a little
41:56 - bit explain to you how they are using
41:58 - that and why i will not you use it and
42:02 - how can we prepare our data to to use my
42:05 - my way it is not my way but what i found
42:07 - better than the more nice way
42:11 - so the method used by monae or monitors
42:14 - they take for example this is a passion
42:16 - i am showing you only one slice but
42:18 - imagine with me you have a number of
42:20 - slices here which is a volume which is
42:23 - actually a nifty file so what they do
42:26 - they do they create some crops
42:28 - they create random crops but i am
42:31 - showing you like this so that you will
42:32 - understand but they are doing random
42:35 - crops here for example a crop here or in
42:37 - the crop here which means they create a
42:39 - window with defined width and height and
42:43 - number of slices and they take this crop
42:46 - the the that they used they cropped
42:49 - using that window and they pass it for
42:51 - the training and the same thing they
42:54 - take in but
42:55 - they do they take one crop for one uh
42:59 - one epoch then in the next epoch they
43:01 - take another crop like this and the
43:04 - other one another couple from and they
43:06 - are random crops not as i am showing you
43:09 - here but just to know how does it look
43:12 - so that that's what they are doing in
43:14 - their tutorials they take only small
43:17 - crops and do the training on this crop
43:19 - and describe this crop etc etc for that
43:22 - they use 600 epochs so that they can
43:25 - pass by all almost all the passenger or
43:27 - almost all the slices but
43:30 - i tested this way but it doesn't work
43:32 - well for me for that i want to show you
43:35 - how i will do i will do it in my way
43:38 - which means we will create by ourselves
43:41 - uh
43:42 - this window but what i what we will do
43:44 - we will let the width and the height the
43:47 - same or we can resize the image but we
43:50 - will not crop it like this or so we will
43:52 - not take only small parts from the image
43:55 - but we will take the whole
43:57 - as you can see the whole shape or the
43:59 - whole content of the image maybe yes not
44:02 - maybe but we will
44:04 - resize the images because if we want to
44:06 - apply to pass them 512 by 512 to the
44:09 - model it will take forever to be trained
44:11 - for that we need to resize the images
44:14 - and what we can do maybe we can crop
44:16 - this areas so that we take only the
44:20 - places or only the area that has content
44:23 - of the image but otherwise we not need
44:26 - to take uh small portions as monai are
44:29 - doing so what i would recommend you i
44:33 - recommend you to not i am recommending
44:35 - you or i will show you how how i will do
44:37 - this on my way how to create the small
44:40 - uh passions or the small slices groups
44:43 - of slices and
44:45 - if you like it or if you want to try it
44:48 - out i will show you everything that you
44:49 - do all the scripts that we will use etc
44:51 - etc otherwise if you want to use the
44:54 - moniz tutorial like that so maybe you
44:57 - can follow me just to understand some of
44:59 - the basics and some of the functions
45:01 - that what i provide but in this way you
45:04 - can you want you will not use my
45:07 - idea and you can skip maybe one hour or
45:10 - something like that from this video
45:11 - because i will be explaining everything
45:14 - to do to prepare the data because if you
45:16 - will use this way you don't need to do
45:19 - any preparation maybe there is a process
45:21 - to change the contrast etc but
45:23 - preparation which means cleaning how
45:25 - many slices you have how how many groups
45:28 - you have you don't need to do all that
45:30 - but if you want to follow me so you need
45:32 - to see how i am doing this and after
45:35 - finishing the course you can try this
45:37 - one and maybe you can try
45:39 - more nice tutorial or more nice way in
45:41 - your data maybe the other way will work
45:44 - for you well because
45:45 - it doesn't work for me maybe it works
45:47 - for you okay so let's now let's go to
45:50 - show you what are the preparations we
45:52 - will need and how to do them
45:56 - so the method that i am proposing is to
45:59 - create small groups which means we will
46:02 - leave the same width and height for now
46:04 - before the pay process will leave the
46:06 - same width and height of all the slides
46:09 - of all the passions but we will create a
46:12 - constant number of slices which means if
46:15 - we have for example a passage with 120
46:20 - slices what we will do for example we
46:22 - will create if we will
46:25 - if we will make a constant number of
46:27 - slices for example like 60 60 slices per
46:31 - group so what does it mean dispassion of
46:34 - 120 of 120
46:37 - slices we will divide it into two groups
46:40 - so it will be the passion zero for
46:42 - example uh slash one for example this is
46:45 - the first part so it will be
46:47 - with 60 slices and the next part will be
46:50 - with another 60 slices and the same
46:53 - thing for all the passions if we fix the
46:55 - number as 60 slices per group or per
47:00 - input that means that we will pass by
47:02 - all passions and divide them into groups
47:05 - of 60 slices this is the idea that i
47:08 - found because maybe you can if you
47:10 - because i don't know how
47:12 - what is your data that you are using
47:14 - because if for example you have
47:15 - passenger with almost almost the same
47:18 - number of slices for example 100 101 102
47:23 - or and something like this and all these
47:24 - passions have almost this range of
47:27 - slices in this case you may not need to
47:30 - do what i will do here because you may
47:32 - you can do in the training you can crop
47:35 - your passions and fix the number of
47:37 - slices into 100 slices per input which
47:41 - means if you have a passion with 150 100
47:46 - slice so this passion will go directly
47:49 - as an input or if you have a passion
47:52 - with 100 one and one slices means that
47:56 - you will crop only one slice and one
47:58 - slice it doesn't affect your uh
48:00 - your data because for example if you
48:03 - crop your data and maybe you you will
48:05 - clear or
48:07 - 10 or 20 slices this maybe you will lose
48:10 - some information of your passion but if
48:12 - you just take off only one slice or two
48:15 - slices it doesn't affect your training
48:17 - or your data i hope that you are
48:19 - understanding what i am saying because
48:21 - if you have only you have almost all
48:23 - this the passion to have almost the same
48:26 - number of slices so in this case you
48:27 - don't need any
48:29 - preparation of this asians but if you
48:32 - have a random data set that has passion
48:35 - with 50 slices another passing with 500
48:38 - another percent with 300 something like
48:40 - that because all the passing that you
48:42 - will all the data that you will find as
48:44 - public data sets you will find them like
48:46 - that so if you will find out like that
48:48 - you need to follow me to clean them and
48:50 - make them ready for the training so the
48:53 - first thing that you need to do is to
48:54 - convert these nifty files into dcoms so
48:58 - that you can convert or you can create
49:01 - small groups okay
49:03 - to do that for now there is no specific
49:06 - python package to do this because i
49:08 - searched for that i didn't find i i
49:11 - tried to create my own package to do
49:14 - this and you will find it on my
49:16 - github profile here
49:18 - like you will find i mean zero one one
49:20 - zero slash nifty to dcom so that was i
49:23 - tried to create and you will find it
49:25 - here it is useful for some cases but not
49:28 - for this case because there is a problem
49:30 - that i couldn't find how to fix it and
49:32 - if any one of you have a suggestion
49:35 - please you can leave it in the comment
49:36 - or you can just take the code and make
49:39 - it ready for you i will tell you what is
49:41 - the problem with this code and so that
49:43 - you will understand
49:44 - this code will create will take a nifty
49:46 - file and create your decon slices but
49:50 - the problem here is that it will give
49:52 - all the slices or all the decomp slices
49:55 - the same number of index what does it
49:58 - mean if you have a nifty file with 10
50:00 - for example 10 slices so when you will
50:03 - convert it into deconfile it decompiles
50:06 - it should be each num each slice or each
50:09 - deconfile with
50:11 - with different index so for example the
50:13 - first nifty file will be with the index
50:15 - 0 the second one with the index 1 2 3
50:19 - until 10 which means if you want to
50:21 - reconstruct or rebuild the nifty file
50:24 - after
50:25 - the
50:26 - python package will understand that this
50:28 - first slice is goes to the first nifty
50:32 - uh
50:32 - to the first
50:34 - [Music]
50:35 - item of the nifty the second one is the
50:37 - second cut third etc etc but the code
50:41 - that i i'm providing here will give the
50:44 - same index to all the passions which
50:46 - means not the passing to all the slices
50:49 - so if you convert one nifty file into
50:52 - ten sli nifty into 10 decom slices all
50:56 - these dcom slices will have the index 0
50:59 - for example yes the first index so in
51:02 - that case you cannot rebuild the nifty
51:05 - file again so
51:07 - in our case we need to rebuild because
51:09 - we need to take groups of d columns and
51:13 - reconvert them into the two nifty files
51:16 - which means it doesn't work for us maybe
51:17 - this type of convergence if you need
51:20 - only to convert into dcom you don't need
51:22 - to
51:23 - or you don't need the indexes in that in
51:25 - that case you can use this but otherwise
51:27 - for our project we cannot use this even
51:30 - if maybe if you find a way how to change
51:33 - the indexes so you can take the code and
51:36 - change the indexes of all the deconfiles
51:38 - otherwise i will show you how you can do
51:40 - it manually without without python code
51:43 - for that this this is the parts that
51:45 - take a lot of time of this work but the
51:47 - others are just coding and everything
51:49 - will i will provide you all the scripts
51:52 - for everything but only this part needs
51:54 - to be done manually and it will take
51:57 - time sorry about that but it will take
51:58 - time for that i am saying if any one of
52:01 - you know how to convert nifty to dcom
52:04 - using python or something like that
52:06 - please provide this in the comments so
52:08 - that anyone
52:09 - who is using doing these projects can
52:11 - use this package
52:13 - as well okay thank you for now
52:15 - now
52:16 - i will show you the second way that you
52:18 - can do it but as i told you it will take
52:21 - time
52:22 - we will use 3d slicer for that when we
52:25 - was installing softwares i told you that
52:27 - we'll use 3d slicer for for some
52:30 - conversions so now it is the time to
52:32 - talk about that
52:34 - i will show you how you can do one or
52:35 - two
52:36 - not i have i i just choose two buttons
52:39 - here so i will show you these two passes
52:42 - how you can
52:43 - convert the images and the labels and
52:46 - you can do this you can see that it is
52:48 - easy but it
52:49 - takes time so you can do it for all the
52:51 - passings that you have so now let's
52:53 - start by before that i want just to
52:56 - create some folders
52:58 - so that we can know where to put our
53:00 - data because i didn't want to make
53:03 - everything with python script because
53:05 - sometimes it is very you can pass
53:08 - 10 minutes writing a script to do
53:11 - something so that you can say that it is
53:13 - automatically but you can create the
53:15 - folder with one in one minute so just
53:18 - click new and create a folder so it will
53:21 - take
53:22 - two or three seconds but if you want to
53:25 - write python script it will take maybe
53:27 - three minutes or more than that so in
53:29 - that case i prefer to do it manually
53:31 - instead of writing a python code to do
53:34 - it okay
53:35 - now let's call it for example dcom
53:39 - decom files maybe because what we will
53:43 - do in this folder we will take these
53:45 - passions and convert each of them into
53:47 - the com slices because nifty is group of
53:50 - dcoms now let's go here this is the
53:53 - decom which creates another folder here
53:56 - one for the images i will call it for
53:59 - example images
54:01 - and then the other one we will call it
54:03 - the if you want to do it directly with
54:06 - the keyboard you can just click ctrl
54:08 - shift and end which is new so we will
54:11 - create a new folder here so this next
54:13 - one we call it labels something like
54:16 - that this
54:18 - this files or these folder names will be
54:20 - changed after because we need them for
54:23 - our specific script but don't worry
54:25 - about that we
54:26 - will come to that later now we have two
54:28 - folders this one images and this one
54:30 - labels
54:31 - now let's do what i was saying to use
54:34 - this software 3d slicer let's start by
54:38 - the images let's take the first one just
54:41 - grab it here drag and drop into your
54:44 - slicer or just you can open it here
54:46 - and now okay open it
54:49 - and it will be opened here as you can
54:51 - see all these the slices you can just
54:54 - scroll down or just do like this so all
54:58 - these are the slices for example this
55:00 - passion has
55:02 - you can just you can read here you can
55:04 - see here it is
55:06 - 74 slices and you can go to other
55:10 - passions you will find maybe 100 slice
55:12 - etc etc so this is the problem you
55:15 - cannot use the same script for all the
55:17 - passengers for that we need to prepare
55:19 - them with the same slices after that we
55:21 - pass them by the to the training phase
55:24 - okay now how to convert them just click
55:27 - here
55:28 - insert and
55:30 - click or type here dcom
55:34 - creates the ad com series so search for
55:37 - create a dcom city so just go here
55:41 - in search
55:42 - dcom
55:43 - creates the comp series so when you
55:46 - click here click two times here you will
55:48 - get this window here the first thing
55:51 - that you need to do is there is nothing
55:53 - uh is hard to do it this is you don't
55:56 - need to change this because creating it
55:57 - becomes serious so you don't need to
55:59 - change that
56:00 - click here on select you need to select
56:02 - the volume or yes the volume or the
56:05 - image that you want to
56:07 - to convert so here you can see that we
56:09 - have volume zero this is the the
56:12 - passing that we are displaying now and
56:14 - this is the passing that we want to
56:17 - convert so you know you need just to
56:19 - choose it here
56:20 - level zero now
56:23 - you need to
56:24 - choose or to change the directory where
56:26 - you want to be to put your conversion
56:30 - now as we were saying we need to go to
56:34 - here to our folder that we have created
56:37 - called nifty files
56:39 - go here
56:41 - youtube
56:43 - yes
56:44 - this one dataset
56:47 - lever and deconfiles
56:49 - and this one is an image not a label or
56:52 - segmentation so we go to the image now
56:55 - we need to create a folder for because
56:57 - if we passed here everything will be
56:59 - here every every slice or all the decon
57:02 - files will be here but we need to to put
57:05 - them into one in one folder which is
57:07 - called with the same name of this button
57:10 - so we need to create a folder here so we
57:13 - can call it lever 0 for example
57:16 - and with the same thing or you if you
57:18 - want to change the name here it doesn't
57:19 - matter
57:21 - now choose now everything is set just
57:24 - click here in apply
57:26 - and you will see that it had the
57:28 - conversion have been completed let's go
57:30 - here and see what's happened here images
57:34 - we have created this and here are all
57:36 - slices as you can see we have 75 from 0
57:41 - from 1 into 75 so everything everything
57:45 - is set and these are all the slices
57:47 - because here we see that the maximum is
57:50 - 74 because it starts from the index 0 so
57:53 - from 0 to 75 but here
57:56 - it is starting from 1 into 75
58:00 - okay so there is no problem with that
58:02 - but these are all the slices for this is
58:06 - for the image one for the lever one now
58:09 - let's do it for the second
58:11 - just go here
58:15 - and
58:16 - the second here we have we had image
58:19 - which is level one
58:20 - now
58:21 - level zero now level one
58:24 - open it here and you can see now we have
58:27 - the lever one and for example this one
58:31 - this one have 122
58:34 - slices which you can see it is not as
58:36 - the first one for that case it was it
58:38 - will pose a big problem when you want to
58:41 - do it or you will lose all the
58:42 - information of your passing if you do
58:44 - some crops for that we need to create
58:47 - groups with the same number of slices
58:51 - now let's select the second one which is
58:53 - what we uploaded now this one level one
58:56 - and here we need to change the path
58:59 - because we had the folder level zero now
59:02 - we need level one something like that
59:06 - and that's it choose
59:08 - and apply
59:11 - this
59:12 - so now we have the two passengers have
59:14 - been the have been
59:16 - converted here
59:18 - let's go images this is the second one
59:21 - now let's do the same thing with the
59:23 - labels let's go here we have label
59:26 - training let's take the first one here
59:31 - and as you can see this is labels with
59:33 - the same number of slices now let's
59:35 - select here you can see because they had
59:38 - the same
59:39 - name level zero level zero so they added
59:42 - this index so that you can know so this
59:44 - is the first this is the first label
59:47 - for for the first passing as well now
59:50 - we will not do it in images now we are
59:52 - in labels so create a new folder call it
59:56 - here lever
59:58 - you need to put it the same because we
60:00 - choose we choose to put the lever zero
60:02 - so we need to put the same thing lever
60:05 - and zero so another so that's the uh
60:09 - when we will do the training etc
60:11 - the the labels with their images will be
60:14 - the same okay
60:15 - now let's choose this one
60:18 - yes
60:19 - here we have the same thing choose and
60:21 - apply
60:23 - and the same thing for the second one
60:26 - which is lever one
60:31 - choose it here
60:33 - change to
60:36 - level then one
60:39 - and choose it apply
60:43 - and now everything is set for this step
60:47 - when we go here
60:49 - the confines you will find images
60:52 - here is for the first one second one and
60:55 - same thing for the labels this is the
60:57 - first one and the second one as well
60:59 - so that's what you need to do at first
61:01 - but for me i am showing you only two
61:04 - passions but you you need to do all the
61:06 - passing sorry it will take time but i
61:08 - didn't find another way to do that okay
61:11 - so as i told you if you have the number
61:13 - of slices sorry i am repeating the word
61:15 - but just to understand if you have if
61:18 - you have the same number of slices for
61:20 - all the passions or almost the same with
61:22 - a minus one or one difference between
61:25 - them so in this case you don't need to
61:28 - do what i am doing here but if you have
61:31 - the public data set as i am saying here
61:34 - as you see
61:35 - you i show you the first if i show you
61:39 - only two passes the first one has 74 the
61:42 - second one have
61:43 - uh 122. so in that case you can see that
61:47 - there is a difference so if we go or if
61:49 - you pass by all the passengers we will
61:50 - see that every passing has each
61:53 - its is
61:55 - unique if we can say unique number of
61:57 - slices which is a problem for that we
62:00 - need to pass by this way now after doing
62:02 - this what we have to do we need to
62:04 - create the groups that i was talking
62:06 - about groups of decom slices which is we
62:09 - can choose any number we want
62:12 - in this case i will choose 64. i don't
62:14 - know why i choose this white but this
62:17 - number
62:18 - maybe i found that the minimum of
62:20 - because i passed by all the passions
62:22 - maybe i found that the
62:24 - person that has less slices was between
62:26 - maybe 64 or 65 for that i choose that
62:29 - number but for you it depends to you and
62:32 - you need to choose
62:33 - the number of slices that you want or
62:36 - that is depending to your data set
62:39 - so you can do the same thing as i did
62:41 - you go by the the passes that you have
62:43 - you see the but the passing that has
62:46 - less number of slices and you take those
62:48 - numbers so that you will not lose that
62:50 - passion because if you take number more
62:52 - than
62:53 - the minimum which means that you will
62:54 - lose that dispassion if you choose for
62:56 - example
62:58 - number of slices unique number slices
63:00 - equal 100 and you have some passion that
63:04 - are having number of slices 60 for
63:06 - example so 60 past ends 60 slices can
63:10 - not be converted into 100 slides so you
63:13 - will lose this passion for that for this
63:16 - case i am telling you to see the person
63:19 - that has the less number of slices and
63:21 - take that number of slices as a
63:23 - reference or a constant number for all
63:26 - the other passions okay
63:28 - now for the next steps which is doing
63:31 - all the conversion creating the groups
63:34 - and reconverts into uh
63:36 - nifty files everything will do it using
63:39 - python so i will show you how you can do
63:41 - it but before talking about or before
63:43 - starting coding i am just telling you
63:46 - that everything is set for now all the
63:48 - code all the scripts all the functions
63:50 - are here in github which i will share
63:52 - with you after you can find everything
63:54 - here the preprocess and everything is
63:57 - here but we will write this code
64:00 - each line by code
64:02 - by ourself but after that i will provide
64:05 - you everything here and i will provide
64:07 - you the notebook jupyter notebook maybe
64:10 - you need you you you would like to use
64:12 - it because in our case we will use
64:14 - jupyter notebook in some cases because
64:16 - it is easier to follow the steps but you
64:19 - will find everything here in github
64:21 - which you will find the link in the
64:23 - description
64:24 - so now let's start creating the groups
64:26 - and converting them into nifties
64:30 - now as i was telling you that you can
64:33 - use jupiter notebook that i i will show
64:36 - you how you can use it i am sure that
64:38 - you know how to use it but maybe
64:41 - did you use it in different way that's
64:43 - what i want to say because you can
64:46 - install it easily in the command window
64:49 - like you go here in cmd you can open
64:51 - this command window just type pip
64:56 - install then jupyter
64:58 - and it will be installed and you can
65:00 - open it uses and there is no problem
65:03 - with that but the problem that you can
65:06 - you may have using this uh jupiter
65:09 - notebook directly here is not probably
65:12 - in the installation but
65:14 - if you want to use a virtual environment
65:16 - in your in your project in that case it
65:19 - is sometimes it is not easy to
65:22 - open or to
65:24 - yes to open jupiter notes book inside a
65:26 - virtual environment or to use gyptonium
65:29 - with virtual environments
65:31 - so
65:32 - the way that i recommend you because i
65:34 - always choose the easiest way and i will
65:36 - show you the easiest way
65:38 - if you like it you can use it otherwise
65:41 - you can use something else but as i told
65:43 - the jupiter notes book if you install it
65:45 - like this there is no problem but when
65:47 - you want to use it with a virtual
65:49 - environment you will have some problems
65:52 - so to make it easy to do this process
65:54 - what you need to do is just to go
65:57 - install anaconda navigator
65:59 - so anaconda navigator is as you can see
66:02 - it is a software that has multiple i
66:05 - will show you multiple software here
66:07 - that you can use and which is the is
66:10 - which is the best thing here that you
66:12 - can create your virtual environments
66:15 - with using conda not a virtual
66:17 - environment with python because there is
66:19 - python vms which is python vertical
66:21 - environment and there is conda virtual
66:24 - environment and when you use anaconda
66:26 - you can create your contact but your
66:29 - environment you can create them using
66:31 - command windows like this here click
66:33 - here contact install and or contact
66:36 - create you and you create your virtual
66:38 - environment exactly with a specific
66:40 - python version and all these things that
66:42 - you want to set
66:44 - but if you are beginner with programming
66:46 - maybe
66:47 - it will be easy to create your virtual
66:49 - environment manually using the gui here
66:52 - anaconda gui so
66:54 - to do that you just come here i will
66:57 - show you first how to down install it
66:59 - which is very easy you can just go here
67:01 - to anaconda dot com slash product slash
67:03 - individual i will leave the the
67:06 - link in the description don't worry
67:07 - about that so when you install your
67:10 - anaconda here and you you download it
67:13 - here and you you follow all the steps as
67:15 - we have installed everything else
67:16 - because i have it already so that i
67:18 - cannot install it reinstall it again but
67:21 - just download it because it is free
67:23 - download this open it and it will and
67:26 - follow the steps and of course you need
67:27 - to choose which operating system for me
67:30 - i am using windows so it is already
67:31 - windows here if you have mac or
67:33 - something else so just you need to click
67:35 - here and search for your operating
67:37 - system
67:38 - now after installing it just open it as
67:42 - here you can when you start it will be
67:43 - something like this now
67:45 - here if you open here this list you will
67:49 - you will see all the uh virtual
67:51 - environment that you have in your pc
67:53 - that you have created in your pc they
67:55 - will be shown here and this is the
67:58 - base when you will create or you will
68:00 - install an account you will find only
68:02 - these two uh vertical environment this
68:04 - is the base which is the base vertical
68:06 - environment of your pc this one mini
68:08 - contact is we can say that it's an
68:10 - example but you will not need it because
68:12 - we will install our virtual environment
68:15 - for our project this is testing i just
68:17 - installed it again
68:19 - but
68:20 - now how to create a virtual environment
68:23 - in anaconda as actually you can do it
68:25 - using the command window here cmd and
68:28 - you can create use the command line and
68:30 - install and create a virtual environment
68:33 - then activate it etc
68:35 - but the easiest way here while we are
68:38 - using the since we are using the gui
68:40 - already you can go here environments and
68:43 - you can see as i show you all the
68:44 - environment that you have here now to
68:46 - create new virtual environments that is
68:49 - here these buttons create a new cloud
68:52 - import backup remove if you want to
68:55 - remove one of these various environments
68:58 - so as we said we want to create one so
69:01 - click on create
69:03 - now choose the name of your virtual
69:05 - environment let's call it for example
69:07 - liver segmentation so this virtual
69:10 - environment will be the virtual
69:11 - environment that we will use in our
69:12 - projects and i will talk about this
69:15 - after but now when you use it check here
69:18 - in python then here you can choose any
69:22 - any python version that has been
69:24 - installed in your pc
69:26 - and just for me i have python 2.7 3.5.6
69:30 - i have everything here so i will just
69:33 - choose 3.8 you can choose any version
69:36 - you want but i am going to choose 3.8
69:39 - and i recommend you to do this because
69:41 - sometimes when using mulai if you go
69:43 - with latest versions maybe you will find
69:45 - some problems so
69:47 - three point seven three point eight is
69:49 - enough for this project so i will choose
69:51 - three point i ate then here create
69:55 - and you will see that the vertical will
69:56 - be created in
69:58 - millisecond not millisecond but in
70:00 - a few seconds and now we just have to
70:03 - wait
70:06 - and this is our virtual environment and
70:08 - now here you can see the uh files or the
70:11 - packages or libraries that have been
70:13 - installed already with the virtual
70:15 - environment as you can see we have pip
70:17 - we have python of course sqlite etcetera
70:20 - but we will not use these because we
70:22 - need other packages like numpy money etc
70:25 - but everything we need to install it by
70:27 - ourselves so the installed packages
70:29 - there is multiple ways to do it we can
70:32 - use conta install we can use pip install
70:35 - or we can just can come here we have
70:38 - here when we are checking here only we
70:41 - are seeing only installed packages we if
70:44 - we click here not installed updatable
70:46 - etc or we can click just in all we will
70:49 - get all the python
70:51 - packages that have been
70:54 - that are available in anaconda and
70:56 - search for anything here then click
70:58 - install but i when we are talking about
71:01 - installing packages i don't prefer this
71:03 - way i prefer using pip for that i will
71:06 - not follow this way i will show you how
71:08 - we can use pip
71:10 - to install different packages
71:13 - so now what we need
71:14 - click create a virtual environment now
71:17 - when you are selecting it here means
71:19 - that you are activating because if you
71:21 - have already used virtual environments
71:24 - it can be virtually environmental python
71:26 - virtual environment or a more conda
71:29 - inverting environment when you did it
71:31 - you have always to create it then
71:33 - activate it when you write virtual
71:35 - environments like script slash activate
71:38 - or source virtual slash bin slash
71:40 - activate
71:41 - but
71:42 - when you use the gy here when you select
71:45 - it here means that it is activated you
71:47 - don't need to do something else to
71:48 - activate your virtual environment
71:50 - now
71:52 - as i was saying we really need to use
71:54 - jupiter notebook so here as you can see
71:57 - there is jupyter notebook there is
71:58 - everything vs code there is pycharm
72:00 - there is everything here we can install
72:02 - it we will install this because we need
72:04 - this after but for now what we need is
72:07 - just to use jupyter notebook so you
72:10 - click here even if you didn't install it
72:13 - before in your life don't worry about it
72:15 - it will be installed when you click here
72:17 - it will be installed in your virtual
72:18 - environment which means that you can use
72:20 - it there
72:21 - so now let's create let's click in
72:23 - install and it will install
72:26 - jupyter notebook in this virtual
72:28 - environment
72:31 - now it is installed as you can see and
72:33 - this is the best thing when using
72:35 - anaconda navigator because you don't
72:38 - need to think about how to uh
72:40 - to link the your
72:43 - virtual environment with jupiter
72:44 - notebook or sunday lines you don't need
72:46 - to care about that
72:48 - the only thing that you need to do is
72:50 - select or create a virtual environment
72:52 - selected then come here and now it is
72:55 - already installed so you will not you
72:57 - don't need to install it every time now
72:59 - you installed if only one time in your
73:02 - new virtual environment now click in
73:04 - launch it will be launched and we will
73:07 - say
73:08 - here
73:10 - now there is jupyter notes book is
73:12 - working and now jupyter notebook is open
73:15 - with your or inside your virtual
73:17 - environment so you don't need to think
73:19 - or care about which virtual environment
73:21 - you have or anything else now all what
73:23 - you need to do is to create your folder
73:26 - to check or to make directory where you
73:29 - want to put your your stuff on your
73:31 - project and inside that folder you
73:34 - create a new notebook now for me i
73:37 - selected this so i will work on this
73:40 - repository which is labor segmentation
73:42 - here where we will put everything or all
73:44 - the code
73:45 - not the data data is somewhere else but
73:48 - here we will put only the code now
73:51 - to create a new notebook just come here
73:54 - click on new as you can see there is
73:56 - python 3 that is text file folder
73:58 - terminal but for us we want to create
74:00 - jupyter notebook for python so python 3
74:04 - ipi ipu
74:06 - sorry iby kernel so ipwa i ipu y means
74:11 - that jupiter notebook and kernel
74:14 - now
74:15 - uh what we will do here we have this is
74:18 - our notebook just you can click here to
74:20 - rename it i will give it for for example
74:23 - prepare because we will use this
74:25 - notebook for now to do the preparation
74:27 - because we were talking
74:29 - now a few few minutes ago we saw we said
74:32 - that we need to convert our images here
74:36 - we had this labels and images they are
74:39 - decode now we need to create groups or
74:43 - yes create groups with the number of
74:45 - slices then reconvert these groups into
74:50 - into nifty files so that's what we will
74:53 - do in this
74:54 - notebook now to do the creation of the
74:58 - groups of
74:59 - 64 slices this was my choice if you want
75:02 - something else you can change it
75:05 - now these are my two parts this is the
75:08 - inputs and this is the output path the
75:10 - output parts we need to talk about it
75:12 - here
75:13 - i have i have because we had this dcom
75:17 - files where we have we had images and
75:20 - labels this is the input path file decon
75:23 - files and we have images and labels
75:26 - we'll start by labels for example then
75:28 - the output part i have created this
75:30 - folder called dcom groups so you need to
75:34 - create a folder you can call it anything
75:36 - you want so that we will take this
75:39 - labels from this
75:42 - that we will convert or because we will
75:44 - not convert actually sorry we will
75:46 - create
75:47 - groups of 64 slices so what will happen
75:50 - now we will create
75:53 - each for each group will create a folder
75:55 - but we will not do it manually all what
75:57 - we need to do is create this group where
75:59 - we will save all the passions all the
76:02 - groups which i call decom groups but we
76:05 - will write the script that will create
76:07 - folder for each group which is 64 slices
76:11 - so that we can
76:12 - after that we can convert this 64 slice
76:16 - into one nifty file but before that what
76:20 - we need to do is to create this decon
76:22 - groups which will be a
76:26 - which will be a folder now there is
76:28 - something else that we need to talk
76:29 - about because we have this decon groups
76:32 - but what we need to do we need to create
76:34 - another folder one for the labels one
76:37 - for the images i am sorry i know that i
76:40 - am doing a lot of things manually but i
76:42 - didn't want to do everything using
76:44 - python scripts because in sometimes you
76:46 - can do something wrong and everything
76:48 - went wrong because imagine with me if
76:50 - you mix only one
76:53 - one person which i mean if you ma you
76:56 - may you put wrong a one
76:59 - label means that everything will go
77:01 - wrong because in segmentation you need
77:03 - to be very precise it is not like any
77:06 - other thing
77:08 - it's not like any other task of computer
77:11 - vision so you need to be precise because
77:13 - if you skip only one slice or only one
77:16 - segmentation everything may be wrong
77:19 - okay for that i am doing much things uh
77:22 - manually so that i
77:24 - i will not make
77:26 - these things wrong there are some stuff
77:28 - that need to be using not need to be
77:31 - done using python scripts but for this i
77:34 - prefer to do it manually now as i told
77:36 - you i need to create a group a folder
77:39 - for labels i add another folder for the
77:42 - images so we just click here as i told
77:45 - you ctrl shift and n for new folder i
77:49 - will call it labels the first one and
77:52 - the second one for the images like this
77:56 - so now here i need to add
77:59 - labels
78:01 - okay so the input path is our labels
78:04 - when we have because for me i am using
78:06 - only two passings as i told you but you
78:09 - for you you have all the passings in
78:11 - your labels because here the confines i
78:13 - have only two passions but for you you
78:15 - have 130 if you use the same dataset or
78:18 - i don't know but you have all the labels
78:20 - that you have here and the output path
78:23 - is what we have created now beacon
78:25 - groups and labels now here where we will
78:28 - save our our
78:30 - groups of decons
78:32 - now to do this just run this one so to
78:35 - run it just click you can click in run
78:37 - or you can click on shift enter shift
78:40 - enter it will
78:42 - run this cell
78:44 - now
78:45 - to do this project we need to install
78:47 - some not projects but i am talking only
78:50 - about this part we will need some
78:52 - packages so the first one is globe so
78:55 - this package globe if you have already
78:57 - used it so you don't need to know what i
78:59 - am saying but if you haven't used before
79:01 - so we need is only to create some parts
79:04 - or to restore all the parts for example
79:07 - here i have this
79:09 - folder
79:12 - which has two passions so the globe
79:14 - function or the globe library will help
79:17 - us to
79:18 - restore the
79:19 - the whole link or the whole part so that
79:22 - we can open this folder and open this
79:25 - folder after you will understand when we
79:27 - will code it okay now i haven't
79:30 - installed it for this project so we need
79:32 - to install it to install in if you are
79:34 - using directly visual code or you are
79:37 - trying to install in a
79:40 - terminal just you need to click to
79:42 - put pip install
79:44 - then the name of the package for us it
79:46 - is glo but for me if you are using
79:49 - jupyter notebook so you need to add this
79:52 - mark okay because if you don't add it it
79:54 - will not work in jupyter notebook now if
79:57 - i will run this cell
79:59 - it will install there is something wrong
80:02 - could
80:04 - [Music]
80:17 - sometimes you can get something wrong we
80:19 - need to see about this why it is not
80:22 - installing
80:25 - now after that i checked because i don't
80:27 - know why i didn't notice that but when
80:30 - you want to install globe sorry about
80:32 - that but we need to check everything
80:34 - every time
80:36 - because i have installed this a long
80:38 - time ago for that i don't remember i
80:40 - didn't remember that i need to add this
80:42 - number two with the globe but that's
80:44 - that's what we need to do because this
80:46 - type of uh
80:48 - errors means there it is true that they
80:51 - are saying no matching distribution
80:52 - found for globe but what they are saying
80:55 - that there is nothing
80:56 - because they don't write that but there
80:58 - is there is no something like this
81:02 - library because the same thing if i i
81:04 - can put pip install i don't know one two
81:06 - three it will say it will give the same
81:08 - error it will not say that there is
81:10 - nothing called one two three but it will
81:12 - say that we couldn't find something
81:15 - matching with this version but that
81:18 - means that you are
81:20 - putting the name of the package wrong so
81:22 - you need to just choose because
81:24 - sometimes you can see the globe when you
81:26 - import it you just put import
81:28 - globe but when you install it there is
81:31 - something else all not all the packages
81:33 - but a lot of packages have this no
81:36 - problem but
81:37 - you need to see exactly
81:39 - what is the name that you need to use
81:41 - when you want to install for example
81:43 - pillow when you install it you click pip
81:45 - install pillow but when you import it
81:47 - you click just pip install pil so for
81:51 - that this is the same thing just click
81:52 - here pip install globe 2 then run it
81:59 - and now as you can see it is installed
82:02 - now there is no problem now the second
82:04 - package that we need to install is
82:06 - chantel
82:07 - shuttered sorry not chanted but because
82:09 - we need this package to move the
82:13 - files because what we will do we will
82:14 - move some
82:16 - lot some but we move 64 past 64 slices
82:20 - to a new folder which is a group of 64
82:23 - slices because i didn't want to just
82:25 - copy them because we will lose a lot of
82:27 - memory doing this copy and paste but i
82:30 - will move them so i will take them from
82:33 - the old
82:35 - directory and post them and put them
82:37 - into the new directory so for that we
82:40 - will use we need this
82:42 - library so pip install
82:45 - shuttle i hope that you need to use the
82:48 - same name maybe there is something else
82:50 - but we will see as you can see the same
82:51 - thing here so what we need to do is just
82:54 - to
82:54 - search for it
82:57 - how to install
83:00 - shuttle something like this
83:02 - and as you can see
83:04 - when you import it you use shuttle but
83:05 - when you want to install it there is by
83:08 - test shuttle so you cannot just install
83:10 - it as i was doing so just take the name
83:14 - and put it here
83:16 - pip install test shuttle now let's see
83:20 - how does it work
83:26 - it will take a few seconds and
83:28 - now everything is good so i will just
83:32 - delete this so to delete them just click
83:35 - on the cell and click two times on d to
83:39 - delete and the same thing for this
83:41 - because i we have already installed them
83:42 - so we don't need them there now we need
83:44 - to import them so import
83:46 - globe and import
83:50 - shut d
83:54 - like this
83:55 - but but what you need to do to know is
83:57 - in globe function
83:59 - this is the name of the package which is
84:01 - globe but the function that we need has
84:04 - the same name which is globe so for that
84:07 - when we want to use the globe we cannot
84:09 - just make glo use globe and deer
84:12 - function we need to import another
84:15 - function or another class called globe
84:17 - from globe
84:19 - that we will use i know that it is
84:21 - strange but that's it this is the
84:23 - package they created like this
84:25 - so we need to write from globe
84:28 - import globe
84:31 - because the same class are the same in
84:33 - the same package so that's what we need
84:35 - because if you take just globe you
84:37 - cannot access to the packages or to the
84:39 - functions that we will need so just run
84:42 - this now there is no problem with that
84:44 - now let's start coding or let's start
84:47 - creating the groups for that the first
84:49 - thing that we have to do is to create a
84:52 - good not a good but a big for loop
84:54 - because that for loop is the most thing
84:58 - that because
84:59 - what we are saying we are we want to
85:01 - pass by all the passions because we
85:03 - can't do it for only one person but we
85:05 - need to run the code each time for 130
85:08 - passes which is not good so we need to
85:11 - create a loop that passes by all the
85:13 - passions so for that we need to create
85:15 - just four
85:17 - and now passion which is a lever for for
85:20 - me i have two only two passes but for
85:22 - you you have everything but you don't
85:24 - need to care about that just for passing
85:27 - and we will use the path because you
85:29 - remember in the part here we have labels
85:32 - after that we'll use the images so in
85:34 - labels there are all the uh
85:37 - all the decon files that you have
85:39 - converted for now
85:41 - so what we have to do for passions in
85:44 - then here what we are saying in this
85:47 - folder but
85:48 - if we do this we will not have
85:51 - the
85:52 - because this in
85:54 - in part will be only one part but what
85:56 - we have to do we need a list of parts
85:59 - okay list of parts each part or each
86:02 - item of this list give us the part to
86:05 - one passion okay for that we need to use
86:08 - the globe this is the use of globe
86:10 - function so we have globe and when we
86:13 - put a part inside this parenthesis of
86:16 - the globe function what it will do it
86:19 - will return a list of
86:21 - all
86:22 - the items that it has in there in the
86:25 - directory not the list like os.list
86:29 - because here we are talking about lists
86:31 - of the parts not only the items so this
86:34 - is the role of globe function so what we
86:37 - have to do is in path
86:39 - input path
86:42 - but
86:43 - when you want to do this you need to
86:44 - specify which extension or which type of
86:48 - folders you want to put in this list so
86:51 - for that we need to add something like
86:53 - because always we have
86:55 - something or the name of the file that's
86:58 - the extension for example and i for the
87:00 - nifty but for us we don't have nifties
87:03 - but we have folders
87:04 - okay for that we don't need to specify
87:07 - the extension just put everything okay
87:10 - but this is something like this so what
87:12 - we are saying that in this input part
87:15 - slash everything
87:17 - if we want to say
87:18 - uh
87:19 - we want to specify the extension so we
87:21 - have to put everything that some that's
87:24 - the
87:25 - nifty for example this what does it mean
87:27 - everything which is we don't care about
87:30 - the names all the names or all the files
87:32 - that have the extension and ii take them
87:35 - but for us we said that we have folders
87:38 - so we need to take everything inside
87:40 - this folder so for passing globe in
87:50 - star means that everything inside that
87:52 - folder
87:54 - so this will return a list of
87:57 - folders now what we have to do is to
88:00 - start doing the conversion the first
88:03 - thing that i want to do is to return the
88:05 - patient's name so that we will use it
88:08 - after to save or to create a new folder
88:11 - for
88:12 - for each group of items because what we
88:15 - have what we will have for example we
88:17 - have a passion with 128
88:20 - slices so this passage will be divided
88:22 - into two groups the first group is 64.
88:25 - the second one is 64. so what we have to
88:28 - do we want to keep the same name of
88:30 - passing for example pass into one in our
88:32 - case we have lever zero lever one so we
88:34 - will keep the same name level zero but
88:38 - we need to add a underscore for example
88:41 - than one
88:42 - and two three etc which is the sub
88:45 - groups so you have the passion zero
88:48 - sl underscore one
88:51 - lever
88:52 - then passion one underscore two
88:56 - that pass into i don't know passing two
88:58 - underscore one etcetera etcetera
89:00 - etcetera so you will know always that
89:03 - this group of 64 belongs to this to the
89:06 - passions one or passing two etc but it
89:09 - is a subgroup of that passion okay i
89:12 - know that i am talking a lot but i am
89:14 - just trying to explain everything here
89:16 - so as i told you i need to return the
89:19 - name of that passages before that we
89:22 - have to add a
89:24 - another library that we'll use so import
89:27 - os
89:28 - and you should know that in each time
89:31 - you add something in that cell you need
89:33 - to run it again because if we don't run
89:35 - it this os will not be imported okay so
89:39 - now
89:40 - after that we did this what we have to
89:42 - do we have to return the passion's name
89:44 - so i will call it for example passion's
89:46 - name
89:48 - so as we said this loop will take the
89:50 - first passion will return its name to
89:53 - return its name that is a function in
89:55 - the os library so os
89:58 - dot path
89:59 - dot
90:00 - base name
90:03 - okay this one will return the base name
90:05 - which is the name of uh
90:08 - of our passions which when we say this
90:10 - base name means that we have all this
90:12 - part this is the base name
90:14 - the last item of the path is the base
90:16 - name and that's what we need because now
90:18 - we have label so this globe will do
90:21 - slash than the first passion so when we
90:24 - return the first uh i will show you
90:27 - something
90:28 - let me just click here below
90:32 - now let me do for example past scenes
90:37 - list
90:38 - equal
90:39 - glow
90:40 - then in path
90:44 - plus
90:46 - this so this as we said this is the uh
90:51 - this list of passions will have for us
90:53 - we have only two persons so now if i
90:55 - will i want to print for example print
90:59 - the first item of the list which should
91:01 - be the path to the first passion so we
91:04 - have passing list
91:07 - then as we said the first item of the
91:09 - list so zero the index zero now you can
91:12 - see that we will have
91:14 - the input path here
91:16 - plus the lever which is the first
91:18 - passion so that's what i was saying if i
91:20 - will put here one
91:23 - it will give us the lever one which is
91:25 - the second passing etc etc now we don't
91:28 - need this so i will delete it
91:31 - now i understand what will be this
91:33 - passing in the first iteration i i
91:36 - forget here in
91:37 - so
91:38 - you know that now in the first iteration
91:40 - we will have the first passing which is
91:42 - the part of the passing so labor slash
91:44 - level zero
91:46 - so what we will do we return that level
91:48 - zero the only the name which will be a
91:51 - string we will use it after
91:53 - for that what we have to do
91:55 - now
91:56 - inside the parenthesis we need to know
91:58 - to normalize our path in case we have
92:00 - any problem or something like this so os
92:02 - dot
92:03 - path
92:04 - dot norm
92:06 - path which is normalizing the path and
92:09 - put here the name of the passing which
92:11 - is this one or not the name but the
92:14 - parts of the passions so this function
92:17 - will normalize the path if and there is
92:19 - anything wrong with that
92:20 - then this function will return the name
92:23 - or the last item of the path which will
92:25 - be the name of the passage and it will
92:28 - be here we will need it after to create
92:30 - a folder and to save the groups in our
92:33 - case
92:34 - now
92:35 - after doing this what we have to do we
92:37 - need to specify or to know how many
92:39 - folders we have
92:41 - or how many groups we will divide our
92:43 - passions so if we have for percent with
92:46 - 160 28 for example slice it will be
92:49 - divided into two so we need to create
92:51 - two folders each folder for us for
92:54 - number of four the first 64 and second
92:57 - one same thing if we have more than that
93:00 - we have to create more than that more
93:02 - folders etc etc so before we need to to
93:05 - know how many folders we need for this
93:08 - for this first passage for example so to
93:10 - do this we have just create
93:13 - number of folders
93:17 - folders then what we need to do is to
93:20 - ins
93:21 - because why i am putting is because we
93:23 - need an integral number because if you
93:25 - have for example 130 you divide it by
93:28 - 64. it will be a float number but we
93:30 - cannot create a fluid float number of
93:33 - folders we need to an integral so we
93:36 - need to put everything inside the
93:37 - function int so that it will convert the
93:40 - final division into a in
93:43 - into an integer okay
93:45 - now what we have to do we have the
93:48 - because what we need to do we have a
93:50 - globe of the passing that we have which
93:52 - is this one
93:54 - this one is the globe of the passion
93:57 - this will return how many passions we
93:59 - have but now we need to know how many
94:02 - slices we have in that specific passion
94:05 - so we need to create another globe which
94:08 - will be something like this globe but
94:10 - now we are not talking about the in
94:13 - the in part which is the input path now
94:16 - we are talking about the patch of that
94:18 - specific persians so globe of passions
94:22 - plus
94:24 - uh
94:25 - slash as
94:26 - slash forward slash then star which
94:29 - means everything we can here specify
94:31 - everything that's decom but we don't
94:33 - need to do that because we know that we
94:34 - don't have jpeg images or something like
94:36 - that in our folders so everything inside
94:40 - the part
94:41 - of the of the passing which are or
94:43 - everything is dcom so the globe will
94:46 - return a list of
94:48 - all that
94:51 - it will return a list of all that
94:53 - passions not passive but slices decom
94:55 - slices now what we have to do we need to
94:58 - know how many uh
95:01 - which will be sparked but we know we
95:02 - need to we need to know how many percent
95:05 - we have how many slices we have to do
95:08 - that we need to to
95:10 - calculate the length of
95:12 - this
95:12 - uh of this list because as i said globe
95:17 - will return a list of parts of each
95:19 - slice now we need to
95:21 - take this
95:23 - one here and calculate the length of
95:26 - this list which will be list of but i
95:30 - will just control x
95:32 - so land the same thing here so we
95:35 - calculate the land so let's what will be
95:37 - the land
95:38 - for example if we have 100 slices we
95:41 - will have 100
95:43 - 100
95:44 - parts which will be a list of 100 item
95:48 - now this is the length which will return
95:50 - it will return 100 because as we said we
95:53 - have 100
95:54 - now we need to divide it by the number
95:56 - of slices that we want to create which
95:59 - is 64 in our case so divided by 64 here
96:04 - so when we divide by 64 means that we
96:08 - will know how many folders we want for
96:10 - us we are putting here integers okay
96:13 - this 64 we can leave it 64.65 we can
96:17 - leave it 64 or we can create a
96:20 - variable for example that takes the
96:22 - number 64. then we use it but we don't
96:25 - care about that we will put it 64 but
96:27 - because as i told you i will give you
96:29 - the code at the end of this course and
96:31 - everything will be clean and all these
96:34 - for loops etc will be inside functions
96:36 - but you can you can just call them and i
96:39 - will show you how you can clone the
96:41 - github repository etc but at the end for
96:43 - now i am just explaining how does it
96:45 - look how does it work in case you have
96:48 - problems in case something differs from
96:51 - your project to my project in that case
96:53 - you can know how to fix these problems
96:55 - okay otherwise you can just use the
96:58 - final part of this course using github
97:00 - cloud repository and no problem with
97:03 - that
97:04 - now
97:05 - as i was saying this number of folders
97:08 - we needed to know how many folders we
97:10 - need to create so or how and not all and
97:13 - and i am saying and in how many groups
97:16 - we need to divide our passions now after
97:19 - having this number of slices what we
97:22 - need to do we need to move the
97:24 - slices from
97:26 - the specific folder which is here
97:30 - [Music]
97:31 - for example here we have all the slices
97:33 - what we need to do we need to take 64
97:35 - from them and move them into a folder
97:38 - that we will create which will be a
97:40 - subfolder or subpassion of lever zero so
97:44 - now let's start doing that loop so it
97:47 - will be a for loop that range does go
97:50 - goes from how many folders at first
97:52 - because what we need to do we need to
97:54 - create the folder first and move the uh
97:58 - passing or the slices from the
98:01 - from each person into that folder that
98:04 - we have created so what we need to do we
98:07 - have to create at first they pass the
98:09 - folder where we want to to put the
98:12 - slices for that what we have to do we
98:14 - have four
98:15 - e in range for example
98:18 - now we said that we need to know how
98:20 - many paths how many folders we need to
98:22 - create so we have number
98:24 - of folders
98:27 - so
98:28 - we will pass by the number of folders we
98:31 - if we have four
98:33 - if this value equal to four which is the
98:35 - number of folders will be four so we
98:38 - this for loop will pass four times if we
98:40 - create the
98:41 - folder then we will write the part where
98:44 - we will move the
98:46 - slices into that folder but now we have
98:49 - to go
98:50 - step by step now we have to do that
98:53 - after doing this we need to create
98:56 - a directory but before that we need to
98:59 - specify what what is the final or the
99:02 - part
99:03 - of the output which means how
99:07 - where we want and how do we call the
99:10 - folder of our outputs of our of our
99:13 - group so what we will do here we need to
99:16 - give a name for example output
99:20 - but for example or output path name
99:23 - something like this what we have to do
99:26 - we need just to
99:27 - we will reconstruct it because we have
99:30 - the output part which is this one this
99:32 - one is the final output part where we
99:35 - want to put everything but
99:37 - we don't need to put just here we need
99:40 - to create another subfolder which will
99:42 - have the same name of the passing which
99:45 - is this one plus a underscore and the
99:48 - sub folder which will be the i the i
99:51 - here so it will be 0 1 2 3 etc
99:55 - so to do it is just to put here
99:58 - os
100:00 - dot path dot
100:02 - join this function always that part that
100:05 - join is something that just to join two
100:07 - folder two parts for example i have path
100:10 - one
100:11 - slash
100:12 - part two
100:13 - comma sorry
100:15 - if i have this so this from this
100:17 - function always that part that's joined
100:20 - what it will do it will do just part one
100:23 - slash
100:24 - but two that's what it will do this uh
100:27 - function so we don't need to worry about
100:30 - it
100:32 - so for us what we have we have the final
100:34 - output there which is out
100:38 - there outputs
100:40 - this one which have we have i have i am
100:43 - putting here then this is the main
100:46 - output of the labels then we need to put
100:49 - the name of the passion which will be
100:51 - here passion name
100:53 - then we need to add the underscore plus
100:56 - the sub folder which is here plus it is
101:00 - a string so we don't need to think about
101:02 - it you can we can put just plus here and
101:04 - it will add it to the part so plus and
101:08 - we said we have underscore then the name
101:11 - of uh not the name but the index of that
101:14 - subfolder so which will be the i here
101:18 - but now i is a antigua we need to
101:21 - convert it into string to do it is just
101:23 - to call the function str
101:26 - and i so what does it mean this it will
101:30 - create something we just i will run it
101:33 - to show you how does it look
101:35 - i have here print out put
101:40 - but name you will see what does it look
101:43 - this one just run it it will create this
101:46 - part which which doesn't exist for now
101:49 - for now we have this part which exists
101:52 - which is this is the output here output
101:54 - part but now we added this lever zero
101:57 - this is the name of the first passion
102:00 - and this is the underscore zero and now
102:03 - here it should be underscore one but for
102:07 - our case if we have a number of passes
102:10 - so i want just to say see something i
102:13 - think there is something wrong here
102:16 - because we should have zero and one not
102:19 - zero one here because we didn't go to
102:21 - the next one
102:23 - otherwise even maybe the
102:26 - i would just ah i know why because
102:29 - here we have for this first passing we
102:32 - have 76
102:33 - uh
102:35 - slices okay so the first passion we will
102:38 - create the first because when we divide
102:40 - this by 64 it will give us one one comma
102:44 - something in that case we cannot create
102:46 - one comma something folders we create an
102:48 - antigen folder it should be one folder
102:50 - so we will we will take 64 first passing
102:53 - but the other 10 we don't need them and
102:55 - in this case you don't worry about the
102:57 - 10 slices is not a problem okay
103:00 - so
103:01 - this is why we have only one
103:04 - one passing one
103:05 - subfolder
103:07 - and same thing for the second one here
103:10 - we have
103:11 - 123 so in this in this case for example
103:14 - it will take the
103:17 - first
103:18 - 64 slices but the others it will not
103:20 - take them okay but don't worry about
103:22 - this there is no problem i am taking 64
103:25 - because there is other passing that are
103:28 - having less than that we can put a
103:30 - number less than this for example we can
103:32 - put 50 or something but i don't think
103:34 - that it is a good idea because we lose
103:37 - some information for us in average in my
103:40 - case i took this number of slices
103:43 - because here if i will take for example
103:46 - 50 so in the first passing i will lose
103:49 - more than
103:51 - more than when i was 64 because if i
103:54 - will use 50 so i will lose 25 slices
103:57 - here so and the more we go with small
104:01 - number of slices more than the training
104:03 - will be
104:05 - will be slow and it will be it won't be
104:07 - accurate because we will put only number
104:10 - of slices like 30 or 40 it will not be
104:13 - something
104:14 - very accurate so the more slices we put
104:17 - the more better we have because in my
104:20 - project in another project where i was
104:22 - doing tumor segmentation i was using a
104:24 - groups of 128 slices because i had
104:28 - passage with much number of slices for
104:31 - that i could use
104:32 - 128 slices and it was very good number i
104:36 - tried more than that and less than that
104:38 - but it was 128
104:40 - the best one if we if i put more than
104:43 - that it can be good accurate but it will
104:45 - take time talking about the training
104:48 - time
104:49 - the training because when we launch the
104:51 - training you will see that it will take
104:53 - time so more the more the
104:56 - number of slices you take more than the
104:59 - epoch will take time in each each time
105:02 - okay
105:03 - so for that i don't recommend you to
105:05 - take a very large number and not very
105:08 - low number
105:10 - in some cases you will lose some slices
105:12 - but it is okay don't worry about that so
105:15 - for that i am using 64 here now you see
105:19 - what will happen about this
105:21 - name just what we need to do that what
105:24 - this function will do just to create
105:26 - this name now what we have to do because
105:29 - as i told you this part doesn't exist so
105:31 - we need to make it exist so we need to
105:33 - create a folder with this part so that
105:36 - we can save our slices in this part so
105:39 - to do this
105:40 - just use the os library so os that's
105:45 - amca the which is make directory and
105:48 - here what we need to do of course the
105:51 - output
105:52 - parts name so this
105:56 - os
105:57 - library will make directory for this
106:00 - output
106:02 - part name so we will have these two
106:04 - folders created for me i have only two
106:07 - but imagine with me you have 131 or 30
106:10 - baskets or more than that so
106:13 - this function or this loop will create
106:16 - folders for each group of bastions don't
106:19 - worry about this now after doing this
106:22 - what i have to do is now after making or
106:25 - after creating the the folder we need to
106:28 - move the images into that folder so to
106:32 - do this it is easy just we have four
106:35 - now we have
106:37 - we this because this first loop will
106:39 - pass by all the passions and this one
106:43 - will pass by all the groups or all the
106:46 - sub folders now we will pass by all the
106:50 - the files or all the slices that we have
106:53 - in each passion so what we have to do is
106:56 - just we have e because what we need to
106:58 - do we need to know where or when the
107:02 - file is
107:04 - when we are more because
107:07 - i'm saying that if we have something
107:09 - like
107:10 - we need to know in which index we are we
107:12 - are so that we can stop the loop when we
107:15 - pass the 64 uh slices so here we have
107:18 - four e because i tell how to use i will
107:21 - need it then i need to refer to the file
107:24 - because
107:25 - this e is the only the index but now i'm
107:28 - going to talk about the file which is
107:29 - the confirm so for e and file of course
107:33 - in because when we use only one variable
107:36 - here we use the range but now we are
107:39 - using two
107:40 - which i am talking about two
107:42 - the first one will take the index and
107:44 - the second one will take the five so we
107:46 - need to use the enumerate
107:48 - enumerate
107:53 - rate function and now here what we have
107:56 - to put that we have only the name of the
107:59 - passions with the part but before doing
108:01 - this we need to know always the path
108:04 - the passion sorry
108:06 - but
108:07 - when we we have a uh a
108:10 - we if i will put only the passings it
108:12 - will be just the folder but what we need
108:15 - to do we have to return all we have to
108:18 - return the list of the passings the same
108:20 - thing that we did just here we have the
108:23 - globe and because this one will globe
108:26 - and passing plus this star it will
108:29 - return all the passions or all the
108:32 - slices that we have in the group or in
108:35 - this folder or passions so i just need
108:38 - to copy this
108:40 - put it here
108:43 - so what we are saying now
108:45 - four
108:46 - e and five in enumerate so this file
108:50 - will have the
108:52 - the the part of each d com slice of the
108:56 - first pass hint for example in the first
108:58 - iteration so what we need to do we need
109:00 - to take it return it and then after that
109:03 - we need to move it into the new folder
109:06 - or to the folder that we have created so
109:09 - what we have to do
109:10 - now
109:12 - after
109:12 - taking the iteration from the group we
109:14 - need to move it so to move this
109:17 - file we have to use as i told you the
109:20 - function
109:22 - sharp till like this so shots will have
109:25 - a function called move this move
109:27 - function will move the file to
109:31 - the uh directory that we want which is
109:33 - now here we have the file and the
109:35 - directory or the output file will be
109:38 - here the output the folder folder that
109:41 - we have created the output part name so
109:45 - what i am saying here we have created
109:47 - the file now we will pass by all the
109:51 - files or all the decon files of that
109:53 - specific passing and move them into that
109:58 - into that folder which is the output
110:00 - name for name but there is nothing here
110:02 - that stops the loop we need something
110:04 - that stops the loop so how to stop it we
110:07 - need to know where we this the
110:09 - iterations of the loop are in the same
110:12 - uh number of slices that we specified
110:14 - which is 64. but we need to do it before
110:17 - moving because if we are already passing
110:20 - the 64 slices we don't need to move
110:23 - other by other slices so just here put
110:27 - but now we need to put here if
110:30 - we said that the i here is the index of
110:33 - the slices which is the iterations so if
110:36 - i
110:37 - equal to the number of slices which is
110:40 - in our case 64 plus one which is when we
110:43 - pass it by one we need to stop the loop
110:46 - which is using the break
110:49 - function so when we call the break it
110:51 - will stop this loop which means we will
110:54 - not move more slices and it will go back
110:57 - here and go to the next iteration to
111:01 - move the new uh
111:03 - so it will go to new iteration it will
111:06 - create a new subfolder and move the next
111:10 - 64 slices to the next to that new
111:13 - subfolder etcetera etcetera until
111:16 - finishing all the subfolders and go
111:18 - moves to the next passions etc etc now
111:21 - let's try this and see how what does it
111:24 - do so just put here
111:27 - and you can see that now it is done
111:29 - let's see
111:31 - our folders
111:35 - as we said here we have liver and we
111:38 - have decon files labels and you can see
111:41 - that it has created the lever zero we
111:44 - said that we couldn't create lever one
111:46 - because there is not enough number of
111:48 - slices to create it so we have zero and
111:51 - if we go we have 64 65 number 65 slices
111:55 - okay i think that i miss one so i maybe
111:58 - we can just leave that
112:02 - this one i can just leave it on but not
112:04 - a problem 64 or 65 not a problem but you
112:08 - can see here that we have created
112:11 - groups of 65 slices for this one and for
112:15 - this one and everything and if you have
112:18 - more than that i am i am using for
112:21 - example only two two buttons to show you
112:23 - but if you have more than that you will
112:25 - see that it will create number of
112:27 - folders or subfolders of each passion so
112:31 - if you have a spacing with 600 slices so
112:34 - it will create i don't know 10
112:37 - 10 or less maybe eight eight or seven
112:40 - subfolders each subfolder contain 65
112:45 - number of slices and of course if you
112:47 - want to change this number of slices
112:49 - just change this number which is 64 here
112:52 - just changes i i didn't make a variable
112:55 - for that because i told you that i am
112:57 - just showing you but at the end of the
112:59 - course you will get a full function that
113:01 - has
113:02 - at the inputs the input path output part
113:05 - the number of slices and it will do
113:07 - everything so that was how to create the
113:11 - the decom groups now the next step is to
113:14 - convert these decom groups and of course
113:17 - i forget to to say that now what we have
113:20 - we did for the labels now we we need to
113:22 - do it for the images so what you need to
113:24 - do just to change here
113:26 - instead of labels you put images
113:30 - and the same thing here
113:33 - images and if i will re-run it this
113:36 - again this we don't need to run but
113:38 - otherwise
113:39 - now if i will run this again
113:42 - it will do the same thing but for
113:45 - the images now we have the labels if i
113:47 - will go to the images you can see that
113:50 - it has created folders with 65 slices so
113:54 - that's what all you need to do create
113:56 - put here labels and after that you need
114:00 - to put images and it will do for all
114:02 - your passions after doing all this now
114:04 - we will go to the next step as i was
114:07 - saying to convert this nifty group to 65
114:11 - i just need to change this because i
114:14 - made this wrong so i need 2.65
114:17 - now we have 60 groups of 65 slices we
114:20 - need to convert them into nifty files so
114:23 - that's what we will do in the next step
114:27 - now
114:28 - let's talk about how to convert the
114:30 - deconfiles that we have created which
114:32 - are 65 slices into one nifty
114:37 - file which we will use uh for the
114:40 - training etc etc
114:42 - so to do that there is only one function
114:44 - and you can do it in one line i am
114:47 - talking about only one file nifty file
114:49 - we can do it in one line and
114:52 - which we have
114:53 - multiple files we can create a loop to
114:55 - do that
114:56 - let's do it step by step with you i
114:58 - didn't want to write it and start
115:00 - talking about it i prefer to write these
115:03 - lines of code with you so that you
115:04 - understand understand each line what
115:06 - what what we are doing with each line of
115:08 - code and of course at the end i will
115:10 - provide the final code only in the
115:13 - training part it will be a very big loop
115:15 - for that i need to write it before start
115:18 - explaining but all these problems
115:21 - pre-processing parts i will explain them
115:23 - like this and i will write the code with
115:25 - you and if i will make some mistakes you
115:28 - will see it live with me so that you
115:30 - will not do these mistakes okay
115:33 - so to do this conversion that we will
115:35 - need a package called dcom to nifty so
115:39 - this library the continuity will do all
115:42 - the work so if you don't already have it
115:45 - installed on your pc we need you can
115:47 - install it using pip install
115:50 - here since we are using jupyter notebook
115:52 - so we need to add this
115:54 - and pip install and then rewrite the
115:58 - name of the library or or of the package
116:02 - for us i said that it is dcom
116:04 - to
116:05 - nifty something like this so when you do
116:08 - it we will run this cell if you want to
116:11 - run the cell here just click on shift
116:13 - enter and it will be run
116:15 - and we'll wait a little bit when you see
116:18 - this star here means that this cell is
116:20 - running we'll wait until this is the
116:23 - only problem with jupiter notebook you
116:25 - cannot see all the execution lines or
116:28 - what is happening you can just see the
116:30 - final
116:32 - output here and as you can see we have
116:34 - successfully installed nifty to decal
116:37 - so after installing it i will just
116:39 - delete this by clicking on the cell and
116:42 - click two times on the
116:44 - two times and it will delete the cell
116:47 - now let's import it here what we have to
116:50 - do just we click import
116:52 - dcom
116:53 - to
116:54 - nifty and we will run the cell because
116:58 - we need to we will need these two
117:00 - libraries os or basic operating system
117:03 - just to create the paths and this d com
117:06 - file or yes and this d com just
117:09 - we needed to do the conversion
117:11 - so the thing that you need to know is
117:14 - when we
117:15 - will use this library we need only one
117:18 - function called dcom series to nifty
117:21 - that there is another function but i
117:23 - don't recommend you to use it because it
117:24 - will not give you the access to
117:27 - to make it or to rename your files which
117:30 - mean if you have only one nifty file
117:32 - that you want to create you can use that
117:34 - function and in that case i don't
117:36 - remember the name of this function but
117:38 - i think it is the com
117:41 - the community but i think it will
117:43 - convert repository but uh i i don't
117:46 - recommend you to use it because as i
117:49 - told you if you have only one passive it
117:51 - is okay but if you have multiple
117:53 - passions you will not have the access to
117:56 - change the name or to specify the name
117:58 - of each passion so in this in this case
118:00 - if you have ten passions it will use the
118:03 - same name for all the passions in that
118:05 - case you will see only the final
118:06 - passings for that case you need to use
118:09 - the
118:10 - decom series to nifty so this function
118:13 - will has two parameters the first one is
118:16 - the part of the folder where you have
118:18 - your nifties and the second parameter is
118:21 - the part where you have
118:23 - when you want to save your nifties plus
118:26 - of course the name
118:28 - of your file
118:29 - now
118:30 - let's talk about
118:32 - our data here we have
118:34 - code
118:36 - the control nifties
118:38 - i don't remember what i put it
118:41 - is here level
118:43 - then the confines
118:45 - and when we did the confines we created
118:48 - the dcom groups we have the images and
118:51 - the labels here so the images and as i
118:54 - showed you i am using only two passions
118:56 - because i don't want to waste time
118:58 - running all these codes because i have
119:01 - already created and prepared all the
119:03 - data so i am using only two so that you
119:06 - can see but don't worry about that
119:08 - because the loops that i am creating
119:10 - will pass by all the passing so if you
119:12 - have two it will cover two if you have
119:14 - ten it will contain ten if you have 100
119:16 - it will convert 100 so don't worry about
119:18 - that
119:19 - so as i told you we have two parts we
119:21 - need to convert for the images and for
119:24 - for the labels to do it what we have to
119:26 - do is just to take the part here
119:30 - so this part is the common part which
119:33 - that is the images and there is labels
119:36 - we will need it let's write it just here
119:38 - so i will write for example
119:42 - in
119:43 - path
119:44 - something like this
119:46 - and let's just save it and i recommend
119:48 - you to use the forward slashes because
119:52 - sometimes the backward slash make
119:55 - problems not for example here but if you
119:57 - have
119:58 - slash
119:59 - r or slash t or slash n it will make a
120:02 - problem so i recommend you to use these
120:05 - slashes
120:07 - forward slash so now
120:10 - this path is the part where there is the
120:13 - images and the labels now let's start by
120:16 - converting the images
120:18 - and you can see that in the folder of
120:20 - images there is two folders this folder
120:22 - contains 65 slices and second one as
120:25 - well now what we have to do what
120:28 - we will start by the images for example
120:30 - let's put here to make it easy we can
120:32 - just use the os but to make it easy here
120:35 - let's make images so this part is for
120:39 - the images
120:40 - let's
120:41 - make here
120:43 - images the same thing for
120:48 - for the labels
120:57 - something like this and the folder
120:59 - called i don't know label labels
121:04 - with s
121:06 - something like this so now we have the
121:09 - the parts of the input images and the
121:11 - inputs labels and you remember that in
121:14 - each part of these there is or there are
121:17 - uh all the uh
121:19 - all the passions or which are all the
121:22 - folders that having group of slices of
121:26 - each passion as like this here
121:28 - now
121:29 - what we need to do we need to return a
121:31 - list that has part of this file or this
121:35 - folder and part of this folder etc etc
121:38 - so if you remember we used this type of
121:41 - uh
121:42 - of
121:43 - groups of or of
121:45 - make of returning all the group of all
121:49 - the files or all the folders from each
121:51 - from a specific folder using this
121:55 - kind of functions because we said that
121:57 - globe when we put globe and we put a
122:00 - path inside that globe function and we
122:03 - add this forward slash then star means
122:06 - that this globe
122:08 - function will return a list of parts of
122:11 - all the files inside that folder so for
122:14 - us for example we have this part of
122:17 - images so the globe function of this
122:20 - part
122:21 - will return
122:22 - to will return a list of two files or
122:25 - two items the first item is the folder
122:28 - of this file and the second item would
122:30 - be a folder of this file like this so
122:34 - that's what we'll do so to make it easy
122:36 - what we can do we can just add the globe
122:40 - here but before that we need to add the
122:42 - forward slash star means that everything
122:45 - that uh that is in that folder which is
122:48 - images and here the same thing
122:50 - everything in the labels
122:52 - now we as i told you i need to return
122:55 - because here now we are writing the
122:57 - paths and the parts so the preferably we
123:00 - will not write it at the same line but
123:02 - you get it you can write everything in
123:04 - one line but i don't want to do it so
123:06 - that's just
123:07 - maybe some of you are not familiar with
123:09 - python so preferably i will write
123:11 - everything in each each thing in
123:14 - specific lines so that you understand
123:16 - how did we go from
123:18 - from the step to the next step etc etc
123:20 - okay so here we can create a new
123:23 - variable called list of images
123:27 - something like this
123:28 - and as i told you we could do it in the
123:31 - first line but i just want you to see
123:33 - how we will use this part to create the
123:36 - list and how we would use the list to
123:37 - create the nifty files now here as i
123:40 - told you we have globe and in the globe
123:42 - function what we will do we put only the
123:45 - parts
123:46 - for example now in images so this one
123:49 - here if i will run this code if i will
123:52 - put here list
123:54 - images if i will run this one as you can
123:57 - see as i told you we have two parts the
123:59 - first one is for the first passion and
124:02 - the second one is for the second and
124:04 - here we have images and the same thing
124:06 - for the
124:07 - for the labels if we create lists
124:11 - labels
124:15 - labels then here we have globe and in
124:19 - path
124:22 - i don't know what i can type
124:25 - labels okay now if we do the same thing
124:28 - here i will just put labels
124:36 - and now as you can see the same thing we
124:38 - have first passing second passing but
124:40 - here we have labels now these two lists
124:44 - contains the folders of each uh of the
124:47 - passing of each for the images and for
124:50 - the labels now after doing this we need
124:53 - i will delete this now what we need to
124:55 - do is just to convert each folder so the
124:58 - function i will just write write it here
125:01 - the function is d com
125:03 - to
125:05 - nifty as i told you the same name of the
125:07 - library now what we have to do is just
125:10 - to write the name of the function that
125:12 - we will use and as i told you the
125:14 - function is d com to the d com series to
125:18 - nifty so when we are we are using a
125:21 - library we want to call it to call a
125:23 - function you can just write decode
125:26 - then
125:27 - series
125:29 - then 2 then
125:30 - [Music]
125:32 - nifty very easy dcom series to nifty
125:36 - very easy function if you are using
125:38 - visual studio code maybe
125:40 - the the editor will suggest it for you
125:42 - but as you can see it is easy the com
125:44 - series to nifty this is the name of the
125:46 - function if it doesn't exist you will
125:48 - got an error but just try to search for
125:51 - it but this is the name the comp series
125:53 - to nifty as i told you there is two
125:55 - parameters or there are two parameters
125:57 - the first parameter is is when we put
126:00 - the input folder
126:02 - the folder that contains all the nifty
126:04 - files
126:05 - and the second parameter will contain
126:07 - the path where you want to save your
126:10 - nifty file and where
126:12 - and what is the name of your
126:14 - output which is 95 so the first thing as
126:18 - we said is the input part
126:21 - here we have this list which contains
126:23 - two parts and these two parts are the
126:26 - input parts that we need so if we take
126:29 - for example
126:31 - list
126:32 - images
126:33 - and we put something like zero means
126:35 - that we are talking about the first part
126:37 - if we want to take talk about the second
126:40 - one we will put one if you have 100 you
126:42 - put 100 or 99 because it starts from
126:45 - zero so 99 means the final or the last
126:49 - uh passing that you have in your 500
126:51 - passengers so that means that this
126:54 - indexes will change the
126:56 - passing that we want to convert
126:59 - and in our case we said that we have i
127:01 - have two but i will not just just put
127:03 - zero and then put one because it is not
127:06 - general for us i want to write a generic
127:08 - code for everyone if you have two three
127:10 - four five any number of passings you
127:13 - have it will work for you i am talking
127:15 - about the code
127:16 - for that we need to pass this
127:20 - this function because this function will
127:21 - do everything all what we need to do is
127:24 - to create a loop that will pass by all
127:26 - the passions so for that case
127:28 - what i will do
127:30 - i will just write here for
127:32 - passions for example
127:35 - in
127:36 - then we said that in what in all the
127:40 - files that we have or all the passing
127:42 - that we have and the passion that we
127:43 - have we have we have the same thing for
127:46 - me i have two but we have two folders we
127:48 - have images and labels let's start by
127:50 - images then we will go to labels so the
127:53 - parts that we have are here list
127:56 - images
127:57 - this first one
127:59 - this first list contain the parts of the
128:01 - images then
128:03 - here we will put the same thing with the
128:05 - columns
128:06 - and just make space now
128:10 - this function this for loop will pass by
128:13 - my two passions for you you have more
128:15 - than that so it will do it for you
128:18 - now before doing that we need to create
128:19 - the output files or the output
128:22 - parts okay
128:24 - to do it what we need to do we can just
128:26 - do it manually or you can write a code i
128:28 - prefer doing my doing it manually
128:31 - because you so that you will know where
128:33 - you are where you are saving your uh
128:36 - your files so for me i will start by
128:39 - creating a new folder here
128:42 - i will give it the name for example
128:44 - nifty
128:46 - files so now we will have the nifty
128:49 - exact final nifty files in this
128:52 - in this folder now let's go and create
128:55 - two folders one for the images and one
128:57 - for the label
128:59 - so let's start by images
129:02 - and the next one is for
129:07 - labels okay now we have i will take just
129:11 - this part
129:14 - then we will add images and labels
129:18 - we can we can write it here
129:20 - so out
129:22 - path
129:23 - images something like this
129:26 - and now let's do
129:28 - the thing i know that i am writing
129:30 - everything here like maybe we don't need
129:33 - to write everything here we can make a
129:35 - script that does that create the folder
129:37 - and does everything but as i told you
129:39 - maybe some of you are not familiar with
129:42 - python so i prefer to use this so you
129:44 - will understand what why i am doing this
129:46 - and maybe
129:48 - you maybe if you are trying your this
129:50 - code because that happens to me when you
129:52 - are trying to use a code of someone else
129:54 - and you will get an error in your code
129:57 - and you will not understand where this
129:59 - error comes from because you you it is
130:02 - it wasn't you who write the code and you
130:04 - don't know where what are the steps and
130:07 - how can you fix your error etc etc for
130:10 - that case i am trying to write it with
130:11 - you so if you use it it doesn't work for
130:14 - yours for your task you will know how to
130:17 - change something how to change the
130:18 - folders or how to change the files etc
130:21 - etc for that i am taking time for that
130:23 - but sorry about this because i didn't
130:26 - like the old the old way which is just
130:29 - writing the code and give it to you
130:30 - because i don't prefer it okay
130:33 - now
130:35 - as i said we have images and the same
130:37 - thing for the labels i will just copy
130:40 - this and paste it
130:45 - here we have labels
130:48 - and the same thing here
130:52 - labels okay
130:54 - now after doing this what we have to do
130:57 - just to i will just rerun this because
131:00 - we need to
131:01 - save these files in the system now as i
131:04 - told you we have to
131:06 - pass by all the passions but before
131:08 - doing this as i told you here we have
131:11 - two parts or two parameters the first
131:14 - one will take the inputs folder the
131:16 - second one will take the output folder
131:19 - so for the input folder as we said we
131:21 - have parts that are in this list so here
131:25 - we have passions
131:27 - so because in each iteration
131:29 - this variable passions will take one
131:31 - part from the list so if you have one it
131:33 - will be of the only one if you have two
131:35 - it will turn two times the first part
131:37 - then the second part if you have ten
131:40 - parts or ten passions it will run t ten
131:42 - times etc etc for that case the first
131:46 - thing here we will put only the part of
131:48 - this uh passion
131:50 - then the next parameter or yeah next
131:52 - parameter on that argument will take the
131:55 - output path plus the name of your
131:57 - passion so the output part here because
131:59 - we are taking talking about the images
132:01 - so the output part here is the image so
132:04 - we can use something like os.pat
132:07 - dot join
132:09 - why i am using this so that we can join
132:11 - the output part plus the name of your
132:14 - passions so in this case the output part
132:16 - here for the images is out but then
132:20 - images this is the output part of the
132:22 - images then the name of your passions we
132:26 - will we need to return it we can just
132:28 - make uh
132:30 - the i here from the index and make
132:32 - passion 0 1 2 3 etc but maybe in some
132:36 - time because here there is something we
132:38 - need to talk about here for example not
132:41 - liver in the groups imagine with me you
132:44 - have maybe 10 or 100 passions and for
132:48 - example for the first person you have
132:50 - two groups so you have level 0 0 level 0
132:54 - 1 level 0 2 3 etc so something like this
132:58 - and at the end you want to know
133:01 - which path is exact because you have
133:03 - created maybe three or four groups but
133:06 - all of these groups belongs to the same
133:08 - passions so maybe at the end you want to
133:11 - know which person had that problem and
133:14 - i will not say maybe because you need it
133:16 - you should know because when you want to
133:19 - say that this passing for example if you
133:21 - are doing tumor segmentation you will
133:23 - you need to know which person has tumor
133:26 - so because if you just create groups and
133:28 - rename them you will not know at the end
133:31 - which pass it has tumor for that when
133:33 - you create these groups you need to know
133:36 - at the end which uh
133:38 - which passions for that you need to save
133:40 - the name of the passion plus the index
133:42 - for that case here when we will do the
133:44 - conversion we will not change the name
133:46 - we'll just extract as we did here
133:49 - you remember you remember here
133:51 - not this one remember this line what we
133:54 - did here just we returned the name of
133:56 - the pass hand and we'll do the same
133:58 - thing we'll return the name of the
133:59 - passage and use it in the saving here so
134:02 - i will just copy this
134:04 - and paste it in my for loop and now i
134:08 - have the password is the same because we
134:10 - are using the same this is very good
134:12 - thing when you do unique stuff so you in
134:15 - each if you will write 200 lines of code
134:18 - you will remember the name of variables
134:20 - because if you put multiple and or
134:22 - random
134:23 - names of variables you will get problems
134:26 - at the end of your uh coding because
134:30 - in some in some case maybe we are coding
134:32 - now after one month you want to read
134:33 - your code you will not understand what
134:35 - this variable is doing because all of us
134:38 - had that problem that calling your
134:40 - variables a equal and it will work but
134:44 - as i told you after one month if you
134:45 - will read your code you will not
134:46 - understand why did you put that for that
134:48 - i am putting in images in past images
134:51 - output images labels etc etcetera
134:54 - so
134:55 - now here we have the outward spots we
134:57 - need to join it with the name of the
135:00 - passion which is here passion's
135:03 - name
135:04 - and that's it passion's name but there
135:07 - is something else passing's name will be
135:09 - only the name of the folder which will
135:11 - be lever
135:12 - here for example lever 0-0
135:16 - underscore 0 not that sorry so
135:19 - but we need the extension because this
135:21 - is the name of the passions so if we
135:23 - have images we need to put dots jpeg
135:26 - that's png that's steve etc and for our
135:29 - case we need to put the uh
135:32 - the extension of our of our files which
135:35 - are nifties for that case we need to add
135:38 - the extension which is a string of
135:40 - course so that's nii
135:43 - if you put just that and i i it will
135:45 - create a nifty file but it will not be
135:47 - compressed if you need to compress you
135:49 - need you need to compress it after but
135:52 - you can just add dot
135:54 - z if you do it like this it will convert
135:57 - the d columns into nifties and compress
136:00 - them at the same time so if you don't
136:02 - need the compressed files you can't put
136:04 - just that's an ii
136:06 - but if you need them converted so you
136:08 - need to put that g z
136:10 - something like this so now this loop it
136:12 - will convert all the passions or all the
136:14 - images or the passions but the images or
136:17 - their volumes
136:18 - then we will do the same thing for the
136:20 - labels so just let's run this
136:23 - and you can see that we have star here
136:25 - saying that this cell is running
136:28 - so it will not take a lot of time so
136:31 - don't worry about that
136:32 - let's just wait so that's it now let's
136:35 - go to our
136:37 - nifty files images and these are our two
136:41 - files that we have created let's try to
136:44 - open one of them we have 3d slices there
136:49 - just to make sure that the files that we
136:50 - have created are
136:52 - good let's try it
136:55 - [Music]
136:56 - it will open in any second now
137:07 - so
137:08 - let's take for example the first one
137:10 - drag it here
137:12 - and you can see that we have only
137:15 - the maximum here is 64 which is which
137:18 - starts from 0 into 64 which are 65
137:21 - slices so these are the slices that we
137:24 - have created and this is the good point
137:28 - because you will have unique number of
137:29 - slices for all the passions so in this
137:31 - case in the training you will not have
137:33 - any problem with your data
137:36 - so now we are making sure that the
137:38 - function is great correct everything is
137:41 - good let's do the same thing for the
137:43 - labels here just change the name into
137:46 - labels
137:48 - and
137:49 - the same thing for the bot
137:52 - let's go here
137:57 - labels and rerun it again
138:00 - and it will convert the labels or to
138:03 - create labels
138:05 - you see that sometimes it take few times
138:07 - when i say a few times few seconds i am
138:10 - saying not few minutes or something like
138:11 - this because it is converting then
138:14 - compressing the file for that it take
138:17 - few maybe 10 to 15 seconds
138:21 - but
138:21 - it is working now these are two other
138:24 - files of uh
138:26 - of of these are the labels the file of
138:28 - the labels and these are for the images
138:31 - and as i told you don't worry about the
138:32 - number because here this for loop it
138:35 - will pass by all your passions so if you
138:37 - have 10 it will convert 10 if you have
138:39 - more it will convert more if you have
138:41 - less it will convert less so that was
138:43 - how to convert the comp files in the
138:46 - next step we'll talk about because all
138:48 - these things that i am talking about are
138:50 - when you have data already segmented or
138:53 - already already labeled but maybe let's
138:56 - suppose that you have passions but you
138:58 - don't have your labels so for that case
139:01 - i will show you how you can do the
139:03 - segmentation by yourself using etk snap
139:08 - now let me show you how you can segment
139:10 - your
139:11 - data if you segment or label your data
139:14 - so if you don't have
139:16 - segmentations because if you have
139:18 - already downloaded data from the net in
139:21 - this case you will find that the labels
139:24 - but maybe
139:25 - as we were saying at the beginning of
139:27 - the course maybe the data that you will
139:29 - download doesn't have the same
139:32 - number the same extension so in this
139:34 - game i don't know or maybe they are
139:36 - using another task for example they are
139:39 - doing uh
139:40 - liver tumor segmentation but you won't
139:43 - use that
139:45 - data for only liver segmentation not the
139:47 - tumor level segmentation for that case
139:49 - maybe you need to correct or to re label
139:52 - your data so for this
139:55 - purpose i am showing you how you can do
139:57 - it yourself
139:58 - for that i am using etk snap that i
140:01 - showed you how you can download it and
140:02 - install it now let's start by i will
140:05 - just make this window bigger
140:08 - i will take this here now let's go to
140:11 - deliver i am not a doctor but i am sure
140:14 - that this is delivered okay so
140:17 - now let's do
140:18 - some segmentation i will show you how
140:20 - you can segment some slices but you will
140:22 - get the point because you can do the
140:24 - same thing with 3d slicer but i found
140:26 - that to these slices is a little bit
140:28 - complicated in term of segmentation but
140:31 - etk snap is the easiest software ever to
140:34 - do this kind of stuff
140:36 - it is old but it is very easy for us i i
140:39 - prefer to use it for segmentation for
140:41 - example i will show you how you can
140:43 - create a new segmentation and i will
140:45 - show you how can you can correct the
140:47 - segmentation even for so if you have
140:50 - already some segmentation and you know
140:52 - you need to just modify it or collect it
140:55 - not to redo it again so i will show you
140:57 - how you can do it let's create one save
141:00 - it and load it to change it after
141:03 - now
141:04 - to do the segmentation you just need to
141:07 - go here you have clear label we'll use
141:10 - it after try to choose one label so for
141:14 - us we have only one thing or one organ
141:17 - that we want to segment which is the
141:18 - liver so we used label one if you have
141:21 - multiple organs that you want to create
141:24 - so you start by for example label one
141:27 - means that you will do or you will
141:29 - segment the first organ then if you want
141:32 - to segment the second organ you choose
141:34 - the label two so it will know it will
141:36 - give two different values to each label
141:39 - and two different colors etc but for us
141:42 - we are segmenting only one organ which
141:44 - is the liver so let's choose the first
141:46 - one which will be in red now let's
141:49 - choose our brush so click on this one
141:52 - here paint brush like this
141:54 - and you choose the shape the shape it
141:56 - can be square or
141:59 - circle something like this or something
142:00 - generally here i prefer to use this and
142:04 - this thing here just bar here just to
142:07 - control the size of your brush something
142:10 - like this and you can use these
142:13 - for sometimes i used i used to use this
142:17 - 3d
142:19 - check box here but what does it mean
142:22 - because i will show you with the 3d and
142:24 - without the 3d when you do without the
142:26 - 3d if you segment this slice
142:29 - means that you have segmented only the
142:31 - slice if you go to the next one you will
142:33 - not you you will not see any
142:35 - segmentation
142:36 - but using the treaty it will segment two
142:38 - or three
142:41 - slices at the same time depending to if
142:44 - the slices are similar or not
142:47 - i don't prefer to use the 3d while doing
142:50 - the segmentation but i use it most most
142:53 - of the time i use it when i want to
142:54 - correct my segmentation in that case i
142:57 - prefer to use the 3d or to delete the
142:59 - segmentation so that it will be fast but
143:02 - when doing the segmentation or doing the
143:04 - labels i prefer to use the 2d normal 2d
143:07 - i segment each slice by itself so let's
143:11 - show you how to do it for one slice and
143:13 - you will get the point for all the
143:15 - slices now just select as i showed you
143:17 - here the shape and everything is good
143:20 - first label the shape here and the the
143:24 - size of that brush here and let's start
143:28 - just clicking and labeling like this as
143:31 - you are painting
143:33 - i am not a good painter but
143:37 - let's try to do it
143:41 - try to make your segmentations as tight
143:44 - as possible and try to cover only the
143:47 - lever
143:48 - so that's the code will not get confused
143:52 - with the other organs because you see
143:54 - that it is in grey scale and everything
143:56 - is similar so if you don't segment very
143:59 - well
144:00 - the mother will start segmenting
144:02 - everything in
144:04 - the body
144:06 - well
144:08 - not too bad it is too bad actually but
144:12 - we correct it
144:18 - let's make it bigger
144:19 - here
144:21 - so that it will be fast
144:27 - oof we did this
144:29 - now let's go to the next slice to do to
144:31 - go to next let's just scroll something
144:33 - like this and you see that for this
144:34 - first slice is segmented the next one is
144:37 - not segmented so you do the same thing
144:39 - here
144:41 - like this i will just
144:43 - do it
144:45 - to have time because it will take time
144:47 - if i will start painting
144:49 - so the same thing for the other ones
144:55 - just like this
145:00 - and do not don't do the same thing that
145:02 - i am doing because i'm just showing you
145:03 - but all these things need to be
145:05 - corrected that i wish i will show you
145:07 - how to correct that but as you can see
145:10 - don't do it
145:14 - that's it's
145:16 - the same thing for all the slices okay
145:19 - so now let's save one
145:21 - segmentation and we will reload it to do
145:25 - the correction for example this part or
145:27 - something so that you will understand
145:28 - how to correct your segmentation
145:30 - now to segment to save it go here in
145:33 - segmentations
145:34 - and save segmentation image
145:37 - and that's it just give the name and it
145:39 - will be saved at the same
145:41 - part where you have your images
145:43 - otherwise if you want to change change
145:46 - the path just clicking browse and change
145:48 - the path let me give it the name for
145:51 - example test segmentation
145:55 - something like this and it will be saved
145:58 - with the same part of my image which is
146:00 - this one
146:01 - now let's just close
146:03 - all these images
146:06 - without saving
146:08 - we we just closed everything now let's
146:10 - just let's try to reload our uh
146:14 - segmentation that we have created now
146:16 - this is the segmentation that we have
146:19 - saved drag and drop here
146:22 - but here when you do it just click on
146:24 - load as segmentation otherwise you can
146:27 - go to in segmentation open segmentation
146:30 - and choose the path but if you have
146:32 - already the folder just drag it drag it
146:34 - and drop it here and click in load as
146:37 - segmentation okay
146:40 - and it will be opened
146:43 - put this one here
146:46 - i'm going in wrong side
146:49 - so
146:50 - these are the slices that we have
146:53 - segmented now let's i will show you how
146:55 - you can correct these segmentations for
146:57 - example let's try this one
147:01 - let's collect this part here and you
147:03 - will get the point and you will see that
147:05 - it is very easy remember when we want we
147:08 - wanted to segment this part we we
147:10 - clicked on segmentation or label one if
147:12 - we want to segment something else we
147:14 - click on label 2 and it will get in the
147:17 - green color and it will segments another
147:19 - organ now we want to clear the
147:22 - segmentation of we need to delete or
147:24 - edit segmentation for that case we click
147:26 - on clear segmentation that's easy click
147:30 - in the brush
147:31 - check the size and check the shape and
147:34 - the size for example
147:35 - and now if i will go here click
147:39 - you can see that it is deleting the
147:41 - segmentation
147:43 - like this it is clearing and if i will
147:45 - do this this we do the same thing
147:47 - so now you get the point how to do the
147:49 - segmentation how to clear the
147:50 - segmentation and how to save it now when
147:53 - doing this if i want to save it again i
147:55 - will just click here save you can just
147:58 - click here in save with the same name if
148:00 - you want to save another file
148:03 - so because here if you click here it
148:05 - will
148:06 - pass this plus this new segmentation in
148:09 - the last one so we will lose the first
148:11 - segmentation but if you want to save it
148:13 - as a new segmentation just click in save
148:16 - as and that's it
148:18 - so that was how to do this segmentation
148:20 - now you have you get the point if you
148:22 - don't have already the segmentations
148:24 - with your data you can do the labeling
148:27 - using this etk snap software after doing
148:30 - this you can pass by the way that we
148:32 - talked about before which is converting
148:34 - into groups and after that converting
148:37 - into nifties because
148:39 - we so i told you why we needed to do
148:40 - this because if your data is ha
148:43 - has the same number of slices for all
148:45 - the passions or something similar like
148:48 - 100 110 120 90 something like this maybe
148:52 - you don't need even to do this type of
148:55 - conversion because
148:56 - 100 or 90 or 110 is nothing you can just
149:01 - resize them and put them at the same
149:03 - at the minimum which is 9 90 slices and
149:06 - put all your passions at that's 90
149:08 - slices but if you have passions with
149:11 - ones or with 90 others with 200 so if
149:15 - you do resize you will lose more than
149:17 - 100 slice for some passions for this
149:19 - case i recommend you to create the
149:20 - groups of specific number of slices as
149:23 - we did before 65 and it's up to you you
149:26 - can choose any number of slices you want
149:29 - so that was for this in the next part we
149:32 - will start doing the pre-processing
149:34 - because this part is the preparation of
149:36 - the data you see that we are just
149:38 - preparing the data in the next part we
149:41 - start doing the pre-process which will
149:43 - be before the training we do the
149:45 - pre-process after that we will do the
149:46 - training so let's see let's do the next
149:49 - parts in the next few minutes
149:53 - so before going to the pre-process there
149:56 - is something that i forgot to talk about
149:58 - which is the images or the groups that
150:00 - we have created
150:02 - there is something here
150:04 - i will go here data set label
150:09 - then the nifty files
150:13 - these
150:14 - so for example this is for the images
150:16 - that we have created and this is for the
150:17 - labels
150:18 - so there is something in some cases when
150:21 - you
150:21 - for example you have a passage with 600
150:24 - slices or this is not strange because
150:27 - you will find dataset does have pass
150:29 - into its 600 800 and more than that
150:33 - so don't don't be confused about that
150:35 - but
150:36 - this is not the point what i am saying
150:38 - or trying to say is maybe in this 600
150:42 - slices
150:43 - only 100 or 200 slices that are useful
150:47 - or maybe if you have passing with 300
150:50 - slices only 100 or 150 slices are useful
150:53 - the others are not useful
150:55 - so when you create groups of 65 slices
151:00 - you will find some sub passions which
151:03 - are groups that we have created for
151:05 - example this one
151:06 - contain nothing which means that the
151:09 - labels are empty which means that part
151:11 - of the body that you
151:13 - subtracted doesn't have anything which
151:16 - means all labels are empty for that case
151:19 - these type of groups or these type of
151:23 - subpassions will cause a problem with
151:26 - the accuracy of your problem of your
151:28 - program or of your your mother sorry
151:31 - for that case preferably you need to
151:34 - take or to delete these parts because
151:36 - they are useful because in your 65
151:39 - passions you will have indeed you will
151:42 - have some empty slices but if you
151:44 - calculate the
151:47 - difference between the empty slices and
151:49 - four slices you will find something like
151:50 - the same or that is not a big difference
151:53 - but when you take a sub
151:56 - subpassing which will be one input so it
151:58 - will be one input without any label so
152:01 - imagine with me that you are doing a
152:03 - program of classification between cat
152:05 - and dog and you put with your data you
152:08 - put images of
152:10 - rabbits or something like this in the
152:12 - training so the program will be confused
152:15 - we will say that this image of rabbits
152:18 - is not useful i will not use it you need
152:20 - it for the classification so why you are
152:21 - putting it
152:23 - in the inputs so i hope that you get the
152:25 - point for that case when you create and
152:27 - this is something good when you create
152:29 - small groups for this case you will
152:31 - delete all the parts of the parts that
152:33 - you don't need
152:34 - so for that case
152:36 - when you create the groups you need to
152:38 - find or to specify which are the
152:40 - slices that are empty or the groups or
152:43 - subpassing that are empty so that you
152:45 - can delete them for that i wrote a
152:48 - script for you it contains only two or
152:50 - three lines of code so don't worry about
152:53 - it which is useful just to show you
152:56 - which are the uh
152:58 - the the files or the passings that
153:01 - doesn't have any label or any
153:04 - segmentation for the 65 slices so to do
153:07 - it we will do it step by step just we
153:09 - need to import one library
153:11 - i don't remember if i think we have
153:13 - already installed niba bell
153:15 - let's try to import it and see
153:20 - there is no problem so we need this if
153:22 - you don't have it just write
153:25 - beep
153:26 - something like this pip
153:29 - install
153:30 - knee
153:32 - bubble and run it for me it is already
153:36 - installed so recommend already satisfied
153:38 - i will delete it so after importing it
153:41 - rerun
153:43 - this cell so this file is this library
153:46 - will be imported now let's use it so
153:48 - this new bubble is a function just to
153:51 - handle the nifty files because what we
153:53 - will do we will
153:55 - load each file
153:57 - which is a nifty file then we will
154:00 - see the values of the pixels if there is
154:04 - values between zero uh if there is
154:07 - values of zero one two and something
154:09 - like this more than only one value means
154:12 - that this uh
154:15 - subpassions contains labels indeed it
154:18 - contains this the
154:20 - zero values for the background and the
154:22 - one for the foreground and if you have
154:25 - multiple objects you have you will have
154:26 - two three extra etc
154:28 - and and if you will find only there is
154:32 - only zeros means that this part contains
154:36 - only the background which means there is
154:37 - no organ there is no lever in that part
154:40 - so you need to delete it okay this is my
154:42 - recommendation if you don't want to use
154:44 - it you want to use all your passions you
154:46 - are free to do it but i don't recommend
154:48 - you to use multiple
154:50 - uh groups or subpassions which doesn't
154:52 - contain anything in that case because
154:55 - when you put the patients directly with
154:58 - with random or with random slices having
155:03 - labels or not at the same time there is
155:06 - no problem but when you put one input
155:09 - without any label so this is the problem
155:11 - so when you create the groups you need
155:13 - to make sure that you don't have any
155:15 - empty labels or any empty passions
155:18 - when i say empty which means there is no
155:20 - parts that doesn't contain
155:23 - doesn't contain
155:24 - lever okay so
155:27 - let's start coding this as i told you
155:29 - the first thing that we need to do is to
155:31 - open the image which will be for example
155:33 - i will call it image or nifty
155:36 - file
155:38 - so to do it we will use the knee barbell
155:41 - i just need to use this i can use the
155:44 - shortcut like as nib it is a convention
155:47 - they are always but you can use directly
155:49 - bubble but it's convention to use nib as
155:52 - for knee bubble to make it short so nib
155:56 - then that's the function load this
155:58 - function load will load one pass hits so
156:01 - let's do it for one passing to show you
156:04 - how does it work then we'll create the
156:05 - loop that will pass by all the passions
156:08 - now let's do it let's start by taking
156:11 - this part for example
156:13 - here is the is this is the output part
156:16 - but for us we need it as an input here
156:19 - because we need this path but you don't
156:21 - need to use the parts or the files of
156:24 - the images because the images we are
156:26 - sure that images are have multiple
156:28 - values have zeros one and something
156:31 - between them
156:32 - but for the material for the medical
156:34 - images you will find values between
156:35 - minus three thousand or minus one
156:37 - thousand into plus one thousand don't
156:40 - worry about that this is the medical
156:42 - imaging welcome to the club
156:44 - so
156:45 - what you have to do is
156:47 - using the labels because we said that we
156:50 - need to see if there is label if there
156:52 - is foreground in that part of the body
156:55 - so for that we need just to check the
156:57 - labels because labels will specify the
156:59 - foreground and the background we cannot
157:01 - see that in the images
157:03 - so let's take the path of this
157:06 - output images which will be our input
157:08 - here
157:09 - so i will just put
157:12 - in
157:13 - put
157:14 - nifty
157:15 - file
157:16 - path for example
157:18 - and
157:19 - that's it's ctrl v
157:22 - so this is the all
157:24 - paths for now we take as i said it will
157:26 - take only one passion so i will just
157:29 - take the name here
157:31 - after using after trying with one
157:33 - passing i will show you how we will just
157:36 - add a loop that will pass by all the
157:38 - passes don't forget to add the gz
157:40 - because the value the files here are
157:44 - compressed so that's gz
157:46 - now let's what we will do just we will
157:48 - load this passions which will be here
157:52 - inputs
157:55 - in
157:55 - [Music]
157:59 - put something like this
158:04 - input nifty file but
158:06 - so if we run this cell there is no error
158:08 - no problem because we just loaded the
158:10 - image it is here in nifty file what we
158:13 - need to do now
158:14 - there is something in the medical
158:16 - imaging if you have already some
158:18 - knowledge about that there is not only
158:20 - the image exactly which is the array of
158:21 - the image
158:23 - we are talking about the nifties or the
158:24 - decons the same thing there are other
158:26 - informations like the passive
158:28 - information the name and age etc there
158:31 - are value or there are informations
158:33 - about the pixels the dimensions of
158:34 - pixels etc will use this in the
158:37 - pre-processing process pre-processing
158:39 - sorry we'll talk about them later on but
158:42 - for now what we need to do we need just
158:44 - to substitute to extract the value
158:48 - the matrix or the
158:49 - array that contains images which are the
158:52 - slices because what we need to do just
158:54 - to take this
158:56 - values or this matrix that has all the
158:59 - values of the slices and verify the
159:02 - slices of each passions where there is
159:05 - only zeros or where there is zero and
159:08 - one or two or something like that
159:10 - for that to to to start to subtract or
159:12 - to extract the array from the image
159:16 - which is nifty image there is a function
159:18 - called
159:19 - getfdata fdata means that frame data so
159:23 - we can just
159:24 - create as i told you we can do
159:26 - everything in one line but i am just
159:28 - writing every each thing in one specific
159:31 - line so that you can understand the
159:33 - steps that we are passing by so here we
159:35 - have f data which means frame data to do
159:38 - it just write the name of your passing
159:41 - which is nifty
159:44 - file
159:46 - dot
159:47 - get f
159:48 - data
159:49 - it is a function so we need to add the
159:51 - parenthesis so this fdf data will
159:55 - contain the
159:56 - values of all the slices so it will be
160:00 - an array of
160:02 - 65 slices because we have passage of 65
160:05 - and each
160:06 - 65 yes slices or 65 items and each item
160:10 - is an array of
160:12 - of an image which contains the values so
160:15 - we need to know if these values are
160:18 - contains only zeros or zeros and one or
160:21 - zero one two three etc for that case we
160:24 - need to specify the dimensions of this f
160:27 - data but
160:28 - using only dimensions will not be the
160:32 - thing that we need because the images
160:33 - will just give you how many slices or
160:35 - something like that but there is a
160:36 - function in numpy called
160:39 - unique numpy that's unique so this
160:41 - function unique will return if there is
160:44 - or if there are unique values so if you
160:47 - have only zeros in your function if in
160:50 - your array so
160:52 - the unique values will be only zero if
160:55 - you have zero one two three but
160:58 - you have multiple one two threes in your
161:00 - image so it will return only the unique
161:03 - values that you have in your image
161:05 - so
161:06 - for us if the unique values will be only
161:09 - zeros means that this image or this
161:12 - passion is contained only zero that
161:14 - means that there is no lever so we need
161:17 - to delete it
161:18 - if this unique function returns zero and
161:22 - one or more than one value means that in
161:25 - that case that uh there is something in
161:27 - the image that is the background and
161:28 - there is the foreground indeed so to do
161:30 - it here what we can do as i told you we
161:33 - can choose the number the uh the
161:35 - function unique so here what we can do
161:37 - just i will create another function
161:40 - sorry about that but as i told you i
161:42 - want to write everything so i will call
161:44 - it numpy unique
161:47 - and now we can i don't remember if i
161:50 - have not by here we don't have it so if
161:52 - you don't have numpy just as i told you
161:55 - just something like this beep install
161:59 - numpy and it will be installed but for
162:02 - me i already have it i think
162:04 - so i will put imports numpy as
162:09 - and b
162:11 - something like this so it is already
162:13 - imported now let's let's use it so np
162:17 - dot
162:18 - unique
162:20 - and here we will put the
162:22 - array that we have and for us we have f
162:26 - data this is our unique uh our array so
162:30 - let's let's let's print this so and be
162:33 - while using japanese notebook you don't
162:35 - need to use the print function you can
162:38 - just write the name of the uh
162:41 - of your variable and run it it will uh
162:44 - it will just print it here like this as
162:46 - you can see and for us for us you can
162:49 - see that we have zero one two for us we
162:52 - have more than one value we don't have
162:53 - only zero means that there is the
162:55 - background and that is the foreground
162:57 - for this case we don't need to delete
162:59 - this passion if we have only zero here
163:02 - we don't have this one and two we have
163:04 - only zero means that we have only the
163:05 - background so this buttons need to be
163:08 - deleted
163:09 - i hope that you get it this is the point
163:11 - that's all what we need so the function
163:13 - that we need to do is
163:15 - only to specify the length of this
163:17 - return or of this unique uh
163:23 - so what we can do
163:25 - we can just say if
163:28 - np
163:29 - unique
163:31 - but as we said we need the length of
163:33 - this
163:35 - of this variable so length if the length
163:38 - of this and be unique
163:40 - is
163:41 - bigger
163:42 - than two which means the the length is
163:44 - not one if there is bigger than two
163:47 - means that we don't need to delete that
163:49 - passion
163:51 - but if this lend is equal to one
163:56 - means that this passion need to be
163:59 - deleted so if equal to one let's make
164:02 - just like print
164:05 - and let's print this this passion so for
164:08 - us we'll print this
164:10 - [Music]
164:12 - this part because we we are having only
164:14 - one but we do it for a loop now let's
164:16 - print it here there is nothing printed
164:18 - because this passion has foreground and
164:22 - background so if you are in the case
164:24 - where there is no foreground and
164:25 - background you have only the background
164:27 - so it will be printed now let's do it
164:30 - for all the passions you have data
164:32 - database for which
164:34 - with i don't know hundreds passions
164:36 - let's do it now
164:38 - so let's say that labels and just change
164:41 - put here star
164:43 - this mean that
164:45 - this
164:46 - part contains multiple files so this
164:49 - star will return everything inside that
164:51 - folder to do it let's start by
164:55 - creating the list as we did here we need
164:58 - to create a list
165:00 - of
165:01 - labels
165:04 - and it is equal to globe then here the
165:07 - parts
165:09 - input
165:12 - parts file uh
165:14 - a nifty file
165:15 - then here this
165:17 - this
165:18 - [Music]
165:19 - list of
165:21 - group of parts will be used in the for
165:24 - loop as we did before
165:26 - so now let's just write for
165:29 - persians in
165:31 - list labels
165:33 - then
165:34 - let's do what we have done here let's
165:37 - just we can just copy these and use them
165:40 - there is no problem let's just
165:43 - pass them here so they will be in the
165:45 - condition if condition
165:47 - now what will be happen but just we need
165:49 - to
165:50 - change this
165:53 - because we need to load that specific
165:55 - passion not the folder here
165:59 - so here load the passions which is here
166:02 - for the loop load the patient
166:04 - and get the frame data from that passion
166:08 - calculate this unique
166:11 - then calculate the length if it is equal
166:13 - to one then print it but we will need to
166:16 - print the passions so here
166:20 - sorry i am
166:25 - passions so we will read it we load it
166:30 - extract the frame data get the frame
166:32 - data then
166:33 - choose the unique calculate the new
166:35 - unique
166:36 - values then if it is equal to one the
166:39 - length then prints let's just run this
166:43 - and you can see that there is nothing
166:45 - printed because the
166:47 - both passings that i have here are
166:50 - with the foreground and background so
166:52 - there is no problem but if you have
166:54 - passions with more because for me or
166:57 - even my passions that i use in this test
167:00 - has only one hydrant and second one has
167:04 - 120 or 110
167:06 - slices so when i created the nifty
167:09 - groups the nifty the decom groups and
167:12 - converted them into a nifty which is
167:14 - which are the sub passions here
167:16 - they have they should have
167:19 - slices with the liver because if i had
167:23 - the
167:23 - large number if i had pass it with 600
167:26 - slices for example in this case i will
167:29 - get definitely definitively i will get
167:31 - three or more than three groups of
167:33 - decoms or groups of 65 slices which are
167:37 - empty so for this case i needed to
167:39 - delete them
167:41 - because
167:42 - in in this in this task i am showing you
167:44 - only two passions but i have already
167:46 - prepared the data and i had that problem
167:49 - and i have deleted all of them
167:51 - when we start doing the preprocess i
167:53 - will show you how i created the folders
167:56 - for the training and for the testing and
167:59 - we'll do everything together don't worry
168:01 - about that
168:02 - now as i told you this is the script
168:05 - let's verify if you have empty
168:08 - files in that case it will print them
168:10 - and you can delete them manually i
168:13 - wanted to do it with a script to delete
168:16 - but i had some problems sometimes if you
168:19 - do something wrong you may delete the
168:22 - wrong files but if you want to do it you
168:24 - can just add the line to delete that
168:26 - button but i don't prefer that i just
168:28 - want to print them maybe verify them but
168:31 - it's up to you if you want to delete
168:33 - them you can just add the delete or the
168:35 - remove function uh from the chantel that
168:38 - we used before here
168:41 - this function gentle you can use it to
168:43 - delete the file and just put the then
168:46 - call the gentle down here put the parts
168:48 - which is the passion of that part of
168:50 - that passing which is the empty and it
168:52 - will delete it for you so if you prefer
168:54 - to do this you can do it
168:56 - so now after doing i think that now we
168:59 - have completed everything about the
169:01 - preparation of the data let's start
169:03 - doing the pre-process and of course
169:06 - eventually the training
169:12 - so now before doing the pre-processing
169:15 - because
169:16 - all the functions that you will use or
169:18 - need to do the pre-process are included
169:20 - in muni and python
169:22 - so before doing that we need to install
169:25 - monae and pytorch and all the
169:27 - dependencies that we need at the
169:29 - beginning maybe
169:30 - in the process we will need some other
169:34 - libraries but not are they are not the
169:36 - most important ones but the important
169:38 - ones are for now monae and pytorch
169:41 - because they will use them for the
169:43 - pre-process for training for the testing
169:45 - etc
169:46 - for that we need to install them
169:49 - but before doing that we need to create
169:50 - to install code cuda
169:54 - which are the packages for the gpu and
169:57 - the tool case for the gpu so that we can
169:59 - do the training using the gpu not cpu
170:02 - because using the gpu and my training
170:05 - sometimes it took two days to two days
170:08 - to be completed because the images are
170:11 - very big so imagine with me if you have
170:14 - 60 or 100 passions and each passion
170:17 - contains 300 slices and these 300 slices
170:20 - we will divide them but i am talking
170:22 - about the at start so for example if
170:25 - each pass it will be divided into two or
170:27 - three parts so multiply your 100 percent
170:31 - by three so it will be 300
170:33 - sub passions and each subpassion
170:36 - contains 60 65
170:38 - maybe slices so imagine with me how
170:41 - large your data will be
170:44 - and we are we will use the 3d monae so
170:47 - we will do 3d convolutions so it will be
170:51 - tight it will take time it will be very
170:53 - slow for us you need to be careful not
170:56 - to be careful but you need to be aware
170:58 - about that
170:59 - you will prepare your data verify it if
171:02 - everything going well
171:04 - just run it and leave it for one day or
171:06 - two days depends to how many passes you
171:09 - have for me
171:10 - i remember one
171:12 - time the training took me two days or
171:14 - two days or a half when i say two days
171:17 - means that 48 hours not only two days
171:19 - just like that
171:21 - so i have a gpu with gtx
171:24 - 1080 but it does it it wasn't that fast
171:28 - so you need to be aware about that
171:30 - because maybe you will say you will say
171:32 - that i can use collab because when i
171:35 - they are using collab in their tutorials
171:37 - but remember that the images or the yes
171:40 - data that they are using in their
171:42 - tutorials
171:43 - are spacings with small number of slices
171:46 - and they have only 40 passings maybe i
171:48 - think yeah
171:50 - and for that the training doesn't take
171:52 - more much time but if you have data set
171:54 - with large number of passings and with
171:56 - large number of slices
171:58 - be aware that it will take time
172:00 - especially if you will run it in your pc
172:02 - because even if you want to run it in
172:04 - collab
172:05 - you you i i think that you know that in
172:07 - collab you cannot run more than 12 hours
172:10 - if you have a good internet connection
172:12 - without any cut or something like that
172:14 - it will it cannot go more than uh one
172:17 - run it one it cannot go more than 12
172:20 - hours so you make it you can pay for
172:24 - call up pro so you will get 24 hours but
172:27 - as i told you something it took two days
172:29 - so be aware about that okay and don't be
172:32 - scared don't be scared if the training
172:35 - took two days because i am just telling
172:37 - you that it can it can do that okay
172:39 - depends on how many passings you have so
172:42 - to do the installation the first thing
172:45 - as i told you we need to install the
172:47 - cuda
172:48 - you can just go to their website
172:50 - developers.nvidia.com cuda downloads
172:52 - otherwise you can just write in google
172:54 - here coda
172:56 - download
172:58 - something like this and go to this
173:01 - first link
173:03 - and
173:04 - you will get cuda toolkit 11
173:07 - if you have problems because we if we
173:11 - are using tensorflow it may be a problem
173:14 - because sensor flow with some versions
173:16 - of cuda or kodiana if you don't
173:19 - download or or if you don't install the
173:21 - specific some specific versions you will
173:23 - get problems at the end
173:25 - but with python don't worry about that
173:27 - because i will show you when we will
173:28 - install python you will see everything
173:30 - clearly so don't worry about the
173:32 - versions if you want to install 11 you
173:35 - can install it if you want to install 10
173:36 - you can install it
173:38 - with no problems
173:40 - so here we want to i have already this
173:44 - uh
173:45 - qdn encoder installed in my pc so i will
173:48 - not download them again but i will show
173:49 - you how to do that to do that
173:51 - then we'll go to the installation part
173:55 - so for me i am using windows if you are
173:58 - using linux you can just click in linux
174:00 - so i will click windows
174:02 - this
174:03 - x86
174:05 - then here the version of windows i have
174:07 - windows 10 then you want to use it in
174:09 - network on local i prefer use it in
174:12 - local and now everything is
174:15 - set you can just click on download and
174:17 - something i will just click to show you
174:19 - and you can choose the directory where
174:21 - you put your file and it will be
174:24 - downloaded successfully without any
174:26 - problem
174:27 - and after downloading this you just go
174:31 - here i have them here
174:33 - open your i will not do it again as i
174:35 - told you because i already have it but i
174:37 - will show you when you click on it you
174:39 - will get the window
174:41 - let's wait
174:43 - my pc is a little bit slow these days i
174:46 - don't know why
174:47 - but
174:48 - let's see
174:52 - so click on run
174:54 - then choose the directory i will not
174:56 - click because if i will click it will
174:58 - start doing the installation so
175:01 - everything is easy just click in next
175:03 - next next and everything will be
175:05 - installed
175:06 - after installing the cuda now let's go
175:09 - to kuden and korean is another package
175:13 - which will be used with cuda so just go
175:16 - here in developers.nvidia.com
175:20 - or just you can go here and
175:23 - [Music]
175:24 - press download
175:26 - typos press
175:28 - download to
175:30 - dna
175:31 - okay
175:33 - so here nvidia cdn
175:35 - the same thing
175:38 - and let's go on download cdn
175:43 - and now to do it you need to have an
175:45 - account and it is free don't worry about
175:47 - that you need to have an account
175:49 - developer account so once you create an
175:52 - account you can just choose version it
175:55 - depends to you so for us we have
175:57 - downloaded cuda 11 so we need to install
176:00 - this if you have already another version
176:03 - of cuda so you need to check the version
176:06 - that you need for your cuda so click on
176:08 - archive or korean archive so you just
176:12 - find all these versions so
176:15 - see which kudi which code that you have
176:17 - installed in your pc and install the
176:19 - available or the corresponding kudn
176:22 - version after downloading it what we
176:25 - will do we i will show you how to do it
176:27 - we this is it will be something like
176:30 - it's like a compressed file when you
176:33 - decompress it you will find this file
176:35 - this
176:36 - folders so that's what you will find so
176:39 - to install kdnn very easy you just need
176:42 - to copy and paste these kdn files into
176:46 - cuda where you you have cuda installed
176:49 - so if you want to see where your your
176:51 - cooler is installed what you need to do
176:54 - just go to your pc
176:57 - and go here in your desk then your
177:01 - program files
177:02 - and you will find the folder here
177:06 - nvidia gpu computing toolkit
177:08 - so this folder will be created
177:10 - automatically when you install kudi and
177:12 - cuda sorry and if you go here you have
177:15 - cuda and you have the version if you
177:17 - have multiple versions you will find
177:18 - multiple versions here but for me i have
177:20 - only one so you have you will find this
177:22 - one
177:24 - now i will just keep this here i will
177:27 - open another one
177:32 - we have
177:34 - three holdings here downloads and cool
177:37 - dnl so as i was saying
177:40 - what you need to do just to copy the
177:42 - files from the bin of the korean
177:45 - paste them into bin of cuda
177:48 - and includes of kodianen just copy them
177:52 - and paste them in includes of cuda the
177:55 - same thing for the
177:57 - lib
177:58 - copy these go to lib x
178:01 - 64 copy them and go to lib here
178:05 - and x 64 and paste them here i have them
178:08 - already so i will not do it again but
178:10 - you get the point because i have kudian
178:12 - and all the files are here so just
178:14 - select all
178:16 - copy them and paste them here that's all
178:20 - what you need to do and the last thing
178:22 - that you need to do is to go to your
178:25 - system environment and add your
178:28 - file
178:29 - the parts of the lib i will just show
178:31 - you here
178:32 - properties
178:34 - advanced parameters
178:36 - variable systems
178:38 - if available environment and now if you
178:41 - go in parts
178:43 - you will find that i have i don't know
178:45 - if i can
178:47 - yes i can move it here now for me i have
178:50 - these parts the path to the bin to do to
178:54 - the bin w uh
178:56 - to the bin
178:58 - and vvb and the the other one which is
179:01 - extra cool
179:03 - t
179:04 - slash lib64 where you if you will find
179:07 - them they are all
179:09 - here
179:11 - good version
179:13 - so this is the first part which is the
179:15 - bin so go to bin
179:17 - copy this part copy it ctrl c and come
179:21 - here click in new and paste it and
179:24 - that's it click enter the same thing for
179:26 - the other one which is the lib and vp
179:30 - this
179:31 - one
179:32 - and copy it
179:34 - create a new part paste it and the
179:38 - same thing for the extra
179:41 - copy tt
179:42 - lib64 and copy this and paste it here
179:46 - and you are and everything is set now
179:48 - you have installed the i will just
179:51 - close this
179:53 - now you have installed your kodi nnn
179:57 - we will go to this one
180:00 - here we have installed cuda kudi and now
180:03 - we need to install monae and python
180:06 - let's start by mulai the easiest one to
180:08 - install mona you can just do bip or
180:10 - conda install so
180:12 - here we
180:14 - install
180:16 - more light
180:17 - that's it it may take some few seconds
180:21 - it depends to your internet connection
180:23 - and because my internet connection is
180:25 - very bad so it will take
180:27 - maybe one minute or less let's stop it
180:30 - for a few seconds
180:32 - and now you can see that it is installed
180:35 - now let's
180:36 - try to install python so to install
180:38 - pytorch we just we need to go to the
180:40 - website pytorch.org
180:42 - okay that's it
180:44 - and now to inst to download it
180:47 - because when you go to python.org you
180:50 - will go to this page just scroll down
180:52 - here
180:53 - check the stable version
180:55 - for me i am using windows if you have
180:57 - mac or linux you can just select them
181:00 - after that i want to install them using
181:03 - pip install if you have you want to use
181:06 - it what really difference is when you
181:08 - click encoder it will be could install
181:10 - instead of beep install but you can see
181:12 - that some some things will be different
181:14 - but
181:15 - when you use for me i am using python
181:18 - pip install so it will download the
181:20 - packages from the uh
181:23 - from the website by touch the website
181:25 - okay so flip then python because you are
181:28 - using python now
181:30 - if you have kuda 11 check code 11 if you
181:33 - have kuda 10 check code 10
181:36 - if you don't have gpu and you want to do
181:38 - your training in cpu i don't recommend
181:40 - you because it will take one week
181:43 - so you need to check on cpu so it will
181:46 - be installed or storage vision touch
181:48 - audio for us we have cuda 11 because we
181:51 - installed cuda 11.5 but don't worry
181:54 - about that 11.3 does the work because
181:57 - you don't you don't have 10 so we have
181:58 - the 11.
182:00 - then copy this lines and we will install
182:03 - them so for us we are using jupyter
182:06 - notebook i need to do it
182:08 - so
182:09 - here you can see that pip3 you can leave
182:12 - it pip3 or you can make just pip
182:14 - where we have pictorially because if we
182:16 - have installed pip 2 uh python 2 and
182:19 - python 3 in the same virtual environment
182:22 - so in that case we preferably need to
182:24 - use pip
182:25 - without number means we are talking
182:28 - about
182:28 - python 2
182:29 - if we put pip 3 means that we want to
182:32 - install this package in the python 3.
182:34 - for us we have only python 3 we don't
182:36 - have python 2 so pip it will
182:38 - install in the python 3. so when we run
182:41 - this cell the same thing this
182:44 - installation may take some time depends
182:46 - to your internet connection
182:48 - so after doing this everything is set
182:51 - when we start doing the pre-processing
182:54 - after installing muni as you can see
182:56 - mona is installed and the
182:59 - cuda installed korean installed and now
183:02 - we are waiting for pytorch
183:04 - let's
183:06 - stay for a few seconds
183:08 - to see this message successfully
183:10 - installed
183:11 - yes we have to see it
183:16 - so now everything is set and you can see
183:19 - that
183:20 - the pytorch is installed without any
183:22 - problem now everything is set we don't
183:24 - need anything to install for now
183:27 - i will delete this and this if i will
183:30 - click for example import monae
183:34 - it will be imported without any problem
183:36 - so
183:37 - now you can see that everything is set
183:39 - because
183:40 - i i i started with this because i told
183:42 - you because we need we will need monae
183:45 - and pytorch for the pre-process even for
183:47 - the president only for the training for
183:49 - that i needed to start by ins by this
183:52 - installation
183:53 - so let's start doing the pre-process
183:59 - now let us let us talk a little bit
184:01 - about how to do the pre-process so i
184:04 - will not go to the to the steps uh each
184:08 - line of code by line
184:10 - because i have already done videos and
184:13 - blog posts about everything that we need
184:16 - to do for the pre-process so you can
184:18 - find the links here in my website that
184:21 - is in my picadco you will find a blog
184:25 - post about pre-processing in detail and
184:28 - also the youtube video youtube video
184:30 - about that so you can check it out so
184:33 - that i will not repeat everything in
184:35 - each video because i know that if i will
184:37 - talk about that it will take a lot of
184:39 - time because only the video about
184:41 - pre-process i have two parts each part
184:44 - for 40 minutes or 50 minutes so imagine
184:47 - with me if i will talk about the
184:48 - pre-process and this augmentation that
184:50 - we will come to it later so it will take
184:53 - a lot of time doing that but there are
184:56 - already videos that i have done about
184:59 - that and there are blog posts that you
185:01 - can read there are code etc but don't
185:03 - worry about the code because the code
185:05 - that we will use here
185:07 - is more
185:09 - i have i have just ordered it and it is
185:12 - well done because here it is
185:14 - you will find the code but it is only
185:16 - for the pre-process but here
185:20 - since we are going to do the training
185:22 - after the pre-process so i have created
185:24 - some functions instead of just scripts
185:28 - doing the pre-process i have created
185:30 - functions that you will find in my
185:32 - youtube repo in my github repository
185:34 - don't worry about that
185:36 - at the end of this course i will be
185:39 - i will be talking about everything so i
185:42 - will show you how you can just get clone
185:44 - this the git cloud this
185:48 - [Music]
185:49 - github repository and how you can call
185:52 - all the functions because you will find
185:53 - that every function that we will use is
185:56 - here for example how to calculate the
185:59 - dice matrix calculate weights everything
186:02 - we will talk about it later here is the
186:04 - function that will do the training
186:05 - because as you know in
186:07 - python there is no a specific function
186:09 - as in because if you have used
186:12 - tensorflow before you will find that
186:14 - there is that function that feeds mod
186:16 - that fit so it will launch the training
186:18 - and is a little bit easier but in python
186:20 - there is no function
186:22 - called that fit so you need to write the
186:24 - loop by yourself and almost all these
186:28 - things in the training part i took them
186:30 - from uh pythorg
186:32 - from sorry from monae
186:34 - tutorial but i just have done some
186:37 - changes to make the code clear but we go
186:41 - we'll come back to this later
186:43 - and here in the not
186:45 - in the pre-process
186:47 - we find all the functions that we talked
186:49 - about for the creating the groups and
186:52 - nifty to decom and find the empty
186:55 - and at the end we we have this function
186:58 - function prepare which contains the
187:00 - lines of code to do the pre-process so
187:03 - everything is here in github but i will
187:06 - make it clear at the end of this course
187:08 - and i will show you how you can just
187:09 - clone the repository use the functions
187:12 - but before that i just wanted to explain
187:14 - to you some of these
187:16 - parts because as i told you i will not
187:18 - go to everything line by line because
187:21 - you will find the explanation here but
187:24 - just to give you a small explanation i
187:27 - will give you here i will talk a little
187:28 - bit about some
187:30 - of the
187:31 - fun not the functions but
187:33 - only some transforms that we used here
187:35 - because if you go in monae's website you
187:39 - will find that there are tons of
187:41 - transforms that you can apply in your
187:43 - data for the pre-process and for the
187:44 - data augmentation but for us i will not
187:47 - use all these data all these transforms
187:50 - sorry i just took smaller
187:53 - few of them just to make the data clear
187:55 - but i didn't do like a
187:58 - huge things for the data because it will
188:00 - take time and it will take memory and i
188:03 - don't have that
188:05 - great gpu to do all these functions
188:08 - but i will show you how it will look
188:10 - using only these pre-processings and you
188:14 - can do it
188:15 - yourself like this if you want to add
188:17 - more functions of course it will be
188:19 - great because you will see the results
188:21 - at the end they will be acceptable but
188:24 - if you
188:25 - train your model for more data than i
188:28 - that then i am using or you if you do
188:31 - more pre-process or more data
188:32 - accommodation of course your model will
188:34 - be improved better than mine
188:37 - but we go to this later
188:39 - now let's talk a little bit about the
188:41 - pre-process as i told you
188:43 - here as you can see i have created four
188:46 - variables each variable contains the
188:48 - path for the training volumes training
188:51 - segmentation then the testing volumes
188:53 - and testing segmentation if you have
188:55 - already seen the
188:57 - tutorials of monae in their website you
189:00 - will find that they are not talking
189:02 - about testing they are talking about
189:03 - validation but i prefer to call it
189:06 - testing because
189:07 - when we see validation in deep learning
189:10 - most of the time means that these data
189:12 - will be used in the training and it can
189:15 - affect the model during the training but
189:18 - here of course we are we will because if
189:20 - you see the tutorials of monae you will
189:23 - see that they are using actually this
189:26 - data that they are calling them
189:28 - validation data
189:30 - they are using them during the training
189:32 - but they are not affecting the training
189:34 - for that
189:36 - they say always testing data because we
189:39 - just use them to see what happened but
189:41 - we don't use the result of that
189:43 - validation data to do some changes in
189:46 - the model for that i prefer
189:49 - calling them testing data and not
189:51 - validation data but it ups to you you
189:53 - can call them anything you want but i
189:55 - don't prefer to call them validation and
189:58 - if you want to leave the validation you
190:00 - can do that
190:01 - so as you can see here the there are
190:04 - some important things that you need to
190:06 - keep in mind the first thing
190:09 - is the name of your folders
190:12 - i don't i am not saying that you need to
190:14 - call your folders with the same names
190:16 - that i am doing but
190:18 - what you need to do or what what is
190:20 - important here is that you need to
190:23 - specify the name the exact name of your
190:26 - folders because here there is the first
190:29 - thing
190:30 - in your path or where you will find your
190:33 - data the first thing is the main path
190:36 - which means the directory where you have
190:39 - all the
190:40 - folders or all the passions for example
190:43 - here
190:44 - for me this is the whole or this is the
190:46 - main folder which contains four four
190:50 - folders i will just minimize
190:52 - this and this directory contains four
190:57 - folders the first one is the testing
191:00 - test segmentation where you will find
191:02 - the masks for the testing
191:04 - and the second one is the test volumes
191:07 - and this one training segmentation and
191:09 - training volumes volumes means the
191:12 - passions and segmentation here means the
191:15 - labels okay
191:16 - so these are the four folders that you
191:19 - will need so if you are calling them the
191:22 - same as i am calling them here you can
191:25 - just leave the code otherwise if you
191:28 - change these name then you need to
191:30 - change these names as well here so if
191:33 - you will go with me at the end and just
191:36 - fork the github repository and use it
191:38 - for that case
191:40 - you need to change your folder's name to
191:42 - make it easy or otherwise you can change
191:45 - in the code but maybe the best thing if
191:48 - you are using the same code the best
191:50 - thing is to change only the names and
191:52 - not all the uh not the code okay
191:55 - and the second thing actually i
191:58 - i will talk about this later on and i
192:00 - will show you some examples
192:02 - but now i will give you just small words
192:05 - about that
192:07 - you need to be specified about this
192:09 - thing here which is the extension of
192:11 - your files
192:13 - as i told you we cannot use something
192:15 - like other types
192:17 - but nifty so we need to use nifty files
192:20 - but the second thing here as i told you
192:22 - here when we add that gz means that this
192:25 - nifty file is compressed
192:28 - so if your files are not compressed you
192:31 - need to delete this dodge gz because if
192:34 - you leave this the gz
192:37 - but your files are not compressed means
192:39 - that this
192:41 - not this is just defining this line is
192:43 - just defining the part but here when you
192:46 - will load your data
192:48 - and
192:50 - you don't put the exact extension here
192:53 - means that the function bell that
192:55 - will open this volume will not find this
192:59 - file it will find for example passion
193:02 - one does nii but it will not find that
193:05 - gz
193:06 - in that case it will not recognize that
193:08 - it is the same passion for that case it
193:11 - will not open it and you will lose
193:14 - this passion and imagine me with me if
193:16 - you're if all your passion doesn't have
193:19 - this
193:19 - gz means that your
193:22 - your code or your program or your own
193:25 - function will not open any type of data
193:28 - and it will not open your passions in
193:31 - that case you will find your data loader
193:33 - here empty like there is no data and you
193:36 - can do nothing with that and the problem
193:39 - here is that you will not know this is
193:42 - the biggest problem with one eye you
193:44 - will not know where is the problem you
193:47 - it will not give you an error here if
193:50 - you will run this code there is no error
193:52 - but when you will try to
193:54 - print no print or you can if you want to
193:57 - print or if you want to upload your
193:59 - images in this case you will find that
194:02 - your data loader is empty and you will
194:04 - not know that the problem is with the
194:06 - extension this is what i am saying you
194:08 - will
194:09 - you will miss to delete this extension
194:12 - but the code will not tell you that you
194:14 - have missed something or there is
194:16 - something wrong or the directory is
194:18 - wrong or there is no such a directive
194:20 - like this because always when we do or
194:23 - when we put the wrong part
194:26 - always we get the error saying that this
194:29 - directory doesn't exist and in that case
194:31 - you will know what is the problem but
194:33 - with mona you will not know that you
194:35 - will find just the data loader is empty
194:39 - but you will not know that it is empty
194:41 - because you just forgot to
194:44 - delete or to add this.gz
194:47 - the same thing for other stuff but as i
194:49 - told you i will show you that
194:51 - in in practical but not for now now now
194:54 - i am just explaining but after that i
194:56 - will give you a small things
194:58 - that will cause problems and i spend a
195:01 - lot of time trying to
195:03 - to debug that because
195:05 - you will not know what is the problem
195:07 - you know you need to print everything in
195:09 - your code so that you may find the
195:11 - problem
195:12 - for that i will first case i will show
195:14 - you some of the problems that i found
195:18 - during my period not pid but during my
195:21 - uh
195:22 - master's thesis while i was doing this
195:24 - project not this project but something
195:26 - similar but
195:28 - uh in this case maybe if you will find
195:31 - or if you will be faced with these
195:33 - problems you will know how to solve them
195:37 - so
195:38 - i try to do there is four
195:41 - for variables each variable represents
195:43 - the path for the volume segmentation for
195:45 - the training volume segmentation for the
195:47 - testing
195:48 - the second thing here is to create two
195:51 - dictionaries the first one is for the
195:53 - training second one is for the testing
195:56 - dictionaries is only some
195:59 - rows and
196:01 - rows and columns
196:02 - and this
196:03 - these are the keywords and these may
196:06 - cause a problem as well but i will not
196:07 - talk about them now
196:09 - so this one is vol for volume this seg
196:12 - for segmentation so these are two
196:15 - keywords each one represents a column so
196:18 - this column is for volumes this column
196:21 - is for segmentation and in each column
196:24 - you will find some rows and each row
196:26 - contain the path for each passion so the
196:30 - first for example first row first column
196:33 - we represent the path to the volume of
196:36 - the first passion this the first row and
196:39 - the second column will represent the
196:41 - segmentation of the first questions etc
196:44 - etc these for the training and same
196:46 - thing for the testing
196:50 - and you will find all the explanation
196:52 - about these in my blog post and in my
196:54 - youtube video about that so just i am
196:57 - just giving you a small uh
197:00 - recalculation but you will find
197:02 - everything there
197:03 - and now let's talk about this transform
197:06 - function this transform function you can
197:08 - see that there is this function composed
197:10 - which is you can find this in python and
197:13 - idea are using the same thing here
197:15 - compose is a function that allows you to
197:18 - use or to apply multiple transforms at
197:20 - the same time not to apply a first
197:24 - transform to the image and the output
197:26 - image passes to the second image that
197:28 - the second function that will do the
197:30 - second transform etcetera etcetera but
197:32 - doing using this compose function you
197:35 - don't need above you don't need to worry
197:37 - about that you just need to define which
197:39 - are the transformers that you want to
197:41 - apply and it will do
197:43 - that it will do that by itself you don't
197:45 - need to specify which one the first the
197:48 - second but here it will take this order
197:51 - this one will be applied the first this
197:53 - one second extra extract until this last
197:56 - and about that
197:58 - some of these functions need to be in
198:01 - the exact order but others doesn't
198:04 - matter you can add them any way you want
198:07 - so the first one that need to be at the
198:10 - exact order which is this one which is
198:13 - load image
198:14 - load image because before doing any
198:17 - transform you need to load the image
198:19 - first
198:20 - so to load the image you need to use
198:23 - this load image d d is for dictionary
198:28 - because you can use more line with these
198:30 - dictionaries or you can use them just
198:33 - with opening images without using this
198:35 - dictionaries so when you do that without
198:39 - dictionaries you need to delete this d
198:42 - but if you are following my code or if
198:44 - you see the code doing by mona they are
198:46 - always using dictionaries because it's
198:49 - fascinating but it facilitates the ev
198:52 - everything in the code because if you
198:53 - use just script with all the parts it
198:57 - will be something painful but here you
199:00 - know that when you specif when you put
199:03 - you or when you use the keyword wall
199:05 - meaning you are talking to volumes here
199:07 - segmentation because you will find that
199:09 - everywhere when we talk about how to
199:12 - show images or how to train images
199:15 - everywhere will use these keywords so it
199:18 - is something that will help you and not
199:21 - be painful for you so i recommend you to
199:24 - use this way which is the dictionaries
199:26 - but if you prefer the other way of
199:28 - course you can use it and you need to
199:29 - delete this d at the end of all the
199:32 - functions okay
199:34 - so after loading the function the
199:36 - passion sorry you need to add a channel
199:38 - because as i told you in our case there
199:41 - there are two uh
199:43 - for us for now there are only two
199:48 - challenges for the output there is the
199:50 - first channel that represents the pixel
199:52 - for pixels or the mask for the
199:54 - background and the second channel will
199:56 - represent the mask for the foreground in
199:59 - that case you need to add a channel here
200:01 - so that you will have two channels okay
200:03 - okay
200:04 - but
200:06 - you will add another one for the for
200:09 - to specify the the batch size but it
200:11 - will be added here from the data loader
200:14 - don't worry about that and of course as
200:16 - i told you you will find everything here
200:18 - explained in this blog post okay
200:21 - now
200:23 - after adding a channel there is
200:25 - something that you need to do which is
200:28 - changing the pixels the dimensions the
200:31 - pixel dimensions of your passions this
200:34 - is as well one of the important things
200:37 - that you need to keep in mind
200:39 - because what you will do here i am using
200:42 - pixdem
200:43 - and this name here because i am using
200:46 - the speaks theme in this in the
200:48 - parameters or in the arguments of my
200:50 - functions that i have created and you
200:52 - can see that i am putting here 1.5 for
200:54 - the width 1.5 for the height and 1.0 for
200:59 - the depth of the pixel
201:02 - so
201:03 - in your case you will find maybe your
201:05 - because the problem here with the public
201:07 - dataset you will find that you will find
201:10 - some passions having uh
201:12 - two by two by two others zero five by
201:16 - zero five by zero five others one by one
201:18 - by one and if you use them as they are
201:22 - you will find we will cause a problem
201:24 - for that case you need to put them at
201:26 - the same dimensions okay for this case
201:29 - you need to use this function which is
201:31 - spacing which will change the spacing
201:34 - and puts
201:35 - all the dimensions the same and the
201:38 - problem that i told you here you will
201:40 - find the problem here with with the
201:42 - depth especially because with the width
201:44 - and height if you define just a constant
201:46 - number here it will fix the problem but
201:49 - with the depth it will cause a problem
201:52 - if you don't choose the right value here
201:55 - i am using one because i found that with
201:58 - data there is no problem with the value
202:00 - one but in others it may cause problem
202:03 - we'll come back to this later when we
202:05 - will talk about all the problems that
202:07 - you can face during
202:09 - using monae and
202:11 - deep learning for medical imaging
202:13 - now
202:15 - the next thing i will not talk about
202:17 - this because it's not that's important
202:20 - but here for example this one scale
202:22 - intensity range this is another
202:25 - important function
202:27 - which will change the intensity values
202:30 - or the intensity range of the of your
202:33 - images because if you print the maximum
202:36 - and the minimum value of your pixels you
202:38 - will find that it is from
202:41 - not all of them but some of them vary
202:43 - from
202:44 - minus 3000 into plus 3 000 others from
202:47 - minus one thousand five hundred into
202:50 - plus dollar one thousand five hundred
202:52 - they are huge values for this case you
202:55 - can never do a training with these
202:57 - values you need to put them from zero to
202:59 - one
203:00 - okay you need to normalize them but
203:02 - before doing that you need to change the
203:04 - contrast because if you don't do any
203:06 - changing of the contrast and leave them
203:09 - as they are
203:10 - the there is no visibility to the images
203:13 - for this case if you will you do a
203:15 - training or something like that you
203:17 - cannot recognize the different areas or
203:21 - different organs from the image for that
203:23 - you need to change the
203:26 - the contrast of your image for that here
203:28 - i am using because this
203:31 - b mean and b max are from
203:34 - what you you will normalize you the
203:36 - values will be from zero to one but this
203:39 - a mean and a max will represent the
203:42 - values that will change the contrast of
203:45 - your passions let me give you an example
203:48 - because for me now i am
203:50 - i as you can see here i am putting a
203:52 - mean equal i mean a max equal a max
203:55 - because these are the arguments that i
203:57 - will pass in this function
203:59 - for by default i am putting them minus
204:01 - 200 into 200 but i when i will call this
204:05 - repair i can change them otherwise if i
204:08 - don't specify them it will take these
204:10 - values by default okay i put this
204:12 - because i found that these values are
204:14 - the most uh the in average this is the
204:18 - important this is the best ones in the
204:20 - average but not all the time
204:22 - but how did i
204:24 - find these values now i will show you a
204:28 - simple trick that you can use to find
204:31 - these values for your specific data so
204:34 - let's open here etk snap
204:38 - and
204:39 - let me
204:40 - wait
204:42 - let's choose one of
204:43 - let's open this patterns for example
204:47 - now as you can see the visibility is
204:49 - little bit
204:50 - we can say normal we can see the
204:52 - different parts of the body so here we
204:55 - can see the lever with no problem but
204:58 - why because i am changing the contrast
205:00 - if i will not change the contrast i will
205:03 - go here to tools you need to click in
205:05 - tools then image contrast then contrast
205:08 - adjustments you will get this window if
205:10 - i will click in reset
205:12 - this is the exact or this is the
205:16 - the value that you can find as you can
205:18 - see here for example the minimum is
205:19 - minus 1000 to maximum is 140
205:25 - for byte or i don't know what is the
205:27 - unit for this pixels but the value of
205:30 - that
205:31 - pixel
205:33 - there are some pixels that they are
205:35 - having the maximum value which is 140
205:38 - for 1 1400 and others having minus 1 000
205:43 - etc etc
205:45 - in this case the visibility is not that
205:47 - easy
205:48 - for us we are doing liver segmentation
205:50 - maybe we can see it but it is not clear
205:53 - imagine me if you are trying to detect
205:55 - something like i don't know this one or
205:57 - something you cannot recognize it
205:59 - because everything has the same color
206:01 - for now
206:02 - so to do that you need to change it and
206:05 - you can choose you can use these
206:08 - arrows and try to find something visible
206:12 - but when i tried this it wasn't that
206:14 - great but i tried
206:16 - just changing values here randomly and
206:19 - for that when i found these
206:21 - here and here where i found the values
206:25 - not this
206:26 - sorry
206:28 - i found here
206:32 - here what what you need to change you
206:34 - can change here values and these are the
206:37 - minus 200 and the plus 200
206:41 - if you want to do some changes you can
206:43 - just adjust these values but you can see
206:46 - that
206:47 - the best thing is minus 200 and plus 200
206:51 - okay and if i will change here you can
206:53 - see that the values here are changing
206:56 - okay
206:57 - but
206:58 - if if you need if or if you want to use
207:01 - this for example this
207:03 - parameter and as you can see here this
207:05 - one is better than minus 200 okay so we
207:08 - can't just take this in concentration
207:11 - but
207:12 - you you don't need to use everything
207:14 - that you can see maybe for my data it is
207:17 - working well but
207:19 - for other data maybe it will not work
207:22 - very well for that okay
207:24 - so
207:26 - you can do a training with this
207:28 - otherwise you can just
207:31 - do do any changes here for example i
207:34 - don't know
207:35 - 100 and here
207:38 - for 500 or something and when you see
207:41 - that the
207:43 - the image or the
207:44 - organ that you want to detect is
207:47 - visible you can just take these
207:50 - minimum and maximum and this minimum and
207:52 - maximum are the values where you will
207:55 - put here
207:57 - a minimum and a maximum that will be
208:00 - placed in the scale internship intensity
208:03 - range
208:04 - and it will be here for a minimum and a
208:07 - maximum okay
208:09 - the next function or the next transform
208:11 - is this one crop background the
208:13 - foreground sorry this group foreground
208:16 - is one of the
208:17 - i will not say important because if you
208:19 - don't use it there is no problem but it
208:22 - is it is one of the useful functions or
208:24 - the useful transforms because here you
208:28 - can see that this is the whole image
208:30 - because it is the black area but
208:32 - i will just reset here
208:35 - just make it clear but you can see that
208:37 - it is a black area but it exists in the
208:40 - image for that case preferably you need
208:42 - to delete all these borders that you
208:45 - don't need and just take this foreground
208:49 - part for that case this function crop
208:52 - foreground is
208:54 - useful for that it will do that
208:56 - because you can see that
208:58 - in each function we do here when we want
209:01 - to specify that transform for the
209:04 - volumes we call the keyword volume when
209:07 - we want to do it for the segmentation we
209:09 - do segmentation when we want for both
209:12 - we write both of them and you can see
209:15 - that most of the time we
209:17 - apply it for every for every
209:20 - keyword which is for the volume and
209:22 - segmentation because we want to load the
209:24 - volume segmentation
209:26 - channel to the volume and segmentation
209:28 - change the spacing for the volume
209:30 - segmentation etc etc but here for the
209:33 - spacing for example we need to do it
209:35 - only in volumes because
209:37 - our segmentations are values from zero
209:40 - not from zero but values of zero and one
209:43 - so if you do the if you do some this
209:45 - these changes you will lose all your
209:48 - mask because they are binary mask so you
209:50 - don't need to change the segmentations
209:53 - for that we write here only volumes
209:55 - and now as i told you here there is
209:58 - say the second keyword or second
210:01 - argument which is source key because if
210:04 - you use the source key like segmentation
210:07 - here in that case segmentation it will
210:08 - be only black alia only something white
210:12 - in the image so if you do that
210:15 - it will crop all your
210:17 - your image and you will lose all the
210:19 - information and you will get only the
210:21 - white area or the place where there is a
210:23 - liver
210:24 - in your mask and
210:26 - in the slices where there is nothing in
210:29 - that slice what i am saying it will crop
210:32 - all the image for this case you need to
210:34 - put here source m source key which is
210:37 - the volume for that case it needs to see
210:40 - or to look at the image not to the mask
210:43 - so it will look to the image and crop
210:46 - this parts and leave only the
210:49 - interesting parts from the image which
210:51 - is the foreground okay
210:53 - now
210:54 - after doing the foreground here there is
210:56 - the resize
210:59 - transform which will resize your images
211:01 - and masks as well
211:03 - so that's what what i am using this here
211:06 - you can
211:07 - find that there is partial size
211:10 - this partial size is
211:12 - what i am putting here in arguments
211:14 - spatial size is the new spatial size of
211:17 - your images or the new dimensions so you
211:21 - can see that i am putting 128 by 20 128
211:24 - by 64.
211:26 - here i can put 64 or i can put 65
211:29 - because our data that we have created
211:32 - are 65 but i will leave it 64 there is
211:35 - no problem but you know that you can put
211:39 - here you need
211:40 - not you can but you need to put here the
211:42 - exact number of slices that you have
211:45 - created so if you have created the same
211:47 - number as i am
211:49 - using here then you can use 64. if you
211:52 - are using more than that you can but you
211:55 - need to change this value otherwise if
211:58 - you didn't create the groups as as i was
212:01 - talking about in few
212:03 - [Music]
212:04 - not minutes maybe a few hours before
212:07 - this part i talked about
212:09 - maybe you don't need to create the
212:11 - groups because maybe you have some
212:14 - new some numbers of slices
212:17 - almost the same for that case you just
212:20 - use here or you just need to put the
212:22 - average number or the minimum not the
212:25 - average but the minimum number so if you
212:27 - have you have passions with 4 with 100
212:30 - slices others with 110 others with 105.
212:34 - so in this case the minimum is 100 so we
212:36 - need to put here 100 so all your
212:39 - passions will be resized into 100 slices
212:42 - and for the width and the height you can
212:45 - put anything you want here but you you
212:47 - need to be um
212:50 - you need to be careful you don't need to
212:52 - put something that will make the image
212:55 - not visible and
212:56 - you will lose all the information of
212:58 - your image and i am putting it this
213:01 - smaller because if i will put it more
213:04 - than that the training will be very very
213:06 - slow and maybe will not be accurate
213:10 - not
213:10 - i think that if you put it 260 456 it
213:14 - will be more accurate because i tried
213:16 - this in another machine not mine
213:19 - but it will be slow okay but for that i
213:22 - don't want to put it in my machine
213:24 - because it will be slow for that i am
213:26 - using 128 because but if you have a good
213:29 - machine or good gpus you can use this
213:34 - you can increase this dimensions of your
213:36 - images when you do the resize okay
213:40 - and finally after the resize what you
213:42 - can do is to
213:45 - change or to convert these images into
213:48 - tensors so
213:50 - this one will open them do all these
213:53 - transforms and after doing everything
213:55 - you need to
213:56 - convert them also transform them into
213:59 - tensors
214:01 - you need to be sure that this function
214:03 - need to be the last function that to be
214:05 - called because you cannot convert them
214:08 - into tensors then resize them it will be
214:11 - an error and you cannot even run it for
214:14 - that you need to be sure that this two
214:16 - tensor is the final or yes the last
214:19 - function that you need to call okay
214:21 - so
214:23 - this all what we need to see
214:26 - but if you go here to the
214:29 - monas
214:31 - documentation
214:32 - you will find that they are they have a
214:35 - huge number of transform that you need
214:38 - you can apply but i didn't want to make
214:41 - it complicated i took only the necessary
214:44 - ones but if you want to put more you can
214:47 - put more
214:48 - and now let's let's talk a little bit
214:50 - about the data augmentation if you want
214:52 - to do some data augmentation
214:55 - then you need to see some transforms
214:57 - here from the exact page because their
215:01 - page of transformed here contains the
215:03 - transforms for pre-process and the
215:05 - transforms for data augmentation so you
215:08 - just need to search for it maybe you
215:10 - just need to search for the word
215:12 - augmentation or data or notation and
215:14 - find all the
215:15 - the functions because i used some
215:18 - gaussian noise there are some zoom there
215:21 - are some
215:22 - flip there are multiple
215:24 - transformers you can use and i wrote
215:27 - another blog post about that that you
215:29 - can see and take an idea about that i
215:32 - think i have some examples here for
215:34 - example this is the same passage with
215:36 - multiple transforms and i have created
215:38 - all these
215:40 - uh this one for with gaussian
215:42 - noise this one shifting this one with
215:44 - flipping rotation rotation everything
215:47 - you can find in the documentation and
215:49 - you can read this blog post just to have
215:51 - an idea about that
215:53 - and
215:55 - and of course of if you need or if you
215:58 - want to add some data augmentation you
216:00 - need to add it in the training parts not
216:03 - in the testing because in the test you
216:04 - don't need to do any augmentation
216:07 - augmentation have to be done in the
216:09 - training so you can find or you can
216:11 - search for the function add it here and
216:14 - of course before this to tensor okay
216:17 - so that's all about the functions
216:20 - and now let's talk a little bit about
216:23 - how to do the data loader deci loader is
216:25 - just to combine between the files
216:28 - which have which which we have been
216:30 - defined here
216:32 - and the uh the transforms that we will
216:36 - apply to each file or to each passions
216:39 - so this is the
216:40 - this is all what you need to know about
216:42 - the data loader it will combine the
216:45 - images or the files with the year
216:48 - transforms and it will apply to
216:49 - transforms and load them in your
216:52 - ram and you can use them after but there
216:55 - is something here which i am putting
216:57 - here cache this cache i am putting here
217:00 - in the arguments if it is false means i
217:03 - will not call it which is i am talking
217:05 - about this part if it is true i will
217:07 - call it here but what does it mean this
217:10 - cache function this cache function
217:12 - because there is you can use cache data
217:15 - set or you can just use dataset if you
217:18 - use this
217:19 - dataset after what i read and what i
217:21 - understand is that this function will
217:24 - load your data into the
217:27 - gpu memory in that case the training
217:30 - will be uh
217:32 - more fast or will be faster and it is
217:35 - true because i try that with the with
217:37 - the cash and without the cash with the
217:39 - cash is faster when i when i say faster
217:43 - is maybe
217:44 - five or ten times without the cash but
217:48 - although it will be slow because even
217:51 - with this crash it will be slow i don't
217:53 - know why but
217:55 - depending to how many percent you have
217:57 - how many what is the batch size that you
217:59 - are using and what is the how many
218:01 - epochs you want to train your model for
218:03 - that case you it will control your the
218:06 - speed of your training
218:08 - but
218:09 - using this cache will make your training
218:12 - faster but not all not always you can
218:15 - use it because if you have a lot of data
218:17 - and you have a small memory in your gpu
218:20 - in that case you cannot load it and if
218:22 - you do it
218:24 - it will start loading it and in some
218:26 - point it will give you an error saying
218:28 - that you don't have memory in your gpu
218:31 - so you can you may
218:33 - you can use it or you can try to use it
218:35 - at the beginning if it works but happy
218:38 - for you if it doesn't work just put this
218:41 - cache force or you can just don't touch
218:44 - it here and it is by default false and
218:46 - it will
218:47 - do the training directly we do without
218:50 - loading any passings in your gpu memory
218:53 - okay
218:54 - now after doing everything here what you
218:56 - need to do just to call it but for now
218:59 - what we need to do if we just call this
219:01 - function we cannot see anything we need
219:04 - to plot it for that i wrote this
219:07 - function for you i didn't wrote it to be
219:09 - honest it is i found this from the
219:11 - moonlight tutorial i just made some
219:13 - changes and i am using it as
219:16 - you are
219:17 - so i didn't do anything by myself i just
219:20 - did some changes i just write and write
219:22 - some documentation here because these
219:25 - are some problems of one eye there is
219:27 - not enough documentation to understand
219:29 - what they are doing
219:30 - and there is no
219:33 - raising well i am saying raising because
219:35 - when you will have problems you don't
219:37 - know what is the exact problem you need
219:39 - to spend days trying to find or to
219:42 - figure out what is the problem so these
219:44 - are two problems with mona if they are
219:46 - watching this video i hope that
219:48 - because you are having great
219:52 - framework but just you need to improve
219:54 - these things and thank you for that
219:58 - and now let's talk about how to ch how
220:02 - to show one passion and of course you
220:05 - can do it for
220:06 - multiple passions
220:09 - the same thing here i am creating a
220:11 - function called show passing that will
220:14 - show a passion you need to put in the
220:16 - parameter here the data loader that you
220:19 - have in your images so this email this
220:23 - part as i told you it will take the data
220:25 - loader which means it will take the
220:27 - output
220:28 - or the return of this function i did
220:31 - this species specifically because i
220:34 - wanted to make it easy for you you don't
220:36 - need to write the same code the same
220:40 - here at the same function here and but
220:42 - you can just call this function and take
220:46 - its output and use it as an input here
220:48 - and it will close your image or your
220:51 - passions for that i didn't want to use
220:53 - it as that's
220:56 - i just want to use it at the same
220:58 - function here i just made this function
221:00 - for the preparation or for the
221:02 - preprocess and this function for the
221:04 - showing one passes
221:06 - so this pass this function as i told you
221:09 - it will just take this data which is
221:11 - data loader and here we are returning
221:14 - the data loader for the training and for
221:16 - the testing for that i am taking here
221:19 - check passion training check passion to
221:21 - test because they here this is a list of
221:24 - two data loaders training and testing
221:26 - and now i am doing this view train view
221:30 - test and now what i am doing here this
221:33 - function
221:34 - called first it is from one eye this
221:36 - function first will just take the first
221:39 - passion from your data loader if you
221:41 - have 100 passes this one will return
221:43 - only one pass hint so that you can plot
221:46 - it or you can do anything you want with
221:48 - it
221:49 - so this first function will return this
221:51 - first passion this first one will return
221:54 - the first passing from the testing and
221:56 - now we have two passings to view them or
221:59 - to show them one from the
222:01 - from the training one from the validity
222:03 - from the testing
222:05 - and that's it i am using here if
222:07 - conditioned one for
222:09 - the training and one for the testing
222:11 - because if you want to see if a passion
222:14 - from the training
222:15 - or you want to see a passage from
222:17 - testing there is no
222:19 - specific thing because if you just want
222:21 - to see
222:22 - your data after pre-process so it
222:24 - doesn't matter if you see a training or
222:26 - testing passion
222:28 - but just i like to put everything here
222:30 - to make it clear for you maybe you
222:33 - you want to play with it for that you
222:35 - can just make this true force or you can
222:37 - put them both too so you
222:40 - plot one from the training one from the
222:42 - validation no problem with that
222:44 - so
222:47 - let's go with this here after doing that
222:49 - just you need to create your figure
222:52 - and i will put here supplies and as i
222:55 - told you these parts i took them from
222:57 - one eye and you can find them in my or
223:00 - other ways because there is just
223:02 - something like only pure python just
223:05 - create a figure figure and before that
223:08 - this
223:09 - much plots leave this function or this
223:12 - package here maybe you didn't have or
223:15 - you don't have it you know in your
223:17 - virtual environment or in your system so
223:20 - you you need to install it i don't know
223:22 - if i talked about this
223:24 - or not but don't worry about this at the
223:26 - end i will at the end i will give you
223:28 - the requirement.txt that you can use to
223:30 - install everything but if you are
223:32 - following the tutorials you can just
223:34 - install it by pick install
223:42 - install then mod plot
223:46 - lib i have it already so i will not
223:48 - install it and the same thing for this
223:51 - tkdm function
223:53 - this function is this library is not
223:58 - if i can say it is not one of the
224:00 - important things but it is included in
224:03 - some parts of the code not only my code
224:06 - but even in the code of monae's so you
224:09 - need to install it because it will just
224:11 - show you the progress so if you run a
224:14 - loop for loop for example it will be
224:16 - running the progress or showing you the
224:18 - progress in which
224:20 - iteration you are or something like that
224:23 - it is it is useful sometimes but for now
224:26 - mona is using it so you need to install
224:28 - it otherwise you will get an error okay
224:30 - so just delete this and
224:34 - now
224:35 - as i told you after installing the
224:38 - matplotlib just import it here much
224:41 - block clip as plt
224:43 - and for that we are using here
224:45 - plt.figure to create the figure plt
224:47 - that's upload to
224:50 - to supply our figure to divide into two
224:53 - parts because here i want one line or
224:56 - one row two columns
224:59 - and plot this first part in the first
225:04 - it's first deviation so if you we have
225:06 - window here we divide it into two
225:08 - so
225:10 - one row two columns and this is the
225:13 - first part where we want to upload the
225:16 - first passion or the first image and for
225:19 - for us the first pass the first image
225:21 - that we want to upload is the volume of
225:23 - that image which is the this part which
225:25 - is this volume
225:27 - and the second part here because this is
225:30 - the second part will be the segmentation
225:32 - of that same volume and here we specify
225:36 - the number of slices not
225:38 - numbers sorry the slice number so if you
225:41 - want to print the first slice second
225:44 - slice and the 64 or 65 slice which we
225:48 - have in my case if you have more you can
225:50 - print more otherwise you can even add a
225:53 - for loop if you want and
225:56 - bloat every every slice you have or
225:58 - every passing you have
226:00 - and you get the point this is for only
226:02 - one pass into one slice
226:05 - and if you want to do it for more you
226:06 - can just change it here as the arguments
226:10 - of my function i am putting here this is
226:13 - the required
226:15 - argument that you need to put the data
226:17 - loader which is the output of the
226:18 - preparation
226:20 - function
226:21 - then here you need you can specify the
226:24 - number of slice number otherwise it will
226:26 - take just the first one and here if you
226:29 - want to print a training passings or
226:32 - testing patterns and that's it that's
226:34 - all what you need now let's
226:36 - try to make an example about that let's
226:39 - run this cell by clicking in shift enter
226:42 - and the same thing for this one and the
226:44 - last one now everything is set let's do
226:47 - an example before that we need to uh
226:51 - we need to return the
226:53 - passion so i will just take
226:55 - this part
226:57 - i will give it in
226:59 - directory equal
227:01 - this here
227:03 - let's
227:04 - change this backwards slashes because
227:07 - sometimes it's give an example a an
227:10 - error so we'll just change them
227:12 - [Music]
227:15 - that's it
227:16 - now after having the in directory we
227:18 - need to create the passes
227:21 - so for example i will give it
227:24 - it is actually it is not passing there
227:26 - are passions so i can we can put
227:28 - spacings or i will put only one passing
227:31 - because we will print only one plot only
227:34 - one passing so let's just
227:36 - name it passions without that's s to
227:39 - make it complicated so passions equal
227:42 - now let's call the function prepare
227:45 - which we
227:46 - called here which we defined here this
227:49 - is the function prepare as i told you
227:51 - the first parameter is the in directory
227:54 - so
227:55 - we have called it the same thing in
227:57 - directory for the other parameters you
228:00 - can change them otherwise if you leave
228:02 - them as they are
228:04 - these are the the greater ones that i
228:07 - found in my case if you want to change
228:09 - them you can play with them and see what
228:11 - will happen
228:12 - but for now i will not change them
228:14 - because they are great for my type of
228:16 - data
228:18 - and now
228:19 - if we run this there is no problem you
228:21 - can see if we want to
228:23 - show one of
228:25 - the passing that we have so just call
228:28 - the function show
228:31 - passions i think this is the name show
228:33 - passions and now here we just need to
228:36 - give the passion
228:38 - as a parameter the other
228:40 - parts we don't need to to change them so
228:43 - for now it is one if i will run the cell
228:47 - it will take few seconds because it will
228:49 - do the data loader after that it will
228:51 - show you this passion now let me change
228:54 - this
228:55 - name
228:56 - this number of slices i think it is the
228:59 - second
229:01 - we can just
229:02 - write here for example
229:05 - five
229:07 - can see here
229:11 - now this is the fifth
229:13 - the fifth slice let's take for example
229:16 - 20
229:22 - and that's it's let's try for example 40
229:27 - and it will be the last one
229:32 - and
229:33 - that's it if you want to do more with
229:36 - that you can just play with this change
229:39 - the passings change everything you want
229:42 - and these are the two parts that
229:45 - that we need to talk about before the
229:47 - training because there is the
229:49 - pre-process
229:50 - and there is the second part which is
229:52 - the how to show one of your passing
229:55 - because we need this function for now
229:57 - and we'll use it after the training to
229:59 - print the results or to plot the results
230:02 - so
230:03 - that was how to do the pre-process how
230:05 - to show passions
230:07 - let's talk about now let's talk now
230:09 - about how to launch the training
230:11 - we're using one eye and paid off
230:17 - now
230:18 - before starting doing the training i
230:20 - will talk a little bit about the common
230:22 - problems that you may face because there
230:25 - are some problems that i found and i
230:27 - didn't know how to fix them because the
230:29 - error doesn't specify where is exactly
230:32 - the problem with my my code okay
230:35 - so i will show you only three of them
230:37 - which were common for me but maybe you
230:40 - will find others that maybe you didn't
230:42 - install numpy or something like this
230:44 - these problems are very common and you
230:47 - can find them but these problems with
230:49 - monae some sometimes you will not find
230:52 - any uh
230:54 - if you go in stock overflow or in even
230:56 - in monash
230:57 - repository in github you will not find
230:59 - answers about this these errors for that
231:02 - i will just give you these three errors
231:05 - that i found
231:06 - not i found but i faced
231:08 - during my project
231:10 - and
231:11 - others maybe if you will find other
231:13 - problems you may ask me in the comments
231:15 - or otherwise you may find them in google
231:18 - because
231:19 - these three problems are the only pro
231:22 - problems that i didn't find solutions
231:24 - after a while doing two or three days
231:27 - trying to debug the code and you will
231:29 - see that the error is something very
231:31 - stupid but you will not know does not
231:34 - cause the problem okay
231:36 - so let me just jump to the code and show
231:38 - you how i will do these mistakes with
231:41 - you and show you how you can fix them it
231:43 - is not it's not about fixing them
231:46 - because you may do everything good at
231:48 - the beginning and you will not face this
231:50 - code these programs but i just wanted to
231:53 - talk about them separately not in the
231:56 - in the in the code okay
231:59 - so the first thing is when you put you
232:02 - did when you put your uh input data to
232:05 - the path with the directory of your data
232:08 - if you do something wrong with it you
232:10 - will face a a problem that i will show
232:13 - you here how how does it look like the
232:15 - error
232:16 - and you may not know that
232:18 - the problem is your with your path
232:20 - because
232:21 - it will not tell you that you have a
232:23 - wrong directory or this directory
232:25 - doesn't exist you will not find this i
232:27 - will show you what is what type of error
232:29 - you will find and if you will get this
232:32 - type of error means that you are making
232:34 - the or you are putting a wrong part or
232:37 - wrong name of your folders or passings
232:40 - or something like this
232:42 - so
232:43 - here i am sure that this part is true
232:45 - but you can do a mistake with your path
232:48 - or
232:49 - some of the time you can you will not do
232:51 - a mistake with the path but i will show
232:53 - you where you can make
232:55 - or when you can do a mistake because it
232:58 - happened to me and it happened to a lot
233:00 - of people
233:01 - you will get wrong
233:03 - name of folders for example these ones
233:06 - because i told you when i shown you
233:08 - defaults i told you that if you want to
233:10 - use the same code you need just to name
233:13 - your folders as mine
233:14 - otherwise if you want to change them in
233:17 - your case then you need to change them
233:19 - even here because you will not get an
233:21 - error telling you that the problem is
233:22 - with the names of the folder but it will
233:25 - not work okay
233:26 - of course because the part is wrong
233:29 - so
233:30 - this first thing maybe you will forget
233:32 - an s here
233:34 - you may just write train volume you
233:36 - forget the s so in that case it will not
233:39 - work
233:40 - but it will not tell you that you are
233:42 - forgetting the s or you are you have the
233:44 - wrong part
233:45 - the second thing maybe you have nifty
233:48 - data not compressed which means you
233:50 - don't need this.gz
233:53 - and you are putting it here for that
233:55 - case the code will search for nifty
233:58 - compressed files and it will not find
234:00 - this nibs nifty compressed or zipped
234:02 - files in that case it will give you an
234:05 - error
234:06 - but it will not tell you that we didn't
234:07 - find this for this file or we didn't
234:10 - find a complex photo it will not tell
234:12 - you that so let me just leave it like
234:14 - this and i will run the code and i will
234:16 - show you how does the error looks like
234:18 - so now let's just run this cell
234:22 - the same thing this cell because i will
234:24 - try to show an image so that you can see
234:26 - because if we run only this you may not
234:29 - find the error because you will find the
234:31 - error when you call this function which
234:34 - is this prepare function so when you
234:36 - call it it will do the operations and it
234:38 - will find the error so to call it
234:40 - you can call it you are doing the
234:42 - training so you may face the problem
234:43 - during training but for us we didn't
234:46 - start the training yet so i will show
234:47 - you
234:48 - how you can face the error only when you
234:50 - are trying to plot one off or to show
234:52 - one of your passions so i run these two
234:56 - cells
234:57 - now let's go to the first problem which
235:00 - is this one as i studio everything is
235:02 - good here the directory is correct
235:04 - everything is correct only this
235:07 - name of passions which are everything
235:10 - does nii
235:11 - it should be that gz because for me all
235:14 - the passings are zipped but i deleted
235:16 - that so that you will find we see how
235:19 - how does the error looks like
235:20 - now let me run this cell
235:24 - let's wait few seconds so this is the
235:26 - error that you will find and it is
235:28 - saying that there is no object
235:31 - or the
235:32 - this because
235:34 - in reality what does it mean it takes
235:36 - this
235:37 - data loader which is the output of this
235:39 - function
235:40 - and take the first passion from that
235:42 - data loader and show it but it is saying
235:46 - that this data data loader or this view
235:49 - passion is not
235:51 - it's not talking about the opacity
235:52 - something called this check passing
235:54 - which is a
235:55 - output which is the data loader it is
235:58 - saying that there is there is nothing in
236:00 - this list it is like an empty list you
236:03 - cannot
236:04 - like doing the index zero index one it
236:06 - is not subscriptable
236:09 - so in that case
236:10 - you will see that
236:11 - your data loader is empty but there is
236:14 - nothing saying that the problem is
236:16 - before the data loader it is not saying
236:18 - that the path is wrong or there is no
236:21 - file name that's an i without the easy
236:24 - it is not saying anything
236:26 - so if you face this this problem you
236:29 - will not understand why your data loader
236:32 - is empty you may understand that your
236:33 - data loader is empty but why
236:36 - why it is empty because you forget this
236:38 - gz
236:40 - that's it maybe you can put that g and
236:43 - you forget z so this part doesn't exist
236:45 - so everything related with the part will
236:48 - not tell you that you have you are
236:50 - having a wrong path so in that case you
236:53 - need to check your parts check your
236:56 - files etc etc
236:58 - so
236:59 - that was the first error that you may
237:01 - face you may face this error saying that
237:04 - your data loader is empty in this case
237:06 - you need to verify before the data
237:08 - loader
237:09 - which are the path here
237:11 - maybe it can be these keywords but for
237:14 - the keywords i found it give you then it
237:16 - give you the specific error it will tell
237:18 - you key errors and it will tell you that
237:20 - the problem is with the key this is a
237:22 - good work but if you have problem with
237:25 - paths it will not tell you so be careful
237:27 - with that
237:28 - now let's go to the next
237:30 - next error which is when you put a wrong
237:33 - keyword in the dictionary
237:35 - so we are using here the same keyword
237:38 - vol for volumes sec for segmentations
237:41 - imagine with me if i will put here for
237:43 - example i do it wrong i put two l's so
237:46 - vol with two else i was writing my code
237:49 - very fast i didn't see this error
237:52 - so this
237:53 - of course i know you are python
237:55 - developer so this will give you an error
237:57 - so it will not work but sometimes you
238:00 - will not see it because i i remember
238:02 - one time i spent more than
238:05 - two two hours trying to debug the code
238:08 - and it was the pro the problem was here
238:10 - and i remember it wasn't even here
238:11 - because here it is very easy to see it
238:14 - it was inside my transforms i maybe it
238:17 - was here i don't remember maybe it was
238:19 - here so if you run the code
238:22 - where is the second error this one wrong
238:25 - so if i will run this code you will get
238:27 - this big error and you will get confused
238:30 - what is this error and i don't
238:31 - understand what is happening here and
238:33 - you can see that it is showing you the
238:35 - uh the arrays of your passions etc and
238:39 - you
238:40 - you
238:41 - for me i was like what is this what is
238:43 - all these writings i didn't understand
238:45 - what is the problem
238:46 - and the key and the problem is just here
238:49 - it will give you because for that you
238:52 - need to read the uh
238:54 - the error carefully this is not this is
238:56 - not my case sometimes when i see this
238:58 - big error i i don't
239:01 - i just stuck and i don't know what is
239:02 - happening here
239:04 - but actually you you maybe you didn't
239:07 - you don't need to read all this because
239:08 - you will not understand what is saying
239:10 - here but if you go just a little bit
239:13 - here you will see that
239:15 - uh where is it but it is saying that the
239:18 - drone is with key error and you come
239:21 - here to tell you that there is a missing
239:24 - key which is key was missing which is
239:26 - this v volume with two l's
239:29 - so in that case you see that's ah there
239:32 - is something wrong
239:33 - and because if you see the last error
239:36 - here because if you don't read that you
239:38 - go to the last error you will find that
239:40 - this is runtime apply and transform
239:43 - and you see what is the problem maybe i
239:45 - am i
239:47 - and it doesn't tell you even here what
239:48 - which transform is wrong so you may go
239:51 - to
239:52 - to all the transformers trying to change
239:54 - the values that's what i
239:56 - that's what i tried to do before i
239:59 - change these values of this big
240:01 - dimensions or
240:03 - maybe spatial size etc and the problem
240:06 - is little bit stupid because just you
240:08 - are putting an l here wrong and when you
240:11 - are stressed doing your project you may
240:13 - not see this type of error believe me i
240:15 - am saying this because it happened to me
240:18 - so
240:19 - but if you read the error carefully you
240:22 - you don't need to read all this
240:24 - writing because it's not needed but you
240:27 - go just here and here it starts telling
240:29 - you where is the problem and here you
240:32 - can understand that there is problem
240:33 - with the key error
240:34 - then you just go here little bits and
240:37 - you can see that problem with this
240:38 - transforms
240:40 - and of course there is here a keyword
240:43 - telling you that
240:44 - the key error telling you that this
240:46 - keyword is wrong and i think they may
240:49 - give you even the name of the
240:51 - transformers where there is the problem
240:53 - because here it is just telling you that
240:55 - there is problem with the keyword but
240:57 - which transform is having the problem
241:01 - [Music]
241:02 - i will just see which one if it give you
241:05 - or not
241:07 - i don't remember that
241:13 - transformed because the problem as you
241:15 - can see here is always telling you that
241:16 - the problem is with the transform okay
241:18 - we understand that but which transform
241:20 - is having this problem
241:22 - i think that it give you which
241:25 - transform having this problem but i
241:27 - cannot see it
241:29 - um
241:38 - no no there is nothing talking about
241:41 - that
241:42 - keyword dictionary yeah yeah that's it
241:46 - and you can see we spit spend time
241:49 - because i know that it exists and i
241:52 - spent few seconds searching for it
241:53 - imagine me if you don't know that there
241:55 - is this kind of errors you will not find
241:57 - it so you can see here runtime error
242:00 - applying transform at because at the end
242:02 - here it is saying the same error runtime
242:05 - error and applying transform but it
242:06 - doesn't say which transform is
242:09 - where which transform is having a
242:10 - problem but if you go a little bit here
242:14 - you can see that the problem is with the
242:16 - spacing the objects transform so you now
242:20 - you have two uh
242:22 - two heads or two keywords to see your
242:24 - problem the first one is you have a
242:26 - missing key with wrong key which is this
242:29 - volume with 2l and the second problem is
242:33 - this you see you know that which
242:35 - transform is having problem which is
242:36 - spacing d
242:38 - and you go just a little bit here
242:44 - now here and it told you that spacing d
242:48 - is having a problem and saying second
242:50 - thing is volume and you see now yeah
242:53 - this is a problem and you delete this
242:54 - and the same thing if you have a problem
242:56 - or we have missing key or wrong key in
242:59 - other
243:00 - parts it can be in the training or in
243:02 - validation or in testing because the
243:04 - problem
243:06 - if you have it in testing and you
243:08 - because all the time when we try to uh
243:12 - to to say not to say but when we try to
243:14 - test or to show passions all the time we
243:17 - use the training passage for that i
243:19 - added here training or testing if you
243:21 - need to you can you need always to use
243:24 - or to test your validation or your
243:27 - testing data so that you will understand
243:29 - because here when you will learn to
243:31 - launch the training because as i told
243:33 - you i am using the same code of the
243:35 - training used by monae so in this case
243:38 - not the same but i made some changes but
243:41 - you will see that
243:42 - in this case they will use the
243:45 - there is a part of which they are
243:47 - calling it validation i am calling it
243:49 - testing i told you why
243:51 - so
243:52 - during the training you will use some of
243:55 - data so that you can print or you can
243:57 - upload some of your uh validation
244:02 - metrics so we will calculate the loss of
244:04 - your testing and the laws of your
244:06 - validation the same thing for both for
244:09 - them they are not calculating the laws
244:10 - for the validation but i added it so
244:12 - that you will get the matrix for both
244:15 - validation and
244:18 - and for the notification for testing and
244:20 - for the training but
244:22 - in that case you will not see the
244:24 - problem only when you will run the code
244:26 - so the code will be run the training
244:29 - part will run without any problem when
244:31 - it comes to the testing which is the
244:34 - validation when it comes to the testing
244:36 - part it will try to load one of the
244:39 - passions and it will find that there is
244:41 - a missing
244:43 - problem with the part or problem with
244:45 - the keys or something like this and it
244:47 - will stop the training tell you there is
244:48 - a problem and you will not understand
244:50 - maybe you will not even know that the
244:52 - problem is with the testing only a key
244:54 - in the testing part so you need to keep
244:56 - in mind that if you get some of these
244:58 - errors maybe this one
245:01 - or maybe this one
245:07 - this one like talking about transforms
245:10 - or something like this you may get only
245:12 - the last one here you need to check your
245:14 - key for keywords in your dictionaries
245:17 - you need to just sure to check your
245:19 - parts of your data
245:21 - now after telling you about these two
245:23 - that is the third one which was one of
245:26 - the biggest problems that i faced in my
245:29 - project
245:30 - when you see doing the uh segmentation
245:35 - and of course most of the time you if
245:37 - you because if you do the segmentation
245:39 - by yourself it is easy and you may not
245:42 - get this type of errors but if you get a
245:44 - public data set or someone give you the
245:46 - public data set with the labels so in
245:49 - that case you may face these problems
245:52 - because maybe they are for us we are
245:54 - doing only liver segmentation
245:56 - but maybe you will and you will download
245:58 - data that have been used for liver and
246:02 - tumor segmentation or liver and heart
246:05 - segmentation which means two
246:08 - not two for three classes that is the
246:10 - background the liver and the heart or
246:12 - background liver and tumor etc etc
246:16 - so the data have been used for that case
246:18 - but you want to use it only for
246:21 - background and level only
246:24 - so in that case you you need only two
246:27 - classes background and foreground which
246:28 - will be level
246:30 - but the data has been haven't been done
246:32 - for that case so you need to change it
246:35 - you can change it before doing any
246:37 - training
246:39 - atk snap i shown you how i have shown
246:41 - you how can you
246:43 - just modify uh your segmentation so you
246:46 - can do it manually otherwise you don't
246:49 - need to do it because if for example you
246:52 - have data because if you have data for
246:55 - liver and tumor and liver tumor
246:58 - segmentation so the liver the tumor will
247:00 - be at the same part of the liver in that
247:02 - case you don't need to clean it before i
247:04 - will show you only in the code in the
247:06 - training part how you can just change it
247:08 - there
247:09 - but if the problem or if the the yeah if
247:12 - the error is in the tray in the
247:16 - for example the data has been made to
247:18 - segment level and heart for example so
247:22 - in this case you need to delete the
247:24 - segmentation for the heart because it
247:26 - will cause a problem but if the the same
247:29 - because sometimes even for if you have
247:31 - data only for labor segmentation you may
247:34 - get
247:35 - maybe the man or the person who was
247:37 - doing the segmentation maybe he did
247:39 - something wrong
247:40 - and in some cases
247:42 - at the same area of the liver he puts
247:45 - another color or another value or
247:47 - something like this so two if you have
247:51 - more than two different uh two different
247:53 - values so the code will will detect them
247:57 - as classes so more more values or more
248:00 - different values you have more the code
248:02 - will detect them different classes and
248:05 - that's what happened to me and you will
248:07 - get the error and you will never
248:09 - understand that error is happening from
248:10 - that and i wrote a code a blog post
248:13 - about that i will just show you
248:17 - but i will show you how you can do it in
248:18 - the good the the to fix this problem you
248:21 - will
248:22 - you will need to do it in the training
248:24 - part
248:25 - not before that because as i told you if
248:28 - you have segmentations for training and
248:31 - for the liver and heart so in that case
248:34 - you need to do it before the training
248:35 - and you need to delete all the
248:37 - segmentation for the heart but if you
248:40 - have the same
248:41 - you have only one segmentation but with
248:43 - different values i am talking values i
248:46 - am talking about the labels because they
248:48 - are masks binary mask it should be zero
248:50 - and one if you have multiple classes so
248:52 - it should be 0 1 2 3 etc each value
248:55 - represents what's one class
248:57 - but for us we are having only two
248:59 - classes so we need only two
249:01 - values which are zero and one and in my
249:04 - data here i have problems and i will
249:07 - show you how
249:08 - what are these problems i will just
249:10 - search for the problem
249:13 - uh yes this one you will get this type
249:16 - of errors
249:18 - it is this error is made from by torch
249:21 - when you will run the code you will get
249:23 - you will get something like this and you
249:26 - will not understand what is the problem
249:27 - you can read this blog post to see where
249:29 - is the problem and i i have here an
249:31 - example to show you if you have labels
249:34 - for example
249:35 - for us for me i was doing tumor
249:37 - segmentation so i had two tumors but for
249:40 - my case i didn't i didn't need to do
249:43 - instant segmentation which is the first
249:45 - stream or second tumor i didn't i did i
249:48 - just needed to know what is the
249:50 - background and which are the tumors so
249:52 - they should have the same value and the
249:54 - same color and here is the problem
249:56 - and
249:57 - now i will show you how you can
250:00 - fix it
250:01 - so as i told you if you have two
250:03 - different parts of the body segmented
250:05 - you need only one so you need to delete
250:06 - the second one using etk snap or any
250:08 - software you want to delete that part
250:11 - otherwise if you have only one organ
250:14 - segmented but with different values so
250:16 - you need to put them at unique value
250:19 - so i will show you one of the passions
250:21 - that i have where i have this problem so
250:24 - one of my passions for example this one
250:26 - has this this problem i will just print
250:28 - it here to show you
250:31 - so you can see that this passion here
250:34 - has two has three different values it
250:37 - has zero one two
250:39 - and in my code i will tell him that i
250:42 - have only two classes the background
250:44 - which has value zero and the foreground
250:46 - which has values one
250:48 - so the code will find these values too
250:50 - so it will detect them as a third class
250:54 - but in my code i will tell you that i
250:55 - have only two classes so in that case
250:57 - pytorch will have that error which is
250:59 - this one
251:01 - what is it this one this error you will
251:03 - get it and you cannot run the code with
251:05 - that error so all what you need to do is
251:08 - just to make a condition saying that all
251:10 - the values which are
251:12 - more different that's what i was doing
251:14 - different to zero i will put them true
251:17 - because i you can use zero and one or
251:19 - true and false because you have binary
251:21 - segmentation so you don't care about
251:23 - that
251:24 - so all what i did
251:26 - zero uh the values which are from uh
251:29 - different to zero i put them into true
251:32 - and the values which are zero i put them
251:35 - into false so that's what happened if
251:37 - you have multiple classes so you need to
251:40 - talk about that and you maybe if you
251:41 - have multiple class everything is good
251:43 - but for me i have only two classes
251:45 - foreground background and it is
251:47 - detecting something as it is giving me
251:49 - this kind of errors so in this case you
251:51 - need to change it okay
251:54 - so that was about the errors that you
251:56 - may face now let's talk let's start
251:58 - talking about the
252:00 - loss function that we will use and we
252:03 - run the script to do the training
252:10 - so for the loss function that we will
252:12 - use we will use the dice coefficient
252:15 - so that's coefficient which is or we can
252:18 - call it dice loss because sometimes you
252:20 - heard about dice coefficients and dice
252:23 - laws and i wrote a blog post about that
252:25 - it is this few months ago talking about
252:28 - what is the difference between them and
252:30 - you will see that there is no difference
252:31 - it is the same thing but
252:33 - you can use it as a metric or you can
252:36 - use it as a loss function i use it for
252:37 - both but you will see that it is stupid
252:40 - doing that but i just used used to both
252:43 - because
252:44 - i tried to use because even more like
252:46 - they are using dice laws for the loss
252:48 - function and they are using the compute
252:51 - they just function called compute dice
252:54 - metric but that's that dice metric the
252:57 - way they are calculating it it may cause
253:00 - an errors for me and maybe it can it may
253:02 - cause errors for you where you when you
253:04 - you have a lot of empty
253:08 - as i can see
253:09 - empty slices where there is no labels so
253:12 - i
253:13 - i understand what is the difference
253:14 - between them and i try to write the uh
253:17 - not function but it is it's a small
253:20 - equation in one line to calculate the
253:22 - dice coefficient from the dice laws
253:26 - actually we need to calculate the dice
253:28 - loss then we calculate the dice
253:30 - coefficients then we calculate the dice
253:32 - laws but
253:33 - monae are providing us directly the dice
253:36 - loss equation and it is working right
253:38 - good so we can go back from the dice
253:40 - laws into the dice coffee scenes i will
253:42 - give you just skew uh
253:45 - sorry not quick quick uh explanation
253:48 - about that and you will know that
253:51 - you can do it even yourself okay but of
253:53 - course i will provide you the code to do
253:55 - it
253:56 - but
253:56 - here the first thing that you need to do
253:58 - is to know is the dice what is the dice
254:01 - coefficient because all of you may be if
254:04 - you have done segmentation before
254:06 - or even you have the objective detection
254:08 - you know the intersection over union uh
254:12 - value or matrix so dice is not that
254:16 - different from the intersection of our
254:17 - union because the intersection of
254:19 - reunion is the intersection between the
254:23 - the ground root and the predicted mask
254:25 - divided by the union the ground root
254:28 - union
254:30 - the
254:31 - predicted mask but the dice value or
254:34 - dice coefficient is calculating the
254:37 - intersection here between the
254:41 - between the ground root and the
254:43 - predicted mask divided by
254:46 - the sum and not the union so divided by
254:49 - the sum and everything you will multiply
254:52 - it by two
254:53 - so i will give you this just small
254:56 - explanation that i have already done in
254:58 - the in this
254:59 - blog post so i am just reading it sorry
255:02 - about that but you will know that these
255:04 - graphs are more you will you will
255:06 - understand with these graphs more than
255:08 - just talking or writing
255:10 - so let's suppose that we have these two
255:13 - uh
255:14 - circles the first one for example a
255:17 - represents the predicted mask and the b
255:20 - represents the ground truth that we have
255:22 - so this is intersection of course you
255:25 - know it and this is when we say
255:28 - intersection over the sum multiplied by
255:30 - 2 means that we the intersection is only
255:33 - this yellow part divided by the sum we
255:36 - don't care about if they are the same or
255:38 - not we sum them and here we put the
255:40 - intersection
255:42 - so what is the the mean or what is the
255:45 - meaning of this case when you have or
255:48 - when you have a good segmentation or
255:50 - good model means that the intersection
255:53 - between the predicted mask and the
255:56 - the prediction and the ground truth will
255:58 - be almost the same so you will get only
256:01 - one circle here because they are
256:03 - supposed uh one uh one over one so you
256:07 - have the uh
256:08 - the ground rules is over the
256:11 - the predicted mask so in this case the
256:13 - value between them is the same
256:16 - and
256:18 - you sorry you will get only one circle
256:20 - which is in yellow here which is the
256:22 - intersection between them because they
256:23 - are the same and in the sum you will get
256:26 - the same thing because we said they they
256:28 - are the same so
256:30 - a plus plus b
256:32 - is the same thing which we are saying
256:34 - one plus one two plus two etcetera
256:35 - etcetera so you will get one thing here
256:38 - because only one
256:39 - divided by
256:41 - one plus one which is two times
256:44 - a or two times b because they are the
256:46 - same so you will get two times one
256:49 - circle or the intersection if you want
256:51 - to say and divided by two times the same
256:54 - thing so you will get one so one is the
256:57 - maximum value that you can get
257:00 - on the other side if you have for
257:02 - example the intersection is not your
257:05 - model is not is very very bad so the the
257:08 - predicted mask is very um
257:12 - it is not as the as your predicted mask
257:14 - so when you do the intersection between
257:17 - them you will get nothing so it will be
257:19 - zero so the intersection will be zero so
257:22 - when the intersection is zero divided by
257:24 - anything it give you zero so zero is the
257:27 - minimum value that you can get for the
257:30 - dice metric and one is the maximum value
257:33 - that you can get so the dice we are
257:36 - saying dice metric and not nice laws so
257:39 - when we say dice matrix so plus we are
257:41 - more we are closer to one more our model
257:44 - is good and more we are closer to zero
257:47 - means that our model is very bad in and
257:50 - there is no segmentation between the
257:52 - or there is no intersection between the
257:54 - predicted mask and the ground root
257:57 - and
257:58 - going from this case we can now
258:03 - choose the or find the the equation of
258:05 - the dice laws and the dice laws what we
258:08 - know about dice laws is not like those
258:10 - what
258:11 - the laws in general the dice the loss in
258:14 - general should be closer to zero so more
258:16 - we are closer to zero means that
258:19 - the error because the loss is an error
258:21 - between the predicted mask or the
258:23 - predicted thing which can be mask class
258:26 - or bonding box and the input which means
258:29 - the error between
258:31 - the output and the input so more the
258:34 - error is
258:36 - is slow which means
258:38 - which which means is closer to zero
258:41 - means that your model is good or your
258:43 - segmentation classification detection is
258:45 - good
258:46 - now we had only this nice value and this
258:50 - dice value we said that when it is
258:52 - closer to one is good and we need to
258:54 - know and we know that the dice loss more
258:56 - it is close to zero is good so what we
258:58 - can do is just to calculate the dice
259:01 - loss is one minus dice which is dice
259:04 - coefficient that we calculated so if
259:07 - this dice is
259:08 - good which means is closer to one or we
259:10 - can say one so one minus one is equal to
259:14 - zero so the dice loss is zero which
259:16 - means you have the minimum loss that you
259:18 - can get which will never get it but
259:20 - the dice law that this dice coefficients
259:22 - may be the maximum will be zero point
259:24 - nine nine nine nine nine nine something
259:26 - like this and one minus zero point nine
259:29 - it will be zero
259:30 - zero very good zero zero zero zero zero
259:33 - one or something like this so in that
259:35 - case you have a good loss good training
259:38 - or and good model
259:39 - so this type of those dice loss we will
259:43 - use in our case in our training there is
259:45 - another loss that you can use which is
259:47 - binary cross entropy laws for for them
259:51 - in
259:53 - in
259:54 - monae they are calling it cross entropy
259:56 - dice loss and it is the same thing i
260:00 - will just give you when we start writing
260:02 - the code i will just give you how you
260:05 - can calculate this
260:06 - cross-entropy because i used it and it
260:09 - was useful in some cases because when
260:12 - you are trying to segment for us we are
260:13 - trying segment level it is something big
260:16 - in the in the image so we don't really
260:19 - need this binary cross entropy but when
260:22 - you are trying to do something because i
260:24 - used it when i was trying to segment
260:26 - tumors so the tumors are small area in
260:29 - the image so in that case when where the
260:31 - tumor is small area means that
260:34 - you will get
260:35 - the number of pixels of the background
260:38 - thousand times or ten thousand times the
260:41 - number of pixels or of the foreground
260:43 - which is the tumors so in this case you
260:46 - will get you will get a problem called
260:48 - imbalance data
260:50 - this problem imbalance data is very
260:52 - simple from very common in the
260:54 - classification and we said that
260:56 - segmentation and classification are
260:58 - almost the same
260:59 - but we are classifying each class each
261:01 - pixel not on all the image so you may
261:05 - face this problem so you need to use
261:07 - that binary cross entropy that will
261:10 - penalize the model when the problem when
261:13 - the error is in the class that has
261:16 - minimum pixel values or minimum pixel
261:18 - numbers not values
261:20 - so i will just provide you after the
261:22 - code to do it to do it but we will not
261:24 - use it in our tutorial we'll use only
261:26 - dice normal dice coffee scenes and dice
261:30 - which is and the dice loss but you if
261:33 - you want in your case maybe you want to
261:35 - use this binary cross entropy or cross
261:38 - entropy dice laws you can use it using
261:41 - the code that i will provide to you
261:51 - so let me talk to you a little bit about
261:53 - the cross entropy the weighted cross
261:55 - entropy that i was talking about when i
261:57 - talk about the loss functions
261:59 - so if you have already know what is the
262:02 - because this is my master's thesis i
262:05 - just wanted to show you what is the
262:07 - difference so if you have the cross
262:09 - entropy
262:10 - laws that you have seen before or used
262:12 - before you will see that you have this
262:14 - equation which is this ground truth
262:17 - multiple the sum of the ground roots
262:18 - multiplied by the log of the predicted
262:21 - mass which is the output everything
262:23 - divided by or
262:26 - multiplied by minus 1 divided by n
262:29 - so this is the normal cross entropy loss
262:33 - but the weighted cross entropy it's the
262:35 - same thing but they are adding this w
262:38 - here which is the weight
262:39 - these weights are the things that we
262:42 - need to calculate and i wrote the code
262:44 - for you to do it you will find just here
262:48 - in utilities so this code code will
262:51 - calculate the weights these weights are
262:53 - nothing but probabilities so if you have
262:56 - for example 1 million
262:58 - pixel of black
263:01 - black pixels which are the background
263:04 - and you have for example 100 000 of
263:07 - pixels of the foreground which are the
263:10 - levels for example level nozzle levels
263:12 - but level for example so in that case
263:15 - you will calculate the probability
263:17 - between them so of course you will get a
263:19 - probability of pixels or having
263:23 - having
263:24 - pixels of background
263:25 - bigger than probability of pixels having
263:28 - foreground which is deliver
263:30 - but this thing here when you want to to
263:34 - calculate the weighted cos entropy what
263:36 - you need to do is invert them use the
263:39 - probability of the black pixels for the
263:42 - error when you are having uh when you
263:45 - are calculating the
263:47 - the dice or the weighted cross the cross
263:50 - entropy of the foreground
263:53 - so here let's let's give it a step by
263:56 - step
263:57 - so let's say we are calculating the
263:58 - cross entropy or we can say the weighted
264:01 - cross entropy so if we are calculating
264:04 - the errors of the background so when the
264:07 - model is
264:09 - is not predicting the background so if
264:11 - you have background and the model is
264:14 - giving you that there is a there is a
264:16 - foreground there so which means there is
264:18 - a tumor a level but in your case you
264:21 - know that not you but the label stays
264:23 - telling that there is no
264:25 - there is no background there is no lever
264:27 - there so it should the output should be
264:29 - a background but the model is outputting
264:32 - a foreground which is a level so in that
264:35 - case you need to penalize it out in the
264:38 - in the back propagation so in that case
264:41 - because the mother will be penalized
264:44 - depending to the error so if the error
264:46 - is big so the model will be penalized a
264:48 - lot so it will change the weights and it
264:51 - will be very penalized but if the
264:54 - problem is in your uh if the error is
264:57 - small for example 0.001
265:00 - so the mother will not change the with
265:03 - all the weights maybe a few of them or
265:05 - and it will not it will not do a big
265:08 - change because it knows that your model
265:11 - is accurate and it doesn't need more uh
265:14 - changes
265:15 - but
265:16 - as you know if the problem if the error
265:19 - is 0.9 or something is closer to one
265:22 - means that your model is very bad it
265:24 - doesn't predicting anything so
265:26 - all the ways need to be changed and
265:28 - that's it
265:29 - updated what i want to say not changed
265:32 - so
265:33 - the the idea here is if you have an
265:36 - error in the background or for us we are
265:39 - saying background because we know that
265:41 - the pixels of the background are maximum
265:44 - of the pixels then the boxes then the
265:47 - pixels of the foreground which is the
265:49 - liver because most of the area of the
265:52 - passions doesn't have a
265:55 - doesn't have a liver not doesn't have
265:57 - liver but the liver there is a liver in
265:59 - specific slices but all the other ones
266:01 - are empty which are for background
266:04 - pixels so if you calculate the uh number
266:07 - of pixels of the background you will
266:09 - find it ten times not ten times you
266:12 - playing this hundred or thousand times
266:14 - than the pixels in the foreground
266:16 - and even for this how to calculate the
266:18 - pixels because you will need them to
266:20 - calculate the probability there is a
266:22 - code that i write it there for you
266:25 - i think
266:27 - utilities
266:29 - show person yes this one this function
266:31 - which is calculate pixels it you will
266:34 - give it the data which will be the data
266:36 - loader which is the output of your of
266:39 - the preprocess function that we created
266:41 - which is prepared so the output of that
266:44 - function will go to this function and
266:47 - this function will calculate the number
266:48 - of pixels which are the pixels of the
266:52 - the
266:52 - the
266:54 - which which are the pixels of the
266:55 - background and the foreground so this
266:57 - function will output an array or a list
267:00 - of two values the first one is the
267:02 - number of pixels of the background and
267:05 - second one is for the foreground which
267:07 - are zeros and ones okay so
267:11 - the values that will be returned from
267:13 - this function you can use them here in
267:16 - the inputs
267:17 - of
267:18 - this so this val you one
267:21 - which will take the number of pixels of
267:24 - the background and this value too will
267:27 - take the number of pixels of the
267:29 - foreground which are the level in our
267:31 - case in your case you can you have
267:33 - something else or the same thing you
267:35 - want to segment but the background is
267:38 - the first one the further the foreground
267:40 - is the second one okay so just to make
267:42 - it easy because you can inverse them but
267:44 - you need to know that you inverted them
267:46 - so the output of your uh
267:49 - of this function which is the return of
267:50 - this function will be returned so you
267:52 - need to take care about that but you
267:55 - need to
267:56 - if you want to something clean you need
267:58 - to write them in the same order so your
268:00 - first class which is the class with the
268:03 - index zero needs to be one two to be
268:06 - here the second one is with the index
268:08 - one two three etc if you have only two
268:10 - so zero and one
268:11 - so this function as i told you it will
268:13 - return the probabilities but it will be
268:15 - inversed so of course we have the number
268:19 - of pixels for the foreground for the
268:20 - background are bigger than the
268:23 - background and then the foreground
268:26 - so what you will do
268:27 - you will use the probability of the
268:30 - background
268:32 - for the error in the foreground so for
268:35 - example let's say that the probability
268:37 - of the background is 0.9
268:39 - and the probability of the foreground
268:41 - which is delivered is 0.1 because we
268:43 - need the sum of them equal to 1.
268:45 - so this one the probability of the
268:48 - background is 0.9 the the error of the
268:51 - foreground is 0.1
268:53 - so what will happen when you are
268:55 - calculating your error here which is the
268:57 - weighted cross entropy when you are
268:59 - calculating the error of the background
269:02 - you will multiply the error by 0.1
269:06 - means that your error will not be bigger
269:09 - so it will be like almost not almost the
269:11 - same but it will not be bigger a lot
269:14 - than it is so in the back propagation
269:17 - when the model trying to update the
269:19 - weight will not change or change them a
269:22 - lot because the problem is in the
269:24 - background and you will not get very big
269:26 - problems in the background because we
269:28 - have a lot of pixels in the background
269:29 - so it will it will be well classified
269:32 - for that you don't want to update the
269:34 - weights when the problem is in the
269:36 - background not not update them but not
269:39 - change them a lot but when the problem
269:41 - is in the foreground
269:43 - you will multiply your loss by this
269:46 - weight which will be the probability of
269:49 - the background which will be 0.9 for
269:51 - example so if we have 0.9 multiplied by
269:55 - something smaller so
269:58 - what will happen 0.9 multiplied by
270:01 - something here the
270:02 - with the error here or the loss value
270:05 - will go higher so when the value of the
270:08 - error will go higher what will happen
270:11 - the weights or yes the weight will be
270:13 - updated more than that because they see
270:15 - that
270:16 - even doing some updates but the loss is
270:19 - always bigger so it needs to update it
270:22 - and to make it more smaller so this is
270:26 - the road of the weighted cross entropy
270:28 - it will penalize the model which means
270:31 - we are when we make the value bigger
270:33 - means that the mother will be penalized
270:36 - in the error in the foreground
270:38 - otherwise if the problem is in the
270:41 - background it doesn't need to change a
270:43 - lot of the weights or and it doesn't
270:45 - need to update the weight
270:48 - so this is what i understand about that
270:50 - if you only if you want to read more
270:53 - about it you can read but that's what i
270:54 - understand about using this weighted
270:56 - cross entropy when you have imbalanced
270:58 - data when you have a class having
271:01 - 10 uh not 10 but 100 or 1000 times
271:04 - data than the other so you need to do
271:06 - this otherwise for for the liver
271:08 - segmentation i used only the normal loss
271:12 - dice loss i didn't use this
271:15 - dice cross entropy but if you want to
271:18 - use it you can just call it as we are
271:20 - calling this here you can just call it
271:23 - dice cross
271:24 - dice cross entropy loss and you give it
271:28 - the
271:29 - all the air not the errors but you give
271:31 - it all all the
271:32 - values here and it will do everything
271:34 - for you and here there is a parameter or
271:37 - an argument would call the weights cross
271:40 - entropy weights so this quantum weight
271:42 - will take the weight that as i i was
271:44 - talking about which will be calculated
271:47 - using this function calculate weights so
271:50 - the return of this function will be the
271:53 - input of
271:55 - this argument which is cross-entropy
271:57 - weight so you just give us calculate
271:59 - weights which is the function that we
272:01 - have created
272:02 - and here in the argument of the weight
272:05 - of this calculate weights we need to
272:06 - give the values of the pixels which are
272:09 - the number of pixels of the foreground
272:11 - and number of pixels of the background
272:13 - and you can see here for example these
272:15 - values are from my
272:17 - tumor segmentation projects so you can
272:20 - see that there is a difference between
272:22 - them so you need to use this
272:23 - cross-entropy
272:25 - uh weighted entropy uh
272:27 - loss okay
272:29 - so
272:29 - this is the idea if you want to use this
272:32 - you have just to change these values by
272:34 - calculating the weights from using this
272:36 - function
272:38 - not the first you need to calculate the
272:40 - pixels it will return the number of
272:42 - pixels of the background and foreground
272:44 - then use these values here to calculate
272:47 - the weights
272:49 - and the return of this weight will be
272:51 - calculated here in this will be used
272:53 - here in this weights chrosotrophy
272:56 - weights which is this one
272:58 - so that was everything that i can say
273:00 - about cross entropy
273:02 - weighted cross entropy loss now let's
273:05 - start running this script to do the
273:07 - training
273:12 - now let's talk about the training script
273:15 - as you can see here there is everything
273:18 - you need to launch your training but i
273:21 - will go a little bit talking about what
273:23 - are the difference that i did because as
273:26 - i told you i took the for loop that will
273:28 - do the training from one eyes
273:30 - so i will just which is with this one so
273:33 - i will just explain few things that i
273:36 - changed the few things that has changed
273:38 - are i added a function that calculates
273:41 - because for them they were calculating
273:43 - the loss for the training and the metric
273:46 - dies for the uh for the for the they are
273:49 - calling it validation i am calling it
273:51 - testing
273:52 - but for me i added calculation for
273:55 - the validation or for the metric of the
273:57 - training and the loss of the valid of
273:59 - the testing so i will get four uh
274:02 - four outputs not for output but four
274:05 - graphs the first one is the loss of the
274:07 - training second one is the metric of the
274:10 - training than the loss of the world of
274:12 - the testing and the metric of the
274:14 - testing so and i needed to save them all
274:17 - because i need to use them for uh to see
274:20 - to analyze our
274:22 - our results to see if the model is doing
274:24 - overfitting and everything or something
274:26 - something like that
274:28 - so
274:29 - and all what you need to know is these
274:32 - are the arguments that you need to put
274:34 - to lunch to launch your training the
274:36 - first the first one is the model which
274:37 - will be unit for us the second thing is
274:40 - the in
274:41 - the data in which is the directory where
274:44 - you have your data
274:46 - and yes you have your data and
274:48 - the
274:49 - second thing is the laws where you have
274:53 - which which loss function you want to
274:54 - use then optimizer and the max epochs
274:58 - that you want to you to do
275:00 - for us maybe we launch for 300 or 400
275:03 - epochs
275:04 - then the model directory where you want
275:07 - to save your model trained model
275:10 - then here there is this test interval
275:12 - for them they are calling it validation
275:15 - because they are everything they are
275:16 - calling its validation i am calling it
275:18 - testings for that i just called it test
275:20 - by interval what does it mean this test
275:23 - interval will
275:25 - will uh
275:26 - control in what you know on in which
275:29 - epoch we want to save the new weights or
275:32 - the new training weights
275:34 - what does it mean for example let's just
275:37 - write here at the end
275:39 - let's just write for example as epoch 1
275:43 - we will get
275:45 - a a loss value for example equal 0.9
275:50 - okay and we will save this
275:53 - model or this checkpoint which are the
275:55 - weights then let's do let's go to the
275:58 - next epoch which is epoch
276:01 - 2
276:02 - okay so in the epoch 2
276:04 - we will get a loss equal to 0.8 for
276:07 - example so in this case the loss is
276:10 - is smaller than the epoch one for that
276:13 - mean so that means that the weights or
276:15 - the checkpoints in this epoch
276:18 - are better than these so we need to save
276:21 - the new epochs or the new model with the
276:23 - new ways which is in epoch 2. so we'll
276:26 - give the order that save
276:28 - i need to add a comment so save model in
276:33 - ebook
276:35 - too
276:36 - something like this okay then we will go
276:39 - to the next epoch for example let's go
276:41 - to the epoch tree
276:43 - and in this epoch we will get something
276:46 - like
276:47 - like for example let's say
276:50 - loss
276:52 - equals 0.85
276:55 - so 0.85 is bigger than zero point
277:00 - so in this case we can understand that
277:03 - the model or the checkpoint in this part
277:06 - or in this epoch are better than these
277:08 - so we don't i will
277:12 - so we don't need to save these weights
277:15 - because we have already better than them
277:18 - so we'll skip the saving in this part so
277:20 - what we will do like don't
277:25 - don't save the model
277:28 - in epoch
277:31 - tree
277:32 - so we go to the next epoch etc etc so
277:35 - this is that's what's always due in the
277:38 - in the
277:39 - in the training but if you are using
277:41 - tensorflow for example this will be done
277:44 - automatically if you just clone the
277:45 - repositories but while doing uh
277:49 - the training using pytorch you can see
277:51 - that we are writing all the for loop by
277:53 - ourself so we are doing everything we
277:56 - are calculating the
277:57 - we give we need to give the order to
277:59 - calculate the to to calculate for
278:01 - example the first output to pass by the
278:04 - model then we call the laws to calculate
278:07 - the laws then we call the optimizer etc
278:09 - etc
278:11 - so we as you can see we are doing
278:13 - everything manually so in this case we
278:15 - need to do even these conditions
278:17 - manually
278:18 - and now
278:20 - what they are doing they are calculating
278:22 - this metric which can be loss or even
278:24 - metric which can be dice for example the
278:26 - dice value so something like this and
278:29 - this is what they are using actually
278:31 - dice and i use the same thing
278:33 - so this dice they calculate the dice so
278:36 - more they have maximum value of dice
278:39 - more than
278:40 - and in that time they save the the new
278:42 - checkpoints
278:43 - but they don't calculate this dice value
278:47 - for the training
278:49 - that's why they are calling it
278:51 - validation indus in the training after
278:54 - each calculator in each epoch they
278:56 - calculate the new or the the dice values
279:00 - of the
279:01 - testing data which they are calling it
279:03 - validation data
279:04 - so when they have a maximum value or
279:08 - bigger value of the dice from epoch to
279:10 - epoch
279:12 - and they calculate it for for the
279:13 - validation data
279:15 - or testing data in that case they use
279:18 - this thing that nothing but they do this
279:22 - this savings so if this for example i
279:26 - will go here like
279:28 - validation or for for me testing data
279:33 - okay so let's say that the first
279:37 - the
279:37 - first dice equal to
279:40 - for example zero
279:43 - point
279:44 - one for example and zero point one is is
279:47 - bad because we need it higher we need
279:49 - closer to one so the dice is 0.1 that's
279:53 - the e-book for example
279:56 - a book
279:58 - one okay now let's go to the epoch 2. so
280:01 - in the epoch 2 if we calculate this dice
280:04 - it will be for example 0.2 so the model
280:07 - in this epoch is better than the first
280:09 - one because here we have the epoch
280:12 - ctrl c
280:14 - control v and here we have epoch2
280:17 - but what they are doing because if you
280:19 - calculate in each epoch i am doing it
280:22 - but it will slow your training a little
280:24 - bit because imagine with me in each
280:26 - epoch you calculate the dice of all your
280:30 - validation data so you do the training
280:33 - find the new model and pass all your
280:36 - testing data by the model and calculate
280:39 - this dice value
280:41 - and
280:42 - going from that value you will save that
280:44 - model in that specific epoch or not
280:46 - so
280:48 - to give the order if you want to
280:49 - calculate this dice or to do this
280:52 - verification in each ebook or in each
280:54 - two epochs or on each three ebooks or
280:56 - something like this this will be
280:59 - controlled by this
281:03 - what is it the training so that will be
281:06 - calculated by this test interval they
281:08 - are calling it validation interval for
281:10 - them they are using this value equal to
281:12 - so in each two epochs they calculate the
281:16 - new dice for all the validation data for
281:18 - them testing data for us and when they
281:21 - get higher value they save that
281:24 - checkpoint for me i used one because i
281:27 - prefer to calculate in each epoch but
281:30 - for you if you don't
281:32 - use that value if you want to fast
281:35 - little bit your training so you can put
281:37 - it two or three or depending on your
281:40 - cases so this value one is by default
281:43 - but when we will
281:46 - call the script or the training function
281:49 - here we can specify it here for me i am
281:51 - not putting it but if you want to give
281:54 - it you can just write test interval
281:56 - something like this and give it two or
281:58 - three or anything you want which will
282:00 - change that
282:02 - value by default
282:03 - and for me i want to leave it one and
282:06 - that was all the parameters that you
282:09 - need for this function
282:10 - and as i told you there is the first
282:12 - thing is the model for us we are using a
282:15 - mono uh sorry a unit but we will import
282:18 - it from one eye as you can see it is
282:20 - here monae monae.networks.net imports
282:23 - units there are other networks but we
282:26 - are using unit
282:28 - so there are these three uh
282:31 - important things that i will i will talk
282:32 - about the first thing is dimensions we
282:36 - said that we are doing volume
282:37 - segmentation which is 3d segmentation or
282:39 - 3d units for that we need to make
282:42 - dimensions equal 3 for 3d
282:44 - and the input channel for us it is one
282:47 - because we have masks with only one
282:49 - channel i am talking about slice each
282:52 - slice has only one channel and that
282:54 - channel have zeros and ones
282:56 - but the output channels we need them to
282:59 - be two each because the number of the
283:02 - output channels is the same number of
283:04 - the classes that you have so the first
283:06 - channel will represent the probabilities
283:08 - or the pixel probabilities for the
283:10 - background the second channel will
283:12 - represent the pixel probabilities for
283:14 - the foreground okay and when you combine
283:17 - them together you get the new uh you get
283:19 - the final output so these are the
283:22 - important things that we need to talk
283:23 - about these are the chain channels which
283:25 - which controls how many kernels or how
283:28 - many filters you want to put in the um
283:32 - how they call it in the convolution
283:33 - blocks and these are the strides and
283:36 - this will create the residual new units
283:38 - and this one to normalize the batch but
283:41 - we don't need to talk to you know
283:43 - everything about that but these three
283:46 - things that are important the first
283:48 - thing is the dimensions which is three
283:50 - for 3d the input channel is one because
283:53 - we have each slice has only one
283:54 - dimension the output is two one for the
283:57 - background segment for the foreground
283:59 - because we have only two classes if you
284:01 - have more it will be more etc etc but
284:04 - others here we have just to call the
284:06 - loss function here is the dice cross
284:08 - entropy if you want to use it i talked
284:10 - about it before
284:12 - and this loss function that we will use
284:14 - we are using a sigmoid here
284:16 - and then the optimizer we are using the
284:19 - adam optimizer with a learning rate 0.
284:23 - 10 minus 10 minus
284:26 - 5. so that's what you can use for you if
284:30 - you want to change it you can just
284:31 - change the values here you can change
284:33 - multiple to find multiple times or you
284:35 - can just make that function that's very
284:38 - which give you an interval of
284:41 - learning rate and it will be changed in
284:43 - each epoch on age 10 epochs or something
284:45 - like this but for me i am putting a
284:47 - constant number for you if you want to
284:49 - change it you can change it it depends
284:51 - to you
284:52 - but that's all what i will talk about
284:54 - here
284:55 - after all what you need to do is just
284:57 - run this
284:59 - this script and as i told you that in
285:02 - this type of training it will take time
285:05 - it may take two two days that's what
285:07 - this is strange but it may take two days
285:09 - depending to your machine and how many
285:12 - data you have and everything
285:14 - and that is other things that i have
285:16 - talked about in the pre-process part
285:19 - i told you that there is this parameter
285:22 - which is the cache it can be false or
285:24 - true
285:26 - and i told you if we put it through
285:28 - means that we will use disk function
285:30 - which will load the data in the memory
285:32 - of the gpu
285:33 - otherwise we will not do it so if you
285:36 - have a good memory you can just hear
285:39 - what is the data
285:41 - the this is this function prepare we
285:44 - call the data so we can just here
285:46 - make cache which is this
285:49 - argument and we put it as true so if we
285:52 - put it through it will load all the data
285:54 - in the memory of the gpu otherwise it
285:58 - will be false so if you put it through
286:00 - it will be the training will be faster
286:01 - faster than without the cache but
286:04 - sometimes if you don't have memory you
286:06 - cannot do it so i will just delete this
286:08 - because if you we do it i will show you
286:09 - that it will take time even before to
286:12 - load the data then it will start
286:14 - training i will just launch it like this
286:16 - so that you see that the training will
286:18 - start after that you can use the cache
286:20 - if you want
286:22 - so if i will run this script
286:25 - you just wait a little bit
286:27 - and this is because here i am putting 20
286:30 - for 20 epochs so i will do 20 epochs and
286:34 - it will calculate the dice train dice
286:36 - and it will calculate the loss for each
286:39 - uh image as you can see here and it of
286:42 - course is starting by a higher value of
286:44 - loss but it will change it will be
286:46 - changed
286:47 - so that's all what you need to do to do
286:50 - the training so and but you need to wait
286:53 - as i told you with gpu for me i have gpu
286:56 - gtx
286:58 - 10 1080 or 1070 i remember
287:01 - but as you can see here you can define
287:04 - define the gpu that you want to use if
287:06 - you have multiple gpus so you can just
287:08 - change the index here otherwise you can
287:10 - leave it like this if you have only one
287:11 - so it will be with the index 0.
287:14 - so
287:15 - that's what that's all what you need to
287:17 - know about the training
287:19 - and nothing else you need just to wait
287:22 - for the training until it will be done
287:24 - and of course here you need to specify
287:26 - the model dear where you want to save
287:28 - your model or your checkpoints plus your
287:31 - plus all the
287:34 - things which are here the loss values or
287:37 - the lows yes the loss values for each
287:40 - epoch and the metric values because we
287:42 - are doing here a save train loss and
287:45 - there is a save a book so this will will
287:49 - save everything that we need so it will
287:51 - save the new in each epoch it will save
287:54 - the new values so the first epoch for
287:56 - example you will get 0.9 the second
287:58 - epoch it will be 0.3 so it will create a
288:01 - list containing all the values for each
288:04 - epoch and it will save them as a numpy
288:06 - list that we can load after and plot it
288:09 - to see what was happening in during the
288:11 - training
288:12 - so that's what i can talk about you need
288:15 - to wait for this training if you want to
288:18 - use google collab it it may work but if
288:21 - you are having a large number of data it
288:24 - may take more than 24 hours and you know
288:27 - that
288:28 - that google collab doesn't sell for i'm
288:30 - talking about the free one it doesn't
288:32 - allow you to to do a training more than
288:34 - 24 hours depending even to your internet
288:37 - connection it will not if it will not
288:39 - cut so you know you need to be careful
288:42 - about doing the 3d convolutions here
288:44 - using
288:45 - 3d unit it will take time you need to
288:47 - know that
288:48 - otherwise there is nothing else to talk
288:50 - about
288:51 - and we will talk after the training i
288:54 - will show you the results that you will
288:56 - get
288:57 - and you will see that you we will not
288:58 - get a perfect result because in medical
289:02 - imaging you will never get something
289:03 - like perfect or like in the other images
289:06 - or other tasks
289:08 - but you can just see the first results
289:11 - after that because for me what i was
289:13 - doing is i made
289:15 - tons of trainings i
289:17 - i launched the first one then i i tried
289:19 - to change something of the data i chose
289:21 - to try to add more data otherwise uh try
289:25 - to change the learning rate there are
289:27 - tons of things that you can change i
289:29 - cannot talk about them all here but
289:31 - because i am telling you only the basic
289:33 - thing and the basic code that you will
289:35 - find in mulai i'm just transforming some
289:37 - things here to make it easy
289:39 - but that's it if you want to make a
289:42 - better better better training you need
289:44 - to do these changes learning great or
289:47 - the the best thing that you can do is
289:48 - adding more data but adding more data
289:52 - means that the training will be more
289:53 - slow but of course at the end it will be
289:55 - better than less data so
289:58 - we will wait until the training will
290:00 - stop and try to analyze our results
290:08 - so now after doing the training let me
290:10 - show you some of the results or the
290:12 - results that i found for my project
290:15 - so i when i i launched the training i
290:18 - put 600
290:20 - epochs but i stopped it as the epoch 100
290:24 - because i know if i will leave it into
290:26 - 600 epochs it will take time and the
290:28 - second thing that uh
290:30 - why i did stop the training at the apoc
290:33 - 100 because i found that here at
290:37 - i don't know at the apoc 100 before 100
290:40 - it was in 80 70 something like this
290:43 - we get this flood here which means that
290:46 - if we add more epochs of course the
290:48 - training loss it will go down and it
290:51 - will converge more than that but for the
290:53 - validation it will always stay here for
290:56 - that i didn't want to leave it to leave
290:58 - the training going more than this
291:00 - because
291:02 - we may get a overfitting or we may get a
291:05 - model which is not very accurate with
291:08 - the validation of with the testing data
291:11 - and for that i will i already will show
291:13 - you one of the passing that i passed it
291:16 - by the model and i will show you the
291:17 - results and you will understand why i
291:20 - should stop the training here okay
291:23 - so to do it i have this uh
291:26 - japanese notebook
291:28 - file that i will share it with you so
291:30 - that you can test your uh
291:32 - your model after the training so the
291:35 - things that you need to to change are
291:37 - only these two parts the path to the
291:39 - data and the path to where you save the
291:43 - model plus these files okay if you
291:45 - remember when we did the training we
291:47 - need
291:48 - in each one in each epoch because i i
291:52 - fixed the i put the number or the value
291:56 - interval test interval into one which
291:58 - means in each epoch it will calculate
292:01 - the through the training not the
292:03 - training but you can get the testing
292:05 - metric
292:06 - or the testing loss the same thing but
292:08 - it will calculate one of them but for
292:10 - for me i did it to to calculate the the
292:13 - test metric so when i get a higher value
292:17 - of this metric in that case i should
292:19 - save the
292:21 - weights okay
292:22 - so
292:23 - i should save the weights which which is
292:25 - the model but in each epoch i should uh
292:28 - save the loss trade the training of the
292:31 - loss uh sorry the loss of the training
292:33 - and the metric of the training the loss
292:35 - of the testing and the metric of the
292:37 - testing in each epoch
292:39 - so that i can plot it like this and you
292:41 - can see this evolution of the laws for
292:44 - the training and these are for
292:46 - validation
292:48 - after doing this now let's let's
292:50 - load one passing or we can load all of
292:53 - them but i will show you only one
292:55 - that i prefer to use not prefer but i
292:58 - will show you how does this look
293:00 - and you can test your test your final
293:03 - model with multiple passions otherwise
293:05 - you may not get the best or the yes the
293:09 - best or the great the perfect model at
293:12 - the beginning so you can do more changes
293:14 - and launch another training okay so for
293:17 - my 100 ebook it took me around five or
293:20 - six hours
293:22 - to be completed okay so you should put
293:24 - this in mind but but i was i was using
293:27 - the cache so the so the
293:30 - data was loaded in the
293:33 - gpu memory for that it took six hours if
293:35 - i didn't do that it will take more than
293:37 - that okay
293:38 - so
293:40 - and but it took six hours for only 100
293:43 - 100 apr i stopped it if i left it into
293:47 - 600 epochs it will take two days maybe
293:50 - okay
293:51 - so for you if you will launch your
293:53 - training in at 6 00 60 600 ebooks for
293:56 - example and if
293:57 - as the epoch 100 or before that you see
294:01 - that your model is doing well and you
294:03 - don't need more training so you can stop
294:05 - it okay you don't need always to
294:07 - complete the whole 600 epochs it is a
294:10 - choice and they are it is a huge number
294:13 - of ebooks so if you see that your model
294:16 - is doing great before that you can stop
294:17 - it okay
294:19 - now
294:19 - when you do when you want to load one of
294:22 - the passions of course you should apply
294:24 - the same transforms that you applied
294:26 - during the training and the testing of
294:28 - course so these are the different
294:32 - transforms that we applied for the
294:33 - training and the same thing i will apply
294:35 - here then we have a test loader because
294:39 - we want to load the testing files so we
294:42 - load them and of course you need to load
294:45 - your model which is the unit
294:48 - and after loading the model this part
294:50 - here will load the weights and put them
294:52 - in the model because you need to create
294:54 - the model first then put the weights or
294:58 - two yes to fill the model with your
295:00 - weights or with checkpoints that you
295:02 - have you have saved during the training
295:04 - so this one will create an empty model
295:07 - this one will put the weights into that
295:09 - model now you have the model ready ready
295:12 - model with the weight that you can use
295:14 - directly for your testing part
295:17 - so
295:18 - as i told you i took only one patient to
295:20 - show you so you can do all the changes
295:22 - to to bloat or yes to show multiple
295:25 - passions but you should you need to be
295:28 - careful with that because the data
295:31 - loader is not like a list you cannot
295:33 - just put data loader zero data loader
295:36 - one extract so you cannot do this you
295:38 - can do for example a for loop
295:40 - so you can do for example i will just
295:43 - write here
295:47 - for passions for example in
295:50 - test
295:51 - loader
295:52 - this one will will work
295:54 - and you can use this way for example if
295:57 - you want to to play to load the first
295:59 - one so you can just add an index here
296:02 - for example
296:04 - i
296:06 - and here you can put enumerate in this
296:08 - data loader and you can say if i equal
296:11 - zero then call this function that will
296:14 - plot otherwise don't do that if
296:17 - this is one way the other way that i use
296:20 - as well which is here
296:22 - when
296:24 - what is it here when you select here i
296:26 - am talking about the test but it should
296:28 - be test here
296:30 - for example
296:32 - so what i am doing here is just
296:34 - selecting a few passions from your data
296:38 - set so if you want to show for example
296:41 - the first one you can do for example
296:42 - zero to line for example if you want to
296:45 - show a second one you can just put
296:47 - from one
296:49 - two nine then from three to nine two
296:51 - twenty etcetera etcetera for example you
296:53 - can put here nine or anything you want
296:56 - so that's what does it mean you will get
296:58 - a new list of passions and always the
297:01 - first person that you will get here he
297:03 - is the passions that you want to show so
297:06 - this is one way that i found not found
297:09 - but you can use this way other thing
297:12 - that because you cannot do like like a
297:15 - list like here i cannot i cannot put
297:18 - here for example this order zero it will
297:20 - not work and it will give you an error
297:22 - about that for that you need to find
297:24 - another way which is for example as i
297:26 - told you before putting the data into
297:28 - the data loader select which passes you
297:31 - want to do the pre before the pre
297:33 - process you need to select which passion
297:35 - so you can do that way or the for loop
297:37 - way that i showed you it up to you but
297:40 - this is the way how you can do it and
297:43 - this script will run on it which will
297:45 - pass each uh
297:47 - it will pass all this like all the
297:49 - passions into the model because we said
297:51 - it is a 3d model 3d unit or cd
297:54 - segmentation so it will pass the whole
297:56 - passion which is here 3d the d volumes
297:59 - which is test volume it will pass it by
298:02 - all the passing for all the passing for
298:05 - with the 64 slices it will pass it by
298:08 - the model here in the model
298:10 - and it will calculate the
298:13 - the output or predicted mask and here
298:15 - this for loop is just to print all the
298:18 - slices of that specific passion so here
298:21 - you can see i will show we start from
298:23 - the wrong segmentation so you can see
298:26 - here for example for these four
298:29 - uh
298:30 - one two three four five six
298:33 - seven
298:35 - we can say seven until eight so this
298:38 - these eight four slices are not well
298:40 - segmented okay
298:42 - so you can see that
298:44 - for these uh the segmentation is great
298:47 - we i i cannot say perfect but it is
298:49 - great but for the
298:51 - the first ones it is not that good
298:53 - so these are
298:55 - the things that you need to keep your in
298:58 - mind in medical imaging you will never
299:00 - get something uh perfect because you can
299:02 - see that
299:03 - we as human and sometimes we cannot
299:05 - differentiate you can see this and this
299:08 - part is it not equal to this one so you
299:10 - can say that this is a level okay but
299:12 - the model fortunately it is not
299:13 - segmenting it as a level but you can see
299:16 - that it is not easy to know which part
299:19 - contain which is the the exact part of
299:21 - the human body so you can see that this
299:24 - is not bad it is segmenting etc but you
299:27 - need to keep in mind because you need to
299:29 - do a lot of changes to get more accurate
299:32 - so you can maybe test these values maybe
299:35 - you can change the contrast for now you
299:37 - can put it like this you can do another
299:40 - training with another values so the
299:42 - contrast will be changed so in that case
299:44 - maybe some
299:46 - some patterns will be better or will
299:49 - look better than these values for
299:51 - example so you can try to
299:53 - changing these or you can the best thing
299:56 - that you can do is try to add more data
299:58 - so you can try to add more data you can
300:00 - change the learning rate
300:02 - there are a lot of things that you can
300:03 - do but
300:05 - and of course you can do more uh
300:08 - more processing or you can add the data
300:11 - augmentation that i talked i told you
300:12 - about i didn't want to add it but you
300:15 - can add this augmentation and sometimes
300:17 - it works very well so why i don't want
300:20 - to try everything because as you see
300:23 - even only 100 epoch took me 500 500 5
300:28 - hours
300:29 - if in my pc so if i will try multiple
300:33 - multiple trainings and multiple
300:35 - parameters it will take me forever to
300:37 - find
300:38 - the best model so but here in this
300:40 - tutorial on this course i am just
300:42 - showing you how you can write the code
300:45 - how you can
300:46 - use the different functions in monae but
300:49 - it up to you to do different changes to
300:52 - do multiple
300:54 - combinations to get the best results but
300:57 - you need to keep in mind in medical
300:58 - imaging you will never get something
301:00 - perfect but you can i am sure that if
301:03 - you do more changes more data etcetera
301:05 - you will get better than these here for
301:07 - this part it is good but for example
301:09 - here it is missing some segmentations
301:11 - okay and you can test it for other
301:14 - passions you will find that sometimes it
301:15 - is good perfect but others is not that's
301:18 - good
301:19 - so that was how to do the training
301:22 - testing how you can as you can see how
301:24 - you can see your segmentations in the in
301:27 - the final part what i will do i will
301:29 - show you just how you can clone the
301:31 - github repository and use it directly so
301:35 - maybe you don't need to write the code
301:37 - by yourself so you can just clone the
301:40 - github repository and launch the
301:42 - training from it so i will show you just
301:44 - in a few few minutes how you can do it
301:47 - so that you will get an idea about that
301:54 - now after that we have done everything
301:57 - step by step
301:58 - now i am telling
302:00 - because i told you that i will give you
302:01 - the code and you will find everything
302:03 - here in this repository so i tried to
302:06 - write some sentences here to explain
302:09 - some of the parts but i didn't have time
302:12 - to write everything but with time i will
302:14 - try to add more and more explanations
302:17 - and of course i am writing some blog
302:20 - posts about all what we were doing we
302:22 - were doing in this course so if you
302:25 - prefer to read instead of watching
302:27 - videos you will find them but i will
302:29 - publish them soon okay because i didn't
302:31 - finish all the blog posts for now so
302:34 - when i will finish all of them i will
302:35 - post them in my website
302:38 - and after understanding what we were
302:41 - saying now what you need to do is just
302:43 - to for example if you want to use the
302:45 - same code that i am using so you can
302:47 - just clone this repository using this
302:50 - part here so just go here and click in
302:52 - this button to copy this line
302:54 - and go to your terminal
302:56 - and cd or change directory into your
303:00 - workspace otherwise if you are using
303:02 - visual studio code so just open the
303:04 - folder where you want you to work and
303:07 - paste it in the terminal here not there
303:11 - and this terminal and paste your this
303:14 - git git clone this repository so this
303:17 - line will clone the repository which
303:18 - means it will download all the files
303:20 - that you have in this repository in this
303:22 - work space i will not do this because i
303:25 - have already this
303:27 - this repository cloned as you can see
303:29 - here so you will get this folder which
303:31 - contains all the files that you find
303:34 - here in this github repository okay
303:37 - so the first thing that you need to do
303:39 - is to install the requirements so there
303:42 - is the first thing here
303:45 - i am putting that
303:46 - and of course when you do this when you
303:50 - you can unders this repository you need
303:52 - to cd to that repository so that you
303:54 - will your new workspace will be this
303:57 - repository so that you can oh you can
303:59 - directly use the code inside that
304:01 - repository so just copy this cd
304:05 - like this and copy and paste it in your
304:09 - in your here in your terminal and it
304:11 - will go
304:12 - to the next repository as you can see
304:14 - here i have already that repository okay
304:17 - so that
304:19 - if i will just
304:20 - make cd
304:23 - and now if i will paste this cd then
304:26 - lever segmentation using mona and python
304:28 - and then it will go
304:30 - it doesn't go because maybe there is a
304:32 - problem with that
304:34 - because i am putting it here wrong
304:36 - [Music]
304:38 - so just
304:40 - correct this spider something like this
304:42 - okay
304:43 - so all what you need to do is just to cd
304:46 - to this directory after doing this you
304:48 - can start installing what you uh
304:52 - what we what we used and of course as i
304:54 - told you about the virtual environment
304:56 - if you need or if you prefer to install
304:59 - to create virtual environment or conda
305:01 - environment you can do it before
305:02 - installing any packages
305:04 - otherwise if you prefer to use your
305:06 - system you can do it directly but i
305:08 - don't recommend you to do that
305:10 - so just copy this to install monae after
305:14 - that all the the other requirements are
305:16 - will be found here in this file
305:19 - requirement.txt so you need to install
305:22 - must not leave numpy
305:24 - blob
305:25 - but when you install globe you need to
305:27 - do group 2 because if you do pip install
305:30 - globe it will not be installed because
305:31 - it is not recognizable
305:34 - then you need to install the control
305:36 - nifty then this channel but before doing
305:39 - it you need to
305:40 - you need to type this keyword because if
305:42 - you do install chat it will not be
305:44 - installed and the same thing for me
305:46 - bubble but don't worry about this you
305:49 - just need to copy this part which is
305:51 - this one
305:52 - pip install dash r then requirement.txt
305:56 - and it will install everything
305:58 - then after installing all the
306:00 - requirements that you need all what you
306:02 - have to do is start coding but as i told
306:05 - you there are
306:06 - some stuff
306:08 - which you will find here the first thing
306:10 - that you need to do is to convert your
306:13 - nifty files into dcoms so that you can
306:16 - create groups using this function that
306:18 - you can call with another main script
306:22 - which will call this function from this
306:25 - file so you can just do imports create
306:28 - or from
306:30 - from what is the name from preprocess
306:32 - that's pi imports create groups and you
306:35 - can just use it to create groups using
306:37 - this function the same thing to do the
306:40 - to convert from the dcom to nifty and to
306:43 - find the empty and finally for the
306:45 - preparation after doing all this stuff
306:48 - and creating the folders with the names
306:50 - that you need which which what i mean
306:52 - with the folder for the volume training
306:55 - volumes training segmentations testing
306:57 - volumes and testing segmentations after
307:00 - that you can just use this function
307:02 - which is prepared to do the pre-process
307:04 - and
307:05 - that's it if you want to do the
307:08 - if you want to show your passions you
307:10 - can find the function show in utilities
307:13 - here
307:14 - i will go here there is the function i
307:16 - think it is at the end
307:18 - yes yes this function
307:20 - will be used to do the or to show one of
307:23 - your passions the same thing all the
307:25 - functions that we were using will be
307:27 - found
307:28 - either in this
307:30 - in this file which is pre-processed the
307:31 - spy for the pre-processing and all in
307:33 - the utilities that you will find some
307:35 - functions to calculate the dice metric
307:37 - calculate the weights for the weighted
307:39 - cross entropy and this function train
307:42 - that you need to do
307:44 - and finally there is this function which
307:46 - calculate the pixels i talk about this
307:48 - as well
307:49 - for when you if you want to use the
307:51 - binary the weighted cross entropy you
307:53 - will need this function and that's it
307:56 - after knowing everything you just need
307:59 - to call this function which is train to
308:02 - to launch your training so for that
308:04 - there is this file which is
308:07 - trained as pi which will call exactly it
308:10 - will call this prepare for to for the
308:11 - play process and it will call the train
308:14 - from utilities import train to do the
308:18 - to do the training using that function
308:20 - train so the first thing is to create
308:22 - the model and launch the training so
308:25 - this
308:26 - this script is like a main script to
308:29 - launch the training but if you want to
308:31 - do the pre-process because if you want
308:33 - to create the groups etc you need to
308:35 - create another script called main or
308:37 - something like that to do all the
308:39 - preparation
308:40 - outside your training etc so after doing
308:43 - the training when you need to test your
308:46 - model you will find this jupyter
308:47 - notebook test that's ip
308:50 - notebook and b
308:51 - so if you open it it will take time some
308:55 - few seconds
308:56 - and you will find everything we
308:58 - explained
308:59 - in the previous minutes you will find
309:00 - them here and just launch this code but
309:04 - by change changing here the path to the
309:07 - data and the part to the result or the
309:09 - checkpoint
309:10 - and everything will work
309:12 - and that's it that's all what you need
309:14 - to know about this
309:16 - project but if you have any questions
309:18 - any problems please don't hesitate to
309:21 - send me emails leave a comment or
309:23 - contact me by er in social media on my
309:26 - website pycad dot co i have no problem
309:29 - answering you answering you but maybe
309:32 - sometimes it will i will take
309:34 - few days or day or one day or two days
309:37 - to answer you if i have projects working
309:39 - on so please don't hesitate to send
309:42 - messages or emails and i hope to s to
309:45 - answer you as soon as possible
309:48 - so i see you in the next courses if you
309:50 - have enjoyed this course please don't
309:52 - forget to thumbs up or leave a comment
309:55 - and i see you in the next videos bye

Cleaned transcript:

one practical use case for artificial intelligence is healthcare imaging if you're interested in the fields of machine learning or artificial intelligence this is a great course for you mohammed who is a computer vision phd student will teach you how to use pytorch and monae for automatic liver segmentation my name is mustard amin i am a research assistant and phd student in computer vision today i am presenting to you my course about liver segmentation using monae and pytorch by this course we'll start by defining what is unit then we will talk about how to prepare our data we'll start by downloading them preparing them and doing the preprocess then as i told you during the preprocessing to data and applying all the transforms that we need to do for medical imaging using monae then we will talk about all the installations that we need to do from one eye by torch cuda dnn etc etc so we'll talk about all the packages that we need from the python packages into the other softwares okay then we will talk about what are the common problems or errors that you may face using one eye for medical imaging of course then we'll talk about the training part which which script that we will use how does it work extra etc then after that we will talk about the testing parts after finishing the training we will analyze our data not data but we will analyze our model and we will pass some testing passions and see what our model is giving us if it is going great or not and i will give you some advices how to fix or how to make your accuracy better if it doesn't go go well at the end and after that at the end i will show you how you can just clone the github repository if you understand everything i will say in this course you can just clone the github repository and try using the scripts so i will show you how you can clone it how to install the different packages and how to use all the scripts that i am providing you in this github repository a little bit about unit so unite is a deep learning architecture for semantic segmentation it was created first for biomedical imaging so when you if you are interested you can read the uh the uh paper so in their paper you will see that this architect architecture was created for biomedical imaging and because it is a great architecture and it has a good accuracy they started using it for the other image segmentation tasks so now let's talk a little bit about something else and we'll go back to the architecture after now maybe some of you die doesn't know what is the difference between image classification object detection or image segmentation so the image classification as you can see it is what is the easiest task in deep learning so image segmentation means the image classification sorry means that if you have an object in an image so you just need to know if there is no there is that specific object in the image or not so in this case we have a cat in the image so the output of your model or classification model will be a problem probability that means that you have a cat or not with a probability from zero to one more closer to one means that this object exists in the image but that's all what you need to do this object exists or not then there is the object detection which means that you need to create or to draw a bounded box in the image or localize the objects in the image not only saying that this image contains a cat but you need to draw a bonding box which means we need to localize it in the image so this is the object detection then the image segmentation means that you need to draw a mask in the image to refer to all the pixels that has that have the same object so in our case we need to specify which pixels have the uh the object which is the cat so in that in this case we need to draw all this mask to refer to the cut in the image so this is the image segmentation then in the ms segmentation there are two types that is here the first type is the image segmentation which is semantic segmentation and the second one is the instance segmentation now here in the left you can see this is the in semantic segmentation means that you need only two segments how many classes you have which means here we have only two classes we have the class person here and the class background so that's all what you need to do in instance instant segmentation you don't care about how many people you have or how many other objects you have in your image you don't you don't care about that you need only two segments the classes that you have here we have class person class background but in the instance segmentation don't only you need to create to segment the classes but you need to specify how many uh objects or how many people here we have in that image so in this case we have person one two three and so far which means that you need to segment the person and say this is a person one this is person two etc etc so if you have two three or more than that classes so and in each class you have more than one object in the image so you need to specify this is the object one from the class x this is the object two from the class from the same class which is class x etc etc so unit is an architecture to do semantic segmentation which means it will do only this type of segmentation it doesn't do this type you can see faster mask mask faster cnn to do instant segmentation but you net you can use it only for semantic segmentation and that's all what we need in our project we need to do a liver segmentation so we need to know what is the liver and what is the other part of the body which is the background so we don't need to have there is no two levels in the same person or something like that so that's all what we need segment the liver and the background so we will for that we will use a unit here now let's talk a little bit about the architecture the architecture is in the shape u for that it is called unit for this shape okay now units you need to know that unix is one of the easiest architectures in deep learning there is nothing hidden or there is nothing difficult on it you can see that there is only or there are only convolution layers and followed by a max pooling convolution layers max pooling convolution layers max pooling and here it will do up convolutions and max pulling up convolutions etc but why they are doing this because unit is divided into two parts there is first part called the encoder which is this one here the down we can we can we can call it the down blocks or the down part here for us which is called the encoder so we don't care about the names but this part here is going down which is the encoder so if you if you look clearly to this part it is looking like a normal image classification architecture okay there is nothing new that is only here convolution blocks because this one is called the convolution block but it is convolution layered followed by max pooling convolution layers max pooling and each output of these these convolution blocks there is a real function so if you understand what is happening here you can see that this is a normal image classification architecture and here this is the final output that we can put it we can pass it by a softmax layer or something to see the output but this is not what we need here we said that our output that we need we need it to be a mask with the same width and height of the input image so that we can specify specify each pixel uh and its class which means pixel one goes to class zero or class background or class lever or something like that for that we need to do this part which is called the decoder so this decoder we take the feature that we have extracted in this encoder part and use them here to build the output image so that you will have each pixel instead of having only one pro one probability for all the image no you will have a probability for each pixel so that you can classify each pixel how many uh uh to which class it goes for us we call this pixel probability not a normal image probability or something like that now let's take an example about how does the output of unit look like here is for example this is one or this is the output that i used for my project which was the tumor segmentation in the whole body so i took just this example to show you how does it look now this is the input mask which is the label or the ground rules you can call it as you like so this is the input mask i didn't have the time not time but i didn't have the space to put the image as well but i think this is enough to see so this is the mask that you have now these are the two outputs of not it is one output with two channels of the unis so if you have this output here or this output channels differs from how many classes you have so if you have two classes so you will have two channels you have three classes you will have three channels etc etc each channel will have the pixel probability for a specific class so in my case i had two channels the background two classes sorry the background class and the foreground class which has the tumor and in our project here we will have two classes the first class is the background the second class will be the level so this was the my outputs this is one of my passions so these are these are the channels for one output this one refers this is the output zero this is out this is the channel zero this is the channel one so this one refers to the background and this one refers to the foreground which is the tumor now the values that you see here more value more the color closer to the yellow means that the value of these pixels here is closer to the value one which because we said we have pixel probabilities which means differs from zero to one so more we have the value yellow more we have the uh the that's pixel goes to the class zero which is the class background and more the value goes to the purple here means that the value is closer to zero so if the value is closer to zero so means that these pixels doesn't go to the class zero which is the class background and here same thing for this part but this channel is the channel for the foreground which means for the pixel 4d for the i forget the name this channel is for the tumors so these values here you can see that they are closer to the yellow means that these pixels contain a a tumor and all these pixels doesn't contain tumor which means these pixels are background and same thing for here so you can use only one of these channels to specify your your predicted or your final prediction or you can use all both of them and use a arg max or you can use a softmax or anything you want to apply or only a simple threshold and get the final output so that's what we will do in uh in the in this course so but these all these parts will be will come later after doing the training and etc but just i am showing you how does the output of unit looks like so you will have this is the label you will have two channels or how many classes you have in our course we will have same thing two classes the background and level so you will have pixel probabilities of each color of each pixel and using arc mugs or a simple threshold you can specif you can get your final binary mask which is like this this values are one these values are zero so this is a binary mask or force and two you can use as anything you want depends to how you are uh doing the threshold or something like that because if you will do a normal threshold so you have force and two if you are using a normal arg max so you have zero and one but it is the same thing you don't need to care about that now that's it and thank you for this part and now let's do some installation now let's talk a little bit about the software that we need in our project we need only two these four softwares which are we need python vs code 3d slicer and etg snap i am not talking about the dependencies like python dependencies that we need like your monae et cetera but all these dependencies will not talk about them now but we'll install only the the software that we need the first one is python as you know because we'll execute our code using pytorch and monae and of course using python not plus or other programming language then we need the text editor where we will need to write our code for that we need to install vs code so this is my choice and you can use any text editor you want but my preference i preferably need to use vs code but if you want or if you prefer using another one or maybe you you want to use jupyter notebook or something like that it depends to you and it doesn't change anything just i am showing you what i will use this in this course so you can follow me if you want then we will use 3d slicer so this 3d slicer we will use only to display our data and we use it as well for something else we may need a conversion that cannot be done using python but we will talk about this in the image in the processing or in the preprocessing part but for that we will need this this 3d slicer software after that we will install it snap because we will need this type of software maybe we will not use it in this course but maybe you will use it because we can i will show you how you can do the segmentation or correct the segmentation using this bt case now because i don't know if you will use the same data set that i will use or maybe you will use your custom dataset so for that case maybe you don't know how to segment or how to correct your segmentation for that we'll use this atk snap software and of course i will show you how we can use it for now i have all these softwares installed in my computer but i will show you how you can do it by your own now let's go here we said that we need to install python first so we have python.org then slash downloads as you can see here this is the latest version which is 3.10 if you want to use this one it's different to you if you want to use another version so you can just click on windows and all these all these versions they are here but don't worry about this maybe i will show you in the following videos when we start coding and when we start installing dependencies we will i will show you that sometimes we need to create a virtual environment and where we will install a specific version of python in that specific virtual environment but at first we will install one of these versions and maybe you need to install the 3.10 doesn't matter because maybe we'll use it only for some preprocess not even preprocessing but we used for preparing the data because we will have for we will pass by three or four phases before doing training because there is preprocess but before the preprocess we need to do something with this data because you know that medical imaging are very very hard to use or to treat for that we need to do some preparation after that we'll do the play process because these are two different processes for that i am saying prepare and play process because uh i am saying i am i i want to say that there are there are two different types okay so if you if you want to install for example python 3.10 just click on this or you can just go here in downloads and download python 3.10 and just save it anywhere you want like this and it will be downloaded of course my internet connection is a little bit slow for that i need to wait a little bit so just you need to execute this command and follow all these steps i don't want to do it because i have already python i have a lot of versions of python installed on my pc for that i will not do this here but you can see that you just need to here because in my case i have already python so i need to install it then install it again but for you you will have only a button to say install and follow up all the steps and it will be installed so i will cancel this yes then here we said that you need to install python here is after that you install it now it is done now we need to install this text editor which is vs code and of course i have it already as you can see in my pc but i will show you just how you can download it and maybe try to install it so vs code download like this and you go here to code that vs code studio and there is order is this link both of them are official so you just need to click here now we have windows and it depends to how many which operating system you have so in my case i am using windows so you can just go here windows and windows 10 and click on download here or it will start the download by itself but if it doesn't start you can just click here on download okay now you need just to install the to to download this one maybe it will take time because as i told you my internet is slow these days so just download this and install it and follow the steps as you will do with python and it is very easy to install as any other software i will just cancel here now after sorry after that we don't need this for now now after installing this vs code let's talk about 3d slicer tree slicer is the same thing it is a free software that you can find here 3d slicer slicer download like this and this is the 3d slicer download just check which operating system you want just take the stable release don't take this one so just choose windows mac os or linux and for my case i am using windows so i need to download and install this one but but but as i told you i have already the software so i will not go and install it again especially my internet connection is slow but you get the point download this and install it step by step it is free and easy then after installing 3d slicer here because i told you that we will need it for some preparation of our data and visualization of course as well then we have the etk snap that we will use for segmentation by the way you can use etk snap for segmentation but sorry you can use 3d slicer for segmentation but i found this little bit difficult because you will see that etk snap is easy very easy it is old but it is very easy to do the segmentation than using 3d slicer but if you have already used 3d slicer for segmentation so you don't need to follow me doing this with etk snap okay so i am telling you with my experience i tried to use 3d slicer and i tried to use other softwares for segmentation but the easiest one was atk's not for me for that i am presenting you just need to etk snap okay and i cannot use use et case now for the uh some preparation for that i need 3d slicers so each one has a specific advantages and disadvantages okay now let's search for atk's not like here we have now we have this or we can just click on download downloads here you can see even the uh web page is too old but it is a good software okay so you can just choose for example windows or and all these versions you will take the latest one okay now you can use for windows mac os linux or something like that the best to you and your operating system so for me of course i would use this one but i told you i have it already on my pc so i will not take the time to download it and install it again so that's all what we will need for our course i am talking about the software we go back after to talk about the dependencies but for now you need to install python vs code i will leave all the links in the description so you need to install python vs code 3d slicer and etk snap and aft after installing this we'll go back and we'll continue doing our course now let's talk about the data set i will show you how you can find some public data sets otherwise if you have already data set in your projects then you can use it but if you don't have and if you maybe you are trying to do this segmentation just to improve your skills for that case in this case i will show you how you can find some public data set so the first source that i will show you that it was helpful for me and it contains a lot of data is the decathlon data set so this digital data set as you can see here there is i think nine tasks we will go here that is papers data there is more things but what we we are interested in is only the data set so we just click here in the guest data and you remember with me you just write the card long data set you will get the first link here but i will leave all the links in the description don't worry about that but when you click here go to get data and it will open the google drive here and you can see that all these tasks as there is 10 tasks as you can see here so all these tasks means that all these are group of data which means it is really you will find the volumes with the segmentation so everything is ready just need to download it and use it but here you can see that there is brain tumor there is heart there is liver as you can see here there is hippocampus there is pro proscad prost sorry prostate and there are all these things that is lung etc etc and this one as you can see here this task nine which is the spleen which was used by monae so if you go to my website here for example i will choose it because our course is based on moonlight as you remember so if you go here in monae and you see the project that they are doing here for example we go to github and most of the projects and most of the tutorials that they are using here you will find that they are using this data set and we see that the because i found this decathlon data set from monae website so when you go here you will find this spleen data maybe you want to to try it i don't know but in our project we'll use the liver segment the liver segmentation so but i am not using this one you can download this one and it depends to you and what you want to try okay so for me i found the data set from cargill i will show you as well there how you can find that and i i'm sure that there are other data sets but for now you can find the best ones here in this website and in kaggle i will show you the data set that i will use in this project if you go here in cargo go to datasets maybe you you need to if you want to search in general you can write just healthcare images or healthcare datasets or medical imaging and found all the tasks that they have otherwise if you are searching for the exact data that i am using or i will use in this course is lever segmentation so just write level segmentation like this so here you will get all these results but these are the the because i am saying these because there is this first part and the second part of the data that i used in my project in discord so if i will open this and this in the other another tab you go here and you found all the these segmentations and these are the volume segmentations are the labels and these are the volumes and you can see that they are not completed for that there is the second part that you will find the other volumes of the first one here so you can download this i have them so i will not download them but you can download this if you want to use the exact data that i am using so you can download this first part and second part put them in the same same folder or something and we'll go to them later now after that you choose your data sets it can be this one this one or other task but what i want you to know is while using monae framework you need to have data set with the extension nifty so it should be and i i dot and i or compressed nifties but you need to have the base the base extension nifty for that reason you need to search for data that has nifty or or you can search for data that can be converted into nifty for example it can be an ldd or an rd or it can be dcom or any data that can be converted into nifty otherwise you cannot use these kinds of data with one eye for why i am saying this because if you are using simple 2d segmentation you can use anything you want and you don't need one line because i am using monae especially for the preprocess part because you can't find a good framework that help you to do preprocessing as the 3d volumes in medical imaging i couldn't find something better than one eye for that i am using because mona is great thing they are not paying me to say this but it is a great framework for medical imaging they have some problems and some things that they need to fix i will talk about them in some in the future lectures or future minutes but before for now i am saying that it is great framework but some improvements does need to be done we will talk about them later so i if you you need to put this in your mind when you want to use mona you need to have nifty files if you don't have a specific niche device you need to find data that can be converted into nifties so how you can convert this data into nifty this is another question so some of the the some of the extensions can be converted using python for example like the dcom images if you have series of decode because a nifty file is a series of decomps because the decom here i will show you an example this one as you can see here this is all these decons that's that goes to one passion so all these d comes each d com is one slice of a ct scan when we combine them all these d comes together we get one volume that one volume is one nifty file because when you take one nifty file and put it into the slicer or any other software to visualize it you will see that it it contains a lot of slices so each slice is a decom file that's what you need to know i don't know if you know that but i am just saying that so as i studio try to find nifty files or files that can be converted into nifties now you get this data if you want to convert them for example if you want to if you have dcoms like these and you want to convert them into nifty you can use 3d slicer but i think that for this kind because there is a python uh the patent package that does help you to do this conversion for that we don't need to use this there is d come to a nifty package that you can use it install it using pip install but don't worry about it we will do this later because now i am just talking in theory but we will do the code to do this conversion after for now i am just telling you that you can do this conversion using tv slicer but i don't recommend you because it will take time to upload or to load the data and save it so don't think about this for now but if you have for example nld images or something like that for that case maybe you cannot convert them using python for that you need to pass by this software here now let me tell you something how you can convert data using this i i will just show you how i i did that so what you can do because i had a problem when i was doing some segmentations i couldn't save them as nifties so i had segmentation or labels they were in energy extension for us i needed to convert them into uh into the nifty for that i passed by this software so now let's take for example this is a nifty file we don't need to convert it but just to show you how you can do that imagine with me this is an nrd file to open it just pass it and put it here in the in your software and drag and drop it in the software and click ok and it will be opened as a volume here and if i will scroll with the mouse you can see here i am passing by all the cuts or all the slides which are already decompiled okay so that's what i was talking about when i am scrolling this here i am passing by all the decon files that have been combined to create one nifty file now imagine with me this was a nrd file for example now i want to convert it into an ec what you can do just put it here drag it and drag it and drop it here it will be opened or you can just open it here file open etc now to convert it click on save now just don't take this one and check your file here you need to see because this one is the project you don't need to uh to save it so just save your file here if you have multiple files you can drag them all together here and they will you wish you they will show you all the files here that you have been opened and you with one click you convert them all at the same time okay so here let's say that this was a nrd file so here you can see that there is the there are all these kinds of files and led like this one for example if imagine with me our file was energy now you want to easy to save it as a nifty file so just click here search for nifty it will be here so there is this one nifty this one the same thing but this one is complete compressed i recommend you to use compressed so that you will save some of your memory you don't need to worry about compressed files when you use monai because it will know how to i will show you how to do that because you don't need to worry about that so i recommend you to save them as nifty which means nii dot gz which is compressed so click here and click on save or you can choose the directory when you where you want to save your file then click on save and it will save your file if you have multiple files just change them all here in the place of nld puts nifty and change them all and click on save it will save them all together in the same repository that you want so that was how to convert any file i am not saying any but you need to see here you have there is nld meter image all this kind of files so if you have data set with this extensions and for that and you want to use monae so you need to convert them into nifties so you need to pass them by this software for example and change them maybe maybe you have some extension that doesn't exist here so you need to search another software or maybe there is a python script that does that so that's my recommendation but if you find directly nifty files of or if you will use directly the data set that i used here like this one and this one in this case you don't need to convert anything because they are already nifty's okay so that was about the data set and in the next uh in the next lecture on next minute we'll start doing some preprocess to our data and there is something we need to talk about before doing the preprocess but don't worry we'll go step by step until the end of this project now let's start preparing our data as i told you in the last parts of this course i said that there are two different parts there is the preparation of the data and there is the preprocess i am calling them this because there is the preparation that we will do manually and it will we will do it in another with script without doing the preprocess because the preprocess we need to do it directly before the training so before doing that we need to clean the data because medical imaging are a little bit confused we can't use them directly to our model or our segmentation or anything like that because if we use them directly we will have some problems and will not have good accuracy and even we cannot fix our problem and we cannot even know where is the problem there so for that reason we need to do some preparation to our data before starting the preprocess or the training or anything uh that we will do later on so as i told you there is the data here in the catalog data set and there is in kaggle let's go here and and i will show you that we will use this this card this decathlon data set i i have already downloaded prepare it and everything i have done but i will show you only with two or three passes to show you how does it work and so that you will have an idea how to preprocess your own data okay because if i will do the preprocess or the preparation of all the data it will take time but we don't need that because when you understand how to do it for one or two passions you can do it for all the buttons and don't worry about the code i will provide you everything uh that will use here in this tutorials so don't worry about that now as i told you you can you go you go here to get data and it will open this one and as i showed you we are doing lever segmentation so this is the details that you need to download as you can do just like this click with your right right hand and click here in download and it will be downloaded and you can use it directly okay now after that you will download this data it will look like something like this and after that you decompress it it will be something like this and when you enter you will find all these files we don't need them you can do it delete them but you will find three different folders this one is image tier which means image images for the training and this one are images for the testing and this last one is labels for the training which means you can see that there are labels only for the training images there is no labels for the testing images so in that in this case it is easy to understand what is delivered but in some cases it is not easy but for now we will not in this course will not need this training you can leave it here but we will not need it because at the end of our training we need a label so that we can compare the label with the images that we have with the output that our model will predict so in this case we'll take only the images training images and testing and training labels and we'll take few passions from from the training maybe we'll take 10 or 20 because we have here you will find that you have 130 these are only because it is redo it here after the completion but in reality there are only 130 passing so if you take 10 or 30 passes for the validation or for the testing so not all of the because validation is different than testing so because in our case we do training and testing will not do validation because when you go to monae tutorials you will find that they are using the word validation validation but i am not sure that this was the validation because because it is true that they will use that data during the training but it is not validation because they will not affect the training or the model they used only to calculate metrics and to uh to yes to test their model for that case we cannot call them validation they are testing data set not validation for that because actually we will not we will use almost the same code i am talking about the preprocess and the training we use almost the same code provided by monae but we will do some changes for example i will not use the word validation i will use testing etc etc but we will go to this uh real back to do this to go to this later but now as i do you will when you will download the data you will find or you will find all these passions but as i told you i will not do the process for all the passes because it will take time and memory and i have already this data so what i did i just took two end here of course the the images with the labels so what you need to do is just to uh follow me how i will do this uh process for two patients and after that i will show you how you can do it for more uh you will know how to do it for all your passions but there is something that i need to talk to tell you about is here in monae you will see that they are using something because when you want to train your data or your uh images here in medical imaging there are two ways to do it because we have images with 512 by 512 i am talking about the width and the height and the number of slices in different difference sometimes you will find 20 sometimes you will find 50 sometimes you will find 500 it differs from it differs from your uh task and your data set okay so in that case we cannot use directly the data because we need to create the same dimensions of each input so that will not get the model confused so when we will fix the width and height for five and five twelve by five twelve and for example slices by 100 so we we need to get all the pacings or all the inputs with this same dimensions for that when you see in monae's tutorials you will find that they are doing some crops so that they can get the same dimensions but that method work for some cases but it doesn't work for others and i tested that method in this lever segmentation it and it doesn't give a good result okay for those i will not use it but i will show you just a little bit explain to you how they are using that and why i will not you use it and how can we prepare our data to to use my my way it is not my way but what i found better than the more nice way so the method used by monae or monitors they take for example this is a passion i am showing you only one slice but imagine with me you have a number of slices here which is a volume which is actually a nifty file so what they do they do they create some crops they create random crops but i am showing you like this so that you will understand but they are doing random crops here for example a crop here or in the crop here which means they create a window with defined width and height and number of slices and they take this crop the the that they used they cropped using that window and they pass it for the training and the same thing they take in but they do they take one crop for one uh one epoch then in the next epoch they take another crop like this and the other one another couple from and they are random crops not as i am showing you here but just to know how does it look so that that's what they are doing in their tutorials they take only small crops and do the training on this crop and describe this crop etc etc for that they use 600 epochs so that they can pass by all almost all the passenger or almost all the slices but i tested this way but it doesn't work well for me for that i want to show you how i will do i will do it in my way which means we will create by ourselves uh this window but what i what we will do we will let the width and the height the same or we can resize the image but we will not crop it like this or so we will not take only small parts from the image but we will take the whole as you can see the whole shape or the whole content of the image maybe yes not maybe but we will resize the images because if we want to apply to pass them 512 by 512 to the model it will take forever to be trained for that we need to resize the images and what we can do maybe we can crop this areas so that we take only the places or only the area that has content of the image but otherwise we not need to take uh small portions as monai are doing so what i would recommend you i recommend you to not i am recommending you or i will show you how how i will do this on my way how to create the small uh passions or the small slices groups of slices and if you like it or if you want to try it out i will show you everything that you do all the scripts that we will use etc etc otherwise if you want to use the moniz tutorial like that so maybe you can follow me just to understand some of the basics and some of the functions that what i provide but in this way you can you want you will not use my idea and you can skip maybe one hour or something like that from this video because i will be explaining everything to do to prepare the data because if you will use this way you don't need to do any preparation maybe there is a process to change the contrast etc but preparation which means cleaning how many slices you have how how many groups you have you don't need to do all that but if you want to follow me so you need to see how i am doing this and after finishing the course you can try this one and maybe you can try more nice tutorial or more nice way in your data maybe the other way will work for you well because it doesn't work for me maybe it works for you okay so let's now let's go to show you what are the preparations we will need and how to do them so the method that i am proposing is to create small groups which means we will leave the same width and height for now before the pay process will leave the same width and height of all the slides of all the passions but we will create a constant number of slices which means if we have for example a passage with 120 slices what we will do for example we will create if we will if we will make a constant number of slices for example like 60 60 slices per group so what does it mean dispassion of 120 of 120 slices we will divide it into two groups so it will be the passion zero for example uh slash one for example this is the first part so it will be with 60 slices and the next part will be with another 60 slices and the same thing for all the passions if we fix the number as 60 slices per group or per input that means that we will pass by all passions and divide them into groups of 60 slices this is the idea that i found because maybe you can if you because i don't know how what is your data that you are using because if for example you have passenger with almost almost the same number of slices for example 100 101 102 or and something like this and all these passions have almost this range of slices in this case you may not need to do what i will do here because you may you can do in the training you can crop your passions and fix the number of slices into 100 slices per input which means if you have a passion with 150 100 slice so this passion will go directly as an input or if you have a passion with 100 one and one slices means that you will crop only one slice and one slice it doesn't affect your uh your data because for example if you crop your data and maybe you you will clear or 10 or 20 slices this maybe you will lose some information of your passion but if you just take off only one slice or two slices it doesn't affect your training or your data i hope that you are understanding what i am saying because if you have only you have almost all this the passion to have almost the same number of slices so in this case you don't need any preparation of this asians but if you have a random data set that has passion with 50 slices another passing with 500 another percent with 300 something like that because all the passing that you will all the data that you will find as public data sets you will find them like that so if you will find out like that you need to follow me to clean them and make them ready for the training so the first thing that you need to do is to convert these nifty files into dcoms so that you can convert or you can create small groups okay to do that for now there is no specific python package to do this because i searched for that i didn't find i i tried to create my own package to do this and you will find it on my github profile here like you will find i mean zero one one zero slash nifty to dcom so that was i tried to create and you will find it here it is useful for some cases but not for this case because there is a problem that i couldn't find how to fix it and if any one of you have a suggestion please you can leave it in the comment or you can just take the code and make it ready for you i will tell you what is the problem with this code and so that you will understand this code will create will take a nifty file and create your decon slices but the problem here is that it will give all the slices or all the decomp slices the same number of index what does it mean if you have a nifty file with 10 for example 10 slices so when you will convert it into deconfile it decompiles it should be each num each slice or each deconfile with with different index so for example the first nifty file will be with the index 0 the second one with the index 1 2 3 until 10 which means if you want to reconstruct or rebuild the nifty file after the python package will understand that this first slice is goes to the first nifty uh to the first item of the nifty the second one is the second cut third etc etc but the code that i i'm providing here will give the same index to all the passions which means not the passing to all the slices so if you convert one nifty file into ten sli nifty into 10 decom slices all these dcom slices will have the index 0 for example yes the first index so in that case you cannot rebuild the nifty file again so in our case we need to rebuild because we need to take groups of d columns and reconvert them into the two nifty files which means it doesn't work for us maybe this type of convergence if you need only to convert into dcom you don't need to or you don't need the indexes in that in that case you can use this but otherwise for our project we cannot use this even if maybe if you find a way how to change the indexes so you can take the code and change the indexes of all the deconfiles otherwise i will show you how you can do it manually without without python code for that this this is the parts that take a lot of time of this work but the others are just coding and everything will i will provide you all the scripts for everything but only this part needs to be done manually and it will take time sorry about that but it will take time for that i am saying if any one of you know how to convert nifty to dcom using python or something like that please provide this in the comments so that anyone who is using doing these projects can use this package as well okay thank you for now now i will show you the second way that you can do it but as i told you it will take time we will use 3d slicer for that when we was installing softwares i told you that we'll use 3d slicer for for some conversions so now it is the time to talk about that i will show you how you can do one or two not i have i i just choose two buttons here so i will show you these two passes how you can convert the images and the labels and you can do this you can see that it is easy but it takes time so you can do it for all the passings that you have so now let's start by before that i want just to create some folders so that we can know where to put our data because i didn't want to make everything with python script because sometimes it is very you can pass 10 minutes writing a script to do something so that you can say that it is automatically but you can create the folder with one in one minute so just click new and create a folder so it will take two or three seconds but if you want to write python script it will take maybe three minutes or more than that so in that case i prefer to do it manually instead of writing a python code to do it okay now let's call it for example dcom decom files maybe because what we will do in this folder we will take these passions and convert each of them into the com slices because nifty is group of dcoms now let's go here this is the decom which creates another folder here one for the images i will call it for example images and then the other one we will call it the if you want to do it directly with the keyboard you can just click ctrl shift and end which is new so we will create a new folder here so this next one we call it labels something like that this this files or these folder names will be changed after because we need them for our specific script but don't worry about that we will come to that later now we have two folders this one images and this one labels now let's do what i was saying to use this software 3d slicer let's start by the images let's take the first one just grab it here drag and drop into your slicer or just you can open it here and now okay open it and it will be opened here as you can see all these the slices you can just scroll down or just do like this so all these are the slices for example this passion has you can just you can read here you can see here it is 74 slices and you can go to other passions you will find maybe 100 slice etc etc so this is the problem you cannot use the same script for all the passengers for that we need to prepare them with the same slices after that we pass them by the to the training phase okay now how to convert them just click here insert and click or type here dcom creates the ad com series so search for create a dcom city so just go here in search dcom creates the comp series so when you click here click two times here you will get this window here the first thing that you need to do is there is nothing uh is hard to do it this is you don't need to change this because creating it becomes serious so you don't need to change that click here on select you need to select the volume or yes the volume or the image that you want to to convert so here you can see that we have volume zero this is the the passing that we are displaying now and this is the passing that we want to convert so you know you need just to choose it here level zero now you need to choose or to change the directory where you want to be to put your conversion now as we were saying we need to go to here to our folder that we have created called nifty files go here youtube yes this one dataset lever and deconfiles and this one is an image not a label or segmentation so we go to the image now we need to create a folder for because if we passed here everything will be here every every slice or all the decon files will be here but we need to to put them into one in one folder which is called with the same name of this button so we need to create a folder here so we can call it lever 0 for example and with the same thing or you if you want to change the name here it doesn't matter now choose now everything is set just click here in apply and you will see that it had the conversion have been completed let's go here and see what's happened here images we have created this and here are all slices as you can see we have 75 from 0 from 1 into 75 so everything everything is set and these are all the slices because here we see that the maximum is 74 because it starts from the index 0 so from 0 to 75 but here it is starting from 1 into 75 okay so there is no problem with that but these are all the slices for this is for the image one for the lever one now let's do it for the second just go here and the second here we have we had image which is level one now level zero now level one open it here and you can see now we have the lever one and for example this one this one have 122 slices which you can see it is not as the first one for that case it was it will pose a big problem when you want to do it or you will lose all the information of your passing if you do some crops for that we need to create groups with the same number of slices now let's select the second one which is what we uploaded now this one level one and here we need to change the path because we had the folder level zero now we need level one something like that and that's it choose and apply this so now we have the two passengers have been the have been converted here let's go images this is the second one now let's do the same thing with the labels let's go here we have label training let's take the first one here and as you can see this is labels with the same number of slices now let's select here you can see because they had the same name level zero level zero so they added this index so that you can know so this is the first this is the first label for for the first passing as well now we will not do it in images now we are in labels so create a new folder call it here lever you need to put it the same because we choose we choose to put the lever zero so we need to put the same thing lever and zero so another so that's the uh when we will do the training etc the the labels with their images will be the same okay now let's choose this one yes here we have the same thing choose and apply and the same thing for the second one which is lever one choose it here change to level then one and choose it apply and now everything is set for this step when we go here the confines you will find images here is for the first one second one and same thing for the labels this is the first one and the second one as well so that's what you need to do at first but for me i am showing you only two passions but you you need to do all the passing sorry it will take time but i didn't find another way to do that okay so as i told you if you have the number of slices sorry i am repeating the word but just to understand if you have if you have the same number of slices for all the passions or almost the same with a minus one or one difference between them so in this case you don't need to do what i am doing here but if you have the public data set as i am saying here as you see you i show you the first if i show you only two passes the first one has 74 the second one have uh 122. so in that case you can see that there is a difference so if we go or if you pass by all the passengers we will see that every passing has each its is unique if we can say unique number of slices which is a problem for that we need to pass by this way now after doing this what we have to do we need to create the groups that i was talking about groups of decom slices which is we can choose any number we want in this case i will choose 64. i don't know why i choose this white but this number maybe i found that the minimum of because i passed by all the passions maybe i found that the person that has less slices was between maybe 64 or 65 for that i choose that number but for you it depends to you and you need to choose the number of slices that you want or that is depending to your data set so you can do the same thing as i did you go by the the passes that you have you see the but the passing that has less number of slices and you take those numbers so that you will not lose that passion because if you take number more than the minimum which means that you will lose that dispassion if you choose for example number of slices unique number slices equal 100 and you have some passion that are having number of slices 60 for example so 60 past ends 60 slices can not be converted into 100 slides so you will lose this passion for that for this case i am telling you to see the person that has the less number of slices and take that number of slices as a reference or a constant number for all the other passions okay now for the next steps which is doing all the conversion creating the groups and reconverts into uh nifty files everything will do it using python so i will show you how you can do it but before talking about or before starting coding i am just telling you that everything is set for now all the code all the scripts all the functions are here in github which i will share with you after you can find everything here the preprocess and everything is here but we will write this code each line by code by ourself but after that i will provide you everything here and i will provide you the notebook jupyter notebook maybe you need you you you would like to use it because in our case we will use jupyter notebook in some cases because it is easier to follow the steps but you will find everything here in github which you will find the link in the description so now let's start creating the groups and converting them into nifties now as i was telling you that you can use jupiter notebook that i i will show you how you can use it i am sure that you know how to use it but maybe did you use it in different way that's what i want to say because you can install it easily in the command window like you go here in cmd you can open this command window just type pip install then jupyter and it will be installed and you can open it uses and there is no problem with that but the problem that you can you may have using this uh jupiter notebook directly here is not probably in the installation but if you want to use a virtual environment in your in your project in that case it is sometimes it is not easy to open or to yes to open jupiter notes book inside a virtual environment or to use gyptonium with virtual environments so the way that i recommend you because i always choose the easiest way and i will show you the easiest way if you like it you can use it otherwise you can use something else but as i told the jupiter notes book if you install it like this there is no problem but when you want to use it with a virtual environment you will have some problems so to make it easy to do this process what you need to do is just to go install anaconda navigator so anaconda navigator is as you can see it is a software that has multiple i will show you multiple software here that you can use and which is the is which is the best thing here that you can create your virtual environments with using conda not a virtual environment with python because there is python vms which is python vertical environment and there is conda virtual environment and when you use anaconda you can create your contact but your environment you can create them using command windows like this here click here contact install and or contact create you and you create your virtual environment exactly with a specific python version and all these things that you want to set but if you are beginner with programming maybe it will be easy to create your virtual environment manually using the gui here anaconda gui so to do that you just come here i will show you first how to down install it which is very easy you can just go here to anaconda dot com slash product slash individual i will leave the the link in the description don't worry about that so when you install your anaconda here and you you download it here and you you follow all the steps as we have installed everything else because i have it already so that i cannot install it reinstall it again but just download it because it is free download this open it and it will and follow the steps and of course you need to choose which operating system for me i am using windows so it is already windows here if you have mac or something else so just you need to click here and search for your operating system now after installing it just open it as here you can when you start it will be something like this now here if you open here this list you will you will see all the uh virtual environment that you have in your pc that you have created in your pc they will be shown here and this is the base when you will create or you will install an account you will find only these two uh vertical environment this is the base which is the base vertical environment of your pc this one mini contact is we can say that it's an example but you will not need it because we will install our virtual environment for our project this is testing i just installed it again but now how to create a virtual environment in anaconda as actually you can do it using the command window here cmd and you can create use the command line and install and create a virtual environment then activate it etc but the easiest way here while we are using the since we are using the gui already you can go here environments and you can see as i show you all the environment that you have here now to create new virtual environments that is here these buttons create a new cloud import backup remove if you want to remove one of these various environments so as we said we want to create one so click on create now choose the name of your virtual environment let's call it for example liver segmentation so this virtual environment will be the virtual environment that we will use in our projects and i will talk about this after but now when you use it check here in python then here you can choose any any python version that has been installed in your pc and just for me i have python 2.7 3.5.6 i have everything here so i will just choose 3.8 you can choose any version you want but i am going to choose 3.8 and i recommend you to do this because sometimes when using mulai if you go with latest versions maybe you will find some problems so three point seven three point eight is enough for this project so i will choose three point i ate then here create and you will see that the vertical will be created in millisecond not millisecond but in a few seconds and now we just have to wait and this is our virtual environment and now here you can see the uh files or the packages or libraries that have been installed already with the virtual environment as you can see we have pip we have python of course sqlite etcetera but we will not use these because we need other packages like numpy money etc but everything we need to install it by ourselves so the installed packages there is multiple ways to do it we can use conta install we can use pip install or we can just can come here we have here when we are checking here only we are seeing only installed packages we if we click here not installed updatable etc or we can click just in all we will get all the python packages that have been that are available in anaconda and search for anything here then click install but i when we are talking about installing packages i don't prefer this way i prefer using pip for that i will not follow this way i will show you how we can use pip to install different packages so now what we need click create a virtual environment now when you are selecting it here means that you are activating because if you have already used virtual environments it can be virtually environmental python virtual environment or a more conda inverting environment when you did it you have always to create it then activate it when you write virtual environments like script slash activate or source virtual slash bin slash activate but when you use the gy here when you select it here means that it is activated you don't need to do something else to activate your virtual environment now as i was saying we really need to use jupiter notebook so here as you can see there is jupyter notebook there is everything vs code there is pycharm there is everything here we can install it we will install this because we need this after but for now what we need is just to use jupyter notebook so you click here even if you didn't install it before in your life don't worry about it it will be installed when you click here it will be installed in your virtual environment which means that you can use it there so now let's create let's click in install and it will install jupyter notebook in this virtual environment now it is installed as you can see and this is the best thing when using anaconda navigator because you don't need to think about how to uh to link the your virtual environment with jupiter notebook or sunday lines you don't need to care about that the only thing that you need to do is select or create a virtual environment selected then come here and now it is already installed so you will not you don't need to install it every time now you installed if only one time in your new virtual environment now click in launch it will be launched and we will say here now there is jupyter notes book is working and now jupyter notebook is open with your or inside your virtual environment so you don't need to think or care about which virtual environment you have or anything else now all what you need to do is to create your folder to check or to make directory where you want to put your your stuff on your project and inside that folder you create a new notebook now for me i selected this so i will work on this repository which is labor segmentation here where we will put everything or all the code not the data data is somewhere else but here we will put only the code now to create a new notebook just come here click on new as you can see there is python 3 that is text file folder terminal but for us we want to create jupyter notebook for python so python 3 ipi ipu sorry iby kernel so ipwa i ipu y means that jupiter notebook and kernel now uh what we will do here we have this is our notebook just you can click here to rename it i will give it for for example prepare because we will use this notebook for now to do the preparation because we were talking now a few few minutes ago we saw we said that we need to convert our images here we had this labels and images they are decode now we need to create groups or yes create groups with the number of slices then reconvert these groups into into nifty files so that's what we will do in this notebook now to do the creation of the groups of 64 slices this was my choice if you want something else you can change it now these are my two parts this is the inputs and this is the output path the output parts we need to talk about it here i have i have because we had this dcom files where we have we had images and labels this is the input path file decon files and we have images and labels we'll start by labels for example then the output part i have created this folder called dcom groups so you need to create a folder you can call it anything you want so that we will take this labels from this that we will convert or because we will not convert actually sorry we will create groups of 64 slices so what will happen now we will create each for each group will create a folder but we will not do it manually all what we need to do is create this group where we will save all the passions all the groups which i call decom groups but we will write the script that will create folder for each group which is 64 slices so that we can after that we can convert this 64 slice into one nifty file but before that what we need to do is to create this decon groups which will be a which will be a folder now there is something else that we need to talk about because we have this decon groups but what we need to do we need to create another folder one for the labels one for the images i am sorry i know that i am doing a lot of things manually but i didn't want to do everything using python scripts because in sometimes you can do something wrong and everything went wrong because imagine with me if you mix only one one person which i mean if you ma you may you put wrong a one label means that everything will go wrong because in segmentation you need to be very precise it is not like any other thing it's not like any other task of computer vision so you need to be precise because if you skip only one slice or only one segmentation everything may be wrong okay for that i am doing much things uh manually so that i i will not make these things wrong there are some stuff that need to be using not need to be done using python scripts but for this i prefer to do it manually now as i told you i need to create a group a folder for labels i add another folder for the images so we just click here as i told you ctrl shift and n for new folder i will call it labels the first one and the second one for the images like this so now here i need to add labels okay so the input path is our labels when we have because for me i am using only two passings as i told you but you for you you have all the passings in your labels because here the confines i have only two passions but for you you have 130 if you use the same dataset or i don't know but you have all the labels that you have here and the output path is what we have created now beacon groups and labels now here where we will save our our groups of decons now to do this just run this one so to run it just click you can click in run or you can click on shift enter shift enter it will run this cell now to do this project we need to install some not projects but i am talking only about this part we will need some packages so the first one is globe so this package globe if you have already used it so you don't need to know what i am saying but if you haven't used before so we need is only to create some parts or to restore all the parts for example here i have this folder which has two passions so the globe function or the globe library will help us to restore the the whole link or the whole part so that we can open this folder and open this folder after you will understand when we will code it okay now i haven't installed it for this project so we need to install it to install in if you are using directly visual code or you are trying to install in a terminal just you need to click to put pip install then the name of the package for us it is glo but for me if you are using jupyter notebook so you need to add this mark okay because if you don't add it it will not work in jupyter notebook now if i will run this cell it will install there is something wrong could sometimes you can get something wrong we need to see about this why it is not installing now after that i checked because i don't know why i didn't notice that but when you want to install globe sorry about that but we need to check everything every time because i have installed this a long time ago for that i don't remember i didn't remember that i need to add this number two with the globe but that's that's what we need to do because this type of uh errors means there it is true that they are saying no matching distribution found for globe but what they are saying that there is nothing because they don't write that but there is there is no something like this library because the same thing if i i can put pip install i don't know one two three it will say it will give the same error it will not say that there is nothing called one two three but it will say that we couldn't find something matching with this version but that means that you are putting the name of the package wrong so you need to just choose because sometimes you can see the globe when you import it you just put import globe but when you install it there is something else all not all the packages but a lot of packages have this no problem but you need to see exactly what is the name that you need to use when you want to install for example pillow when you install it you click pip install pillow but when you import it you click just pip install pil so for that this is the same thing just click here pip install globe 2 then run it and now as you can see it is installed now there is no problem now the second package that we need to install is chantel shuttered sorry not chanted but because we need this package to move the files because what we will do we will move some lot some but we move 64 past 64 slices to a new folder which is a group of 64 slices because i didn't want to just copy them because we will lose a lot of memory doing this copy and paste but i will move them so i will take them from the old directory and post them and put them into the new directory so for that we will use we need this library so pip install shuttle i hope that you need to use the same name maybe there is something else but we will see as you can see the same thing here so what we need to do is just to search for it how to install shuttle something like this and as you can see when you import it you use shuttle but when you want to install it there is by test shuttle so you cannot just install it as i was doing so just take the name and put it here pip install test shuttle now let's see how does it work it will take a few seconds and now everything is good so i will just delete this so to delete them just click on the cell and click two times on d to delete and the same thing for this because i we have already installed them so we don't need them there now we need to import them so import globe and import shut d like this but but what you need to do to know is in globe function this is the name of the package which is globe but the function that we need has the same name which is globe so for that when we want to use the globe we cannot just make glo use globe and deer function we need to import another function or another class called globe from globe that we will use i know that it is strange but that's it this is the package they created like this so we need to write from globe import globe because the same class are the same in the same package so that's what we need because if you take just globe you cannot access to the packages or to the functions that we will need so just run this now there is no problem with that now let's start coding or let's start creating the groups for that the first thing that we have to do is to create a good not a good but a big for loop because that for loop is the most thing that because what we are saying we are we want to pass by all the passions because we can't do it for only one person but we need to run the code each time for 130 passes which is not good so we need to create a loop that passes by all the passions so for that we need to create just four and now passion which is a lever for for me i have two only two passes but for you you have everything but you don't need to care about that just for passing and we will use the path because you remember in the part here we have labels after that we'll use the images so in labels there are all the uh all the decon files that you have converted for now so what we have to do for passions in then here what we are saying in this folder but if we do this we will not have the because this in in part will be only one part but what we have to do we need a list of parts okay list of parts each part or each item of this list give us the part to one passion okay for that we need to use the globe this is the use of globe function so we have globe and when we put a part inside this parenthesis of the globe function what it will do it will return a list of all the items that it has in there in the directory not the list like os.list because here we are talking about lists of the parts not only the items so this is the role of globe function so what we have to do is in path input path but when you want to do this you need to specify which extension or which type of folders you want to put in this list so for that we need to add something like because always we have something or the name of the file that's the extension for example and i for the nifty but for us we don't have nifties but we have folders okay for that we don't need to specify the extension just put everything okay but this is something like this so what we are saying that in this input part slash everything if we want to say uh we want to specify the extension so we have to put everything that some that's the nifty for example this what does it mean everything which is we don't care about the names all the names or all the files that have the extension and ii take them but for us we said that we have folders so we need to take everything inside this folder so for passing globe in star means that everything inside that folder so this will return a list of folders now what we have to do is to start doing the conversion the first thing that i want to do is to return the patient's name so that we will use it after to save or to create a new folder for for each group of items because what we have what we will have for example we have a passion with 128 slices so this passage will be divided into two groups the first group is 64. the second one is 64. so what we have to do we want to keep the same name of passing for example pass into one in our case we have lever zero lever one so we will keep the same name level zero but we need to add a underscore for example than one and two three etc which is the sub groups so you have the passion zero sl underscore one lever then passion one underscore two that pass into i don't know passing two underscore one etcetera etcetera etcetera so you will know always that this group of 64 belongs to this to the passions one or passing two etc but it is a subgroup of that passion okay i know that i am talking a lot but i am just trying to explain everything here so as i told you i need to return the name of that passages before that we have to add a another library that we'll use so import os and you should know that in each time you add something in that cell you need to run it again because if we don't run it this os will not be imported okay so now after that we did this what we have to do we have to return the passion's name so i will call it for example passion's name so as we said this loop will take the first passion will return its name to return its name that is a function in the os library so os dot path dot base name okay this one will return the base name which is the name of uh of our passions which when we say this base name means that we have all this part this is the base name the last item of the path is the base name and that's what we need because now we have label so this globe will do slash than the first passion so when we return the first uh i will show you something let me just click here below now let me do for example past scenes list equal glow then in path plus this so this as we said this is the uh this list of passions will have for us we have only two persons so now if i will i want to print for example print the first item of the list which should be the path to the first passion so we have passing list then as we said the first item of the list so zero the index zero now you can see that we will have the input path here plus the lever which is the first passion so that's what i was saying if i will put here one it will give us the lever one which is the second passing etc etc now we don't need this so i will delete it now i understand what will be this passing in the first iteration i i forget here in so you know that now in the first iteration we will have the first passing which is the part of the passing so labor slash level zero so what we will do we return that level zero the only the name which will be a string we will use it after for that what we have to do now inside the parenthesis we need to know to normalize our path in case we have any problem or something like this so os dot path dot norm path which is normalizing the path and put here the name of the passing which is this one or not the name but the parts of the passions so this function will normalize the path if and there is anything wrong with that then this function will return the name or the last item of the path which will be the name of the passage and it will be here we will need it after to create a folder and to save the groups in our case now after doing this what we have to do we need to specify or to know how many folders we have or how many groups we will divide our passions so if we have for percent with 160 28 for example slice it will be divided into two so we need to create two folders each folder for us for number of four the first 64 and second one same thing if we have more than that we have to create more than that more folders etc etc so before we need to to know how many folders we need for this for this first passage for example so to do this we have just create number of folders folders then what we need to do is to ins because why i am putting is because we need an integral number because if you have for example 130 you divide it by 64. it will be a float number but we cannot create a fluid float number of folders we need to an integral so we need to put everything inside the function int so that it will convert the final division into a in into an integer okay now what we have to do we have the because what we need to do we have a globe of the passing that we have which is this one this one is the globe of the passion this will return how many passions we have but now we need to know how many slices we have in that specific passion so we need to create another globe which will be something like this globe but now we are not talking about the in the in part which is the input path now we are talking about the patch of that specific persians so globe of passions plus uh slash as slash forward slash then star which means everything we can here specify everything that's decom but we don't need to do that because we know that we don't have jpeg images or something like that in our folders so everything inside the part of the of the passing which are or everything is dcom so the globe will return a list of all that it will return a list of all that passions not passive but slices decom slices now what we have to do we need to know how many uh which will be sparked but we know we need to we need to know how many percent we have how many slices we have to do that we need to to calculate the length of this uh of this list because as i said globe will return a list of parts of each slice now we need to take this one here and calculate the length of this list which will be list of but i will just control x so land the same thing here so we calculate the land so let's what will be the land for example if we have 100 slices we will have 100 100 parts which will be a list of 100 item now this is the length which will return it will return 100 because as we said we have 100 now we need to divide it by the number of slices that we want to create which is 64 in our case so divided by 64 here so when we divide by 64 means that we will know how many folders we want for us we are putting here integers okay this 64 we can leave it 64.65 we can leave it 64 or we can create a variable for example that takes the number 64. then we use it but we don't care about that we will put it 64 but because as i told you i will give you the code at the end of this course and everything will be clean and all these for loops etc will be inside functions but you can you can just call them and i will show you how you can clone the github repository etc but at the end for now i am just explaining how does it look how does it work in case you have problems in case something differs from your project to my project in that case you can know how to fix these problems okay otherwise you can just use the final part of this course using github cloud repository and no problem with that now as i was saying this number of folders we needed to know how many folders we need to create so or how and not all and and i am saying and in how many groups we need to divide our passions now after having this number of slices what we need to do we need to move the slices from the specific folder which is here for example here we have all the slices what we need to do we need to take 64 from them and move them into a folder that we will create which will be a subfolder or subpassion of lever zero so now let's start doing that loop so it will be a for loop that range does go goes from how many folders at first because what we need to do we need to create the folder first and move the uh passing or the slices from the from each person into that folder that we have created so what we need to do we have to create at first they pass the folder where we want to to put the slices for that what we have to do we have four e in range for example now we said that we need to know how many paths how many folders we need to create so we have number of folders so we will pass by the number of folders we if we have four if this value equal to four which is the number of folders will be four so we this for loop will pass four times if we create the folder then we will write the part where we will move the slices into that folder but now we have to go step by step now we have to do that after doing this we need to create a directory but before that we need to specify what what is the final or the part of the output which means how where we want and how do we call the folder of our outputs of our of our group so what we will do here we need to give a name for example output but for example or output path name something like this what we have to do we need just to we will reconstruct it because we have the output part which is this one this one is the final output part where we want to put everything but we don't need to put just here we need to create another subfolder which will have the same name of the passing which is this one plus a underscore and the sub folder which will be the i the i here so it will be 0 1 2 3 etc so to do it is just to put here os dot path dot join this function always that part that join is something that just to join two folder two parts for example i have path one slash part two comma sorry if i have this so this from this function always that part that's joined what it will do it will do just part one slash but two that's what it will do this uh function so we don't need to worry about it so for us what we have we have the final output there which is out there outputs this one which have we have i have i am putting here then this is the main output of the labels then we need to put the name of the passion which will be here passion name then we need to add the underscore plus the sub folder which is here plus it is a string so we don't need to think about it you can we can put just plus here and it will add it to the part so plus and we said we have underscore then the name of uh not the name but the index of that subfolder so which will be the i here but now i is a antigua we need to convert it into string to do it is just to call the function str and i so what does it mean this it will create something we just i will run it to show you how does it look i have here print out put but name you will see what does it look this one just run it it will create this part which which doesn't exist for now for now we have this part which exists which is this is the output here output part but now we added this lever zero this is the name of the first passion and this is the underscore zero and now here it should be underscore one but for our case if we have a number of passes so i want just to say see something i think there is something wrong here because we should have zero and one not zero one here because we didn't go to the next one otherwise even maybe the i would just ah i know why because here we have for this first passing we have 76 uh slices okay so the first passion we will create the first because when we divide this by 64 it will give us one one comma something in that case we cannot create one comma something folders we create an antigen folder it should be one folder so we will we will take 64 first passing but the other 10 we don't need them and in this case you don't worry about the 10 slices is not a problem okay so this is why we have only one one passing one subfolder and same thing for the second one here we have 123 so in this in this case for example it will take the first 64 slices but the others it will not take them okay but don't worry about this there is no problem i am taking 64 because there is other passing that are having less than that we can put a number less than this for example we can put 50 or something but i don't think that it is a good idea because we lose some information for us in average in my case i took this number of slices because here if i will take for example 50 so in the first passing i will lose more than more than when i was 64 because if i will use 50 so i will lose 25 slices here so and the more we go with small number of slices more than the training will be will be slow and it will be it won't be accurate because we will put only number of slices like 30 or 40 it will not be something very accurate so the more slices we put the more better we have because in my project in another project where i was doing tumor segmentation i was using a groups of 128 slices because i had passage with much number of slices for that i could use 128 slices and it was very good number i tried more than that and less than that but it was 128 the best one if we if i put more than that it can be good accurate but it will take time talking about the training time the training because when we launch the training you will see that it will take time so more the more the number of slices you take more than the epoch will take time in each each time okay so for that i don't recommend you to take a very large number and not very low number in some cases you will lose some slices but it is okay don't worry about that so for that i am using 64 here now you see what will happen about this name just what we need to do that what this function will do just to create this name now what we have to do because as i told you this part doesn't exist so we need to make it exist so we need to create a folder with this part so that we can save our slices in this part so to do this just use the os library so os that's amca the which is make directory and here what we need to do of course the output parts name so this os library will make directory for this output part name so we will have these two folders created for me i have only two but imagine with me you have 131 or 30 baskets or more than that so this function or this loop will create folders for each group of bastions don't worry about this now after doing this what i have to do is now after making or after creating the the folder we need to move the images into that folder so to do this it is easy just we have four now we have we this because this first loop will pass by all the passions and this one will pass by all the groups or all the sub folders now we will pass by all the the files or all the slices that we have in each passion so what we have to do is just we have e because what we need to do we need to know where or when the file is when we are more because i'm saying that if we have something like we need to know in which index we are we are so that we can stop the loop when we pass the 64 uh slices so here we have four e because i tell how to use i will need it then i need to refer to the file because this e is the only the index but now i'm going to talk about the file which is the confirm so for e and file of course in because when we use only one variable here we use the range but now we are using two which i am talking about two the first one will take the index and the second one will take the five so we need to use the enumerate enumerate rate function and now here what we have to put that we have only the name of the passions with the part but before doing this we need to know always the path the passion sorry but when we we have a uh a we if i will put only the passings it will be just the folder but what we need to do we have to return all we have to return the list of the passings the same thing that we did just here we have the globe and because this one will globe and passing plus this star it will return all the passions or all the slices that we have in the group or in this folder or passions so i just need to copy this put it here so what we are saying now four e and five in enumerate so this file will have the the the part of each d com slice of the first pass hint for example in the first iteration so what we need to do we need to take it return it and then after that we need to move it into the new folder or to the folder that we have created so what we have to do now after taking the iteration from the group we need to move it so to move this file we have to use as i told you the function sharp till like this so shots will have a function called move this move function will move the file to the uh directory that we want which is now here we have the file and the directory or the output file will be here the output the folder folder that we have created the output part name so what i am saying here we have created the file now we will pass by all the files or all the decon files of that specific passing and move them into that into that folder which is the output name for name but there is nothing here that stops the loop we need something that stops the loop so how to stop it we need to know where we this the iterations of the loop are in the same uh number of slices that we specified which is 64. but we need to do it before moving because if we are already passing the 64 slices we don't need to move other by other slices so just here put but now we need to put here if we said that the i here is the index of the slices which is the iterations so if i equal to the number of slices which is in our case 64 plus one which is when we pass it by one we need to stop the loop which is using the break function so when we call the break it will stop this loop which means we will not move more slices and it will go back here and go to the next iteration to move the new uh so it will go to new iteration it will create a new subfolder and move the next 64 slices to the next to that new subfolder etcetera etcetera until finishing all the subfolders and go moves to the next passions etc etc now let's try this and see how what does it do so just put here and you can see that now it is done let's see our folders as we said here we have liver and we have decon files labels and you can see that it has created the lever zero we said that we couldn't create lever one because there is not enough number of slices to create it so we have zero and if we go we have 64 65 number 65 slices okay i think that i miss one so i maybe we can just leave that this one i can just leave it on but not a problem 64 or 65 not a problem but you can see here that we have created groups of 65 slices for this one and for this one and everything and if you have more than that i am i am using for example only two two buttons to show you but if you have more than that you will see that it will create number of folders or subfolders of each passion so if you have a spacing with 600 slices so it will create i don't know 10 10 or less maybe eight eight or seven subfolders each subfolder contain 65 number of slices and of course if you want to change this number of slices just change this number which is 64 here just changes i i didn't make a variable for that because i told you that i am just showing you but at the end of the course you will get a full function that has at the inputs the input path output part the number of slices and it will do everything so that was how to create the the decom groups now the next step is to convert these decom groups and of course i forget to to say that now what we have we did for the labels now we we need to do it for the images so what you need to do just to change here instead of labels you put images and the same thing here images and if i will rerun it this again this we don't need to run but otherwise now if i will run this again it will do the same thing but for the images now we have the labels if i will go to the images you can see that it has created folders with 65 slices so that's what all you need to do create put here labels and after that you need to put images and it will do for all your passions after doing all this now we will go to the next step as i was saying to convert this nifty group to 65 i just need to change this because i made this wrong so i need 2.65 now we have 60 groups of 65 slices we need to convert them into nifty files so that's what we will do in the next step now let's talk about how to convert the deconfiles that we have created which are 65 slices into one nifty file which we will use uh for the training etc etc so to do that there is only one function and you can do it in one line i am talking about only one file nifty file we can do it in one line and which we have multiple files we can create a loop to do that let's do it step by step with you i didn't want to write it and start talking about it i prefer to write these lines of code with you so that you understand understand each line what what what we are doing with each line of code and of course at the end i will provide the final code only in the training part it will be a very big loop for that i need to write it before start explaining but all these problems preprocessing parts i will explain them like this and i will write the code with you and if i will make some mistakes you will see it live with me so that you will not do these mistakes okay so to do this conversion that we will need a package called dcom to nifty so this library the continuity will do all the work so if you don't already have it installed on your pc we need you can install it using pip install here since we are using jupyter notebook so we need to add this and pip install and then rewrite the name of the library or or of the package for us i said that it is dcom to nifty something like this so when you do it we will run this cell if you want to run the cell here just click on shift enter and it will be run and we'll wait a little bit when you see this star here means that this cell is running we'll wait until this is the only problem with jupiter notebook you cannot see all the execution lines or what is happening you can just see the final output here and as you can see we have successfully installed nifty to decal so after installing it i will just delete this by clicking on the cell and click two times on the two times and it will delete the cell now let's import it here what we have to do just we click import dcom to nifty and we will run the cell because we need to we will need these two libraries os or basic operating system just to create the paths and this d com file or yes and this d com just we needed to do the conversion so the thing that you need to know is when we will use this library we need only one function called dcom series to nifty that there is another function but i don't recommend you to use it because it will not give you the access to to make it or to rename your files which mean if you have only one nifty file that you want to create you can use that function and in that case i don't remember the name of this function but i think it is the com the community but i think it will convert repository but uh i i don't recommend you to use it because as i told you if you have only one passive it is okay but if you have multiple passions you will not have the access to change the name or to specify the name of each passion so in this in this case if you have ten passions it will use the same name for all the passions in that case you will see only the final passings for that case you need to use the decom series to nifty so this function will has two parameters the first one is the part of the folder where you have your nifties and the second parameter is the part where you have when you want to save your nifties plus of course the name of your file now let's talk about our data here we have code the control nifties i don't remember what i put it is here level then the confines and when we did the confines we created the dcom groups we have the images and the labels here so the images and as i showed you i am using only two passions because i don't want to waste time running all these codes because i have already created and prepared all the data so i am using only two so that you can see but don't worry about that because the loops that i am creating will pass by all the passing so if you have two it will cover two if you have ten it will contain ten if you have 100 it will convert 100 so don't worry about that so as i told you we have two parts we need to convert for the images and for for the labels to do it what we have to do is just to take the part here so this part is the common part which that is the images and there is labels we will need it let's write it just here so i will write for example in path something like this and let's just save it and i recommend you to use the forward slashes because sometimes the backward slash make problems not for example here but if you have slash r or slash t or slash n it will make a problem so i recommend you to use these slashes forward slash so now this path is the part where there is the images and the labels now let's start by converting the images and you can see that in the folder of images there is two folders this folder contains 65 slices and second one as well now what we have to do what we will start by the images for example let's put here to make it easy we can just use the os but to make it easy here let's make images so this part is for the images let's make here images the same thing for for the labels something like this and the folder called i don't know label labels with s something like this so now we have the the parts of the input images and the inputs labels and you remember that in each part of these there is or there are uh all the uh all the passions or which are all the folders that having group of slices of each passion as like this here now what we need to do we need to return a list that has part of this file or this folder and part of this folder etc etc so if you remember we used this type of uh of groups of or of make of returning all the group of all the files or all the folders from each from a specific folder using this kind of functions because we said that globe when we put globe and we put a path inside that globe function and we add this forward slash then star means that this globe function will return a list of parts of all the files inside that folder so for us for example we have this part of images so the globe function of this part will return to will return a list of two files or two items the first item is the folder of this file and the second item would be a folder of this file like this so that's what we'll do so to make it easy what we can do we can just add the globe here but before that we need to add the forward slash star means that everything that uh that is in that folder which is images and here the same thing everything in the labels now we as i told you i need to return because here now we are writing the paths and the parts so the preferably we will not write it at the same line but you get it you can write everything in one line but i don't want to do it so that's just maybe some of you are not familiar with python so preferably i will write everything in each each thing in specific lines so that you understand how did we go from from the step to the next step etc etc okay so here we can create a new variable called list of images something like this and as i told you we could do it in the first line but i just want you to see how we will use this part to create the list and how we would use the list to create the nifty files now here as i told you we have globe and in the globe function what we will do we put only the parts for example now in images so this one here if i will run this code if i will put here list images if i will run this one as you can see as i told you we have two parts the first one is for the first passion and the second one is for the second and here we have images and the same thing for the for the labels if we create lists labels labels then here we have globe and in path i don't know what i can type labels okay now if we do the same thing here i will just put labels and now as you can see the same thing we have first passing second passing but here we have labels now these two lists contains the folders of each uh of the passing of each for the images and for the labels now after doing this we need i will delete this now what we need to do is just to convert each folder so the function i will just write write it here the function is d com to nifty as i told you the same name of the library now what we have to do is just to write the name of the function that we will use and as i told you the function is d com to the d com series to nifty so when we are we are using a library we want to call it to call a function you can just write decode then series then 2 then nifty very easy dcom series to nifty very easy function if you are using visual studio code maybe the the editor will suggest it for you but as you can see it is easy the com series to nifty this is the name of the function if it doesn't exist you will got an error but just try to search for it but this is the name the comp series to nifty as i told you there is two parameters or there are two parameters the first parameter is is when we put the input folder the folder that contains all the nifty files and the second parameter will contain the path where you want to save your nifty file and where and what is the name of your output which is 95 so the first thing as we said is the input part here we have this list which contains two parts and these two parts are the input parts that we need so if we take for example list images and we put something like zero means that we are talking about the first part if we want to take talk about the second one we will put one if you have 100 you put 100 or 99 because it starts from zero so 99 means the final or the last uh passing that you have in your 500 passengers so that means that this indexes will change the passing that we want to convert and in our case we said that we have i have two but i will not just just put zero and then put one because it is not general for us i want to write a generic code for everyone if you have two three four five any number of passings you have it will work for you i am talking about the code for that we need to pass this this function because this function will do everything all what we need to do is to create a loop that will pass by all the passions so for that case what i will do i will just write here for passions for example in then we said that in what in all the files that we have or all the passing that we have and the passion that we have we have we have the same thing for me i have two but we have two folders we have images and labels let's start by images then we will go to labels so the parts that we have are here list images this first one this first list contain the parts of the images then here we will put the same thing with the columns and just make space now this function this for loop will pass by my two passions for you you have more than that so it will do it for you now before doing that we need to create the output files or the output parts okay to do it what we need to do we can just do it manually or you can write a code i prefer doing my doing it manually because you so that you will know where you are where you are saving your uh your files so for me i will start by creating a new folder here i will give it the name for example nifty files so now we will have the nifty exact final nifty files in this in this folder now let's go and create two folders one for the images and one for the label so let's start by images and the next one is for labels okay now we have i will take just this part then we will add images and labels we can we can write it here so out path images something like this and now let's do the thing i know that i am writing everything here like maybe we don't need to write everything here we can make a script that does that create the folder and does everything but as i told you maybe some of you are not familiar with python so i prefer to use this so you will understand what why i am doing this and maybe you maybe if you are trying your this code because that happens to me when you are trying to use a code of someone else and you will get an error in your code and you will not understand where this error comes from because you you it is it wasn't you who write the code and you don't know where what are the steps and how can you fix your error etc etc for that case i am trying to write it with you so if you use it it doesn't work for yours for your task you will know how to change something how to change the folders or how to change the files etc etc for that i am taking time for that but sorry about this because i didn't like the old the old way which is just writing the code and give it to you because i don't prefer it okay now as i said we have images and the same thing for the labels i will just copy this and paste it here we have labels and the same thing here labels okay now after doing this what we have to do just to i will just rerun this because we need to save these files in the system now as i told you we have to pass by all the passions but before doing this as i told you here we have two parts or two parameters the first one will take the inputs folder the second one will take the output folder so for the input folder as we said we have parts that are in this list so here we have passions so because in each iteration this variable passions will take one part from the list so if you have one it will be of the only one if you have two it will turn two times the first part then the second part if you have ten parts or ten passions it will run t ten times etc etc for that case the first thing here we will put only the part of this uh passion then the next parameter or yeah next parameter on that argument will take the output path plus the name of your passion so the output part here because we are taking talking about the images so the output part here is the image so we can use something like os.pat dot join why i am using this so that we can join the output part plus the name of your passions so in this case the output part here for the images is out but then images this is the output part of the images then the name of your passions we will we need to return it we can just make uh the i here from the index and make passion 0 1 2 3 etc but maybe in some time because here there is something we need to talk about here for example not liver in the groups imagine with me you have maybe 10 or 100 passions and for example for the first person you have two groups so you have level 0 0 level 0 1 level 0 2 3 etc so something like this and at the end you want to know which path is exact because you have created maybe three or four groups but all of these groups belongs to the same passions so maybe at the end you want to know which person had that problem and i will not say maybe because you need it you should know because when you want to say that this passing for example if you are doing tumor segmentation you will you need to know which person has tumor so because if you just create groups and rename them you will not know at the end which pass it has tumor for that when you create these groups you need to know at the end which uh which passions for that you need to save the name of the passion plus the index for that case here when we will do the conversion we will not change the name we'll just extract as we did here you remember you remember here not this one remember this line what we did here just we returned the name of the pass hand and we'll do the same thing we'll return the name of the passage and use it in the saving here so i will just copy this and paste it in my for loop and now i have the password is the same because we are using the same this is very good thing when you do unique stuff so you in each if you will write 200 lines of code you will remember the name of variables because if you put multiple and or random names of variables you will get problems at the end of your uh coding because in some in some case maybe we are coding now after one month you want to read your code you will not understand what this variable is doing because all of us had that problem that calling your variables a equal and it will work but as i told you after one month if you will read your code you will not understand why did you put that for that i am putting in images in past images output images labels etc etcetera so now here we have the outward spots we need to join it with the name of the passion which is here passion's name and that's it passion's name but there is something else passing's name will be only the name of the folder which will be lever here for example lever 00 underscore 0 not that sorry so but we need the extension because this is the name of the passions so if we have images we need to put dots jpeg that's png that's steve etc and for our case we need to put the uh the extension of our of our files which are nifties for that case we need to add the extension which is a string of course so that's nii if you put just that and i i it will create a nifty file but it will not be compressed if you need to compress you need you need to compress it after but you can just add dot z if you do it like this it will convert the d columns into nifties and compress them at the same time so if you don't need the compressed files you can't put just that's an ii but if you need them converted so you need to put that g z something like this so now this loop it will convert all the passions or all the images or the passions but the images or their volumes then we will do the same thing for the labels so just let's run this and you can see that we have star here saying that this cell is running so it will not take a lot of time so don't worry about that let's just wait so that's it now let's go to our nifty files images and these are our two files that we have created let's try to open one of them we have 3d slices there just to make sure that the files that we have created are good let's try it it will open in any second now so let's take for example the first one drag it here and you can see that we have only the maximum here is 64 which is which starts from 0 into 64 which are 65 slices so these are the slices that we have created and this is the good point because you will have unique number of slices for all the passions so in this case in the training you will not have any problem with your data so now we are making sure that the function is great correct everything is good let's do the same thing for the labels here just change the name into labels and the same thing for the bot let's go here labels and rerun it again and it will convert the labels or to create labels you see that sometimes it take few times when i say a few times few seconds i am saying not few minutes or something like this because it is converting then compressing the file for that it take few maybe 10 to 15 seconds but it is working now these are two other files of uh of of these are the labels the file of the labels and these are for the images and as i told you don't worry about the number because here this for loop it will pass by all your passions so if you have 10 it will convert 10 if you have more it will convert more if you have less it will convert less so that was how to convert the comp files in the next step we'll talk about because all these things that i am talking about are when you have data already segmented or already already labeled but maybe let's suppose that you have passions but you don't have your labels so for that case i will show you how you can do the segmentation by yourself using etk snap now let me show you how you can segment your data if you segment or label your data so if you don't have segmentations because if you have already downloaded data from the net in this case you will find that the labels but maybe as we were saying at the beginning of the course maybe the data that you will download doesn't have the same number the same extension so in this game i don't know or maybe they are using another task for example they are doing uh liver tumor segmentation but you won't use that data for only liver segmentation not the tumor level segmentation for that case maybe you need to correct or to re label your data so for this purpose i am showing you how you can do it yourself for that i am using etk snap that i showed you how you can download it and install it now let's start by i will just make this window bigger i will take this here now let's go to deliver i am not a doctor but i am sure that this is delivered okay so now let's do some segmentation i will show you how you can segment some slices but you will get the point because you can do the same thing with 3d slicer but i found that to these slices is a little bit complicated in term of segmentation but etk snap is the easiest software ever to do this kind of stuff it is old but it is very easy for us i i prefer to use it for segmentation for example i will show you how you can create a new segmentation and i will show you how can you can correct the segmentation even for so if you have already some segmentation and you know you need to just modify it or collect it not to redo it again so i will show you how you can do it let's create one save it and load it to change it after now to do the segmentation you just need to go here you have clear label we'll use it after try to choose one label so for us we have only one thing or one organ that we want to segment which is the liver so we used label one if you have multiple organs that you want to create so you start by for example label one means that you will do or you will segment the first organ then if you want to segment the second organ you choose the label two so it will know it will give two different values to each label and two different colors etc but for us we are segmenting only one organ which is the liver so let's choose the first one which will be in red now let's choose our brush so click on this one here paint brush like this and you choose the shape the shape it can be square or circle something like this or something generally here i prefer to use this and this thing here just bar here just to control the size of your brush something like this and you can use these for sometimes i used i used to use this 3d check box here but what does it mean because i will show you with the 3d and without the 3d when you do without the 3d if you segment this slice means that you have segmented only the slice if you go to the next one you will not you you will not see any segmentation but using the treaty it will segment two or three slices at the same time depending to if the slices are similar or not i don't prefer to use the 3d while doing the segmentation but i use it most most of the time i use it when i want to correct my segmentation in that case i prefer to use the 3d or to delete the segmentation so that it will be fast but when doing the segmentation or doing the labels i prefer to use the 2d normal 2d i segment each slice by itself so let's show you how to do it for one slice and you will get the point for all the slices now just select as i showed you here the shape and everything is good first label the shape here and the the size of that brush here and let's start just clicking and labeling like this as you are painting i am not a good painter but let's try to do it try to make your segmentations as tight as possible and try to cover only the lever so that's the code will not get confused with the other organs because you see that it is in grey scale and everything is similar so if you don't segment very well the mother will start segmenting everything in the body well not too bad it is too bad actually but we correct it let's make it bigger here so that it will be fast oof we did this now let's go to the next slice to do to go to next let's just scroll something like this and you see that for this first slice is segmented the next one is not segmented so you do the same thing here like this i will just do it to have time because it will take time if i will start painting so the same thing for the other ones just like this and do not don't do the same thing that i am doing because i'm just showing you but all these things need to be corrected that i wish i will show you how to correct that but as you can see don't do it that's it's the same thing for all the slices okay so now let's save one segmentation and we will reload it to do the correction for example this part or something so that you will understand how to correct your segmentation now to segment to save it go here in segmentations and save segmentation image and that's it just give the name and it will be saved at the same part where you have your images otherwise if you want to change change the path just clicking browse and change the path let me give it the name for example test segmentation something like this and it will be saved with the same part of my image which is this one now let's just close all these images without saving we we just closed everything now let's just let's try to reload our uh segmentation that we have created now this is the segmentation that we have saved drag and drop here but here when you do it just click on load as segmentation otherwise you can go to in segmentation open segmentation and choose the path but if you have already the folder just drag it drag it and drop it here and click in load as segmentation okay and it will be opened put this one here i'm going in wrong side so these are the slices that we have segmented now let's i will show you how you can correct these segmentations for example let's try this one let's collect this part here and you will get the point and you will see that it is very easy remember when we want we wanted to segment this part we we clicked on segmentation or label one if we want to segment something else we click on label 2 and it will get in the green color and it will segments another organ now we want to clear the segmentation of we need to delete or edit segmentation for that case we click on clear segmentation that's easy click in the brush check the size and check the shape and the size for example and now if i will go here click you can see that it is deleting the segmentation like this it is clearing and if i will do this this we do the same thing so now you get the point how to do the segmentation how to clear the segmentation and how to save it now when doing this if i want to save it again i will just click here save you can just click here in save with the same name if you want to save another file so because here if you click here it will pass this plus this new segmentation in the last one so we will lose the first segmentation but if you want to save it as a new segmentation just click in save as and that's it so that was how to do this segmentation now you have you get the point if you don't have already the segmentations with your data you can do the labeling using this etk snap software after doing this you can pass by the way that we talked about before which is converting into groups and after that converting into nifties because we so i told you why we needed to do this because if your data is ha has the same number of slices for all the passions or something similar like 100 110 120 90 something like this maybe you don't need even to do this type of conversion because 100 or 90 or 110 is nothing you can just resize them and put them at the same at the minimum which is 9 90 slices and put all your passions at that's 90 slices but if you have passions with ones or with 90 others with 200 so if you do resize you will lose more than 100 slice for some passions for this case i recommend you to create the groups of specific number of slices as we did before 65 and it's up to you you can choose any number of slices you want so that was for this in the next part we will start doing the preprocessing because this part is the preparation of the data you see that we are just preparing the data in the next part we start doing the preprocess which will be before the training we do the preprocess after that we will do the training so let's see let's do the next parts in the next few minutes so before going to the preprocess there is something that i forgot to talk about which is the images or the groups that we have created there is something here i will go here data set label then the nifty files these so for example this is for the images that we have created and this is for the labels so there is something in some cases when you for example you have a passage with 600 slices or this is not strange because you will find dataset does have pass into its 600 800 and more than that so don't don't be confused about that but this is not the point what i am saying or trying to say is maybe in this 600 slices only 100 or 200 slices that are useful or maybe if you have passing with 300 slices only 100 or 150 slices are useful the others are not useful so when you create groups of 65 slices you will find some sub passions which are groups that we have created for example this one contain nothing which means that the labels are empty which means that part of the body that you subtracted doesn't have anything which means all labels are empty for that case these type of groups or these type of subpassions will cause a problem with the accuracy of your problem of your program or of your your mother sorry for that case preferably you need to take or to delete these parts because they are useful because in your 65 passions you will have indeed you will have some empty slices but if you calculate the difference between the empty slices and four slices you will find something like the same or that is not a big difference but when you take a sub subpassing which will be one input so it will be one input without any label so imagine with me that you are doing a program of classification between cat and dog and you put with your data you put images of rabbits or something like this in the training so the program will be confused we will say that this image of rabbits is not useful i will not use it you need it for the classification so why you are putting it in the inputs so i hope that you get the point for that case when you create and this is something good when you create small groups for this case you will delete all the parts of the parts that you don't need so for that case when you create the groups you need to find or to specify which are the slices that are empty or the groups or subpassing that are empty so that you can delete them for that i wrote a script for you it contains only two or three lines of code so don't worry about it which is useful just to show you which are the uh the the files or the passings that doesn't have any label or any segmentation for the 65 slices so to do it we will do it step by step just we need to import one library i don't remember if i think we have already installed niba bell let's try to import it and see there is no problem so we need this if you don't have it just write beep something like this pip install knee bubble and run it for me it is already installed so recommend already satisfied i will delete it so after importing it rerun this cell so this file is this library will be imported now let's use it so this new bubble is a function just to handle the nifty files because what we will do we will load each file which is a nifty file then we will see the values of the pixels if there is values between zero uh if there is values of zero one two and something like this more than only one value means that this uh subpassions contains labels indeed it contains this the zero values for the background and the one for the foreground and if you have multiple objects you have you will have two three extra etc and and if you will find only there is only zeros means that this part contains only the background which means there is no organ there is no lever in that part so you need to delete it okay this is my recommendation if you don't want to use it you want to use all your passions you are free to do it but i don't recommend you to use multiple uh groups or subpassions which doesn't contain anything in that case because when you put the patients directly with with random or with random slices having labels or not at the same time there is no problem but when you put one input without any label so this is the problem so when you create the groups you need to make sure that you don't have any empty labels or any empty passions when i say empty which means there is no parts that doesn't contain doesn't contain lever okay so let's start coding this as i told you the first thing that we need to do is to open the image which will be for example i will call it image or nifty file so to do it we will use the knee barbell i just need to use this i can use the shortcut like as nib it is a convention they are always but you can use directly bubble but it's convention to use nib as for knee bubble to make it short so nib then that's the function load this function load will load one pass hits so let's do it for one passing to show you how does it work then we'll create the loop that will pass by all the passions now let's do it let's start by taking this part for example here is the is this is the output part but for us we need it as an input here because we need this path but you don't need to use the parts or the files of the images because the images we are sure that images are have multiple values have zeros one and something between them but for the material for the medical images you will find values between minus three thousand or minus one thousand into plus one thousand don't worry about that this is the medical imaging welcome to the club so what you have to do is using the labels because we said that we need to see if there is label if there is foreground in that part of the body so for that we need just to check the labels because labels will specify the foreground and the background we cannot see that in the images so let's take the path of this output images which will be our input here so i will just put in put nifty file path for example and that's it's ctrl v so this is the all paths for now we take as i said it will take only one passion so i will just take the name here after using after trying with one passing i will show you how we will just add a loop that will pass by all the passes don't forget to add the gz because the value the files here are compressed so that's gz now let's what we will do just we will load this passions which will be here inputs in put something like this input nifty file but so if we run this cell there is no error no problem because we just loaded the image it is here in nifty file what we need to do now there is something in the medical imaging if you have already some knowledge about that there is not only the image exactly which is the array of the image we are talking about the nifties or the decons the same thing there are other informations like the passive information the name and age etc there are value or there are informations about the pixels the dimensions of pixels etc will use this in the preprocessing process preprocessing sorry we'll talk about them later on but for now what we need to do we need just to substitute to extract the value the matrix or the array that contains images which are the slices because what we need to do just to take this values or this matrix that has all the values of the slices and verify the slices of each passions where there is only zeros or where there is zero and one or two or something like that for that to to to start to subtract or to extract the array from the image which is nifty image there is a function called getfdata fdata means that frame data so we can just create as i told you we can do everything in one line but i am just writing every each thing in one specific line so that you can understand the steps that we are passing by so here we have f data which means frame data to do it just write the name of your passing which is nifty file dot get f data it is a function so we need to add the parenthesis so this fdf data will contain the values of all the slices so it will be an array of 65 slices because we have passage of 65 and each 65 yes slices or 65 items and each item is an array of of an image which contains the values so we need to know if these values are contains only zeros or zeros and one or zero one two three etc for that case we need to specify the dimensions of this f data but using only dimensions will not be the thing that we need because the images will just give you how many slices or something like that but there is a function in numpy called unique numpy that's unique so this function unique will return if there is or if there are unique values so if you have only zeros in your function if in your array so the unique values will be only zero if you have zero one two three but you have multiple one two threes in your image so it will return only the unique values that you have in your image so for us if the unique values will be only zeros means that this image or this passion is contained only zero that means that there is no lever so we need to delete it if this unique function returns zero and one or more than one value means that in that case that uh there is something in the image that is the background and there is the foreground indeed so to do it here what we can do as i told you we can choose the number the uh the function unique so here what we can do just i will create another function sorry about that but as i told you i want to write everything so i will call it numpy unique and now we can i don't remember if i have not by here we don't have it so if you don't have numpy just as i told you just something like this beep install numpy and it will be installed but for me i already have it i think so i will put imports numpy as and b something like this so it is already imported now let's let's use it so np dot unique and here we will put the array that we have and for us we have f data this is our unique uh our array so let's let's let's print this so and be while using japanese notebook you don't need to use the print function you can just write the name of the uh of your variable and run it it will uh it will just print it here like this as you can see and for us for us you can see that we have zero one two for us we have more than one value we don't have only zero means that there is the background and that is the foreground for this case we don't need to delete this passion if we have only zero here we don't have this one and two we have only zero means that we have only the background so this buttons need to be deleted i hope that you get it this is the point that's all what we need so the function that we need to do is only to specify the length of this return or of this unique uh so what we can do we can just say if np unique but as we said we need the length of this of this variable so length if the length of this and be unique is bigger than two which means the the length is not one if there is bigger than two means that we don't need to delete that passion but if this lend is equal to one means that this passion need to be deleted so if equal to one let's make just like print and let's print this this passion so for us we'll print this this part because we we are having only one but we do it for a loop now let's print it here there is nothing printed because this passion has foreground and background so if you are in the case where there is no foreground and background you have only the background so it will be printed now let's do it for all the passions you have data database for which with i don't know hundreds passions let's do it now so let's say that labels and just change put here star this mean that this part contains multiple files so this star will return everything inside that folder to do it let's start by creating the list as we did here we need to create a list of labels and it is equal to globe then here the parts input parts file uh a nifty file then here this this list of group of parts will be used in the for loop as we did before so now let's just write for persians in list labels then let's do what we have done here let's just we can just copy these and use them there is no problem let's just pass them here so they will be in the condition if condition now what will be happen but just we need to change this because we need to load that specific passion not the folder here so here load the passions which is here for the loop load the patient and get the frame data from that passion calculate this unique then calculate the length if it is equal to one then print it but we will need to print the passions so here sorry i am passions so we will read it we load it extract the frame data get the frame data then choose the unique calculate the new unique values then if it is equal to one the length then prints let's just run this and you can see that there is nothing printed because the both passings that i have here are with the foreground and background so there is no problem but if you have passions with more because for me or even my passions that i use in this test has only one hydrant and second one has 120 or 110 slices so when i created the nifty groups the nifty the decom groups and converted them into a nifty which is which are the sub passions here they have they should have slices with the liver because if i had the large number if i had pass it with 600 slices for example in this case i will get definitely definitively i will get three or more than three groups of decoms or groups of 65 slices which are empty so for this case i needed to delete them because in in this in this task i am showing you only two passions but i have already prepared the data and i had that problem and i have deleted all of them when we start doing the preprocess i will show you how i created the folders for the training and for the testing and we'll do everything together don't worry about that now as i told you this is the script let's verify if you have empty files in that case it will print them and you can delete them manually i wanted to do it with a script to delete but i had some problems sometimes if you do something wrong you may delete the wrong files but if you want to do it you can just add the line to delete that button but i don't prefer that i just want to print them maybe verify them but it's up to you if you want to delete them you can just add the delete or the remove function uh from the chantel that we used before here this function gentle you can use it to delete the file and just put the then call the gentle down here put the parts which is the passion of that part of that passing which is the empty and it will delete it for you so if you prefer to do this you can do it so now after doing i think that now we have completed everything about the preparation of the data let's start doing the preprocess and of course eventually the training so now before doing the preprocessing because all the functions that you will use or need to do the preprocess are included in muni and python so before doing that we need to install monae and pytorch and all the dependencies that we need at the beginning maybe in the process we will need some other libraries but not are they are not the most important ones but the important ones are for now monae and pytorch because they will use them for the preprocess for training for the testing etc for that we need to install them but before doing that we need to create to install code cuda which are the packages for the gpu and the tool case for the gpu so that we can do the training using the gpu not cpu because using the gpu and my training sometimes it took two days to two days to be completed because the images are very big so imagine with me if you have 60 or 100 passions and each passion contains 300 slices and these 300 slices we will divide them but i am talking about the at start so for example if each pass it will be divided into two or three parts so multiply your 100 percent by three so it will be 300 sub passions and each subpassion contains 60 65 maybe slices so imagine with me how large your data will be and we are we will use the 3d monae so we will do 3d convolutions so it will be tight it will take time it will be very slow for us you need to be careful not to be careful but you need to be aware about that you will prepare your data verify it if everything going well just run it and leave it for one day or two days depends to how many passes you have for me i remember one time the training took me two days or two days or a half when i say two days means that 48 hours not only two days just like that so i have a gpu with gtx 1080 but it does it it wasn't that fast so you need to be aware about that because maybe you will say you will say that i can use collab because when i they are using collab in their tutorials but remember that the images or the yes data that they are using in their tutorials are spacings with small number of slices and they have only 40 passings maybe i think yeah and for that the training doesn't take more much time but if you have data set with large number of passings and with large number of slices be aware that it will take time especially if you will run it in your pc because even if you want to run it in collab you you i i think that you know that in collab you cannot run more than 12 hours if you have a good internet connection without any cut or something like that it will it cannot go more than uh one run it one it cannot go more than 12 hours so you make it you can pay for call up pro so you will get 24 hours but as i told you something it took two days so be aware about that okay and don't be scared don't be scared if the training took two days because i am just telling you that it can it can do that okay depends on how many passings you have so to do the installation the first thing as i told you we need to install the cuda you can just go to their website developers.nvidia.com cuda downloads otherwise you can just write in google here coda download something like this and go to this first link and you will get cuda toolkit 11 if you have problems because we if we are using tensorflow it may be a problem because sensor flow with some versions of cuda or kodiana if you don't download or or if you don't install the specific some specific versions you will get problems at the end but with python don't worry about that because i will show you when we will install python you will see everything clearly so don't worry about the versions if you want to install 11 you can install it if you want to install 10 you can install it with no problems so here we want to i have already this uh qdn encoder installed in my pc so i will not download them again but i will show you how to do that to do that then we'll go to the installation part so for me i am using windows if you are using linux you can just click in linux so i will click windows this x86 then here the version of windows i have windows 10 then you want to use it in network on local i prefer use it in local and now everything is set you can just click on download and something i will just click to show you and you can choose the directory where you put your file and it will be downloaded successfully without any problem and after downloading this you just go here i have them here open your i will not do it again as i told you because i already have it but i will show you when you click on it you will get the window let's wait my pc is a little bit slow these days i don't know why but let's see so click on run then choose the directory i will not click because if i will click it will start doing the installation so everything is easy just click in next next next and everything will be installed after installing the cuda now let's go to kuden and korean is another package which will be used with cuda so just go here in developers.nvidia.com or just you can go here and press download typos press download to dna okay so here nvidia cdn the same thing and let's go on download cdn and now to do it you need to have an account and it is free don't worry about that you need to have an account developer account so once you create an account you can just choose version it depends to you so for us we have downloaded cuda 11 so we need to install this if you have already another version of cuda so you need to check the version that you need for your cuda so click on archive or korean archive so you just find all these versions so see which kudi which code that you have installed in your pc and install the available or the corresponding kudn version after downloading it what we will do we i will show you how to do it we this is it will be something like it's like a compressed file when you decompress it you will find this file this folders so that's what you will find so to install kdnn very easy you just need to copy and paste these kdn files into cuda where you you have cuda installed so if you want to see where your your cooler is installed what you need to do just go to your pc and go here in your desk then your program files and you will find the folder here nvidia gpu computing toolkit so this folder will be created automatically when you install kudi and cuda sorry and if you go here you have cuda and you have the version if you have multiple versions you will find multiple versions here but for me i have only one so you have you will find this one now i will just keep this here i will open another one we have three holdings here downloads and cool dnl so as i was saying what you need to do just to copy the files from the bin of the korean paste them into bin of cuda and includes of kodianen just copy them and paste them in includes of cuda the same thing for the lib copy these go to lib x 64 copy them and go to lib here and x 64 and paste them here i have them already so i will not do it again but you get the point because i have kudian and all the files are here so just select all copy them and paste them here that's all what you need to do and the last thing that you need to do is to go to your system environment and add your file the parts of the lib i will just show you here properties advanced parameters variable systems if available environment and now if you go in parts you will find that i have i don't know if i can yes i can move it here now for me i have these parts the path to the bin to do to the bin w uh to the bin and vvb and the the other one which is extra cool t slash lib64 where you if you will find them they are all here good version so this is the first part which is the bin so go to bin copy this part copy it ctrl c and come here click in new and paste it and that's it click enter the same thing for the other one which is the lib and vp this one and copy it create a new part paste it and the same thing for the extra copy tt lib64 and copy this and paste it here and you are and everything is set now you have installed the i will just close this now you have installed your kodi nnn we will go to this one here we have installed cuda kudi and now we need to install monae and python let's start by mulai the easiest one to install mona you can just do bip or conda install so here we install more light that's it it may take some few seconds it depends to your internet connection and because my internet connection is very bad so it will take maybe one minute or less let's stop it for a few seconds and now you can see that it is installed now let's try to install python so to install pytorch we just we need to go to the website pytorch.org okay that's it and now to inst to download it because when you go to python.org you will go to this page just scroll down here check the stable version for me i am using windows if you have mac or linux you can just select them after that i want to install them using pip install if you have you want to use it what really difference is when you click encoder it will be could install instead of beep install but you can see that some some things will be different but when you use for me i am using python pip install so it will download the packages from the uh from the website by touch the website okay so flip then python because you are using python now if you have kuda 11 check code 11 if you have kuda 10 check code 10 if you don't have gpu and you want to do your training in cpu i don't recommend you because it will take one week so you need to check on cpu so it will be installed or storage vision touch audio for us we have cuda 11 because we installed cuda 11.5 but don't worry about that 11.3 does the work because you don't you don't have 10 so we have the 11. then copy this lines and we will install them so for us we are using jupyter notebook i need to do it so here you can see that pip3 you can leave it pip3 or you can make just pip where we have pictorially because if we have installed pip 2 uh python 2 and python 3 in the same virtual environment so in that case we preferably need to use pip without number means we are talking about python 2 if we put pip 3 means that we want to install this package in the python 3. for us we have only python 3 we don't have python 2 so pip it will install in the python 3. so when we run this cell the same thing this installation may take some time depends to your internet connection so after doing this everything is set when we start doing the preprocessing after installing muni as you can see mona is installed and the cuda installed korean installed and now we are waiting for pytorch let's stay for a few seconds to see this message successfully installed yes we have to see it so now everything is set and you can see that the pytorch is installed without any problem now everything is set we don't need anything to install for now i will delete this and this if i will click for example import monae it will be imported without any problem so now you can see that everything is set because i i i started with this because i told you because we need we will need monae and pytorch for the preprocess even for the president only for the training for that i needed to start by ins by this installation so let's start doing the preprocess now let us let us talk a little bit about how to do the preprocess so i will not go to the to the steps uh each line of code by line because i have already done videos and blog posts about everything that we need to do for the preprocess so you can find the links here in my website that is in my picadco you will find a blog post about preprocessing in detail and also the youtube video youtube video about that so you can check it out so that i will not repeat everything in each video because i know that if i will talk about that it will take a lot of time because only the video about preprocess i have two parts each part for 40 minutes or 50 minutes so imagine with me if i will talk about the preprocess and this augmentation that we will come to it later so it will take a lot of time doing that but there are already videos that i have done about that and there are blog posts that you can read there are code etc but don't worry about the code because the code that we will use here is more i have i have just ordered it and it is well done because here it is you will find the code but it is only for the preprocess but here since we are going to do the training after the preprocess so i have created some functions instead of just scripts doing the preprocess i have created functions that you will find in my youtube repo in my github repository don't worry about that at the end of this course i will be i will be talking about everything so i will show you how you can just get clone this the git cloud this github repository and how you can call all the functions because you will find that every function that we will use is here for example how to calculate the dice matrix calculate weights everything we will talk about it later here is the function that will do the training because as you know in python there is no a specific function as in because if you have used tensorflow before you will find that there is that function that feeds mod that fit so it will launch the training and is a little bit easier but in python there is no function called that fit so you need to write the loop by yourself and almost all these things in the training part i took them from uh pythorg from sorry from monae tutorial but i just have done some changes to make the code clear but we go we'll come back to this later and here in the not in the preprocess we find all the functions that we talked about for the creating the groups and nifty to decom and find the empty and at the end we we have this function function prepare which contains the lines of code to do the preprocess so everything is here in github but i will make it clear at the end of this course and i will show you how you can just clone the repository use the functions but before that i just wanted to explain to you some of these parts because as i told you i will not go to everything line by line because you will find the explanation here but just to give you a small explanation i will give you here i will talk a little bit about some of the fun not the functions but only some transforms that we used here because if you go in monae's website you will find that there are tons of transforms that you can apply in your data for the preprocess and for the data augmentation but for us i will not use all these data all these transforms sorry i just took smaller few of them just to make the data clear but i didn't do like a huge things for the data because it will take time and it will take memory and i don't have that great gpu to do all these functions but i will show you how it will look using only these preprocessings and you can do it yourself like this if you want to add more functions of course it will be great because you will see the results at the end they will be acceptable but if you train your model for more data than i that then i am using or you if you do more preprocess or more data accommodation of course your model will be improved better than mine but we go to this later now let's talk a little bit about the preprocess as i told you here as you can see i have created four variables each variable contains the path for the training volumes training segmentation then the testing volumes and testing segmentation if you have already seen the tutorials of monae in their website you will find that they are not talking about testing they are talking about validation but i prefer to call it testing because when we see validation in deep learning most of the time means that these data will be used in the training and it can affect the model during the training but here of course we are we will because if you see the tutorials of monae you will see that they are using actually this data that they are calling them validation data they are using them during the training but they are not affecting the training for that they say always testing data because we just use them to see what happened but we don't use the result of that validation data to do some changes in the model for that i prefer calling them testing data and not validation data but it ups to you you can call them anything you want but i don't prefer to call them validation and if you want to leave the validation you can do that so as you can see here the there are some important things that you need to keep in mind the first thing is the name of your folders i don't i am not saying that you need to call your folders with the same names that i am doing but what you need to do or what what is important here is that you need to specify the name the exact name of your folders because here there is the first thing in your path or where you will find your data the first thing is the main path which means the directory where you have all the folders or all the passions for example here for me this is the whole or this is the main folder which contains four four folders i will just minimize this and this directory contains four folders the first one is the testing test segmentation where you will find the masks for the testing and the second one is the test volumes and this one training segmentation and training volumes volumes means the passions and segmentation here means the labels okay so these are the four folders that you will need so if you are calling them the same as i am calling them here you can just leave the code otherwise if you change these name then you need to change these names as well here so if you will go with me at the end and just fork the github repository and use it for that case you need to change your folder's name to make it easy or otherwise you can change in the code but maybe the best thing if you are using the same code the best thing is to change only the names and not all the uh not the code okay and the second thing actually i i will talk about this later on and i will show you some examples but now i will give you just small words about that you need to be specified about this thing here which is the extension of your files as i told you we cannot use something like other types but nifty so we need to use nifty files but the second thing here as i told you here when we add that gz means that this nifty file is compressed so if your files are not compressed you need to delete this dodge gz because if you leave this the gz but your files are not compressed means that this not this is just defining this line is just defining the part but here when you will load your data and you don't put the exact extension here means that the function bell that will open this volume will not find this file it will find for example passion one does nii but it will not find that gz in that case it will not recognize that it is the same passion for that case it will not open it and you will lose this passion and imagine me with me if you're if all your passion doesn't have this gz means that your your code or your program or your own function will not open any type of data and it will not open your passions in that case you will find your data loader here empty like there is no data and you can do nothing with that and the problem here is that you will not know this is the biggest problem with one eye you will not know where is the problem you it will not give you an error here if you will run this code there is no error but when you will try to print no print or you can if you want to print or if you want to upload your images in this case you will find that your data loader is empty and you will not know that the problem is with the extension this is what i am saying you will you will miss to delete this extension but the code will not tell you that you have missed something or there is something wrong or the directory is wrong or there is no such a directive like this because always when we do or when we put the wrong part always we get the error saying that this directory doesn't exist and in that case you will know what is the problem but with mona you will not know that you will find just the data loader is empty but you will not know that it is empty because you just forgot to delete or to add this.gz the same thing for other stuff but as i told you i will show you that in in practical but not for now now now i am just explaining but after that i will give you a small things that will cause problems and i spend a lot of time trying to to debug that because you will not know what is the problem you know you need to print everything in your code so that you may find the problem for that i will first case i will show you some of the problems that i found during my period not pid but during my uh master's thesis while i was doing this project not this project but something similar but uh in this case maybe if you will find or if you will be faced with these problems you will know how to solve them so i try to do there is four for variables each variable represents the path for the volume segmentation for the training volume segmentation for the testing the second thing here is to create two dictionaries the first one is for the training second one is for the testing dictionaries is only some rows and rows and columns and this these are the keywords and these may cause a problem as well but i will not talk about them now so this one is vol for volume this seg for segmentation so these are two keywords each one represents a column so this column is for volumes this column is for segmentation and in each column you will find some rows and each row contain the path for each passion so the first for example first row first column we represent the path to the volume of the first passion this the first row and the second column will represent the segmentation of the first questions etc etc these for the training and same thing for the testing and you will find all the explanation about these in my blog post and in my youtube video about that so just i am just giving you a small uh recalculation but you will find everything there and now let's talk about this transform function this transform function you can see that there is this function composed which is you can find this in python and idea are using the same thing here compose is a function that allows you to use or to apply multiple transforms at the same time not to apply a first transform to the image and the output image passes to the second image that the second function that will do the second transform etcetera etcetera but doing using this compose function you don't need above you don't need to worry about that you just need to define which are the transformers that you want to apply and it will do that it will do that by itself you don't need to specify which one the first the second but here it will take this order this one will be applied the first this one second extra extract until this last and about that some of these functions need to be in the exact order but others doesn't matter you can add them any way you want so the first one that need to be at the exact order which is this one which is load image load image because before doing any transform you need to load the image first so to load the image you need to use this load image d d is for dictionary because you can use more line with these dictionaries or you can use them just with opening images without using this dictionaries so when you do that without dictionaries you need to delete this d but if you are following my code or if you see the code doing by mona they are always using dictionaries because it's fascinating but it facilitates the ev everything in the code because if you use just script with all the parts it will be something painful but here you know that when you specif when you put you or when you use the keyword wall meaning you are talking to volumes here segmentation because you will find that everywhere when we talk about how to show images or how to train images everywhere will use these keywords so it is something that will help you and not be painful for you so i recommend you to use this way which is the dictionaries but if you prefer the other way of course you can use it and you need to delete this d at the end of all the functions okay so after loading the function the passion sorry you need to add a channel because as i told you in our case there there are two uh for us for now there are only two challenges for the output there is the first channel that represents the pixel for pixels or the mask for the background and the second channel will represent the mask for the foreground in that case you need to add a channel here so that you will have two channels okay okay but you will add another one for the for to specify the the batch size but it will be added here from the data loader don't worry about that and of course as i told you you will find everything here explained in this blog post okay now after adding a channel there is something that you need to do which is changing the pixels the dimensions the pixel dimensions of your passions this is as well one of the important things that you need to keep in mind because what you will do here i am using pixdem and this name here because i am using the speaks theme in this in the parameters or in the arguments of my functions that i have created and you can see that i am putting here 1.5 for the width 1.5 for the height and 1.0 for the depth of the pixel so in your case you will find maybe your because the problem here with the public dataset you will find that you will find some passions having uh two by two by two others zero five by zero five by zero five others one by one by one and if you use them as they are you will find we will cause a problem for that case you need to put them at the same dimensions okay for this case you need to use this function which is spacing which will change the spacing and puts all the dimensions the same and the problem that i told you here you will find the problem here with with the depth especially because with the width and height if you define just a constant number here it will fix the problem but with the depth it will cause a problem if you don't choose the right value here i am using one because i found that with data there is no problem with the value one but in others it may cause problem we'll come back to this later when we will talk about all the problems that you can face during using monae and deep learning for medical imaging now the next thing i will not talk about this because it's not that's important but here for example this one scale intensity range this is another important function which will change the intensity values or the intensity range of the of your images because if you print the maximum and the minimum value of your pixels you will find that it is from not all of them but some of them vary from minus 3000 into plus 3 000 others from minus one thousand five hundred into plus dollar one thousand five hundred they are huge values for this case you can never do a training with these values you need to put them from zero to one okay you need to normalize them but before doing that you need to change the contrast because if you don't do any changing of the contrast and leave them as they are the there is no visibility to the images for this case if you will you do a training or something like that you cannot recognize the different areas or different organs from the image for that you need to change the the contrast of your image for that here i am using because this b mean and b max are from what you you will normalize you the values will be from zero to one but this a mean and a max will represent the values that will change the contrast of your passions let me give you an example because for me now i am i as you can see here i am putting a mean equal i mean a max equal a max because these are the arguments that i will pass in this function for by default i am putting them minus 200 into 200 but i when i will call this repair i can change them otherwise if i don't specify them it will take these values by default okay i put this because i found that these values are the most uh the in average this is the important this is the best ones in the average but not all the time but how did i find these values now i will show you a simple trick that you can use to find these values for your specific data so let's open here etk snap and let me wait let's choose one of let's open this patterns for example now as you can see the visibility is little bit we can say normal we can see the different parts of the body so here we can see the lever with no problem but why because i am changing the contrast if i will not change the contrast i will go here to tools you need to click in tools then image contrast then contrast adjustments you will get this window if i will click in reset this is the exact or this is the the value that you can find as you can see here for example the minimum is minus 1000 to maximum is 140 for byte or i don't know what is the unit for this pixels but the value of that pixel there are some pixels that they are having the maximum value which is 140 for 1 1400 and others having minus 1 000 etc etc in this case the visibility is not that easy for us we are doing liver segmentation maybe we can see it but it is not clear imagine me if you are trying to detect something like i don't know this one or something you cannot recognize it because everything has the same color for now so to do that you need to change it and you can choose you can use these arrows and try to find something visible but when i tried this it wasn't that great but i tried just changing values here randomly and for that when i found these here and here where i found the values not this sorry i found here here what what you need to change you can change here values and these are the minus 200 and the plus 200 if you want to do some changes you can just adjust these values but you can see that the best thing is minus 200 and plus 200 okay and if i will change here you can see that the values here are changing okay but if if you need if or if you want to use this for example this parameter and as you can see here this one is better than minus 200 okay so we can't just take this in concentration but you you don't need to use everything that you can see maybe for my data it is working well but for other data maybe it will not work very well for that okay so you can do a training with this otherwise you can just do do any changes here for example i don't know 100 and here for 500 or something and when you see that the the image or the organ that you want to detect is visible you can just take these minimum and maximum and this minimum and maximum are the values where you will put here a minimum and a maximum that will be placed in the scale internship intensity range and it will be here for a minimum and a maximum okay the next function or the next transform is this one crop background the foreground sorry this group foreground is one of the i will not say important because if you don't use it there is no problem but it is it is one of the useful functions or the useful transforms because here you can see that this is the whole image because it is the black area but i will just reset here just make it clear but you can see that it is a black area but it exists in the image for that case preferably you need to delete all these borders that you don't need and just take this foreground part for that case this function crop foreground is useful for that it will do that because you can see that in each function we do here when we want to specify that transform for the volumes we call the keyword volume when we want to do it for the segmentation we do segmentation when we want for both we write both of them and you can see that most of the time we apply it for every for every keyword which is for the volume and segmentation because we want to load the volume segmentation channel to the volume and segmentation change the spacing for the volume segmentation etc etc but here for the spacing for example we need to do it only in volumes because our segmentations are values from zero not from zero but values of zero and one so if you do the if you do some this these changes you will lose all your mask because they are binary mask so you don't need to change the segmentations for that we write here only volumes and now as i told you here there is say the second keyword or second argument which is source key because if you use the source key like segmentation here in that case segmentation it will be only black alia only something white in the image so if you do that it will crop all your your image and you will lose all the information and you will get only the white area or the place where there is a liver in your mask and in the slices where there is nothing in that slice what i am saying it will crop all the image for this case you need to put here source m source key which is the volume for that case it needs to see or to look at the image not to the mask so it will look to the image and crop this parts and leave only the interesting parts from the image which is the foreground okay now after doing the foreground here there is the resize transform which will resize your images and masks as well so that's what what i am using this here you can find that there is partial size this partial size is what i am putting here in arguments spatial size is the new spatial size of your images or the new dimensions so you can see that i am putting 128 by 20 128 by 64. here i can put 64 or i can put 65 because our data that we have created are 65 but i will leave it 64 there is no problem but you know that you can put here you need not you can but you need to put here the exact number of slices that you have created so if you have created the same number as i am using here then you can use 64. if you are using more than that you can but you need to change this value otherwise if you didn't create the groups as as i was talking about in few not minutes maybe a few hours before this part i talked about maybe you don't need to create the groups because maybe you have some new some numbers of slices almost the same for that case you just use here or you just need to put the average number or the minimum not the average but the minimum number so if you have you have passions with 4 with 100 slices others with 110 others with 105. so in this case the minimum is 100 so we need to put here 100 so all your passions will be resized into 100 slices and for the width and the height you can put anything you want here but you you need to be um you need to be careful you don't need to put something that will make the image not visible and you will lose all the information of your image and i am putting it this smaller because if i will put it more than that the training will be very very slow and maybe will not be accurate not i think that if you put it 260 456 it will be more accurate because i tried this in another machine not mine but it will be slow okay but for that i don't want to put it in my machine because it will be slow for that i am using 128 because but if you have a good machine or good gpus you can use this you can increase this dimensions of your images when you do the resize okay and finally after the resize what you can do is to change or to convert these images into tensors so this one will open them do all these transforms and after doing everything you need to convert them also transform them into tensors you need to be sure that this function need to be the last function that to be called because you cannot convert them into tensors then resize them it will be an error and you cannot even run it for that you need to be sure that this two tensor is the final or yes the last function that you need to call okay so this all what we need to see but if you go here to the monas documentation you will find that they are they have a huge number of transform that you need you can apply but i didn't want to make it complicated i took only the necessary ones but if you want to put more you can put more and now let's let's talk a little bit about the data augmentation if you want to do some data augmentation then you need to see some transforms here from the exact page because their page of transformed here contains the transforms for preprocess and the transforms for data augmentation so you just need to search for it maybe you just need to search for the word augmentation or data or notation and find all the the functions because i used some gaussian noise there are some zoom there are some flip there are multiple transformers you can use and i wrote another blog post about that that you can see and take an idea about that i think i have some examples here for example this is the same passage with multiple transforms and i have created all these uh this one for with gaussian noise this one shifting this one with flipping rotation rotation everything you can find in the documentation and you can read this blog post just to have an idea about that and and of course of if you need or if you want to add some data augmentation you need to add it in the training parts not in the testing because in the test you don't need to do any augmentation augmentation have to be done in the training so you can find or you can search for the function add it here and of course before this to tensor okay so that's all about the functions and now let's talk a little bit about how to do the data loader deci loader is just to combine between the files which have which which we have been defined here and the uh the transforms that we will apply to each file or to each passions so this is the this is all what you need to know about the data loader it will combine the images or the files with the year transforms and it will apply to transforms and load them in your ram and you can use them after but there is something here which i am putting here cache this cache i am putting here in the arguments if it is false means i will not call it which is i am talking about this part if it is true i will call it here but what does it mean this cache function this cache function because there is you can use cache data set or you can just use dataset if you use this dataset after what i read and what i understand is that this function will load your data into the gpu memory in that case the training will be uh more fast or will be faster and it is true because i try that with the with the cash and without the cash with the cash is faster when i when i say faster is maybe five or ten times without the cash but although it will be slow because even with this crash it will be slow i don't know why but depending to how many percent you have how many what is the batch size that you are using and what is the how many epochs you want to train your model for that case you it will control your the speed of your training but using this cache will make your training faster but not all not always you can use it because if you have a lot of data and you have a small memory in your gpu in that case you cannot load it and if you do it it will start loading it and in some point it will give you an error saying that you don't have memory in your gpu so you can you may you can use it or you can try to use it at the beginning if it works but happy for you if it doesn't work just put this cache force or you can just don't touch it here and it is by default false and it will do the training directly we do without loading any passings in your gpu memory okay now after doing everything here what you need to do just to call it but for now what we need to do if we just call this function we cannot see anything we need to plot it for that i wrote this function for you i didn't wrote it to be honest it is i found this from the moonlight tutorial i just made some changes and i am using it as you are so i didn't do anything by myself i just did some changes i just write and write some documentation here because these are some problems of one eye there is not enough documentation to understand what they are doing and there is no raising well i am saying raising because when you will have problems you don't know what is the exact problem you need to spend days trying to find or to figure out what is the problem so these are two problems with mona if they are watching this video i hope that because you are having great framework but just you need to improve these things and thank you for that and now let's talk about how to ch how to show one passion and of course you can do it for multiple passions the same thing here i am creating a function called show passing that will show a passion you need to put in the parameter here the data loader that you have in your images so this email this part as i told you it will take the data loader which means it will take the output or the return of this function i did this species specifically because i wanted to make it easy for you you don't need to write the same code the same here at the same function here and but you can just call this function and take its output and use it as an input here and it will close your image or your passions for that i didn't want to use it as that's i just want to use it at the same function here i just made this function for the preparation or for the preprocess and this function for the showing one passes so this pass this function as i told you it will just take this data which is data loader and here we are returning the data loader for the training and for the testing for that i am taking here check passion training check passion to test because they here this is a list of two data loaders training and testing and now i am doing this view train view test and now what i am doing here this function called first it is from one eye this function first will just take the first passion from your data loader if you have 100 passes this one will return only one pass hint so that you can plot it or you can do anything you want with it so this first function will return this first passion this first one will return the first passing from the testing and now we have two passings to view them or to show them one from the from the training one from the validity from the testing and that's it i am using here if conditioned one for the training and one for the testing because if you want to see if a passion from the training or you want to see a passage from testing there is no specific thing because if you just want to see your data after preprocess so it doesn't matter if you see a training or testing passion but just i like to put everything here to make it clear for you maybe you you want to play with it for that you can just make this true force or you can put them both too so you plot one from the training one from the validation no problem with that so let's go with this here after doing that just you need to create your figure and i will put here supplies and as i told you these parts i took them from one eye and you can find them in my or other ways because there is just something like only pure python just create a figure figure and before that this much plots leave this function or this package here maybe you didn't have or you don't have it you know in your virtual environment or in your system so you you need to install it i don't know if i talked about this or not but don't worry about this at the end i will at the end i will give you the requirement.txt that you can use to install everything but if you are following the tutorials you can just install it by pick install install then mod plot lib i have it already so i will not install it and the same thing for this tkdm function this function is this library is not if i can say it is not one of the important things but it is included in some parts of the code not only my code but even in the code of monae's so you need to install it because it will just show you the progress so if you run a loop for loop for example it will be running the progress or showing you the progress in which iteration you are or something like that it is it is useful sometimes but for now mona is using it so you need to install it otherwise you will get an error okay so just delete this and now as i told you after installing the matplotlib just import it here much block clip as plt and for that we are using here plt.figure to create the figure plt that's upload to to supply our figure to divide into two parts because here i want one line or one row two columns and plot this first part in the first it's first deviation so if you we have window here we divide it into two so one row two columns and this is the first part where we want to upload the first passion or the first image and for for us the first pass the first image that we want to upload is the volume of that image which is the this part which is this volume and the second part here because this is the second part will be the segmentation of that same volume and here we specify the number of slices not numbers sorry the slice number so if you want to print the first slice second slice and the 64 or 65 slice which we have in my case if you have more you can print more otherwise you can even add a for loop if you want and bloat every every slice you have or every passing you have and you get the point this is for only one pass into one slice and if you want to do it for more you can just change it here as the arguments of my function i am putting here this is the required argument that you need to put the data loader which is the output of the preparation function then here you need you can specify the number of slice number otherwise it will take just the first one and here if you want to print a training passings or testing patterns and that's it that's all what you need now let's try to make an example about that let's run this cell by clicking in shift enter and the same thing for this one and the last one now everything is set let's do an example before that we need to uh we need to return the passion so i will just take this part i will give it in directory equal this here let's change this backwards slashes because sometimes it's give an example a an error so we'll just change them that's it now after having the in directory we need to create the passes so for example i will give it it is actually it is not passing there are passions so i can we can put spacings or i will put only one passing because we will print only one plot only one passing so let's just name it passions without that's s to make it complicated so passions equal now let's call the function prepare which we called here which we defined here this is the function prepare as i told you the first parameter is the in directory so we have called it the same thing in directory for the other parameters you can change them otherwise if you leave them as they are these are the the greater ones that i found in my case if you want to change them you can play with them and see what will happen but for now i will not change them because they are great for my type of data and now if we run this there is no problem you can see if we want to show one of the passing that we have so just call the function show passions i think this is the name show passions and now here we just need to give the passion as a parameter the other parts we don't need to to change them so for now it is one if i will run the cell it will take few seconds because it will do the data loader after that it will show you this passion now let me change this name this number of slices i think it is the second we can just write here for example five can see here now this is the fifth the fifth slice let's take for example 20 and that's it's let's try for example 40 and it will be the last one and that's it if you want to do more with that you can just play with this change the passings change everything you want and these are the two parts that that we need to talk about before the training because there is the preprocess and there is the second part which is the how to show one of your passing because we need this function for now and we'll use it after the training to print the results or to plot the results so that was how to do the preprocess how to show passions let's talk about now let's talk now about how to launch the training we're using one eye and paid off now before starting doing the training i will talk a little bit about the common problems that you may face because there are some problems that i found and i didn't know how to fix them because the error doesn't specify where is exactly the problem with my my code okay so i will show you only three of them which were common for me but maybe you will find others that maybe you didn't install numpy or something like this these problems are very common and you can find them but these problems with monae some sometimes you will not find any uh if you go in stock overflow or in even in monash repository in github you will not find answers about this these errors for that i will just give you these three errors that i found not i found but i faced during my project and others maybe if you will find other problems you may ask me in the comments or otherwise you may find them in google because these three problems are the only pro problems that i didn't find solutions after a while doing two or three days trying to debug the code and you will see that the error is something very stupid but you will not know does not cause the problem okay so let me just jump to the code and show you how i will do these mistakes with you and show you how you can fix them it is not it's not about fixing them because you may do everything good at the beginning and you will not face this code these programs but i just wanted to talk about them separately not in the in the in the code okay so the first thing is when you put you did when you put your uh input data to the path with the directory of your data if you do something wrong with it you will face a a problem that i will show you here how how does it look like the error and you may not know that the problem is your with your path because it will not tell you that you have a wrong directory or this directory doesn't exist you will not find this i will show you what is what type of error you will find and if you will get this type of error means that you are making the or you are putting a wrong part or wrong name of your folders or passings or something like this so here i am sure that this part is true but you can do a mistake with your path or some of the time you can you will not do a mistake with the path but i will show you where you can make or when you can do a mistake because it happened to me and it happened to a lot of people you will get wrong name of folders for example these ones because i told you when i shown you defaults i told you that if you want to use the same code you need just to name your folders as mine otherwise if you want to change them in your case then you need to change them even here because you will not get an error telling you that the problem is with the names of the folder but it will not work okay of course because the part is wrong so this first thing maybe you will forget an s here you may just write train volume you forget the s so in that case it will not work but it will not tell you that you are forgetting the s or you are you have the wrong part the second thing maybe you have nifty data not compressed which means you don't need this.gz and you are putting it here for that case the code will search for nifty compressed files and it will not find this nibs nifty compressed or zipped files in that case it will give you an error but it will not tell you that we didn't find this for this file or we didn't find a complex photo it will not tell you that so let me just leave it like this and i will run the code and i will show you how does the error looks like so now let's just run this cell the same thing this cell because i will try to show an image so that you can see because if we run only this you may not find the error because you will find the error when you call this function which is this prepare function so when you call it it will do the operations and it will find the error so to call it you can call it you are doing the training so you may face the problem during training but for us we didn't start the training yet so i will show you how you can face the error only when you are trying to plot one off or to show one of your passions so i run these two cells now let's go to the first problem which is this one as i studio everything is good here the directory is correct everything is correct only this name of passions which are everything does nii it should be that gz because for me all the passings are zipped but i deleted that so that you will find we see how how does the error looks like now let me run this cell let's wait few seconds so this is the error that you will find and it is saying that there is no object or the this because in reality what does it mean it takes this data loader which is the output of this function and take the first passion from that data loader and show it but it is saying that this data data loader or this view passion is not it's not talking about the opacity something called this check passing which is a output which is the data loader it is saying that there is there is nothing in this list it is like an empty list you cannot like doing the index zero index one it is not subscriptable so in that case you will see that your data loader is empty but there is nothing saying that the problem is before the data loader it is not saying that the path is wrong or there is no file name that's an i without the easy it is not saying anything so if you face this this problem you will not understand why your data loader is empty you may understand that your data loader is empty but why why it is empty because you forget this gz that's it maybe you can put that g and you forget z so this part doesn't exist so everything related with the part will not tell you that you have you are having a wrong path so in that case you need to check your parts check your files etc etc so that was the first error that you may face you may face this error saying that your data loader is empty in this case you need to verify before the data loader which are the path here maybe it can be these keywords but for the keywords i found it give you then it give you the specific error it will tell you key errors and it will tell you that the problem is with the key this is a good work but if you have problem with paths it will not tell you so be careful with that now let's go to the next next error which is when you put a wrong keyword in the dictionary so we are using here the same keyword vol for volumes sec for segmentations imagine with me if i will put here for example i do it wrong i put two l's so vol with two else i was writing my code very fast i didn't see this error so this of course i know you are python developer so this will give you an error so it will not work but sometimes you will not see it because i i remember one time i spent more than two two hours trying to debug the code and it was the pro the problem was here and i remember it wasn't even here because here it is very easy to see it it was inside my transforms i maybe it was here i don't remember maybe it was here so if you run the code where is the second error this one wrong so if i will run this code you will get this big error and you will get confused what is this error and i don't understand what is happening here and you can see that it is showing you the uh the arrays of your passions etc and you you for me i was like what is this what is all these writings i didn't understand what is the problem and the key and the problem is just here it will give you because for that you need to read the uh the error carefully this is not this is not my case sometimes when i see this big error i i don't i just stuck and i don't know what is happening here but actually you you maybe you didn't you don't need to read all this because you will not understand what is saying here but if you go just a little bit here you will see that uh where is it but it is saying that the drone is with key error and you come here to tell you that there is a missing key which is key was missing which is this v volume with two l's so in that case you see that's ah there is something wrong and because if you see the last error here because if you don't read that you go to the last error you will find that this is runtime apply and transform and you see what is the problem maybe i am i and it doesn't tell you even here what which transform is wrong so you may go to to all the transformers trying to change the values that's what i that's what i tried to do before i change these values of this big dimensions or maybe spatial size etc and the problem is little bit stupid because just you are putting an l here wrong and when you are stressed doing your project you may not see this type of error believe me i am saying this because it happened to me so but if you read the error carefully you you don't need to read all this writing because it's not needed but you go just here and here it starts telling you where is the problem and here you can understand that there is problem with the key error then you just go here little bits and you can see that problem with this transforms and of course there is here a keyword telling you that the key error telling you that this keyword is wrong and i think they may give you even the name of the transformers where there is the problem because here it is just telling you that there is problem with the keyword but which transform is having the problem i will just see which one if it give you or not i don't remember that transformed because the problem as you can see here is always telling you that the problem is with the transform okay we understand that but which transform is having this problem i think that it give you which transform having this problem but i cannot see it um no no there is nothing talking about that keyword dictionary yeah yeah that's it and you can see we spit spend time because i know that it exists and i spent few seconds searching for it imagine me if you don't know that there is this kind of errors you will not find it so you can see here runtime error applying transform at because at the end here it is saying the same error runtime error and applying transform but it doesn't say which transform is where which transform is having a problem but if you go a little bit here you can see that the problem is with the spacing the objects transform so you now you have two uh two heads or two keywords to see your problem the first one is you have a missing key with wrong key which is this volume with 2l and the second problem is this you see you know that which transform is having problem which is spacing d and you go just a little bit here now here and it told you that spacing d is having a problem and saying second thing is volume and you see now yeah this is a problem and you delete this and the same thing if you have a problem or we have missing key or wrong key in other parts it can be in the training or in validation or in testing because the problem if you have it in testing and you because all the time when we try to uh to to say not to say but when we try to test or to show passions all the time we use the training passage for that i added here training or testing if you need to you can you need always to use or to test your validation or your testing data so that you will understand because here when you will learn to launch the training because as i told you i am using the same code of the training used by monae so in this case not the same but i made some changes but you will see that in this case they will use the there is a part of which they are calling it validation i am calling it testing i told you why so during the training you will use some of data so that you can print or you can upload some of your uh validation metrics so we will calculate the loss of your testing and the laws of your validation the same thing for both for them they are not calculating the laws for the validation but i added it so that you will get the matrix for both validation and and for the notification for testing and for the training but in that case you will not see the problem only when you will run the code so the code will be run the training part will run without any problem when it comes to the testing which is the validation when it comes to the testing part it will try to load one of the passions and it will find that there is a missing problem with the part or problem with the keys or something like this and it will stop the training tell you there is a problem and you will not understand maybe you will not even know that the problem is with the testing only a key in the testing part so you need to keep in mind that if you get some of these errors maybe this one or maybe this one this one like talking about transforms or something like this you may get only the last one here you need to check your key for keywords in your dictionaries you need to just sure to check your parts of your data now after telling you about these two that is the third one which was one of the biggest problems that i faced in my project when you see doing the uh segmentation and of course most of the time you if you because if you do the segmentation by yourself it is easy and you may not get this type of errors but if you get a public data set or someone give you the public data set with the labels so in that case you may face these problems because maybe they are for us we are doing only liver segmentation but maybe you will and you will download data that have been used for liver and tumor segmentation or liver and heart segmentation which means two not two for three classes that is the background the liver and the heart or background liver and tumor etc etc so the data have been used for that case but you want to use it only for background and level only so in that case you you need only two classes background and foreground which will be level but the data has been haven't been done for that case so you need to change it you can change it before doing any training atk snap i shown you how i have shown you how can you just modify uh your segmentation so you can do it manually otherwise you don't need to do it because if for example you have data because if you have data for liver and tumor and liver tumor segmentation so the liver the tumor will be at the same part of the liver in that case you don't need to clean it before i will show you only in the code in the training part how you can just change it there but if the problem or if the the yeah if the error is in the tray in the for example the data has been made to segment level and heart for example so in this case you need to delete the segmentation for the heart because it will cause a problem but if the the same because sometimes even for if you have data only for labor segmentation you may get maybe the man or the person who was doing the segmentation maybe he did something wrong and in some cases at the same area of the liver he puts another color or another value or something like this so two if you have more than two different uh two different values so the code will will detect them as classes so more more values or more different values you have more the code will detect them different classes and that's what happened to me and you will get the error and you will never understand that error is happening from that and i wrote a code a blog post about that i will just show you but i will show you how you can do it in the good the the to fix this problem you will you will need to do it in the training part not before that because as i told you if you have segmentations for training and for the liver and heart so in that case you need to do it before the training and you need to delete all the segmentation for the heart but if you have the same you have only one segmentation but with different values i am talking values i am talking about the labels because they are masks binary mask it should be zero and one if you have multiple classes so it should be 0 1 2 3 etc each value represents what's one class but for us we are having only two classes so we need only two values which are zero and one and in my data here i have problems and i will show you how what are these problems i will just search for the problem uh yes this one you will get this type of errors it is this error is made from by torch when you will run the code you will get you will get something like this and you will not understand what is the problem you can read this blog post to see where is the problem and i i have here an example to show you if you have labels for example for us for me i was doing tumor segmentation so i had two tumors but for my case i didn't i didn't need to do instant segmentation which is the first stream or second tumor i didn't i did i just needed to know what is the background and which are the tumors so they should have the same value and the same color and here is the problem and now i will show you how you can fix it so as i told you if you have two different parts of the body segmented you need only one so you need to delete the second one using etk snap or any software you want to delete that part otherwise if you have only one organ segmented but with different values so you need to put them at unique value so i will show you one of the passions that i have where i have this problem so one of my passions for example this one has this this problem i will just print it here to show you so you can see that this passion here has two has three different values it has zero one two and in my code i will tell him that i have only two classes the background which has value zero and the foreground which has values one so the code will find these values too so it will detect them as a third class but in my code i will tell you that i have only two classes so in that case pytorch will have that error which is this one what is it this one this error you will get it and you cannot run the code with that error so all what you need to do is just to make a condition saying that all the values which are more different that's what i was doing different to zero i will put them true because i you can use zero and one or true and false because you have binary segmentation so you don't care about that so all what i did zero uh the values which are from uh different to zero i put them into true and the values which are zero i put them into false so that's what happened if you have multiple classes so you need to talk about that and you maybe if you have multiple class everything is good but for me i have only two classes foreground background and it is detecting something as it is giving me this kind of errors so in this case you need to change it okay so that was about the errors that you may face now let's talk let's start talking about the loss function that we will use and we run the script to do the training so for the loss function that we will use we will use the dice coefficient so that's coefficient which is or we can call it dice loss because sometimes you heard about dice coefficients and dice laws and i wrote a blog post about that it is this few months ago talking about what is the difference between them and you will see that there is no difference it is the same thing but you can use it as a metric or you can use it as a loss function i use it for both but you will see that it is stupid doing that but i just used used to both because i tried to use because even more like they are using dice laws for the loss function and they are using the compute they just function called compute dice metric but that's that dice metric the way they are calculating it it may cause an errors for me and maybe it can it may cause errors for you where you when you you have a lot of empty as i can see empty slices where there is no labels so i i understand what is the difference between them and i try to write the uh not function but it is it's a small equation in one line to calculate the dice coefficient from the dice laws actually we need to calculate the dice loss then we calculate the dice coefficients then we calculate the dice laws but monae are providing us directly the dice loss equation and it is working right good so we can go back from the dice laws into the dice coffee scenes i will give you just skew uh sorry not quick quick uh explanation about that and you will know that you can do it even yourself okay but of course i will provide you the code to do it but here the first thing that you need to do is to know is the dice what is the dice coefficient because all of you may be if you have done segmentation before or even you have the objective detection you know the intersection over union uh value or matrix so dice is not that different from the intersection of our union because the intersection of reunion is the intersection between the the ground root and the predicted mask divided by the union the ground root union the predicted mask but the dice value or dice coefficient is calculating the intersection here between the between the ground root and the predicted mask divided by the sum and not the union so divided by the sum and everything you will multiply it by two so i will give you this just small explanation that i have already done in the in this blog post so i am just reading it sorry about that but you will know that these graphs are more you will you will understand with these graphs more than just talking or writing so let's suppose that we have these two uh circles the first one for example a represents the predicted mask and the b represents the ground truth that we have so this is intersection of course you know it and this is when we say intersection over the sum multiplied by 2 means that we the intersection is only this yellow part divided by the sum we don't care about if they are the same or not we sum them and here we put the intersection so what is the the mean or what is the meaning of this case when you have or when you have a good segmentation or good model means that the intersection between the predicted mask and the the prediction and the ground truth will be almost the same so you will get only one circle here because they are supposed uh one uh one over one so you have the uh the ground rules is over the the predicted mask so in this case the value between them is the same and you sorry you will get only one circle which is in yellow here which is the intersection between them because they are the same and in the sum you will get the same thing because we said they they are the same so a plus plus b is the same thing which we are saying one plus one two plus two etcetera etcetera so you will get one thing here because only one divided by one plus one which is two times a or two times b because they are the same so you will get two times one circle or the intersection if you want to say and divided by two times the same thing so you will get one so one is the maximum value that you can get on the other side if you have for example the intersection is not your model is not is very very bad so the the predicted mask is very um it is not as the as your predicted mask so when you do the intersection between them you will get nothing so it will be zero so the intersection will be zero so when the intersection is zero divided by anything it give you zero so zero is the minimum value that you can get for the dice metric and one is the maximum value that you can get so the dice we are saying dice metric and not nice laws so when we say dice matrix so plus we are more we are closer to one more our model is good and more we are closer to zero means that our model is very bad in and there is no segmentation between the or there is no intersection between the predicted mask and the ground root and going from this case we can now choose the or find the the equation of the dice laws and the dice laws what we know about dice laws is not like those what the laws in general the dice the loss in general should be closer to zero so more we are closer to zero means that the error because the loss is an error between the predicted mask or the predicted thing which can be mask class or bonding box and the input which means the error between the output and the input so more the error is is slow which means which which means is closer to zero means that your model is good or your segmentation classification detection is good now we had only this nice value and this dice value we said that when it is closer to one is good and we need to know and we know that the dice loss more it is close to zero is good so what we can do is just to calculate the dice loss is one minus dice which is dice coefficient that we calculated so if this dice is good which means is closer to one or we can say one so one minus one is equal to zero so the dice loss is zero which means you have the minimum loss that you can get which will never get it but the dice law that this dice coefficients may be the maximum will be zero point nine nine nine nine nine nine something like this and one minus zero point nine it will be zero zero very good zero zero zero zero zero one or something like this so in that case you have a good loss good training or and good model so this type of those dice loss we will use in our case in our training there is another loss that you can use which is binary cross entropy laws for for them in in monae they are calling it cross entropy dice loss and it is the same thing i will just give you when we start writing the code i will just give you how you can calculate this crossentropy because i used it and it was useful in some cases because when you are trying to segment for us we are trying segment level it is something big in the in the image so we don't really need this binary cross entropy but when you are trying to do something because i used it when i was trying to segment tumors so the tumors are small area in the image so in that case when where the tumor is small area means that you will get the number of pixels of the background thousand times or ten thousand times the number of pixels or of the foreground which is the tumors so in this case you will get you will get a problem called imbalance data this problem imbalance data is very simple from very common in the classification and we said that segmentation and classification are almost the same but we are classifying each class each pixel not on all the image so you may face this problem so you need to use that binary cross entropy that will penalize the model when the problem when the error is in the class that has minimum pixel values or minimum pixel numbers not values so i will just provide you after the code to do it to do it but we will not use it in our tutorial we'll use only dice normal dice coffee scenes and dice which is and the dice loss but you if you want in your case maybe you want to use this binary cross entropy or cross entropy dice laws you can use it using the code that i will provide to you so let me talk to you a little bit about the cross entropy the weighted cross entropy that i was talking about when i talk about the loss functions so if you have already know what is the because this is my master's thesis i just wanted to show you what is the difference so if you have the cross entropy laws that you have seen before or used before you will see that you have this equation which is this ground truth multiple the sum of the ground roots multiplied by the log of the predicted mass which is the output everything divided by or multiplied by minus 1 divided by n so this is the normal cross entropy loss but the weighted cross entropy it's the same thing but they are adding this w here which is the weight these weights are the things that we need to calculate and i wrote the code for you to do it you will find just here in utilities so this code code will calculate the weights these weights are nothing but probabilities so if you have for example 1 million pixel of black black pixels which are the background and you have for example 100 000 of pixels of the foreground which are the levels for example level nozzle levels but level for example so in that case you will calculate the probability between them so of course you will get a probability of pixels or having having pixels of background bigger than probability of pixels having foreground which is deliver but this thing here when you want to to calculate the weighted cos entropy what you need to do is invert them use the probability of the black pixels for the error when you are having uh when you are calculating the the dice or the weighted cross the cross entropy of the foreground so here let's let's give it a step by step so let's say we are calculating the cross entropy or we can say the weighted cross entropy so if we are calculating the errors of the background so when the model is is not predicting the background so if you have background and the model is giving you that there is a there is a foreground there so which means there is a tumor a level but in your case you know that not you but the label stays telling that there is no there is no background there is no lever there so it should the output should be a background but the model is outputting a foreground which is a level so in that case you need to penalize it out in the in the back propagation so in that case because the mother will be penalized depending to the error so if the error is big so the model will be penalized a lot so it will change the weights and it will be very penalized but if the problem is in your uh if the error is small for example 0.001 so the mother will not change the with all the weights maybe a few of them or and it will not it will not do a big change because it knows that your model is accurate and it doesn't need more uh changes but as you know if the problem if the error is 0.9 or something is closer to one means that your model is very bad it doesn't predicting anything so all the ways need to be changed and that's it updated what i want to say not changed so the the idea here is if you have an error in the background or for us we are saying background because we know that the pixels of the background are maximum of the pixels then the boxes then the pixels of the foreground which is the liver because most of the area of the passions doesn't have a doesn't have a liver not doesn't have liver but the liver there is a liver in specific slices but all the other ones are empty which are for background pixels so if you calculate the uh number of pixels of the background you will find it ten times not ten times you playing this hundred or thousand times than the pixels in the foreground and even for this how to calculate the pixels because you will need them to calculate the probability there is a code that i write it there for you i think utilities show person yes this one this function which is calculate pixels it you will give it the data which will be the data loader which is the output of your of the preprocess function that we created which is prepared so the output of that function will go to this function and this function will calculate the number of pixels which are the pixels of the the the which which are the pixels of the background and the foreground so this function will output an array or a list of two values the first one is the number of pixels of the background and second one is for the foreground which are zeros and ones okay so the values that will be returned from this function you can use them here in the inputs of this so this val you one which will take the number of pixels of the background and this value too will take the number of pixels of the foreground which are the level in our case in your case you can you have something else or the same thing you want to segment but the background is the first one the further the foreground is the second one okay so just to make it easy because you can inverse them but you need to know that you inverted them so the output of your uh of this function which is the return of this function will be returned so you need to take care about that but you need to if you want to something clean you need to write them in the same order so your first class which is the class with the index zero needs to be one two to be here the second one is with the index one two three etc if you have only two so zero and one so this function as i told you it will return the probabilities but it will be inversed so of course we have the number of pixels for the foreground for the background are bigger than the background and then the foreground so what you will do you will use the probability of the background for the error in the foreground so for example let's say that the probability of the background is 0.9 and the probability of the foreground which is delivered is 0.1 because we need the sum of them equal to 1. so this one the probability of the background is 0.9 the the error of the foreground is 0.1 so what will happen when you are calculating your error here which is the weighted cross entropy when you are calculating the error of the background you will multiply the error by 0.1 means that your error will not be bigger so it will be like almost not almost the same but it will not be bigger a lot than it is so in the back propagation when the model trying to update the weight will not change or change them a lot because the problem is in the background and you will not get very big problems in the background because we have a lot of pixels in the background so it will it will be well classified for that you don't want to update the weights when the problem is in the background not not update them but not change them a lot but when the problem is in the foreground you will multiply your loss by this weight which will be the probability of the background which will be 0.9 for example so if we have 0.9 multiplied by something smaller so what will happen 0.9 multiplied by something here the with the error here or the loss value will go higher so when the value of the error will go higher what will happen the weights or yes the weight will be updated more than that because they see that even doing some updates but the loss is always bigger so it needs to update it and to make it more smaller so this is the road of the weighted cross entropy it will penalize the model which means we are when we make the value bigger means that the mother will be penalized in the error in the foreground otherwise if the problem is in the background it doesn't need to change a lot of the weights or and it doesn't need to update the weight so this is what i understand about that if you only if you want to read more about it you can read but that's what i understand about using this weighted cross entropy when you have imbalanced data when you have a class having 10 uh not 10 but 100 or 1000 times data than the other so you need to do this otherwise for for the liver segmentation i used only the normal loss dice loss i didn't use this dice cross entropy but if you want to use it you can just call it as we are calling this here you can just call it dice cross dice cross entropy loss and you give it the all the air not the errors but you give it all all the values here and it will do everything for you and here there is a parameter or an argument would call the weights cross entropy weights so this quantum weight will take the weight that as i i was talking about which will be calculated using this function calculate weights so the return of this function will be the input of this argument which is crossentropy weight so you just give us calculate weights which is the function that we have created and here in the argument of the weight of this calculate weights we need to give the values of the pixels which are the number of pixels of the foreground and number of pixels of the background and you can see here for example these values are from my tumor segmentation projects so you can see that there is a difference between them so you need to use this crossentropy uh weighted entropy uh loss okay so this is the idea if you want to use this you have just to change these values by calculating the weights from using this function not the first you need to calculate the pixels it will return the number of pixels of the background and foreground then use these values here to calculate the weights and the return of this weight will be calculated here in this will be used here in this weights chrosotrophy weights which is this one so that was everything that i can say about cross entropy weighted cross entropy loss now let's start running this script to do the training now let's talk about the training script as you can see here there is everything you need to launch your training but i will go a little bit talking about what are the difference that i did because as i told you i took the for loop that will do the training from one eyes so i will just which is with this one so i will just explain few things that i changed the few things that has changed are i added a function that calculates because for them they were calculating the loss for the training and the metric dies for the uh for the for the they are calling it validation i am calling it testing but for me i added calculation for the validation or for the metric of the training and the loss of the valid of the testing so i will get four uh four outputs not for output but four graphs the first one is the loss of the training second one is the metric of the training than the loss of the world of the testing and the metric of the testing so and i needed to save them all because i need to use them for uh to see to analyze our our results to see if the model is doing overfitting and everything or something something like that so and all what you need to know is these are the arguments that you need to put to lunch to launch your training the first the first one is the model which will be unit for us the second thing is the in the data in which is the directory where you have your data and yes you have your data and the second thing is the laws where you have which which loss function you want to use then optimizer and the max epochs that you want to you to do for us maybe we launch for 300 or 400 epochs then the model directory where you want to save your model trained model then here there is this test interval for them they are calling it validation because they are everything they are calling its validation i am calling it testings for that i just called it test by interval what does it mean this test interval will will uh control in what you know on in which epoch we want to save the new weights or the new training weights what does it mean for example let's just write here at the end let's just write for example as epoch 1 we will get a a loss value for example equal 0.9 okay and we will save this model or this checkpoint which are the weights then let's do let's go to the next epoch which is epoch 2 okay so in the epoch 2 we will get a loss equal to 0.8 for example so in this case the loss is is smaller than the epoch one for that mean so that means that the weights or the checkpoints in this epoch are better than these so we need to save the new epochs or the new model with the new ways which is in epoch 2. so we'll give the order that save i need to add a comment so save model in ebook too something like this okay then we will go to the next epoch for example let's go to the epoch tree and in this epoch we will get something like like for example let's say loss equals 0.85 so 0.85 is bigger than zero point so in this case we can understand that the model or the checkpoint in this part or in this epoch are better than these so we don't i will so we don't need to save these weights because we have already better than them so we'll skip the saving in this part so what we will do like don't don't save the model in epoch tree so we go to the next epoch etc etc so this is that's what's always due in the in the in the training but if you are using tensorflow for example this will be done automatically if you just clone the repositories but while doing uh the training using pytorch you can see that we are writing all the for loop by ourself so we are doing everything we are calculating the we give we need to give the order to calculate the to to calculate for example the first output to pass by the model then we call the laws to calculate the laws then we call the optimizer etc etc so we as you can see we are doing everything manually so in this case we need to do even these conditions manually and now what they are doing they are calculating this metric which can be loss or even metric which can be dice for example the dice value so something like this and this is what they are using actually dice and i use the same thing so this dice they calculate the dice so more they have maximum value of dice more than and in that time they save the the new checkpoints but they don't calculate this dice value for the training that's why they are calling it validation indus in the training after each calculator in each epoch they calculate the new or the the dice values of the testing data which they are calling it validation data so when they have a maximum value or bigger value of the dice from epoch to epoch and they calculate it for for the validation data or testing data in that case they use this thing that nothing but they do this this savings so if this for example i will go here like validation or for for me testing data okay so let's say that the first the first dice equal to for example zero point one for example and zero point one is is bad because we need it higher we need closer to one so the dice is 0.1 that's the ebook for example a book one okay now let's go to the epoch 2. so in the epoch 2 if we calculate this dice it will be for example 0.2 so the model in this epoch is better than the first one because here we have the epoch ctrl c control v and here we have epoch2 but what they are doing because if you calculate in each epoch i am doing it but it will slow your training a little bit because imagine with me in each epoch you calculate the dice of all your validation data so you do the training find the new model and pass all your testing data by the model and calculate this dice value and going from that value you will save that model in that specific epoch or not so to give the order if you want to calculate this dice or to do this verification in each ebook or in each two epochs or on each three ebooks or something like this this will be controlled by this what is it the training so that will be calculated by this test interval they are calling it validation interval for them they are using this value equal to so in each two epochs they calculate the new dice for all the validation data for them testing data for us and when they get higher value they save that checkpoint for me i used one because i prefer to calculate in each epoch but for you if you don't use that value if you want to fast little bit your training so you can put it two or three or depending on your cases so this value one is by default but when we will call the script or the training function here we can specify it here for me i am not putting it but if you want to give it you can just write test interval something like this and give it two or three or anything you want which will change that value by default and for me i want to leave it one and that was all the parameters that you need for this function and as i told you there is the first thing is the model for us we are using a mono uh sorry a unit but we will import it from one eye as you can see it is here monae monae.networks.net imports units there are other networks but we are using unit so there are these three uh important things that i will i will talk about the first thing is dimensions we said that we are doing volume segmentation which is 3d segmentation or 3d units for that we need to make dimensions equal 3 for 3d and the input channel for us it is one because we have masks with only one channel i am talking about slice each slice has only one channel and that channel have zeros and ones but the output channels we need them to be two each because the number of the output channels is the same number of the classes that you have so the first channel will represent the probabilities or the pixel probabilities for the background the second channel will represent the pixel probabilities for the foreground okay and when you combine them together you get the new uh you get the final output so these are the important things that we need to talk about these are the chain channels which which controls how many kernels or how many filters you want to put in the um how they call it in the convolution blocks and these are the strides and this will create the residual new units and this one to normalize the batch but we don't need to talk to you know everything about that but these three things that are important the first thing is the dimensions which is three for 3d the input channel is one because we have each slice has only one dimension the output is two one for the background segment for the foreground because we have only two classes if you have more it will be more etc etc but others here we have just to call the loss function here is the dice cross entropy if you want to use it i talked about it before and this loss function that we will use we are using a sigmoid here and then the optimizer we are using the adam optimizer with a learning rate 0. 10 minus 10 minus 5. so that's what you can use for you if you want to change it you can just change the values here you can change multiple to find multiple times or you can just make that function that's very which give you an interval of learning rate and it will be changed in each epoch on age 10 epochs or something like this but for me i am putting a constant number for you if you want to change it you can change it it depends to you but that's all what i will talk about here after all what you need to do is just run this this script and as i told you that in this type of training it will take time it may take two two days that's what this is strange but it may take two days depending to your machine and how many data you have and everything and that is other things that i have talked about in the preprocess part i told you that there is this parameter which is the cache it can be false or true and i told you if we put it through means that we will use disk function which will load the data in the memory of the gpu otherwise we will not do it so if you have a good memory you can just hear what is the data the this is this function prepare we call the data so we can just here make cache which is this argument and we put it as true so if we put it through it will load all the data in the memory of the gpu otherwise it will be false so if you put it through it will be the training will be faster faster than without the cache but sometimes if you don't have memory you cannot do it so i will just delete this because if you we do it i will show you that it will take time even before to load the data then it will start training i will just launch it like this so that you see that the training will start after that you can use the cache if you want so if i will run this script you just wait a little bit and this is because here i am putting 20 for 20 epochs so i will do 20 epochs and it will calculate the dice train dice and it will calculate the loss for each uh image as you can see here and it of course is starting by a higher value of loss but it will change it will be changed so that's all what you need to do to do the training so and but you need to wait as i told you with gpu for me i have gpu gtx 10 1080 or 1070 i remember but as you can see here you can define define the gpu that you want to use if you have multiple gpus so you can just change the index here otherwise you can leave it like this if you have only one so it will be with the index 0. so that's what that's all what you need to know about the training and nothing else you need just to wait for the training until it will be done and of course here you need to specify the model dear where you want to save your model or your checkpoints plus your plus all the things which are here the loss values or the lows yes the loss values for each epoch and the metric values because we are doing here a save train loss and there is a save a book so this will will save everything that we need so it will save the new in each epoch it will save the new values so the first epoch for example you will get 0.9 the second epoch it will be 0.3 so it will create a list containing all the values for each epoch and it will save them as a numpy list that we can load after and plot it to see what was happening in during the training so that's what i can talk about you need to wait for this training if you want to use google collab it it may work but if you are having a large number of data it may take more than 24 hours and you know that that google collab doesn't sell for i'm talking about the free one it doesn't allow you to to do a training more than 24 hours depending even to your internet connection it will not if it will not cut so you know you need to be careful about doing the 3d convolutions here using 3d unit it will take time you need to know that otherwise there is nothing else to talk about and we will talk after the training i will show you the results that you will get and you will see that you we will not get a perfect result because in medical imaging you will never get something like perfect or like in the other images or other tasks but you can just see the first results after that because for me what i was doing is i made tons of trainings i i launched the first one then i i tried to change something of the data i chose to try to add more data otherwise uh try to change the learning rate there are tons of things that you can change i cannot talk about them all here but because i am telling you only the basic thing and the basic code that you will find in mulai i'm just transforming some things here to make it easy but that's it if you want to make a better better better training you need to do these changes learning great or the the best thing that you can do is adding more data but adding more data means that the training will be more slow but of course at the end it will be better than less data so we will wait until the training will stop and try to analyze our results so now after doing the training let me show you some of the results or the results that i found for my project so i when i i launched the training i put 600 epochs but i stopped it as the epoch 100 because i know if i will leave it into 600 epochs it will take time and the second thing that uh why i did stop the training at the apoc 100 because i found that here at i don't know at the apoc 100 before 100 it was in 80 70 something like this we get this flood here which means that if we add more epochs of course the training loss it will go down and it will converge more than that but for the validation it will always stay here for that i didn't want to leave it to leave the training going more than this because we may get a overfitting or we may get a model which is not very accurate with the validation of with the testing data and for that i will i already will show you one of the passing that i passed it by the model and i will show you the results and you will understand why i should stop the training here okay so to do it i have this uh japanese notebook file that i will share it with you so that you can test your uh your model after the training so the things that you need to to change are only these two parts the path to the data and the path to where you save the model plus these files okay if you remember when we did the training we need in each one in each epoch because i i fixed the i put the number or the value interval test interval into one which means in each epoch it will calculate the through the training not the training but you can get the testing metric or the testing loss the same thing but it will calculate one of them but for for me i did it to to calculate the the test metric so when i get a higher value of this metric in that case i should save the weights okay so i should save the weights which which is the model but in each epoch i should uh save the loss trade the training of the loss uh sorry the loss of the training and the metric of the training the loss of the testing and the metric of the testing in each epoch so that i can plot it like this and you can see this evolution of the laws for the training and these are for validation after doing this now let's let's load one passing or we can load all of them but i will show you only one that i prefer to use not prefer but i will show you how does this look and you can test your test your final model with multiple passions otherwise you may not get the best or the yes the best or the great the perfect model at the beginning so you can do more changes and launch another training okay so for my 100 ebook it took me around five or six hours to be completed okay so you should put this in mind but but i was i was using the cache so the so the data was loaded in the gpu memory for that it took six hours if i didn't do that it will take more than that okay so and but it took six hours for only 100 100 apr i stopped it if i left it into 600 epochs it will take two days maybe okay so for you if you will launch your training in at 6 00 60 600 ebooks for example and if as the epoch 100 or before that you see that your model is doing well and you don't need more training so you can stop it okay you don't need always to complete the whole 600 epochs it is a choice and they are it is a huge number of ebooks so if you see that your model is doing great before that you can stop it okay now when you do when you want to load one of the passions of course you should apply the same transforms that you applied during the training and the testing of course so these are the different transforms that we applied for the training and the same thing i will apply here then we have a test loader because we want to load the testing files so we load them and of course you need to load your model which is the unit and after loading the model this part here will load the weights and put them in the model because you need to create the model first then put the weights or two yes to fill the model with your weights or with checkpoints that you have you have saved during the training so this one will create an empty model this one will put the weights into that model now you have the model ready ready model with the weight that you can use directly for your testing part so as i told you i took only one patient to show you so you can do all the changes to to bloat or yes to show multiple passions but you should you need to be careful with that because the data loader is not like a list you cannot just put data loader zero data loader one extract so you cannot do this you can do for example a for loop so you can do for example i will just write here for passions for example in test loader this one will will work and you can use this way for example if you want to to play to load the first one so you can just add an index here for example i and here you can put enumerate in this data loader and you can say if i equal zero then call this function that will plot otherwise don't do that if this is one way the other way that i use as well which is here when what is it here when you select here i am talking about the test but it should be test here for example so what i am doing here is just selecting a few passions from your data set so if you want to show for example the first one you can do for example zero to line for example if you want to show a second one you can just put from one two nine then from three to nine two twenty etcetera etcetera for example you can put here nine or anything you want so that's what does it mean you will get a new list of passions and always the first person that you will get here he is the passions that you want to show so this is one way that i found not found but you can use this way other thing that because you cannot do like like a list like here i cannot i cannot put here for example this order zero it will not work and it will give you an error about that for that you need to find another way which is for example as i told you before putting the data into the data loader select which passes you want to do the pre before the pre process you need to select which passion so you can do that way or the for loop way that i showed you it up to you but this is the way how you can do it and this script will run on it which will pass each uh it will pass all this like all the passions into the model because we said it is a 3d model 3d unit or cd segmentation so it will pass the whole passion which is here 3d the d volumes which is test volume it will pass it by all the passing for all the passing for with the 64 slices it will pass it by the model here in the model and it will calculate the the output or predicted mask and here this for loop is just to print all the slices of that specific passion so here you can see i will show we start from the wrong segmentation so you can see here for example for these four uh one two three four five six seven we can say seven until eight so this these eight four slices are not well segmented okay so you can see that for these uh the segmentation is great we i i cannot say perfect but it is great but for the the first ones it is not that good so these are the things that you need to keep your in mind in medical imaging you will never get something uh perfect because you can see that we as human and sometimes we cannot differentiate you can see this and this part is it not equal to this one so you can say that this is a level okay but the model fortunately it is not segmenting it as a level but you can see that it is not easy to know which part contain which is the the exact part of the human body so you can see that this is not bad it is segmenting etc but you need to keep in mind because you need to do a lot of changes to get more accurate so you can maybe test these values maybe you can change the contrast for now you can put it like this you can do another training with another values so the contrast will be changed so in that case maybe some some patterns will be better or will look better than these values for example so you can try to changing these or you can the best thing that you can do is try to add more data so you can try to add more data you can change the learning rate there are a lot of things that you can do but and of course you can do more uh more processing or you can add the data augmentation that i talked i told you about i didn't want to add it but you can add this augmentation and sometimes it works very well so why i don't want to try everything because as you see even only 100 epoch took me 500 500 5 hours if in my pc so if i will try multiple multiple trainings and multiple parameters it will take me forever to find the best model so but here in this tutorial on this course i am just showing you how you can write the code how you can use the different functions in monae but it up to you to do different changes to do multiple combinations to get the best results but you need to keep in mind in medical imaging you will never get something perfect but you can i am sure that if you do more changes more data etcetera you will get better than these here for this part it is good but for example here it is missing some segmentations okay and you can test it for other passions you will find that sometimes it is good perfect but others is not that's good so that was how to do the training testing how you can as you can see how you can see your segmentations in the in the final part what i will do i will show you just how you can clone the github repository and use it directly so maybe you don't need to write the code by yourself so you can just clone the github repository and launch the training from it so i will show you just in a few few minutes how you can do it so that you will get an idea about that now after that we have done everything step by step now i am telling because i told you that i will give you the code and you will find everything here in this repository so i tried to write some sentences here to explain some of the parts but i didn't have time to write everything but with time i will try to add more and more explanations and of course i am writing some blog posts about all what we were doing we were doing in this course so if you prefer to read instead of watching videos you will find them but i will publish them soon okay because i didn't finish all the blog posts for now so when i will finish all of them i will post them in my website and after understanding what we were saying now what you need to do is just to for example if you want to use the same code that i am using so you can just clone this repository using this part here so just go here and click in this button to copy this line and go to your terminal and cd or change directory into your workspace otherwise if you are using visual studio code so just open the folder where you want you to work and paste it in the terminal here not there and this terminal and paste your this git git clone this repository so this line will clone the repository which means it will download all the files that you have in this repository in this work space i will not do this because i have already this this repository cloned as you can see here so you will get this folder which contains all the files that you find here in this github repository okay so the first thing that you need to do is to install the requirements so there is the first thing here i am putting that and of course when you do this when you you can unders this repository you need to cd to that repository so that you will your new workspace will be this repository so that you can oh you can directly use the code inside that repository so just copy this cd like this and copy and paste it in your in your here in your terminal and it will go to the next repository as you can see here i have already that repository okay so that if i will just make cd and now if i will paste this cd then lever segmentation using mona and python and then it will go it doesn't go because maybe there is a problem with that because i am putting it here wrong so just correct this spider something like this okay so all what you need to do is just to cd to this directory after doing this you can start installing what you uh what we what we used and of course as i told you about the virtual environment if you need or if you prefer to install to create virtual environment or conda environment you can do it before installing any packages otherwise if you prefer to use your system you can do it directly but i don't recommend you to do that so just copy this to install monae after that all the the other requirements are will be found here in this file requirement.txt so you need to install must not leave numpy blob but when you install globe you need to do group 2 because if you do pip install globe it will not be installed because it is not recognizable then you need to install the control nifty then this channel but before doing it you need to you need to type this keyword because if you do install chat it will not be installed and the same thing for me bubble but don't worry about this you just need to copy this part which is this one pip install dash r then requirement.txt and it will install everything then after installing all the requirements that you need all what you have to do is start coding but as i told you there are some stuff which you will find here the first thing that you need to do is to convert your nifty files into dcoms so that you can create groups using this function that you can call with another main script which will call this function from this file so you can just do imports create or from from what is the name from preprocess that's pi imports create groups and you can just use it to create groups using this function the same thing to do the to convert from the dcom to nifty and to find the empty and finally for the preparation after doing all this stuff and creating the folders with the names that you need which which what i mean with the folder for the volume training volumes training segmentations testing volumes and testing segmentations after that you can just use this function which is prepared to do the preprocess and that's it if you want to do the if you want to show your passions you can find the function show in utilities here i will go here there is the function i think it is at the end yes yes this function will be used to do the or to show one of your passions the same thing all the functions that we were using will be found either in this in this file which is preprocessed the spy for the preprocessing and all in the utilities that you will find some functions to calculate the dice metric calculate the weights for the weighted cross entropy and this function train that you need to do and finally there is this function which calculate the pixels i talk about this as well for when you if you want to use the binary the weighted cross entropy you will need this function and that's it after knowing everything you just need to call this function which is train to to launch your training so for that there is this file which is trained as pi which will call exactly it will call this prepare for to for the play process and it will call the train from utilities import train to do the to do the training using that function train so the first thing is to create the model and launch the training so this this script is like a main script to launch the training but if you want to do the preprocess because if you want to create the groups etc you need to create another script called main or something like that to do all the preparation outside your training etc so after doing the training when you need to test your model you will find this jupyter notebook test that's ip notebook and b so if you open it it will take time some few seconds and you will find everything we explained in the previous minutes you will find them here and just launch this code but by change changing here the path to the data and the part to the result or the checkpoint and everything will work and that's it that's all what you need to know about this project but if you have any questions any problems please don't hesitate to send me emails leave a comment or contact me by er in social media on my website pycad dot co i have no problem answering you answering you but maybe sometimes it will i will take few days or day or one day or two days to answer you if i have projects working on so please don't hesitate to send messages or emails and i hope to s to answer you as soon as possible so i see you in the next courses if you have enjoyed this course please don't forget to thumbs up or leave a comment and i see you in the next videos bye
