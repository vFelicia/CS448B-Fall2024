With timestamps:

00:00 - tensorflow can do some amazing things
00:02 - when it comes to computer vision in this
00:04 - course machine learning engineer noor
00:07 - islam muktari will teach you how to
00:09 - create multiple computer vision projects
00:12 - using tensorflow 2. hello and welcome to
00:15 - my course introduction to tensorflow for
00:18 - computer vision
00:19 - so just a quick introduction about
00:21 - myself
00:22 - my name is noor islam
00:25 - i work as a machine learning engineer
00:28 - and i'll be your instructor for this
00:29 - course
00:30 - if you have any questions regarding the
00:33 - course material and content or anything
00:35 - related to machine learning and computer
00:37 - vision feel free to connect with me on
00:40 - linkedin and twitter
00:42 - and if you're starting a career in
00:44 - machine learning and computer vision
00:46 - then please check out my free ml job
00:49 - ready checklist that i have put together
00:51 - which contains some information that
00:53 - might help you to set a roadmap for
00:56 - things you should learn and maybe things
00:58 - that the machine learning and computer
01:00 - vision industries might expect from you
01:03 - so all of these information regarding my
01:07 - social media accounts and also this free
01:09 - checklist can be found in the link below
01:12 - it's one link but it's gonna show you
01:15 - all of the necessary information once
01:17 - you click it
01:20 - let's take a look at the course outline
01:23 - [Music]
01:24 - so
01:25 - we're going to start the course by doing
01:27 - some software setup
01:29 - then i'm going to show you how to do
01:32 - image classification using mnist dataset
01:35 - which is basically the equivalent of the
01:37 - hello world
01:39 - examples in the machine learning field
01:42 - then we're going to look at the image
01:43 - classification using german traffic
01:46 - science which is a real world data set
01:49 - that reflects more challenges compared
01:52 - to the mnist dataset
01:55 - so for the software setup we're going to
01:57 - start by
01:58 - downloading and installing visual studio
02:01 - code
02:02 - i'm also going to show you how to get
02:04 - miniconda i'm going to tell you why we
02:06 - need it and how to install it
02:08 - we're gonna be
02:10 - using minicanda with vs code so i'm
02:12 - gonna show you how to make those two
02:14 - work together
02:16 - then we're gonna install tensorflow 2
02:18 - cpu and gpu versions we're also gonna be
02:22 - installing different python packages
02:24 - along the way
02:27 - for the second part
02:29 - which is the amnest example we're gonna
02:32 - basically explore the amnest data set
02:35 - i'm going to show you how to build a
02:36 - function that
02:38 - randomly looks into the data set and it
02:40 - gives you some ideas about how this
02:42 - dataset is constructed
02:45 - i'm also going to show you how to use
02:46 - tensorflow layers how to import them and
02:49 - how to use them to build the neural
02:50 - network we're going to be building the
02:52 - same neural network architecture in
02:54 - three different ways which are the ways
02:58 - supported by tensorflow
03:00 - so the first one is called the
03:02 - sequential way by using the sequential
03:04 - class the second
03:06 - approach is called the functional way
03:09 - which is basically your model is wrapped
03:11 - inside a function
03:13 - and the third approach is the model
03:15 - class way which is by inheriting from
03:19 - the model class we then
03:22 - gonna do the compilation of the model
03:25 - and we're gonna fit the amnes data set
03:27 - into our model we're gonna finish this
03:30 - part of the course by restructuring our
03:33 - code for better readability which is
03:35 - something you're going to find yourself
03:37 - often doing when working on machine
03:39 - learning projects in the industry
03:43 - and for the last part of the course
03:45 - we're going to be working with the
03:47 - german traffic signs data set which is a
03:50 - real world data set that reflects the
03:53 - real challenges when working on machine
03:56 - learning projects
03:57 - compared to prepared data sets like the
04:00 - amnest dataset
04:02 - so for this we're going to start by
04:03 - downloading and exploring the data set
04:06 - we're going to prepare the training
04:08 - validation and the test sets because
04:10 - they're not already prepared
04:12 - we're going to build our neural network
04:15 - we're going to create some data
04:16 - generators which is a different approach
04:19 - than the one we
04:21 - will be using for the first example
04:24 - which is the amnesty example we're going
04:26 - to compile the model and fit the data
04:29 - i'm also going to show you how to add
04:30 - some callbacks and why they could be
04:32 - very useful
04:34 - and i'm going to show you how to
04:35 - evaluate your model using the generators
04:38 - you created before
04:41 - then i'm gonna show you some potential
04:44 - improvements that you can do to get even
04:46 - better results
04:48 - and we're gonna finish this uh
04:51 - part of the course and basically the
04:52 - whole course by
04:54 - a an example of how you would use your
04:57 - model to make prediction on single
04:59 - images so basically how to build a
05:02 - standalone example that can make or that
05:04 - can use your model in order to make uh
05:08 - separate predictions
05:11 - so
05:12 - who is this course for
05:14 - basically this course is for anyone
05:16 - who's interested in learning about
05:17 - tensorflow specifically for computer
05:20 - vision applications
05:22 - ideally you should have good knowledge
05:24 - about python
05:26 - like
05:27 - classes and functions in python and also
05:30 - basic concepts in deep learning such as
05:32 - convolutional layers
05:35 - so why would you learn tensorflow anyway
05:38 - well there are several reasons but these
05:41 - are three of
05:43 - the main reasons in my opinion
05:46 - so tensorflow is the leading framework
05:48 - in deep learning followed by pytorch
05:52 - and you can build powerful deep learning
05:54 - solutions with it for your own use and
05:58 - also for your company the company you're
06:00 - working for
06:02 - and there are lots of companies working
06:03 - on deep learning projects and they are
06:06 - using tensorflow so the job market is
06:09 - very large and it's only growing so
06:12 - these are the main reasons of why you
06:15 - would want to learn tensorflow but at
06:18 - the end of the day maybe you just want
06:19 - to learn it for fun
06:21 - so that depends on you
06:25 - so just a quick note before we continue
06:28 - with the course material we will be
06:30 - using an ide and not notebooks
06:33 - we will be specifically using visual
06:35 - studio code
06:37 - and this is for several reasons in
06:39 - industry projects you usually use ides
06:43 - and not notebooks
06:45 - with ides you easily scale your machine
06:48 - learning code so you can add a lot of
06:51 - scripts you can test them separately you
06:53 - can import them in different
06:55 - and other scripts
06:57 - and also
06:58 - the i am for the opinion that says that
07:00 - ides are for building your projects and
07:03 - notebooks are for presenting your work
07:06 - so for me and i think many other machine
07:09 - learning practitioners agree with me on
07:12 - this is that we usually use notebooks
07:15 - for presenting the work
07:17 - but when we're building large
07:19 - machine learning projects we usually go
07:22 - with ides
07:25 - so the first thing we're going to start
07:26 - doing is downloading visual studio code
07:29 - is an ide that we will be using
07:31 - throughout the course to write the code
07:34 - and also to
07:35 - run that code so if you go to
07:38 - code.visualstudio.com you're going to
07:40 - get this page here and as you can see it
07:43 - automatically detected my system so i
07:46 - can just click here and download visual
07:48 - studio code for my windows machine if
07:51 - you have a different machine
07:53 - it should detect it if not then you can
07:55 - just click on this button here and
07:58 - choose the right software for your
08:00 - machine so if you click this
08:03 - you're just going to get this download
08:05 - here and you can just save it to your
08:07 - machine and run this executable just
08:09 - like you would run
08:11 - on
08:12 - any other installation process there's
08:15 - nothing unique or special here so i'm
08:17 - not going to go through it here
08:20 - now after we install it
08:22 - if you go to
08:24 - your run
08:25 - menu here and you just type
08:28 - visual
08:31 - studio
08:32 - code
08:33 - you're gonna get this
08:35 - uh
08:36 - the icon here where you can run visual
08:39 - studio code usually i like to
08:41 - pin it to my start so as you can see
08:43 - it's already pinned here which means i
08:45 - can just access it from here you can
08:48 - choose to do that as well if you prefer
08:50 - that
08:51 - so
08:52 - let's run visual studio code
08:57 - and the first time you run it you're
08:59 - gonna get
09:01 - this new window here where you have
09:04 - the starting menu so you can
09:07 - create new file
09:08 - open a file or
09:10 - or do all of these
09:12 - other things and also for me as you can
09:15 - see i have this part here that says
09:17 - recent which are my recent projects
09:20 - if it's the first time you're using
09:21 - visual studio code you will not have
09:23 - this
09:24 - so
09:26 - the first thing i'm gonna do is just to
09:28 - open a folder so i'm gonna click on open
09:30 - a folder here you can choose any place
09:33 - on your machine to
09:35 - to open that folder
09:38 - so for me i have chosen this place on my
09:42 - machine so
09:43 - i have a disk called d code for courses
09:46 - and introduction to tensorflow 2.
09:49 - i created this new folder and now i'm
09:50 - just gonna select it so select folder
09:54 - and now it's gonna open this uh new
09:57 - window
09:59 - okay here it says uh if i trust the
10:02 - authors of this files yes no problem
10:05 - these are my files
10:07 - so here
10:08 - you get this new window where you have
10:11 - this empty folder on the left
10:15 - and you can add new files you can also
10:18 - add new folders inside of this folder
10:22 - and here we will get
10:23 - uh
10:24 - the place where we can write code and
10:27 - also we can get the terminal at the
10:29 - bottom here
10:30 - so for now this is it for installing and
10:34 - setting up
10:35 - a visual studio code what we're going to
10:37 - do
10:38 - now is look at the other software that
10:41 - we will use throughout the course and
10:43 - also later we're going to start adding
10:45 - files here so that we can start writing
10:47 - some code
10:49 - so the second software we need to
10:52 - install
10:53 - is called miniconda
10:55 - so
10:56 - if you look online you're gonna find
10:59 - two types of products for condo there's
11:01 - mini conda and there's anaconda anaconda
11:05 - is actually a gui that allows you to do
11:08 - almost everything that mini conda allows
11:11 - you to do the only difference is that
11:13 - uniconda does not have a gui
11:15 - we will just use it in a
11:18 - command line prompt so if you type
11:20 - miniconda in your google search bar
11:23 - you're gonna get
11:25 - the first result here so if just open
11:28 - this
11:30 - here you get all of these links to
11:33 - install miniconda on your machine so if
11:36 - you are on windows you choose this
11:38 - otherwise you choose the
11:40 - other types here
11:42 - and again this there's nothing special
11:44 - here you can just click the link save it
11:47 - save the file to your
11:49 - to your local machine and then run the
11:51 - installation process and also there is
11:54 - nothing special
11:55 - when installing minicanda so i'm not
11:58 - going to go through it here
12:01 - now
12:02 - when you install miniconda
12:04 - if you go to your
12:06 - run menu here and you just type
12:09 - you're going to see anaconda prompt
12:12 - and between that parentheses there is
12:14 - minicom.3 so if you open it you're going
12:17 - to see that it looks just like the
12:19 - command window
12:21 - on windows
12:23 - so they are
12:25 - basically
12:26 - or almost identical
12:29 - the
12:30 - only difference that we can notice here
12:33 - is that
12:34 - here we see this
12:36 - name
12:36 - called base between parentheses here and
12:39 - here we can see it in the default
12:42 - windows
12:43 - command line window
12:46 - now what this means is that in fact
12:49 - in the miniconda prompt prompt
12:51 - we are
12:52 - actually now inside what's called a
12:55 - virtual environment
12:56 - and this virtual environment is called
12:58 - base
12:59 - so
13:00 - i'll go a little bit into more details
13:03 - about what these virtual environments do
13:05 - and why
13:06 - would we need them
13:08 - and why don't we just install things
13:10 - straight uh on our system using just the
13:14 - windows
13:15 - command line prompt
13:17 - i'll go into details about this
13:20 - just next
13:23 - so what are these virtual environments
13:26 - well you can actually think of them as
13:28 - these separate entities inside your
13:30 - system but they do not necessarily
13:33 - affect your system
13:34 - so
13:35 - for example we can think of it in this
13:38 - way so you have your system and inside
13:40 - your system you have python say 3.8
13:44 - installed and you have some python
13:46 - packages
13:47 - and now with virtual environments what
13:50 - we can do is create
13:52 - as many environments as we want so for
13:55 - example here i can create i show you an
13:58 - example where we created three different
14:00 - virtual environments so the first one
14:03 - is called vm1
14:05 - the second one vm2 and we have vm3 so in
14:09 - the first one
14:10 - we can install python 3.7
14:13 - and for example we installed tensorflow
14:15 - 2.6
14:17 - now when you do this you're not actually
14:19 - installing uh python or the python
14:23 - packages straight onto your system
14:26 - you're actually installing them inside
14:28 - this virtual environment so this virtual
14:30 - environment
14:32 - it actually lives inside your system but
14:34 - what you install in it does not
14:36 - necessarily affect your system so here
14:40 - as you can see on your system you might
14:41 - have
14:42 - python version 3.8
14:45 - but inside your virtual environment you
14:46 - can change that and you can use python
14:49 - 3.7
14:50 - and as you can see you can create as
14:52 - many virtual environments as you like
14:55 - and the goal here or the why would you
14:59 - even want to do something like this
15:01 - is really
15:02 - when you're doing machine learning or
15:04 - data science you're going to be doing
15:06 - lots of experimentation so for example
15:09 - there might be a new tensorflow version
15:12 - that has some new functionalities and
15:14 - you want to test it
15:15 - if you have everything installed on your
15:17 - system and then you just upgrade to the
15:20 - newest version of tensorflow then you
15:23 - might
15:24 - affect your existing code so you might
15:28 - something that
15:29 - has already worked in the previous
15:31 - version of tensorflow may not work in
15:33 - the newest version
15:34 - and that could cause a lot of conflicts
15:37 - so now that now you find yourself in a
15:39 - situation where you have to go back to
15:42 - an older version which is not uh very
15:45 - good
15:46 - so when you do this you can do these
15:48 - experimentations separately and as you
15:51 - can see
15:52 - for example if i want to test pytos and
15:54 - i don't want it to be used in the same
15:56 - virtual environment as tensorflow i can
15:58 - create
15:59 - uh completely separate virtual
16:01 - environments
16:02 - install
16:03 - uh
16:04 - whatever version of python i need and
16:06 - then i install pytorch here and if i
16:09 - want to test for example an older
16:10 - version of pytorch i can create another
16:13 - virtual environment and do the same
16:15 - thing
16:16 - and you can imagine all of these
16:18 - benefits that you can have for example
16:20 - many companies are still using
16:22 - tensorflow version 1.x
16:25 - so
16:26 - if you want to do this if you want to
16:28 - install a
16:30 - previous version or older version of
16:32 - tensorflow so 1.5 1.6
16:36 - then it's better to install it in a
16:38 - virtual environment instead of doing it
16:39 - on your system
16:41 - so this is uh the goal of why we're
16:45 - trying to use virtual environments i
16:48 - really encourage you to use this kind of
16:50 - framework when you're doing your
16:52 - experimentation instead of installing
16:54 - everything on your system
16:57 - i've
16:57 - been working in the machine learning
16:59 - field for some years now and i have
17:02 - always found that it's better to use
17:03 - virtual environments rather than install
17:06 - everything on your
17:07 - directly on your system so i hope that
17:09 - now you can see the benefits of
17:12 - following this kind of paradigm
17:14 - and next let's start creating a virtual
17:17 - environment and installed necessary
17:19 - python and python packages inside of it
17:23 - so now just before we start installing
17:26 - tensorflow
17:28 - and
17:29 - creating our virtual environment let me
17:32 - just
17:32 - clear some
17:34 - some of the doubt that you might have
17:36 - here so as you can see when we installed
17:38 - miniconda we have this command prompt
17:41 - here and also i showed you that we have
17:44 - the default
17:45 - windows command line
17:47 - here and they are similar but how are we
17:50 - going to use
17:51 - our virtual virtual environments inside
17:54 - visual studio code
17:56 - so in fact if you go to visual studio
17:59 - code if you go to terminal new terminal
18:03 - here in fact we are inside our
18:07 - command line
18:08 - [Music]
18:09 - default command line window
18:11 - so what you do here is going to be
18:13 - identical to what you would do here
18:17 - and in fact let's just for example type
18:20 - python so here you see on my system
18:22 - there's python 3.6.8
18:25 - installed
18:26 - and here if i write python i get the
18:29 - same uh version here so i have
18:33 - whatever i do here i'll uh i'll be able
18:36 - to do it here and vice versa
18:39 - and
18:40 - now let me just exit this
18:43 - what we want is to actually be able to
18:46 - use
18:48 - our virtual environments and just use
18:50 - mini conda in general inside our
18:53 - terminal here on visual studio code so
18:56 - in order to do that what you can do is
18:59 - just look up where miniconda is
19:01 - installed on your machine so for me i'm
19:03 - using a tool called everything it's a
19:06 - search tool
19:07 - you don't have to install it i just
19:09 - prefer it
19:10 - than the
19:11 - default search tool on windows
19:14 - so here when i type miniconda3
19:17 - which is the software that we installed
19:21 - if i open this
19:23 - folder here
19:24 - there is another folder called scripts
19:27 - and then there is activate.bat so if i
19:30 - just take this copy it
19:32 - paste it
19:33 - and then
19:35 - run activate dot that
19:39 - now as you can see i have
19:41 - the base name here written before
19:45 - my
19:46 - before this path here
19:48 - and as you can see we have the same
19:50 - thing here so now we are in fact inside
19:53 - the virtual environment called base and
19:56 - whatever you do
19:57 - inside
19:58 - this command
20:00 - this window here is going to be
20:02 - reflected here and vice versa so now
20:05 - that we have
20:06 - we can access
20:08 - condyle commands on our
20:11 - visual studio code terminal let's try to
20:14 - see what we can do with it so here
20:17 - let me just
20:18 - clear this
20:20 - part here
20:22 - and in fact you can run so many conduct
20:24 - commands so to run the contact command
20:27 - you
20:28 - start by
20:29 - writing canda and then you finish the
20:32 - rest of the command with whatever you
20:35 - need to do so for example we can look at
20:39 - our uh virtual environments that are
20:41 - already installed
20:43 - in order to do that you can run this
20:45 - command calenda info dash dash ms and if
20:48 - you've never had a mini conda before
20:52 - you will have nothing
20:54 - when you run this command but for me as
20:56 - you can see i already have some virtual
20:59 - environments installed here so let me
21:03 - just
21:03 - clear this one here
21:05 - and next what we're going to do is
21:08 - create a new virtual environment and
21:10 - then
21:11 - we will choose the right python version
21:14 - that we want and then we're going to
21:16 - install tensorflow inside that virtual
21:18 - environment
21:20 - to create a virtual environment using
21:22 - canda the command that you should run is
21:26 - kanda
21:27 - create
21:29 - dash and
21:30 - now you can give a name to your virtual
21:32 - environment you can choose any name you
21:34 - like
21:35 - usually for me since i do many
21:37 - experimentations with tensorflow i just
21:40 - like to call it for example
21:42 - tf2
21:44 - uh or i give it the full for example
21:46 - version of tensorflow so tf 2.5 or 0.6
21:50 - or whatever
21:51 - and here let's just call it for example
21:54 - tf2
21:57 - vm
21:59 - so vm for virtual environment and then
22:02 - you can give it the parameter python and
22:04 - here you can choose whatever version of
22:06 - python you like so let's just use 3.8
22:11 - since i've been working with it for uh
22:13 - for a long time and it's uh it works
22:16 - great with tensorflow
22:18 - so here i'm just gonna run this command
22:22 - so now it's gonna ask us whether we
22:24 - accept to install these unnecessary
22:27 - packages so i'm gonna choose yes and
22:30 - click
22:32 - and this should not take that long
22:34 - because these are not large packages so
22:37 - after we have our packages installed we
22:40 - can run
22:41 - kanda
22:42 - activate tf2
22:46 - vm
22:48 - and
22:49 - of course you can see that the
22:50 - suggestion is shown here in order to
22:52 - activate your virtual environment so
22:56 - now if you remember we are inside a
22:59 - virtual environment called base so after
23:02 - i run this command now we're inside our
23:05 - new newly created virtual environment
23:07 - called tf2 vm and here whatever you
23:11 - install
23:12 - is going to be
23:14 - separate from your system so it will not
23:16 - affect it so here for example let's just
23:19 - run python and as you can see is version
23:23 - 3.8 if you remember on my system i have
23:26 - 3.6
23:28 - installed but here inside my virtual
23:30 - environment because i specified that i
23:33 - want
23:34 - python version 3.8 i have 3.8 installed
23:38 - here
23:40 - so now that we are we have created our
23:43 - virtual environment we start installing
23:45 - the necessary packages so
23:49 - now we can install for example
23:50 - tensorflow and if you go to the official
23:54 - website of tensorflow
23:56 - you can see if you just go to
23:57 - tensorflow.org install you can see
24:00 - different ways you can install uh
24:02 - tensorflow for us we're gonna use
24:04 - uh tensorflow or download it and install
24:07 - it as a python package so these are the
24:09 - commands we can run
24:12 - so here uh
24:14 - first command we can run as just for
24:16 - upgrading pip so if you don't know what
24:20 - bib is so bip is just a package manager
24:23 - that helps us install python packages so
24:26 - let me paste it here
24:28 - and see if i don't have the latest
24:30 - version apparently
24:32 - not so it's just gonna download it and
24:35 - install it
24:38 - so when i tried to upgrade pip on my
24:41 - machine it gave me a
24:44 - basically an access error but uh
24:47 - you if you have that error you can just
24:50 - run the same command but you add dash
24:52 - dash user at the end
24:54 - so for me it says requirements already
24:56 - satisfied in fact i didn't really need
24:59 - to run this command i already had the
25:01 - last
25:02 - version of pip already installed but you
25:04 - can run it just
25:06 - for
25:07 - the sake of it
25:10 - and now we're gonna
25:12 - use this command so pip install
25:14 - tensorflow and here i just want to
25:15 - mention something really quickly as you
25:18 - can see it mentions that the current
25:19 - stable release for cpu and gpu so when
25:22 - you run this command it's gonna install
25:25 - the
25:25 - stable versions for both cpu and gpu
25:28 - support
25:30 - before
25:31 - i can't remember before which
25:34 - release from tensorflow but before
25:37 - in order to install the gpu version you
25:39 - would add tensorflow
25:41 - gpu so you specifically mentioned that
25:44 - you want to install tensorflow with gpu
25:46 - support but apparently now when you when
25:49 - you just run this command it's gonna
25:51 - install
25:52 - the
25:53 - stability release for cpu and gpu
25:57 - so
25:58 - i'm gonna go back to
26:00 - my virtual environment here i'm just
26:02 - gonna paste it pip install tensorflow
26:06 - and let's run this command
26:08 - [Music]
26:09 - again just
26:10 - to
26:12 - mention this important point whatever
26:14 - we're installing here is being installed
26:16 - inside our virtual environment and not
26:18 - inside our system
26:20 - so this might take a little time
26:23 - depending on your internet speed and on
26:25 - your system so when the download and
26:28 - installation is finished
26:30 - i'll be back to show you what we can do
26:32 - next
26:35 - so now i have
26:37 - tensorflow downloaded and installed
26:39 - inside my virtual environment
26:41 - and i can verify that for example by
26:44 - running python console here and just
26:47 - trying to import
26:50 - tensorflow
26:52 - and it should be imported without any
26:55 - problems and just
26:57 - to show you that we're actually not
27:00 - installing things inside our
27:02 - uh on our system directly here if i run
27:06 - python and i do
27:08 - import
27:10 - tensorflow you see that module name
27:13 - or module not found here so it doesn't
27:15 - find the tensorflow module because it's
27:17 - not installed on my system
27:20 - i'm just showing you this here because
27:23 - from time to time you might face a
27:24 - problem like this and you start asking
27:27 - yourself why
27:29 - why don't i have tensorflow when you
27:32 - have already installed it but just make
27:34 - sure that if you install it in one
27:37 - specific virtual environment you should
27:38 - be using that virtual environment to run
27:40 - your code and
27:43 - this just this small detail here could
27:45 - help you solve this kind of errors
27:48 - and now that we have it what i would
27:51 - like to do is just run a command
27:54 - tensorflow.config.list
28:01 - physical
28:02 - [Music]
28:05 - devices
28:07 - so what this command is going to do is
28:09 - to show me on my
28:11 - machine which
28:13 - devices can i use to train deep learning
28:16 - models using tensorflow
28:18 - so as you can see here i have
28:21 - two devices there is the cpu and there
28:23 - is the gpu there's only one gpu as you
28:26 - can see
28:28 - for you
28:29 - it's very likely if it's the first time
28:31 - you're using tensorflow it's very likely
28:33 - that you will not have this second part
28:36 - here you won't have the gpu
28:39 - and
28:40 - this could be for several reasons for
28:43 - example you may not have an nvidia gpu
28:47 - on your machine so that's
28:49 - a common reason why you wouldn't have
28:51 - this
28:52 - the second common reason is that you
28:54 - might have an nvidia gpu but
28:58 - it's not
28:59 - it doesn't have support for training
29:02 - tensorflow or deep learning models in
29:04 - general on that gpu
29:06 - and the
29:08 - if you
29:09 - if you're not in one of these two
29:11 - categories then most likely
29:13 - you're not seeing the gpu because you
29:15 - just haven't
29:17 - set up what's necessary in order for you
29:20 - to run the training on
29:22 - the gpu and for me i have already done
29:25 - the necessary setup
29:27 - and i do have a
29:29 - nvidia gpu that can run the training
29:32 - that's why i'm seeing it here
29:34 - for you if you
29:36 - don't
29:37 - fall in the first two categories and you
29:40 - know that you can run the training on
29:41 - your gpu then i'll show you next what
29:44 - are the necessary uh hardware
29:47 - requirements and software requirements
29:49 - what are the things that you need to
29:50 - install in order to be able to use your
29:54 - gpu
29:56 - if you want to be able to run the
29:58 - training on your gpu and you know that
30:00 - you have nvidia gpu
30:03 - one thing you can do is to follow the
30:05 - right process that's mentioned in the
30:08 - official tensorflow installation
30:11 - page
30:12 - so
30:12 - here if you go to the download package
30:14 - which is what we just used
30:17 - if you go to gpu guide
30:19 - you can open this page here and
30:23 - when we when you use a bib package like
30:26 - we're doing you need to have some
30:28 - hardware requirements and also software
30:30 - requirements so the first thing let's
30:33 - check the hardware requirements so as
30:36 - you can see here it mentions that
30:38 - there are some nvidia cards where you
30:41 - can
30:42 - that are supported
30:43 - for
30:44 - you to train deep learning models on
30:46 - them so if you open
30:48 - this list here of cards that are that
30:51 - have cuda enabled architectures you can
30:54 - see a list of devices here and you can
30:57 - try to find whether your device is
30:59 - inside this list or not
31:01 - so in fact funnily enough
31:06 - for me i actually have a card geforce
31:11 - gtx 1050 ti
31:14 - and
31:15 - it doesn't exist on this list but i
31:17 - still can run the training on it anyway
31:21 - i remember the first time when i checked
31:22 - the list i didn't find it then i just
31:26 - started searching online i found that
31:28 - many people said yes they have the same
31:31 - card and they were able to run the
31:33 - training on it so this is just
31:35 - a small remark
31:38 - but uh if you find your card here then
31:41 - that's you can definitely run the
31:43 - training on the gpu
31:46 - so that's the first thing you need to
31:47 - check
31:49 - uh
31:50 - if you have that
31:52 - then most likely you can run the
31:54 - training and then you have some
31:58 - some remarks mentioned here for example
32:01 - for gpus with unsupported cuda
32:03 - architectures
32:04 - or to avoid compilation use different
32:07 - versions of nvidia so you can check
32:09 - these if you
32:10 - uh if you fall into one of these
32:13 - categories but for me usually just
32:16 - checking whether the architecture works
32:20 - is enough
32:21 - and then for the software requirements
32:23 - this is where
32:25 - in fact you need to have some software
32:27 - installed before
32:29 - your
32:30 - nvidia card can recognize
32:32 - that you can do the training using
32:35 - tensorflow
32:37 - so the first thing is
32:39 - the nvidia
32:41 - gpu drivers
32:43 - so here it says cuda 11.2 requires 450
32:48 - or higher
32:50 - so you can go to
32:52 - the website here and for me it has
32:55 - automatically detected in fact i think
32:57 - that it's because i have already done
32:59 - this so maybe it's saved in my
33:02 - in the cookies but uh
33:05 - for you if it doesn't if you don't see
33:08 - your machine directly here you can just
33:10 - go search for it manually so you choose
33:12 - the product type the product series and
33:14 - then at the end
33:17 - you just click search and it's gonna
33:20 - give you the download link
33:22 - and again this is
33:24 - when you download this and you start uh
33:28 - installing it
33:29 - okay it does didn't start automatically
33:31 - let me click again okay now when you
33:34 - have this on your machine you just run
33:36 - the installation process there's nothing
33:39 - really special you just go next next
33:41 - next and you install everything so
33:44 - that's the first thing that you need to
33:46 - do
33:47 - and then
33:49 - you have
33:50 - cuda toolkits
33:52 - that you need to install
33:54 - and just i want to mention something
33:56 - here because uh i think a lot of people
33:59 - make a mistake when they start
34:01 - installing
34:02 - all of this software
34:04 - so here specifically it mentions for
34:07 - example cuda 11.2
34:10 - and also tensorflow supports cuda 11.2
34:14 - so any version of tensorflow that's
34:16 - higher than 2.5
34:19 - it requires
34:21 - cuda 11.2
34:23 - so for us we have installed
34:26 - tensorflow so if i do
34:29 - for example
34:31 - tensorflow and then i just
34:33 - run
34:34 - or check the version of tensorflow
34:38 - insert flow
34:41 - version
34:42 - so here you can see i have version 2.6.0
34:46 - so i do fall into this category i need
34:49 - to have cuda 11.2
34:52 - uh installed
34:54 - here when you go to the cuda toolkit
34:57 - archive you
34:59 - just don't take the latest version for
35:01 - example i see many people do this
35:04 - mistake they just go to the latest
35:06 - version but here if it's mentioned that
35:08 - you need to use 11.2 then you need to
35:11 - look for 11.2
35:14 - and here what i usually do is i take the
35:16 - latest version
35:18 - of 11.2 because here you can see there's
35:21 - 11.2.0.1.2
35:24 - so i just take this one here
35:28 - and then you just choose your operating
35:31 - system the architecture is only one here
35:35 - version 10 of windows and then you can
35:37 - choose one of two options
35:39 - [Music]
35:40 - there is the local installer and the
35:42 - network installer the difference is that
35:45 - the local installer has a large file
35:48 - which doesn't require a require internet
35:50 - access i mean after you download it you
35:52 - don't require uh internet access in
35:55 - order to install
35:57 - cuda toolkit
35:58 - and this one
36:00 - is a smaller file but it does require
36:02 - internet access if you have good
36:04 - internet then i suggest you just
36:07 - download this small file
36:08 - if not then you can download the largest
36:11 - file here and again
36:14 - there is nothing really special about
36:16 - this you just download it and then you
36:18 - go next next next there is
36:21 - and then you have the cuda toolkit
36:23 - installed on your machine so that's the
36:26 - second part
36:28 - uh for the cup tie you don't need to do
36:30 - that it mentions here that it ships with
36:33 - cuda toolkit so
36:35 - if you have the kuda toolkit you already
36:37 - have kubtai
36:38 - and then you need to install crew dnn
36:42 - sdk
36:44 - 8.1.0
36:46 - so if we click this
36:49 - let me check here
36:52 - so download cooldmn
36:56 - and in fact
36:57 - for you to download that
36:59 - file or that folder
37:02 - you need to be a member
37:05 - on the website and this is you can do
37:07 - this for free you can just
37:09 - log in if you already have an account or
37:11 - you can join now
37:13 - for example and you just uh use your
37:16 - email and
37:18 - there is nothing special here you just
37:20 - join the
37:22 - the
37:22 - website
37:23 - so for me i already have a an account
37:27 - here
37:28 - so once i log
37:30 - into my account
37:32 - i get this web page here so i'm just
37:35 - going to agree to the terms and then
37:37 - here you can download the version
37:41 - for
37:42 - uh or kudianon 8.2.4
37:46 - and in fact here when you look at this
37:49 - you see that there is for cuda 11.4 and
37:52 - this is for cuda 11.2 let's see if we
37:55 - can find for cuda
37:58 - 11.2
38:01 - so there is none
38:03 - in that case
38:05 - we're just gonna use the latest version
38:07 - here so let me just go back here and
38:10 - check
38:11 - okay we have the cuda versions
38:17 - yes apparently
38:20 - okay 11.1 here
38:24 - yeah in fact there is so
38:26 - this is again this is a sometimes a
38:29 - problem that many people face so here we
38:32 - need hoo dnn sdk 8.1.0
38:37 - when i clicked on the qdnn versions i
38:40 - get to this website here and here if you
38:44 - just don't take the latest version you
38:46 - need to look for your own specific
38:49 - version
38:50 - so here i have
38:52 - uh
38:54 - the
38:54 - version
38:56 - 8.1.0 which is
38:58 - what we need so for eight point one
39:01 - point zero we have one for cuda 10.2 and
39:05 - then one for cuda point eleven point
39:08 - zero point one and point two
39:10 - for us we have cuda
39:13 - 11.2
39:15 - as you remember so
39:17 - we need
39:18 - this
39:20 - this version here
39:22 - so these are small details but just
39:25 - make sure you follow them so that you
39:27 - don't face a problem later
39:30 - many times i find people saying that
39:32 - they installed everything but still
39:35 - their car does not recognize uh
39:39 - cannot do the training with tensorflow
39:42 - but usually the problem just comes from
39:44 - one of these small details
39:47 - so if you click this
39:48 - then you can choose the right software
39:51 - for your machine so for example we are
39:54 - on a windows machine so i can just click
39:57 - goody and then library for windows
40:01 - and this is going to download
40:04 - a zipped folder
40:06 - and in fact i already have it on my
40:09 - machine here
40:11 - now i'm going to show you what
40:14 - what you need to do with this folder
40:18 - so when you installed
40:20 - cuda 11.2
40:23 - it was installed in this path here so if
40:26 - you go to c program files nvidia gpu
40:29 - computing toolkit
40:31 - then you go to cuda
40:33 - for me i have several versions of cruda
40:35 - because
40:36 - from time to time i would
40:39 - upgrade or use the newest version of
40:42 - tensorflow and then many times it
40:44 - requires new version of cuda so i would
40:47 - download
40:48 - and install the right cuda version for
40:51 - you if you've never did this before then
40:53 - probably you will have only one
40:55 - version which is 11.2
40:58 - and now
41:00 - what we're gonna do with the
41:02 - uh the zipped folder that you downloaded
41:06 - what you need to do is to unzip it so
41:08 - when you unzip it you're gonna get
41:11 - a folder called cuda inside of it you're
41:13 - gonna have these folders and this file
41:16 - here
41:17 - so what we're gonna do now is basically
41:20 - just copy the contents from these
41:23 - folders to the corresponding folders
41:25 - in cuda 11.2 so for example you would go
41:29 - to the bin folder
41:31 - copy everything then go
41:33 - here and paste everything
41:35 - for me i've already copied and pasted
41:38 - these so i'm not going to do it but this
41:41 - is the only thing you need to do then
41:42 - you go to the include
41:45 - folder
41:46 - copy everything paste it in the
41:49 - include folder
41:51 - and last
41:53 - you go to the
41:55 - lib folder you copy everything inside
41:57 - x64
41:58 - and then the same thing here lib you go
42:01 - to
42:02 - x64 and then you paste everything there
42:06 - when you do this you can go back to
42:10 - your terminal
42:12 - so what i would suggest is to
42:15 - close
42:16 - and reopen the terminal
42:19 - and then
42:20 - if you run the same command that we that
42:23 - i showed you before so
42:25 - for example let's just do it again
42:29 - import
42:31 - tensorflow
42:32 - so here if we
42:35 - if we run
42:38 - tensorflow.list or
42:41 - config
42:42 - not list
42:46 - physical
42:49 - devices
42:52 - now you should be able to see this
42:55 - gpu part here so
42:59 - now i have shown you exactly the full
43:01 - process of installing a tensorflow so
43:04 - that you can use it with your gpu if you
43:07 - have a cuda enabled nvidia gpu
43:11 - and this is gonna allow you to run the
43:13 - train the training of your deep learning
43:15 - models much much faster
43:17 - which is uh almost always recommended
43:20 - and with this
43:22 - let's now look at what we can start
43:25 - adding
43:27 - from the coding part so that we can
43:30 - start exploring tensorflow
43:32 - library
43:34 - so here we're gonna start with the
43:37 - first
43:38 - classification task using tensorflow and
43:41 - it's actually a classical task so
43:44 - basically what we want to achieve
43:47 - is
43:48 - uh to build a system that can take
43:52 - images like this one here or here or
43:55 - here and at the output it would tell us
43:57 - whether there is a three or there's a
43:59 - seven there's a zero inside that image
44:02 - so our data set looks something like
44:05 - this of course these think of these are
44:08 - as separate
44:09 - small
44:10 - images just like these ones here these
44:12 - are just put together here for
44:15 - visualizations
44:16 - purposes
44:18 - so our data set has so many zeros so
44:20 - many ones twos until the digit nine
44:25 - and we want to build a system that can
44:27 - take an image like this
44:30 - at the at the start or as an input and
44:34 - adds the at the output we want to get
44:37 - the value that's written inside of that
44:41 - uh
44:42 - of that image
44:43 - so it's always good to really think
44:46 - about
44:48 - whatever task you're trying to achieve
44:50 - before you start the coding part so here
44:53 - this is just a quick overview of what we
44:55 - want to achieve and in fact this amnest
44:58 - test is
45:00 - a
45:01 - uh you can say as a tradition in the
45:04 - deep learning community it's just like a
45:06 - hello world
45:08 - program when you're learning a new
45:09 - programming language so now
45:12 - that you have
45:14 - hopefully understood the purpose of this
45:16 - task let's get into the code and see
45:20 - what
45:20 - how we can achieve this
45:23 - this goal here
45:25 - now let's get to the coding part so the
45:28 - first thing i'm going to do is just add
45:30 - a new file
45:31 - i'm going to call for example mnist
45:35 - example.buy
45:38 - and it's automatically opened on this
45:40 - side here
45:42 - so let's start by importing
45:45 - for example
45:46 - tensorflow since we will definitely need
45:49 - it later
45:50 - and
45:52 - one thing we gonna add from the start is
45:56 - just
45:57 - check if
45:59 - name
46:00 - equals
46:02 - main
46:02 - [Music]
46:03 - then we're going to run the code so
46:06 - if you're not familiar with this
46:09 - python
46:10 - part here just means that
46:12 - if i run my
46:14 - script then i want this part here to be
46:17 - rand and if i import it for example i
46:20 - can import my file into another script
46:23 - and in that case this part will not be
46:25 - called it's a good habit to
46:27 - always add this one
46:28 - [Music]
46:30 - on your scripts when you want
46:32 - to separate the behaviors between
46:34 - importing those scripts and running
46:36 - those scripts
46:38 - so the first thing that you might notice
46:41 - here is that it says
46:43 - tensorflow is not accessed it doesn't
46:45 - find tensorflow
46:48 - so here in fact what's happening is that
46:51 - if
46:52 - if you run your script from the terminal
46:55 - then there will be no problem
46:57 - so if i do python
47:00 - and this example dot y
47:03 - nothing is going to happen but
47:05 - there will be no problem that's what i
47:07 - mean
47:08 - but here if you try to run it using the
47:11 - run button here
47:13 - then you see it says no module named
47:16 - tensorflow and in fact what just
47:17 - happened is that
47:19 - vs code has opened a new terminal window
47:24 - automatically and it tried to run this
47:27 - script
47:28 - using our
47:30 - python that exists on our system and not
47:32 - inside our virtual environment
47:35 - so in fact we still have our virtual
47:37 - environment here and this is the new
47:39 - terminal window that was
47:41 - started by vs code
47:43 - so
47:44 - in order to run your scripts so you can
47:47 - in fact just ignore these
47:50 - these warnings here and you just run
47:52 - your script from the terminal but if
47:55 - this
47:56 - uh is annoying for you as it is for me
47:59 - you can fix it by
48:01 - actually telling vs code that this code
48:05 - here that we're writing is going to be
48:06 - around inside our virtual environment
48:09 - tf2vm so in order to do that you can
48:12 - click ctrl shift p
48:15 - on your keyboard so again ctrl shift p
48:19 - you push them
48:20 - you click them together and then you
48:23 - just search for
48:25 - interpreter and you choose python select
48:28 - interpreter
48:30 - and here is going to give you a list of
48:32 - a different python
48:34 - executables that it found on your system
48:37 - and here we're going to look for the
48:39 - virtual environment that we created so
48:42 - it's called tf2bn
48:44 - so
48:45 - let's just go
48:47 - step by step here try to find it so i
48:49 - have many virtual environments that's
48:51 - why it's not clear okay it's this one
48:54 - for you you may not have all of these
48:56 - virtual environments so it will be
48:58 - quick to spot which one is the
49:01 - environment that you created
49:03 - so i'm gonna click on tf2 vm and now as
49:06 - you can see
49:07 - vs code recognizes tensorflow because
49:10 - it's installed inside our virtual
49:12 - environment
49:13 - and i can click this one here
49:17 - and
49:19 - as you can see the program runs
49:21 - correctly with no problem
49:24 - so
49:26 - now let's go to our code editor here and
49:31 - let's start
49:32 - looking into what we can do
49:35 - for our task that we defined previously
49:38 - so
49:39 - one thing we can start doing is by
49:41 - actually importing the data set
49:43 - so in fact
49:45 - if you're doing a new project with your
49:48 - own data set it may not be
49:50 - this easy but since this is the first
49:54 - example of the first tutorial we're
49:56 - gonna do we're just gonna use the
49:58 - easiest and the quickest things so that
50:00 - we can put something together and see uh
50:03 - see basically the workflow of a
50:05 - tensorflow
50:07 - program
50:08 - so what we're gonna do is use
50:10 - tensorflow.js
50:13 - dot
50:15 - data sets
50:17 - or
50:18 - let me just check
50:21 - yes in fact it should be data sets
50:24 - dot
50:26 - load
50:29 - or dot mnist
50:31 - dot
50:32 - load
50:34 - data
50:37 - so
50:38 - let me just do this and in fact what
50:40 - this is going to do is load our data but
50:44 - we need to tell it
50:46 - where to store it so for us
50:49 - we're just going to use
50:52 - x train
50:53 - for the training data set and y train
50:56 - for the corresponding labels
50:59 - and then
51:01 - we're gonna use
51:04 - x test
51:06 - and y
51:08 - test
51:11 - so what this is going to do is
51:13 - load the mnist data set in fact if it's
51:17 - not if it doesn't exist on your system
51:19 - if it's the first time you'll be running
51:21 - this
51:22 - program here then it will download it
51:25 - first
51:26 - and then it's gonna load it into these
51:28 - variables that we defined here
51:31 - and it's already split into two parts
51:34 - one for training and one for testing
51:38 - so
51:39 - let's run this command or this program
51:42 - here and just
51:44 - i would like to
51:46 - print the shapes of
51:48 - these uh these variables that we defined
51:51 - and that we're going to load our data
51:53 - set in them so xtrain
51:57 - dot shape
52:02 - and let me just run this
52:05 - and i'm just gonna
52:09 - paste this
52:12 - three times and i want to do this for
52:14 - every variable that we have here
52:18 - ctrl c
52:20 - ctrl v
52:27 - so
52:28 - now let me just run my
52:31 - script again from the terminal
52:34 - and let's see what we get
52:37 - so as you can see it has loaded the data
52:39 - set
52:41 - and
52:42 - it has put them into these variables and
52:44 - we can see the shapes
52:46 - or basically the size of the data set so
52:49 - as you can see for the training part
52:51 - there are 60 000 images each image is of
52:56 - 28 by 28 pixels
52:58 - the labels there are sixty thousand
53:00 - labels because each image has its own
53:03 - label
53:04 - and by the label here i mean that if an
53:06 - image contains the number three in it
53:09 - then the label will be the number three
53:13 - and for the test part we have 10 000
53:16 - images and of course their corresponding
53:18 - 10 000
53:19 - labels
53:20 - so just just a quickly to go through why
53:24 - do we separate our data set into these
53:26 - two parts so in fact in deep learning
53:29 - what we do is
53:30 - we do some sort of cross validation
53:34 - there are many types of cross validation
53:37 - the simplest one is to
53:39 - split the data set into two parts one
53:42 - you're gonna use to train your model and
53:44 - one you're gonna use to validate your
53:47 - model
53:48 - and the difference is that during the
53:50 - training
53:51 - these are the examples that will be used
53:54 - and at the end of each epoch
53:57 - uh what's going to happen is that the
53:59 - neural network is going to run
54:01 - one forward pass of these test examples
54:05 - and this is going to give you an idea of
54:07 - how your neural network is performing on
54:10 - data that's not used during the training
54:13 - so it's this is going to give you an
54:16 - idea of uh how well the network is
54:19 - learning
54:20 - so this is just you can keep it in mind
54:23 - there's a whole theory behind this but i
54:25 - just want to go quickly
54:28 - through this so that you understand why
54:30 - do we have these two different splits
54:34 - so
54:34 - now what is usually good to do is to
54:38 - explore more your data set so what we
54:40 - have done here is some sort of an
54:42 - exploration we
54:43 - basically checked the size of our data
54:46 - set we now know that each image is 28 by
54:49 - 28 pixels but it's also good to
54:53 - plot some of the examples and their
54:55 - corresponding labels
54:56 - so for that i'm just going to create a
54:59 - help helping function so i'm going to
55:02 - call it for example
55:04 - display some
55:07 - examples
55:08 - and what's going to take
55:11 - as parameters are the
55:14 - examples or data points and the labels
55:19 - so basically what i want to do here is
55:24 - create a figure and add
55:26 - many of the images randomly i'll choose
55:29 - them randomly from the data set and then
55:31 - i'll add them inside uh
55:34 - this figure and then i'm gonna plot this
55:37 - figure so that we can see those images
55:40 - so one thing you can use
55:43 - which is a very famous package in python
55:46 - is a matplotlib so
55:49 - usually we just call it plt for short
55:53 - and in order to do that you need to
55:56 - import
55:57 - matte blot lib dot
56:00 - pi
56:01 - as plt
56:03 - and then you can use this package
56:06 - to do all sorts of things like creating
56:08 - figures and adding
56:09 - different images
56:11 - on those figures
56:13 - so as you can see here
56:15 - visual studio code does not recognize
56:17 - this package here because in fact we
56:19 - don't have it installed inside our
56:21 - virtual machine
56:23 - so before we go
56:26 - anywhere let's
56:28 - just
56:29 - installed it and to install any new
56:31 - package you can just run pip
56:34 - install and the name of the package so
56:36 - matt lard lib
56:38 - and usually
56:40 - i
56:40 - install packages on the go so whenever i
56:43 - need the package i installed it i
56:46 - don't like to install many things in the
56:48 - beginning
56:49 - because i don't know beforehand which
56:51 - ones which of the packages i'll
56:53 - definitely need and which ones i won't
56:56 - need so usually i just write my code and
56:58 - whenever i need a package i install it
57:02 - on the spot so here let me run pip
57:04 - install map.lib
57:06 - so it shouldn't take long
57:10 - okay it's installed and now it should be
57:13 - recognized i guess
57:15 - maybe it's not
57:16 - refreshed automatically but now we can
57:19 - use plt
57:21 - so
57:22 - we're going to start by creating a
57:25 - figure
57:26 - and we're going to give it a fix size of
57:31 - let's say 10
57:33 - by 10
57:34 - [Music]
57:36 - and
57:37 - then what we're gonna do is
57:39 - basically
57:40 - plot 25 images so it's going to be a
57:43 - grid of five by five
57:45 - so we're gonna do a for loop so for i
57:50 - in range
57:51 - 25 so i'm choosing 25 here you can
57:55 - choose whatever number you like for me i
57:57 - think 25 images is already enough to get
58:00 - an idea about your data set
58:03 - and here the first thing i'm gonna do is
58:06 - randomly choose so each time i'm going
58:09 - to randomly choose an index
58:12 - from
58:13 - my
58:14 - data set so let me just code it and it's
58:17 - going to be
58:19 - much clearer so i'm going to do index
58:21 - and
58:22 - numpy
58:24 - okay i don't have numpy
58:26 - imported so let me just
58:29 - import
58:31 - numpy snp and here i'm just gonna do np
58:36 - dot
58:37 - random
58:38 - dot rant in so i want to
58:41 - randomly choose an integer
58:44 - and i really like this uh kind of a
58:46 - tooltip that comes
58:48 - when you're coding on visual studio code
58:51 - and it basically gives you a small
58:53 - documentation about that function and
58:55 - what you can do with it
58:56 - so here for this function we need to
58:59 - give it a lower
59:01 - end and the higher end and it's going to
59:03 - use an integer between those two numbers
59:06 - so here i'm going to choose something
59:07 - between 0 and the size of
59:11 - so examples
59:13 - dot shape
59:17 - and
59:19 - i'm going to do 0
59:20 - and here minus 1. so
59:23 - what am i doing here so if you remember
59:26 - here
59:27 - whether you choose the training set or
59:29 - the test set for example the training
59:31 - set there is 60 000 images so i want to
59:34 - choose a number between 0
59:37 - and
59:38 - basically
59:39 - 59 999
59:43 - because that would represent the number
59:45 - corresponding to the last image
59:47 - and here this is all i'm doing so here
59:49 - i'm basically choosing between zero and
59:53 - uh
59:55 - and sixty thousand minus one
59:58 - and then what i'm gonna do is use this
60:01 - index
60:03 - to
60:04 - get the corresponding image so now i can
60:07 - do examples
60:09 - index
60:11 - and then i want to get also the
60:13 - corresponding label
60:15 - so i'm gonna do labels
60:17 - and index
60:20 - and now i'm gonna
60:23 - plot that specific image so for that i'm
60:26 - gonna use plt
60:29 - subplot
60:29 - [Music]
60:31 - and just make sure i think there are
60:33 - there is subplot and subplots but what
60:36 - you want to use a subplot without the s
60:40 - and here we gonna give it basically the
60:43 - grid
60:44 - size so it's a 5x5 because we want to
60:47 - plot
60:48 - 25 images
60:50 - and
60:51 - here
60:52 - this is the number of
60:54 - the image
60:56 - and here i'm gonna do
60:58 - plot
61:00 - i'm gonna first
61:02 - plot the
61:03 - sorry here the title
61:05 - so the title of each image i want it to
61:08 - be the corresponding label so
61:10 - and it also needs to be into a string
61:13 - sorry so here i'm just gonna transform
61:15 - my
61:16 - label
61:17 - into a string so this is going to be the
61:20 - title of each
61:21 - uh image and then
61:24 - i'm going to add
61:27 - an mshow
61:30 - method to show the corresponding image
61:32 - so here i'm going to do
61:35 - show my image
61:37 - and at the end you need to tell
61:40 - python that
61:42 - show
61:43 - all of the figure now
61:46 - so now that we have this function coded
61:49 - let's try it out here
61:52 - by calling the name of the function then
61:56 - let's run it on the train set so here
62:01 - i'm gonna run it on the xtrain and y
62:03 - train
62:06 - so let me clear the terminal quickly
62:09 - and
62:10 - do
62:12 - python
62:13 - mnistexample.buy
62:18 - so now as you can see we get
62:21 - these images in a 5x5 grid
62:25 - and
62:26 - we have all of these examples now one
62:29 - thing you
62:30 - you might
62:31 - observe is that we have these images
62:35 - that have this kind of weird color
62:38 - and also we have
62:41 - basically the space between the images
62:43 - is too small so we don't clearly see
62:46 - that okay this is this has a label of
62:48 - nine but it's not very clear so let's
62:51 - fix these two problems quickly now
62:55 - so first of all we know that our images
62:57 - are grayscale images they're not rgb
63:00 - images
63:01 - because here we see that the size is 28
63:04 - by 28 which means there's only one
63:07 - channel and there are no there are three
63:10 - channels so it's not an rgb image
63:12 - so in order to tell matplotlib that this
63:16 - is a grayscale image we can use
63:20 - the c-map
63:23 - argument here and we can tell it that
63:25 - it's actually gray
63:27 - and to fix the problem of the layouts
63:31 - what we can do is
63:33 - use plt
63:35 - dot type layout
63:37 - and this is gonna automatically
63:39 - add more space so that we can
63:42 - see the labels and the images uh in a
63:46 - much more understandable way so let me
63:48 - run the command again
63:50 - python
63:52 - and this example.buy
63:55 - and as you can see now it looks much
63:58 - more clear
63:59 - these are
64:00 - the images that exist inside our data
64:03 - set they are grayscale images and
64:06 - above each one we have the corresponding
64:08 - label so this is a two this is a one a
64:10 - one this is a four a three here a six so
64:15 - we have all of these examples and why do
64:18 - we do this it's just a way to basically
64:21 - quickly check your data set sometimes
64:24 - what happens is that when you're
64:26 - building your own data set and you do
64:29 - this kind of exploration you quickly
64:31 - spot some things for example you might
64:33 - spot that this is a zero but uh
64:36 - but it's not labeled correctly
64:39 - for example you must see that this is
64:41 - labeled as nine when it's actually a
64:43 - zero
64:44 - so that's gonna give you
64:46 - basically just quick hint that there is
64:48 - there are problems
64:50 - with your data set
64:51 - and you can maybe go fix them quickly
64:56 - and the good thing is that whenever you
64:58 - run this script it's going to choose
65:01 - randomly different images so you can see
65:04 - different parts of your data set each
65:06 - time you run the script so here we have
65:07 - the two six one for example in the
65:09 - beginning just so that we can remember
65:12 - and let's run it again
65:17 - okay
65:19 - and now as you can see we have five 572
65:21 - instead of the
65:23 - 261 i think it was before
65:26 - so
65:27 - this is just about the exploration of
65:30 - your data set as i mentioned it's always
65:33 - a good idea to do these quick
65:35 - exploration steps before we start doing
65:38 - anything
65:39 - and now that we see that okay our data
65:41 - set is
65:43 - more or less okay
65:45 - let's see what we can do next
65:48 - in regards of creating a model and later
65:51 - training it
65:54 - now that we have our data set
65:56 - loaded and ready
65:59 - let's see how we can build our neural
66:01 - network
66:02 - so in fact tensorflow
66:05 - gives you access to so many layers
66:08 - that you can use to build your neural
66:10 - network so if for example you
66:15 - do from
66:16 - tensorflow
66:22 - import here you have
66:25 - many different layers that you can
66:27 - import
66:28 - for our classification task and for many
66:32 - of the computer vision tasks
66:35 - we usually have a set of layers that we
66:38 - basically always use so
66:41 - these layers are
66:43 - conf
66:44 - 2d
66:45 - so this is a 2d convolution
66:49 - we also
66:50 - uh always
66:52 - use
66:53 - of course an input layer so here i'm
66:55 - going to add input so this is a layer
66:58 - that basically gets our input and then
67:01 - passes it to the rest of the layers
67:03 - and
67:04 - there is also the dense layer
67:08 - so it's also called fully connected
67:10 - layer
67:12 - we have the
67:13 - max pool 2d
67:15 - so since we're doing 2d convolutions
67:17 - we're going to combine them with a max
67:20 - pool 2d
67:21 - and
67:23 - it's always good to use batch
67:25 - normalization to normalize our batches
67:30 - and also
67:31 - we might
67:33 - want to use a flattened layer
67:36 - which basically takes the output from
67:39 - some
67:40 - multi-dimensional layers like a
67:41 - convolutional layer and then it just
67:43 - flattens them and puts them in
67:46 - some sort of a vector
67:49 - and also in fact
67:52 - in many cases
67:54 - you can use just
67:56 - global
67:58 - average pooling
68:00 - or global
68:02 - sorry here global
68:05 - average pool 2d
68:09 - so this layer also can uh
68:12 - can work in a way that's
68:15 - closely similar with flattened but
68:17 - they're different in the way they do it
68:19 - so flatten basically takes all of the
68:22 - uh all of the
68:24 - outputs of a previous layer puts them
68:26 - into a vector but
68:28 - in the global average pooling there is
68:31 - some sort of a
68:33 - compute computation of the mean
68:35 - based on some axis and then
68:38 - the output
68:40 - usually is much smaller than the output
68:42 - given by a flattened layer so
68:45 - here
68:46 - i'm basically mentioning some of the
68:48 - basic layers that we use in a neural
68:52 - network for doing
68:55 - image processing or doing uh
68:58 - deep learning for images type of things
69:01 - so for classification this is one case
69:03 - there's also object detection image
69:05 - segmentation
69:06 - all of these
69:08 - tasks usually you're going to find this
69:10 - type of layers in them and sometimes you
69:12 - find more complex layers
69:15 - and sometimes those complex layers are
69:17 - just
69:18 - basically stacking together different uh
69:21 - basic layers like these ones here
69:24 - so
69:25 - these are the layers that we're gonna
69:27 - use to build our neural network
69:30 - and now let's see how we can build that
69:33 - neural network there are several
69:36 - ways and mainly three ways that you can
69:38 - build a neural network in tensorflow
69:40 - we're gonna explore them now one by one
69:44 - the three approaches that tensorflow
69:47 - gives us or provides us in order to be
69:50 - able to build deep learning models are
69:52 - the following
69:53 - so
69:54 - the first approach is by using
69:59 - tensorflow.keras dot sequential
70:03 - so you can call it the sequential way
70:06 - this is the easiest way to build a deep
70:08 - learning model you just stack different
70:10 - layers together
70:12 - and we're gonna do this in a minute
70:14 - the second approach is by
70:17 - what's called
70:19 - the functional way
70:21 - or the functional approach so basically
70:24 - here you build a
70:26 - function
70:27 - that
70:29 - returns
70:30 - a
70:31 - deep learning model or just let's just
70:33 - write a model
70:35 - and the third approach
70:38 - is to basically inherit from a base
70:41 - class
70:43 - this base class is in
70:45 - tensorflow.keras
70:48 - dot
70:49 - model so you inherit from this class and
70:52 - then
70:53 - you
70:55 - you re-implement or you overwrite some
70:58 - of the methods of this class
71:00 - and then you can have a deep learning
71:03 - model so
71:05 - inherit
71:07 - from this class
71:10 - so these are the three different
71:11 - approaches let's start with the first
71:13 - one
71:14 - so in order to build a deep learning
71:17 - model
71:18 - architecture using this sequential class
71:22 - in fact it's very easy you just call for
71:25 - example
71:27 - let's
71:28 - call our model model and then
71:31 - you
71:32 - call this
71:34 - sequential
71:36 - class
71:37 - and show
71:40 - and
71:41 - then you can start
71:43 - stacking layers here
71:46 - so
71:47 - what we start with always is an input
71:50 - layer so here
71:53 - we're going to use the
71:55 - input layer that we imported here
71:58 - and what this input layer takes
72:00 - as a an argument it takes many arguments
72:04 - but the main one that we need to set is
72:06 - the shape of the input
72:08 - so as you remember our images are 28 by
72:11 - 28
72:13 - and
72:14 - they only have uh one channel they are
72:17 - grayscale images so there's only one
72:20 - channel this means that our input needs
72:23 - to be 28 by 28 by one
72:27 - one represents only one channel
72:31 - and then the second layer that we're
72:34 - gonna add here is going to take as input
72:36 - this layer
72:38 - and usually when you're doing image
72:40 - classification
72:42 - [Music]
72:44 - tasks or other computer vision related
72:46 - tasks in deep learning you take the
72:49 - image and then you pass it through some
72:52 - convolutional layers so here we're going
72:54 - to do the same thing so conf 2d
72:58 - and
72:59 - since this is the
73:01 - the first
73:02 - convolutional layer
73:05 - let's go through some of the
73:08 - parameters that exist
73:10 - in this layer so one thing that i like
73:12 - to do is
73:13 - to just hold the ctrl key and then hover
73:17 - over that class and as you can see
73:20 - visual studio code can give you so many
73:22 - information about that class
73:24 - and here the mandatory
73:27 - parameters that we need to set are
73:28 - filters and the kernel size and then you
73:32 - have the rest of the parameters already
73:34 - set you can change them if you like
73:37 - and here even gives you some examples
73:40 - and they give some explanations of the
73:43 - different
73:45 - different parameters
73:47 - so
73:48 - the number of filters here so let's
73:51 - start with for example
73:53 - 32 filters of size 3
73:56 - by 3
73:59 - and here let's also set an activation
74:02 - function
74:04 - and i'm going to use
74:06 - a real u activation function
74:09 - so here there are all of these
74:10 - parameters what do they
74:12 - basically represent for us so this
74:15 - number here the 32 represents how many
74:18 - filters or how many uh
74:21 - basically
74:22 - well each filter
74:24 - has a set of weights and in fact here
74:27 - we're defining how many
74:30 - weights values are in that filter
74:34 - so
74:35 - this means that we're creating 32
74:37 - filters each filter filter is three by
74:40 - three of size
74:42 - and then we're choosing an activation
74:44 - function here
74:46 - we're choosing rectified linear unit
74:48 - there are several activation functions
74:52 - and all of these parameters you might be
74:54 - thinking why do we choose 32 and not
74:56 - another one why do we
74:58 - choose three by three and this is real
75:00 - you why do we choose these specific
75:02 - parameters where in fact
75:04 - these parameters are hyperparameters you
75:07 - might have heard of this term and these
75:10 - are parameters that you can
75:12 - change and each time you change and you
75:16 - train your new deep learning model and
75:17 - you see whether the
75:20 - accuracy has improved or not so far
75:24 - there's no
75:25 - very solid theory on
75:28 - how many parameters you should choose in
75:31 - each phase so it's really an
75:32 - experimental
75:34 - approach you choose some of these
75:37 - parameters you train your model and then
75:40 - you go change them again and train your
75:42 - model again and see if you get a better
75:45 - accuracy
75:46 - now i am choosing some of these
75:48 - parameters based on
75:50 - much previous work that has been done by
75:53 - researchers if you see a lot of the
75:56 - neural networks used for classification
75:58 - they would start with something very
76:00 - similar to this so i am following on
76:03 - their footsteps because i know that they
76:05 - have done so many experimentations
76:07 - with those neural networks
76:10 - so here i'm going to start with a
76:12 - convolutional layer
76:13 - usually what we do is we create a block
76:17 - of convolution where you have a
76:18 - convolutional layer then you would use
76:21 - max pool
76:22 - 2d
76:24 - and
76:24 - then you would use a batch normalization
76:27 - layer
76:28 - and then you can do the same thing again
76:31 - another convolution max pool
76:32 - normalization and you just change for
76:34 - example the number of filters or the
76:37 - filter size here or the activation
76:41 - function
76:43 - so what this max pool 2d does is that it
76:46 - takes the output of the convolution and
76:50 - it looks in both directions and based on
76:53 - the pool size so again let's maybe go to
76:56 - the documentation
76:58 - that's
76:59 - written inside the code here
77:02 - what you have is
77:05 - let me just go way down you have the
77:07 - pool size
77:09 - and it's two by two what this means
77:12 - is that the output of the convolution
77:15 - we're gonna look a two by two window of
77:18 - the output of this layer
77:20 - and each time we're gonna use we're
77:22 - gonna keep only the max value between
77:25 - those four values because it's a two by
77:27 - two window so there are four values we
77:29 - only keep the
77:31 - max value
77:32 - between all of those four values and
77:35 - here you can in fact change this you can
77:37 - set the pull size to four by four which
77:39 - means it's a four by four window where
77:41 - you keep only the max value in that
77:45 - in that window
77:48 - and again why do we keep two by two why
77:50 - don't we change it as
77:52 - these are also hyper parameters that you
77:55 - can change and each time you change you
77:58 - retrain your model and see whether you
78:00 - get better results so this also goes
78:03 - into that experimental
78:05 - experimentation approach
78:07 - that we do at uh as machine learning
78:10 - engineers or data scientists
78:13 - so
78:15 - this is one way to do things and the
78:18 - in fact you're not
78:20 - you're not let's say
78:23 - you don't strictly need to follow these
78:26 - approaches
78:27 - you can experiment for example you can
78:29 - add
78:30 - a convolution to the here
78:33 - and you
78:35 - for example let's do 64
78:39 - and the three by three
78:42 - and activation
78:48 - is uh
78:49 - is it activations or activation sorry
78:51 - let me just
78:52 - check again
78:54 - [Music]
78:56 - so here
78:58 - let me go into the parameters
79:04 - activation now it's only is without an s
79:07 - okay
79:10 - so you can do this you can remove it you
79:12 - can add another layer
79:14 - feel free to experiment with this uh
79:16 - architecture because this is where
79:20 - deep learning is is different than uh
79:23 - conventional software engineering you
79:25 - can do so much experimentation with all
79:27 - of these things and you will have
79:30 - different results and only based on
79:32 - those results you can say that your
79:34 - model is better than the previous ones
79:36 - or not
79:37 - so here let's for example keep it like
79:40 - this and let's create another stack of
79:43 - layers here
79:45 - so conf
79:46 - 2d
79:48 - and i'm gonna for example use 128
79:53 - filters
79:55 - keep them three by three
79:57 - and
79:58 - the activation
80:00 - is the same
80:02 - as before so real you
80:06 - and
80:07 - this approach here where i take 32 64
80:10 - and 128 is also something that i've seen
80:13 - being done in research so many neural
80:16 - network architectures follow this kind
80:18 - of
80:19 - approach where each time they double the
80:21 - number of filters so i'm choosing to do
80:24 - that but in fact nothing is stopping you
80:26 - from using
80:28 - other numbers here you can use for
80:29 - example 110
80:32 - or just 100 or whatever you like so i'm
80:35 - gonna
80:36 - finish the architecture using the same
80:38 - approach here
80:41 - so now i have
80:43 - these layers that are
80:46 - very similar so we take an input we do
80:49 - some convolution here then the second
80:51 - convolution we max pool we do batch
80:54 - normalization then again we do
80:56 - convolution max polling batch
80:58 - normalization and here just if i didn't
81:00 - mention batch normalization before so
81:04 - batch normalization is basically looks
81:06 - at your batches and does normalization
81:09 - on that batch this is an operation that
81:12 - is that is inspired from the
81:15 - uh normalization of the input which is
81:17 - something that we're going to do a
81:19 - little later
81:20 - so
81:22 - basically researchers have noticed that
81:25 - when you normalize your input this helps
81:27 - the gradient
81:29 - the computational of the gradient and it
81:32 - helps when we're trying to minimize our
81:34 - cost function so some other researchers
81:37 - said okay if we're normalizing our
81:40 - inputs why not normalize the
81:43 - outputs of the layers inside the neural
81:45 - network so this is why
81:47 - they created this
81:48 - new type of layer where it takes the
81:50 - output of this previous layer and then
81:53 - it normalized the the batches so each
81:58 - time we have a new batch we normalize
82:01 - the data inside that batch
82:04 - and finally since we finished the
82:07 - convolutional parts here which are
82:10 - the
82:11 - main
82:12 - layers that's going to affect our neural
82:15 - network because they can learn so much
82:18 - and you can
82:19 - check some of the
82:21 - papers about this
82:23 - maybe the young lacoon
82:25 - paper which was the first one that
82:27 - introduced the
82:29 - convolution or 2d convolution and you
82:31 - can see how much we're saving in memory
82:34 - and how much they actually improved the
82:37 - results
82:38 - now let's get to the
82:40 - part where we basically built what comes
82:44 - later at our
82:46 - neural network architecture
82:48 - so here i'm going to use a global
82:51 - average pooling
82:53 - and then i'm gonna add a dense layer
82:57 - i'm gonna add a dense layer of 64
83:00 - units
83:02 - and an activation
83:03 - of
83:05 - real you so i'm gonna keep the same
83:08 - activation function as before
83:11 - and then i'm gonna add
83:13 - a final layer here
83:15 - and now i'm gonna use
83:18 - an activation
83:22 - called soft max
83:25 - and with this i have actually finished
83:27 - building my neural network using the
83:29 - sequential approach
83:30 - and let me just go through these layers
83:33 - quickly and what we're doing here so the
83:36 - global average pool 2d
83:38 - it takes the output from this patch
83:40 - normalization layer and it computes the
83:44 - average
83:45 - of those values according to some axes
83:49 - and then we're going to get a
83:52 - set of values here and then those values
83:55 - are going to be fed to a dense layer
83:58 - this dense layer you can think of it as
83:59 - a vector containing values so there are
84:02 - no filters like the convolution
84:05 - like 2d convolution here
84:08 - and finally
84:09 - we're going to add another
84:11 - dense layer which has 10 values and this
84:15 - will be the output layer of our neural
84:17 - network
84:18 - and
84:20 - we're choosing 10 here because
84:22 - in our data set the amnes data set there
84:25 - are 10 different
84:28 - classes that we can have from zero to
84:30 - nine so there are ten classes so
84:33 - again if we go back to the first uh
84:37 - the first time i spoke about our
84:39 - classification system i mentioned that
84:41 - we want to build the system that takes
84:43 - the image as an input
84:46 - and we want it to tell us at the output
84:49 - which of the ten categories so is it
84:52 - zero one or until nine
84:55 - so
84:56 - this model here reflects exactly that
84:59 - we're taking an input image and the
85:02 - output is
85:03 - a set of 10 values which will be in fact
85:06 - 10 probabilities we're getting
85:08 - probabilities because we're using this
85:11 - activation function called soft max so
85:13 - the soft max gives us 10 probabilities
85:17 - and they sum up to one
85:19 - so what we're going to do is look at
85:21 - those probabilities and look at the
85:23 - highest one and that would correspond to
85:26 - the class predicted by our model
85:30 - so this
85:31 - basically explains why we're using 10
85:34 - here and we're using
85:36 - the softmax activation function here and
85:40 - at this stage here you don't have uh
85:43 - as many options as you would have in
85:45 - these layers for example in this dense
85:48 - layer
85:48 - you can choose
85:50 - a different value here so
85:52 - 128 132 it doesn't matter you can change
85:57 - the activation to something else
85:59 - but at this level here here we are at
86:02 - the output of our layer and we know that
86:06 - we want to predict one of 10 values so
86:09 - it has to be 10 here and also we want
86:12 - those values to be probabilities so that
86:14 - they reflect what the model thinks about
86:16 - our image that's why we're using soft
86:19 - max here
86:21 - apart from this
86:23 - there's also the input layer where you
86:24 - don't have much
86:27 - choice you have to set the
86:30 - shape
86:31 - that corresponds to the shape of your
86:34 - dataset so we know that our images have
86:36 - 28 by 28 pixels so
86:39 - it has to be 28 by 28
86:42 - input we also know that our images are
86:44 - grayscale so they have only one channel
86:47 - that's why we have to choose one here so
86:50 - apart from the inputs and the output
86:52 - layers
86:53 - these layers here you can change so many
86:55 - parameters in them and each time you
86:58 - train your model and see whether
87:01 - it gives better results or not
87:03 - so with this we're actually done
87:05 - building our first neural network using
87:08 - the sequential approach
87:10 - now what we're going to do is continue
87:13 - creating the rest of our program so that
87:15 - we can make use of this model train it
87:18 - and then test it on some of the examples
87:20 - in our data set
87:23 - so now that our model architecture is
87:25 - ready
87:26 - let's look at how we basically set up
87:29 - the rest of the things so that we can
87:31 - run the training so the first thing i
87:33 - want to do here is just
87:35 - basically omit this part here and one
87:38 - thing that i like to do is just use some
87:41 - kind of switchers here so it falls so
87:43 - that
87:44 - i don't like to comment the code that's
87:47 - uh that's important and also i don't
87:50 - like to delete it so i just like to use
87:52 - this kind of approach here
87:55 - and now what we're going to do is
87:59 - the first thing we need to consider is
88:01 - that our data is in some sort of a
88:04 - a row uh manner this is how we got it
88:08 - from the load data method here
88:11 - but before we
88:14 - start to pass it through our model so
88:16 - that it can start to learn
88:17 - [Music]
88:19 - we need to normalize it so in order to
88:23 - normalize the data
88:25 - we're gonna use some
88:29 - basically
88:30 - division approach so here we're going to
88:32 - do x strain
88:34 - and usually what you would do is just
88:36 - divide it by
88:37 - 255 because our values are between 0 and
88:42 - 255
88:43 - to 255 represents white and 0 represents
88:47 - black
88:49 - and the thing is our
88:52 - data set here is an unsigned integer
88:55 - 8-bit
88:57 - data type
88:59 - before we do that before we do the
89:01 - division i mean we need to
89:04 - basically transform it into another type
89:07 - so as type
89:09 - and here i'm gonna do float 32 bits and
89:12 - why are we doing this
89:14 - is because if we don't transform it into
89:17 - this
89:18 - float 32-bit type
89:21 - what's going to happen is that the
89:22 - values that are between 0 and 255 so
89:25 - let's say
89:26 - 2
89:27 - 200 for example when you divide it it's
89:30 - gonna become zero instead of zero point
89:33 - something that's because the data is an
89:36 - unsigned integer
89:37 - 8 bits format but when we turn it into
89:40 - 32
89:41 - float
89:42 - format what's going to happen is that
89:44 - we're going to get that zero point uh
89:47 - something
89:49 - which will not be absolute zero which is
89:52 - which is exactly what we want to have
89:54 - here
89:55 - and we're gonna do the same thing for
89:57 - the
89:58 - test
89:59 - set so
90:00 - test
90:01 - as
90:02 - type
90:03 - i'm gonna do float 32
90:08 - and then divide it by 255.
90:11 - so
90:12 - again why do we do this normalization
90:15 - approach here
90:16 - uh it just it's been uh by
90:20 - experimentation
90:21 - we've seen that when you normalize your
90:23 - data the gradient moves
90:26 - faster towards
90:28 - the global minimum of your cost function
90:30 - but
90:31 - i have to say that i have done so many
90:33 - experimentations where i didn't
90:35 - normalize the data and it still worked
90:38 - okay there wasn't that much difference
90:40 - between when i normalized and when i
90:42 - didn't normalize the data but here just
90:44 - for the sake of good practices i'm gonna
90:47 - keep the normalization here
90:50 - and
90:51 - uh one thing also that we need to do is
90:55 - to
90:56 - basically make our data set in a in in
91:00 - such a way that
91:01 - our model can accept it in its input so
91:05 - as you can see the input model expects
91:07 - expects 28 by 28 by one
91:11 - and here as you can see our data set
91:14 - uh of course there are these sixty
91:17 - thousand images this does not matter for
91:19 - our model it's gonna take them
91:22 - batch by batch but
91:25 - here we see that our
91:28 - arrays are formatted in such a way where
91:30 - we only have two dimensions so 28 by 28
91:34 - but we want to have 28 by 28 by one
91:38 - so in order to remedy this we're gonna
91:41 - do
91:43 - x train
91:45 - equals mp dot expand dims so this is to
91:49 - expand the dimensions of an array and
91:52 - we're going to give it
91:54 - the same array so x strain and then
91:57 - we can use the
91:59 - axis number so here
92:03 - we want to expand the last dimension so
92:06 - we know that our array has
92:08 - here three dimensions so
92:11 - of course when they are three that means
92:12 - this is dimension zero this is one this
92:14 - is two so we can use for example
92:17 - three here
92:18 - and that would work
92:20 - but
92:21 - uh you can also do just minus one which
92:23 - means we want to add dimension at the
92:26 - end
92:28 - so here we're going to do
92:30 - x test the same way
92:32 - so let me just copy this
92:36 - and
92:37 - here
92:39 - i'm gonna do test
92:42 - so now in fact
92:44 - our data let me just maybe copy this and
92:47 - paste it again just so that you can see
92:50 - the difference
92:53 - so now our data is normalized because we
92:56 - use this
92:57 - uh
92:58 - these operations here and but also the
93:01 - dimensions have been changed so let me
93:04 - just
93:05 - clear this then run
93:07 - mnist example
93:09 - just quickly to see what we have
93:12 - differently so as you can see
93:14 - we had this
93:16 - shape for our data set before now we
93:18 - have this
93:20 - and this is
93:21 - the right shape to use with our
93:23 - architecture because again our
93:26 - architecture accepts 28 by 28 by one of
93:29 - course the first dimension that
93:31 - represents the batches it doesn't matter
93:34 - so we don't mention it here so uh it's
93:37 - not gonna cause any problems but if we
93:41 - don't have our data set in this format
93:43 - it's gonna actually pose a problem and
93:46 - maybe you will have this question of why
93:48 - don't we just remove this here
93:50 - why don't we just do this and then we
93:52 - don't need to
93:54 - expand the dimensions in fact if you do
93:57 - this what's going to happen is that the
93:59 - combo you're going to have a problem
94:01 - with this layer here because the 2d
94:04 - convolution expects a
94:06 - 4d four-dimensional tensor
94:09 - and what this means is that
94:12 - here we have
94:13 - the this tensor that represents the
94:16 - shape of the data but there will also be
94:18 - a dimension here it's hidden here it's
94:21 - not shown which represents the batches
94:24 - so we can take several images at the
94:26 - same time
94:27 - so with
94:29 - adding that dimension for the batches
94:31 - we're going to have four
94:33 - dimensions here and then the convolution
94:36 - 2d will not complain about dimensions so
94:39 - that's why we're doing this here and
94:42 - that's why we're
94:44 - expanding the dimensions here
94:46 - and
94:47 - okay let me just maybe remove this
94:50 - for now we don't need it
94:54 - and now that we have
94:57 - all of these
94:58 - uh all of our data ready to be uh passed
95:02 - through our model
95:03 - let's
95:04 - compile our model here
95:06 - and by compiling i means i mean we're
95:09 - gonna set some of the important aspects
95:11 - of the training so we're going to do
95:15 - model that
95:16 - compile
95:18 - and then inside this
95:20 - function here you have several
95:23 - parameters that you need to set so
95:25 - there's the optimizer
95:29 - and there is also the loss
95:34 - and finally
95:35 - there are the
95:36 - metrics
95:39 - so these are the three important
95:41 - parameters that you need to set
95:44 - so here the optimizer
95:47 - what it represents is the algorithm that
95:50 - we're gonna use
95:51 - in order to
95:53 - uh to optimize our cost function
95:57 - and by optimizing i mean trying to find
96:00 - the global minimum of our cost function
96:03 - so for this we have several options in
96:06 - tensorflow
96:08 - the most famous one is
96:10 - adam which we will be using but there
96:12 - are or several uh
96:15 - optimizers in tensorflow so let me just
96:18 - maybe try to
96:20 - okay sometimes it's not giving me option
96:22 - to see uh
96:24 - to see all of the parameters but
96:29 - here we can set the parameter atom
96:32 - there's also ada and there are several
96:36 - others that you can use
96:39 - so here if you go to the tensorflow
96:41 - documentation and the
96:43 - tf.keras.optimizers you see that you
96:45 - have all of these options that you can
96:47 - choose from there's the ada delta other
96:50 - grad adam so on so forth you have the
96:53 - stochastic gradient descent here
96:55 - so you have all these options that you
96:57 - can use again which one to use really
97:00 - depends on uh the case that you are uh
97:04 - you are doing and this also goes into
97:07 - the hyper parameters
97:09 - part where you for example you might
97:11 - choose adam train your model and then
97:15 - you might change that and choose for
97:17 - example an adam and you might get better
97:20 - results using this uh
97:22 - other optimizer so it's really an
97:24 - experimental approach and i again i do
97:27 - encourage you to change things and see
97:29 - what you can get with those different
97:31 - parameters
97:33 - so let me uh go back to our example here
97:38 - so here
97:40 - when you want to pass
97:41 - a parameter to this
97:44 - argument here optimizer you can just put
97:46 - it between parentheses or between
97:50 - these quotation marks here and you just
97:52 - write the name
97:53 - and you can of course
97:56 - choose any of the other ones and write
97:59 - it here
98:01 - and this is how you set the optimizer
98:03 - the second thing which is very important
98:06 - that we need to set is the loss function
98:08 - so
98:10 - for the loss
98:12 - for every task in uh in deep learning
98:15 - you have a set of loss functions that
98:18 - you can use for that specific
98:21 - task so in classification
98:24 - one of the widely used
98:27 - loss functions is
98:28 - called cross
98:32 - entropy so these are
98:34 - two different uh
98:36 - two different words cross entropy
98:38 - and this is actually a function that
98:40 - uses uh
98:42 - probabilities and
98:45 - it computes some sort of probabilities
98:47 - that
98:48 - helps penalize your
98:51 - neural network weights when they are
98:53 - when the when it predicts the wrong
98:55 - thing and also helps it know which
98:59 - values are predicted correctly so there
99:02 - is a whole
99:03 - a lot of research about cross entropy
99:05 - that you can look up online
99:07 - but
99:09 - in fact just in tensorflow you have
99:11 - three different
99:12 - loss functions that have the name cross
99:15 - entropy in them
99:18 - so here again i'm looking at the
99:20 - documentation on in tensorflow and
99:24 - if i didn't mention it before i would
99:26 - very much
99:27 - recommend looking at this documentation
99:29 - from time to time it's uh written
99:32 - in a quite understandable manner and you
99:35 - can get a lot of information from it
99:37 - so again for cross entropy if you go to
99:40 - the
99:41 - documentation you'll see that you have
99:43 - binary cross entropy you have
99:45 - categorical cross entropy and also
99:48 - you have sparse categorical cross
99:51 - entropy so all of them they have cross
99:54 - entropy
99:55 - in them so they use this
99:58 - cross entropy approach but
100:01 - each one of these three
100:03 - loss functions uses it
100:06 - differently and for us
100:09 - here we're gonna use
100:12 - categorical cross entropy and we're
100:15 - gonna use spas categorical cross entropy
100:17 - and i'll show you what's the difference
100:19 - between them
100:21 - so here
100:23 - let me start by
100:25 - using
100:26 - catigorical
100:29 - cross entropy
100:30 - and i'll explain a little bit later
100:35 - do we why would you want to use
100:37 - categorical and why would you want to
100:39 - use sparse categorical
100:43 - for now let me just finish this part
100:45 - here for compiling our model so for the
100:47 - metrics which is the last argument here
100:50 - we need to set a metric for which the
100:54 - uh basically we're going to guide our
100:58 - training
100:59 - so that our model knows that it's
101:00 - becoming better or worse so here usually
101:04 - for classification
101:05 - we would use the accuracy so the
101:07 - accuracy represents how many
101:11 - examples are we predicting correctly
101:13 - from all of the examples that exist in
101:16 - the data sets so let's say you have a
101:19 - data set of 100
101:23 - examples
101:25 - let's say images
101:27 - and when you do the prediction
101:32 - prediction
101:34 - you get
101:36 - let's say
101:37 - 88 images
101:40 - correct
101:41 - and the rest are incorrect in this case
101:44 - the accuracy would be 88 over 100 which
101:47 - is
101:48 - 88
101:50 - this means the accuracy is 88
101:53 - so this means that your model
101:55 - makes a good prediction 88 of the time
101:58 - so if now we have a thousand images and
102:01 - around 880 images will be
102:04 - correctly predicted
102:07 - so for classification this is what we
102:09 - would need as a metric
102:12 - and of course here i am using the
102:15 - usual
102:16 - values that are used in classification
102:19 - but there's a lot of advanced things
102:22 - that you can do for example you can
102:23 - create your
102:24 - uh your own loss function your own
102:26 - optimizer your own metrics and then you
102:29 - can pass it here as a parameter but this
102:31 - is a little bit advanced so for now i'm
102:34 - just gonna
102:35 - go through the steps with the usual
102:38 - values that are used in the deep
102:40 - learning community so now that we have
102:42 - compiled our model
102:45 - the only thing that's left is to
102:47 - fit the data
102:49 - into our model so for that we're going
102:51 - to call model fit
102:54 - and the fit function
102:56 - uh takes several
102:58 - uh parameters
103:00 - the first parameter is the
103:02 - x strain so the uh the images and then
103:06 - it's gonna take the y train so the
103:09 - labels corresponding to those images
103:11 - it's also going to take a batch size
103:14 - so this batch size represents
103:17 - how many images
103:18 - is our model going to see each time
103:21 - so
103:22 - here you can for example if you set it
103:23 - to one this means that we're gonna pass
103:25 - one image
103:27 - uh
103:27 - at a time to our model but
103:31 - we usually don't do this we usually
103:32 - choose a larger number of images to pass
103:35 - them through our model so here for
103:38 - example we can use 64.
103:41 - this is also one of the hyper parameters
103:44 - that you can change and see
103:46 - how your model will perform
103:49 - based on different
103:51 - and also we're gonna
103:54 - set the parameter epochs here
103:57 - and let's say i'm gonna choose
104:00 - for example
104:01 - only three epochs so that we can quickly
104:03 - do some experimentation
104:06 - and the epoch represents
104:09 - one epoch in fact represents
104:11 - that the fact that your model has seen
104:14 - all of your data set once so when all of
104:18 - your images are passed through the model
104:21 - if they're if this is done once then
104:23 - this is one epoch
104:25 - if
104:26 - your model has seen them twice
104:28 - then these are two epochs so on and so
104:31 - forth so
104:33 - basically here we're defining the number
104:34 - of times that your model is going to
104:36 - look at all of your data sets
104:40 - this is also a hyper parameter
104:43 - so
104:44 - here in fact we can keep it just like
104:46 - this and we can run the training which
104:48 - means that all of the images that exist
104:51 - in the train set are going to be used
104:53 - for training
104:56 - but
104:57 - one thing that
104:58 - that you can do in fact is use a
105:02 - validation
105:04 - split
105:05 - so
105:06 - a validation split here for example
105:08 - let's say i'm going to use 0.2 this
105:11 - means that i want to use 20
105:14 - of the train images for validation
105:18 - so again what would what does validation
105:21 - mean what what is it why is it different
105:23 - than the test set
105:25 - for example
105:26 - in fact in the when doing cross
105:29 - usually you split your data into
105:32 - the train
105:34 - the
105:35 - validation
105:36 - and the test sets split them into these
105:39 - three parts
105:40 - the train
105:42 - set will be used to train the model the
105:44 - validation will be used at the end of
105:47 - every epoch we're gonna run
105:50 - the model on the validation not for
105:52 - training but just for prediction so that
105:54 - we can see how well the model is doing
105:57 - on data that it did not see
106:00 - it did not use to train
106:02 - so these in fact these two splits
106:06 - are the ones we use to fine tune our
106:10 - our model so when i mentioned hyper
106:13 - parameters i mentioned that this for
106:15 - example hyperparameter this is a hyper
106:17 - parameter the values here are hyper
106:19 - parameters but when do you say that
106:22 - one
106:23 - or a set of hyper parameters is better
106:26 - than another set of hyper parameters in
106:28 - fact you do this using the validation
106:31 - split
106:32 - so whenever you train you test on the
106:35 - validation split
106:37 - or on the validation part and then you
106:39 - see whether that
106:42 - metric that you're using has improved or
106:44 - not so in our case the metric is the
106:46 - accuracy is the accuracy uh becoming
106:49 - better when we change the hyper
106:50 - parameters so you do one training with a
106:53 - set of training parameters
106:55 - you see the validation set is it good or
106:58 - not
107:00 - and then you change the hyper parameters
107:03 - you run the training again and you look
107:04 - at the validation
107:06 - accuracy did it become better they
107:08 - become worse
107:09 - and you keep doing uh this loop of
107:12 - experimentation until you get to a point
107:14 - where you see that you're not
107:16 - improving anymore on the validation set
107:19 - and then
107:20 - only when you're done with this
107:22 - experimentation phase that you keep the
107:25 - final model that works well on the
107:27 - validation set and then you test it on
107:29 - the test set
107:31 - so
107:33 - with this parameter here validation
107:35 - splits what we're gonna do is
107:37 - split our training set
107:40 - into two parts eighty percent of the
107:43 - training
107:44 - images or the images that exist in this
107:47 - uh
107:47 - extreme variable are going to be used
107:50 - for training and 20 of them are going to
107:53 - be used for validation
107:56 - and then we're going to keep the tests
107:58 - set here until the end when we finish
108:01 - the training
108:02 - and we're going to use it to
108:04 - evaluate our model to see how well it
108:07 - performed on images that it has never
108:09 - seen
108:10 - so
108:11 - the
108:12 - images here whether they are in the
108:14 - train set or the validation set
108:17 - the model is gonna see them at some
108:19 - point during the training but the test
108:21 - set we're not gonna use it in this
108:23 - function here which means that the model
108:25 - will never see it during the training
108:27 - and is we can
108:29 - uh we can pass that set of images to the
108:33 - model only at the end of the training so
108:36 - for example we can pass it here
108:39 - model that
108:40 - evaluate and we can give it the
108:43 - x test
108:46 - apply test and
108:48 - we can also
108:50 - choose a batch size here let's just keep
108:52 - it
108:53 - the same as before
108:55 - so
108:56 - again just to summarize quickly what
108:58 - we're doing here we're taking the
109:01 - train images so 60 000
109:03 - images we're gonna split them into two
109:05 - parts eighty percent of the images so
109:09 - eighty percent of the sixty thousand
109:10 - images is going to be used for training
109:13 - the rest which is 20 is going to be used
109:16 - for validation
109:17 - [Music]
109:18 - and
109:19 - the train set or the test says sorry
109:22 - which is the 10 000 images here are
109:24 - going to be used at the end when the
109:26 - model has finished training so
109:29 - at this point here
109:31 - this is
109:32 - model training
109:34 - once this
109:36 - line here is done then the model is
109:39 - trained and here we can do
109:42 - evaluation on test set
109:47 - this set here the x test
109:50 - is going to help us
109:51 - identify how well our model is going to
109:54 - perform on data that it has never seen
109:57 - because usually what you do is you train
110:00 - a model
110:01 - you put it in production and then you
110:03 - start testing it on new data that's
110:05 - coming from for example your users if
110:08 - you have some sort of a web product
110:11 - and those examples the model has never
110:14 - seen them
110:15 - so
110:16 - in order to get an idea of how well your
110:19 - model will perform on examples like that
110:22 - you keep this part here separate from
110:25 - the training and the validation you keep
110:27 - it until the end and then at the end you
110:30 - test your model on it
110:33 - so this is the goal of this test set and
110:36 - the the goal of splitting the
110:39 - this set here into two parts
110:41 - now we have a complete program that we
110:44 - can run and we can train our model
110:48 - and we can see how well it performs on
110:51 - train validation and test sets so let us
110:55 - do that right now let me just clear this
110:58 - and i'm gonna run our example here
111:03 - so this might take some time depending
111:06 - on your machine
111:10 - but usually it shouldn't take that long
111:13 - well in fact when i ran the code i got
111:16 - into this error here and
111:19 - in fact i wanted you to see this error
111:21 - because it's a very common error and
111:25 - uh i wanted to use it in order to
111:27 - explain to you why you would want to use
111:29 - categorical cross entropy
111:32 - or sparse cross entropy in fact this
111:34 - error is coming from uh from this
111:37 - specific detail here
111:40 - so when you have
111:42 - a data set like we have here if you use
111:45 - categorical cross entropy
111:47 - then
111:48 - in fact this loss function is going to
111:50 - expect
111:52 - your
111:53 - labels which are these ones uh the
111:56 - [Music]
111:57 - x the y train and the y test is going to
112:00 - expect them to be one heart encoded
112:04 - and if you don't want to use one heart
112:06 - encoding then you need to use a
112:09 - different loss function which is the
112:11 - sparse categorical cross entropy
112:15 - so this is a minor detail but it's very
112:18 - important
112:19 - so if you go in fact to the
112:21 - documentation
112:24 - so here in the documentation i just
112:26 - opened uh
112:28 - the two pages for categorical cross
112:30 - entropy and for sparse categorical cross
112:34 - entropy
112:35 - so for the categorical cross entropy
112:38 - here although uh
112:40 - it's not specifically mentioned here
112:43 - but in fact if you look at the example
112:45 - you see that
112:47 - this is how you would use categorical
112:50 - cross entropy these this this is how
112:53 - your labels need to be set so in fact
112:56 - this is
112:57 - one label for one image
112:59 - which is in the form of a vector
113:02 - and in that vector
113:04 - the one will correspond to the right
113:06 - class and the zeros will correspond to
113:08 - the wrong classes so if you have three
113:11 - classes then
113:13 - you need to set one to the right class
113:16 - and zeros for the rest in our case
113:20 - if we wanted to do one hot encoding then
113:24 - for example if you have
113:27 - let me just do this quick example here
113:29 - if you have
113:30 - label
113:32 - two
113:34 - then
113:34 - [Music]
113:36 - one hat
113:38 - encoding will be like this
113:40 - it will be a vector of
113:42 - 0
113:44 - 0
113:46 - 1
113:47 - then 0 0 0
113:50 - and 8 9 10.
113:52 - this will be the corresponding label for
113:56 - that
113:56 - for that image so the image contains the
113:59 - number two but your label needs to be
114:01 - like this
114:02 - and this is called
114:04 - one hot encoding of your labels
114:08 - now uh
114:09 - if in the case
114:11 - uh how we're using our data set in fact
114:14 - we're not using
114:15 - one hot encoding so our labels are just
114:17 - encoded as numbers so if it's the second
114:20 - if it's number two then the
114:22 - corresponding label is two if it's zero
114:24 - then it's zero so on and so forth we're
114:26 - not using one-half encoding
114:28 - so if you use
114:31 - categorical cross-entropy
114:33 - then you have to use one-half encoding
114:35 - which means that you have to take the
114:38 - y train y test and turn them into one
114:41 - hot encoded
114:44 - labels
114:45 - and if you don't want to do that you
114:47 - need to add the
114:49 - sparse categorical entropy here instead
114:52 - of the categorical
114:54 - cross entropy because if you go to the
114:56 - documentation
114:57 - you look at the sparse categorical
115:00 - cross entropy you see here that we're
115:03 - using labels in the format of the normal
115:06 - format
115:08 - not the one using one hat encoding
115:11 - so when doing this
115:14 - if we save this
115:16 - let me clear this again if i run my
115:19 - example now we should have no problems
115:23 - everything should be running smoothly
115:26 - and as you can see the training has
115:28 - started here and let me just stop it
115:30 - here just to show you
115:33 - uh if you were to use categorical cross
115:36 - entropy what would you have what would
115:38 - you need to do differently
115:40 - because sometimes you might have a data
115:42 - set that already has
115:45 - one hot encoding labels
115:47 - in that case
115:49 - if you just want to use them as they are
115:51 - you don't want to
115:52 - transform your labels into a different
115:55 - format
115:57 - in that case you would just use
115:59 - categorical cross entropy but if you
116:01 - have labels like this that are not one
116:04 - hot encoded and you want to turn them
116:05 - into one hat
116:07 - encoded
116:08 - what you can do is
116:10 - use
116:13 - a utility from uh tensorflow
116:16 - so here we're gonna do y train
116:18 - [Music]
116:20 - tensorflow.keras.utils.2
116:28 - categorical
116:30 - and then you would give it
116:33 - y
116:34 - the same uh array so y train and then
116:37 - you want to tell it how many classes you
116:39 - have so we have 10 classes between 0 and
116:42 - 9
116:43 - and you would do the same for the y test
116:47 - tensorflow keras
116:50 - details
116:51 - 2
116:52 - categorical
116:54 - and here i want to give it test and 10
116:57 - classes
116:58 - so now if i do this
117:01 - then in fact i'm transforming my labels
117:03 - into one hot encoded labels and in that
117:06 - case i can use categorical cross entropy
117:09 - so
117:10 - let's run the training again and see if
117:14 - this works or not
117:17 - so as you can see the training has
117:20 - started correctly with no problems
117:23 - and i hope now you understand
117:25 - differences between categorical cross
117:27 - entropy and sparse cross
117:30 - sparse categorical cross entropy and
117:32 - when to use which
117:34 - so i'm gonna wait for the training to
117:37 - finish i've only set
117:39 - the epoxy 3
117:41 - because it already gives us some
117:44 - good
117:46 - metrics here
117:47 - and it's done
117:49 - so let's go a little bit over the logs
117:51 - here and i would like to explain to you
117:54 - what these things mean
117:56 - so
117:57 - this one here the first number here 11
118:00 - seconds represents how much how much
118:02 - time we spent uh doing this one epoch
118:06 - and also this tells us the speed so
118:10 - 12 milliseconds per step and the step
118:12 - here means doing
118:14 - a full badge so we have a badge of 64
118:17 - images
118:18 - so where the model is processing 64
118:21 - images at the same time
118:23 - in 12 milliseconds
118:25 - and
118:27 - by doing that the first epoch we got a
118:30 - training loss so this loss here is the
118:32 - training loss of 0.2368
118:36 - we have an accuracy of around 93
118:40 - we have a validation loss of
118:43 - 0.0994
118:45 - and we have a validation accuracy of
118:47 - around 97
118:51 - and what this means is that
118:54 - as you remember we did this split here
118:56 - validation split so
118:59 - the
118:59 - first loss and accuracy are reported
119:02 - based on the 80
119:04 - of
119:05 - the data that we use for training
119:08 - and
119:09 - this part here for the validation is
119:11 - reported based on the 20
119:13 - that we left out for the validation so
119:16 - it's 20 of that extreme
119:19 - and after each epoch we get these values
119:22 - so that we can see the development of
119:24 - the loss and the accuracy and what you
119:27 - want to get here is a lower loss during
119:30 - the training and a higher accuracy
119:33 - and at the end this last line here we've
119:38 - actually ran it over the
119:40 - test set
119:41 - just to see how well our
119:44 - model our final model that we got here
119:46 - how well
119:48 - is it doing on
119:50 - the
119:51 - test set and here we see that we got a
119:53 - 98.36
119:56 - accuracy which is not bad on this task
120:00 - so as you can see now we have a full
120:04 - program that
120:05 - has a deep learning model
120:08 - and it compiles that model with specific
120:10 - optimizer loss metrics and then it fits
120:15 - the data into that model and when we're
120:17 - doing evaluation we're getting some good
120:19 - results
120:21 - so
120:21 - with this we have finished the
120:24 - first let's say a part of doing
120:28 - training for an image classification
120:30 - task and as you can see
120:33 - it with tensorflow it makes so many
120:35 - things easier you don't have to do a lot
120:38 - of things you just need to set the right
120:40 - parameters and prepare your data set in
120:42 - the right
120:44 - way
120:45 - so
120:45 - now that we have this uh first version
120:48 - of our program working let's see what we
120:50 - can do next
120:52 - this first model that we created and we
120:55 - trained was using the sequential
120:58 - approach here where we just stacked
121:00 - different layers
121:02 - and now let's take a look at the
121:05 - other approach that we can use which is
121:07 - the functional approach
121:09 - so first let me just maybe
121:11 - change this
121:13 - to
121:14 - sequential
121:15 - model just changing the name here
121:19 - and
121:20 - here what we want is to build the same
121:24 - exact architecture but in the functional
121:27 - approach
121:28 - so in fact to do this
121:30 - you just need to create a function
121:33 - and let's call it for example functional
121:37 - model
121:39 - and
121:40 - here you need to use
121:43 - these same
121:45 - same layers that we used in our
121:47 - sequential model
121:50 - but we're gonna use them in a
121:53 - functional way
121:54 - so let us just maybe copy them from here
121:58 - and
122:00 - just
122:01 - paste them here
122:03 - let me fix the indentation
122:08 - and in order to build a model
122:11 - using the functional approach what you
122:13 - need to do is
122:15 - basically
122:17 - define a
122:19 - set of layers and each time you need to
122:21 - pass the output of the previous layer to
122:24 - as an input to the new layer so here for
122:27 - example i would call this my input
122:31 - and then for
122:33 - the convolution 2d i need to actually
122:36 - pass my
122:38 - input
122:39 - as
122:40 - as a parameter to
122:42 - this convolution 2d and then i need to
122:45 - store this into a variable
122:48 - and i need to do this for the rest of
122:50 - the layers so each time i have an output
122:53 - of a layer i need to pass it as an input
122:56 - to the
122:57 - upcoming layer so let me just do this
123:00 - quickly here
123:04 - so
123:06 - now i have done exactly what i explained
123:08 - to you i'm just
123:10 - using each time the variable x to store
123:13 - the output of a certain layer then i'll
123:15 - pass that variable as an input to the
123:18 - next layer and i do this for all the
123:20 - layers oops i've got this one here
123:24 - and
123:25 - okay we have it here here we have it
123:27 - everywhere
123:28 - and now
123:29 - when you finish doing this
123:32 - you need to basically create the model
123:35 - where you tell it that this is the input
123:38 - and this is the output
123:39 - so the input is this and each time we're
123:42 - passing it to our layers and we're
123:45 - getting an output here which is x
123:50 - but in order to construct a deep
123:52 - learning model that you can call the
123:54 - compile function and the fix the fit
123:56 - function on it you have to
123:59 - use
124:01 - the
124:02 - tensorflow.keras.model
124:06 - class
124:08 - and here you need to give it
124:12 - inputs
124:13 - and it's going to be my input
124:16 - and also
124:17 - outputs which is going to be x
124:20 - and then you
124:22 - return
124:23 - your model
124:25 - so this is how you would build
124:27 - a deep learning model architecture using
124:30 - the functional approach so as you can
124:33 - see it's the same exact model
124:36 - it's just that we're building it
124:38 - differently
124:39 - now why would you use this approach
124:41 - rather than this sequential approach
124:43 - well in fact the sequential approach is
124:46 - rarely used when you're building
124:49 - deep learning models
124:51 - for some
124:53 - let's say complex
124:55 - tasks and even for smaller tasks i think
124:58 - it's if it's uh it's better to build
125:01 - your model in this way here because it's
125:04 - much more
125:06 - flexible you can do so many things for
125:08 - example if you have let's say two
125:10 - different inputs you can just set them
125:12 - here this will be a list
125:14 - of inputs where you just add the inputs
125:18 - to it the same thing if you have several
125:20 - outputs so it's a lot more flexible
125:24 - i think
125:25 - and also it's going to allow you to
125:27 - for example you can build one part of
125:29 - the model then create another part and
125:32 - use those two parts into
125:34 - when building a larger deep learning
125:37 - model so this is a much better approach
125:40 - in my opinion i've only seen the
125:42 - sequential approach here used in some
125:45 - tutorials online because it's easy
125:48 - and it's basically allows you to quickly
125:50 - build something
125:52 - that you can
125:53 - manipulate but
125:55 - for
125:56 - real world projects i think that using
125:59 - this functional approach is much more
126:02 - recommended so now that we have this
126:05 - we can just go to our code here
126:11 - sorry let me just close this here
126:14 - here i'm just gonna call
126:16 - my function so model
126:19 - functional
126:20 - [Music]
126:21 - model
126:23 - and then
126:24 - i'm just gonna call the same exact
126:27 - methods on it so the compile method the
126:29 - fit method the evaluate method
126:33 - and what's also good about this
126:35 - functional approach is that you can make
126:37 - this
126:38 - uh
126:39 - this
126:40 - architecture much more flexible for
126:42 - example
126:43 - by uh
126:45 - adding parameters to your function that
126:47 - you later add them here for example the
126:49 - number of filters here the
126:51 - uh the filter size here you just add
126:54 - them all as parameters here and then you
126:57 - can generate
126:59 - several models quickly you can just
127:01 - create for example a for loop
127:03 - and you create
127:05 - several models with different hyper
127:06 - parameters and then you compile them and
127:09 - fit them and compare between them so as
127:12 - you can see this would be
127:14 - a good use case for functional model
127:17 - instead of using sequential model so now
127:20 - that we have this let's
127:22 - run our code again and see if this works
127:26 - or not so let me just run this
127:33 - so the training should start and it did
127:36 - so as you can see we have just defined
127:39 - the same architecture in a different
127:42 - approach which is the functional
127:44 - approach
127:45 - and it's working
127:47 - well
127:48 - the loss is going down the accuracy is
127:50 - going up
127:52 - and let's just wait for it to finish
127:55 - this should not take long it's going to
127:58 - run the evaluation on the test set here
128:02 - and as you can see we got the
128:05 - uh
128:06 - the results here from our functional
128:08 - model and there was no problem during
128:10 - the training
128:12 - uh or the evaluation
128:15 - so this is the second approach that you
128:17 - can use to build deep learning models
128:19 - the third and last approach is by using
128:24 - or by inheriting from the
128:26 - tensorflow.kerastat model class and
128:29 - which is what we're gonna do next
128:34 - to build a deep learning model
128:36 - architecture using this third approach
128:39 - you start by
128:41 - creating a class you can give it any
128:43 - name you like so for me i'm just gonna
128:45 - call it my custom
128:47 - model
128:48 - and then you need to inherit from the
128:50 - class
128:52 - tensorflow.keras.model and in python to
128:54 - do that you just add parentheses and you
128:58 - have the class that you want to
129:00 - inherit from
129:02 - so
129:03 - here model
129:06 - let's start with the instructor here
129:10 - and here we're calling it on the uh
129:14 - the mother class which is this class
129:16 - here
129:18 - let me just maybe remove this we don't
129:21 - need to use it
129:24 - and now
129:26 - what you would do and
129:29 - in this third approach is that you need
129:31 - first to define all of the
129:34 - layers and you need to give them a name
129:37 - and then
129:38 - you would use the
129:40 - or you would
129:42 - call the function
129:44 - in fact implement the function call
129:46 - which is
129:49 - just like this and then you can give it
129:51 - your
129:52 - input
129:56 - and then
129:57 - here what you would do is you would pass
130:00 - your input
130:02 - throughout your layers here so you start
130:05 - with the first layer and then you
130:06 - continue so to make this more clear let
130:09 - me just
130:10 - do this here first we're gonna define
130:12 - all the layers and again i'm going to
130:14 - use the exact same architecture
130:17 - and just
130:18 - we're implementing it in three different
130:20 - ways so that you can compare between the
130:23 - uh three approaches
130:25 - so here i'm just gonna start by
130:30 - creating these layers and give it giving
130:32 - them names
130:36 - so here i have just done exactly that
130:40 - as you can see i call my first
130:42 - convolutional layer
130:44 - self.com1 cell.com2 so on and so forth
130:49 - and here
130:51 - when i go to my call function here i can
130:55 - start calling them
130:57 - so
130:58 - my input
130:59 - needs to be passed through this first
131:01 - layer and then the output of it needs to
131:03 - be passed to the second layer so on and
131:05 - so forth so this is what the call method
131:08 - here needs to do so
131:11 - let me just do this quickly now
131:13 - [Music]
131:15 - so i have just finished doing exactly
131:18 - that i just
131:20 - i take my input i passed it to my com1
131:25 - cell.com1 layer which is this
131:28 - convolutional 2d
131:30 - and then i get an output then i pass it
131:32 - to the second one so on and so forth and
131:35 - at the end i need
131:37 - to return x
131:40 - and
131:41 - this might look a little strange this
131:43 - approach compared to the other ones
131:45 - but this is also one of the approaches
131:47 - you can use to build custom models
131:49 - especially if they're
131:51 - much more complex than than this you can
131:53 - do so many things when you have a class
131:56 - specific for your
131:59 - for your tensorflow model
132:01 - and in fact if you've worked with
132:03 - pytorch before then this should be very
132:06 - familiar to you because
132:07 - it's very similar to what pytorch does
132:10 - in pytorch you do the same thing you
132:12 - define the layers first and then
132:15 - there is a method
132:17 - i think it's forward if i'm not mistaken
132:20 - instead of call and then you do the same
132:22 - thing you pass the input
132:25 - to the first layer and then the output
132:27 - to the next layer so on and so forth
132:30 - so
132:31 - we're doing this with in fact we just
132:34 - finished uh defining our model using
132:37 - this third approach and we can
132:40 - use it
132:41 - to
132:42 - in the practically the same manner we
132:44 - used the functional and the sequential
132:47 - model so let's see how we can do this
132:51 - so i'm just gonna comment this one here
132:56 - and now instead of using my functional
132:58 - model i'm just gonna use
133:00 - my custom model
133:03 - so just calling
133:05 - or instantiating an object from my
133:07 - custom model class
133:09 - i get my model and then i can do exactly
133:12 - the same thing i can compile my model i
133:14 - can fit my model i can evaluate my model
133:17 - and let's test this quickly here
133:20 - let me run the example again
133:25 - so
133:27 - okay it says okay now the training is
133:30 - running and as you can see uh
133:33 - we're doing the exact same thing as we
133:35 - did with the first two approaches
133:39 - and
133:40 - now you have seen the three different
133:42 - approaches used when creating an
133:45 - architecture for a deep learning model
133:47 - and tensorflow
133:49 - and you can use whatever you like
133:52 - you can also use them all three
133:54 - depending on the task that you're doing
133:56 - and depending on the
133:59 - specific circumstances
134:01 - but here as you can see we defined the
134:04 - same architecture in three different
134:06 - approaches and we were able to fit the
134:09 - data and evaluate our model and the
134:12 - results are
134:13 - very close
134:15 - so
134:16 - now
134:17 - you have all of these uh these
134:20 - tools and these approaches that you've
134:23 - learned
134:24 - and we use them on the amnest
134:27 - data set let's see now what we can do
134:29 - next
134:31 - so there are some things that i omitted
134:34 - in this first tutorial here
134:37 - i just wanted i wanted to only show you
134:40 - the main parts that you need when
134:44 - training a deep learning model
134:47 - but
134:47 - in fact you can do a lot more things and
134:50 - there are some necessary parts that i
134:52 - didn't mention here so for example one
134:55 - thing is about saving the model
134:58 - so here we're just doing the training
135:00 - and evaluating the model but we're not
135:02 - saving anything so what if i want to use
135:05 - this trained model in production what if
135:08 - i want to use it in some sort of a web
135:10 - app or an embedded application
135:12 - in that case i would need a model that i
135:15 - can take and then i can
135:18 - run in a separate script that just loads
135:20 - the model and makes predictions with it
135:23 - something else that i didn't do
135:25 - is
135:26 - saving the best model during the
135:27 - training so there's one thing you can do
135:30 - here we just saved the final model but
135:33 - if you notice here for example let's see
135:36 - if we have a good example
135:39 - uh
135:39 - yes okay so you see this second
135:42 - step here
135:43 - we have a higher accuracy than the last
135:47 - epoch
135:48 - so it's actually better to save this
135:50 - model
135:51 - that was uh finalized in this epoch
135:54 - rather than the last model
135:56 - with which was uh
135:59 - saved or it wasn't safe but which we got
136:02 - at the third epoch
136:04 - so we're not doing this now we're not
136:06 - saving the best model we're not saving
136:08 - any model in fact
136:11 - i wanted to show you this in this
136:13 - tutorial but then i thought it would be
136:15 - better if we leave this
136:17 - in the next tutorial that i'll show you
136:19 - which will represent a real world uh
136:23 - scenario because
136:25 - here with the amnest examples which are
136:28 - the hello world equivalent in
136:31 - programming
136:33 - you have the amnest data set already
136:36 - prepared for you you see we just used it
136:38 - as part of the tensorflow
136:40 - framework so we're just loading it and
136:43 - then
136:43 - we are using these
136:46 - these images and labels
136:48 - when training our model but if you're
136:51 - working on a real world
136:53 - case then maybe you would
136:56 - maybe you would have
136:58 - collected images by yourself maybe you
137:00 - went outside and
137:02 - captured some images here and there so
137:04 - in that case you need to
137:06 - create your own data set
137:09 - that is compatible with tensorflow and
137:11 - that you can use it to train a deep
137:14 - learning model that you would define
137:16 - just like we did here
137:18 - so
137:19 - i wanted to leave these
137:21 - details of saving the model during the
137:23 - training and saving the final model
137:26 - the format of saving the model i wanted
137:28 - to leave them for the next tutorial that
137:31 - we're gonna do
137:32 - so
137:33 - with this first tutorial you should have
137:36 - all the uh necessary
137:39 - steps that you would use to train a deep
137:41 - learning model for classification
137:44 - uh many of these
137:46 - or most of them in fact most of these
137:48 - uh parameters most of these things that
137:51 - we've done here we're gonna redo that in
137:53 - the next tutorial
137:55 - but just we're gonna go into maybe more
137:57 - details about specific things like the
138:00 - data set uh how to create a data set
138:04 - that you can use just like the keras or
138:07 - or just like the amnes data that sorry
138:09 - how to save the model during the
138:11 - training
138:12 - how to save the final model in the saved
138:15 - model format
138:17 - and things like that
138:18 - so for now this is it for this tutorial
138:22 - and let's take a look next at what we
138:25 - can do in a real case scenario
138:29 - so before we continue along the course
138:32 - let's maybe restructure a little bit our
138:35 - code for better readability this is
138:38 - something that you're gonna find
138:40 - yourself doing often when you're
138:42 - developing projects for uh for a company
138:45 - that you're working for
138:47 - and in
138:49 - by doing this you're actually gonna make
138:51 - your life easier in the future because
138:53 - you're gonna have all of these different
138:55 - modules that contain different parts of
138:58 - the code and
138:59 - many of them will be reusable modules so
139:02 - that you can use them in other projects
139:04 - as well
139:05 - so
139:06 - the first thing we're going to do is
139:08 - maybe move these two models the
139:11 - functional model and the
139:14 - the model that inherited from this class
139:17 - into a different
139:19 - file so for that let me just create a
139:22 - new file and maybe just call it
139:24 - deep learning
139:26 - models dot by
139:30 - and what i'm going to do here is just
139:33 - move
139:34 - these
139:35 - parts of the code
139:39 - so
139:40 - let me just move these
139:42 - ctrl x
139:44 - and
139:47 - control v
139:50 - and here
139:51 - i can just
139:53 - import the same
139:56 - modules or the same
139:59 - functions and classes that
140:01 - we used
140:03 - in our code
140:04 - and also
140:06 - i'm gonna
140:08 - import
140:09 - of course
140:10 - tensorflow because we're using it
140:13 - here
140:14 - and by this we're gonna have our
140:18 - models in a separate file and then we
140:21 - can just come to
140:23 - our main script and do for example
140:26 - from
140:28 - deep learning models import
140:31 - functional model
140:32 - and also my custom model
140:36 - so as you can see we moved large part of
140:38 - the code
140:41 - into another file and now we have this
140:44 - file here that just contains the deep
140:46 - learning models so
140:48 - maybe we can use these models in a
140:51 - different projects and we will find them
140:55 - in a separate file instead of
140:57 - finding them in this script that's
141:00 - specifically made for
141:02 - mnist data set
141:04 - another thing we can do for example is
141:06 - move this
141:08 - function here display some examples to a
141:12 - different file so maybe
141:14 - we can call it for example my
141:17 - utils
141:18 - dot by
141:20 - and
141:22 - also okay let me close this
141:24 - i'm gonna come here and just
141:28 - cut this
141:30 - and paste it
141:33 - here
141:34 - and here of course i'm gonna have to
141:36 - import
141:38 - mad
141:39 - plotlib dot pi
141:41 - plot
141:43 - as plt
141:46 - and also i need to import
141:49 - port
141:50 - numpy
141:51 - as
141:52 - mp
141:55 - so now we have this and of course
141:58 - we can import our functions
142:00 - the same way from
142:02 - my utils import
142:05 - display some examples
142:09 - and now as you can see a large part has
142:11 - been moved from this file and now this
142:14 - file is specifically made for the amnest
142:17 - data set and we're importing the
142:19 - necessary
142:21 - models and functions from
142:23 - our other files that we just created so
142:27 - i am showing to showing you this here
142:29 - just as an example that you can use
142:33 - for your projects because
142:35 - when you're working for a company and
142:36 - you're building
142:38 - ai projects machine learning models
142:41 - you're going to find yourself doing lots
142:43 - of experimentation you're going to find
142:44 - yourself reusing parts of your code so
142:47 - if you get used to this
142:49 - habit of taking uh different parts of
142:52 - the code that are reusable and putting
142:55 - them into separate files this is going
142:57 - to help you a lot uh and your future
142:59 - self is gonna thank you
143:01 - and with this uh that would be it for
143:05 - the coding of this first tutorial let's
143:09 - see what we can do next
143:12 - so let's just recap what we have seen in
143:14 - this first tutorial
143:17 - so basically we took a look at the
143:19 - amnest data set
143:21 - we saw how we can load it from the
143:24 - tensorflow data sets
143:25 - we explored that data set by
143:28 - implementing a function that can go
143:30 - through the data set and randomly choose
143:32 - some images with their corresponding
143:34 - labels
143:35 - we took a look at the tensorflow layers
143:38 - how to import them and then we saw how
143:41 - we can use those layers to build a
143:43 - neural network architecture
143:45 - in three different approaches the
143:47 - sequential way the functional way and by
143:50 - inheriting from the model class
143:53 - at the end we compiled our model and fit
143:56 - the data
143:58 - and we finished the tutorial by
144:00 - restructuring our code for better
144:03 - readability
144:05 - so with this this would be the end of
144:07 - this first tutorial let's see what we
144:09 - can cover next
144:11 - welcome to this second part or second
144:14 - tutorial in this introductory tensorflow
144:17 - course
144:18 - so
144:20 - in this tutorial
144:21 - what we want to achieve is something
144:24 - like the following
144:26 - so we're going to have a data set of
144:28 - traffic signs like the ones you see here
144:31 - and the goal would be to develop a deep
144:34 - learning model that can take an image of
144:38 - a traffic sign like this one and then it
144:41 - gives us at the output that this image
144:44 - actually corresponds to the traffic sign
144:47 - of speed limit 100 kilometers
144:50 - per hour
144:51 - and
144:52 - maybe it will not tell us exactly this
144:55 - expression here but maybe it can tell us
144:57 - that it's one and that one corresponds
145:00 - to this speed limit uh 100 kilometers
145:04 - per hour and if we try if we change the
145:06 - traffic sign we want to get the
145:08 - corresponding
145:10 - sign here so we're going to be
145:13 - developing
145:14 - and building and training this deep
145:17 - learning model
145:18 - and this will be the goal of this second
145:21 - tutorial
145:23 - the data set that we will be using for
145:25 - this tutorial is called german traffic
145:28 - sign recognition benchmark
145:30 - so this data set you can find it on
145:33 - kaggle so if you don't know the website
145:36 - kaggle it's a website that many data
145:39 - scientists machine learning engineers
145:42 - and just anyone who's interested in
145:44 - machine learning uses it because it has
145:46 - so many data sets it also has some
145:48 - competitions that you can join and you
145:51 - can even be part of a team and you can
145:54 - learn a lot by doing that
145:57 - so
145:58 - this data set in order for you to get it
146:00 - you can go to this
146:02 - link here and if it's maybe the link is
146:06 - not that clear since we see so many meow
146:09 - meow here you can just
146:11 - take the german traffic sign recognition
146:14 - benchmark
146:16 - expression here and you can
146:19 - look it up
146:20 - let me just maybe go back to make it
146:22 - clear so if you're on the kaggle website
146:25 - you're gonna go here on the search bar
146:28 - type this and look it up and it should
146:31 - be the first result
146:35 - and then you're gonna get to the same
146:37 - page that i showed you earlier
146:39 - just a quick note here so in order for
146:42 - you to get access to the data set and
146:44 - download it you need to have an account
146:46 - on kaggle it's completely free i already
146:49 - have one and i'm already logged in
146:52 - but if you don't have an account you can
146:55 - just
146:57 - create a an account for free and then
147:00 - you can
147:01 - continue with
147:02 - going to the data set page and download
147:05 - it
147:06 - so in order to download the data set you
147:08 - just click on the button download
147:12 - and then it's gonna download it to your
147:15 - own machine
147:16 - and
147:17 - once it's downloaded it's going to be a
147:20 - zipped folder like this and then you can
147:22 - unzip it in order to get
147:25 - a set of files and folders like this
147:28 - just a quick note here also
147:31 - when i was
147:32 - unzipping this folder here i realized
147:35 - that
147:36 - i think the data set is
147:39 - duplicated
147:40 - so
147:41 - many files it asked me that whether i
147:44 - want to replace them or just keep both
147:47 - versions when i was
147:50 - unzipping this file here
147:52 - i chose to
147:55 - replace them
147:56 - so that i don't have a duplicate of
147:58 - every file and every folder in my data
148:01 - set
148:02 - i think this is
148:03 - maybe a mistake that was done by the
148:06 - person who
148:08 - collected or put the data set on kaggle
148:11 - but it's not a big deal you can just
148:15 - unzip the folder and when it asks you
148:17 - whether
148:18 - there are new files and folders that
148:21 - have the same name just choose replace
148:24 - or choose do not replace for the rest of
148:27 - the data set and that way you won't have
148:29 - any duplicated folders and files
148:32 - and now that we have it here and as you
148:35 - can see i unzipped it
148:38 - we see that we have
148:39 - three files and three folders
148:42 - so the main files and maybe the main
148:45 - folders that we're gonna be looking at
148:48 - are the tests
148:49 - and train folders and also the
148:52 - test.csv
148:54 - file
148:55 - so let's first go to the train folder
148:57 - here
148:59 - so as you can see we have
149:01 - 43 folders of from 0 to 42 so 40 43
149:07 - folders and in each folder we have
149:10 - images
149:12 - that belong to the same class let me see
149:14 - if this is the large let's see i is the
149:17 - same okay
149:19 - so for example we can see here that this
149:22 - is a sign for
149:23 - the
149:25 - traffic sign that says
149:27 - there's a speed limit of 20 kilometers
149:29 - per hour
149:31 - we also have
149:32 - this data set here
149:35 - of the speed limit 50
149:38 - and we have all sorts of
149:40 - speed signs as you can see
149:43 - and what i really like about this data
149:46 - set
149:46 - is that
149:48 - the images represent real life cases now
149:51 - not like the amnest example where
149:55 - the data set is more or less already
149:57 - prepared for us
149:59 - but
150:00 - in the case of these traffic signs we
150:02 - see that these
150:05 - signs are taken into in uh different
150:09 - luminosity levels uh different light
150:12 - levels
150:13 - uh it also comes in different sizes so
150:16 - different images have different sizes
150:18 - they're not all the same
150:21 - and also if we go to the next folder
150:25 - which is the test folder
150:26 - here you can see that we have a set of
150:28 - images
150:30 - and we can't know just from the name for
150:33 - example whether this image belongs to
150:35 - class 1 2 or whatever so we can't know
150:39 - from
150:40 - just looking at the image and looking at
150:42 - the name of the image in order for us to
150:45 - know uh each image belongs to which
150:48 - class we need to go and look at the
150:51 - csv file corresponding to that folder so
150:54 - test.csv for the test folder
150:57 - and let me just open it here
151:02 - okay let me close this
151:05 - so here as you can see in the
151:08 - test.csv file
151:10 - we have a
151:12 - different lines corresponding to
151:14 - different images each line has
151:17 - these width and height of the image also
151:20 - has a roy area i guess it's a more
151:24 - tightened area around the
151:27 - traffic sign
151:28 - we also have the name of the image
151:32 - and we have the id of the image
151:35 - and these are the
151:37 - two most important
151:39 - information that we need from this so we
151:42 - need the path and we for each image we
151:46 - need to know the corresponding class
151:47 - idea so
151:49 - here let me just maybe
151:51 - open this
151:53 - close so let's go to the test
151:56 - so for example the first image
151:59 - 000.png
152:02 - it says that this belongs to class
152:05 - number 16. this is the class id so
152:09 - it's 16
152:11 - and if we want to just quickly verify
152:14 - uh just remember this is uh i think a
152:17 - traffic sign that says
152:19 - the trucks cannot pass through here
152:22 - or only for trucks i can't remember
152:24 - honestly
152:25 - and if i go to the train set and i go to
152:29 - class 16
152:31 - as you can see it corresponds to the
152:33 - right class
152:35 - so
152:37 - from with what we see here we have
152:40 - two folders
152:41 - the first one for training
152:44 - the second one for the test set the test
152:46 - set is not organized like the train set
152:51 - uh in order for us to know which image
152:53 - belongs to which label we have to look
152:55 - at the csv file
152:58 - and there's also the fact that we only
153:00 - have two sets so there's only the train
153:03 - and test set
153:05 - but in reality what you want to have
153:08 - when you're developing deep learning
153:10 - models for real life cases you want to
153:13 - have three sets you want to have a train
153:15 - set a validation set and a test set
153:19 - so there is a lot of work
153:21 - to be done before we can train a deep
153:24 - learning model on this data set
153:27 - and
153:28 - this tutorial for me represents a much
153:31 - more
153:33 - mature case of uh much of a machine
153:36 - learning project where
153:37 - basically you are using a real-life data
153:41 - set
153:42 - if someone collects it maybe uh he
153:44 - chooses to
153:45 - annotate the data set like this where it
153:48 - just puts the images in one folder and
153:50 - keeps a csv file corresponding to those
153:53 - images and their labels so as you can
153:55 - see it's not very clean not like the
153:58 - case where we had the amnes data set we
154:00 - just basically loaded it so now in order
154:03 - to build a deep learning model on
154:06 - this data set we have to
154:09 - basically
154:10 - do some cleaning and also some
154:13 - preparation of this data set and this is
154:16 - exactly what we're going to be doing
154:18 - next
154:20 - so the first thing we're going to do now
154:22 - to prepare our data set for training
154:25 - is
154:26 - to
154:27 - go to this
154:28 - train folder
154:30 - and we're going to split this
154:33 - data set here that exists in this folder
154:35 - into two different folders one for
154:38 - training and one for validation
154:41 - so basically what we want to do is to
154:43 - create some function that can go through
154:47 - all of these folders and each time
154:50 - it goes through the images in every
154:52 - folder and it takes part of them and
154:55 - puts them in a training folder and the
154:58 - rest it puts them in the validation
155:00 - folder
155:01 - so let's start by uh coding this
155:05 - and before that let me just maybe add
155:08 - a new script we're going to call it
155:12 - street
155:13 - signs
155:15 - example that buy
155:16 - [Music]
155:18 - so this will be for all the necessary
155:21 - code
155:22 - to basically
155:24 - load the data set and uh also train the
155:28 - model and evaluate it
155:30 - and here
155:31 - maybe let's first start by defining a
155:34 - function
155:35 - that's gonna split the data so let's
155:38 - call it
155:39 - split data
155:41 - and what this function is going to take
155:44 - is the path to the data so the original
155:48 - folder
155:49 - which is
155:50 - this one here we're going to take a look
155:53 - uh or we're gonna look into this folder
155:56 - here and then we want to split the data
155:59 - into
156:01 - a training folder so that to
156:04 - maybe let's call it say train and also
156:08 - path to
156:10 - save
156:11 - valve for validation
156:14 - and we're also gonna choose a split size
156:17 - and it's going to be between
156:19 - zero and one
156:21 - and i'm just going to give it a default
156:23 - value of
156:24 - 0.1 and what i want is
156:28 - for 90 of the data to be put in the
156:31 - training folder
156:33 - and the rest which is 10
156:35 - it's gonna be put inside the save for
156:38 - the the validation folder
156:40 - so here
156:42 - let me
156:43 - come here and
156:45 - the first thing we're gonna do is
156:46 - basically get the folders
156:49 - so i'm gonna use os dot
156:52 - list deer and i'm gonna give it the path
156:55 - to data
156:56 - and since we don't have this module let
156:59 - me import it here
157:01 - so what
157:02 - this uh
157:04 - line here is going to do is basically
157:06 - it's going to give us a list of all the
157:08 - folders that exist inside this directory
157:11 - here
157:12 - and then what i want to do is to
157:16 - iterate through the folders so i'm gonna
157:18 - do for
157:20 - folder
157:21 - and
157:23 - folders
157:25 - and here first i want to get the path
157:29 - to
157:30 - or maybe let me call it
157:32 - full
157:33 - path
157:34 - which is going to be the path
157:36 - or the full path to the directory so
157:39 - here
157:41 - we're gonna have this path
157:43 - and then this first command here is
157:45 - going to give us the folders now we want
157:47 - to concatenate the name of the folder
157:49 - with this
157:51 - path here in order to get the full path
157:53 - to
157:54 - this set of images for example or this
157:57 - set of
157:58 - images so here i'm gonna use
158:02 - os.path
158:04 - dot join
158:06 - and we're just gonna use
158:07 - the path to data and also i'm gonna
158:11 - concatenate that with the folder
158:14 - after that what i want to get
158:17 - is a
158:19 - list of all the paths to the images
158:22 - inside that folder so i'm going to call
158:24 - it images paths and for this i'm going
158:27 - to use the module globe
158:30 - so it doesn't exist here so let me just
158:34 - import glob here so this module is going
158:38 - to allow me to look inside a folder and
158:41 - load
158:43 - all of the
158:45 - files that exist in that folder
158:47 - depending on an extension that i
158:50 - choose
158:51 - so
158:52 - here what i want to do is
158:54 - use os dot pat dot join
158:58 - and i want to join the full pad that i
159:02 - just constructed
159:04 - and also i only want to load the
159:07 - images so
159:09 - our images let me just take a look
159:12 - quickly all of our images have a png
159:15 - extension so i only want to load png
159:17 - files
159:18 - so here
159:20 - by doing this what i'm what i'm saying
159:22 - is that i'm telling this glob module to
159:26 - give me a list of all the files that
159:29 - have extension
159:31 - png
159:32 - inside my
159:34 - inside this
159:35 - folder here full path so
159:39 - now we have a list of all the images
159:42 - inside that folder
159:45 - and what we can do now is
159:47 - we can for example to extrane
159:52 - and
159:53 - x val
159:55 - and we want to
159:57 - basically split the data set into these
160:01 - two different parts and for that there's
160:04 - actually a utility function
160:06 - called
160:07 - train
160:08 - test
160:09 - split
160:10 - which we can import from
160:13 - the
160:14 - scikit-learn module
160:16 - so here if i do
160:18 - from
160:21 - scikit-learn
160:22 - dot
160:25 - model selection
160:29 - import
160:31 - train test
160:33 - split
160:35 - so by doing this i'll be able to use
160:38 - this
160:39 - train test split
160:41 - function here and what this function
160:43 - takes
160:45 - is
160:46 - basically the images pads
160:50 - images pads and also
160:52 - it's gonna take the
160:54 - test size
160:55 - so this is going to be the fraction that
160:58 - represents the number of images that we
161:00 - want to put inside
161:03 - this
161:04 - variable here
161:05 - and for this i'm just going to use
161:08 - my split
161:10 - size which i pass here as an argument so
161:14 - what i'm what i'm saying here is that
161:17 - please split all of uh the the please
161:21 - split the list of all of the images here
161:23 - into two parts
161:25 - train and val for validation and i want
161:29 - this second part to be only
161:32 - uh this fraction of the data set which
161:34 - is uh
161:35 - if we keep the value as it is then it's
161:37 - going to be 10
161:39 - and if we call the function and we
161:40 - change this split size
161:42 - then it's going to take that exact
161:46 - fraction
161:47 - so
161:48 - now we have
161:49 - our
161:50 - train and
161:52 - validation
161:53 - pads and what we can do now is basically
161:56 - just go through them
161:58 - so first we're gonna go through for
162:00 - so for x in
162:03 - x trains
162:05 - so we're going through all of the images
162:07 - that were selected for the train set
162:11 - and the first thing we're going to do is
162:13 - get the name
162:14 - of the image and in order to get that
162:18 - we're just going to use the
162:20 - function
162:22 - os dot pad dot base name
162:25 - and we're gonna give it
162:27 - x as
162:29 - the argument here and was remember this
162:32 - x represents a full path here we want to
162:35 - get just the name of the image
162:38 - so we would like for example to get this
162:41 - only this uh five zeros five zeros five
162:44 - zeros dot png so this is what we can i'm
162:47 - gonna get as the base name
162:50 - and then we're gonna use
162:54 - basically the space name to reconstruct
162:58 - a new path
162:59 - that
163:01 - points to this path here and is we're
163:03 - going to save our image inside this path
163:06 - here so let us first do
163:11 - this
163:12 - folder i'm going to construct a
163:15 - path here os.path dot
163:19 - join
163:19 - [Music]
163:21 - and i'm gonna do
163:23 - path
163:23 - to save
163:25 - train
163:27 - and folder
163:30 - so here what i'm doing is
163:32 - uh imagine that for example i want to
163:36 - save my
163:37 - images into this
163:39 - let's create a new folder for example
163:42 - and let's call it
163:45 - [Music]
163:47 - training
163:48 - data
163:50 - and inside of this i'm going to create a
163:53 - folder called train
163:55 - and another call another folder called
163:58 - val for validation
164:01 - so
164:02 - what i'm going to do is
164:04 - take
164:06 - the images from folders like this
164:09 - and just go for example to the train set
164:12 - or the train folder and just put that
164:15 - image here
164:17 - and for now i'm just going to copy the
164:18 - images i'm not going to move them just
164:21 - so that i keep the original data set as
164:23 - it is but first here i need to add a
164:26 - folder for example one
164:28 - two three that responds to that
164:31 - specific
164:33 - label for that image and that's why what
164:36 - we're doing here is we're constructing
164:38 - this
164:39 - full path here
164:40 - so this is going to be
164:44 - this path
164:45 - and then we're gonna add
164:47 - a
164:48 - folder with the same name as the folder
164:51 - that we found in the original data set
164:54 - here
164:55 - and after that
164:58 - what we're gonna do is check
165:00 - if
165:01 - this
165:02 - folder does not exist
165:04 - so path to folder
165:07 - sorry if not
165:09 - os dot
165:10 - path dot his
165:13 - directory
165:14 - so this is gonna check whether this
165:16 - folder exists or not if it doesn't exist
165:19 - we're gonna create one what's that make
165:22 - theirs so this is to create
165:24 - that folder and i'm gonna do that to
165:28 - folder
165:30 - so this part here just checks whether
165:32 - that folder exists or not if it doesn't
165:34 - it creates that folder
165:36 - and now what we're gonna do is use the
165:40 - you the utility module sh
165:44 - util
165:46 - and i don't have it imported so i'm
165:49 - gonna import it here
165:51 - sh
165:52 - util
165:53 - [Music]
165:54 - and this module here gives me access to
165:58 - several functions
166:00 - one of them is the copy function that i
166:02 - can use and now what i can do is
166:06 - basically copy my image
166:10 - and put it inside a new
166:14 - directory that i just
166:16 - constructed here and if it didn't exist
166:18 - i would have already created it here
166:21 - and now i want to put my image inside
166:24 - this folder so
166:27 - what we can do is actually two things
166:30 - now that i'm looking at it we can either
166:32 - do path to folder and this is going to
166:35 - copy the image with the exact
166:40 - name that it has inside this folder or
166:42 - we can construct
166:44 - a complete directory with the
166:46 - name of that image
166:48 - so basically we don't need this here is
166:51 - in fact just going to take the name of
166:52 - the image and
166:54 - put it inside the new folder so this is
166:57 - going to be for the train set and we're
166:59 - going to do the same thing for the
167:01 - validation set
167:05 - so i have just added the
167:08 - part here for the validation and this is
167:10 - going to be identical to the train set
167:14 - the only thing i'm doing is looking at
167:16 - the original
167:18 - directory
167:19 - going through the folders constructing a
167:21 - new folder
167:23 - inside the train and the validation
167:24 - folders and then copying that image from
167:28 - the original
167:30 - data set or the original folder into the
167:32 - corresponding folder whether it's strain
167:35 - or validation
167:37 - and now that we have this let's test our
167:40 - function
167:41 - and i have also here
167:43 - activated the virtual environment that
167:46 - we used before which is tf2vn
167:49 - and in order to do that you can just
167:52 - point to the folder where you have
167:54 - anaconda 3 installed on your machine
167:57 - uh in order to use the script called
167:59 - activate and then point to the name of
168:04 - the
168:06 - environment that you have and also
168:08 - something that
168:10 - may be
168:11 - a quick way to do this
168:14 - let me
168:14 - just clear this first in fact if you're
168:18 - on visual studio code and if you have
168:20 - already used a specific virtual
168:23 - environment with anaconda before then
168:25 - what i have noticed is that if you click
168:27 - on the plus sign here is going to open a
168:30 - new terminal and also is going to
168:33 - activate that
168:34 - environment
168:36 - automatically so you can use this
168:38 - quick way
168:40 - to
168:40 - activate your virtual environment
168:44 - and now that we have
168:45 - this
168:46 - uh
168:47 - let me maybe first
168:50 - activate or
168:51 - save my script here and one thing you
168:54 - can notice is that
168:56 - this script or this module scalene is
169:01 - not recognized
169:02 - and
169:03 - uh just to reiterate what i showed you
169:06 - in the first tutorial if you click on
169:08 - control shift p you can choose the right
169:10 - interpreter and here i'm making sure
169:12 - that i am using the same virtual
169:14 - environment so it's tf2 vm
169:17 - and this module is not installed inside
169:20 - this virtual environment so for that you
169:23 - can do a quick pip install scaler for
169:27 - scikit-learn and this is going to
169:30 - install that
169:31 - module if it's not already installed
169:35 - and once this is done
169:37 - then here we can
169:39 - do the same thing as with before so if
169:42 - name
169:43 - equals
169:45 - main
169:45 - [Music]
169:47 - then i would like to do a set of things
169:49 - here
169:50 - so
169:52 - i'm gonna do
169:53 - uh i'm gonna
169:54 - basically choose the paths
169:57 - that i want in order for me to split my
170:00 - data set
170:01 - so the first path needs to be
170:04 - towards my
170:07 - original set which is this one so i'm
170:10 - gonna do this ctrl c
170:12 - and here i'm gonna paste it
170:15 - i'm just gonna add
170:16 - [Music]
170:17 - these
170:19 - uh backwards slashes here just so that i
170:21 - don't get any problem and if you are on
170:25 - linux machine i believe that this is
170:28 - a safe way so that
170:30 - you don't face any problems because
170:33 - between windows and linux they handle
170:35 - paths differently but if you do
170:38 - two backward slashes like i'm doing here
170:41 - then you shouldn't face any problem
170:43 - so this is the path to data and then
170:46 - path to save
170:49 - train
170:50 - so this is going to be the path where i
170:52 - want to save the
170:55 - train part so
170:57 - i want
170:58 - to save it here
171:00 - ctrl
171:02 - c ctrl v and let me
171:07 - fix these as i have done before
171:11 - very quickly okay
171:14 - and then i want
171:16 - to
171:17 - basically paste the same path here so
171:20 - path to
171:23 - save
171:24 - valve
171:26 - and
171:27 - let me paste it except that it's going
171:30 - to point to the valve folder
171:33 - which is
171:35 - this one here
171:37 - so now that we have our three different
171:41 - folders
171:42 - or paths we can call our function called
171:45 - split data
171:47 - so it's going to take
171:49 - path to
171:50 - data
171:52 - path
171:52 - to
171:54 - save
171:55 - train let me just make sure that i'm
171:57 - using
171:59 - to save train and also path
172:04 - to
172:05 - save
172:06 - valve as path
172:09 - to save val
172:11 - and for the split size we can keep it as
172:14 - it is so we don't have to call it here
172:19 - and let me just save my script
172:22 - let me clear my terminal so the goal is
172:26 - to
172:27 - copy the
172:30 - images from the original
172:32 - folder into these two folders and it's
172:35 - going to put 90 of those images in the
172:37 - train folder and 10
172:40 - in the validation folder so let me run
172:43 - this script quickly
172:45 - and see if it works without any problems
172:51 - so here
172:53 - it's gonna
172:54 - this module should be installed so there
172:56 - should be no problem here and now the
172:59 - script is actually running it's just
173:01 - that we don't see
173:03 - uh we don't see it work because we don't
173:04 - print anything but if we go here you see
173:07 - that it started to construct these
173:10 - folders
173:11 - in both
173:13 - the train and validation folder
173:15 - and in each one we should have a set of
173:18 - images like it's shown here
173:20 - so this might take a little bit of time
173:22 - because we have a lot of images
173:24 - at the end i'll show you what we get and
173:28 - all the images that were copied we're
173:30 - gonna see that they have been correctly
173:32 - copied with the correct split size that
173:35 - we chose
173:38 - so now the script has finished and the
173:41 - program has finished working
173:43 - and if we look at our data here
173:47 - we see now that in my training folder i
173:49 - have 43 folders and the same for the
173:53 - validation folder
173:55 - and in fact if we check
173:57 - quickly the number of images
174:00 - here we see that in the train set we
174:01 - have around 35 000 images
174:05 - and in the validation set
174:09 - we have around 4 000 images so that
174:12 - sounds about right so the split size
174:14 - seems to be correct
174:17 - and if we go to every every folder we
174:20 - have the exact same
174:21 - uh
174:22 - images that we had in the original
174:25 - set which was this one here
174:28 - so now we have
174:29 - our training and validation sets
174:32 - what we need is the test set
174:36 - and as you remember the test set is
174:38 - comprised of images like this and in
174:40 - order for us to know
174:42 - which label which basically which label
174:45 - corresponds to that image we need to
174:48 - look at the corresponding csv file
174:51 - so for that let us create a function
174:54 - that does this so our function is going
174:56 - to take
174:57 - as arguments the path to
175:00 - the folder and the path to the csv file
175:04 - and based on these two we're gonna
175:06 - construct a folder that contains the
175:09 - right images just like this so we want
175:12 - to order our
175:14 - test set so that it starts looking like
175:17 - this folder here or these folders here
175:22 - so let us get into this and maybe since
175:26 - this is also a utility function maybe we
175:28 - can just remove it from this main script
175:32 - and
175:32 - maybe add it to our
175:35 - utilities script
175:38 - and here
175:40 - we need the os module so import os
175:45 - so
175:46 - and also import glob
175:49 - import glob
175:52 - and
175:54 - finally the
175:56 - scikit-learn
175:58 - from
175:59 - scikit-learn dot
176:01 - model
176:02 - selection
176:03 - import
176:05 - train tests later from numbers taken let
176:07 - me check this
176:09 - train test splits
176:11 - this sounds
176:13 - correct
176:16 - and also we need the sh util
176:20 - sage
176:21 - util
176:24 - so this these are the modules necessary
176:27 - import
176:30 - so these are the modules necessary to
176:32 - run these functions and now here we
176:35 - don't have that we can also remove these
176:38 - if we want
176:39 - for now i'm just going to keep them a
176:41 - star problem and here i'm going to do
176:43 - from
176:44 - my utils
176:46 - import split data
176:49 - so this is
176:50 - a much cleaned
176:52 - a much cleaner script
176:54 - and now let's
176:56 - maybe do the same for the test set as i
176:59 - mentioned so we want to build this
177:01 - function that orders the test set so
177:05 - let's call it
177:06 - uh or maybe let's just code this
177:08 - straight in the utilities
177:12 - script here so i'm going to define a
177:14 - function called
177:16 - order test set
177:18 - and what this function is going to take
177:21 - as i mentioned
177:22 - the path to the images and also
177:26 - that to csv file
177:28 - [Music]
177:30 - or just csv is clear
177:32 - and here what i want is to construct a
177:36 - dictionary that basically
177:38 - has the name of the image as
177:42 - uh
177:43 - as the key and also the corresponding
177:45 - label
177:46 - as
177:48 - the as the value
177:54 - so let's start by defining
177:57 - our dictionary
178:00 - and by the way this dictionary here is
178:02 - just going to help us keep
178:05 - track of the data set later if we want
178:07 - but it's not really necessary for us
178:09 - when we're just ordering the test set
178:12 - i just prefer to do this so that i have
178:15 - or i could have some sort of
178:19 - a data structure that contains my image
178:22 - paths and also their corresponding
178:24 - labels
178:25 - but for you it's not
178:28 - it's not really necessary for
178:30 - our ordering
178:32 - part because as you remember we just
178:34 - want
178:36 - to go through these images
178:39 - and just order them
178:41 - like we have here
178:43 - so here let me start by
178:46 - creating a try block and what i'm going
178:49 - to do here is to
178:52 - open my csv file
178:54 - so path
178:56 - to csv
178:57 - and the mode is read i don't want to
179:01 - write
179:02 - this inside this file i just want to
179:04 - read
179:05 - and i want to open it as csv file
179:09 - and then
179:10 - i can create a reader
179:12 - and it's going to use the module csv
179:15 - the reader
179:16 - and since we don't have the module csv
179:19 - we can import it here
179:23 - and just maybe a quick note here
179:26 - if you see me using module that's not
179:28 - installed inside your virtual
179:29 - environment then
179:31 - it's very easy to install any module you
179:33 - want you just run pip install the name
179:36 - of that module
179:38 - so here i'm gonna use
179:41 - this function or this method here
179:43 - and i'm gonna give it my csv file
179:46 - [Music]
179:48 - and also i'm gonna use
179:50 - i'm gonna choose the delimiter to be
179:53 - a comma here and why comma because
179:57 - inside my csv file you see that these
179:59 - elements are separated using a comma
180:04 - and now
180:06 - what i want to do is
180:08 - basically go through all the rows that
180:10 - exist in this reader because this reader
180:13 - is going to contain
180:15 - each row inside my csv file
180:18 - including including in fact this first
180:21 - row here that only contains information
180:24 - so only the headers which we don't need
180:28 - so we need to make sure that we don't
180:31 - use that information in that first row
180:34 - so that's why we're gonna do
180:36 - for i row and
180:38 - enumerate
180:40 - reader
180:42 - and the first thing i'm going to do is
180:44 - check if
180:46 - i'm looking at the first row and if i am
180:49 - i'm just going to continue which means
180:51 - that i don't want to use any information
180:53 - in that row i just want to go to the
180:55 - next one
180:56 - and for the rest of the rows what we're
180:59 - going to do is first get the image name
181:03 - and for that what we can do is use our
181:07 - row
181:08 - and in fact our row is going to contain
181:12 - all of the elements inside that row so
181:15 - it's going to contain this value then
181:18 - this and this this and you can access
181:20 - them using the correct index so row 0 is
181:23 - going to access this
181:25 - value here and row
181:28 - minus 1 for example is going to access
181:30 - the last
181:31 - element which is the path to the image
181:35 - so here what i want to do is
181:37 - get the image name so for that i'm gonna
181:40 - get the final or the end value inside
181:44 - that row
181:45 - and remember that
181:48 - each image here this is how the data set
181:51 - was constructed so we have we don't just
181:53 - have the name of the image we also have
181:55 - this test
181:56 - and forward slash next to it so we don't
181:59 - want it we just want the name of the
182:02 - image so for example the first one would
182:04 - be zero zero zero zero zero dot png we
182:06 - just want this we don't want this part
182:09 - so what we what we're gonna do here is
182:12 - since this is a string
182:15 - we're gonna
182:16 - use the method replace and i want to
182:20 - replace
182:22 - this string here with an empty string
182:25 - this means that
182:27 - we're gonna take
182:29 - this
182:30 - full
182:31 - information we're gonna remove this and
182:34 - we're just gonna keep the name of the
182:36 - image
182:37 - and the second thing we want to get is
182:40 - the
182:40 - label
182:42 - so for the label
182:44 - this is going to be row
182:47 - minus 2 and that's because this is the
182:51 - second element starting from the end so
182:54 - this class id is the second element from
182:56 - the end or it's zero one two three four
183:00 - five six sixth element so
183:04 - we're gonna
183:05 - use this or you can do just this
183:09 - for me i think this is much cleaner -2
183:12 - because now i know just from the end i'm
183:15 - just going to look at the second value
183:18 - there
183:19 - and then what we're going to do is
183:21 - construct a path
183:24 - to
183:25 - folder and this is going to be a path
183:28 - that
183:29 - uh
183:30 - [Music]
183:31 - that is constructed using the path to
183:34 - the images and also the label so add a
183:37 - join
183:38 - that
183:40 - two images
183:42 - and also
183:43 - label since it's a string
183:47 - and then i'm gonna check if
183:49 - this path does not exist
183:52 - that path that is directory
183:55 - path
183:56 - to folder if it doesn't exist i'm gonna
183:59 - create it
184:01 - and
184:03 - here
184:04 - i'm gonna do os dot
184:07 - make deers
184:09 - path
184:10 - to folder
184:12 - so this is
184:14 - exactly what we did in the previous part
184:17 - so i'm just redoing it here
184:20 - and now what i want is
184:22 - to move my
184:24 - image
184:25 - from the original
184:28 - set so here
184:30 - from the test set here i want to move it
184:33 - into this new folder that corresponds to
184:36 - the right label and you'll see in a
184:39 - minute what i mean by this
184:41 - so here i'm gonna do
184:43 - image
184:46 - full path
184:49 - os.path dot join
184:52 - path
184:53 - to
184:55 - images
184:57 - image name
185:00 - so i'm constructing a full path and then
185:03 - i can do sh
185:05 - util dot move
185:08 - you can either copy or move the images i
185:11 - showed you before
185:12 - in the previous function here we
185:14 - we copied it in this one split data and
185:17 - now we're just gonna use the utility
185:20 - function move
185:21 - so
185:23 - for this we're gonna move the image so
185:26 - because we just got the full path to
185:28 - that image and we want to move it into
185:31 - the right folder which is path to folder
185:37 - and
185:38 - this would be it here
185:40 - i'm gonna use the
185:43 - accept command
185:45 - so that if we can't open
185:47 - the csv file
185:49 - i'm gonna get a message here that lets
185:51 - me know that we couldn't do that so for
185:53 - that i'm just gonna do
185:55 - print
185:56 - and for example i'm gonna use
185:59 - the info class
186:01 - and i'm going to write
186:03 - error
186:04 - reading csv file
186:08 - and if everything
186:10 - goes
186:12 - fine
186:13 - at the end we're gonna
186:14 - return
186:16 - test data
186:18 - well in fact since we're not using the
186:21 - test data here we're not constructing
186:23 - anything let me just maybe remove it
186:27 - because
186:28 - it's not going to add a lot of
186:30 - information for us
186:31 - so i'm just going to save this i'm going
186:33 - to open the csv file read the necessary
186:36 - information move the
186:38 - images to a new folder that responds to
186:41 - their labels
186:43 - and
186:44 - with this we will have
186:46 - our images
186:48 - in the right order
186:50 - and now here what i'm going to do is
186:53 - import my function so this order test
186:57 - set
186:59 - and again i'm going to use that
187:02 - basically
187:03 - trick that
187:05 - i use
187:06 - false
187:08 - so that i deactivate parts of my code
187:13 - and now we're gonna use or we're gonna
187:16 - use our function that we just
187:18 - constructed and remember we're gonna
187:20 - have to give it the path to the images
187:22 - and path to the csv so i'm gonna do path
187:26 - two images
187:27 - and this is going to be
187:31 - this one here
187:32 - ctrl
187:33 - c
187:35 - ctrl
187:36 - v and let's go quickly
187:41 - to our path here
187:45 - and also we're gonna have to give it the
187:47 - path to csv
187:50 - and this is going to be
187:54 - this one here
187:55 - in fact for the test we can just click
187:59 - shift
188:00 - and then copy path
188:04 - and we're going to get the full path
188:05 - like this
188:07 - so now we have
188:08 - our path to the images we also have the
188:11 - path to the csv file and then we can
188:14 - call our
188:16 - order test set function
188:18 - and this function is going to take
188:21 - that to
188:23 - images and also path to csv
188:28 - so if this function works correctly and
188:31 - works as it's intended to do then now
188:34 - what we should have is a set of folders
188:37 - here that contain the right images we're
188:39 - gonna move these images to their
188:41 - corresponding folders
188:43 - so let me
188:45 - everything is saved okay let me run the
188:48 - same script again
188:52 - and again this might take a little time
188:54 - because
188:55 - we have a lot of images but if we take a
188:58 - look at our folder as you can see it has
189:01 - created all of these folders and now
189:04 - it's moving the images you see their
189:05 - numbers going down it's moving them to
189:08 - the right folder
189:10 - and with this
189:12 - now we have our data set
189:15 - in the correct format
189:18 - and in fact when we added just a quick
189:21 - note here when we added
189:24 - the
189:25 - part of
189:27 - replace here it was necessary to add
189:30 - this part because
189:32 - here we have that
189:35 - test part as
189:37 - part of the image path and if we didn't
189:39 - do this it would have given us an error
189:43 - and now we have our data set for the
189:45 - test set correctly uh
189:48 - presented correctly ordered and now we
189:51 - have a set of
189:53 - data
189:55 - or a set of folders that correct that
189:57 - contain our data in a very good format
190:00 - that we can use for training and testing
190:03 - our model
190:05 - and with this we have our data set ready
190:08 - let's see what we can do next for
190:11 - building our deep learning model and
190:12 - doing all the fun stuff for deep
190:15 - learning
190:17 - let's start creating our deep learning
190:19 - model
190:20 - so
190:21 - that we can fit our
190:23 - traffic signs
190:25 - data set that we just ordered and
190:28 - prepared
190:29 - so for that i'm gonna
190:31 - open my deep learning models file
190:35 - as you remember we have created this
190:36 - file where we put all of our deep
190:38 - learning models in it
190:40 - and
190:41 - i'm just gonna add at the end
190:45 - i'm gonna create a new function
190:48 - for our new deep learning model so in
190:50 - the previous tutorial i showed you for
190:53 - the amnes data set how to create a deep
190:55 - learning model using three approaches
190:57 - sequential way functional way and by
191:00 - using
191:01 - a class that inherits from the model
191:04 - class but for this example since i have
191:07 - already shown you the other three
191:08 - approaches i'm just gonna use one
191:10 - approach which is the functional way so
191:13 - here i'm gonna create a new function
191:16 - for my model i'm gonna call it
191:19 - street
191:20 - signs model
191:23 - and what my function is going to take
191:26 - is the
191:27 - number of
191:29 - classes as a parameter
191:32 - and now let's start building our deep
191:35 - learning model
191:36 - so one thing to notice is that between
191:40 - the amnes data set and the
191:42 - science data set
191:45 - so for the
191:46 - science data set we have an rgb
191:50 - we have rgb images so it's uh
191:53 - we see we have blue
191:56 - red we have all colors unlike the amnes
191:58 - data set which was grayscale
192:01 - data set
192:02 - so now we need to take this into
192:04 - consideration because when you have an
192:06 - image that's
192:08 - that has a
192:09 - red blue and green this means it has
192:12 - three channels if it's just
192:15 - different layers of gray scales then in
192:18 - this case it has only one channel
192:21 - so why i'm mentioning this because for
192:24 - our first
192:26 - layer here which is the output layer
192:28 - we're going to use as before the
192:31 - input
192:32 - layer that's imported here
192:35 - and we're gonna have to give it a shape
192:40 - so this shape here is gonna represent
192:42 - the
192:43 - width height and also the number of
192:46 - channels for our images
192:49 - so when looking at these images we see
192:52 - that most of them are almost squared
192:56 - shapes and here i checked a few
193:00 - images
193:01 - just to see the size and as you can see
193:04 - this is 44 by 45 almost a square and
193:07 - even the largest ones are still
193:10 - in
193:11 - squared form
193:13 - and here we can see 80 by 84 almost
193:17 - square as well and the same thing goes
193:19 - for all of the
193:20 - images in our data set
193:23 - so
193:24 - since these are
193:26 - small images relatively small and
193:28 - they're squared
193:30 - i thought that using a size 60 by 60
193:35 - would be a good choice
193:36 - because i've seen some images that has
193:39 - that had width and height
193:41 - smaller than 60 and some of them a
193:44 - little
193:45 - higher than 60 so 60 by 60 is
193:50 - an acceptable choice although you can do
193:53 - something which sometimes i do which is
193:55 - going through all of the images in the
193:57 - data set computing the mean of the width
194:00 - and the height and maybe even the median
194:02 - and by looking at those values you can
194:04 - have an idea about where the widths and
194:08 - heights of the images in your data set
194:10 - are lying so in that case you can
194:14 - basically choose a good value for your
194:18 - width and height and for your input
194:21 - model like we're doing here
194:23 - so here i'm going to choose 60 by 60 and
194:27 - since we have rgb images i'm going to
194:29 - choose three which is going to be
194:30 - different than the first model where we
194:33 - had one
194:35 - and then since we have this we're just
194:37 - going to do the same thing as we did for
194:40 - the first model for the mnist data set
194:43 - and i'm just going to do this quickly
194:45 - here
194:47 - so i have used the
194:50 - the layers that we used before which is
194:53 - convolution
194:54 - max pooling batch normalization and i
194:57 - use them in these blocks as you can see
194:59 - these are basically similar blocks
195:03 - each time i use a convolution followed
195:05 - by max pool 2d then batch normalization
195:09 - and here i have actually
195:12 - i wanted to show you the difference
195:14 - between
195:15 - a layer called flatten and the global
195:18 - average pool 2d layer
195:20 - so first of all let me import this layer
195:24 - here so it's flattening
195:27 - so there's no problem
195:29 - and also
195:31 - let me get
195:32 - the model
195:35 - the model
195:37 - function from
195:38 - okay let's
195:40 - find them here
195:42 - it should be in the
195:44 - [Music]
195:45 - okay i can't see it
195:49 - okay in that case let's just go here
195:52 - and do from
195:54 - tensorflow.keras
195:59 - import
196:00 - model
196:02 - so this is what we're going to use here
196:05 - so here i have commented this part
196:08 - this is the same
196:10 - layer that we used previously with the
196:12 - amnes data set
196:13 - and i told you that you can also use the
196:16 - flatten layer here which is just going
196:19 - to flatten all of the
196:22 - uh the values that are coming from the
196:24 - previous layer so in this case the batch
196:26 - normalization
196:28 - and what i wanted to do is to
196:30 - basically
196:31 - build this model and show it to you and
196:34 - then we're gonna change this
196:37 - layer to global average pool 2d
196:39 - and i'm going to show you the new model
196:42 - and then we're gonna look at the
196:44 - difference between the two
196:47 - so here
196:48 - uh
196:50 - basically we have our model and we can
196:53 - import it from here so
196:57 - from
196:58 - deep learning models
197:00 - import
197:01 - street signs model and we can use it
197:04 - here
197:05 - and just something that i also do from
197:08 - time to time when i'm doing
197:10 - experimentations such as these ones
197:13 - sometimes even in my
197:16 - scripts that are not used in the main
197:19 - script so these are scripts that just
197:21 - contain some utility functions and
197:23 - classes just like this script here
197:26 - sometimes even in these scripts i do the
197:30 - i create
197:32 - basically part of my code
197:36 - where
197:38 - i can test things straight inside this
197:41 - script so for example now what i wanted
197:43 - to show you is
197:45 - this model we're going to build it with
197:46 - this layer flattened layer and then
197:48 - we're going to build it with the global
197:50 - average pool 2d layer and we're going to
197:52 - see the difference there
197:54 - so here i'm gonna do
197:56 - model equals
197:58 - street signs model and for now i'm just
198:00 - gonna give it
198:02 - uh whatever i want since this is not the
198:05 - model that i'll be using with the data
198:07 - set this is just for testing purposes
198:09 - and what i want to do is to call
198:12 - the
198:14 - method summary
198:16 - and this method is going to show us
198:18 - the model architecture the different
198:21 - layers inputs and outputs shapes so this
198:24 - is going to help us get an idea of how
198:26 - our
198:27 - model looks like
198:29 - so here
198:30 - let me run this
198:33 - python
198:33 - [Music]
198:35 - deep learning models dot by and as you
198:37 - can see the the goal of these of this
198:40 - part here this is gonna help us for
198:43 - example when we're doing tests like i'm
198:45 - gonna show you in a minute we can just
198:47 - call this script here but if i import
198:50 - this script in another script so for
198:53 - example here i am importing this
198:56 - function from my
198:58 - script here in this case this part of
199:01 - the code will not be called
199:03 - so this is a good way to separate parts
199:06 - where you just want to test something
199:07 - quick and also the parts where you want
199:10 - to reuse them in other scripts
199:13 - so with this let me run this quickly
199:16 - here
199:18 - and let me maybe
199:21 - put this like this
199:24 - so this is
199:26 - the architecture of our deep learning
199:28 - model as you can see the the input is 60
199:31 - 60 by 3 and also we have
199:35 - this first
199:36 - uh value here represents the batch size
199:39 - so none means that it can be any batch
199:41 - size we want and then there is the
199:43 - convolution 2d
199:45 - the max pooling and so on and so forth
199:49 - and when we come at the end here
199:52 - we have the flattened layer as you can
199:54 - see what the flattened layer has done is
199:56 - that it took all the values from the
199:58 - previous layer so here we have
200:01 - uh basically a some sort of a cube where
200:04 - you have five by five and it has a depth
200:06 - of
200:07 - 128
200:08 - and what it did is that just took all of
200:11 - the values and put them in one vector
200:13 - that's why we get 3200 because it's
200:16 - equal to 5x5
200:19 - by 128.
200:21 - now
200:22 - if let me let me change this to the
200:25 - global average pooling instead and i'm
200:28 - gonna comment this
200:30 - so let me
200:32 - run the same script again
200:34 - [Music]
200:35 - and also enlarge this part here
200:39 - now
200:40 - when we come to the layer here
200:43 - so before you see we had the flattened
200:45 - layer
200:46 - third from the last layer so this is we
200:50 - changed it with the global average
200:51 - pulling 2d and now you see we don't have
200:54 - 3 thousand
200:55 - and two hundred
200:57 - because the global average pooling 2d
200:59 - what it does is that it actually
201:01 - computes the average in these
201:04 - uh in
201:05 - these windows here so imagine you have a
201:08 - cube where it's 5 by 5 100 by 128 so
201:13 - every 5 by 5 will compute the average
201:16 - there so at the end we only we're only
201:18 - left with 128 values
201:21 - so this is the difference between those
201:24 - two
201:24 - layers i wanted to
201:26 - show you how
201:28 - basically reflect in the architecture
201:31 - and whether you should use one or the
201:34 - other it's actually one of the things
201:37 - that you can experiment with just like i
201:39 - mentioned in the first tutorial
201:41 - when you're doing deep learning machine
201:43 - learning in general you're going to be
201:44 - doing lots of experimentation so this
201:46 - could be one factor of your
201:48 - experimentation where you change these
201:51 - two different layers and see which ones
201:54 - uh which one gives you the best results
201:58 - so now we have our architecture ready
202:02 - and we can
202:03 - call it from our main scripts here and
202:06 - we can compile the model and fit the
202:08 - data so we're going to be doing this
202:10 - next
202:13 - in fact before we
202:16 - compile our model and fit the data we
202:18 - have to create what's called
202:21 - data generators
202:23 - so
202:23 - data generators are actually going to
202:27 - take the images from our data sets
202:31 - folders so as you remember we have
202:34 - train and validation
202:36 - folders
202:38 - and we also have the test folder that we
202:41 - organized
202:43 - so
202:44 - now
202:45 - we're going to use some uh basically
202:48 - tensorflow utilities that help us
202:50 - achieve this
202:52 - very easily which is
202:54 - one of the main points of tensorflow
202:57 - i've been using tensorflow for some time
203:00 - and
203:01 - every
203:02 - basically with every release there are
203:04 - lots of
203:05 - functionalities new features that make
203:08 - your
203:09 - building the model uh preparing the data
203:12 - set makes all of this a lot easier
203:15 - so here i'm going to create a utility
203:17 - function again i'm inside my
203:21 - myutils.by
203:22 - file which i use to add all types of
203:26 - utility function that i might use in the
203:29 - future so
203:30 - here i'm gonna define a function i'm
203:33 - gonna call it create
203:35 - generators
203:38 - and basically my function is gonna take
203:41 - uh some arguments so the first argument
203:44 - is going to be the batch size i want to
203:46 - be able to pass the batch size to
203:48 - as an argument to my generators and also
203:52 - i'm going to pass the train train
203:55 - data path
203:57 - the validation data path and also the
204:01 - test data
204:03 - path
204:04 - so as you can guess we're going to
204:06 - create
204:07 - generators for each part of our data set
204:11 - so the first thing we're going to do is
204:13 - create a preprocessor
204:15 - so
204:17 - let me just define it here
204:20 - so this preprocessor is going to
204:23 - basically be used in order to
204:25 - pre-process our data before it's fed to
204:29 - our deep learning model
204:31 - so for this we're going to use a class
204:34 - from tensorflow which is the
204:37 - image data generator class so let me
204:40 - just
204:41 - import it here first
204:44 - so
204:45 - from
204:46 - tensorflow
204:47 - that
204:48 - keras that
204:50 - preprocessing
204:52 - that image
204:56 - import
204:59 - image data generator
205:02 - and here we're gonna be using this image
205:05 - data generator
205:07 - so i'm gonna call
205:08 - my
205:10 - class here
205:11 - [Music]
205:12 - and
205:14 - here in fact if you look at this class
205:17 - image data generator you're gonna see
205:18 - that you have
205:19 - many different transformations that you
205:21 - can apply
205:22 - for now let's just not worry too much
205:24 - about them for now i just want to focus
205:26 - on one thing which is the rescale
205:30 - parameter and the rescale parameter is
205:33 - gonna basically rescale our data so it's
205:36 - going to rescale our images and here
205:39 - what i want to do is
205:43 - choose a value that will be multiplied
205:47 - with our data set so that it's rescaled
205:51 - so i want basically to divide the values
205:55 - of my
205:56 - pixels by 255 which is the maximum
205:59 - possible value
206:01 - in rgb images so here i'm just going to
206:04 - choose 1
206:06 - over
206:07 - 255
206:10 - and what this means is that
206:12 - i want my preprocessor to be used i'll
206:15 - show you in a minute how we're going to
206:16 - use it but i want it to be used to
206:19 - pre-process my images before they are
206:22 - passed through
206:23 - my deep learning model
206:25 - so here i'm going to create my
206:27 - generators so i have
206:30 - i need three generators so train
206:32 - generator
206:34 - is going to be the first one
206:36 - and for this i'm just gonna use my
206:39 - preprocessor
206:41 - and i'm gonna use a utility function
206:44 - called flow
206:47 - from
206:49 - directory
206:50 - so this is a very helpful function that
206:54 - you can use
206:55 - and in fact what it does is that
206:58 - it takes a path to your folder so for
207:01 - example for the trained data we're gonna
207:03 - do
207:04 - uh
207:05 - that
207:05 - or sorry what did i call it train data
207:08 - path
207:09 - so train
207:10 - data path
207:12 - and then what it's going to do is just
207:14 - going to look at our
207:17 - folder
207:18 - so for example for the train
207:20 - data path folder and you're just going
207:22 - to look at all the folders that exist
207:25 - within that directory and it's gonna
207:27 - suppose that each folder contains
207:30 - images that belong to one class so that
207:33 - specific class
207:35 - so
207:36 - this means that our generator is gonna
207:38 - automatically know that all of the
207:40 - images belong that exists inside this
207:42 - folder belong to the same class same
207:45 - thing for this folder and for the other
207:48 - folders as well so this is going to help
207:51 - us immensely we don't need to
207:53 - specifically build the data set where we
207:55 - say
207:56 - this image has this label in fact with
207:59 - this utility function tensorflow is
208:01 - going to help us do that automatically
208:04 - so
208:05 - other
208:06 - parameters that we need to give to this
208:08 - utility function as the
208:11 - class mode
208:12 - so for the class mode i'm gonna use
208:16 - categorical
208:19 - and for the
208:21 - target size i'm gonna use 60
208:25 - by
208:26 - 60
208:28 - so this means that i want all of my
208:31 - images to be resized to 60 by 60 and for
208:34 - the categorical
208:36 - as i mentioned it in the first tutorial
208:39 - if we use categorical here we have to
208:41 - also use categorical cross entropy when
208:44 - we are compiling our model we can also
208:47 - use
208:48 - uh
208:49 - sparse let me just check here if it's
208:52 - maybe uh
208:54 - shown here class mode one of it's either
208:56 - categorical binary or sparse so if we
208:58 - use sparse then we need to use
209:01 - uh sparse
209:03 - labels if we choose categorical then
209:05 - this means that our labels need to be
209:07 - one heart encoded
209:10 - so let's look at the next
209:13 - parameter so here we're gonna choose
209:15 - color mode to be
209:18 - rgb because my images are colored images
209:23 - uh also there is a parameter called
209:26 - shuffle that i want to set to true this
209:29 - means that
209:30 - in each epoch
209:33 - or in each batch
209:35 - my images will be shuffled so that
209:37 - between two epochs basically the order
209:40 - of the images will not be the same this
209:42 - kind of
209:43 - uh
209:44 - randomness helps our model be more
209:47 - generalized and learn
209:50 - features and ignore that order between
209:52 - the images because we don't want our
209:54 - model to learn that
209:57 - and finally the batch size we're gonna
209:59 - give it the batch size which we are
210:02 - passing here as a parameter
210:04 - so this will be for the train generator
210:07 - and we're going to be doing exactly the
210:09 - same thing for the validation set and
210:12 - for
210:13 - the test set the only thing that's going
210:15 - to change is
210:18 - the
210:19 - the path and maybe for the test set we
210:22 - can set this to false because we don't
210:24 - need
210:26 - we don't need to shuffle the data when
210:27 - we're just testing so let me do this
210:30 - quickly now
210:31 - [Music]
210:32 - so i have finished
210:34 - creating generators for my
210:37 - different folders so for the test data
210:40 - i'm using this approach the same thing
210:43 - for the validation set and for the test
210:46 - set
210:46 - and as i mentioned the only difference
210:49 - is that for the validation set of course
210:51 - i'm using the
210:52 - validation images for the test set the
210:54 - test images
210:56 - and i'm just returning these generators
210:58 - here i also
211:01 - set shuffle to false for validation and
211:04 - for test because it doesn't matter that
211:07 - much for when we're validating on or
211:09 - when we're testing our model whether we
211:12 - have
211:13 - that basically a
211:15 - randomness or not that randomness
211:18 - matters much more when we're doing the
211:20 - training which is why we're setting
211:22 - shuffle to true for the train generator
211:25 - so now we have our generators ready what
211:28 - we need to do now is to
211:30 - use our function so that we have our
211:32 - data set ready in order to
211:36 - start training our deep learning model
211:40 - so let's instantiate first our
211:43 - generators
211:45 - and here let me just
211:47 - maybe
211:49 - deactivate this part of my code because
211:51 - i don't need it
211:54 - of course you don't have to always
211:56 - follow what i'm doing here you can just
211:58 - remove these parts because
212:00 - we don't need them anymore so we split
212:02 - the data we ordered to test
212:04 - the test set so we don't need this these
212:07 - parts but for now i'm just going to keep
212:09 - them i might delete them next but they
212:12 - will not have any effect on what we're
212:14 - going to add here
212:16 - so
212:17 - first i need to import
212:20 - my
212:22 - function that creates generators and
212:25 - then i have to use
212:27 - i have to set the paths to my
212:30 - train and validation folders so they
212:32 - will be
212:34 - these folders here so
212:37 - let me just put this here
212:42 - in fact let's just delete these
212:45 - they're not they're just going to be
212:48 - taking some space
212:51 - and here since i have
212:54 - the train
212:55 - folder the validation folder i only need
212:58 - to add the
212:59 - path
213:01 - to
213:05 - test
213:06 - and here i'm just gonna maybe change the
213:09 - name so that
213:10 - because we're not gonna be saving
213:12 - anything in these folders
213:15 - and here i'm gonna set it to my test
213:19 - folder
213:21 - so my test folder is
213:24 - this one so i'm gonna copy this path
213:27 - [Music]
213:28 - paste it
213:29 - then
213:31 - i'm just gonna
213:33 - add my
213:36 - backward slashes here
213:41 - so now we have all of our three pads
213:44 - and i can use my
213:47 - create generators
213:49 - function and it's going to take a batch
213:51 - size let me maybe set a batch size here
213:55 - so
213:56 - i'm going to choose a batch size of 64.
213:59 - now this is also again another parameter
214:02 - you can play with you can choose
214:03 - different values i recommend you choose
214:06 - something like
214:07 - you know a multiplied number of two so
214:11 - you choose for example 2 4 8
214:14 - 16 32 64 so on and so forth
214:18 - and here i'm going to keep it
214:20 - 64 and you might face a problem sometime
214:24 - when the
214:26 - batch size is too large for example
214:28 - let's say you choose 512
214:30 - maybe the training will not start and
214:32 - you're gonna get an error where it says
214:34 - oom which means out of memory which
214:37 - means that you don't have enough memory
214:39 - to load all of those images at once so
214:42 - if you face that error i i suggest you
214:46 - decrease this number here and it should
214:49 - work fine
214:50 - so
214:51 - let's go here and pass
214:54 - our
214:55 - parameters so
214:57 - path
214:58 - to
214:59 - train
215:00 - that to well and path to
215:04 - test
215:05 - and of course let's go to our function
215:08 - just to check we're going to get these
215:11 - as outputs so let me maybe just copy
215:13 - them so that we can go quickly here
215:17 - so now with this i can generate
215:20 - my or i can create my generators using
215:24 - the images that exist in these paths
215:27 - here
215:28 - and with this we can now pass these
215:31 - generators to our deep learning model so
215:34 - that we can
215:35 - train the model
215:38 - first we're gonna create our deep
215:41 - learning model architecture so for that
215:43 - we're gonna
215:44 - use our
215:47 - street signs model here
215:49 - street science model and the street
215:52 - science model takes the number of
215:55 - classes as a parameter
215:58 - so here for the number of classes we can
216:01 - actually
216:02 - get them using
216:05 - the generators any of the generators
216:07 - since the train generator is
216:10 - the one that contains the most images
216:12 - let me maybe just use it so
216:15 - number classes equals
216:17 - train generator dot num classes and then
216:21 - i can pass this to my deep learning
216:24 - model
216:28 - and
216:29 - now i have my model ready
216:33 - then we need to do the same as we did in
216:35 - the first tutorial tutorial so here
216:38 - we're gonna first compile
216:41 - our model
216:43 - and to compile it we have uh several
216:45 - options the first one is the
216:48 - optimizer
216:50 - so for now let's just
216:52 - keep adam as the first tutorial
216:56 - second we need to set the
216:58 - loss
216:59 - and here
217:00 - i'm gonna use categorical
217:04 - cross
217:05 - entropy
217:06 - and again i'm using categorical cross
217:09 - entropy because
217:10 - my generators here i have set the class
217:13 - mode to categorical if i set this to
217:15 - sparse and i set this to
217:18 - and i keep this categorical then i'm
217:20 - going to have
217:22 - an error at the end
217:25 - and
217:27 - the final thing we need to define here
217:29 - are the
217:30 - metrics
217:32 - and for that i'm just going to use the
217:35 - accuracy
217:39 - so
217:40 - by this
217:41 - by doing this we're going to have our
217:43 - model compiled and what's gonna be left
217:45 - now is to fit the data so here i'm gonna
217:49 - do model.fit
217:53 - and here we can actually
217:56 - do something
217:57 - uh that's that looks a little different
217:59 - than the first tutorial so in the first
218:01 - tutorial we had that
218:03 - x and y
218:05 - but in fact you can just pass the full
218:08 - generator so this generator and this and
218:11 - this one they all contain the
218:14 - correct image
218:15 - and also its corresponding label we
218:18 - didn't have to explicitly do that by
218:22 - when we used the
218:24 - from flow from directory method it has
218:28 - done this for us so we have all
218:30 - generators ready so we can just pass
218:33 - the train generated generator sorry as a
218:37 - parameter like this
218:39 - and then we can set
218:41 - for example other parameters
218:43 - like
218:46 - the
218:47 - ebox
218:50 - so here we can choose whatever epochs we
218:53 - want maybe i'm just gonna
218:56 - add it
218:57 - here so that it's easily
219:00 - changed later
219:01 - ebox
219:04 - and also we have the batch size we're
219:08 - gonna use the same batch size
219:13 - and also
219:14 - we gonna pass the validation images
219:18 - and the validation generator here so for
219:20 - that we can use the
219:23 - validation
219:24 - data parameter and we can pass the
219:28 - valve generator
219:31 - as the argument
219:33 - so here as you can see we didn't have to
219:37 - specifically mention the images and
219:40 - their labels
219:41 - separately like we did in the mnist
219:44 - example so here in the amnest we had the
219:46 - x strain contains the images the y train
219:49 - contains the labels but in this case
219:52 - here we didn't need to do that because
219:54 - our generator takes care of that there's
219:57 - already the images and their
219:59 - corresponding labels so with this we can
220:03 - fit our data and we can train our deep
220:06 - learning model
220:08 - and this would be almost uh
220:10 - almost identical to what we did before
220:12 - apart from the generators and i
220:15 - mentioned in the previous tutorial that
220:17 - there are some things that we need to do
220:20 - when we're building a project like this
220:23 - so for example one of the important
220:25 - things would be to save your model save
220:28 - the best model during training so i'm
220:30 - going to show you how to do this now
220:35 - so in order to save the best model
220:37 - during training we're going to use
220:39 - something
220:40 - in tensorflow that's called callbacks
220:43 - and
220:45 - these callbacks are actually
220:47 - functions that are called during the
220:49 - training
220:50 - and
220:51 - basically they do whatever you want them
220:54 - to do specifically we want to save the
220:56 - best model so we're going to use a
220:58 - callback that saves the best model
221:01 - so in order to do that we're gonna be
221:04 - using some
221:07 - some modules or some
221:10 - classes from tensorflow so here i'm
221:13 - gonna do
221:14 - from tensorflow.keras.covacs
221:19 - i'm gonna import
221:21 - a callback called
221:24 - model checkpoint
221:26 - so here i'm going to use this one
221:30 - here i'm going to give it a name
221:32 - so for example
221:35 - we can call it
221:36 - checkpoint saver so kpt
221:39 - saver and i'm gonna instantiate that
221:42 - class so model checkpoint and then i'm
221:46 - gonna pass
221:48 - a set of parameters to my class
221:51 - so here
221:52 - the first thing we need to give it is a
221:54 - path to where we want our model to be
221:57 - saved so path
221:59 - to save
222:01 - model
222:02 - and let me maybe define it
222:06 - right here so path to save
222:10 - model
222:11 - and i just want to save it in the same
222:13 - directory
222:15 - i want to
222:16 - create a directory called data
222:18 - and
222:20 - or maybe just
222:23 - models
222:25 - and that will be it so i'm gonna be
222:27 - saving my
222:29 - model inside a directory here that will
222:32 - be called models
222:34 - and
222:35 - then i need to give other parameters to
222:38 - my callback
222:40 - so one thing would be the
222:42 - monitor
222:44 - and here i'm going to give it
222:46 - the valve
222:48 - accuracy
222:49 - so what this
222:51 - parameter is going to do
222:54 - so this parameter here monitor is
222:57 - basically going to well monitor this
222:59 - value here
223:01 - and what we wanted to do is that
223:04 - we wanted to follow this mode
223:07 - so here i'm going to set it to max which
223:10 - means that
223:11 - i want my
223:14 - basically my program to save the model
223:16 - whenever i get a validation accuracy
223:20 - that is higher than the previous
223:23 - saved accuracy
223:25 - and this is why i'm setting here max
223:28 - because it's going to be
223:29 - my model is going to be looking at the
223:31 - validation accuracy and whenever it gets
223:35 - a little higher
223:36 - then it's going to save it
223:38 - if it gets lower then we don't do
223:40 - anything we keep the same
223:42 - model that was saved before
223:44 - and
223:45 - why we're sending here
223:47 - max is specifically for the reason that
223:50 - i just mentioned which is we need
223:53 - to basically only save the models that
223:56 - have higher validation accuracy if for
223:59 - example i had here
224:01 - to monitor validation loss
224:04 - then i would be using the min mode
224:07 - because
224:09 - for the validation loss the
224:12 - less it becomes the better my model
224:14 - would become so i only want to save my
224:17 - model when this validation accuracy
224:19 - becomes lower hence the mode min
224:23 - so for me i want to monitor the
224:25 - validation accuracy the higher it gets
224:28 - the the program will save it
224:31 - so that's why i'm setting to validation
224:33 - accuracy and the mode to max
224:36 - and also
224:37 - there is a parameter called saved best
224:39 - only
224:41 - i'm gonna set it to true so i only want
224:43 - to i only want the best to to be saved
224:47 - which means that i'm only going to have
224:49 - one model to be saved
224:51 - which means that if i had a validation
224:53 - accuracy i save a
224:56 - model for that validation accuracy if a
224:58 - new model has better validation accuracy
225:01 - then i'm gonna replace the previous
225:03 - model
225:04 - uh if i set this to false then i'm gonna
225:06 - keep the previous model and save the new
225:08 - one
225:09 - next to it so for me i just want to save
225:12 - the best one so i'm going to set this
225:15 - parameter to true
225:17 - and also
225:19 - we can choose a frequency of saving
225:23 - so
225:24 - here i'm going to set it to epoch so
225:27 - we're only going to look at the the
225:29 - validation accuracy at the end of the
225:31 - epoch and only then we can choose
225:33 - whether to save the
225:36 - uh parameter the model or not
225:40 - and finally
225:41 - i'm just going to set verbose to
225:44 - 1 which is just
225:46 - helps us for debugging purposes to see
225:48 - when the model
225:50 - has been saved or not
225:52 - so now i have my callback ready and
225:56 - to use the this callback what you need
225:59 - to do is to add
226:01 - a
226:03 - parameter here called callbacks to the
226:06 - fit function
226:08 - and here you can give it a list of
226:10 - callbacks so for now we only have one
226:13 - which is the checkpoint
226:16 - saver so i'm going to pass it here if we
226:19 - had other callbacks then we can also
226:22 - pass them here as part of the list but
226:26 - we're not gonna do this unless as i
226:29 - mentioned we have another callback and
226:32 - speaking of callbacks i also want to
226:34 - show you another
226:35 - interesting callback that you can use
226:38 - which we can also import from the
226:40 - callbacks
226:42 - module here and it's called
226:45 - early stopping
226:48 - so
226:48 - this uh callback here what it does is
226:52 - that we can set
226:53 - some number of epochs
226:55 - that according to these this number of
226:59 - epochs if my model does not improve then
227:02 - i'm just gonna stop the training
227:04 - so this could be useful when you're
227:06 - training for
227:07 - a
227:08 - large number of epochs and maybe for
227:11 - let's say 30 or 50 epochs your model
227:14 - does not improve at all so it's better
227:17 - to just stop the training
227:20 - so here how to use this is almost the
227:24 - same way we
227:26 - use the model checkpoint callback so
227:29 - we're going to have to
227:31 - instantiate the class so i'm going to
227:32 - call it early stop
227:35 - and i'm going to use the class early
227:37 - stopping
227:39 - i'm going to monitor something so here
227:42 - i'm going to choose to monitor the
227:44 - validation accuracy
227:46 - just like i did for the model checkpoint
227:50 - and also i need to set the patients so
227:53 - here for example i can set the patients
227:56 - to 10
227:57 - so what this means is that
227:59 - i'm telling my
228:01 - my program here that if after 10 epochs
228:05 - my validation accuracy does not go
228:07 - higher then just stop the training
228:10 - so for example i might i might use
228:13 - let's say
228:14 - let's let's say
228:16 - 100 epochs
228:18 - and after 10 epochs we reach certain
228:20 - validation accuracy and at the 20th
228:24 - epoch the validation accuracy does not
228:27 - go higher so that means the model did
228:30 - not improve in that case i'm just going
228:32 - to stop the training before continuing
228:34 - the rest of the 80 epochs
228:36 - so this could be a very useful and
228:39 - different
228:40 - scenarios and we're using it here and in
228:42 - order to tell our model to basically use
228:46 - this callback we need to pass it
228:50 - as
228:51 - part of the list of callbacks here
228:54 - so now we have
228:56 - our
228:59 - program ready and we can fit the data to
229:03 - our model and we can save
229:05 - the
229:06 - the model
229:08 - inside a folder here called
229:11 - models and we have everything ready so
229:14 - with this
229:15 - let us test our model let me clear the
229:18 - terminal i'm gonna run python
229:22 - stream
229:23 - in fact i just noticed that actually my
229:26 - script is called stree instead of street
229:28 - signs so let me just
229:30 - quickly
229:32 - modify this
229:33 - so street signs example
229:40 - and now let me
229:42 - call it or let me
229:44 - call my
229:45 - script from here so street
229:47 - signs example
229:50 - so let's run this
229:52 - and see what we get
229:55 - hopefully we don't have any errors
229:58 - so as you can see from the logs uh when
230:00 - you when you're using generators also
230:02 - gives you an idea about number of images
230:05 - that are using that are being used so
230:07 - since we have trained validation and
230:10 - tests this is for the number of trained
230:12 - images this is for the validation this
230:13 - is for the test and we also have 43
230:16 - classes
230:17 - and as you can see the training has
230:20 - started
230:21 - and
230:22 - our script is working
230:24 - properly so now this might take some
230:27 - time since it's 15 epochs i'm going to
230:30 - wait for it
230:31 - until it
230:32 - it finishes and then we're gonna look at
230:35 - our
230:36 - uh saved model and maybe i'm gonna come
230:40 - back before it even finishes just to
230:42 - show you that there was a model saved
230:44 - here
230:45 - after the first epoch
230:50 - so here after
230:52 - the end of the first epoch as you can
230:55 - see
230:56 - we reached this validation accuracy
231:00 - but the most important part for us now
231:03 - is that there's this
231:05 - line here that says validation accuracy
231:08 - improved from minus infinity to 0.4
231:12 - so
231:13 - this means that
231:14 - our validation accuracy has improved
231:18 - this means that we're going to save the
231:19 - model to this folder here and as you can
231:22 - see this folder was automatically
231:24 - created and if we go inside of it we see
231:27 - these files here and these files
231:29 - actually represent our model so we have
231:32 - this file we have these
231:35 - two folders so this folder contains the
231:37 - weights and
231:39 - this
231:40 - all of the
231:41 - elements that exist inside this folder
231:44 - represent our model
231:46 - so now each time it's
231:48 - improved
231:50 - it's gonna be saved in the same place
231:52 - here and for now i'm just gonna wait
231:55 - until the training is done and then i'll
231:58 - show you how
231:59 - how to use that final model to evaluate
232:02 - the
232:03 - test set for example and to do other
232:05 - things
232:08 - so now the training has finished it
232:11 - didn't take that long
232:13 - and at the end you see that in different
232:16 - uh epochs
232:18 - whenever the accuracy
232:20 - the validation accuracy became higher we
232:22 - saved the model so now we're sure that
232:26 - this folder here contains the best model
232:29 - that was saved during the training
232:32 - and now that we have this
232:34 - we can use our model
232:36 - in order to evaluate the data sets and
232:40 - this could be done easily using also
232:43 - some tensorflow utilities so for example
232:48 - since we don't need this part here
232:51 - i can just
232:53 - for example said this
232:55 - and this is also something that
232:57 - sometimes i do
232:59 - which is to
233:00 - uh basically set what i call switchers
233:04 - so train
233:06 - i'm gonna use i'm gonna set it to false
233:09 - because i'm not training
233:13 - and i would do this whenever
233:15 - i'm doing part of the code that i know i
233:18 - might use it
233:20 - again so i set it to
233:23 - this switch switcher here
233:26 - and i can set it to true or false
233:28 - depending on what i want
233:30 - and
233:31 - for example
233:32 - i can set this
233:34 - test to
233:37 - true and then my
233:40 - part of the code that does the testing
233:42 - will be added here so if
233:45 - test
233:50 - so if test
233:51 - then
233:54 - if i am using this switch then i want to
233:56 - use my model that was saved in order to
234:00 - evaluate my
234:01 - data set
234:03 - so now that we have
234:05 - uh
234:06 - our model here we can use some
234:09 - [Music]
234:10 - tensorflow utilities in order to load
234:13 - our model
234:14 - so here for example
234:16 - i can call my model
234:19 - and load it using tf dot
234:23 - keras
234:24 - actually i don't think i have
234:26 - okay
234:27 - import tensorflow as tf i did not import
234:31 - tensorflow in this module here so
234:35 - tf.keras.models
234:41 - dot
234:43 - load
234:44 - model
234:45 - and here i can give it a path to my
234:49 - model so
234:52 - my model is saved in this path here so
234:55 - whenever i call my script it's going to
234:57 - find it
234:59 - it's right next to it and then what i
235:01 - can do is
235:04 - for example
235:05 - maybe i might be i can
235:07 - [Music]
235:10 - basically print my model's architecture
235:14 - and the most important thing is that we
235:16 - can use the model to
235:19 - evaluate
235:20 - the set the sets that we have so i want
235:24 - to evaluate my model on the validation
235:27 - set and on the test set so we can also
235:30 - do this very easily
235:32 - here by passing the
235:34 - generator directly
235:37 - and
235:38 - maybe
235:39 - i can add a print here
235:45 - evaluating
235:47 - validation set
235:50 - and
235:54 - evaluating
235:56 - test set
235:58 - and here
235:59 - i'm gonna call
236:01 - model.evaluate on my test
236:05 - generator
236:07 - so
236:08 - let's now if we run the code the
236:11 - training will not start
236:13 - we will only have the
236:14 - ma the data
236:16 - basically loaded into these generators
236:19 - and then we're gonna evaluate those
236:21 - generators
236:22 - so here i'm gonna call my script again
236:26 - everything is saved let's see if
236:29 - this runs without any problems
236:32 - okay again since we have the generators
236:34 - it's gonna show us this
236:36 - uh i don't know this is actually a
236:39 - summary
236:41 - okay let me save this
236:45 - i'm gonna run the script again
236:48 - hopefully there are no more
236:50 - errors
236:52 - let's see
236:54 - okay the architecture
236:57 - is here
237:00 - and then the evaluation has started
237:05 - so now it finished evaluating the
237:08 - validation set which is 99
237:11 - percent accuracy 99.67 to be exact and
237:15 - on the test set
237:16 - we'll see how much it is so on the test
237:19 - set we see that we get an accuracy of
237:22 - 96.81
237:25 - which is not too bad it's really good
237:28 - so this means that
237:30 - by training our model on
237:33 - these uh images here
237:38 - and by testing them on the test set that
237:41 - we organized
237:43 - these images were never seen by our
237:45 - model
237:47 - and it still
237:48 - achieved a very high accuracy of 96.81
237:54 - so
237:55 - now you know how to basically train your
237:58 - model and also how to evaluate it let's
238:01 - see what we can do next
238:05 - so what i would like to show you now are
238:08 - maybe some things that you can do to
238:10 - improve the results even more
238:12 - because
238:13 - when you're doing machine learning or
238:15 - deep learning you're going to be doing
238:17 - lots of experimentation and your goal
238:19 - will be to always improve this test
238:23 - accuracy this is the most important
238:25 - metric for you
238:28 - when of course when you're doing a
238:30 - task such as classification if you have
238:33 - a different task for example object
238:34 - detection then maybe your metric will be
238:38 - mean average precision for example
238:42 - but here since we have classification we
238:44 - want to improve this accuracy even more
238:47 - if we can
238:48 - so
238:50 - i want to show you some
238:52 - few techniques that you can do in order
238:54 - to try to improve the results
238:57 - the first ones are just by
239:01 - basically doing lots of experimentation
239:03 - by changing these
239:05 - values here so for example you can train
239:08 - for longer i've only used 15 epochs
239:10 - maybe you can go
239:12 - longer 30 50 even 100 epochs and see if
239:16 - that can improve the model
239:18 - you can change the batch size you can
239:20 - also
239:23 - change your deep learning model
239:25 - architecture you can add few layers
239:27 - remove few layers you can change these
239:31 - numbers of
239:32 - filters here
239:34 - you can for example experiment with
239:36 - global average pooling you can maybe
239:39 - remove this and add flatten layer
239:41 - instead and see how all of this can
239:45 - affect your results
239:47 - so
239:48 - as you can see you have a lot
239:51 - of things that you can experiment with
239:54 - and also
239:55 - this is from a maybe a model perspective
239:59 - but from a data perspective you can also
240:01 - do a few things so for example here
240:05 - you have the generator
240:07 - and we're using this image
240:09 - data generator class and in fact inside
240:12 - this class you have several data
240:14 - augmentation techniques so data
240:16 - augmentation techniques can help a lot
240:19 - in avoiding overfitting and it can also
240:23 - give your accuracy a bit of a notch and
240:27 - so that you can get maybe a few points
240:30 - more
240:31 - and for example if you're going to
240:34 - follow this path
240:35 - then i want to mention something
240:37 - important here so
240:40 - so far we created only one preprocessor
240:43 - that we use for train validation and
240:45 - test
240:46 - but
240:47 - this is because the only thing we're
240:49 - doing now is scaling so
240:52 - if we're scaling the images for the
240:54 - train set we need to do it for the
240:56 - validation set and the test set but if
240:58 - you start adding
241:00 - other
241:01 - data augmentation techniques for example
241:04 - let's say
241:06 - let me just check here
241:10 - shift
241:11 - or maybe let me just read a little bit
241:13 - here
241:16 - what can we use i think there's
241:19 - rotation range
241:21 - for example and rotation range for
241:23 - example you can choose
241:25 - i think it's
241:26 - in degrees so you can choose for example
241:29 - 10 degrees this means that your images
241:31 - will be
241:33 - uh
241:34 - will be rotated between 10 and -10
241:37 - degrees
241:38 - uh you can add
241:40 - other things like
241:42 - shift or maybe width shift range yeah
241:46 - so this is to shift your image a little
241:49 - bit
241:50 - uh from left to right just a little bit
241:53 - and you can give it
241:54 - a
241:55 - small
241:56 - amount for example
241:58 - let's say
242:00 - 0.1 which means 10
242:02 - so i want like my image to be shifted 10
242:06 - to the left and 10 to the right
242:09 - and between these two so it can be like
242:11 - 5 3
242:12 - this is uh going to be used as a range
242:15 - and you can do all sorts of other
242:18 - uh data augmentation techniques
242:21 - so the first thing that i want to
242:25 - basically emphasize here is that if
242:27 - you're using
242:28 - this as preprocessor you shouldn't use
242:31 - it for
242:32 - validation and for the test set and the
242:34 - reason for this is that
242:36 - the validation and test sets
242:39 - basically represent
242:41 - the
242:42 - sets that your model were in your model
242:45 - where will encounter in real life so in
242:48 - real life
242:49 - uh it's not necessarily you're not
242:51 - necessarily gonna have these shifts
242:53 - because these are synthetic
242:55 - augmentations
242:57 - in real life you want to test only on
242:59 - real images
243:01 - but when you're training
243:02 - you can do all sorts of these
243:05 - augmentation techniques
243:07 - so
243:08 - in order to avoid this you should
243:10 - always create two uh
243:13 - two preprocessors for example you can
243:15 - call this train preprocessor
243:17 - and you can
243:19 - for example add another one you can call
243:22 - it
243:23 - test preprocessor for the test
243:25 - preprocessor you remove these
243:27 - you only leave the scaling part because
243:30 - it's necessary if you scale the train
243:32 - set then you have to apply the same
243:34 - thing for the validation and the test
243:36 - sets but then you can use this
243:39 - preprocessor
243:40 - for the training part and this
243:43 - for
243:43 - [Music]
243:44 - the validation and the test generators
243:48 - so this is how you would do it and this
243:50 - could also bring
243:53 - some improvements to your model
243:55 - so just make sure you follow this kind
243:58 - of methodology when you're
244:01 - doing these different data advancation
244:03 - things
244:05 - and
244:06 - apart from this
244:08 - as you can see you have several things
244:10 - you can do you can add more augmentation
244:12 - you can change
244:13 - you can even change the target size
244:15 - maybe
244:16 - use 40 by 40 or 80 by 80 see if that can
244:20 - improve the results or not
244:23 - so i definitely
244:26 - recommend and i urge you to
244:28 - experiment with this and see if you can
244:31 - beat this accuracy which is 96.81
244:36 - and this is gonna help you
244:38 - basically learn more and it's gonna
244:41 - show you the power of deep learning
244:43 - sometimes just by changing a small
244:45 - parameter you can get a large
244:48 - improvement
244:50 - and then
244:51 - one last thing i want to show you also
244:53 - in terms of things you can improve
244:56 - for example here for the optimizer i
244:58 - have
245:00 - passed it as a string because this is
245:02 - one possibility to do it another one
245:05 - would be to
245:07 - create an optimizer here
245:10 - and you can use
245:12 - tf.keras dot
245:15 - the optimizers let me check
245:19 - so tf
245:21 - optimizers
245:23 - and here
245:24 - you can call for example the optimizer
245:27 - adam
245:28 - and
245:29 - this is something that you can find in
245:32 - the documentation so tf keras optimizers
245:36 - so the documentation can be very very
245:39 - helpful when you're
245:41 - working with tensorflow they have lots
245:42 - of examples they have lots of uh
245:46 - of
245:47 - tutorials that you can use
245:50 - for your projects
245:53 - and here so what i wanted to show you is
245:55 - that if you
245:57 - use the
245:58 - adam optimizer like this then you have
246:01 - the option to pass some parameters to it
246:04 - so here if we go to the documentation
246:06 - you see that you can pass the learning
246:08 - rate for example which is very important
246:10 - parameter in deep learning
246:13 - these parameters here
246:15 - i usually don't touch
246:17 - but for the learning rate i
246:19 - do lots of experimentations with it
246:21 - because i have seen that
246:24 - it can have
246:25 - great
246:26 - effect on your model so here
246:30 - for example you can
246:32 - add learning rate
246:34 - so lr for learning rate
246:37 - let's say
246:38 - 0.02
246:41 - uh so this 10 to the power of -4
246:45 - and then i can pass this as
246:48 - my
246:51 - parameter here
246:53 - r let me check just if this is the
246:56 - correct way to call the parameter yeah
246:58 - learning rate
247:00 - and then i can pass it here and then you
247:01 - can this is another hyper parameter for
247:04 - you that you can play with and see if
247:06 - you can improve the results and then the
247:09 - way you would do it is that you can pass
247:11 - this optimizer
247:13 - here like so
247:17 - so this is also something that i wanted
247:19 - to show you
247:21 - just for the adam optimizer you see you
247:22 - can play with the learning rate
247:25 - value here and also since we're talking
247:28 - about atom optimizer just a quick note
247:31 - you see here that there is this last
247:34 - parameter called or this parameter
247:36 - called ams grad and it's by default set
247:40 - to false this is actually a variation of
247:43 - the adam optimizer
247:45 - i've read a little bit the paper
247:48 - that showed this technique and they
247:50 - showed that in some cases adam actually
247:54 - fails to converge and by converging i
247:57 - mean it fails to
248:00 - basically get the loss function to go
248:02 - very low and in those cases in many of
248:06 - those cases ams grad can help so for
248:08 - example you can also
248:11 - if you're using adam for your
248:14 - deep learning task and you see that the
248:16 - loss function is not
248:17 - going down
248:19 - then maybe one thing you can experiment
248:21 - with is to set the
248:24 - ams
248:25 - grad
248:27 - to true and you can test with this
248:30 - variation of adam optimizer so as you
248:33 - can see you have a lot and a lot of
248:35 - things that you can do but just
248:38 - this
248:39 - this set of parameters and this set of
248:41 - techniques that i mentioned now can help
248:44 - you improve the accuracy by a large
248:47 - margin
248:50 - so when you're done training and
248:52 - evaluating your model
248:53 - what you basically
248:56 - need to do at the end is
248:58 - to
248:59 - use that model in your application it
249:01 - could be a web app web application it
249:03 - could be a mobile application or an
249:06 - embedded application
249:08 - and for that what you would usually do
249:10 - is uh use this standalone script that
249:13 - just loads your model and for example it
249:15 - takes a path to an image as a parameter
249:19 - and it gives you a prediction on that
249:21 - image so this is what i'm going to show
249:23 - you now so
249:25 - let's create a new script and i'm going
249:28 - to call it for example
249:32 - predictor dot by
249:35 - let me just maybe choose my predictor
249:38 - dot phi
249:42 - in this example what i want to do is uh
249:45 - to show you
249:47 - how we can just load an image load our
249:49 - model and make a prediction with our
249:53 - model on that image
249:54 - so let me maybe start here by defining
249:59 - this part here
250:03 - and
250:04 - i want to basically
250:07 - have a pad to my image
250:10 - let me call it maybe image path
250:14 - and what i would like to have is some
250:16 - sort of a function
250:18 - called predict
250:20 - with model and this function would take
250:24 - image
250:25 - it would take the image path
250:27 - um maybe it would take my
250:30 - model and image path and it would return
250:34 - to me the correct prediction
250:37 - so it would be something like this
250:40 - so now let me define this function here
250:45 - and
250:47 - maybe let's start defining it here and
250:49 - maybe later move it to the utility
250:51 - script
250:52 - so define
250:55 - predict
250:57 - with
250:58 - model
250:59 - and it's going to take model and
251:01 - image path
251:04 - so here what i want to do is
251:06 - to first
251:08 - load the load that image and then use my
251:11 - model to predict on that image
251:14 - so
251:16 - first thing uh the first
251:17 - approach i'm going to use is by
251:20 - using purely tensorflow functions so let
251:23 - me import
251:25 - tensorflow
251:27 - stf here
251:29 - i'm going to use
251:31 - my
251:32 - tensorflow import here to
251:36 - load my image
251:38 - so i'm going to use here or create a
251:40 - variable called image
251:42 - tf dot
251:44 - io dot
251:45 - read file
251:46 - [Music]
251:47 - and i'm going to give it my
251:50 - image path here
251:52 - so this is
251:53 - a utility function that's going to help
251:55 - us load this image and save it
251:58 - inside this variable called image and
252:01 - then
252:02 - i want to
252:04 - basically decode my image
252:09 - tf dot
252:12 - image dot
252:14 - decode
252:16 - png since
252:18 - all of my images
252:20 - are
252:20 - png images
252:24 - so here i'm gonna
252:26 - do this
252:27 - decode as png
252:29 - so i'm gonna decode my image
252:33 - and then i need to choose the number of
252:35 - channels since it's an rgb image i'm
252:38 - gonna choose three
252:42 - then what i'm gonna do is
252:44 - basically rescale my image
252:47 - and in order to do that i'm gonna use a
252:50 - utility function also so i'm gonna do
252:53 - image equals
252:55 - tf dot image dot convert
252:59 - image d type
253:01 - and
253:02 - i'm gonna give it my
253:04 - image as a parameter here i'm gonna
253:08 - choose the type to be
253:10 - tf dot float 32
253:14 - so in fact just by doing this
253:18 - during this part of the
253:20 - of the code here
253:21 - i'm reading the file reading the image
253:24 - using this read file method i'm decoding
253:26 - it since it's a png image i'm using
253:28 - decode png and then by using this
253:32 - function here here convert image d type
253:35 - it's going to convert my
253:37 - image
253:38 - pixels since now they are unsigned
253:40 - integers in eight bits it's gonna
253:43 - turn them into a float32
253:46 - uh type and also it's gonna scale them
253:50 - by
253:52 - turning the pixel values between 0 and 1
253:55 - instead of 0 and 255
253:58 - so without even mentioning here the
254:01 - scale value by saying for example divide
254:05 - by 255 this function is going to do it
254:07 - for us
254:10 - and you can check that by going to the
254:11 - documentation regarding this function
254:14 - here
254:16 - after that i'm going to have to resize
254:18 - my image so i'm going to use tf
254:22 - dot image dot
254:24 - resize
254:25 - and i'm going to give it my image and
254:28 - then a list of the width and height
254:34 - and here i'm choosing 60 by 60 because
254:37 - as you remember
254:39 - in the generators here or in the flow
254:42 - from directory we are
254:44 - using target size 60 by 60 which means
254:47 - that all of our images are resized to 60
254:50 - by 60 so we need to keep that same order
254:53 - when
254:54 - reading an image
254:56 - to pass it through our model
254:59 - so here we have resized our image
255:02 - and last we need to
255:05 - basically expand
255:08 - dimensions of my
255:11 - tensor and here i'm going to give it my
255:14 - image and axis 0.
255:17 - so just to explain what this does in
255:20 - fact at this level here we can have
255:23 - a shape of 60 by 60 by 3
255:27 - but
255:28 - by doing this by expanding the
255:30 - dimensions we're going to get a shape of
255:33 - 1
255:34 - by
255:36 - 60 by 60 by 3.
255:40 - and this is the format that our model
255:43 - is expecting our images to be in so let
255:46 - me check here as you can see the input
255:49 - layer expects none then 60 by 60 by 3
255:54 - and this none can be anything
255:57 - but there needs to be this dimension
255:59 - here so if we're using one image to pass
256:02 - it to our model we need to set that
256:04 - first value to one to say that this is
256:07 - one image of size 60 by 60 by 3 and then
256:11 - our input layer will not complain
256:13 - because
256:14 - this
256:16 - this basically
256:18 - follows the same
256:20 - shape that we defined during the
256:22 - training
256:24 - and then once we have our image ready
256:27 - what we can do is call
256:30 - our model predict function and we're
256:34 - gonna pass the image to it
256:37 - so this is gonna give us a list of
256:41 - probabilities
256:43 - of
256:45 - that image belonging to one of the
256:49 - one of the classes so here i'm going to
256:51 - save my
256:52 - predictions
256:54 - to this variable here
256:57 - so you can choose this function to
256:59 - return
257:00 - the list of probabilities
257:02 - maybe you want to
257:03 - to use this
257:05 - for
257:07 - maybe
257:08 - using some threshold to say that this is
257:11 - acceptable or not so at this stage here
257:14 - for example you might get
257:16 - 0.005
257:18 - for the first class
257:21 - 0.003 for the second class then you
257:24 - might you may you might get
257:27 - 0.99 for the
257:29 - uh
257:30 - class here the third class and then also
257:33 - the rest will be
257:35 - zero zero point something and for the
257:38 - rest of the other classes as well
257:42 - so this means that
257:44 - our model if we get a result like this
257:46 - and our model thinks that this image
257:49 - most likely belongs to class three or
257:52 - class two because our folders
257:55 - as you remember they start from zero so
257:57 - we start from class zero if we go to the
257:59 - third class it's actually two
258:03 - so if we do if we run this command and
258:06 - we get
258:07 - this
258:09 - list here then this means that our model
258:11 - thinks that this image belongs to
258:16 - this class here
258:19 - so what we want is
258:21 - uh basically to get only that class and
258:25 - we don't want to get probabilities at
258:27 - least for me that's what i want to do
258:29 - but for you feel free to maybe return
258:31 - this
258:32 - list here and then do whatever you want
258:34 - with it but for me since i just want to
258:37 - return the exact class that we got
258:40 - i'm gonna do
258:41 - [Music]
258:43 - predictions equals
258:46 - numpy dot
258:50 - in fact
258:52 - we can give it
258:54 - my predictions here
258:57 - and let me just import numpy
259:00 - in port
259:02 - numpy s and p
259:06 - so
259:07 - what this is going to give me is the
259:09 - index of the max value which is exactly
259:12 - what i want so in this case for example
259:15 - it would return
259:16 - let me just maybe do it
259:18 - in a comment here
259:21 - it would give me
259:22 - 2 because
259:24 - 2 is the index of the max value
259:28 - 0.99
259:30 - and then i'm just gonna return
259:32 - my
259:34 - predictions
259:36 - so now we have our function ready and
259:40 - here let's choose for example
259:42 - one of the
259:44 - images
259:45 - in the test set
259:47 - let's choose this for example
259:52 - and copy as path so that we can quickly
259:56 - do that
259:58 - i'm just going to paste it here
260:01 - i'm going to add the backwards slashes
260:04 - here
260:05 - quickly
260:10 - and then
260:11 - of course i need to load my model so
260:14 - just like we did
260:17 - here
260:18 - we can load our model
260:19 - by using this command here
260:25 - so the model
260:27 - exists in this folder called models
260:30 - so we're going to be able to find it
260:32 - from our script mypredictor.pi i'm going
260:35 - to pass it
260:37 - to our function predict with model and
260:40 - then we're gonna get
260:41 - the
260:42 - corresponding class and then here i'm
260:44 - just gonna
260:45 - print something like
260:47 - okay i'm gonna use an f string
260:50 - prediction
260:51 - [Music]
260:52 - equals
260:56 - prediction
261:00 - so
261:01 - let's run our script and see what we can
261:04 - get let me clear this first python
261:09 - my predictor.buy and just do one last
261:12 - look here
261:14 - see hopefully we have no
261:17 - errors
261:21 - okay well the first prediction was
261:23 - actually uh wrong so this prediction it
261:27 - says this this is class 12 but it
261:30 - actually
261:30 - is class 2. let's test with
261:33 - other images as well
261:38 - so here for example i added this
261:41 - image here from the test set
261:44 - which which should give us the
261:46 - label 0
261:48 - so let's run our
261:50 - predictor.buy
261:56 - and here as you can see we get the
261:58 - correct result is zero i know
262:01 - i know that the correct result is zero
262:02 - because i'm just looking at the
262:03 - corresponding folder here
262:06 - so
262:07 - we got the wrong result for this one the
262:09 - correct one for this one
262:11 - but this is basically
262:14 - this is not a way to test the model the
262:16 - best way to test the model is by doing
262:18 - evaluation as we did before but this is
262:21 - just to show you how you would use
262:24 - your deep learning model
262:26 - to
262:27 - predict on images
262:29 - in a standalone application so as you
262:31 - can see here we have an application
262:34 - this could be easily embedded in
262:37 - any sort of application web app or
262:40 - mobile app or whatever
262:43 - and basically we just have a function
262:45 - that reads the image uses the model and
262:47 - makes prediction with it and then you
262:49 - get that prediction and you can do
262:51 - whatever you want with it
262:53 - so now you have seen how
262:56 - to use your model in a standalone
262:58 - application in order to make predictions
263:01 - on
263:02 - specific images
263:04 - so just a quick recap of what we've seen
263:07 - in this last part
263:09 - so basically we used a german traffic
263:12 - signs data set that was collected
263:15 - and we had real life images
263:18 - we explored that data set we prepared
263:21 - the training validation and test sets we
263:24 - built a neural network the functional
263:26 - way
263:27 - we also created data generators we added
263:30 - callbacks to our fit method
263:33 - we trained and evaluated our model
263:36 - and we discussed some potential
263:38 - improvements that we can do to get
263:40 - better results for example data
263:42 - augmentation
263:43 - we also finished that part by
263:47 - by running inference on single images
263:50 - and building standalone examples on how
263:53 - you would use your model
263:57 - so if you have any questions regarding
263:59 - what we have covered so far then please
264:01 - feel free to contact me on
264:04 - my social media accounts so i have
264:06 - linkedin account and also twitter
264:08 - account
264:09 - and if you're interested in
264:11 - a free machine learning job ready
264:13 - checklist which is a checklist that i
264:15 - put together based on my experience
264:17 - working on machine learning projects in
264:20 - the computer vision industry
264:22 - then please check the link below there
264:24 - will be only one link but it's going to
264:26 - point you to all the necessary
264:28 - information
264:29 - regarding my
264:31 - social media accounts and also this free
264:34 - checklist

Cleaned transcript:

tensorflow can do some amazing things when it comes to computer vision in this course machine learning engineer noor islam muktari will teach you how to create multiple computer vision projects using tensorflow 2. hello and welcome to my course introduction to tensorflow for computer vision so just a quick introduction about myself my name is noor islam i work as a machine learning engineer and i'll be your instructor for this course if you have any questions regarding the course material and content or anything related to machine learning and computer vision feel free to connect with me on linkedin and twitter and if you're starting a career in machine learning and computer vision then please check out my free ml job ready checklist that i have put together which contains some information that might help you to set a roadmap for things you should learn and maybe things that the machine learning and computer vision industries might expect from you so all of these information regarding my social media accounts and also this free checklist can be found in the link below it's one link but it's gonna show you all of the necessary information once you click it let's take a look at the course outline so we're going to start the course by doing some software setup then i'm going to show you how to do image classification using mnist dataset which is basically the equivalent of the hello world examples in the machine learning field then we're going to look at the image classification using german traffic science which is a real world data set that reflects more challenges compared to the mnist dataset so for the software setup we're going to start by downloading and installing visual studio code i'm also going to show you how to get miniconda i'm going to tell you why we need it and how to install it we're gonna be using minicanda with vs code so i'm gonna show you how to make those two work together then we're gonna install tensorflow 2 cpu and gpu versions we're also gonna be installing different python packages along the way for the second part which is the amnest example we're gonna basically explore the amnest data set i'm going to show you how to build a function that randomly looks into the data set and it gives you some ideas about how this dataset is constructed i'm also going to show you how to use tensorflow layers how to import them and how to use them to build the neural network we're going to be building the same neural network architecture in three different ways which are the ways supported by tensorflow so the first one is called the sequential way by using the sequential class the second approach is called the functional way which is basically your model is wrapped inside a function and the third approach is the model class way which is by inheriting from the model class we then gonna do the compilation of the model and we're gonna fit the amnes data set into our model we're gonna finish this part of the course by restructuring our code for better readability which is something you're going to find yourself often doing when working on machine learning projects in the industry and for the last part of the course we're going to be working with the german traffic signs data set which is a real world data set that reflects the real challenges when working on machine learning projects compared to prepared data sets like the amnest dataset so for this we're going to start by downloading and exploring the data set we're going to prepare the training validation and the test sets because they're not already prepared we're going to build our neural network we're going to create some data generators which is a different approach than the one we will be using for the first example which is the amnesty example we're going to compile the model and fit the data i'm also going to show you how to add some callbacks and why they could be very useful and i'm going to show you how to evaluate your model using the generators you created before then i'm gonna show you some potential improvements that you can do to get even better results and we're gonna finish this uh part of the course and basically the whole course by a an example of how you would use your model to make prediction on single images so basically how to build a standalone example that can make or that can use your model in order to make uh separate predictions so who is this course for basically this course is for anyone who's interested in learning about tensorflow specifically for computer vision applications ideally you should have good knowledge about python like classes and functions in python and also basic concepts in deep learning such as convolutional layers so why would you learn tensorflow anyway well there are several reasons but these are three of the main reasons in my opinion so tensorflow is the leading framework in deep learning followed by pytorch and you can build powerful deep learning solutions with it for your own use and also for your company the company you're working for and there are lots of companies working on deep learning projects and they are using tensorflow so the job market is very large and it's only growing so these are the main reasons of why you would want to learn tensorflow but at the end of the day maybe you just want to learn it for fun so that depends on you so just a quick note before we continue with the course material we will be using an ide and not notebooks we will be specifically using visual studio code and this is for several reasons in industry projects you usually use ides and not notebooks with ides you easily scale your machine learning code so you can add a lot of scripts you can test them separately you can import them in different and other scripts and also the i am for the opinion that says that ides are for building your projects and notebooks are for presenting your work so for me and i think many other machine learning practitioners agree with me on this is that we usually use notebooks for presenting the work but when we're building large machine learning projects we usually go with ides so the first thing we're going to start doing is downloading visual studio code is an ide that we will be using throughout the course to write the code and also to run that code so if you go to code.visualstudio.com you're going to get this page here and as you can see it automatically detected my system so i can just click here and download visual studio code for my windows machine if you have a different machine it should detect it if not then you can just click on this button here and choose the right software for your machine so if you click this you're just going to get this download here and you can just save it to your machine and run this executable just like you would run on any other installation process there's nothing unique or special here so i'm not going to go through it here now after we install it if you go to your run menu here and you just type visual studio code you're gonna get this uh the icon here where you can run visual studio code usually i like to pin it to my start so as you can see it's already pinned here which means i can just access it from here you can choose to do that as well if you prefer that so let's run visual studio code and the first time you run it you're gonna get this new window here where you have the starting menu so you can create new file open a file or or do all of these other things and also for me as you can see i have this part here that says recent which are my recent projects if it's the first time you're using visual studio code you will not have this so the first thing i'm gonna do is just to open a folder so i'm gonna click on open a folder here you can choose any place on your machine to to open that folder so for me i have chosen this place on my machine so i have a disk called d code for courses and introduction to tensorflow 2. i created this new folder and now i'm just gonna select it so select folder and now it's gonna open this uh new window okay here it says uh if i trust the authors of this files yes no problem these are my files so here you get this new window where you have this empty folder on the left and you can add new files you can also add new folders inside of this folder and here we will get uh the place where we can write code and also we can get the terminal at the bottom here so for now this is it for installing and setting up a visual studio code what we're going to do now is look at the other software that we will use throughout the course and also later we're going to start adding files here so that we can start writing some code so the second software we need to install is called miniconda so if you look online you're gonna find two types of products for condo there's mini conda and there's anaconda anaconda is actually a gui that allows you to do almost everything that mini conda allows you to do the only difference is that uniconda does not have a gui we will just use it in a command line prompt so if you type miniconda in your google search bar you're gonna get the first result here so if just open this here you get all of these links to install miniconda on your machine so if you are on windows you choose this otherwise you choose the other types here and again this there's nothing special here you can just click the link save it save the file to your to your local machine and then run the installation process and also there is nothing special when installing minicanda so i'm not going to go through it here now when you install miniconda if you go to your run menu here and you just type you're going to see anaconda prompt and between that parentheses there is minicom.3 so if you open it you're going to see that it looks just like the command window on windows so they are basically or almost identical the only difference that we can notice here is that here we see this name called base between parentheses here and here we can see it in the default windows command line window now what this means is that in fact in the miniconda prompt prompt we are actually now inside what's called a virtual environment and this virtual environment is called base so i'll go a little bit into more details about what these virtual environments do and why would we need them and why don't we just install things straight uh on our system using just the windows command line prompt i'll go into details about this just next so what are these virtual environments well you can actually think of them as these separate entities inside your system but they do not necessarily affect your system so for example we can think of it in this way so you have your system and inside your system you have python say 3.8 installed and you have some python packages and now with virtual environments what we can do is create as many environments as we want so for example here i can create i show you an example where we created three different virtual environments so the first one is called vm1 the second one vm2 and we have vm3 so in the first one we can install python 3.7 and for example we installed tensorflow 2.6 now when you do this you're not actually installing uh python or the python packages straight onto your system you're actually installing them inside this virtual environment so this virtual environment it actually lives inside your system but what you install in it does not necessarily affect your system so here as you can see on your system you might have python version 3.8 but inside your virtual environment you can change that and you can use python 3.7 and as you can see you can create as many virtual environments as you like and the goal here or the why would you even want to do something like this is really when you're doing machine learning or data science you're going to be doing lots of experimentation so for example there might be a new tensorflow version that has some new functionalities and you want to test it if you have everything installed on your system and then you just upgrade to the newest version of tensorflow then you might affect your existing code so you might something that has already worked in the previous version of tensorflow may not work in the newest version and that could cause a lot of conflicts so now that now you find yourself in a situation where you have to go back to an older version which is not uh very good so when you do this you can do these experimentations separately and as you can see for example if i want to test pytos and i don't want it to be used in the same virtual environment as tensorflow i can create uh completely separate virtual environments install uh whatever version of python i need and then i install pytorch here and if i want to test for example an older version of pytorch i can create another virtual environment and do the same thing and you can imagine all of these benefits that you can have for example many companies are still using tensorflow version 1.x so if you want to do this if you want to install a previous version or older version of tensorflow so 1.5 1.6 then it's better to install it in a virtual environment instead of doing it on your system so this is uh the goal of why we're trying to use virtual environments i really encourage you to use this kind of framework when you're doing your experimentation instead of installing everything on your system i've been working in the machine learning field for some years now and i have always found that it's better to use virtual environments rather than install everything on your directly on your system so i hope that now you can see the benefits of following this kind of paradigm and next let's start creating a virtual environment and installed necessary python and python packages inside of it so now just before we start installing tensorflow and creating our virtual environment let me just clear some some of the doubt that you might have here so as you can see when we installed miniconda we have this command prompt here and also i showed you that we have the default windows command line here and they are similar but how are we going to use our virtual virtual environments inside visual studio code so in fact if you go to visual studio code if you go to terminal new terminal here in fact we are inside our command line default command line window so what you do here is going to be identical to what you would do here and in fact let's just for example type python so here you see on my system there's python 3.6.8 installed and here if i write python i get the same uh version here so i have whatever i do here i'll uh i'll be able to do it here and vice versa and now let me just exit this what we want is to actually be able to use our virtual environments and just use mini conda in general inside our terminal here on visual studio code so in order to do that what you can do is just look up where miniconda is installed on your machine so for me i'm using a tool called everything it's a search tool you don't have to install it i just prefer it than the default search tool on windows so here when i type miniconda3 which is the software that we installed if i open this folder here there is another folder called scripts and then there is activate.bat so if i just take this copy it paste it and then run activate dot that now as you can see i have the base name here written before my before this path here and as you can see we have the same thing here so now we are in fact inside the virtual environment called base and whatever you do inside this command this window here is going to be reflected here and vice versa so now that we have we can access condyle commands on our visual studio code terminal let's try to see what we can do with it so here let me just clear this part here and in fact you can run so many conduct commands so to run the contact command you start by writing canda and then you finish the rest of the command with whatever you need to do so for example we can look at our uh virtual environments that are already installed in order to do that you can run this command calenda info dash dash ms and if you've never had a mini conda before you will have nothing when you run this command but for me as you can see i already have some virtual environments installed here so let me just clear this one here and next what we're going to do is create a new virtual environment and then we will choose the right python version that we want and then we're going to install tensorflow inside that virtual environment to create a virtual environment using canda the command that you should run is kanda create dash and now you can give a name to your virtual environment you can choose any name you like usually for me since i do many experimentations with tensorflow i just like to call it for example tf2 uh or i give it the full for example version of tensorflow so tf 2.5 or 0.6 or whatever and here let's just call it for example tf2 vm so vm for virtual environment and then you can give it the parameter python and here you can choose whatever version of python you like so let's just use 3.8 since i've been working with it for uh for a long time and it's uh it works great with tensorflow so here i'm just gonna run this command so now it's gonna ask us whether we accept to install these unnecessary packages so i'm gonna choose yes and click and this should not take that long because these are not large packages so after we have our packages installed we can run kanda activate tf2 vm and of course you can see that the suggestion is shown here in order to activate your virtual environment so now if you remember we are inside a virtual environment called base so after i run this command now we're inside our new newly created virtual environment called tf2 vm and here whatever you install is going to be separate from your system so it will not affect it so here for example let's just run python and as you can see is version 3.8 if you remember on my system i have 3.6 installed but here inside my virtual environment because i specified that i want python version 3.8 i have 3.8 installed here so now that we are we have created our virtual environment we start installing the necessary packages so now we can install for example tensorflow and if you go to the official website of tensorflow you can see if you just go to tensorflow.org install you can see different ways you can install uh tensorflow for us we're gonna use uh tensorflow or download it and install it as a python package so these are the commands we can run so here uh first command we can run as just for upgrading pip so if you don't know what bib is so bip is just a package manager that helps us install python packages so let me paste it here and see if i don't have the latest version apparently not so it's just gonna download it and install it so when i tried to upgrade pip on my machine it gave me a basically an access error but uh you if you have that error you can just run the same command but you add dash dash user at the end so for me it says requirements already satisfied in fact i didn't really need to run this command i already had the last version of pip already installed but you can run it just for the sake of it and now we're gonna use this command so pip install tensorflow and here i just want to mention something really quickly as you can see it mentions that the current stable release for cpu and gpu so when you run this command it's gonna install the stable versions for both cpu and gpu support before i can't remember before which release from tensorflow but before in order to install the gpu version you would add tensorflow gpu so you specifically mentioned that you want to install tensorflow with gpu support but apparently now when you when you just run this command it's gonna install the stability release for cpu and gpu so i'm gonna go back to my virtual environment here i'm just gonna paste it pip install tensorflow and let's run this command again just to mention this important point whatever we're installing here is being installed inside our virtual environment and not inside our system so this might take a little time depending on your internet speed and on your system so when the download and installation is finished i'll be back to show you what we can do next so now i have tensorflow downloaded and installed inside my virtual environment and i can verify that for example by running python console here and just trying to import tensorflow and it should be imported without any problems and just to show you that we're actually not installing things inside our uh on our system directly here if i run python and i do import tensorflow you see that module name or module not found here so it doesn't find the tensorflow module because it's not installed on my system i'm just showing you this here because from time to time you might face a problem like this and you start asking yourself why why don't i have tensorflow when you have already installed it but just make sure that if you install it in one specific virtual environment you should be using that virtual environment to run your code and this just this small detail here could help you solve this kind of errors and now that we have it what i would like to do is just run a command tensorflow.config.list physical devices so what this command is going to do is to show me on my machine which devices can i use to train deep learning models using tensorflow so as you can see here i have two devices there is the cpu and there is the gpu there's only one gpu as you can see for you it's very likely if it's the first time you're using tensorflow it's very likely that you will not have this second part here you won't have the gpu and this could be for several reasons for example you may not have an nvidia gpu on your machine so that's a common reason why you wouldn't have this the second common reason is that you might have an nvidia gpu but it's not it doesn't have support for training tensorflow or deep learning models in general on that gpu and the if you if you're not in one of these two categories then most likely you're not seeing the gpu because you just haven't set up what's necessary in order for you to run the training on the gpu and for me i have already done the necessary setup and i do have a nvidia gpu that can run the training that's why i'm seeing it here for you if you don't fall in the first two categories and you know that you can run the training on your gpu then i'll show you next what are the necessary uh hardware requirements and software requirements what are the things that you need to install in order to be able to use your gpu if you want to be able to run the training on your gpu and you know that you have nvidia gpu one thing you can do is to follow the right process that's mentioned in the official tensorflow installation page so here if you go to the download package which is what we just used if you go to gpu guide you can open this page here and when we when you use a bib package like we're doing you need to have some hardware requirements and also software requirements so the first thing let's check the hardware requirements so as you can see here it mentions that there are some nvidia cards where you can that are supported for you to train deep learning models on them so if you open this list here of cards that are that have cuda enabled architectures you can see a list of devices here and you can try to find whether your device is inside this list or not so in fact funnily enough for me i actually have a card geforce gtx 1050 ti and it doesn't exist on this list but i still can run the training on it anyway i remember the first time when i checked the list i didn't find it then i just started searching online i found that many people said yes they have the same card and they were able to run the training on it so this is just a small remark but uh if you find your card here then that's you can definitely run the training on the gpu so that's the first thing you need to check uh if you have that then most likely you can run the training and then you have some some remarks mentioned here for example for gpus with unsupported cuda architectures or to avoid compilation use different versions of nvidia so you can check these if you uh if you fall into one of these categories but for me usually just checking whether the architecture works is enough and then for the software requirements this is where in fact you need to have some software installed before your nvidia card can recognize that you can do the training using tensorflow so the first thing is the nvidia gpu drivers so here it says cuda 11.2 requires 450 or higher so you can go to the website here and for me it has automatically detected in fact i think that it's because i have already done this so maybe it's saved in my in the cookies but uh for you if it doesn't if you don't see your machine directly here you can just go search for it manually so you choose the product type the product series and then at the end you just click search and it's gonna give you the download link and again this is when you download this and you start uh installing it okay it does didn't start automatically let me click again okay now when you have this on your machine you just run the installation process there's nothing really special you just go next next next and you install everything so that's the first thing that you need to do and then you have cuda toolkits that you need to install and just i want to mention something here because uh i think a lot of people make a mistake when they start installing all of this software so here specifically it mentions for example cuda 11.2 and also tensorflow supports cuda 11.2 so any version of tensorflow that's higher than 2.5 it requires cuda 11.2 so for us we have installed tensorflow so if i do for example tensorflow and then i just run or check the version of tensorflow insert flow version so here you can see i have version 2.6.0 so i do fall into this category i need to have cuda 11.2 uh installed here when you go to the cuda toolkit archive you just don't take the latest version for example i see many people do this mistake they just go to the latest version but here if it's mentioned that you need to use 11.2 then you need to look for 11.2 and here what i usually do is i take the latest version of 11.2 because here you can see there's 11.2.0.1.2 so i just take this one here and then you just choose your operating system the architecture is only one here version 10 of windows and then you can choose one of two options there is the local installer and the network installer the difference is that the local installer has a large file which doesn't require a require internet access i mean after you download it you don't require uh internet access in order to install cuda toolkit and this one is a smaller file but it does require internet access if you have good internet then i suggest you just download this small file if not then you can download the largest file here and again there is nothing really special about this you just download it and then you go next next next there is and then you have the cuda toolkit installed on your machine so that's the second part uh for the cup tie you don't need to do that it mentions here that it ships with cuda toolkit so if you have the kuda toolkit you already have kubtai and then you need to install crew dnn sdk 8.1.0 so if we click this let me check here so download cooldmn and in fact for you to download that file or that folder you need to be a member on the website and this is you can do this for free you can just log in if you already have an account or you can join now for example and you just uh use your email and there is nothing special here you just join the the website so for me i already have a an account here so once i log into my account i get this web page here so i'm just going to agree to the terms and then here you can download the version for uh or kudianon 8.2.4 and in fact here when you look at this you see that there is for cuda 11.4 and this is for cuda 11.2 let's see if we can find for cuda 11.2 so there is none in that case we're just gonna use the latest version here so let me just go back here and check okay we have the cuda versions yes apparently okay 11.1 here yeah in fact there is so this is again this is a sometimes a problem that many people face so here we need hoo dnn sdk 8.1.0 when i clicked on the qdnn versions i get to this website here and here if you just don't take the latest version you need to look for your own specific version so here i have uh the version 8.1.0 which is what we need so for eight point one point zero we have one for cuda 10.2 and then one for cuda point eleven point zero point one and point two for us we have cuda 11.2 as you remember so we need this this version here so these are small details but just make sure you follow them so that you don't face a problem later many times i find people saying that they installed everything but still their car does not recognize uh cannot do the training with tensorflow but usually the problem just comes from one of these small details so if you click this then you can choose the right software for your machine so for example we are on a windows machine so i can just click goody and then library for windows and this is going to download a zipped folder and in fact i already have it on my machine here now i'm going to show you what what you need to do with this folder so when you installed cuda 11.2 it was installed in this path here so if you go to c program files nvidia gpu computing toolkit then you go to cuda for me i have several versions of cruda because from time to time i would upgrade or use the newest version of tensorflow and then many times it requires new version of cuda so i would download and install the right cuda version for you if you've never did this before then probably you will have only one version which is 11.2 and now what we're gonna do with the uh the zipped folder that you downloaded what you need to do is to unzip it so when you unzip it you're gonna get a folder called cuda inside of it you're gonna have these folders and this file here so what we're gonna do now is basically just copy the contents from these folders to the corresponding folders in cuda 11.2 so for example you would go to the bin folder copy everything then go here and paste everything for me i've already copied and pasted these so i'm not going to do it but this is the only thing you need to do then you go to the include folder copy everything paste it in the include folder and last you go to the lib folder you copy everything inside x64 and then the same thing here lib you go to x64 and then you paste everything there when you do this you can go back to your terminal so what i would suggest is to close and reopen the terminal and then if you run the same command that we that i showed you before so for example let's just do it again import tensorflow so here if we if we run tensorflow.list or config not list physical devices now you should be able to see this gpu part here so now i have shown you exactly the full process of installing a tensorflow so that you can use it with your gpu if you have a cuda enabled nvidia gpu and this is gonna allow you to run the train the training of your deep learning models much much faster which is uh almost always recommended and with this let's now look at what we can start adding from the coding part so that we can start exploring tensorflow library so here we're gonna start with the first classification task using tensorflow and it's actually a classical task so basically what we want to achieve is uh to build a system that can take images like this one here or here or here and at the output it would tell us whether there is a three or there's a seven there's a zero inside that image so our data set looks something like this of course these think of these are as separate small images just like these ones here these are just put together here for visualizations purposes so our data set has so many zeros so many ones twos until the digit nine and we want to build a system that can take an image like this at the at the start or as an input and adds the at the output we want to get the value that's written inside of that uh of that image so it's always good to really think about whatever task you're trying to achieve before you start the coding part so here this is just a quick overview of what we want to achieve and in fact this amnest test is a uh you can say as a tradition in the deep learning community it's just like a hello world program when you're learning a new programming language so now that you have hopefully understood the purpose of this task let's get into the code and see what how we can achieve this this goal here now let's get to the coding part so the first thing i'm going to do is just add a new file i'm going to call for example mnist example.buy and it's automatically opened on this side here so let's start by importing for example tensorflow since we will definitely need it later and one thing we gonna add from the start is just check if name equals main then we're going to run the code so if you're not familiar with this python part here just means that if i run my script then i want this part here to be rand and if i import it for example i can import my file into another script and in that case this part will not be called it's a good habit to always add this one on your scripts when you want to separate the behaviors between importing those scripts and running those scripts so the first thing that you might notice here is that it says tensorflow is not accessed it doesn't find tensorflow so here in fact what's happening is that if if you run your script from the terminal then there will be no problem so if i do python and this example dot y nothing is going to happen but there will be no problem that's what i mean but here if you try to run it using the run button here then you see it says no module named tensorflow and in fact what just happened is that vs code has opened a new terminal window automatically and it tried to run this script using our python that exists on our system and not inside our virtual environment so in fact we still have our virtual environment here and this is the new terminal window that was started by vs code so in order to run your scripts so you can in fact just ignore these these warnings here and you just run your script from the terminal but if this uh is annoying for you as it is for me you can fix it by actually telling vs code that this code here that we're writing is going to be around inside our virtual environment tf2vm so in order to do that you can click ctrl shift p on your keyboard so again ctrl shift p you push them you click them together and then you just search for interpreter and you choose python select interpreter and here is going to give you a list of a different python executables that it found on your system and here we're going to look for the virtual environment that we created so it's called tf2bn so let's just go step by step here try to find it so i have many virtual environments that's why it's not clear okay it's this one for you you may not have all of these virtual environments so it will be quick to spot which one is the environment that you created so i'm gonna click on tf2 vm and now as you can see vs code recognizes tensorflow because it's installed inside our virtual environment and i can click this one here and as you can see the program runs correctly with no problem so now let's go to our code editor here and let's start looking into what we can do for our task that we defined previously so one thing we can start doing is by actually importing the data set so in fact if you're doing a new project with your own data set it may not be this easy but since this is the first example of the first tutorial we're gonna do we're just gonna use the easiest and the quickest things so that we can put something together and see uh see basically the workflow of a tensorflow program so what we're gonna do is use tensorflow.js dot data sets or let me just check yes in fact it should be data sets dot load or dot mnist dot load data so let me just do this and in fact what this is going to do is load our data but we need to tell it where to store it so for us we're just going to use x train for the training data set and y train for the corresponding labels and then we're gonna use x test and y test so what this is going to do is load the mnist data set in fact if it's not if it doesn't exist on your system if it's the first time you'll be running this program here then it will download it first and then it's gonna load it into these variables that we defined here and it's already split into two parts one for training and one for testing so let's run this command or this program here and just i would like to print the shapes of these uh these variables that we defined and that we're going to load our data set in them so xtrain dot shape and let me just run this and i'm just gonna paste this three times and i want to do this for every variable that we have here ctrl c ctrl v so now let me just run my script again from the terminal and let's see what we get so as you can see it has loaded the data set and it has put them into these variables and we can see the shapes or basically the size of the data set so as you can see for the training part there are 60 000 images each image is of 28 by 28 pixels the labels there are sixty thousand labels because each image has its own label and by the label here i mean that if an image contains the number three in it then the label will be the number three and for the test part we have 10 000 images and of course their corresponding 10 000 labels so just just a quickly to go through why do we separate our data set into these two parts so in fact in deep learning what we do is we do some sort of cross validation there are many types of cross validation the simplest one is to split the data set into two parts one you're gonna use to train your model and one you're gonna use to validate your model and the difference is that during the training these are the examples that will be used and at the end of each epoch uh what's going to happen is that the neural network is going to run one forward pass of these test examples and this is going to give you an idea of how your neural network is performing on data that's not used during the training so it's this is going to give you an idea of uh how well the network is learning so this is just you can keep it in mind there's a whole theory behind this but i just want to go quickly through this so that you understand why do we have these two different splits so now what is usually good to do is to explore more your data set so what we have done here is some sort of an exploration we basically checked the size of our data set we now know that each image is 28 by 28 pixels but it's also good to plot some of the examples and their corresponding labels so for that i'm just going to create a help helping function so i'm going to call it for example display some examples and what's going to take as parameters are the examples or data points and the labels so basically what i want to do here is create a figure and add many of the images randomly i'll choose them randomly from the data set and then i'll add them inside uh this figure and then i'm gonna plot this figure so that we can see those images so one thing you can use which is a very famous package in python is a matplotlib so usually we just call it plt for short and in order to do that you need to import matte blot lib dot pi as plt and then you can use this package to do all sorts of things like creating figures and adding different images on those figures so as you can see here visual studio code does not recognize this package here because in fact we don't have it installed inside our virtual machine so before we go anywhere let's just installed it and to install any new package you can just run pip install and the name of the package so matt lard lib and usually i install packages on the go so whenever i need the package i installed it i don't like to install many things in the beginning because i don't know beforehand which ones which of the packages i'll definitely need and which ones i won't need so usually i just write my code and whenever i need a package i install it on the spot so here let me run pip install map.lib so it shouldn't take long okay it's installed and now it should be recognized i guess maybe it's not refreshed automatically but now we can use plt so we're going to start by creating a figure and we're going to give it a fix size of let's say 10 by 10 and then what we're gonna do is basically plot 25 images so it's going to be a grid of five by five so we're gonna do a for loop so for i in range 25 so i'm choosing 25 here you can choose whatever number you like for me i think 25 images is already enough to get an idea about your data set and here the first thing i'm gonna do is randomly choose so each time i'm going to randomly choose an index from my data set so let me just code it and it's going to be much clearer so i'm going to do index and numpy okay i don't have numpy imported so let me just import numpy snp and here i'm just gonna do np dot random dot rant in so i want to randomly choose an integer and i really like this uh kind of a tooltip that comes when you're coding on visual studio code and it basically gives you a small documentation about that function and what you can do with it so here for this function we need to give it a lower end and the higher end and it's going to use an integer between those two numbers so here i'm going to choose something between 0 and the size of so examples dot shape and i'm going to do 0 and here minus 1. so what am i doing here so if you remember here whether you choose the training set or the test set for example the training set there is 60 000 images so i want to choose a number between 0 and basically 59 999 because that would represent the number corresponding to the last image and here this is all i'm doing so here i'm basically choosing between zero and uh and sixty thousand minus one and then what i'm gonna do is use this index to get the corresponding image so now i can do examples index and then i want to get also the corresponding label so i'm gonna do labels and index and now i'm gonna plot that specific image so for that i'm gonna use plt subplot and just make sure i think there are there is subplot and subplots but what you want to use a subplot without the s and here we gonna give it basically the grid size so it's a 5x5 because we want to plot 25 images and here this is the number of the image and here i'm gonna do plot i'm gonna first plot the sorry here the title so the title of each image i want it to be the corresponding label so and it also needs to be into a string sorry so here i'm just gonna transform my label into a string so this is going to be the title of each uh image and then i'm going to add an mshow method to show the corresponding image so here i'm going to do show my image and at the end you need to tell python that show all of the figure now so now that we have this function coded let's try it out here by calling the name of the function then let's run it on the train set so here i'm gonna run it on the xtrain and y train so let me clear the terminal quickly and do python mnistexample.buy so now as you can see we get these images in a 5x5 grid and we have all of these examples now one thing you you might observe is that we have these images that have this kind of weird color and also we have basically the space between the images is too small so we don't clearly see that okay this is this has a label of nine but it's not very clear so let's fix these two problems quickly now so first of all we know that our images are grayscale images they're not rgb images because here we see that the size is 28 by 28 which means there's only one channel and there are no there are three channels so it's not an rgb image so in order to tell matplotlib that this is a grayscale image we can use the cmap argument here and we can tell it that it's actually gray and to fix the problem of the layouts what we can do is use plt dot type layout and this is gonna automatically add more space so that we can see the labels and the images uh in a much more understandable way so let me run the command again python and this example.buy and as you can see now it looks much more clear these are the images that exist inside our data set they are grayscale images and above each one we have the corresponding label so this is a two this is a one a one this is a four a three here a six so we have all of these examples and why do we do this it's just a way to basically quickly check your data set sometimes what happens is that when you're building your own data set and you do this kind of exploration you quickly spot some things for example you might spot that this is a zero but uh but it's not labeled correctly for example you must see that this is labeled as nine when it's actually a zero so that's gonna give you basically just quick hint that there is there are problems with your data set and you can maybe go fix them quickly and the good thing is that whenever you run this script it's going to choose randomly different images so you can see different parts of your data set each time you run the script so here we have the two six one for example in the beginning just so that we can remember and let's run it again okay and now as you can see we have five 572 instead of the 261 i think it was before so this is just about the exploration of your data set as i mentioned it's always a good idea to do these quick exploration steps before we start doing anything and now that we see that okay our data set is more or less okay let's see what we can do next in regards of creating a model and later training it now that we have our data set loaded and ready let's see how we can build our neural network so in fact tensorflow gives you access to so many layers that you can use to build your neural network so if for example you do from tensorflow import here you have many different layers that you can import for our classification task and for many of the computer vision tasks we usually have a set of layers that we basically always use so these layers are conf 2d so this is a 2d convolution we also uh always use of course an input layer so here i'm going to add input so this is a layer that basically gets our input and then passes it to the rest of the layers and there is also the dense layer so it's also called fully connected layer we have the max pool 2d so since we're doing 2d convolutions we're going to combine them with a max pool 2d and it's always good to use batch normalization to normalize our batches and also we might want to use a flattened layer which basically takes the output from some multidimensional layers like a convolutional layer and then it just flattens them and puts them in some sort of a vector and also in fact in many cases you can use just global average pooling or global sorry here global average pool 2d so this layer also can uh can work in a way that's closely similar with flattened but they're different in the way they do it so flatten basically takes all of the uh all of the outputs of a previous layer puts them into a vector but in the global average pooling there is some sort of a compute computation of the mean based on some axis and then the output usually is much smaller than the output given by a flattened layer so here i'm basically mentioning some of the basic layers that we use in a neural network for doing image processing or doing uh deep learning for images type of things so for classification this is one case there's also object detection image segmentation all of these tasks usually you're going to find this type of layers in them and sometimes you find more complex layers and sometimes those complex layers are just basically stacking together different uh basic layers like these ones here so these are the layers that we're gonna use to build our neural network and now let's see how we can build that neural network there are several ways and mainly three ways that you can build a neural network in tensorflow we're gonna explore them now one by one the three approaches that tensorflow gives us or provides us in order to be able to build deep learning models are the following so the first approach is by using tensorflow.keras dot sequential so you can call it the sequential way this is the easiest way to build a deep learning model you just stack different layers together and we're gonna do this in a minute the second approach is by what's called the functional way or the functional approach so basically here you build a function that returns a deep learning model or just let's just write a model and the third approach is to basically inherit from a base class this base class is in tensorflow.keras dot model so you inherit from this class and then you you reimplement or you overwrite some of the methods of this class and then you can have a deep learning model so inherit from this class so these are the three different approaches let's start with the first one so in order to build a deep learning model architecture using this sequential class in fact it's very easy you just call for example let's call our model model and then you call this sequential class and show and then you can start stacking layers here so what we start with always is an input layer so here we're going to use the input layer that we imported here and what this input layer takes as a an argument it takes many arguments but the main one that we need to set is the shape of the input so as you remember our images are 28 by 28 and they only have uh one channel they are grayscale images so there's only one channel this means that our input needs to be 28 by 28 by one one represents only one channel and then the second layer that we're gonna add here is going to take as input this layer and usually when you're doing image classification tasks or other computer vision related tasks in deep learning you take the image and then you pass it through some convolutional layers so here we're going to do the same thing so conf 2d and since this is the the first convolutional layer let's go through some of the parameters that exist in this layer so one thing that i like to do is to just hold the ctrl key and then hover over that class and as you can see visual studio code can give you so many information about that class and here the mandatory parameters that we need to set are filters and the kernel size and then you have the rest of the parameters already set you can change them if you like and here even gives you some examples and they give some explanations of the different different parameters so the number of filters here so let's start with for example 32 filters of size 3 by 3 and here let's also set an activation function and i'm going to use a real u activation function so here there are all of these parameters what do they basically represent for us so this number here the 32 represents how many filters or how many uh basically well each filter has a set of weights and in fact here we're defining how many weights values are in that filter so this means that we're creating 32 filters each filter filter is three by three of size and then we're choosing an activation function here we're choosing rectified linear unit there are several activation functions and all of these parameters you might be thinking why do we choose 32 and not another one why do we choose three by three and this is real you why do we choose these specific parameters where in fact these parameters are hyperparameters you might have heard of this term and these are parameters that you can change and each time you change and you train your new deep learning model and you see whether the accuracy has improved or not so far there's no very solid theory on how many parameters you should choose in each phase so it's really an experimental approach you choose some of these parameters you train your model and then you go change them again and train your model again and see if you get a better accuracy now i am choosing some of these parameters based on much previous work that has been done by researchers if you see a lot of the neural networks used for classification they would start with something very similar to this so i am following on their footsteps because i know that they have done so many experimentations with those neural networks so here i'm going to start with a convolutional layer usually what we do is we create a block of convolution where you have a convolutional layer then you would use max pool 2d and then you would use a batch normalization layer and then you can do the same thing again another convolution max pool normalization and you just change for example the number of filters or the filter size here or the activation function so what this max pool 2d does is that it takes the output of the convolution and it looks in both directions and based on the pool size so again let's maybe go to the documentation that's written inside the code here what you have is let me just go way down you have the pool size and it's two by two what this means is that the output of the convolution we're gonna look a two by two window of the output of this layer and each time we're gonna use we're gonna keep only the max value between those four values because it's a two by two window so there are four values we only keep the max value between all of those four values and here you can in fact change this you can set the pull size to four by four which means it's a four by four window where you keep only the max value in that in that window and again why do we keep two by two why don't we change it as these are also hyper parameters that you can change and each time you change you retrain your model and see whether you get better results so this also goes into that experimental experimentation approach that we do at uh as machine learning engineers or data scientists so this is one way to do things and the in fact you're not you're not let's say you don't strictly need to follow these approaches you can experiment for example you can add a convolution to the here and you for example let's do 64 and the three by three and activation is uh is it activations or activation sorry let me just check again so here let me go into the parameters activation now it's only is without an s okay so you can do this you can remove it you can add another layer feel free to experiment with this uh architecture because this is where deep learning is is different than uh conventional software engineering you can do so much experimentation with all of these things and you will have different results and only based on those results you can say that your model is better than the previous ones or not so here let's for example keep it like this and let's create another stack of layers here so conf 2d and i'm gonna for example use 128 filters keep them three by three and the activation is the same as before so real you and this approach here where i take 32 64 and 128 is also something that i've seen being done in research so many neural network architectures follow this kind of approach where each time they double the number of filters so i'm choosing to do that but in fact nothing is stopping you from using other numbers here you can use for example 110 or just 100 or whatever you like so i'm gonna finish the architecture using the same approach here so now i have these layers that are very similar so we take an input we do some convolution here then the second convolution we max pool we do batch normalization then again we do convolution max polling batch normalization and here just if i didn't mention batch normalization before so batch normalization is basically looks at your batches and does normalization on that batch this is an operation that is that is inspired from the uh normalization of the input which is something that we're going to do a little later so basically researchers have noticed that when you normalize your input this helps the gradient the computational of the gradient and it helps when we're trying to minimize our cost function so some other researchers said okay if we're normalizing our inputs why not normalize the outputs of the layers inside the neural network so this is why they created this new type of layer where it takes the output of this previous layer and then it normalized the the batches so each time we have a new batch we normalize the data inside that batch and finally since we finished the convolutional parts here which are the main layers that's going to affect our neural network because they can learn so much and you can check some of the papers about this maybe the young lacoon paper which was the first one that introduced the convolution or 2d convolution and you can see how much we're saving in memory and how much they actually improved the results now let's get to the part where we basically built what comes later at our neural network architecture so here i'm going to use a global average pooling and then i'm gonna add a dense layer i'm gonna add a dense layer of 64 units and an activation of real you so i'm gonna keep the same activation function as before and then i'm gonna add a final layer here and now i'm gonna use an activation called soft max and with this i have actually finished building my neural network using the sequential approach and let me just go through these layers quickly and what we're doing here so the global average pool 2d it takes the output from this patch normalization layer and it computes the average of those values according to some axes and then we're going to get a set of values here and then those values are going to be fed to a dense layer this dense layer you can think of it as a vector containing values so there are no filters like the convolution like 2d convolution here and finally we're going to add another dense layer which has 10 values and this will be the output layer of our neural network and we're choosing 10 here because in our data set the amnes data set there are 10 different classes that we can have from zero to nine so there are ten classes so again if we go back to the first uh the first time i spoke about our classification system i mentioned that we want to build the system that takes the image as an input and we want it to tell us at the output which of the ten categories so is it zero one or until nine so this model here reflects exactly that we're taking an input image and the output is a set of 10 values which will be in fact 10 probabilities we're getting probabilities because we're using this activation function called soft max so the soft max gives us 10 probabilities and they sum up to one so what we're going to do is look at those probabilities and look at the highest one and that would correspond to the class predicted by our model so this basically explains why we're using 10 here and we're using the softmax activation function here and at this stage here you don't have uh as many options as you would have in these layers for example in this dense layer you can choose a different value here so 128 132 it doesn't matter you can change the activation to something else but at this level here here we are at the output of our layer and we know that we want to predict one of 10 values so it has to be 10 here and also we want those values to be probabilities so that they reflect what the model thinks about our image that's why we're using soft max here apart from this there's also the input layer where you don't have much choice you have to set the shape that corresponds to the shape of your dataset so we know that our images have 28 by 28 pixels so it has to be 28 by 28 input we also know that our images are grayscale so they have only one channel that's why we have to choose one here so apart from the inputs and the output layers these layers here you can change so many parameters in them and each time you train your model and see whether it gives better results or not so with this we're actually done building our first neural network using the sequential approach now what we're going to do is continue creating the rest of our program so that we can make use of this model train it and then test it on some of the examples in our data set so now that our model architecture is ready let's look at how we basically set up the rest of the things so that we can run the training so the first thing i want to do here is just basically omit this part here and one thing that i like to do is just use some kind of switchers here so it falls so that i don't like to comment the code that's uh that's important and also i don't like to delete it so i just like to use this kind of approach here and now what we're going to do is the first thing we need to consider is that our data is in some sort of a a row uh manner this is how we got it from the load data method here but before we start to pass it through our model so that it can start to learn we need to normalize it so in order to normalize the data we're gonna use some basically division approach so here we're going to do x strain and usually what you would do is just divide it by 255 because our values are between 0 and 255 to 255 represents white and 0 represents black and the thing is our data set here is an unsigned integer 8bit data type before we do that before we do the division i mean we need to basically transform it into another type so as type and here i'm gonna do float 32 bits and why are we doing this is because if we don't transform it into this float 32bit type what's going to happen is that the values that are between 0 and 255 so let's say 2 200 for example when you divide it it's gonna become zero instead of zero point something that's because the data is an unsigned integer 8 bits format but when we turn it into 32 float format what's going to happen is that we're going to get that zero point uh something which will not be absolute zero which is which is exactly what we want to have here and we're gonna do the same thing for the test set so test as type i'm gonna do float 32 and then divide it by 255. so again why do we do this normalization approach here uh it just it's been uh by experimentation we've seen that when you normalize your data the gradient moves faster towards the global minimum of your cost function but i have to say that i have done so many experimentations where i didn't normalize the data and it still worked okay there wasn't that much difference between when i normalized and when i didn't normalize the data but here just for the sake of good practices i'm gonna keep the normalization here and uh one thing also that we need to do is to basically make our data set in a in in such a way that our model can accept it in its input so as you can see the input model expects expects 28 by 28 by one and here as you can see our data set uh of course there are these sixty thousand images this does not matter for our model it's gonna take them batch by batch but here we see that our arrays are formatted in such a way where we only have two dimensions so 28 by 28 but we want to have 28 by 28 by one so in order to remedy this we're gonna do x train equals mp dot expand dims so this is to expand the dimensions of an array and we're going to give it the same array so x strain and then we can use the axis number so here we want to expand the last dimension so we know that our array has here three dimensions so of course when they are three that means this is dimension zero this is one this is two so we can use for example three here and that would work but uh you can also do just minus one which means we want to add dimension at the end so here we're going to do x test the same way so let me just copy this and here i'm gonna do test so now in fact our data let me just maybe copy this and paste it again just so that you can see the difference so now our data is normalized because we use this uh these operations here and but also the dimensions have been changed so let me just clear this then run mnist example just quickly to see what we have differently so as you can see we had this shape for our data set before now we have this and this is the right shape to use with our architecture because again our architecture accepts 28 by 28 by one of course the first dimension that represents the batches it doesn't matter so we don't mention it here so uh it's not gonna cause any problems but if we don't have our data set in this format it's gonna actually pose a problem and maybe you will have this question of why don't we just remove this here why don't we just do this and then we don't need to expand the dimensions in fact if you do this what's going to happen is that the combo you're going to have a problem with this layer here because the 2d convolution expects a 4d fourdimensional tensor and what this means is that here we have the this tensor that represents the shape of the data but there will also be a dimension here it's hidden here it's not shown which represents the batches so we can take several images at the same time so with adding that dimension for the batches we're going to have four dimensions here and then the convolution 2d will not complain about dimensions so that's why we're doing this here and that's why we're expanding the dimensions here and okay let me just maybe remove this for now we don't need it and now that we have all of these uh all of our data ready to be uh passed through our model let's compile our model here and by compiling i means i mean we're gonna set some of the important aspects of the training so we're going to do model that compile and then inside this function here you have several parameters that you need to set so there's the optimizer and there is also the loss and finally there are the metrics so these are the three important parameters that you need to set so here the optimizer what it represents is the algorithm that we're gonna use in order to uh to optimize our cost function and by optimizing i mean trying to find the global minimum of our cost function so for this we have several options in tensorflow the most famous one is adam which we will be using but there are or several uh optimizers in tensorflow so let me just maybe try to okay sometimes it's not giving me option to see uh to see all of the parameters but here we can set the parameter atom there's also ada and there are several others that you can use so here if you go to the tensorflow documentation and the tf.keras.optimizers you see that you have all of these options that you can choose from there's the ada delta other grad adam so on so forth you have the stochastic gradient descent here so you have all these options that you can use again which one to use really depends on uh the case that you are uh you are doing and this also goes into the hyper parameters part where you for example you might choose adam train your model and then you might change that and choose for example an adam and you might get better results using this uh other optimizer so it's really an experimental approach and i again i do encourage you to change things and see what you can get with those different parameters so let me uh go back to our example here so here when you want to pass a parameter to this argument here optimizer you can just put it between parentheses or between these quotation marks here and you just write the name and you can of course choose any of the other ones and write it here and this is how you set the optimizer the second thing which is very important that we need to set is the loss function so for the loss for every task in uh in deep learning you have a set of loss functions that you can use for that specific task so in classification one of the widely used loss functions is called cross entropy so these are two different uh two different words cross entropy and this is actually a function that uses uh probabilities and it computes some sort of probabilities that helps penalize your neural network weights when they are when the when it predicts the wrong thing and also helps it know which values are predicted correctly so there is a whole a lot of research about cross entropy that you can look up online but in fact just in tensorflow you have three different loss functions that have the name cross entropy in them so here again i'm looking at the documentation on in tensorflow and if i didn't mention it before i would very much recommend looking at this documentation from time to time it's uh written in a quite understandable manner and you can get a lot of information from it so again for cross entropy if you go to the documentation you'll see that you have binary cross entropy you have categorical cross entropy and also you have sparse categorical cross entropy so all of them they have cross entropy in them so they use this cross entropy approach but each one of these three loss functions uses it differently and for us here we're gonna use categorical cross entropy and we're gonna use spas categorical cross entropy and i'll show you what's the difference between them so here let me start by using catigorical cross entropy and i'll explain a little bit later do we why would you want to use categorical and why would you want to use sparse categorical for now let me just finish this part here for compiling our model so for the metrics which is the last argument here we need to set a metric for which the uh basically we're going to guide our training so that our model knows that it's becoming better or worse so here usually for classification we would use the accuracy so the accuracy represents how many examples are we predicting correctly from all of the examples that exist in the data sets so let's say you have a data set of 100 examples let's say images and when you do the prediction prediction you get let's say 88 images correct and the rest are incorrect in this case the accuracy would be 88 over 100 which is 88 this means the accuracy is 88 so this means that your model makes a good prediction 88 of the time so if now we have a thousand images and around 880 images will be correctly predicted so for classification this is what we would need as a metric and of course here i am using the usual values that are used in classification but there's a lot of advanced things that you can do for example you can create your uh your own loss function your own optimizer your own metrics and then you can pass it here as a parameter but this is a little bit advanced so for now i'm just gonna go through the steps with the usual values that are used in the deep learning community so now that we have compiled our model the only thing that's left is to fit the data into our model so for that we're going to call model fit and the fit function uh takes several uh parameters the first parameter is the x strain so the uh the images and then it's gonna take the y train so the labels corresponding to those images it's also going to take a batch size so this batch size represents how many images is our model going to see each time so here you can for example if you set it to one this means that we're gonna pass one image uh at a time to our model but we usually don't do this we usually choose a larger number of images to pass them through our model so here for example we can use 64. this is also one of the hyper parameters that you can change and see how your model will perform based on different and also we're gonna set the parameter epochs here and let's say i'm gonna choose for example only three epochs so that we can quickly do some experimentation and the epoch represents one epoch in fact represents that the fact that your model has seen all of your data set once so when all of your images are passed through the model if they're if this is done once then this is one epoch if your model has seen them twice then these are two epochs so on and so forth so basically here we're defining the number of times that your model is going to look at all of your data sets this is also a hyper parameter so here in fact we can keep it just like this and we can run the training which means that all of the images that exist in the train set are going to be used for training but one thing that that you can do in fact is use a validation split so a validation split here for example let's say i'm going to use 0.2 this means that i want to use 20 of the train images for validation so again what would what does validation mean what what is it why is it different than the test set for example in fact in the when doing cross usually you split your data into the train the validation and the test sets split them into these three parts the train set will be used to train the model the validation will be used at the end of every epoch we're gonna run the model on the validation not for training but just for prediction so that we can see how well the model is doing on data that it did not see it did not use to train so these in fact these two splits are the ones we use to fine tune our our model so when i mentioned hyper parameters i mentioned that this for example hyperparameter this is a hyper parameter the values here are hyper parameters but when do you say that one or a set of hyper parameters is better than another set of hyper parameters in fact you do this using the validation split so whenever you train you test on the validation split or on the validation part and then you see whether that metric that you're using has improved or not so in our case the metric is the accuracy is the accuracy uh becoming better when we change the hyper parameters so you do one training with a set of training parameters you see the validation set is it good or not and then you change the hyper parameters you run the training again and you look at the validation accuracy did it become better they become worse and you keep doing uh this loop of experimentation until you get to a point where you see that you're not improving anymore on the validation set and then only when you're done with this experimentation phase that you keep the final model that works well on the validation set and then you test it on the test set so with this parameter here validation splits what we're gonna do is split our training set into two parts eighty percent of the training images or the images that exist in this uh extreme variable are going to be used for training and 20 of them are going to be used for validation and then we're going to keep the tests set here until the end when we finish the training and we're going to use it to evaluate our model to see how well it performed on images that it has never seen so the images here whether they are in the train set or the validation set the model is gonna see them at some point during the training but the test set we're not gonna use it in this function here which means that the model will never see it during the training and is we can uh we can pass that set of images to the model only at the end of the training so for example we can pass it here model that evaluate and we can give it the x test apply test and we can also choose a batch size here let's just keep it the same as before so again just to summarize quickly what we're doing here we're taking the train images so 60 000 images we're gonna split them into two parts eighty percent of the images so eighty percent of the sixty thousand images is going to be used for training the rest which is 20 is going to be used for validation and the train set or the test says sorry which is the 10 000 images here are going to be used at the end when the model has finished training so at this point here this is model training once this line here is done then the model is trained and here we can do evaluation on test set this set here the x test is going to help us identify how well our model is going to perform on data that it has never seen because usually what you do is you train a model you put it in production and then you start testing it on new data that's coming from for example your users if you have some sort of a web product and those examples the model has never seen them so in order to get an idea of how well your model will perform on examples like that you keep this part here separate from the training and the validation you keep it until the end and then at the end you test your model on it so this is the goal of this test set and the the goal of splitting the this set here into two parts now we have a complete program that we can run and we can train our model and we can see how well it performs on train validation and test sets so let us do that right now let me just clear this and i'm gonna run our example here so this might take some time depending on your machine but usually it shouldn't take that long well in fact when i ran the code i got into this error here and in fact i wanted you to see this error because it's a very common error and uh i wanted to use it in order to explain to you why you would want to use categorical cross entropy or sparse cross entropy in fact this error is coming from uh from this specific detail here so when you have a data set like we have here if you use categorical cross entropy then in fact this loss function is going to expect your labels which are these ones uh the x the y train and the y test is going to expect them to be one heart encoded and if you don't want to use one heart encoding then you need to use a different loss function which is the sparse categorical cross entropy so this is a minor detail but it's very important so if you go in fact to the documentation so here in the documentation i just opened uh the two pages for categorical cross entropy and for sparse categorical cross entropy so for the categorical cross entropy here although uh it's not specifically mentioned here but in fact if you look at the example you see that this is how you would use categorical cross entropy these this this is how your labels need to be set so in fact this is one label for one image which is in the form of a vector and in that vector the one will correspond to the right class and the zeros will correspond to the wrong classes so if you have three classes then you need to set one to the right class and zeros for the rest in our case if we wanted to do one hot encoding then for example if you have let me just do this quick example here if you have label two then one hat encoding will be like this it will be a vector of 0 0 1 then 0 0 0 and 8 9 10. this will be the corresponding label for that for that image so the image contains the number two but your label needs to be like this and this is called one hot encoding of your labels now uh if in the case uh how we're using our data set in fact we're not using one hot encoding so our labels are just encoded as numbers so if it's the second if it's number two then the corresponding label is two if it's zero then it's zero so on and so forth we're not using onehalf encoding so if you use categorical crossentropy then you have to use onehalf encoding which means that you have to take the y train y test and turn them into one hot encoded labels and if you don't want to do that you need to add the sparse categorical entropy here instead of the categorical cross entropy because if you go to the documentation you look at the sparse categorical cross entropy you see here that we're using labels in the format of the normal format not the one using one hat encoding so when doing this if we save this let me clear this again if i run my example now we should have no problems everything should be running smoothly and as you can see the training has started here and let me just stop it here just to show you uh if you were to use categorical cross entropy what would you have what would you need to do differently because sometimes you might have a data set that already has one hot encoding labels in that case if you just want to use them as they are you don't want to transform your labels into a different format in that case you would just use categorical cross entropy but if you have labels like this that are not one hot encoded and you want to turn them into one hat encoded what you can do is use a utility from uh tensorflow so here we're gonna do y train tensorflow.keras.utils.2 categorical and then you would give it y the same uh array so y train and then you want to tell it how many classes you have so we have 10 classes between 0 and 9 and you would do the same for the y test tensorflow keras details 2 categorical and here i want to give it test and 10 classes so now if i do this then in fact i'm transforming my labels into one hot encoded labels and in that case i can use categorical cross entropy so let's run the training again and see if this works or not so as you can see the training has started correctly with no problems and i hope now you understand differences between categorical cross entropy and sparse cross sparse categorical cross entropy and when to use which so i'm gonna wait for the training to finish i've only set the epoxy 3 because it already gives us some good metrics here and it's done so let's go a little bit over the logs here and i would like to explain to you what these things mean so this one here the first number here 11 seconds represents how much how much time we spent uh doing this one epoch and also this tells us the speed so 12 milliseconds per step and the step here means doing a full badge so we have a badge of 64 images so where the model is processing 64 images at the same time in 12 milliseconds and by doing that the first epoch we got a training loss so this loss here is the training loss of 0.2368 we have an accuracy of around 93 we have a validation loss of 0.0994 and we have a validation accuracy of around 97 and what this means is that as you remember we did this split here validation split so the first loss and accuracy are reported based on the 80 of the data that we use for training and this part here for the validation is reported based on the 20 that we left out for the validation so it's 20 of that extreme and after each epoch we get these values so that we can see the development of the loss and the accuracy and what you want to get here is a lower loss during the training and a higher accuracy and at the end this last line here we've actually ran it over the test set just to see how well our model our final model that we got here how well is it doing on the test set and here we see that we got a 98.36 accuracy which is not bad on this task so as you can see now we have a full program that has a deep learning model and it compiles that model with specific optimizer loss metrics and then it fits the data into that model and when we're doing evaluation we're getting some good results so with this we have finished the first let's say a part of doing training for an image classification task and as you can see it with tensorflow it makes so many things easier you don't have to do a lot of things you just need to set the right parameters and prepare your data set in the right way so now that we have this uh first version of our program working let's see what we can do next this first model that we created and we trained was using the sequential approach here where we just stacked different layers and now let's take a look at the other approach that we can use which is the functional approach so first let me just maybe change this to sequential model just changing the name here and here what we want is to build the same exact architecture but in the functional approach so in fact to do this you just need to create a function and let's call it for example functional model and here you need to use these same same layers that we used in our sequential model but we're gonna use them in a functional way so let us just maybe copy them from here and just paste them here let me fix the indentation and in order to build a model using the functional approach what you need to do is basically define a set of layers and each time you need to pass the output of the previous layer to as an input to the new layer so here for example i would call this my input and then for the convolution 2d i need to actually pass my input as as a parameter to this convolution 2d and then i need to store this into a variable and i need to do this for the rest of the layers so each time i have an output of a layer i need to pass it as an input to the upcoming layer so let me just do this quickly here so now i have done exactly what i explained to you i'm just using each time the variable x to store the output of a certain layer then i'll pass that variable as an input to the next layer and i do this for all the layers oops i've got this one here and okay we have it here here we have it everywhere and now when you finish doing this you need to basically create the model where you tell it that this is the input and this is the output so the input is this and each time we're passing it to our layers and we're getting an output here which is x but in order to construct a deep learning model that you can call the compile function and the fix the fit function on it you have to use the tensorflow.keras.model class and here you need to give it inputs and it's going to be my input and also outputs which is going to be x and then you return your model so this is how you would build a deep learning model architecture using the functional approach so as you can see it's the same exact model it's just that we're building it differently now why would you use this approach rather than this sequential approach well in fact the sequential approach is rarely used when you're building deep learning models for some let's say complex tasks and even for smaller tasks i think it's if it's uh it's better to build your model in this way here because it's much more flexible you can do so many things for example if you have let's say two different inputs you can just set them here this will be a list of inputs where you just add the inputs to it the same thing if you have several outputs so it's a lot more flexible i think and also it's going to allow you to for example you can build one part of the model then create another part and use those two parts into when building a larger deep learning model so this is a much better approach in my opinion i've only seen the sequential approach here used in some tutorials online because it's easy and it's basically allows you to quickly build something that you can manipulate but for real world projects i think that using this functional approach is much more recommended so now that we have this we can just go to our code here sorry let me just close this here here i'm just gonna call my function so model functional model and then i'm just gonna call the same exact methods on it so the compile method the fit method the evaluate method and what's also good about this functional approach is that you can make this uh this architecture much more flexible for example by uh adding parameters to your function that you later add them here for example the number of filters here the uh the filter size here you just add them all as parameters here and then you can generate several models quickly you can just create for example a for loop and you create several models with different hyper parameters and then you compile them and fit them and compare between them so as you can see this would be a good use case for functional model instead of using sequential model so now that we have this let's run our code again and see if this works or not so let me just run this so the training should start and it did so as you can see we have just defined the same architecture in a different approach which is the functional approach and it's working well the loss is going down the accuracy is going up and let's just wait for it to finish this should not take long it's going to run the evaluation on the test set here and as you can see we got the uh the results here from our functional model and there was no problem during the training uh or the evaluation so this is the second approach that you can use to build deep learning models the third and last approach is by using or by inheriting from the tensorflow.kerastat model class and which is what we're gonna do next to build a deep learning model architecture using this third approach you start by creating a class you can give it any name you like so for me i'm just gonna call it my custom model and then you need to inherit from the class tensorflow.keras.model and in python to do that you just add parentheses and you have the class that you want to inherit from so here model let's start with the instructor here and here we're calling it on the uh the mother class which is this class here let me just maybe remove this we don't need to use it and now what you would do and in this third approach is that you need first to define all of the layers and you need to give them a name and then you would use the or you would call the function in fact implement the function call which is just like this and then you can give it your input and then here what you would do is you would pass your input throughout your layers here so you start with the first layer and then you continue so to make this more clear let me just do this here first we're gonna define all the layers and again i'm going to use the exact same architecture and just we're implementing it in three different ways so that you can compare between the uh three approaches so here i'm just gonna start by creating these layers and give it giving them names so here i have just done exactly that as you can see i call my first convolutional layer self.com1 cell.com2 so on and so forth and here when i go to my call function here i can start calling them so my input needs to be passed through this first layer and then the output of it needs to be passed to the second layer so on and so forth so this is what the call method here needs to do so let me just do this quickly now so i have just finished doing exactly that i just i take my input i passed it to my com1 cell.com1 layer which is this convolutional 2d and then i get an output then i pass it to the second one so on and so forth and at the end i need to return x and this might look a little strange this approach compared to the other ones but this is also one of the approaches you can use to build custom models especially if they're much more complex than than this you can do so many things when you have a class specific for your for your tensorflow model and in fact if you've worked with pytorch before then this should be very familiar to you because it's very similar to what pytorch does in pytorch you do the same thing you define the layers first and then there is a method i think it's forward if i'm not mistaken instead of call and then you do the same thing you pass the input to the first layer and then the output to the next layer so on and so forth so we're doing this with in fact we just finished uh defining our model using this third approach and we can use it to in the practically the same manner we used the functional and the sequential model so let's see how we can do this so i'm just gonna comment this one here and now instead of using my functional model i'm just gonna use my custom model so just calling or instantiating an object from my custom model class i get my model and then i can do exactly the same thing i can compile my model i can fit my model i can evaluate my model and let's test this quickly here let me run the example again so okay it says okay now the training is running and as you can see uh we're doing the exact same thing as we did with the first two approaches and now you have seen the three different approaches used when creating an architecture for a deep learning model and tensorflow and you can use whatever you like you can also use them all three depending on the task that you're doing and depending on the specific circumstances but here as you can see we defined the same architecture in three different approaches and we were able to fit the data and evaluate our model and the results are very close so now you have all of these uh these tools and these approaches that you've learned and we use them on the amnest data set let's see now what we can do next so there are some things that i omitted in this first tutorial here i just wanted i wanted to only show you the main parts that you need when training a deep learning model but in fact you can do a lot more things and there are some necessary parts that i didn't mention here so for example one thing is about saving the model so here we're just doing the training and evaluating the model but we're not saving anything so what if i want to use this trained model in production what if i want to use it in some sort of a web app or an embedded application in that case i would need a model that i can take and then i can run in a separate script that just loads the model and makes predictions with it something else that i didn't do is saving the best model during the training so there's one thing you can do here we just saved the final model but if you notice here for example let's see if we have a good example uh yes okay so you see this second step here we have a higher accuracy than the last epoch so it's actually better to save this model that was uh finalized in this epoch rather than the last model with which was uh saved or it wasn't safe but which we got at the third epoch so we're not doing this now we're not saving the best model we're not saving any model in fact i wanted to show you this in this tutorial but then i thought it would be better if we leave this in the next tutorial that i'll show you which will represent a real world uh scenario because here with the amnest examples which are the hello world equivalent in programming you have the amnest data set already prepared for you you see we just used it as part of the tensorflow framework so we're just loading it and then we are using these these images and labels when training our model but if you're working on a real world case then maybe you would maybe you would have collected images by yourself maybe you went outside and captured some images here and there so in that case you need to create your own data set that is compatible with tensorflow and that you can use it to train a deep learning model that you would define just like we did here so i wanted to leave these details of saving the model during the training and saving the final model the format of saving the model i wanted to leave them for the next tutorial that we're gonna do so with this first tutorial you should have all the uh necessary steps that you would use to train a deep learning model for classification uh many of these or most of them in fact most of these uh parameters most of these things that we've done here we're gonna redo that in the next tutorial but just we're gonna go into maybe more details about specific things like the data set uh how to create a data set that you can use just like the keras or or just like the amnes data that sorry how to save the model during the training how to save the final model in the saved model format and things like that so for now this is it for this tutorial and let's take a look next at what we can do in a real case scenario so before we continue along the course let's maybe restructure a little bit our code for better readability this is something that you're gonna find yourself doing often when you're developing projects for uh for a company that you're working for and in by doing this you're actually gonna make your life easier in the future because you're gonna have all of these different modules that contain different parts of the code and many of them will be reusable modules so that you can use them in other projects as well so the first thing we're going to do is maybe move these two models the functional model and the the model that inherited from this class into a different file so for that let me just create a new file and maybe just call it deep learning models dot by and what i'm going to do here is just move these parts of the code so let me just move these ctrl x and control v and here i can just import the same modules or the same functions and classes that we used in our code and also i'm gonna import of course tensorflow because we're using it here and by this we're gonna have our models in a separate file and then we can just come to our main script and do for example from deep learning models import functional model and also my custom model so as you can see we moved large part of the code into another file and now we have this file here that just contains the deep learning models so maybe we can use these models in a different projects and we will find them in a separate file instead of finding them in this script that's specifically made for mnist data set another thing we can do for example is move this function here display some examples to a different file so maybe we can call it for example my utils dot by and also okay let me close this i'm gonna come here and just cut this and paste it here and here of course i'm gonna have to import mad plotlib dot pi plot as plt and also i need to import port numpy as mp so now we have this and of course we can import our functions the same way from my utils import display some examples and now as you can see a large part has been moved from this file and now this file is specifically made for the amnest data set and we're importing the necessary models and functions from our other files that we just created so i am showing to showing you this here just as an example that you can use for your projects because when you're working for a company and you're building ai projects machine learning models you're going to find yourself doing lots of experimentation you're going to find yourself reusing parts of your code so if you get used to this habit of taking uh different parts of the code that are reusable and putting them into separate files this is going to help you a lot uh and your future self is gonna thank you and with this uh that would be it for the coding of this first tutorial let's see what we can do next so let's just recap what we have seen in this first tutorial so basically we took a look at the amnest data set we saw how we can load it from the tensorflow data sets we explored that data set by implementing a function that can go through the data set and randomly choose some images with their corresponding labels we took a look at the tensorflow layers how to import them and then we saw how we can use those layers to build a neural network architecture in three different approaches the sequential way the functional way and by inheriting from the model class at the end we compiled our model and fit the data and we finished the tutorial by restructuring our code for better readability so with this this would be the end of this first tutorial let's see what we can cover next welcome to this second part or second tutorial in this introductory tensorflow course so in this tutorial what we want to achieve is something like the following so we're going to have a data set of traffic signs like the ones you see here and the goal would be to develop a deep learning model that can take an image of a traffic sign like this one and then it gives us at the output that this image actually corresponds to the traffic sign of speed limit 100 kilometers per hour and maybe it will not tell us exactly this expression here but maybe it can tell us that it's one and that one corresponds to this speed limit uh 100 kilometers per hour and if we try if we change the traffic sign we want to get the corresponding sign here so we're going to be developing and building and training this deep learning model and this will be the goal of this second tutorial the data set that we will be using for this tutorial is called german traffic sign recognition benchmark so this data set you can find it on kaggle so if you don't know the website kaggle it's a website that many data scientists machine learning engineers and just anyone who's interested in machine learning uses it because it has so many data sets it also has some competitions that you can join and you can even be part of a team and you can learn a lot by doing that so this data set in order for you to get it you can go to this link here and if it's maybe the link is not that clear since we see so many meow meow here you can just take the german traffic sign recognition benchmark expression here and you can look it up let me just maybe go back to make it clear so if you're on the kaggle website you're gonna go here on the search bar type this and look it up and it should be the first result and then you're gonna get to the same page that i showed you earlier just a quick note here so in order for you to get access to the data set and download it you need to have an account on kaggle it's completely free i already have one and i'm already logged in but if you don't have an account you can just create a an account for free and then you can continue with going to the data set page and download it so in order to download the data set you just click on the button download and then it's gonna download it to your own machine and once it's downloaded it's going to be a zipped folder like this and then you can unzip it in order to get a set of files and folders like this just a quick note here also when i was unzipping this folder here i realized that i think the data set is duplicated so many files it asked me that whether i want to replace them or just keep both versions when i was unzipping this file here i chose to replace them so that i don't have a duplicate of every file and every folder in my data set i think this is maybe a mistake that was done by the person who collected or put the data set on kaggle but it's not a big deal you can just unzip the folder and when it asks you whether there are new files and folders that have the same name just choose replace or choose do not replace for the rest of the data set and that way you won't have any duplicated folders and files and now that we have it here and as you can see i unzipped it we see that we have three files and three folders so the main files and maybe the main folders that we're gonna be looking at are the tests and train folders and also the test.csv file so let's first go to the train folder here so as you can see we have 43 folders of from 0 to 42 so 40 43 folders and in each folder we have images that belong to the same class let me see if this is the large let's see i is the same okay so for example we can see here that this is a sign for the traffic sign that says there's a speed limit of 20 kilometers per hour we also have this data set here of the speed limit 50 and we have all sorts of speed signs as you can see and what i really like about this data set is that the images represent real life cases now not like the amnest example where the data set is more or less already prepared for us but in the case of these traffic signs we see that these signs are taken into in uh different luminosity levels uh different light levels uh it also comes in different sizes so different images have different sizes they're not all the same and also if we go to the next folder which is the test folder here you can see that we have a set of images and we can't know just from the name for example whether this image belongs to class 1 2 or whatever so we can't know from just looking at the image and looking at the name of the image in order for us to know uh each image belongs to which class we need to go and look at the csv file corresponding to that folder so test.csv for the test folder and let me just open it here okay let me close this so here as you can see in the test.csv file we have a different lines corresponding to different images each line has these width and height of the image also has a roy area i guess it's a more tightened area around the traffic sign we also have the name of the image and we have the id of the image and these are the two most important information that we need from this so we need the path and we for each image we need to know the corresponding class idea so here let me just maybe open this close so let's go to the test so for example the first image 000.png it says that this belongs to class number 16. this is the class id so it's 16 and if we want to just quickly verify uh just remember this is uh i think a traffic sign that says the trucks cannot pass through here or only for trucks i can't remember honestly and if i go to the train set and i go to class 16 as you can see it corresponds to the right class so from with what we see here we have two folders the first one for training the second one for the test set the test set is not organized like the train set uh in order for us to know which image belongs to which label we have to look at the csv file and there's also the fact that we only have two sets so there's only the train and test set but in reality what you want to have when you're developing deep learning models for real life cases you want to have three sets you want to have a train set a validation set and a test set so there is a lot of work to be done before we can train a deep learning model on this data set and this tutorial for me represents a much more mature case of uh much of a machine learning project where basically you are using a reallife data set if someone collects it maybe uh he chooses to annotate the data set like this where it just puts the images in one folder and keeps a csv file corresponding to those images and their labels so as you can see it's not very clean not like the case where we had the amnes data set we just basically loaded it so now in order to build a deep learning model on this data set we have to basically do some cleaning and also some preparation of this data set and this is exactly what we're going to be doing next so the first thing we're going to do now to prepare our data set for training is to go to this train folder and we're going to split this data set here that exists in this folder into two different folders one for training and one for validation so basically what we want to do is to create some function that can go through all of these folders and each time it goes through the images in every folder and it takes part of them and puts them in a training folder and the rest it puts them in the validation folder so let's start by uh coding this and before that let me just maybe add a new script we're going to call it street signs example that buy so this will be for all the necessary code to basically load the data set and uh also train the model and evaluate it and here maybe let's first start by defining a function that's gonna split the data so let's call it split data and what this function is going to take is the path to the data so the original folder which is this one here we're going to take a look uh or we're gonna look into this folder here and then we want to split the data into a training folder so that to maybe let's call it say train and also path to save valve for validation and we're also gonna choose a split size and it's going to be between zero and one and i'm just going to give it a default value of 0.1 and what i want is for 90 of the data to be put in the training folder and the rest which is 10 it's gonna be put inside the save for the the validation folder so here let me come here and the first thing we're gonna do is basically get the folders so i'm gonna use os dot list deer and i'm gonna give it the path to data and since we don't have this module let me import it here so what this uh line here is going to do is basically it's going to give us a list of all the folders that exist inside this directory here and then what i want to do is to iterate through the folders so i'm gonna do for folder and folders and here first i want to get the path to or maybe let me call it full path which is going to be the path or the full path to the directory so here we're gonna have this path and then this first command here is going to give us the folders now we want to concatenate the name of the folder with this path here in order to get the full path to this set of images for example or this set of images so here i'm gonna use os.path dot join and we're just gonna use the path to data and also i'm gonna concatenate that with the folder after that what i want to get is a list of all the paths to the images inside that folder so i'm going to call it images paths and for this i'm going to use the module globe so it doesn't exist here so let me just import glob here so this module is going to allow me to look inside a folder and load all of the files that exist in that folder depending on an extension that i choose so here what i want to do is use os dot pat dot join and i want to join the full pad that i just constructed and also i only want to load the images so our images let me just take a look quickly all of our images have a png extension so i only want to load png files so here by doing this what i'm what i'm saying is that i'm telling this glob module to give me a list of all the files that have extension png inside my inside this folder here full path so now we have a list of all the images inside that folder and what we can do now is we can for example to extrane and x val and we want to basically split the data set into these two different parts and for that there's actually a utility function called train test split which we can import from the scikitlearn module so here if i do from scikitlearn dot model selection import train test split so by doing this i'll be able to use this train test split function here and what this function takes is basically the images pads images pads and also it's gonna take the test size so this is going to be the fraction that represents the number of images that we want to put inside this variable here and for this i'm just going to use my split size which i pass here as an argument so what i'm what i'm saying here is that please split all of uh the the please split the list of all of the images here into two parts train and val for validation and i want this second part to be only uh this fraction of the data set which is uh if we keep the value as it is then it's going to be 10 and if we call the function and we change this split size then it's going to take that exact fraction so now we have our train and validation pads and what we can do now is basically just go through them so first we're gonna go through for so for x in x trains so we're going through all of the images that were selected for the train set and the first thing we're going to do is get the name of the image and in order to get that we're just going to use the function os dot pad dot base name and we're gonna give it x as the argument here and was remember this x represents a full path here we want to get just the name of the image so we would like for example to get this only this uh five zeros five zeros five zeros dot png so this is what we can i'm gonna get as the base name and then we're gonna use basically the space name to reconstruct a new path that points to this path here and is we're going to save our image inside this path here so let us first do this folder i'm going to construct a path here os.path dot join and i'm gonna do path to save train and folder so here what i'm doing is uh imagine that for example i want to save my images into this let's create a new folder for example and let's call it training data and inside of this i'm going to create a folder called train and another call another folder called val for validation so what i'm going to do is take the images from folders like this and just go for example to the train set or the train folder and just put that image here and for now i'm just going to copy the images i'm not going to move them just so that i keep the original data set as it is but first here i need to add a folder for example one two three that responds to that specific label for that image and that's why what we're doing here is we're constructing this full path here so this is going to be this path and then we're gonna add a folder with the same name as the folder that we found in the original data set here and after that what we're gonna do is check if this folder does not exist so path to folder sorry if not os dot path dot his directory so this is gonna check whether this folder exists or not if it doesn't exist we're gonna create one what's that make theirs so this is to create that folder and i'm gonna do that to folder so this part here just checks whether that folder exists or not if it doesn't it creates that folder and now what we're gonna do is use the you the utility module sh util and i don't have it imported so i'm gonna import it here sh util and this module here gives me access to several functions one of them is the copy function that i can use and now what i can do is basically copy my image and put it inside a new directory that i just constructed here and if it didn't exist i would have already created it here and now i want to put my image inside this folder so what we can do is actually two things now that i'm looking at it we can either do path to folder and this is going to copy the image with the exact name that it has inside this folder or we can construct a complete directory with the name of that image so basically we don't need this here is in fact just going to take the name of the image and put it inside the new folder so this is going to be for the train set and we're going to do the same thing for the validation set so i have just added the part here for the validation and this is going to be identical to the train set the only thing i'm doing is looking at the original directory going through the folders constructing a new folder inside the train and the validation folders and then copying that image from the original data set or the original folder into the corresponding folder whether it's strain or validation and now that we have this let's test our function and i have also here activated the virtual environment that we used before which is tf2vn and in order to do that you can just point to the folder where you have anaconda 3 installed on your machine uh in order to use the script called activate and then point to the name of the environment that you have and also something that may be a quick way to do this let me just clear this first in fact if you're on visual studio code and if you have already used a specific virtual environment with anaconda before then what i have noticed is that if you click on the plus sign here is going to open a new terminal and also is going to activate that environment automatically so you can use this quick way to activate your virtual environment and now that we have this uh let me maybe first activate or save my script here and one thing you can notice is that this script or this module scalene is not recognized and uh just to reiterate what i showed you in the first tutorial if you click on control shift p you can choose the right interpreter and here i'm making sure that i am using the same virtual environment so it's tf2 vm and this module is not installed inside this virtual environment so for that you can do a quick pip install scaler for scikitlearn and this is going to install that module if it's not already installed and once this is done then here we can do the same thing as with before so if name equals main then i would like to do a set of things here so i'm gonna do uh i'm gonna basically choose the paths that i want in order for me to split my data set so the first path needs to be towards my original set which is this one so i'm gonna do this ctrl c and here i'm gonna paste it i'm just gonna add these uh backwards slashes here just so that i don't get any problem and if you are on linux machine i believe that this is a safe way so that you don't face any problems because between windows and linux they handle paths differently but if you do two backward slashes like i'm doing here then you shouldn't face any problem so this is the path to data and then path to save train so this is going to be the path where i want to save the train part so i want to save it here ctrl c ctrl v and let me fix these as i have done before very quickly okay and then i want to basically paste the same path here so path to save valve and let me paste it except that it's going to point to the valve folder which is this one here so now that we have our three different folders or paths we can call our function called split data so it's going to take path to data path to save train let me just make sure that i'm using to save train and also path to save valve as path to save val and for the split size we can keep it as it is so we don't have to call it here and let me just save my script let me clear my terminal so the goal is to copy the images from the original folder into these two folders and it's going to put 90 of those images in the train folder and 10 in the validation folder so let me run this script quickly and see if it works without any problems so here it's gonna this module should be installed so there should be no problem here and now the script is actually running it's just that we don't see uh we don't see it work because we don't print anything but if we go here you see that it started to construct these folders in both the train and validation folder and in each one we should have a set of images like it's shown here so this might take a little bit of time because we have a lot of images at the end i'll show you what we get and all the images that were copied we're gonna see that they have been correctly copied with the correct split size that we chose so now the script has finished and the program has finished working and if we look at our data here we see now that in my training folder i have 43 folders and the same for the validation folder and in fact if we check quickly the number of images here we see that in the train set we have around 35 000 images and in the validation set we have around 4 000 images so that sounds about right so the split size seems to be correct and if we go to every every folder we have the exact same uh images that we had in the original set which was this one here so now we have our training and validation sets what we need is the test set and as you remember the test set is comprised of images like this and in order for us to know which label which basically which label corresponds to that image we need to look at the corresponding csv file so for that let us create a function that does this so our function is going to take as arguments the path to the folder and the path to the csv file and based on these two we're gonna construct a folder that contains the right images just like this so we want to order our test set so that it starts looking like this folder here or these folders here so let us get into this and maybe since this is also a utility function maybe we can just remove it from this main script and maybe add it to our utilities script and here we need the os module so import os so and also import glob import glob and finally the scikitlearn from scikitlearn dot model selection import train tests later from numbers taken let me check this train test splits this sounds correct and also we need the sh util sage util so this these are the modules necessary import so these are the modules necessary to run these functions and now here we don't have that we can also remove these if we want for now i'm just going to keep them a star problem and here i'm going to do from my utils import split data so this is a much cleaned a much cleaner script and now let's maybe do the same for the test set as i mentioned so we want to build this function that orders the test set so let's call it uh or maybe let's just code this straight in the utilities script here so i'm going to define a function called order test set and what this function is going to take as i mentioned the path to the images and also that to csv file or just csv is clear and here what i want is to construct a dictionary that basically has the name of the image as uh as the key and also the corresponding label as the as the value so let's start by defining our dictionary and by the way this dictionary here is just going to help us keep track of the data set later if we want but it's not really necessary for us when we're just ordering the test set i just prefer to do this so that i have or i could have some sort of a data structure that contains my image paths and also their corresponding labels but for you it's not it's not really necessary for our ordering part because as you remember we just want to go through these images and just order them like we have here so here let me start by creating a try block and what i'm going to do here is to open my csv file so path to csv and the mode is read i don't want to write this inside this file i just want to read and i want to open it as csv file and then i can create a reader and it's going to use the module csv the reader and since we don't have the module csv we can import it here and just maybe a quick note here if you see me using module that's not installed inside your virtual environment then it's very easy to install any module you want you just run pip install the name of that module so here i'm gonna use this function or this method here and i'm gonna give it my csv file and also i'm gonna use i'm gonna choose the delimiter to be a comma here and why comma because inside my csv file you see that these elements are separated using a comma and now what i want to do is basically go through all the rows that exist in this reader because this reader is going to contain each row inside my csv file including including in fact this first row here that only contains information so only the headers which we don't need so we need to make sure that we don't use that information in that first row so that's why we're gonna do for i row and enumerate reader and the first thing i'm going to do is check if i'm looking at the first row and if i am i'm just going to continue which means that i don't want to use any information in that row i just want to go to the next one and for the rest of the rows what we're going to do is first get the image name and for that what we can do is use our row and in fact our row is going to contain all of the elements inside that row so it's going to contain this value then this and this this and you can access them using the correct index so row 0 is going to access this value here and row minus 1 for example is going to access the last element which is the path to the image so here what i want to do is get the image name so for that i'm gonna get the final or the end value inside that row and remember that each image here this is how the data set was constructed so we have we don't just have the name of the image we also have this test and forward slash next to it so we don't want it we just want the name of the image so for example the first one would be zero zero zero zero zero dot png we just want this we don't want this part so what we what we're gonna do here is since this is a string we're gonna use the method replace and i want to replace this string here with an empty string this means that we're gonna take this full information we're gonna remove this and we're just gonna keep the name of the image and the second thing we want to get is the label so for the label this is going to be row minus 2 and that's because this is the second element starting from the end so this class id is the second element from the end or it's zero one two three four five six sixth element so we're gonna use this or you can do just this for me i think this is much cleaner 2 because now i know just from the end i'm just going to look at the second value there and then what we're going to do is construct a path to folder and this is going to be a path that uh that is constructed using the path to the images and also the label so add a join that two images and also label since it's a string and then i'm gonna check if this path does not exist that path that is directory path to folder if it doesn't exist i'm gonna create it and here i'm gonna do os dot make deers path to folder so this is exactly what we did in the previous part so i'm just redoing it here and now what i want is to move my image from the original set so here from the test set here i want to move it into this new folder that corresponds to the right label and you'll see in a minute what i mean by this so here i'm gonna do image full path os.path dot join path to images image name so i'm constructing a full path and then i can do sh util dot move you can either copy or move the images i showed you before in the previous function here we we copied it in this one split data and now we're just gonna use the utility function move so for this we're gonna move the image so because we just got the full path to that image and we want to move it into the right folder which is path to folder and this would be it here i'm gonna use the accept command so that if we can't open the csv file i'm gonna get a message here that lets me know that we couldn't do that so for that i'm just gonna do print and for example i'm gonna use the info class and i'm going to write error reading csv file and if everything goes fine at the end we're gonna return test data well in fact since we're not using the test data here we're not constructing anything let me just maybe remove it because it's not going to add a lot of information for us so i'm just going to save this i'm going to open the csv file read the necessary information move the images to a new folder that responds to their labels and with this we will have our images in the right order and now here what i'm going to do is import my function so this order test set and again i'm going to use that basically trick that i use false so that i deactivate parts of my code and now we're gonna use or we're gonna use our function that we just constructed and remember we're gonna have to give it the path to the images and path to the csv so i'm gonna do path two images and this is going to be this one here ctrl c ctrl v and let's go quickly to our path here and also we're gonna have to give it the path to csv and this is going to be this one here in fact for the test we can just click shift and then copy path and we're going to get the full path like this so now we have our path to the images we also have the path to the csv file and then we can call our order test set function and this function is going to take that to images and also path to csv so if this function works correctly and works as it's intended to do then now what we should have is a set of folders here that contain the right images we're gonna move these images to their corresponding folders so let me everything is saved okay let me run the same script again and again this might take a little time because we have a lot of images but if we take a look at our folder as you can see it has created all of these folders and now it's moving the images you see their numbers going down it's moving them to the right folder and with this now we have our data set in the correct format and in fact when we added just a quick note here when we added the part of replace here it was necessary to add this part because here we have that test part as part of the image path and if we didn't do this it would have given us an error and now we have our data set for the test set correctly uh presented correctly ordered and now we have a set of data or a set of folders that correct that contain our data in a very good format that we can use for training and testing our model and with this we have our data set ready let's see what we can do next for building our deep learning model and doing all the fun stuff for deep learning let's start creating our deep learning model so that we can fit our traffic signs data set that we just ordered and prepared so for that i'm gonna open my deep learning models file as you remember we have created this file where we put all of our deep learning models in it and i'm just gonna add at the end i'm gonna create a new function for our new deep learning model so in the previous tutorial i showed you for the amnes data set how to create a deep learning model using three approaches sequential way functional way and by using a class that inherits from the model class but for this example since i have already shown you the other three approaches i'm just gonna use one approach which is the functional way so here i'm gonna create a new function for my model i'm gonna call it street signs model and what my function is going to take is the number of classes as a parameter and now let's start building our deep learning model so one thing to notice is that between the amnes data set and the science data set so for the science data set we have an rgb we have rgb images so it's uh we see we have blue red we have all colors unlike the amnes data set which was grayscale data set so now we need to take this into consideration because when you have an image that's that has a red blue and green this means it has three channels if it's just different layers of gray scales then in this case it has only one channel so why i'm mentioning this because for our first layer here which is the output layer we're going to use as before the input layer that's imported here and we're gonna have to give it a shape so this shape here is gonna represent the width height and also the number of channels for our images so when looking at these images we see that most of them are almost squared shapes and here i checked a few images just to see the size and as you can see this is 44 by 45 almost a square and even the largest ones are still in squared form and here we can see 80 by 84 almost square as well and the same thing goes for all of the images in our data set so since these are small images relatively small and they're squared i thought that using a size 60 by 60 would be a good choice because i've seen some images that has that had width and height smaller than 60 and some of them a little higher than 60 so 60 by 60 is an acceptable choice although you can do something which sometimes i do which is going through all of the images in the data set computing the mean of the width and the height and maybe even the median and by looking at those values you can have an idea about where the widths and heights of the images in your data set are lying so in that case you can basically choose a good value for your width and height and for your input model like we're doing here so here i'm going to choose 60 by 60 and since we have rgb images i'm going to choose three which is going to be different than the first model where we had one and then since we have this we're just going to do the same thing as we did for the first model for the mnist data set and i'm just going to do this quickly here so i have used the the layers that we used before which is convolution max pooling batch normalization and i use them in these blocks as you can see these are basically similar blocks each time i use a convolution followed by max pool 2d then batch normalization and here i have actually i wanted to show you the difference between a layer called flatten and the global average pool 2d layer so first of all let me import this layer here so it's flattening so there's no problem and also let me get the model the model function from okay let's find them here it should be in the okay i can't see it okay in that case let's just go here and do from tensorflow.keras import model so this is what we're going to use here so here i have commented this part this is the same layer that we used previously with the amnes data set and i told you that you can also use the flatten layer here which is just going to flatten all of the uh the values that are coming from the previous layer so in this case the batch normalization and what i wanted to do is to basically build this model and show it to you and then we're gonna change this layer to global average pool 2d and i'm going to show you the new model and then we're gonna look at the difference between the two so here uh basically we have our model and we can import it from here so from deep learning models import street signs model and we can use it here and just something that i also do from time to time when i'm doing experimentations such as these ones sometimes even in my scripts that are not used in the main script so these are scripts that just contain some utility functions and classes just like this script here sometimes even in these scripts i do the i create basically part of my code where i can test things straight inside this script so for example now what i wanted to show you is this model we're going to build it with this layer flattened layer and then we're going to build it with the global average pool 2d layer and we're going to see the difference there so here i'm gonna do model equals street signs model and for now i'm just gonna give it uh whatever i want since this is not the model that i'll be using with the data set this is just for testing purposes and what i want to do is to call the method summary and this method is going to show us the model architecture the different layers inputs and outputs shapes so this is going to help us get an idea of how our model looks like so here let me run this python deep learning models dot by and as you can see the the goal of these of this part here this is gonna help us for example when we're doing tests like i'm gonna show you in a minute we can just call this script here but if i import this script in another script so for example here i am importing this function from my script here in this case this part of the code will not be called so this is a good way to separate parts where you just want to test something quick and also the parts where you want to reuse them in other scripts so with this let me run this quickly here and let me maybe put this like this so this is the architecture of our deep learning model as you can see the the input is 60 60 by 3 and also we have this first uh value here represents the batch size so none means that it can be any batch size we want and then there is the convolution 2d the max pooling and so on and so forth and when we come at the end here we have the flattened layer as you can see what the flattened layer has done is that it took all the values from the previous layer so here we have uh basically a some sort of a cube where you have five by five and it has a depth of 128 and what it did is that just took all of the values and put them in one vector that's why we get 3200 because it's equal to 5x5 by 128. now if let me let me change this to the global average pooling instead and i'm gonna comment this so let me run the same script again and also enlarge this part here now when we come to the layer here so before you see we had the flattened layer third from the last layer so this is we changed it with the global average pulling 2d and now you see we don't have 3 thousand and two hundred because the global average pooling 2d what it does is that it actually computes the average in these uh in these windows here so imagine you have a cube where it's 5 by 5 100 by 128 so every 5 by 5 will compute the average there so at the end we only we're only left with 128 values so this is the difference between those two layers i wanted to show you how basically reflect in the architecture and whether you should use one or the other it's actually one of the things that you can experiment with just like i mentioned in the first tutorial when you're doing deep learning machine learning in general you're going to be doing lots of experimentation so this could be one factor of your experimentation where you change these two different layers and see which ones uh which one gives you the best results so now we have our architecture ready and we can call it from our main scripts here and we can compile the model and fit the data so we're going to be doing this next in fact before we compile our model and fit the data we have to create what's called data generators so data generators are actually going to take the images from our data sets folders so as you remember we have train and validation folders and we also have the test folder that we organized so now we're going to use some uh basically tensorflow utilities that help us achieve this very easily which is one of the main points of tensorflow i've been using tensorflow for some time and every basically with every release there are lots of functionalities new features that make your building the model uh preparing the data set makes all of this a lot easier so here i'm going to create a utility function again i'm inside my myutils.by file which i use to add all types of utility function that i might use in the future so here i'm gonna define a function i'm gonna call it create generators and basically my function is gonna take uh some arguments so the first argument is going to be the batch size i want to be able to pass the batch size to as an argument to my generators and also i'm going to pass the train train data path the validation data path and also the test data path so as you can guess we're going to create generators for each part of our data set so the first thing we're going to do is create a preprocessor so let me just define it here so this preprocessor is going to basically be used in order to preprocess our data before it's fed to our deep learning model so for this we're going to use a class from tensorflow which is the image data generator class so let me just import it here first so from tensorflow that keras that preprocessing that image import image data generator and here we're gonna be using this image data generator so i'm gonna call my class here and here in fact if you look at this class image data generator you're gonna see that you have many different transformations that you can apply for now let's just not worry too much about them for now i just want to focus on one thing which is the rescale parameter and the rescale parameter is gonna basically rescale our data so it's going to rescale our images and here what i want to do is choose a value that will be multiplied with our data set so that it's rescaled so i want basically to divide the values of my pixels by 255 which is the maximum possible value in rgb images so here i'm just going to choose 1 over 255 and what this means is that i want my preprocessor to be used i'll show you in a minute how we're going to use it but i want it to be used to preprocess my images before they are passed through my deep learning model so here i'm going to create my generators so i have i need three generators so train generator is going to be the first one and for this i'm just gonna use my preprocessor and i'm gonna use a utility function called flow from directory so this is a very helpful function that you can use and in fact what it does is that it takes a path to your folder so for example for the trained data we're gonna do uh that or sorry what did i call it train data path so train data path and then what it's going to do is just going to look at our folder so for example for the train data path folder and you're just going to look at all the folders that exist within that directory and it's gonna suppose that each folder contains images that belong to one class so that specific class so this means that our generator is gonna automatically know that all of the images belong that exists inside this folder belong to the same class same thing for this folder and for the other folders as well so this is going to help us immensely we don't need to specifically build the data set where we say this image has this label in fact with this utility function tensorflow is going to help us do that automatically so other parameters that we need to give to this utility function as the class mode so for the class mode i'm gonna use categorical and for the target size i'm gonna use 60 by 60 so this means that i want all of my images to be resized to 60 by 60 and for the categorical as i mentioned it in the first tutorial if we use categorical here we have to also use categorical cross entropy when we are compiling our model we can also use uh sparse let me just check here if it's maybe uh shown here class mode one of it's either categorical binary or sparse so if we use sparse then we need to use uh sparse labels if we choose categorical then this means that our labels need to be one heart encoded so let's look at the next parameter so here we're gonna choose color mode to be rgb because my images are colored images uh also there is a parameter called shuffle that i want to set to true this means that in each epoch or in each batch my images will be shuffled so that between two epochs basically the order of the images will not be the same this kind of uh randomness helps our model be more generalized and learn features and ignore that order between the images because we don't want our model to learn that and finally the batch size we're gonna give it the batch size which we are passing here as a parameter so this will be for the train generator and we're going to be doing exactly the same thing for the validation set and for the test set the only thing that's going to change is the the path and maybe for the test set we can set this to false because we don't need we don't need to shuffle the data when we're just testing so let me do this quickly now so i have finished creating generators for my different folders so for the test data i'm using this approach the same thing for the validation set and for the test set and as i mentioned the only difference is that for the validation set of course i'm using the validation images for the test set the test images and i'm just returning these generators here i also set shuffle to false for validation and for test because it doesn't matter that much for when we're validating on or when we're testing our model whether we have that basically a randomness or not that randomness matters much more when we're doing the training which is why we're setting shuffle to true for the train generator so now we have our generators ready what we need to do now is to use our function so that we have our data set ready in order to start training our deep learning model so let's instantiate first our generators and here let me just maybe deactivate this part of my code because i don't need it of course you don't have to always follow what i'm doing here you can just remove these parts because we don't need them anymore so we split the data we ordered to test the test set so we don't need this these parts but for now i'm just going to keep them i might delete them next but they will not have any effect on what we're going to add here so first i need to import my function that creates generators and then i have to use i have to set the paths to my train and validation folders so they will be these folders here so let me just put this here in fact let's just delete these they're not they're just going to be taking some space and here since i have the train folder the validation folder i only need to add the path to test and here i'm just gonna maybe change the name so that because we're not gonna be saving anything in these folders and here i'm gonna set it to my test folder so my test folder is this one so i'm gonna copy this path paste it then i'm just gonna add my backward slashes here so now we have all of our three pads and i can use my create generators function and it's going to take a batch size let me maybe set a batch size here so i'm going to choose a batch size of 64. now this is also again another parameter you can play with you can choose different values i recommend you choose something like you know a multiplied number of two so you choose for example 2 4 8 16 32 64 so on and so forth and here i'm going to keep it 64 and you might face a problem sometime when the batch size is too large for example let's say you choose 512 maybe the training will not start and you're gonna get an error where it says oom which means out of memory which means that you don't have enough memory to load all of those images at once so if you face that error i i suggest you decrease this number here and it should work fine so let's go here and pass our parameters so path to train that to well and path to test and of course let's go to our function just to check we're going to get these as outputs so let me maybe just copy them so that we can go quickly here so now with this i can generate my or i can create my generators using the images that exist in these paths here and with this we can now pass these generators to our deep learning model so that we can train the model first we're gonna create our deep learning model architecture so for that we're gonna use our street signs model here street science model and the street science model takes the number of classes as a parameter so here for the number of classes we can actually get them using the generators any of the generators since the train generator is the one that contains the most images let me maybe just use it so number classes equals train generator dot num classes and then i can pass this to my deep learning model and now i have my model ready then we need to do the same as we did in the first tutorial tutorial so here we're gonna first compile our model and to compile it we have uh several options the first one is the optimizer so for now let's just keep adam as the first tutorial second we need to set the loss and here i'm gonna use categorical cross entropy and again i'm using categorical cross entropy because my generators here i have set the class mode to categorical if i set this to sparse and i set this to and i keep this categorical then i'm going to have an error at the end and the final thing we need to define here are the metrics and for that i'm just going to use the accuracy so by this by doing this we're going to have our model compiled and what's gonna be left now is to fit the data so here i'm gonna do model.fit and here we can actually do something uh that's that looks a little different than the first tutorial so in the first tutorial we had that x and y but in fact you can just pass the full generator so this generator and this and this one they all contain the correct image and also its corresponding label we didn't have to explicitly do that by when we used the from flow from directory method it has done this for us so we have all generators ready so we can just pass the train generated generator sorry as a parameter like this and then we can set for example other parameters like the ebox so here we can choose whatever epochs we want maybe i'm just gonna add it here so that it's easily changed later ebox and also we have the batch size we're gonna use the same batch size and also we gonna pass the validation images and the validation generator here so for that we can use the validation data parameter and we can pass the valve generator as the argument so here as you can see we didn't have to specifically mention the images and their labels separately like we did in the mnist example so here in the amnest we had the x strain contains the images the y train contains the labels but in this case here we didn't need to do that because our generator takes care of that there's already the images and their corresponding labels so with this we can fit our data and we can train our deep learning model and this would be almost uh almost identical to what we did before apart from the generators and i mentioned in the previous tutorial that there are some things that we need to do when we're building a project like this so for example one of the important things would be to save your model save the best model during training so i'm going to show you how to do this now so in order to save the best model during training we're going to use something in tensorflow that's called callbacks and these callbacks are actually functions that are called during the training and basically they do whatever you want them to do specifically we want to save the best model so we're going to use a callback that saves the best model so in order to do that we're gonna be using some some modules or some classes from tensorflow so here i'm gonna do from tensorflow.keras.covacs i'm gonna import a callback called model checkpoint so here i'm going to use this one here i'm going to give it a name so for example we can call it checkpoint saver so kpt saver and i'm gonna instantiate that class so model checkpoint and then i'm gonna pass a set of parameters to my class so here the first thing we need to give it is a path to where we want our model to be saved so path to save model and let me maybe define it right here so path to save model and i just want to save it in the same directory i want to create a directory called data and or maybe just models and that will be it so i'm gonna be saving my model inside a directory here that will be called models and then i need to give other parameters to my callback so one thing would be the monitor and here i'm going to give it the valve accuracy so what this parameter is going to do so this parameter here monitor is basically going to well monitor this value here and what we wanted to do is that we wanted to follow this mode so here i'm going to set it to max which means that i want my basically my program to save the model whenever i get a validation accuracy that is higher than the previous saved accuracy and this is why i'm setting here max because it's going to be my model is going to be looking at the validation accuracy and whenever it gets a little higher then it's going to save it if it gets lower then we don't do anything we keep the same model that was saved before and why we're sending here max is specifically for the reason that i just mentioned which is we need to basically only save the models that have higher validation accuracy if for example i had here to monitor validation loss then i would be using the min mode because for the validation loss the less it becomes the better my model would become so i only want to save my model when this validation accuracy becomes lower hence the mode min so for me i want to monitor the validation accuracy the higher it gets the the program will save it so that's why i'm setting to validation accuracy and the mode to max and also there is a parameter called saved best only i'm gonna set it to true so i only want to i only want the best to to be saved which means that i'm only going to have one model to be saved which means that if i had a validation accuracy i save a model for that validation accuracy if a new model has better validation accuracy then i'm gonna replace the previous model uh if i set this to false then i'm gonna keep the previous model and save the new one next to it so for me i just want to save the best one so i'm going to set this parameter to true and also we can choose a frequency of saving so here i'm going to set it to epoch so we're only going to look at the the validation accuracy at the end of the epoch and only then we can choose whether to save the uh parameter the model or not and finally i'm just going to set verbose to 1 which is just helps us for debugging purposes to see when the model has been saved or not so now i have my callback ready and to use the this callback what you need to do is to add a parameter here called callbacks to the fit function and here you can give it a list of callbacks so for now we only have one which is the checkpoint saver so i'm going to pass it here if we had other callbacks then we can also pass them here as part of the list but we're not gonna do this unless as i mentioned we have another callback and speaking of callbacks i also want to show you another interesting callback that you can use which we can also import from the callbacks module here and it's called early stopping so this uh callback here what it does is that we can set some number of epochs that according to these this number of epochs if my model does not improve then i'm just gonna stop the training so this could be useful when you're training for a large number of epochs and maybe for let's say 30 or 50 epochs your model does not improve at all so it's better to just stop the training so here how to use this is almost the same way we use the model checkpoint callback so we're going to have to instantiate the class so i'm going to call it early stop and i'm going to use the class early stopping i'm going to monitor something so here i'm going to choose to monitor the validation accuracy just like i did for the model checkpoint and also i need to set the patients so here for example i can set the patients to 10 so what this means is that i'm telling my my program here that if after 10 epochs my validation accuracy does not go higher then just stop the training so for example i might i might use let's say let's let's say 100 epochs and after 10 epochs we reach certain validation accuracy and at the 20th epoch the validation accuracy does not go higher so that means the model did not improve in that case i'm just going to stop the training before continuing the rest of the 80 epochs so this could be a very useful and different scenarios and we're using it here and in order to tell our model to basically use this callback we need to pass it as part of the list of callbacks here so now we have our program ready and we can fit the data to our model and we can save the the model inside a folder here called models and we have everything ready so with this let us test our model let me clear the terminal i'm gonna run python stream in fact i just noticed that actually my script is called stree instead of street signs so let me just quickly modify this so street signs example and now let me call it or let me call my script from here so street signs example so let's run this and see what we get hopefully we don't have any errors so as you can see from the logs uh when you when you're using generators also gives you an idea about number of images that are using that are being used so since we have trained validation and tests this is for the number of trained images this is for the validation this is for the test and we also have 43 classes and as you can see the training has started and our script is working properly so now this might take some time since it's 15 epochs i'm going to wait for it until it it finishes and then we're gonna look at our uh saved model and maybe i'm gonna come back before it even finishes just to show you that there was a model saved here after the first epoch so here after the end of the first epoch as you can see we reached this validation accuracy but the most important part for us now is that there's this line here that says validation accuracy improved from minus infinity to 0.4 so this means that our validation accuracy has improved this means that we're going to save the model to this folder here and as you can see this folder was automatically created and if we go inside of it we see these files here and these files actually represent our model so we have this file we have these two folders so this folder contains the weights and this all of the elements that exist inside this folder represent our model so now each time it's improved it's gonna be saved in the same place here and for now i'm just gonna wait until the training is done and then i'll show you how how to use that final model to evaluate the test set for example and to do other things so now the training has finished it didn't take that long and at the end you see that in different uh epochs whenever the accuracy the validation accuracy became higher we saved the model so now we're sure that this folder here contains the best model that was saved during the training and now that we have this we can use our model in order to evaluate the data sets and this could be done easily using also some tensorflow utilities so for example since we don't need this part here i can just for example said this and this is also something that sometimes i do which is to uh basically set what i call switchers so train i'm gonna use i'm gonna set it to false because i'm not training and i would do this whenever i'm doing part of the code that i know i might use it again so i set it to this switch switcher here and i can set it to true or false depending on what i want and for example i can set this test to true and then my part of the code that does the testing will be added here so if test so if test then if i am using this switch then i want to use my model that was saved in order to evaluate my data set so now that we have uh our model here we can use some tensorflow utilities in order to load our model so here for example i can call my model and load it using tf dot keras actually i don't think i have okay import tensorflow as tf i did not import tensorflow in this module here so tf.keras.models dot load model and here i can give it a path to my model so my model is saved in this path here so whenever i call my script it's going to find it it's right next to it and then what i can do is for example maybe i might be i can basically print my model's architecture and the most important thing is that we can use the model to evaluate the set the sets that we have so i want to evaluate my model on the validation set and on the test set so we can also do this very easily here by passing the generator directly and maybe i can add a print here evaluating validation set and evaluating test set and here i'm gonna call model.evaluate on my test generator so let's now if we run the code the training will not start we will only have the ma the data basically loaded into these generators and then we're gonna evaluate those generators so here i'm gonna call my script again everything is saved let's see if this runs without any problems okay again since we have the generators it's gonna show us this uh i don't know this is actually a summary okay let me save this i'm gonna run the script again hopefully there are no more errors let's see okay the architecture is here and then the evaluation has started so now it finished evaluating the validation set which is 99 percent accuracy 99.67 to be exact and on the test set we'll see how much it is so on the test set we see that we get an accuracy of 96.81 which is not too bad it's really good so this means that by training our model on these uh images here and by testing them on the test set that we organized these images were never seen by our model and it still achieved a very high accuracy of 96.81 so now you know how to basically train your model and also how to evaluate it let's see what we can do next so what i would like to show you now are maybe some things that you can do to improve the results even more because when you're doing machine learning or deep learning you're going to be doing lots of experimentation and your goal will be to always improve this test accuracy this is the most important metric for you when of course when you're doing a task such as classification if you have a different task for example object detection then maybe your metric will be mean average precision for example but here since we have classification we want to improve this accuracy even more if we can so i want to show you some few techniques that you can do in order to try to improve the results the first ones are just by basically doing lots of experimentation by changing these values here so for example you can train for longer i've only used 15 epochs maybe you can go longer 30 50 even 100 epochs and see if that can improve the model you can change the batch size you can also change your deep learning model architecture you can add few layers remove few layers you can change these numbers of filters here you can for example experiment with global average pooling you can maybe remove this and add flatten layer instead and see how all of this can affect your results so as you can see you have a lot of things that you can experiment with and also this is from a maybe a model perspective but from a data perspective you can also do a few things so for example here you have the generator and we're using this image data generator class and in fact inside this class you have several data augmentation techniques so data augmentation techniques can help a lot in avoiding overfitting and it can also give your accuracy a bit of a notch and so that you can get maybe a few points more and for example if you're going to follow this path then i want to mention something important here so so far we created only one preprocessor that we use for train validation and test but this is because the only thing we're doing now is scaling so if we're scaling the images for the train set we need to do it for the validation set and the test set but if you start adding other data augmentation techniques for example let's say let me just check here shift or maybe let me just read a little bit here what can we use i think there's rotation range for example and rotation range for example you can choose i think it's in degrees so you can choose for example 10 degrees this means that your images will be uh will be rotated between 10 and 10 degrees uh you can add other things like shift or maybe width shift range yeah so this is to shift your image a little bit uh from left to right just a little bit and you can give it a small amount for example let's say 0.1 which means 10 so i want like my image to be shifted 10 to the left and 10 to the right and between these two so it can be like 5 3 this is uh going to be used as a range and you can do all sorts of other uh data augmentation techniques so the first thing that i want to basically emphasize here is that if you're using this as preprocessor you shouldn't use it for validation and for the test set and the reason for this is that the validation and test sets basically represent the sets that your model were in your model where will encounter in real life so in real life uh it's not necessarily you're not necessarily gonna have these shifts because these are synthetic augmentations in real life you want to test only on real images but when you're training you can do all sorts of these augmentation techniques so in order to avoid this you should always create two uh two preprocessors for example you can call this train preprocessor and you can for example add another one you can call it test preprocessor for the test preprocessor you remove these you only leave the scaling part because it's necessary if you scale the train set then you have to apply the same thing for the validation and the test sets but then you can use this preprocessor for the training part and this for the validation and the test generators so this is how you would do it and this could also bring some improvements to your model so just make sure you follow this kind of methodology when you're doing these different data advancation things and apart from this as you can see you have several things you can do you can add more augmentation you can change you can even change the target size maybe use 40 by 40 or 80 by 80 see if that can improve the results or not so i definitely recommend and i urge you to experiment with this and see if you can beat this accuracy which is 96.81 and this is gonna help you basically learn more and it's gonna show you the power of deep learning sometimes just by changing a small parameter you can get a large improvement and then one last thing i want to show you also in terms of things you can improve for example here for the optimizer i have passed it as a string because this is one possibility to do it another one would be to create an optimizer here and you can use tf.keras dot the optimizers let me check so tf optimizers and here you can call for example the optimizer adam and this is something that you can find in the documentation so tf keras optimizers so the documentation can be very very helpful when you're working with tensorflow they have lots of examples they have lots of uh of tutorials that you can use for your projects and here so what i wanted to show you is that if you use the adam optimizer like this then you have the option to pass some parameters to it so here if we go to the documentation you see that you can pass the learning rate for example which is very important parameter in deep learning these parameters here i usually don't touch but for the learning rate i do lots of experimentations with it because i have seen that it can have great effect on your model so here for example you can add learning rate so lr for learning rate let's say 0.02 uh so this 10 to the power of 4 and then i can pass this as my parameter here r let me check just if this is the correct way to call the parameter yeah learning rate and then i can pass it here and then you can this is another hyper parameter for you that you can play with and see if you can improve the results and then the way you would do it is that you can pass this optimizer here like so so this is also something that i wanted to show you just for the adam optimizer you see you can play with the learning rate value here and also since we're talking about atom optimizer just a quick note you see here that there is this last parameter called or this parameter called ams grad and it's by default set to false this is actually a variation of the adam optimizer i've read a little bit the paper that showed this technique and they showed that in some cases adam actually fails to converge and by converging i mean it fails to basically get the loss function to go very low and in those cases in many of those cases ams grad can help so for example you can also if you're using adam for your deep learning task and you see that the loss function is not going down then maybe one thing you can experiment with is to set the ams grad to true and you can test with this variation of adam optimizer so as you can see you have a lot and a lot of things that you can do but just this this set of parameters and this set of techniques that i mentioned now can help you improve the accuracy by a large margin so when you're done training and evaluating your model what you basically need to do at the end is to use that model in your application it could be a web app web application it could be a mobile application or an embedded application and for that what you would usually do is uh use this standalone script that just loads your model and for example it takes a path to an image as a parameter and it gives you a prediction on that image so this is what i'm going to show you now so let's create a new script and i'm going to call it for example predictor dot by let me just maybe choose my predictor dot phi in this example what i want to do is uh to show you how we can just load an image load our model and make a prediction with our model on that image so let me maybe start here by defining this part here and i want to basically have a pad to my image let me call it maybe image path and what i would like to have is some sort of a function called predict with model and this function would take image it would take the image path um maybe it would take my model and image path and it would return to me the correct prediction so it would be something like this so now let me define this function here and maybe let's start defining it here and maybe later move it to the utility script so define predict with model and it's going to take model and image path so here what i want to do is to first load the load that image and then use my model to predict on that image so first thing uh the first approach i'm going to use is by using purely tensorflow functions so let me import tensorflow stf here i'm going to use my tensorflow import here to load my image so i'm going to use here or create a variable called image tf dot io dot read file and i'm going to give it my image path here so this is a utility function that's going to help us load this image and save it inside this variable called image and then i want to basically decode my image tf dot image dot decode png since all of my images are png images so here i'm gonna do this decode as png so i'm gonna decode my image and then i need to choose the number of channels since it's an rgb image i'm gonna choose three then what i'm gonna do is basically rescale my image and in order to do that i'm gonna use a utility function also so i'm gonna do image equals tf dot image dot convert image d type and i'm gonna give it my image as a parameter here i'm gonna choose the type to be tf dot float 32 so in fact just by doing this during this part of the of the code here i'm reading the file reading the image using this read file method i'm decoding it since it's a png image i'm using decode png and then by using this function here here convert image d type it's going to convert my image pixels since now they are unsigned integers in eight bits it's gonna turn them into a float32 uh type and also it's gonna scale them by turning the pixel values between 0 and 1 instead of 0 and 255 so without even mentioning here the scale value by saying for example divide by 255 this function is going to do it for us and you can check that by going to the documentation regarding this function here after that i'm going to have to resize my image so i'm going to use tf dot image dot resize and i'm going to give it my image and then a list of the width and height and here i'm choosing 60 by 60 because as you remember in the generators here or in the flow from directory we are using target size 60 by 60 which means that all of our images are resized to 60 by 60 so we need to keep that same order when reading an image to pass it through our model so here we have resized our image and last we need to basically expand dimensions of my tensor and here i'm going to give it my image and axis 0. so just to explain what this does in fact at this level here we can have a shape of 60 by 60 by 3 but by doing this by expanding the dimensions we're going to get a shape of 1 by 60 by 60 by 3. and this is the format that our model is expecting our images to be in so let me check here as you can see the input layer expects none then 60 by 60 by 3 and this none can be anything but there needs to be this dimension here so if we're using one image to pass it to our model we need to set that first value to one to say that this is one image of size 60 by 60 by 3 and then our input layer will not complain because this this basically follows the same shape that we defined during the training and then once we have our image ready what we can do is call our model predict function and we're gonna pass the image to it so this is gonna give us a list of probabilities of that image belonging to one of the one of the classes so here i'm going to save my predictions to this variable here so you can choose this function to return the list of probabilities maybe you want to to use this for maybe using some threshold to say that this is acceptable or not so at this stage here for example you might get 0.005 for the first class 0.003 for the second class then you might you may you might get 0.99 for the uh class here the third class and then also the rest will be zero zero point something and for the rest of the other classes as well so this means that our model if we get a result like this and our model thinks that this image most likely belongs to class three or class two because our folders as you remember they start from zero so we start from class zero if we go to the third class it's actually two so if we do if we run this command and we get this list here then this means that our model thinks that this image belongs to this class here so what we want is uh basically to get only that class and we don't want to get probabilities at least for me that's what i want to do but for you feel free to maybe return this list here and then do whatever you want with it but for me since i just want to return the exact class that we got i'm gonna do predictions equals numpy dot in fact we can give it my predictions here and let me just import numpy in port numpy s and p so what this is going to give me is the index of the max value which is exactly what i want so in this case for example it would return let me just maybe do it in a comment here it would give me 2 because 2 is the index of the max value 0.99 and then i'm just gonna return my predictions so now we have our function ready and here let's choose for example one of the images in the test set let's choose this for example and copy as path so that we can quickly do that i'm just going to paste it here i'm going to add the backwards slashes here quickly and then of course i need to load my model so just like we did here we can load our model by using this command here so the model exists in this folder called models so we're going to be able to find it from our script mypredictor.pi i'm going to pass it to our function predict with model and then we're gonna get the corresponding class and then here i'm just gonna print something like okay i'm gonna use an f string prediction equals prediction so let's run our script and see what we can get let me clear this first python my predictor.buy and just do one last look here see hopefully we have no errors okay well the first prediction was actually uh wrong so this prediction it says this this is class 12 but it actually is class 2. let's test with other images as well so here for example i added this image here from the test set which which should give us the label 0 so let's run our predictor.buy and here as you can see we get the correct result is zero i know i know that the correct result is zero because i'm just looking at the corresponding folder here so we got the wrong result for this one the correct one for this one but this is basically this is not a way to test the model the best way to test the model is by doing evaluation as we did before but this is just to show you how you would use your deep learning model to predict on images in a standalone application so as you can see here we have an application this could be easily embedded in any sort of application web app or mobile app or whatever and basically we just have a function that reads the image uses the model and makes prediction with it and then you get that prediction and you can do whatever you want with it so now you have seen how to use your model in a standalone application in order to make predictions on specific images so just a quick recap of what we've seen in this last part so basically we used a german traffic signs data set that was collected and we had real life images we explored that data set we prepared the training validation and test sets we built a neural network the functional way we also created data generators we added callbacks to our fit method we trained and evaluated our model and we discussed some potential improvements that we can do to get better results for example data augmentation we also finished that part by by running inference on single images and building standalone examples on how you would use your model so if you have any questions regarding what we have covered so far then please feel free to contact me on my social media accounts so i have linkedin account and also twitter account and if you're interested in a free machine learning job ready checklist which is a checklist that i put together based on my experience working on machine learning projects in the computer vision industry then please check the link below there will be only one link but it's going to point you to all the necessary information regarding my social media accounts and also this free checklist
