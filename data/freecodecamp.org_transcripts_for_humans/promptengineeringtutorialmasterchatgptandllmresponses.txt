With timestamps:

00:00 - Learn how to get chat GPT and other LLMs
00:02 - to give you the perfect responses
00:04 - by mastering prompt engineering strategies.
00:07 - Anu Kubo is one of our most popular instructors.
00:10 - And in this course, she will teach you the latest techniques
00:13 - to maximize your productivity with large language models.
00:17 - Hi everyone and welcome to this course on prompt engineering.
00:21 - My name is Anu Kubo and I'm a software developer
00:24 - as well as course cruiser here on FreeCoCamp
00:26 - as well as on my own channel.
00:28 - This is going to be a unique course for me
00:30 - as there is going to be a lot less coding going on
00:33 - but a lot more understanding
00:35 - about the topic of prompt engineering
00:37 - and why some companies are paying up to $335,000 a year
00:42 - according to Bloomberg for people in this profession.
00:44 - And no, no coding background is necessarily required.
00:48 - So what are we waiting for?
00:50 - Let's do it.
00:51 - In this course, we will learn what prompt engineering
00:54 - is exactly, get a brief introduction to AI,
00:58 - a look at large language models or LLMs
01:01 - such as chat GPT, a look at text to image models
01:04 - such as mid journey, a look at emerging models.
01:07 - This would include text to speech,
01:09 - text to audio or speech to text
01:11 - as well as prompt engineering mindset, best practices,
01:15 - zero-shot prompting, few-shot prompting, chain of thought,
01:19 - AI hallucinations, vexes, text embeddings
01:22 - and also end with a quick intro to chat GPT.
01:26 - So let's start off with looking at what exactly
01:29 - prompt engineering is in the first place.
01:31 - Prompt engineering in a nutshell is a career
01:34 - that came about of the back of the rise
01:36 - of artificial intelligence.
01:38 - It involves human writing, refining and optimizing prompts
01:41 - in a structured way.
01:43 - This is done with the intention of perfecting the interaction
01:46 - between humans and AI to the highest degree possible.
01:49 - Not only that, however, a prompt engineer is then also
01:53 - required to continuously monitor those prompts
01:55 - ensure their effectiveness with time as AI progresses.
01:59 - Maintaining an up-to-date prompt library will be a requirement
02:02 - that is placed onto the prompt engineer
02:04 - as well as reporting on findings and in general,
02:07 - being a thought leader in this space.
02:09 - But why do we need it?
02:11 - And how did it come about from AI?
02:13 - Before moving on, let's actually make sure
02:15 - we are on the same page about what exactly AI is.
02:19 - Artificial intelligence is the simulation
02:22 - of human intelligence processes by machines.
02:25 - I say simulation as artificial intelligence
02:28 - is not sentient, at least not yet anyways,
02:31 - meaning it cannot think for itself
02:33 - as much as it may seem it does.
02:36 - Often, and this is certainly the case with tools
02:38 - such as chat GPT, for example, when we say AI,
02:43 - we are simply referring to a term called machine learning.
02:46 - Machine learning works by using large amounts
02:48 - of training data that is then analyzed
02:51 - for correlations and patterns.
02:53 - These patterns are then used to predict outcomes
02:56 - based on the training data provided.
02:58 - So for example, here we are feeding data
03:01 - saying that if a paragraph looks like this
03:03 - with this type of title, then it should be categorized
03:07 - as international finance.
03:09 - The second paragraph should be put in the category
03:11 - of earning reports and so on.
03:14 - With some code, we should be able to train our AI model
03:18 - to correctly guess what future paragraphs are about.
03:21 - And that's it.
03:22 - Of course, that is a super basic example
03:25 - and we would need way more data
03:27 - than these five paragraphs right here,
03:29 - but you get the idea.
03:30 - If you want to build your own AI model
03:32 - and understand the concept of machine learning better
03:34 - as a total beginner, please check out my video on it
03:37 - on my channel, Code with Anya Kubo.
03:39 - As of now, rapidly improving general AI techniques
03:42 - can create realistic text responses
03:44 - and even images, music, and other media
03:47 - thanks to the huge amounts of training data
03:49 - and talented developers working on it today.
03:53 - Why is prompt engineering useful?
03:56 - With the quick and exponential growing rise of AI,
03:59 - even the architects of it themselves struggle
04:01 - to control it and its outputs.
04:04 - This might be a bit hard to understand,
04:06 - but think of it this way.
04:07 - If you were to ask an AI chatbot what is four plus four,
04:11 - you would expect it to say eight, right?
04:13 - The result of eight is pretty indisputable.
04:16 - However, imagine you are a young student
04:19 - trying to learn the English language.
04:21 - I'm going to show you just how different responses can be
04:24 - based on the prompts you feed
04:27 - and in turn your learning experience.
04:29 - For this example, I'm going to be using
04:31 - Chat GPT's GPT-4 model.
04:34 - So let's start with the basics.
04:36 - If you were to type, correct my paragraph
04:39 - and then paste it a badly written paragraph.
04:43 - So just like this, today was great in the world for me.
04:45 - I went to a Disneyland with my mom.
04:47 - It could have been better though if it wasn't raining.
04:50 - Great, the young English learner has a better sentence,
04:53 - but it kind of stops there
04:55 - and the learner is just left to their own devices.
04:57 - And honestly, the sentence really isn't that great anyway.
05:02 - What if the learner could get the best sentences possible
05:05 - from a teacher who understands their interests
05:08 - to keep them engaged?
05:10 - With the correct prompts,
05:11 - we can actually create that with AI.
05:14 - So let's give it a go and let's write a prompt to do this.
05:17 - So here's the prompt I'm going to give it.
05:20 - I'm going to write,
05:21 - I want you to act as a spoken English teacher.
05:24 - I will speak to you in English
05:25 - and you'll reply to me in English
05:27 - to practice my spoken English.
05:30 - I want you to keep my reply neat,
05:32 - limiting the reply to 100 words.
05:35 - I also want you to strictly correct
05:37 - my grammar mistakes and typos.
05:39 - And I want you to ask me a question in your reply.
05:43 - Now, let's start practicing.
05:45 - You could ask me a question first.
05:48 - Remember, I want you to strictly correct
05:50 - my grammar mistakes and typos.
05:52 - So there's my prompt.
05:54 - You can also go a step further
05:56 - and ask it to correct your factual errors too,
05:59 - which I think would be an excellent addition to the prompt
06:01 - that will benefit the young learner.
06:03 - Okay, so let's go ahead and add that to the prompt.
06:06 - Okay, and let us do its thing.
06:09 - And great, so now this is way more interactive.
06:13 - As you will see, it's asking you a question
06:15 - and telling you what to do
06:17 - and will provide you with corrections if needed.
06:19 - So in a way, you're communicating with the AI.
06:23 - It's giving you suggestions
06:24 - and you're learning along the way.
06:26 - It's a completely different experience
06:28 - thanks to the prompt that we wrote.
06:30 - Pretty cool, right?
06:31 - We're gonna be diving into a bunch of these concepts soon,
06:34 - but first let's start with the basics.
06:37 - Linguistics.
06:38 - Linguistics is the study of language.
06:41 - It focuses on everything from phonetics,
06:44 - so the study of how speech sounds
06:46 - are produced and perceived.
06:47 - Phonology, so the study of sound patterns and changes.
06:51 - Morphology, the study of word structure.
06:54 - Syntax, so the study of sentence structure.
06:57 - Semantics, so the study of linguistic meaning.
07:01 - Pragmatics, so in other words,
07:02 - the study of how language is used in context.
07:05 - Historical linguistics, or the study of language change.
07:09 - Sociolinguistics, or in other words,
07:12 - the study of the relation between language and society.
07:16 - Computational linguistics,
07:18 - so the study of how computers can process human language.
07:21 - And physiolinguistics,
07:23 - or the study of how humans acquire and use language.
07:27 - So a lot.
07:29 - Linguistics are the key to prompt engineering.
07:32 - Why?
07:33 - Understanding the nuances of language
07:35 - and how it is used in different contexts
07:37 - is crucial for crafting effective prompts.
07:40 - Not only that,
07:41 - but knowing how to use a grammar or language structure
07:44 - that is universally used
07:45 - will result in the AI system
07:47 - returning back the most accurate results.
07:50 - As you can imagine,
07:51 - the sheer amount of data that it is trained on
07:54 - is most likely to mostly use the standard grammar
07:58 - and language structure that is universally used.
08:00 - So sticking to the standardization is key.
08:04 - Language models.
08:06 - Imagine a world where computers possess the power
08:08 - to understand and generate human language.
08:11 - A world where machines can chat, write stories,
08:14 - and even compose poetry.
08:16 - In this magical realm,
08:18 - language models can come into play.
08:21 - They are like the wizards of the digital realm
08:23 - capable of understanding and creating human-like text.
08:27 - A language model is a clever computer program
08:31 - that learns from a vast collection of written text.
08:34 - It takes in books, articles, websites,
08:36 - and all sorts of written resources,
08:38 - allowing it to gather knowledge
08:40 - about how humans use language.
08:42 - Just like a master linguist,
08:44 - it becomes an expert in the art of conversation,
08:46 - grammar, and style.
08:48 - But how does this all work?
08:50 - Well, imagine you feed a sentence.
08:53 - The language model will then analyze the sentence,
08:55 - examine the order of words, their meanings,
08:58 - and the way they fit together.
08:59 - Then the language model would generate a prediction
09:03 - or a continuation of the sentence
09:05 - that makes sense based on its understanding of the language.
09:08 - It will weave words together one by one,
09:11 - creating a response that seems like it was crafted
09:13 - by a human being.
09:15 - Imagine having a conversation with the language model
09:18 - as if you were exchanging ideas with a digital friend.
09:20 - You ask a question,
09:22 - and it responds with a well-crafted answer.
09:24 - You tell a joke, and it counters with a witty remark.
09:27 - It's like having a language expert by your side
09:29 - always ready to assist and engage in conversation.
09:33 - Now, you may wonder where these language models are used.
09:36 - They can be found in various places,
09:39 - from your smartphone's virtual assistants
09:41 - to customer service chatbots,
09:43 - and even in the creative realm of writing.
09:46 - They help us find information,
09:48 - offer suggestions, and create content.
09:50 - But remember, while language models
09:52 - possess incredible abilities,
09:54 - they still rely on the human to create and train them.
09:58 - They are, in fact, a fusion of human ingenuity
10:00 - and the power of algorithms,
10:02 - blending the best of both worlds.
10:05 - Let's start off by looking at the history of language models,
10:08 - starting with the first AI, Eliza, back in the 60s.
10:12 - Eliza is an early natural language processing computer
10:15 - program created from 1964 to 1966 at MIT by Joseph Wiesenbaum.
10:22 - Eliza was designed to simulate a conversation
10:25 - with a human being.
10:26 - Eliza had a special knack for mimicking
10:28 - a Rogerian psychotherapist,
10:30 - someone who essentially listens attentively
10:33 - and asks probing questions
10:35 - to help people explore their thoughts and feelings.
10:37 - Eliza's secret weapon was its mastery of pattern matching.
10:42 - It had a treasure trove of predefined patterns,
10:44 - each associated with specific responses.
10:47 - These patterns were like magical spells
10:50 - that allowed Eliza to understand
10:51 - and respond to human language.
10:54 - When you engage in a conversation with Eliza,
10:56 - it would carefully analyze your input,
10:58 - seeking patterns and keywords.
11:00 - It would then transform your words
11:01 - into a series of symbols,
11:03 - searching for patterns that match those symbols
11:06 - in its repertoire.
11:07 - Once a pattern was detected,
11:09 - Eliza would work its magic by transforming your words
11:12 - into a question or statement
11:14 - that aimed to explore your thoughts and emotions.
11:17 - It was as if Eliza was holding up a metaphorical mirror,
11:20 - encouraging you to delve deeper into your own thinking.
11:24 - For example, if you said something like, I feel sad,
11:27 - Eliza would detect the pattern
11:29 - and respond with a question like,
11:31 - why do you think you feel sad?
11:33 - It encouraged reflection and introspection,
11:36 - just like a caring therapist would.
11:39 - But here's the delightful twist.
11:41 - Eliza didn't truly understand what you were saying.
11:44 - It was just a clever illusion.
11:46 - It used pattern matching
11:48 - and some creative programming tricks
11:50 - to create the illusion of understanding
11:53 - while in reality,
11:54 - it was just following a set of predefined rules.
11:57 - Yet, even though Eliza was a simple program,
12:00 - people were often captivated
12:02 - by its conversational abilities.
12:04 - They felt heard and understood,
12:06 - even if they knew they were talking to a machine.
12:09 - It was like having a digital confident
12:11 - who was always ready to listen and offer gentle guidance.
12:15 - Eliza's creator, Weisenbaum,
12:17 - intended the program as a method to explore communication
12:20 - between humans and machines.
12:22 - He was surprised and shocked that individuals,
12:24 - including his secretary,
12:26 - attributed human-like feelings to the computer program.
12:29 - But that is a whole other topic of conversation in itself.
12:34 - Eliza's impact was profound,
12:35 - sparking interest and research
12:37 - in the field of natural language processing.
12:39 - It paved the way for more advanced systems
12:41 - that could truly understand and generate human language.
12:45 - It was the humble beginning of a grand adventure
12:48 - in the world of conversational AI.
12:51 - Fast forward to the 1970s,
12:52 - when a program named Shudlu appeared.
12:56 - It could understand simple commands
12:57 - and interact with a virtual world of blocks.
13:00 - Although Shudlu wasn't a language model per se,
13:04 - it laid the foundation for the idea of machines
13:06 - comprehending human language.
13:08 - But the true language models began around 2010,
13:12 - when the power of deep learning
13:13 - and neural networks came into play.
13:16 - Enter the mighty GPT,
13:19 - short for generative pre-trained transformer,
13:22 - ready to conquer the world of language.
13:24 - In the year 2018,
13:26 - the fast iteration of GPT emerged,
13:28 - created by the company OpenAI.
13:31 - It was trained on a large amount of text data,
13:34 - absorbing knowledge from books, articles,
13:36 - and a large chunk of the internet.
13:38 - GPT-1 was a taste of things to come,
13:41 - an impressive language model,
13:42 - but small compared to its descendants that we use today.
13:46 - As time went on,
13:47 - the saga continued with the arrival of GPT-2 in 2019,
13:51 - followed by GPT-3 in 2020.
13:54 - This was a titan among language models
13:57 - equipped with a large number of parameters,
13:59 - over 175 billion to be precise.
14:02 - GPT-3 dazzled the world
14:04 - with its unparalleled ability to understand,
14:06 - respond, and even generate creative pieces of writing.
14:09 - The arrival of GPT-3 marked a real turning point
14:12 - in terms of language models and AI.
14:15 - At the time of writing,
14:16 - we now also have GPT-4,
14:18 - trained on pretty much the whole internet,
14:20 - rather than outdated large data sets,
14:22 - as well as BERT from Google and so much more.
14:25 - It would seem we are only just at the start
14:27 - when it comes to language models and AI.
14:30 - So learning how to harness this data with prompt engineering
14:32 - is a smart move for anyone today.
14:36 - The prompt engineering mindset.
14:38 - When thinking of good prompts,
14:39 - it is always best to get in the correct mindset.
14:42 - Essentially, you want to just write one prompt, right?
14:45 - And not have to waste time and tokens,
14:48 - writing lots of different prompts
14:50 - until you get the result you desire.
14:52 - So essentially, kind of the same
14:54 - as when you Google stuff, right?
14:56 - How good are your Googling skills now,
14:58 - as opposed to five years ago?
15:00 - I'm assuming a lot better.
15:02 - We have grown to intuitively know
15:04 - what to type into Google the first time round
15:07 - as to not waste time.
15:09 - Having the same mindset for prompt engineering
15:11 - can also be applied.
15:13 - Mahail Eric of the Infinite Machine Learning Podcast
15:16 - says it well when he says,
15:18 - I personally like the analogy of prompting
15:20 - to designing effective Google searches.
15:23 - There are clearly better and worse ways to write queries
15:26 - against the Google search engine that solve your task.
15:29 - This variance exists because of the opaqueness
15:32 - of what Google is doing under the hood.
15:35 - We are gonna keep this in mind
15:36 - for the remainder of the course.
15:39 - A quick intro to using chat GPT by OpenAI.
15:43 - So as I said in this course for the examples,
15:46 - I will be using chat GPT's GPT for model.
15:51 - In order to follow along or just to understand
15:55 - how we are going to be using the platform,
15:58 - please head over to openai.com
16:00 - and just go ahead and sign up.
16:03 - I've already signed up,
16:04 - so I'm just gonna go ahead and log in
16:07 - and that will take me to the platform
16:09 - in which I can choose what I want to interact with.
16:13 - For this tutorial,
16:15 - we are going to be interacting with chat GPT for.
16:19 - So please go ahead and click on here
16:22 - and that will take you to the platform.
16:24 - And then I'm just gonna go ahead
16:26 - and switch to the GPT for model,
16:29 - which is the latest one.
16:31 - Okay, so great.
16:33 - You will see here all the previous chats that I've had.
16:37 - I'm just going to minimize this.
16:39 - And if we want to create a new chat,
16:41 - all we'd have to do is click the new chat button.
16:44 - Okay, so here, for example,
16:47 - what I can do is just go ahead and ask any questions.
16:51 - So what is four plus four?
16:54 - And then hit send.
16:55 - And that will essentially give me a response.
16:58 - So I'm now interacting with chat GPT for.
17:02 - On this occasion,
17:03 - I can actually build on the previous conversation.
17:07 - So what I can do is say, great.
17:11 - Now, can you add another five to that?
17:19 - What is the answer?
17:21 - And it will take into account everything
17:24 - that I have previously.
17:25 - Okay, I am building on top of the knowledge
17:28 - that it already has.
17:30 - Great.
17:31 - So again, this is just a very quick introduction
17:35 - to how to use this,
17:36 - we will be doing a deeper dive into this
17:39 - throughout this course.
17:41 - So once again, to create a new chat,
17:43 - all you'd have to do is create new chat.
17:45 - And if you want to delete the old one,
17:46 - just go ahead and click that delete button.
17:48 - And that will delete it.
17:50 - And then a new chat is brought up automatically.
17:53 - Wonderful.
17:55 - Now you might have seen my course on open AI
17:58 - in which we can also use the API.
18:02 - And to use the API,
18:03 - just go over to the API references.
18:06 - And all you would have to do is get an API key.
18:10 - And the API key can be viewed here.
18:13 - And then you just go ahead and create an API key.
18:16 - And that will allow you to interact with the open AI API
18:21 - in order for you to build out your own platforms
18:24 - just as the one we saw before.
18:26 - So if you're interested in that,
18:27 - please do head over to my tutorial on this,
18:31 - again, on the free COCAM channel.
18:33 - Otherwise, let's continue using chat GPT.
18:38 - So once again, I'm just going to log in
18:40 - and head back to the platform here.
18:43 - And that is it, we are ready to go.
18:47 - Another thing I want to discuss is tokens.
18:51 - As you might find that you have run out of the free tokens
18:55 - that you have in order to interact with chat GPT.
18:58 - So in order to do that, I'm just going to show you this,
19:02 - I'm going to head over to the documentation
19:05 - and talk to you a little bit about tokens.
19:09 - So GPT-4 essentially processes all texts
19:13 - in chunks called tokens.
19:16 - And this token is approximately four characters
19:20 - or 0.75 words for English text.
19:24 - And we essentially get charged by token.
19:27 - If you want to know exactly how many tokens you are using,
19:31 - you can check it out here,
19:33 - you can check out the tokenizer tool,
19:35 - and it will give you a rough example.
19:37 - So for example, I can say, what is four plus four.
19:44 - And with that piece of text,
19:47 - the total count of tokens is going to be six.
19:51 - Okay, so there we go.
19:54 - That is exactly how many tokens will be used
19:56 - in order to produce a answer for this request.
20:02 - Great, so here is a URL for that.
20:04 - You can play around with it.
20:06 - I hope you have fun.
20:08 - If you want to see your usage,
20:09 - you can head over to account
20:11 - and then you can manage your account.
20:14 - And this should be able to show you your usage.
20:17 - So it will show you your usage right here per month.
20:21 - And then you can, of course, also add billing
20:24 - in order to carry on using chat GPT
20:28 - in case you've used up all your tokens
20:30 - and you can't use it anymore.
20:32 - So once again, this is under account billing overview.
20:36 - So just go check it out.
20:38 - Okay, and now back to the platform.
20:42 - Best practices.
20:44 - The biggest misconception
20:46 - when it comes to prompt engineering
20:48 - is that it's an easy job with no science to it.
20:51 - I imagine a lot of people think
20:53 - it's just about constructing a one-off sentence
20:56 - such as correct my paragraph
20:58 - that we saw in the previous example.
21:00 - When you start to look at it,
21:01 - creating effective prompts
21:03 - relies on a bunch of different factors.
21:06 - Here are some things to consider
21:08 - when writing a good prompt.
21:10 - Consider writing clear instructions
21:12 - with details in your query.
21:14 - Consider adopting a persona
21:16 - as well as specifying the format
21:19 - using iterative prompting,
21:21 - meaning if you have a multi-part question
21:24 - or if the first response wasn't sufficient,
21:26 - you can continue by asking follow-up questions
21:28 - or asking the model to elaborate
21:31 - and avoid leading the answer.
21:33 - Try not to make your prompts so leading
21:35 - that it inadvertently tells the model
21:37 - what answer you're expecting.
21:39 - This might bias the response unduly.
21:42 - And finally, limit the scope for long topics.
21:45 - If you're asking about a broad topic,
21:47 - it's helpful to break it down
21:48 - or limit the scope to get a more focused answer.
21:51 - Let's look at some of these now.
21:53 - In order to write clearer instructions,
21:55 - we can adopt writing more details in our queries.
21:59 - And to get the best results,
22:00 - don't assume the AI knows what you are talking about.
22:04 - Writing something like, when is the election,
22:07 - implies that you are expecting the AI to know
22:10 - what election you are talking about
22:12 - and what country you mean.
22:14 - This may result in you asking a few follow-up questions
22:17 - to finally get the result you want,
22:19 - resulting in time loss and frankly,
22:21 - perhaps some frustration.
22:23 - Consider taking the time to write a prompt
22:25 - with clear instructions.
22:27 - So, for example, instead of writing,
22:30 - when is the election, you could write,
22:32 - when is the next presidential election for Poland?
22:36 - So let's go ahead and run this.
22:39 - And this will be much more precise
22:41 - and knows exactly what we are asking about.
22:44 - It's not gonna go guessing and waste our time
22:48 - as well as waste our resources.
22:50 - So in other words, tokens that we are using,
22:52 - so in other words, money,
22:54 - in order to get the right answer the first time.
22:57 - Here are some other examples
22:59 - of how you could write clearer prompts.
23:01 - So for example, we have this prompt here,
23:03 - which says write code to filter out the ages from data.
23:07 - And if you run it,
23:09 - you don't really know what language
23:10 - it's gonna come back with, let's see.
23:12 - So for example, here it's using Python.
23:15 - I actually didn't wanna use Python, okay?
23:18 - So now we've lost some tokens asking this.
23:21 - We've also lost some time
23:23 - and we just haven't got the right response.
23:25 - This could have been so easily avoided.
23:28 - So I'm gonna stop this from generating
23:30 - and let's try again.
23:32 - So this time, let's be more specific by writing,
23:36 - write a JavaScript function
23:38 - that will take an array of objects
23:40 - and filter out the value of age property
23:42 - and put them in a new array.
23:44 - Please explain what each code snippet does.
23:47 - In this example, I am not assuming the AI knows
23:50 - what computer language I like to use
23:52 - and I am being more specific
23:54 - about what my data actually looks like.
23:56 - On this occasion, it's an array of objects.
23:59 - Not only that, I'm also asking the AI
24:02 - to explain why it's doing each step
24:05 - so that I in turn can understand
24:07 - and not just copy paste the code
24:08 - without gaining any knowledge from it.
24:11 - Okay, so here you can see a live example
24:13 - of what's coming back to us from GPT-4.
24:17 - It's given us the correct code.
24:20 - So I have checked that
24:21 - and I was also giving us an example
24:24 - of how you would use the function,
24:25 - which is something I didn't ask,
24:27 - which is super useful.
24:28 - It's kind of gone above and beyond
24:30 - for helping me out in understanding what is going on.
24:35 - Let's look at another example.
24:37 - We can write, tell me what this essay is about.
24:41 - So I'm going to just type this
24:44 - and then just paste in an essay and hit go.
24:46 - And then chat GPT will do its thing.
24:49 - It's going to give me a summarization
24:51 - as it thinks best.
24:53 - So on this occasion,
24:55 - it is essentially giving me numbered points
24:57 - about what this essay is about.
25:00 - They're really long.
25:01 - I really didn't want to read this much.
25:03 - It's pretty much looking to be the same
25:06 - as the original essay.
25:08 - So this is not something I wanted.
25:11 - I should have been way more specific
25:13 - in telling it what I need.
25:16 - So what I'm going to do is just add to this conversation.
25:19 - So it's going to learn on what I wrote previously.
25:22 - And I'm just going to specify to use bullet points
25:24 - to explain what this essay is about,
25:27 - making sure each point is no longer the 10 words long.
25:30 - So I am being super specific
25:33 - in providing the instructions of what I want
25:37 - and let's hit go.
25:39 - So now this is a lot shorter.
25:40 - Okay, as you can see,
25:42 - each point is no longer than 10 words long.
25:44 - And then I'm going to get a summary
25:47 - that is a bit longer
25:48 - and will give me a summary of the essay
25:51 - that I pasted in above.
25:54 - So great, of course you can do this
25:57 - on any essay or piece of text that you wish
26:01 - and you can set your own clear
26:03 - and specific instructions as well.
26:07 - Okay, so I hope you can see
26:08 - why the second one is better.
26:11 - It's because I am not assuming the AI knows
26:13 - what kind of format I want the summarization
26:15 - of the essay to be in.
26:17 - I am being specific that I want very short notes
26:20 - on the essay in bullet point format
26:22 - with a short conclusion at the end.
26:25 - If I did not put this,
26:26 - the summary could have been just as long as the essay itself
26:30 - and the prompt could be considered useless in my eyes.
26:34 - Next up, we can also adopt a persona.
26:37 - When writing prompts, it is sometimes helpful
26:39 - to create a persona.
26:40 - This means you're asking the AI to respond to you
26:43 - and a certain character.
26:45 - So exactly like the English language teacher example
26:47 - we saw earlier, using a persona in prompt engineering
26:51 - can help ensure that the language model's output
26:53 - is relevant, useful and consistent
26:56 - with the needs and preferences of the target audience,
26:59 - making it a powerful tool
27:01 - for developing effective language models
27:03 - that meet the needs of users.
27:05 - Let's look at some examples of adopting a persona.
27:08 - So for example, you're gonna have this prompt right here.
27:12 - Write a poem for a sister's high school graduation
27:15 - that will be read out to a family and close friends.
27:19 - So let's go ahead and run this
27:21 - and let's see what comes back.
27:24 - So there we go.
27:25 - It is quite good in a room filled with kin and close ties.
27:29 - We gathered to honor the mist in our eyes
27:31 - for a journey has ended another begun
27:34 - as our dear sister steps into the sun.
27:36 - Okay, so it's coming out with a poem I can see here.
27:41 - It is quite a good one, I guess,
27:43 - probably better than anything that I would have written.
27:46 - And it is maybe a little bit generic.
27:50 - Maybe that's what you wanted.
27:52 - I think we can do better than this.
27:54 - So let's try this.
27:56 - This time I'm gonna write a prompt with a persona.
28:00 - So this time I'm gonna specify who I'm writing as.
28:03 - I'm gonna do write a poem as Helena.
28:09 - Helena is 25 years old and an amazing writer.
28:18 - Her writing style is similar to famous
28:24 - 21st century poet Rupi Kaur.
28:29 - Writing as Helena, write a poem for her 18 year old sister
28:44 - to celebrate her sister's high school graduation.
28:49 - High school graduation, this will be read out to friends
29:00 - and family at the gathering.
29:06 - Okay, so let's check it out now.
29:08 - We're writing as Helena, she's 25, she's an amazing writer
29:14 - and we've also assigned a writing style.
29:17 - So let's check it out.
29:19 - Now Chat GPT should be using anything it knows about
29:23 - Rupi Kaur, hopefully from the internet,
29:26 - in order to apply that style to this poem.
29:29 - Okay, and as you can see, this is maybe
29:32 - a little bit more affectionate.
29:34 - We've said sister, it's obviously a younger sister,
29:37 - so the words little sister are being used.
29:39 - And in general, I think this is a much higher quality poem
29:45 - and if Helena truly does have the style of Rupi Kaur
29:48 - in writing, it will be almost indistinguishable
29:52 - who wrote this poem, Chat GPT or Helena.
29:56 - So here we go, here's the full thing.
29:58 - It starts off, in the garden of our youth,
30:00 - I watch you bloom from bud to blossom,
30:03 - from child to woman, 18 summers passed.
30:06 - Again, utilizing the fact that we fed it, she was 18
30:10 - and every winter's chill only made you stronger,
30:13 - a force of nature still.
30:14 - So yes, in my eyes, this poem is a lot more better
30:18 - it's much more refined, it's much more personal,
30:21 - thanks to the prompts that we wrote.
30:24 - We've already had a brief look at specifying format
30:27 - when we limited the word count of our bullet points
30:30 - in a previous example.
30:33 - So that was a great example, limiting words
30:35 - is one that I use often.
30:37 - However, we can do a bunch of other things,
30:41 - including specifying if something is a summary,
30:44 - a list or a detailed explanation.
30:47 - Heck, you can even create checklists.
30:49 - So I'm going to go ahead and show you how to do this.
30:52 - Here is an example prompt and I'm just going to run it.
30:56 - And there we go, we have created a checklist.
31:00 - So many things you can do in Chat GPT.
31:05 - Just make sure to specify the type of format you want
31:10 - and it should be able to do it.
31:13 - Okay, great.
31:14 - Now that we looked at some best practices,
31:16 - let's move on to some more advanced topics
31:19 - in the prompt engineering.
31:21 - In this section, I'm going to talk about two types
31:23 - of prompting we can do, zero-shot prompting
31:27 - and few-shot prompting.
31:28 - Zero-shot prompting leverages a pre-trained model's
31:31 - understanding of words and concept relationships
31:34 - without further training.
31:36 - And few-shot prompting enhances the model
31:38 - with training examples via the prompt avoiding retraining.
31:42 - So essentially in the context of the GPT-4 model,
31:46 - we don't really need to do much.
31:48 - We are already using all of the data that it has
31:50 - in order to ask when is Christmas in America?
31:53 - So let's go ahead and do some zero-shot prompting.
31:57 - When is Christmas in America?
32:03 - And here, go.
32:05 - Okay, so it clearly already has the data for this.
32:10 - We don't need to add any examples or anything like that.
32:13 - So as you can see, zero-shot prompting refers
32:17 - to a way of querying models like GPT
32:21 - without any explicit training examples
32:23 - for the task at hand.
32:25 - In the context of machine learning and not just GPT,
32:29 - zero-shot typically means that a model performs a task
32:33 - without having seen any examples
32:35 - of that task during its training.
32:38 - Okay, great.
32:40 - So now let's look at few-shot prompting.
32:43 - So once again, with zero-shot prompting,
32:46 - we gave our language model a prompt and got a response.
32:49 - But sometimes that's just not enough
32:52 - and we need a bit more training.
32:54 - So let's use few-shot prompting
32:57 - and level up our language model by showing a few examples
33:00 - of the tasks we want it to perform.
33:02 - So instead of zero examples, we give it a tiny bit of data.
33:07 - So let's think, what would GPT for not know?
33:12 - I guess it would not know my favorite types of food.
33:16 - So for example, let's check,
33:18 - what is Ania's favorite type of food?
33:26 - Plural, okay.
33:28 - And I mean, it can guess,
33:30 - but no, it's just telling me that it doesn't know.
33:34 - So that is absolutely fine, let's stop generating.
33:38 - So now let's feed it in some example data.
33:40 - I'm gonna feed it in a tiny bit of data.
33:43 - Ania's favorite type of food includes,
33:51 - sorry about my English.
33:54 - Let's go with burgers, fries, I love fries, pizza,
34:01 - and hit enter, okay?
34:03 - So we are essentially giving chat GPT some information.
34:09 - So now if I type what restaurant should I take Ania
34:17 - to in Dubai this weekend and hit here,
34:26 - it should hopefully understand
34:28 - that my favorite types of foods are burgers, fries,
34:31 - and pizza, and given that find me some restaurants
34:35 - in Dubai that I would like to go to.
34:38 - So here are some, this has been updated as of September,
34:42 - 2021, but you know, these are pretty good ones.
34:45 - So I would totally go to these.
34:48 - This is a great example of few shop prompting
34:51 - in which it wouldn't have been able to answer this question
34:55 - if I hadn't had given it some example data
34:58 - or just trained the model a little bit more
35:02 - in order to get the response that I want.
35:05 - Great, AI hallucinations.
35:09 - Now we're delving into something
35:10 - you probably never thought you'd hear in an AI context
35:13 - and that's hallucinations.
35:16 - So what exactly are AI hallucinations?
35:19 - And no, they're not when your AI assistants
35:22 - start seeing unicorns and rainbows.
35:24 - It's actually a time that refers to the unusual outputs
35:28 - that AI models can produce when they misinterpret data.
35:32 - A prime example of this is Google's Deep Dream.
35:36 - You know, that project that turns pictures of your dog
35:38 - into a nightmarish blend of dog faces
35:41 - and well, more dog faces.
35:44 - Deep Dream is an experiment that visualizes the patterns
35:47 - learned by a neural network.
35:49 - It is built to over interpret and enhance the patterns
35:52 - it sees in an image, or in other words,
35:55 - fill in the gaps with images.
35:58 - But some of the time those gaps
36:00 - can be filled with the wrong thing.
36:02 - This is an example of an unusual output
36:05 - that AI models can produce when they misinterpret data.
36:10 - Now, why do these hallucinations happen, you ask?
36:13 - They're trained on a huge amount of data
36:16 - and they make sense of new data
36:18 - based on what they've seen before.
36:20 - Sometimes, however, they make connections that are,
36:24 - let's call it creative.
36:26 - And voila, an AI hallucination occurs.
36:29 - Despite their funny results,
36:31 - AI hallucinations aren't just entertaining.
36:34 - They're also quite enlightening.
36:36 - They show us how our AI models interpret
36:38 - and understand data.
36:40 - It's like a sneak peek into their thought processes.
36:43 - This example is actually an AI image hallucination,
36:46 - as I thought it would be a fun one to show.
36:49 - AI hallucinations can also happen with text models.
36:52 - An example of this is us asking a text model
36:55 - about a historical figure
36:57 - and the text model not having an answer
36:59 - and hallucinating one instead,
37:00 - resulting in an inaccurate response.
37:04 - Vectors and text embeddings.
37:06 - To finish off, I'm going to leave you
37:08 - with a slightly more complex subject.
37:11 - We're going to take a quick look
37:12 - at the topic of text embedding and vectors.
37:15 - In computer science,
37:17 - particularly in the realm of machine learning
37:19 - and natural language processing or NLP,
37:22 - text embedding is a popular technique
37:24 - to represent textual information in a format
37:26 - that can be easily processed by algorithms,
37:29 - especially deep learning models.
37:31 - In the context of prompt engineering,
37:33 - LLM embedding refers to representing prompts
37:35 - in a form that the model can understand and process.
37:39 - This involves converting the text prompt
37:41 - into a high dimensional vector
37:43 - that captures its semantic information.
37:46 - So essentially the word food is represented by this.
37:49 - If using the create embedding API from open AI.
37:53 - Okay, so you will see it's represented,
37:56 - the word was represented by an array
37:58 - of lots and lots of numbers.
38:00 - But why do this?
38:02 - Well, think about it this way.
38:04 - If you ask a computer to come back
38:06 - with a similar word to food,
38:08 - you wouldn't really expect it to come back
38:10 - with burger or pizza, right?
38:12 - That's what a human might do
38:14 - when thinking of similar words to food.
38:16 - A computer would more likely look
38:18 - at the word lexicographically,
38:21 - kind of like when you scroll through a dictionary
38:23 - and come back with foot, for example.
38:26 - This is kind of useless to us.
38:28 - We wanna capture a word's semantic meaning.
38:31 - So the meaning behind the word.
38:34 - Text embeddings do essentially that,
38:36 - thanks to the data captured in this super long array.
38:40 - Now, I can find words that are similar to food
38:44 - in a large corpus of text
38:46 - by comparing text embedding to text embedding
38:49 - and returning the most similar ones.
38:51 - So words such as burger instead of foot
38:54 - will be more similar.
38:56 - To create a text embedding of a word
38:58 - or even a whole sentence,
39:00 - check out the create embedding API here from OpenAI.
39:05 - So here's the URL that you should visit
39:08 - and to create your own text embedding,
39:10 - you're gonna have to create a post request
39:13 - to this endpoint.
39:15 - Okay, so that's what you can do.
39:17 - You can also take the code from here.
39:20 - So this is an example request written in Node.js
39:25 - and you would have to install the OpenAI package,
39:30 - take these two methods from it
39:33 - in order to pass through your OpenAI API key
39:37 - that I showed you how to get earlier.
39:39 - As a refresher, you should go here and view API keys
39:42 - to create your own API key.
39:45 - And once you pass that through,
39:47 - you can then use the configuration
39:51 - and pass it through here in order to use OpenAI
39:55 - and all of its wonderfulness,
39:57 - including the create embedding method
40:00 - in which you pass through an object.
40:02 - That object has to include the model
40:05 - and it also is gonna include the input.
40:07 - So in this case, it is the text
40:10 - that you want to turn into an embedding.
40:13 - So this is the code for doing that.
40:16 - And here is the response, which comes back as an object.
40:21 - And then you would use dot notation to get the data,
40:24 - go into the array in order to get the embedding.
40:28 - So this is gonna be the embedding that we saw earlier.
40:31 - It's an array made up of numbers
40:34 - and a lot of these numbers, okay?
40:37 - So not just these three,
40:39 - this does spill out
40:40 - and this will be a very, very long array of numbers
40:44 - that will give you this semantic meaning
40:46 - of whatever text you pass through, okay?
40:50 - So please have a go at playing around with this API
40:54 - in order to create your own text embeddings
40:57 - and compare them against other texts embeddings
40:59 - in order to find similar text.
41:02 - And that's it.
41:04 - Thank you so much for watching
41:05 - this course on prompt engineering
41:08 - in which we covered what it is.
41:10 - We covered an introduction to AI
41:12 - as well as looked at linguistics, language models,
41:15 - prompt engineering mindset, using GPT-4,
41:19 - how to look at best practices
41:20 - as well as zero shot and few shot prompting,
41:23 - as well as AI hallucinations, vectors or texts embeddings
41:27 - and this recap right here.
41:29 - So I hope you've enjoyed it
41:31 - and I'll see you again on the FreeCocam channel.

Cleaned transcript:

Learn how to get chat GPT and other LLMs to give you the perfect responses by mastering prompt engineering strategies. Anu Kubo is one of our most popular instructors. And in this course, she will teach you the latest techniques to maximize your productivity with large language models. Hi everyone and welcome to this course on prompt engineering. My name is Anu Kubo and I'm a software developer as well as course cruiser here on FreeCoCamp as well as on my own channel. This is going to be a unique course for me as there is going to be a lot less coding going on but a lot more understanding about the topic of prompt engineering and why some companies are paying up to $335,000 a year according to Bloomberg for people in this profession. And no, no coding background is necessarily required. So what are we waiting for? Let's do it. In this course, we will learn what prompt engineering is exactly, get a brief introduction to AI, a look at large language models or LLMs such as chat GPT, a look at text to image models such as mid journey, a look at emerging models. This would include text to speech, text to audio or speech to text as well as prompt engineering mindset, best practices, zeroshot prompting, fewshot prompting, chain of thought, AI hallucinations, vexes, text embeddings and also end with a quick intro to chat GPT. So let's start off with looking at what exactly prompt engineering is in the first place. Prompt engineering in a nutshell is a career that came about of the back of the rise of artificial intelligence. It involves human writing, refining and optimizing prompts in a structured way. This is done with the intention of perfecting the interaction between humans and AI to the highest degree possible. Not only that, however, a prompt engineer is then also required to continuously monitor those prompts ensure their effectiveness with time as AI progresses. Maintaining an uptodate prompt library will be a requirement that is placed onto the prompt engineer as well as reporting on findings and in general, being a thought leader in this space. But why do we need it? And how did it come about from AI? Before moving on, let's actually make sure we are on the same page about what exactly AI is. Artificial intelligence is the simulation of human intelligence processes by machines. I say simulation as artificial intelligence is not sentient, at least not yet anyways, meaning it cannot think for itself as much as it may seem it does. Often, and this is certainly the case with tools such as chat GPT, for example, when we say AI, we are simply referring to a term called machine learning. Machine learning works by using large amounts of training data that is then analyzed for correlations and patterns. These patterns are then used to predict outcomes based on the training data provided. So for example, here we are feeding data saying that if a paragraph looks like this with this type of title, then it should be categorized as international finance. The second paragraph should be put in the category of earning reports and so on. With some code, we should be able to train our AI model to correctly guess what future paragraphs are about. And that's it. Of course, that is a super basic example and we would need way more data than these five paragraphs right here, but you get the idea. If you want to build your own AI model and understand the concept of machine learning better as a total beginner, please check out my video on it on my channel, Code with Anya Kubo. As of now, rapidly improving general AI techniques can create realistic text responses and even images, music, and other media thanks to the huge amounts of training data and talented developers working on it today. Why is prompt engineering useful? With the quick and exponential growing rise of AI, even the architects of it themselves struggle to control it and its outputs. This might be a bit hard to understand, but think of it this way. If you were to ask an AI chatbot what is four plus four, you would expect it to say eight, right? The result of eight is pretty indisputable. However, imagine you are a young student trying to learn the English language. I'm going to show you just how different responses can be based on the prompts you feed and in turn your learning experience. For this example, I'm going to be using Chat GPT's GPT4 model. So let's start with the basics. If you were to type, correct my paragraph and then paste it a badly written paragraph. So just like this, today was great in the world for me. I went to a Disneyland with my mom. It could have been better though if it wasn't raining. Great, the young English learner has a better sentence, but it kind of stops there and the learner is just left to their own devices. And honestly, the sentence really isn't that great anyway. What if the learner could get the best sentences possible from a teacher who understands their interests to keep them engaged? With the correct prompts, we can actually create that with AI. So let's give it a go and let's write a prompt to do this. So here's the prompt I'm going to give it. I'm going to write, I want you to act as a spoken English teacher. I will speak to you in English and you'll reply to me in English to practice my spoken English. I want you to keep my reply neat, limiting the reply to 100 words. I also want you to strictly correct my grammar mistakes and typos. And I want you to ask me a question in your reply. Now, let's start practicing. You could ask me a question first. Remember, I want you to strictly correct my grammar mistakes and typos. So there's my prompt. You can also go a step further and ask it to correct your factual errors too, which I think would be an excellent addition to the prompt that will benefit the young learner. Okay, so let's go ahead and add that to the prompt. Okay, and let us do its thing. And great, so now this is way more interactive. As you will see, it's asking you a question and telling you what to do and will provide you with corrections if needed. So in a way, you're communicating with the AI. It's giving you suggestions and you're learning along the way. It's a completely different experience thanks to the prompt that we wrote. Pretty cool, right? We're gonna be diving into a bunch of these concepts soon, but first let's start with the basics. Linguistics. Linguistics is the study of language. It focuses on everything from phonetics, so the study of how speech sounds are produced and perceived. Phonology, so the study of sound patterns and changes. Morphology, the study of word structure. Syntax, so the study of sentence structure. Semantics, so the study of linguistic meaning. Pragmatics, so in other words, the study of how language is used in context. Historical linguistics, or the study of language change. Sociolinguistics, or in other words, the study of the relation between language and society. Computational linguistics, so the study of how computers can process human language. And physiolinguistics, or the study of how humans acquire and use language. So a lot. Linguistics are the key to prompt engineering. Why? Understanding the nuances of language and how it is used in different contexts is crucial for crafting effective prompts. Not only that, but knowing how to use a grammar or language structure that is universally used will result in the AI system returning back the most accurate results. As you can imagine, the sheer amount of data that it is trained on is most likely to mostly use the standard grammar and language structure that is universally used. So sticking to the standardization is key. Language models. Imagine a world where computers possess the power to understand and generate human language. A world where machines can chat, write stories, and even compose poetry. In this magical realm, language models can come into play. They are like the wizards of the digital realm capable of understanding and creating humanlike text. A language model is a clever computer program that learns from a vast collection of written text. It takes in books, articles, websites, and all sorts of written resources, allowing it to gather knowledge about how humans use language. Just like a master linguist, it becomes an expert in the art of conversation, grammar, and style. But how does this all work? Well, imagine you feed a sentence. The language model will then analyze the sentence, examine the order of words, their meanings, and the way they fit together. Then the language model would generate a prediction or a continuation of the sentence that makes sense based on its understanding of the language. It will weave words together one by one, creating a response that seems like it was crafted by a human being. Imagine having a conversation with the language model as if you were exchanging ideas with a digital friend. You ask a question, and it responds with a wellcrafted answer. You tell a joke, and it counters with a witty remark. It's like having a language expert by your side always ready to assist and engage in conversation. Now, you may wonder where these language models are used. They can be found in various places, from your smartphone's virtual assistants to customer service chatbots, and even in the creative realm of writing. They help us find information, offer suggestions, and create content. But remember, while language models possess incredible abilities, they still rely on the human to create and train them. They are, in fact, a fusion of human ingenuity and the power of algorithms, blending the best of both worlds. Let's start off by looking at the history of language models, starting with the first AI, Eliza, back in the 60s. Eliza is an early natural language processing computer program created from 1964 to 1966 at MIT by Joseph Wiesenbaum. Eliza was designed to simulate a conversation with a human being. Eliza had a special knack for mimicking a Rogerian psychotherapist, someone who essentially listens attentively and asks probing questions to help people explore their thoughts and feelings. Eliza's secret weapon was its mastery of pattern matching. It had a treasure trove of predefined patterns, each associated with specific responses. These patterns were like magical spells that allowed Eliza to understand and respond to human language. When you engage in a conversation with Eliza, it would carefully analyze your input, seeking patterns and keywords. It would then transform your words into a series of symbols, searching for patterns that match those symbols in its repertoire. Once a pattern was detected, Eliza would work its magic by transforming your words into a question or statement that aimed to explore your thoughts and emotions. It was as if Eliza was holding up a metaphorical mirror, encouraging you to delve deeper into your own thinking. For example, if you said something like, I feel sad, Eliza would detect the pattern and respond with a question like, why do you think you feel sad? It encouraged reflection and introspection, just like a caring therapist would. But here's the delightful twist. Eliza didn't truly understand what you were saying. It was just a clever illusion. It used pattern matching and some creative programming tricks to create the illusion of understanding while in reality, it was just following a set of predefined rules. Yet, even though Eliza was a simple program, people were often captivated by its conversational abilities. They felt heard and understood, even if they knew they were talking to a machine. It was like having a digital confident who was always ready to listen and offer gentle guidance. Eliza's creator, Weisenbaum, intended the program as a method to explore communication between humans and machines. He was surprised and shocked that individuals, including his secretary, attributed humanlike feelings to the computer program. But that is a whole other topic of conversation in itself. Eliza's impact was profound, sparking interest and research in the field of natural language processing. It paved the way for more advanced systems that could truly understand and generate human language. It was the humble beginning of a grand adventure in the world of conversational AI. Fast forward to the 1970s, when a program named Shudlu appeared. It could understand simple commands and interact with a virtual world of blocks. Although Shudlu wasn't a language model per se, it laid the foundation for the idea of machines comprehending human language. But the true language models began around 2010, when the power of deep learning and neural networks came into play. Enter the mighty GPT, short for generative pretrained transformer, ready to conquer the world of language. In the year 2018, the fast iteration of GPT emerged, created by the company OpenAI. It was trained on a large amount of text data, absorbing knowledge from books, articles, and a large chunk of the internet. GPT1 was a taste of things to come, an impressive language model, but small compared to its descendants that we use today. As time went on, the saga continued with the arrival of GPT2 in 2019, followed by GPT3 in 2020. This was a titan among language models equipped with a large number of parameters, over 175 billion to be precise. GPT3 dazzled the world with its unparalleled ability to understand, respond, and even generate creative pieces of writing. The arrival of GPT3 marked a real turning point in terms of language models and AI. At the time of writing, we now also have GPT4, trained on pretty much the whole internet, rather than outdated large data sets, as well as BERT from Google and so much more. It would seem we are only just at the start when it comes to language models and AI. So learning how to harness this data with prompt engineering is a smart move for anyone today. The prompt engineering mindset. When thinking of good prompts, it is always best to get in the correct mindset. Essentially, you want to just write one prompt, right? And not have to waste time and tokens, writing lots of different prompts until you get the result you desire. So essentially, kind of the same as when you Google stuff, right? How good are your Googling skills now, as opposed to five years ago? I'm assuming a lot better. We have grown to intuitively know what to type into Google the first time round as to not waste time. Having the same mindset for prompt engineering can also be applied. Mahail Eric of the Infinite Machine Learning Podcast says it well when he says, I personally like the analogy of prompting to designing effective Google searches. There are clearly better and worse ways to write queries against the Google search engine that solve your task. This variance exists because of the opaqueness of what Google is doing under the hood. We are gonna keep this in mind for the remainder of the course. A quick intro to using chat GPT by OpenAI. So as I said in this course for the examples, I will be using chat GPT's GPT for model. In order to follow along or just to understand how we are going to be using the platform, please head over to openai.com and just go ahead and sign up. I've already signed up, so I'm just gonna go ahead and log in and that will take me to the platform in which I can choose what I want to interact with. For this tutorial, we are going to be interacting with chat GPT for. So please go ahead and click on here and that will take you to the platform. And then I'm just gonna go ahead and switch to the GPT for model, which is the latest one. Okay, so great. You will see here all the previous chats that I've had. I'm just going to minimize this. And if we want to create a new chat, all we'd have to do is click the new chat button. Okay, so here, for example, what I can do is just go ahead and ask any questions. So what is four plus four? And then hit send. And that will essentially give me a response. So I'm now interacting with chat GPT for. On this occasion, I can actually build on the previous conversation. So what I can do is say, great. Now, can you add another five to that? What is the answer? And it will take into account everything that I have previously. Okay, I am building on top of the knowledge that it already has. Great. So again, this is just a very quick introduction to how to use this, we will be doing a deeper dive into this throughout this course. So once again, to create a new chat, all you'd have to do is create new chat. And if you want to delete the old one, just go ahead and click that delete button. And that will delete it. And then a new chat is brought up automatically. Wonderful. Now you might have seen my course on open AI in which we can also use the API. And to use the API, just go over to the API references. And all you would have to do is get an API key. And the API key can be viewed here. And then you just go ahead and create an API key. And that will allow you to interact with the open AI API in order for you to build out your own platforms just as the one we saw before. So if you're interested in that, please do head over to my tutorial on this, again, on the free COCAM channel. Otherwise, let's continue using chat GPT. So once again, I'm just going to log in and head back to the platform here. And that is it, we are ready to go. Another thing I want to discuss is tokens. As you might find that you have run out of the free tokens that you have in order to interact with chat GPT. So in order to do that, I'm just going to show you this, I'm going to head over to the documentation and talk to you a little bit about tokens. So GPT4 essentially processes all texts in chunks called tokens. And this token is approximately four characters or 0.75 words for English text. And we essentially get charged by token. If you want to know exactly how many tokens you are using, you can check it out here, you can check out the tokenizer tool, and it will give you a rough example. So for example, I can say, what is four plus four. And with that piece of text, the total count of tokens is going to be six. Okay, so there we go. That is exactly how many tokens will be used in order to produce a answer for this request. Great, so here is a URL for that. You can play around with it. I hope you have fun. If you want to see your usage, you can head over to account and then you can manage your account. And this should be able to show you your usage. So it will show you your usage right here per month. And then you can, of course, also add billing in order to carry on using chat GPT in case you've used up all your tokens and you can't use it anymore. So once again, this is under account billing overview. So just go check it out. Okay, and now back to the platform. Best practices. The biggest misconception when it comes to prompt engineering is that it's an easy job with no science to it. I imagine a lot of people think it's just about constructing a oneoff sentence such as correct my paragraph that we saw in the previous example. When you start to look at it, creating effective prompts relies on a bunch of different factors. Here are some things to consider when writing a good prompt. Consider writing clear instructions with details in your query. Consider adopting a persona as well as specifying the format using iterative prompting, meaning if you have a multipart question or if the first response wasn't sufficient, you can continue by asking followup questions or asking the model to elaborate and avoid leading the answer. Try not to make your prompts so leading that it inadvertently tells the model what answer you're expecting. This might bias the response unduly. And finally, limit the scope for long topics. If you're asking about a broad topic, it's helpful to break it down or limit the scope to get a more focused answer. Let's look at some of these now. In order to write clearer instructions, we can adopt writing more details in our queries. And to get the best results, don't assume the AI knows what you are talking about. Writing something like, when is the election, implies that you are expecting the AI to know what election you are talking about and what country you mean. This may result in you asking a few followup questions to finally get the result you want, resulting in time loss and frankly, perhaps some frustration. Consider taking the time to write a prompt with clear instructions. So, for example, instead of writing, when is the election, you could write, when is the next presidential election for Poland? So let's go ahead and run this. And this will be much more precise and knows exactly what we are asking about. It's not gonna go guessing and waste our time as well as waste our resources. So in other words, tokens that we are using, so in other words, money, in order to get the right answer the first time. Here are some other examples of how you could write clearer prompts. So for example, we have this prompt here, which says write code to filter out the ages from data. And if you run it, you don't really know what language it's gonna come back with, let's see. So for example, here it's using Python. I actually didn't wanna use Python, okay? So now we've lost some tokens asking this. We've also lost some time and we just haven't got the right response. This could have been so easily avoided. So I'm gonna stop this from generating and let's try again. So this time, let's be more specific by writing, write a JavaScript function that will take an array of objects and filter out the value of age property and put them in a new array. Please explain what each code snippet does. In this example, I am not assuming the AI knows what computer language I like to use and I am being more specific about what my data actually looks like. On this occasion, it's an array of objects. Not only that, I'm also asking the AI to explain why it's doing each step so that I in turn can understand and not just copy paste the code without gaining any knowledge from it. Okay, so here you can see a live example of what's coming back to us from GPT4. It's given us the correct code. So I have checked that and I was also giving us an example of how you would use the function, which is something I didn't ask, which is super useful. It's kind of gone above and beyond for helping me out in understanding what is going on. Let's look at another example. We can write, tell me what this essay is about. So I'm going to just type this and then just paste in an essay and hit go. And then chat GPT will do its thing. It's going to give me a summarization as it thinks best. So on this occasion, it is essentially giving me numbered points about what this essay is about. They're really long. I really didn't want to read this much. It's pretty much looking to be the same as the original essay. So this is not something I wanted. I should have been way more specific in telling it what I need. So what I'm going to do is just add to this conversation. So it's going to learn on what I wrote previously. And I'm just going to specify to use bullet points to explain what this essay is about, making sure each point is no longer the 10 words long. So I am being super specific in providing the instructions of what I want and let's hit go. So now this is a lot shorter. Okay, as you can see, each point is no longer than 10 words long. And then I'm going to get a summary that is a bit longer and will give me a summary of the essay that I pasted in above. So great, of course you can do this on any essay or piece of text that you wish and you can set your own clear and specific instructions as well. Okay, so I hope you can see why the second one is better. It's because I am not assuming the AI knows what kind of format I want the summarization of the essay to be in. I am being specific that I want very short notes on the essay in bullet point format with a short conclusion at the end. If I did not put this, the summary could have been just as long as the essay itself and the prompt could be considered useless in my eyes. Next up, we can also adopt a persona. When writing prompts, it is sometimes helpful to create a persona. This means you're asking the AI to respond to you and a certain character. So exactly like the English language teacher example we saw earlier, using a persona in prompt engineering can help ensure that the language model's output is relevant, useful and consistent with the needs and preferences of the target audience, making it a powerful tool for developing effective language models that meet the needs of users. Let's look at some examples of adopting a persona. So for example, you're gonna have this prompt right here. Write a poem for a sister's high school graduation that will be read out to a family and close friends. So let's go ahead and run this and let's see what comes back. So there we go. It is quite good in a room filled with kin and close ties. We gathered to honor the mist in our eyes for a journey has ended another begun as our dear sister steps into the sun. Okay, so it's coming out with a poem I can see here. It is quite a good one, I guess, probably better than anything that I would have written. And it is maybe a little bit generic. Maybe that's what you wanted. I think we can do better than this. So let's try this. This time I'm gonna write a prompt with a persona. So this time I'm gonna specify who I'm writing as. I'm gonna do write a poem as Helena. Helena is 25 years old and an amazing writer. Her writing style is similar to famous 21st century poet Rupi Kaur. Writing as Helena, write a poem for her 18 year old sister to celebrate her sister's high school graduation. High school graduation, this will be read out to friends and family at the gathering. Okay, so let's check it out now. We're writing as Helena, she's 25, she's an amazing writer and we've also assigned a writing style. So let's check it out. Now Chat GPT should be using anything it knows about Rupi Kaur, hopefully from the internet, in order to apply that style to this poem. Okay, and as you can see, this is maybe a little bit more affectionate. We've said sister, it's obviously a younger sister, so the words little sister are being used. And in general, I think this is a much higher quality poem and if Helena truly does have the style of Rupi Kaur in writing, it will be almost indistinguishable who wrote this poem, Chat GPT or Helena. So here we go, here's the full thing. It starts off, in the garden of our youth, I watch you bloom from bud to blossom, from child to woman, 18 summers passed. Again, utilizing the fact that we fed it, she was 18 and every winter's chill only made you stronger, a force of nature still. So yes, in my eyes, this poem is a lot more better it's much more refined, it's much more personal, thanks to the prompts that we wrote. We've already had a brief look at specifying format when we limited the word count of our bullet points in a previous example. So that was a great example, limiting words is one that I use often. However, we can do a bunch of other things, including specifying if something is a summary, a list or a detailed explanation. Heck, you can even create checklists. So I'm going to go ahead and show you how to do this. Here is an example prompt and I'm just going to run it. And there we go, we have created a checklist. So many things you can do in Chat GPT. Just make sure to specify the type of format you want and it should be able to do it. Okay, great. Now that we looked at some best practices, let's move on to some more advanced topics in the prompt engineering. In this section, I'm going to talk about two types of prompting we can do, zeroshot prompting and fewshot prompting. Zeroshot prompting leverages a pretrained model's understanding of words and concept relationships without further training. And fewshot prompting enhances the model with training examples via the prompt avoiding retraining. So essentially in the context of the GPT4 model, we don't really need to do much. We are already using all of the data that it has in order to ask when is Christmas in America? So let's go ahead and do some zeroshot prompting. When is Christmas in America? And here, go. Okay, so it clearly already has the data for this. We don't need to add any examples or anything like that. So as you can see, zeroshot prompting refers to a way of querying models like GPT without any explicit training examples for the task at hand. In the context of machine learning and not just GPT, zeroshot typically means that a model performs a task without having seen any examples of that task during its training. Okay, great. So now let's look at fewshot prompting. So once again, with zeroshot prompting, we gave our language model a prompt and got a response. But sometimes that's just not enough and we need a bit more training. So let's use fewshot prompting and level up our language model by showing a few examples of the tasks we want it to perform. So instead of zero examples, we give it a tiny bit of data. So let's think, what would GPT for not know? I guess it would not know my favorite types of food. So for example, let's check, what is Ania's favorite type of food? Plural, okay. And I mean, it can guess, but no, it's just telling me that it doesn't know. So that is absolutely fine, let's stop generating. So now let's feed it in some example data. I'm gonna feed it in a tiny bit of data. Ania's favorite type of food includes, sorry about my English. Let's go with burgers, fries, I love fries, pizza, and hit enter, okay? So we are essentially giving chat GPT some information. So now if I type what restaurant should I take Ania to in Dubai this weekend and hit here, it should hopefully understand that my favorite types of foods are burgers, fries, and pizza, and given that find me some restaurants in Dubai that I would like to go to. So here are some, this has been updated as of September, 2021, but you know, these are pretty good ones. So I would totally go to these. This is a great example of few shop prompting in which it wouldn't have been able to answer this question if I hadn't had given it some example data or just trained the model a little bit more in order to get the response that I want. Great, AI hallucinations. Now we're delving into something you probably never thought you'd hear in an AI context and that's hallucinations. So what exactly are AI hallucinations? And no, they're not when your AI assistants start seeing unicorns and rainbows. It's actually a time that refers to the unusual outputs that AI models can produce when they misinterpret data. A prime example of this is Google's Deep Dream. You know, that project that turns pictures of your dog into a nightmarish blend of dog faces and well, more dog faces. Deep Dream is an experiment that visualizes the patterns learned by a neural network. It is built to over interpret and enhance the patterns it sees in an image, or in other words, fill in the gaps with images. But some of the time those gaps can be filled with the wrong thing. This is an example of an unusual output that AI models can produce when they misinterpret data. Now, why do these hallucinations happen, you ask? They're trained on a huge amount of data and they make sense of new data based on what they've seen before. Sometimes, however, they make connections that are, let's call it creative. And voila, an AI hallucination occurs. Despite their funny results, AI hallucinations aren't just entertaining. They're also quite enlightening. They show us how our AI models interpret and understand data. It's like a sneak peek into their thought processes. This example is actually an AI image hallucination, as I thought it would be a fun one to show. AI hallucinations can also happen with text models. An example of this is us asking a text model about a historical figure and the text model not having an answer and hallucinating one instead, resulting in an inaccurate response. Vectors and text embeddings. To finish off, I'm going to leave you with a slightly more complex subject. We're going to take a quick look at the topic of text embedding and vectors. In computer science, particularly in the realm of machine learning and natural language processing or NLP, text embedding is a popular technique to represent textual information in a format that can be easily processed by algorithms, especially deep learning models. In the context of prompt engineering, LLM embedding refers to representing prompts in a form that the model can understand and process. This involves converting the text prompt into a high dimensional vector that captures its semantic information. So essentially the word food is represented by this. If using the create embedding API from open AI. Okay, so you will see it's represented, the word was represented by an array of lots and lots of numbers. But why do this? Well, think about it this way. If you ask a computer to come back with a similar word to food, you wouldn't really expect it to come back with burger or pizza, right? That's what a human might do when thinking of similar words to food. A computer would more likely look at the word lexicographically, kind of like when you scroll through a dictionary and come back with foot, for example. This is kind of useless to us. We wanna capture a word's semantic meaning. So the meaning behind the word. Text embeddings do essentially that, thanks to the data captured in this super long array. Now, I can find words that are similar to food in a large corpus of text by comparing text embedding to text embedding and returning the most similar ones. So words such as burger instead of foot will be more similar. To create a text embedding of a word or even a whole sentence, check out the create embedding API here from OpenAI. So here's the URL that you should visit and to create your own text embedding, you're gonna have to create a post request to this endpoint. Okay, so that's what you can do. You can also take the code from here. So this is an example request written in Node.js and you would have to install the OpenAI package, take these two methods from it in order to pass through your OpenAI API key that I showed you how to get earlier. As a refresher, you should go here and view API keys to create your own API key. And once you pass that through, you can then use the configuration and pass it through here in order to use OpenAI and all of its wonderfulness, including the create embedding method in which you pass through an object. That object has to include the model and it also is gonna include the input. So in this case, it is the text that you want to turn into an embedding. So this is the code for doing that. And here is the response, which comes back as an object. And then you would use dot notation to get the data, go into the array in order to get the embedding. So this is gonna be the embedding that we saw earlier. It's an array made up of numbers and a lot of these numbers, okay? So not just these three, this does spill out and this will be a very, very long array of numbers that will give you this semantic meaning of whatever text you pass through, okay? So please have a go at playing around with this API in order to create your own text embeddings and compare them against other texts embeddings in order to find similar text. And that's it. Thank you so much for watching this course on prompt engineering in which we covered what it is. We covered an introduction to AI as well as looked at linguistics, language models, prompt engineering mindset, using GPT4, how to look at best practices as well as zero shot and few shot prompting, as well as AI hallucinations, vectors or texts embeddings and this recap right here. So I hope you've enjoyed it and I'll see you again on the FreeCocam channel.
