With timestamps:

00:02 - hey everyone and welcome to my mini
00:04 - course on the essentials of data science
00:06 - this mini course provides a super basic
00:08 - looking to data science what it is and
00:11 - the three main components that make up
00:13 - data science data science is a very
00:15 - mainstream word like it's thrown around
00:17 - a lot but its actual definition is quite
00:19 - vague this mini course is designed to
00:22 - help those of you who are curious about
00:24 - data science develop a better and more
00:26 - specific understanding of the topic
00:28 - there are definitely more advanced
00:30 - techniques within data science such as
00:32 - machine learning but even these can be
00:34 - traced back to the three essential
00:36 - components that we'll cover before we
00:38 - get straight into it
00:39 - I thought I'd quickly introduce myself
00:40 - my name is Max and I work as a data
00:43 - scientist after getting my degree in
00:45 - physics I find myself more and more
00:48 - drawn into the world of data science so
00:50 - instead of diving into the realm of
00:51 - physics research I taught myself all the
00:54 - tools and techniques a data scientist
00:56 - needs and shortly after landed my dream
00:59 - data science job I've since also started
01:02 - teaching data science to others and have
01:04 - been fortunate enough to teach what is
01:05 - currently over 9,000 students the skills
01:08 - of gathered and learned over the past
01:09 - five years of my data science journey so
01:12 - let's jump right into it so what is data
01:16 - science well data science is you can
01:19 - kind of summarize it in different ways
01:20 - but the main parts of it are
01:22 - transforming data into information and
01:25 - this is a really big step because a lot
01:28 - of people talk about you know data and
01:29 - big data and all these things but data
01:31 - by itself isn't really that useful until
01:35 - you can turn it into information and so
01:38 - if you just have a bunch of numbers
01:39 - appearing somewhere and it's just you
01:41 - know so much of it no one can make sense
01:44 - of that and that's where you need a data
01:45 - scientist to be able to transform all of
01:48 - these all of this vagueness and kind of
01:51 - this noise to that's going on and you
01:53 - need to be able to extract information
01:54 - from it
01:55 - and that's what a data scientist does
01:57 - now what you do with this - with this
02:00 - information or how you get this
02:02 - information
02:02 - it's through analyzing your data so a
02:04 - big part of it would be you know
02:06 - cleaning things up doing some some
02:09 - processes on it and then you analyze
02:11 - once you've clean things up
02:13 - and that is one of the ways that you can
02:15 - then get information out of your data
02:18 - through this analysis and you can kind
02:20 - of continue on and you see trends and
02:22 - patterns and all types of correlations
02:24 - hopefully and all of these things again
02:27 - build up into this turning data into
02:29 - information component and then
02:33 - ultimately you also need to
02:34 - contextualize everything that you have
02:36 - so your computer can't do that for you
02:38 - you can Peter can kind of crunch the
02:40 - numbers and stuff but it's your
02:41 - responsibility also to make sense what's
02:43 - in front of you and even if you see
02:45 - something you just don't blindly trust
02:47 - it but you need to understand you know
02:49 - where am I at where am i coming from
02:52 - where is this data coming from you need
02:53 - to be able to contextualize these things
02:55 - and then of course be able to apply as
02:57 - well as understand them and so once you
03:00 - have this data you know it's great but
03:02 - turning it into an information into
03:04 - great information that you can use and
03:06 - directly apply that's where the real
03:09 - power lies and that's also kind of the
03:12 - role of a data scientist so that's what
03:14 - the data that's what data science pretty
03:17 - much is and so what is the data
03:19 - scientists do well we kind of already
03:21 - talked about this just a little bit but
03:23 - let's go over it again any more concrete
03:25 - examples um so a data scientist would
03:28 - for example get and process this raw
03:31 - data and then convert it into something
03:33 - a little bit cleaner so you can imagine
03:36 - kind of just like a data stream coming
03:37 - in and it's you have this measuring
03:39 - device and constantly is just measuring
03:41 - all sorts of data and because like
03:44 - nothing is really constant so everything
03:45 - will be fluctuating up and down and so a
03:47 - data scientist would be to kind of take
03:49 - all of this data it'd be to kind of
03:51 - clean it up a little bit you know maybe
03:53 - reduce this fluctuation that you know
03:55 - isn't supposed to be there that's just
03:56 - kind of background stuff going on and
03:59 - then put it into a format so that you
04:01 - can easily plot it against some things
04:03 - and then we already get to the next
04:05 - point that you know once this data is
04:06 - cleaner you can maybe do start doing
04:08 - some calculations on them figuring out
04:11 - the core statistical components you know
04:13 - like what is the average values of these
04:15 - what what am I really dealing with you
04:18 - know getting a first look at first
04:19 - understanding of what it actually is
04:21 - that you're tackling and then once you
04:23 - have this kind of understanding then you
04:25 - can start to do some visualize they
04:26 - which helped you as a data scientist
04:29 - maybe see some trends or patterns
04:30 - already but visualization was also
04:32 - really key because they let you show it
04:35 - to other people and there are great
04:37 - means of communication so they help both
04:39 - you as a data scientist as well as
04:41 - helping others when you try to convey
04:42 - this information to them all right and
04:45 - then finally you have to suggest some
04:47 - applications of the information so it's
04:49 - not really enough to just be able to
04:50 - look at it and say like yeah I see it
04:53 - goes up and down and that's that's good
04:55 - but what does that mean how does this
04:57 - transfer into something useful and
04:59 - that's also one of the key roles of a
05:02 - data scientist transferring information
05:04 - into knowledge and so you've got this
05:06 - data into information step but you also
05:09 - need to transfer this information into
05:11 - knowledge and those are two really
05:13 - powerful things that are worth a lot a
05:15 - lot and that's pretty much what a data
05:18 - scientist focuses on and then you can go
05:20 - further you know and take this data and
05:22 - do machine learning with it or something
05:24 - if you really understand what's going on
05:25 - or if you have some hypotheses of you
05:28 - know what could happen so you can take
05:29 - things a lot further but ultimately this
05:31 - kind of turning data into information
05:33 - and then into knowledge that's kind of
05:36 - your role all right so let's go into the
05:39 - essential techniques or the essential
05:41 - components of data science so the first
05:44 - essential component and we kind of
05:45 - touched on this already is statistics
05:48 - and basically we're gonna cover this
05:51 - later on but let's just give a kind of
05:53 - quick wrap down so in statistics need to
05:56 - understand different data types that you
05:58 - can encounter and so there are data can
06:01 - come in different ways and we'll go
06:03 - again into more detail with this later
06:05 - but it's not just you know you get a
06:07 - bunch of numbers data can come in very
06:09 - many different ways depending on the
06:11 - field that you're in and so you need to
06:12 - be prepared and you need to kind of be
06:14 - aware that data may not always just be a
06:16 - direct number for you then of course you
06:19 - need to understand some key statistical
06:20 - terms like you know the different types
06:22 - of means and also understanding
06:24 - fluctuations in data and the reason that
06:26 - this is important is because these key
06:29 - statistical terms give you an overview
06:31 - of how this data is behaving and
06:33 - depending on how the data is behaving
06:35 - you may want to approach it differently
06:36 - so if you know that your data is
06:39 - very clean there's a very little
06:40 - fluctuation then if you visualize things
06:43 - you can probably trust what's going on
06:45 - or if you want to maybe fit some curves
06:47 - to it or something but if you see
06:49 - there's a lot of fluctuation in your
06:50 - data visualizing it is going to be much
06:52 - more difficult because you just see
06:54 - jumps everywhere and you're not really
06:55 - sure which of this is actually true and
06:58 - which of this is caused by you know like
07:00 - some interference somewhere or someone
07:02 - is messed with my system and so all of
07:05 - these things will kind of be hinted to
07:07 - you through statistical terms so it's
07:10 - probably good that you know you're kind
07:12 - of comfortable with these things and
07:13 - that you can be able to get some meaning
07:16 - and meaning out of them all right and
07:19 - then finally it be in statistics to be
07:22 - able to you know split up and group or
07:24 - segment data points so that when you
07:27 - have this big data set you want to be
07:28 - able to you know maybe split it up into
07:30 - smaller things compare different regions
07:32 - look more into more detail into some
07:35 - things and maybe you know isolate two
07:37 - components because you know hey these
07:39 - things are probably going to be
07:40 - important the rest I don't really care
07:42 - about that much so being able to kind of
07:44 - pinpoint an isolate and meddle with the
07:46 - data a little bit so these are the kind
07:48 - of statistical components that we're
07:49 - gonna look into all right so the next
07:52 - big thing and we've already talked about
07:54 - this too is data visualization and we'll
07:57 - see why data visualization is a really
07:59 - key skill for data scientists and then
08:02 - we're also be gonna be covering
08:04 - different types of grass that you can
08:05 - use and how you can compare different
08:07 - number of variables so for example you
08:09 - can have one variable grass where you
08:11 - only look at one thing and you only want
08:14 - to look at this and you want to see how
08:15 - these how this changes you have your
08:17 - typical two variable grass which you
08:19 - probably know where you have this X and
08:21 - a y-axis and then you can kind of see
08:23 - how two variables relate to each other
08:25 - or you can have three variable or even
08:27 - higher variable graphs and where you
08:29 - plot maybe three different things or
08:31 - even more if you want as long as it
08:33 - makes sense next to each other so that
08:36 - you can compare multiple things at the
08:37 - same time all right and now we come to
08:42 - the other big thing that you're probably
08:43 - going to need as a data scientist which
08:45 - is going to be the ability to program
08:47 - now not every data scientist can do this
08:51 - but this is
08:52 - really really essential in my opinion to
08:56 - your role as a data scientist because
08:58 - knowing how to program is going to make
08:59 - your life so much easier if you know how
09:02 - to program you can kind of take your
09:04 - ideas and your thoughts and you can put
09:06 - them into actions in the computer and
09:08 - you can just automate everything you can
09:10 - customize things you can explore you can
09:12 - prototype you can test and you're not
09:14 - reliant on some you know application you
09:17 - don't have to master some application
09:19 - and if it doesn't work or if one feature
09:20 - isn't there you have to contact customer
09:22 - support and maybe it's not even possible
09:25 - and then you have to wait for an update
09:26 - or maybe something is bugged
09:28 - with programming there's just you're so
09:30 - much more reliant on yourself and you
09:32 - can really just do whatever it is you
09:34 - want to do and you're not reliant on
09:36 - other people or on the tools that other
09:38 - people have built for you but rather you
09:40 - can just pretty much go and you know
09:42 - just do what you want to do without
09:44 - there being major roadblocks and then
09:47 - we'll also look at some essential
09:49 - packages in Python so in programming you
09:52 - never want to reinvent the wheel you
09:54 - always want to start off where the last
09:55 - person left off and so the ability to
09:58 - program and be able to write simple
10:00 - programs you would need to teach
10:02 - yourself but you wouldn't need to write
10:03 - highly complex mathematical packages or
10:06 - data analysis packages those are already
10:08 - out there all you need to do is be able
10:10 - to download them and implement them in
10:13 - your code and they're gonna work you
10:15 - know they've been tested a lot there's a
10:17 - huge community's working on them on
10:20 - improving them and everything all of
10:22 - this is for the community and so the
10:24 - whole community kind of works together
10:26 - to improve it no one's really directly
10:28 - trying to make a lot of money off of it
10:29 - so they're not going to charge you all
10:31 - of these service fees and everything
10:33 - everyone's just trying to improve their
10:34 - package because if it improves everyone
10:37 - also benefits from it and so we'll look
10:39 - at some of the libraries or we'll talk
10:42 - about some libraries that you can use
10:44 - especially in Python and to help you
10:46 - along your way with data analysis and to
10:49 - become a successful data scientist in
10:51 - this chapter we're going to talk about
10:53 - statistical data types now we're going
10:56 - to look at the three different types of
10:58 - data which are summarized as numerical
11:01 - categorical and ordinal types of data
11:04 - now these are the types of data that we
11:07 - talked about before how you can't just
11:09 - expect your data to be cut be kind of
11:11 - numerical and so we'll see the miracle
11:14 - data but we'll also see the two other
11:16 - types of data that you may be you know
11:19 - encountering in your career as a data
11:21 - scientist all right
11:23 - so let's talk about numerical data first
11:25 - though numerical data is also known as
11:28 - quantitative data and it's pretty much
11:31 - things that you can kind of measure it's
11:33 - it's great numerical stuff that you can
11:36 - do math with you can compare it you know
11:39 - saying this Plus this makes sense he is
11:42 - greater than B these are you know all
11:45 - examples of numerical data numerical but
11:48 - data can we split up into two different
11:50 - segments one of them is going to be
11:52 - discrete and so discrete means the
11:54 - values only take on distinct numbers and
11:57 - an example of this would be you know IQ
12:01 - or something like that a measurement of
12:02 - IQ or if you do a coin toss the number
12:05 - of times that you toss heads so you can
12:07 - you know you can have 15 heads you can
12:10 - have 12 heads out of you know 20 coin
12:12 - tosses you can have 500 heads out of a
12:14 - thousand coin tosses or 500 out of 600
12:17 - or all of these things but all of these
12:18 - are distinct numbers and now they don't
12:22 - have to be whole specifically but they
12:25 - do have to be distinct so that's that's
12:28 - the kind of very important part that you
12:30 - know there's a kind of step size that
12:33 - you're dealing with and of course you
12:35 - can still say hey you know flipping
12:37 - eight heads out of twenty is better than
12:38 - filling seven heads out of twenty so if
12:41 - you want to flip heads lettuce or
12:43 - flipping eight out of 20 is worse than
12:45 - flipping 7 out of 20 if you're going for
12:47 - as many tails as you can so all of these
12:49 - kind of comparisons that make sense so
12:52 - that's the discrete part of numerical
12:54 - data then we have the continuous part
12:56 - and now the continuous part is really
12:59 - that values can just take on any number
13:01 - and they're not unlimited by decimal
13:02 - place so a value that can you know can
13:05 - be like one point one and then the next
13:08 - value would be one point two that's not
13:09 - continuous that's still discrete because
13:12 - you have this step size of zero point
13:14 - one continuous means literally ever
13:18 - number from start to finish can be taken
13:21 - on and this doesn't mean that every
13:23 - possible number in the universe from
13:25 - negative infinity to plus infinity and
13:27 - all imaginary numbers and everything
13:29 - that comes with it that doesn't that
13:31 - that's not required for continuous it
13:33 - could really be that just every number
13:35 - between zero and one can be taken on so
13:38 - for example let's say you have a bottle
13:41 - of water and this bottle of water can
13:43 - hold one liter now if you fill your
13:47 - bottle up and it starts off empty and
13:49 - you fill it all the way up to the top
13:51 - the amount of water that you've had
13:53 - needed to take on every single number
13:56 - between zero and one because you can't
14:00 - just fill up water you know in kind of
14:01 - small increments of say hey I'm gonna
14:03 - put in 0.2 liters every single time
14:06 - because the water doesn't just you know
14:08 - teleport from A to B but when you're
14:10 - pouring in water it's more like we see
14:13 - in the stream here and the water level
14:15 - rises and Rises and Rises and so the
14:18 - amount of water that we have in our cup
14:20 - needs to take on every value between
14:22 - zero and one so that's an example of
14:25 - continuous data for but you see that you
14:29 - know we can be limited to zero and to be
14:31 - between zero and one we don't have to
14:33 - you know start at zero and go all the
14:35 - way up to infinity or something but it's
14:37 - just that the range that we're looking
14:39 - at every single number can can be
14:44 - applied or every single number can you
14:46 - know happen another good example would
14:50 - be the speed of a car if you start and
14:52 - you you know you're standing still and
14:55 - you're studying you're standing at a
14:56 - stoplight and then you want to
14:58 - accelerate in the speed limit us say you
15:00 - know 50 miles an hour or something to
15:02 - get to 50 miles an hour from your
15:05 - starting position your car has to take
15:07 - on every single speed in between and of
15:11 - course you won't see that you know on
15:13 - your spot on the speedometer it would
15:14 - say something like zero miles an hour
15:16 - one mile an hour you know maybe you can
15:18 - go to like it's going 0.1 0.2 0.3 or
15:21 - something like that so it may look
15:23 - discrete to you but that's not how your
15:25 - car is going your car doesn't say it
15:27 - like oh I'm gonna go in these step sizes
15:29 - of speed it's gonna accelerate
15:31 - gonna take on every value starting from
15:33 - zero going up to 50 miles an hour and
15:36 - you're gonna when you're in this
15:38 - transition you're gonna take on every
15:40 - single one of those speed values so
15:43 - that's how continuous data looks like
15:45 - and it's important to understand the
15:48 - difference between this discrete and
15:49 - continuous just because you may want to
15:53 - approach it differently now of course if
15:55 - we're dealing with computers our
15:56 - computers can't deal with infinite
15:59 - numbers in the decimal places we have to
16:01 - cut it off somewhere and so usually
16:04 - continuous data is gonna be rounded off
16:06 - at some point but it's still important
16:08 - for you to know that you're dealing with
16:09 - continuous data here rather than
16:11 - discrete so that you know hey there can
16:13 - still be other stuff in between here and
16:15 - or all of these things rather than you
16:17 - know having specific step sizes and all
16:19 - you see is just kind of a bunch of lines
16:21 - at every step size but you can expect
16:24 - that when you have continuous data that
16:26 - everything is just kind of filled filled
16:29 - up that everything can and may even well
16:32 - be in between certain places so that's
16:35 - that's kind of the important thing to
16:36 - note between discrete and continuous
16:39 - alright so the next type of data that
16:42 - we'll have is categorical now
16:44 - categorical data doesn't really have a
16:47 - mathematical meaning and you may also
16:49 - know it to be qualitative data um and
16:52 - categorical data it describes
16:54 - characteristics so a good example of
16:56 - this would be for example gender so here
17:00 - there is no real mathematical meaning to
17:02 - gender of course you know if you have
17:04 - good data you can say male is zero and
17:07 - female is one but you can't really
17:10 - compare the two numbers even though you
17:12 - assign numbers to them and you may just
17:14 - do this so that you can split it up
17:15 - later on there your computer can
17:17 - understand but it doesn't really make
17:19 - any sense to compare you can't say you
17:22 - know is male equal what you can say male
17:25 - is not equal to female but you can't
17:27 - really say is one greater than the other
17:29 - or is one approximately equal to the
17:32 - other those things don't really make
17:33 - sense because they're not well-defined
17:35 - what does that mean and you can't really
17:38 - add them up either you can't say male
17:40 - plus female but that doesn't it doesn't
17:43 - give you a third
17:45 - category or something so categories that
17:48 - you can't really apply math to them but
17:49 - there are nice ways to kind of split up
17:51 - or group your data and they provide
17:53 - these nice qualitative pieces of
17:55 - information that are still important
17:56 - it's just you can't really go that well
18:00 - about you know like plotting them on a
18:01 - line or something like that
18:03 - so those are important things to note
18:05 - with categorical data and then another
18:07 - example would for example be yeah
18:08 - ethnicity or you could also have
18:10 - nationality all of these things are
18:13 - examples of categorical types of data
18:17 - yeah I'm so like we said you can assign
18:19 - numbers to them but that's really just
18:21 - for your code so that it's easy to kind
18:23 - of split them up but you still can't
18:26 - really compare them how are you gonna
18:27 - compare nationalities there is really no
18:30 - definition for you know comparing one
18:33 - type of category to another alright and
18:37 - so the third type of data that you can
18:39 - encounter is something called ordinal
18:41 - data
18:41 - now ordinal data is a mixture of
18:44 - numerical and categorical data and a
18:47 - good example of this would be both tell
18:49 - ratings so you have you know star
18:52 - ratings 0 0 1 2 3 4 or 5 stars or maybe
18:56 - even 6 stars or you know whatever it is
18:58 - whatever the hotels go up to these days
19:00 - um but it's still not as straightforward
19:02 - to compare so I'm sure you've seen two
19:05 - different types of three-star hotels one
19:07 - of them you know had the bare minimums
19:09 - the beds were okay but it wasn't really
19:11 - anything special and then you had this
19:14 - three-star hotels that you could have
19:15 - sworn we're at least four-star and so
19:18 - star ratings do make sense we can say
19:21 - you know a four-star hotel is probably
19:24 - better than the three tier hotel because
19:26 - there have been standards there are
19:28 - standards for these things they have
19:29 - been checked you know if you go to a
19:30 - four-star hotel you know what to kind of
19:32 - expect but still it's not completely
19:37 - defined so like you know coming back to
19:39 - this three star example it's very hard
19:42 - if you just say hey we're going to a
19:43 - three-star Hotel it's very hard to know
19:45 - exactly what to expect because there are
19:48 - different parts of three-star hotels
19:50 - there are three-star hotels that have
19:52 - developed onto like have a swimming pool
19:54 - maybe or something like that and then
19:56 - there are those three-star hotels
19:58 - that are really more like hostels or
20:00 - something that I've just made it past
20:01 - the to start place and so there it's
20:03 - much harder to kind of define or to know
20:06 - what to expect now if you take averages
20:10 - of these star systems though then you do
20:12 - get a much better idea of what's going
20:14 - on so if you have you know consumer
20:16 - reviews or something like that and you
20:18 - say Oh from you know 500 reviews our
20:21 - hotel has an average rating of like 3.8
20:24 - then you know that the three star hotel
20:27 - that you're looking at is pretty much a
20:29 - four star hotel it feels like a four
20:32 - star hotel even though it may not have
20:34 - all of those qualifying characteristics
20:37 - that's the kind of feel you get from it
20:39 - whereas from another three star hotel
20:41 - you may have a rating of like 2.9 or
20:44 - something and there you know oh you know
20:46 - this hotel is more towards the lower end
20:48 - of the three star some people may not
20:49 - even consider it to be three stars and
20:51 - of course you know this rating may be a
20:53 - little bit biased because they went to a
20:55 - different three hard star hotel first
20:57 - and then they went to this one and they
20:59 - were expecting something completely else
21:00 - from the three star hotel so they said
21:02 - this can't be three stars this is two
21:03 - stars but it's because of the way that
21:06 - the ranking system is defined underneath
21:08 - and everything and so when we have these
21:10 - averages of these ordinal numbers then
21:12 - they kind of start to make a little bit
21:14 - more sense alright so let's go over a
21:18 - small exercise and see if we can
21:20 - identify what type of data we're dealing
21:22 - with so the first thing we'll look at is
21:25 - gonna be the survey response to
21:27 - happiness now you have people filling
21:29 - out a survey and then this and then one
21:31 - of the questions is you know how would
21:33 - you rate your happiness and it's gonna
21:34 - be bad neutral good or excellent what
21:38 - type of data with this be well this
21:42 - would be an ordinal type of data because
21:44 - it's still in a form of categories and
21:47 - you're asking for the subjective opinion
21:49 - but it does make sense so you can still
21:51 - compare them you can say excellent is
21:53 - greater than good good is greater than
21:55 - neutral neutral is greater than bad but
21:57 - what exactly does it mean to be good and
22:00 - excellent you know where do different
22:02 - people draw the line for this there's
22:04 - it's still a little bit of vagueness
22:05 - involved but generally it does make
22:07 - sense and you can compare it and if you
22:09 - have a lot of surveys
22:11 - and you averaged them the values you're
22:13 - gonna get are probably going to be very
22:15 - well representative or at least pretty
22:16 - good representative all right so if we
22:20 - look at the next thing which is going to
22:22 - be the height of a child what type of
22:25 - data is that now we can say it's
22:29 - probably numerical and well it actually
22:32 - most definitely is numerical so the
22:35 - height of a child is a numerical value
22:37 - but let's go a little bit deeper and say
22:39 - is the height of a child discrete or is
22:41 - the height of a child continuous well
22:45 - even though when you measure height you
22:47 - get something like you know five foot
22:49 - five foot three or 160 centimeters or
22:53 - something like that it's not a discrete
22:57 - value because to get that height you
22:59 - have to have reached every single height
23:02 - before and so even though at the moment
23:05 - you may be measuring it you're kind of
23:07 - rounding it off to how much your
23:09 - measuring tape can measure so like your
23:12 - measuring tape is kind of limiting the
23:14 - height but if you had a super super
23:16 - precise measuring instrument you could
23:18 - measure not just you know five foot
23:20 - three or something like that you could
23:22 - really go into detail with the inches
23:24 - and the decimal places and there and
23:26 - everything kind of going on so the
23:29 - height of a child would be a numerical
23:30 - data type but it would be continuous all
23:33 - right now let's take about talk about
23:34 - the weight of an adult do you expect the
23:37 - weight of an adult to be either discrete
23:38 - or continuous so we can probably agree
23:41 - that it's numerical because it's a
23:43 - weight value it's it's pretty much
23:45 - defined to be a number and what do you
23:48 - expect it to be discrete or continuous
23:49 - well the right answer here is gonna be
23:52 - continuous again because to reach a
23:55 - certain weight they would have had to
23:57 - have reached every single weight in
23:59 - between before so again the weight is
24:02 - something that we can consider to be
24:04 - continuous all right and so finally
24:07 - let's look at the number of coins in
24:09 - your wallet again we can already by the
24:12 - name it says a number of coins so we can
24:14 - probably agree that this is a numerical
24:17 - type of data but the number of coins in
24:19 - your wallet would that be discrete or
24:22 - continuous well the answer would be
24:24 - discrete
24:24 - because it doesn't really matter what's
24:27 - your anoint your coins are they could be
24:28 - 50 cent pieces that could be 25 cent
24:30 - pieces ten or five or ones or anything
24:33 - you know like a two or something like
24:34 - that but they're not going to be but the
24:37 - number of coins that you're gonna have
24:38 - we're gonna sum up to a whole number so
24:40 - you can have one coin you can have two
24:41 - you can have three all of these things
24:44 - but you can't have infinite fractions of
24:47 - a coin you can't have say you know the
24:50 - square root of two number of coins that
24:52 - doesn't really make sense so you have a
24:55 - defined step size you have one coin and
24:57 - then if you have a second coin then you
24:59 - have to you get a third coin meaning of
25:00 - three you're going in step sizes of one
25:02 - so for the number of coins in your
25:04 - wallet we'd be having discrete numerical
25:08 - data in this tutorial we're going to
25:10 - talk about the different types of
25:12 - averages now we're going to see the
25:14 - three different types of averages which
25:16 - is the mean the median and the mode
25:19 - alright let's get started so we'll start
25:22 - off with the mean now the mean is the
25:24 - typical average that you know and really
25:28 - what the mean is is you just sum all of
25:30 - your values up and then you divide them
25:32 - by the total number of values that you
25:33 - have now the great pros of the mean is
25:36 - that it's very easy to understand it
25:39 - makes sense we just have everything we
25:40 - have and just kind of add it all up and
25:43 - then divided by what we have and that
25:45 - should give us a good representation of
25:48 - what is the average and it also takes
25:50 - into account all of the data so since
25:52 - we're adding everything up and then but
25:54 - dividing by how much data we have we're
25:56 - taking into consideration every single
25:58 - data point now there are some problems
26:01 - with this so one of the problems is that
26:03 - the mean may not always be the best
26:06 - description and we'll see why when we
26:09 - look at examples for when we should use
26:11 - the median and the mode and the mean is
26:14 - also very heavily affected by outliers
26:15 - so since we're taking everything into
26:19 - consideration if we have big outliers
26:22 - that's really gonna change how our mean
26:25 - looks like so if we just have normal
26:27 - values you know between like one and
26:30 - five and all of a sudden we have like
26:31 - 10,000 in there that's really gonna
26:33 - affect our mean so mean is heavily
26:36 - influenced by outliers and the bigger
26:38 - the outlier
26:38 - more the mean is influenced by it all
26:41 - right so let's see some examples of the
26:43 - mean we'll go through a worked example
26:46 - first and we can see our data set here
26:48 - which is just a bunch of numbers and
26:51 - what we're gonna do to calculate the
26:53 - mean is we're just gonna take every
26:55 - single one of these numbers and we're
26:56 - gonna add them up and we can see the
26:59 - total result that we get here and then
27:01 - the next thing we're gonna do is we're
27:02 - gonna take this total result we're gonna
27:03 - count the amount of data points that we
27:06 - have and we're gonna divide one by the
27:08 - other which then gives us our mean as we
27:11 - can see here so that's an example
27:13 - calculation of the mean but let's see
27:15 - some example applications of the means
27:17 - so when would we use it well good
27:19 - application would say if you look at the
27:22 - time it takes you to walk to the
27:24 - supermarket so sometimes you walk a
27:26 - little bit faster and maybe it takes you
27:28 - 20 minutes to get there sometimes you
27:30 - walk a little bit slower it takes you 25
27:32 - but on average it takes you somewhere
27:35 - like 22 or maybe 22 and a half minutes
27:38 - or something like that so if you say I'm
27:40 - gonna go to the supermarket you're like
27:42 - it's gonna take me this much time to get
27:45 - there another good example of the mean
27:48 - would be exam score for a class so to
27:51 - get a good understanding of how people
27:54 - do in an exam or in a class you can look
27:58 - at the mean exam score last year and
28:00 - since our exam scores are kind of in a
28:03 - smaller range a mean is gonna be good to
28:06 - use it because you can get anything
28:07 - between 0 and 100 but realistically
28:10 - speaking no one's probably going to get
28:12 - a zero so your range is even smaller and
28:14 - so you're less affected by outliers and
28:16 - you kind of know how hard a class is
28:19 - gonna be just by being you know able to
28:21 - compare their means so if you look at
28:22 - one class and it's mean is higher than
28:26 - the other but they have a large number
28:28 - of students or something then you can
28:30 - probably say hey it's easier to get a
28:32 - good grade here or something like that
28:33 - or maybe you know some of these it's
28:36 - more simpler overviews without diving
28:38 - too deep into it alright another good
28:41 - example of the mean would be to say how
28:43 - much chocolate do you require when you
28:45 - get this kind of sweet craving and
28:47 - you're not gonna say like oh you know I
28:50 - require one chocolate bar two chocolate
28:52 - bars
28:52 - but like you're gonna say Oh on average
28:55 - you know I require you know maybe
28:57 - three-quarters of a chocolate bar and
28:59 - sometimes I may want a little bit more
29:01 - because I feel like it and when I start
29:03 - eating chocolate I crave it even more
29:05 - sometimes you know I have it at first
29:08 - and like the tasters doesn't sit right
29:09 - with me right now and so I have a little
29:11 - bit less but these are kind of the
29:14 - amount of things so like if you have
29:15 - this craving you know either you say oh
29:17 - I'm gonna try to be strong or you like
29:18 - hmm well I know this feeling and I know
29:20 - if I eat about you know three-quarters
29:22 - of a bar of chocolate or something I'm
29:24 - gonna feel good my craving is gonna be
29:26 - satisfied so you kind of know what to
29:29 - expect so these are some of the examples
29:31 - for how we would deal with a mean well
29:35 - when we would use mean all right so
29:37 - let's look at the next thing which is
29:38 - going to be the median now the median
29:41 - represents the middle value in your debt
29:44 - data says now if you have an even number
29:47 - of data points you don't really have a
29:48 - middle value and so in that case the
29:50 - meeting is gonna be the mean of the two
29:53 - values so it's going to be the two
29:55 - meeting values added together and then
29:57 - divided by two so the pros of using a
30:01 - median value is that the median can
30:03 - sometimes be more accurate than the mean
30:06 - and we'll see some examples of this
30:08 - the median also evenly splits your data
30:10 - so you're not really you know affected
30:13 - by the mean in the sense that if you
30:14 - have an outlier in the mean and it drags
30:17 - everything to the right it could be that
30:19 - your outlier drags things so far to the
30:22 - right that all of your data is to the
30:24 - left of the mean and only the outliers
30:25 - to the right so that would be an extreme
30:27 - case but that can happen whereas the
30:29 - median you know it's always located
30:31 - directly in the center of your data and
30:34 - the median also doesn't care about
30:35 - outliers so if you have huge outliers at
30:37 - the beginning and at the end it doesn't
30:40 - really care because outliers by
30:41 - definition aren't very common because
30:44 - they're outliers and so if you have them
30:46 - at the beginning or house them at the
30:47 - end they're gonna be very few in number
30:49 - which makes them outliers and therefore
30:52 - the median doesn't really care about
30:54 - outliers that much a con though is that
30:57 - the median doesn't really give you much
30:59 - information on the rest of the data
31:00 - sure you know you know what's at the
31:03 - center but you don't know how does
31:04 - everything
31:05 - we behave you only know where is the
31:08 - center of our data so let's see some
31:10 - examples well do a working example first
31:13 - where we see our data set here and we
31:15 - can count how many values we have is we
31:17 - go from left to right then we can say
31:18 - we've got 1 2 3 4 5 6 7 8 9 10 11 12 and
31:26 - 13 data points so we've got an odd
31:28 - number and so our median value our
31:30 - center value is going to be the seventh
31:33 - data point because it's 6 from the
31:36 - beginning and it's also 6 from the end
31:38 - so it's equally spaced both from the
31:40 - beginning and from the end and so that's
31:43 - why we see our median value here is 26
31:45 - it's located directly in the center now
31:49 - what is the median useful for well the
31:52 - median is often used if you look at you
31:54 - know household incomes for a country
31:56 - because if you were to use the moon then
31:58 - these billionaires they would just
32:00 - completely you know they would give you
32:03 - a false description of what really an
32:06 - average household income is because
32:09 - normally if you have you know like an
32:12 - average value and you can say oh the
32:13 - average household income from this
32:15 - family would be say $40,000 or something
32:18 - like that or that would be the median
32:20 - value but if you were to use the mean
32:22 - instead then all of the billionaires and
32:24 - all the millionaires in the country they
32:25 - would change that household income and
32:28 - then you would say oh you know the
32:29 - average household income per family
32:31 - would look like 60k and that's a bad
32:33 - representation because that doesn't
32:36 - actually give you a realistic look at
32:39 - what the average household family has
32:42 - and the average household family really
32:44 - does it's you know centered at like 40k
32:47 - and sure there are people below and
32:48 - there few people be high but that's
32:50 - what's in the middle whereas if you were
32:52 - to use the mean instead for your average
32:54 - you would kind of get this inflated
32:57 - household income which wouldn't be
32:58 - representative to the rest of your and
33:01 - the rest of the country another good
33:04 - example of the median would be the
33:06 - distance that people cover to get to
33:08 - work so if you look at this in terms of
33:10 - you know kilometers then you can say
33:12 - like oh you know some people they walk
33:14 - to work and it's like you know one
33:16 - kilometer at most so something like that
33:19 - and then you can expect people to travel
33:21 - most people travel around three
33:23 - kilometers to work and sure there are
33:25 - some you know that travel much further
33:26 - because they want to live outside of the
33:28 - city and there are some that travel very
33:31 - very short distances because they have a
33:32 - house right next to the office where
33:35 - their house is the office or something
33:36 - like that depending on where you're
33:37 - working but then you can look at you
33:40 - know like we're in the middle how do
33:43 - people travel to work what time or what
33:45 - distance do they need to cover and so
33:48 - that would be another good use of the
33:50 - median and a meeting another good
33:52 - meeting value is what do you usually
33:54 - spend when you buy a new item of
33:56 - clothing and so sure you know sometimes
33:58 - may go to that expensive clothing store
34:00 - and you could get a jacket that costs I
34:03 - don't know north of a couple hundred
34:04 - euros or dollars whatever system you
34:06 - want to use and sometimes you can go to
34:08 - a secondhand store and get it for very
34:10 - cheap but usually if you go into stores
34:13 - a jacket I don't know maybe cost you
34:15 - like a hundred dollars or something like
34:17 - that and so you know if you go out you
34:19 - can expect to pay about $100 no not
34:24 - really you know taking that much
34:26 - accountant - what story going in - so
34:28 - most of the stores that you're gonna
34:29 - visit are gonna have that price for the
34:32 - jacket so that would be another good use
34:34 - for the median all right let's look at
34:36 - the third type of average that we can do
34:38 - which is the mode now the mode looks at
34:41 - the most common value in your data and
34:44 - it's not really defined if there are
34:46 - several most common values but if
34:48 - there's only one most occurring value
34:50 - then that's what your mode would be and
34:53 - so we'll see an example of this in a
34:54 - second to the pros of using the mode is
34:57 - that it's not only applicable to
34:59 - numerical data so if you look at
35:01 - categories for example then you can say
35:03 - hey we've got five people from the US
35:05 - you know and two from Canada and one
35:08 - from France and you know that the mode
35:11 - is gonna be the US because there are
35:13 - five people from the US so mode is the
35:17 - great average that's not only applicable
35:18 - to numerical data in this sense but you
35:22 - can technically also apply it to
35:24 - categories or to ordinal numbers if you
35:27 - wanted so that you can say the most
35:28 - common country that we have were the the
35:31 - average kind of country that we would
35:32 - expect
35:33 - tear is the US and sure there are other
35:35 - countries but the average or the most
35:37 - common one is gonna be the u.s. in this
35:39 - case so yeah and then of course and the
35:43 - other Pro is that we allow to see what's
35:45 - most common what pops up the most so
35:48 - that's a great use of the mode if there
35:51 - are cases when you know recurring values
35:54 - happen a lot which is the case for
35:56 - discrete numbers for example so in
35:58 - discrete numbers values recur often and
36:01 - so it's good to use the mode icon of the
36:05 - mode it's gonna be that it doesn't
36:07 - really again give you good understanding
36:09 - the rest of the data similar to what we
36:11 - had for the median but also it's not
36:13 - really applicable if you just have a
36:15 - bunch of different types of data then
36:17 - there isn't really gonna be a mode if
36:19 - there's not enough of each data it's not
36:22 - really good to use the mode you don't
36:23 - want to you know have thousands of data
36:25 - points and the most reoccurring value it
36:28 - reoccurs like three times that's not
36:31 - good you want to use the mode for
36:33 - situations where data re occurs often so
36:36 - like we saw the country example but
36:38 - let's actually see a worked example but
36:41 - also some other examples for the mode so
36:43 - the worked example here would be again
36:45 - we take our data set and we can count
36:48 - how many times different numbers appear
36:50 - and so if we go through the numbers
36:52 - we'll see that twenty six occurs the
36:55 - most and so that's gonna be our mode
36:57 - here so we've got 22 and 25 that both
37:00 - occurred twice but 26 occurs three times
37:03 - and so 26 is gonna be our Millah it's
37:06 - gonna be our most occurring value now
37:08 - the mode is gonna be useful for things
37:11 - like the peak of a histogram so if you
37:14 - draw this histogram and if you don't
37:15 - know what a histogram is don't worry
37:16 - we'll cover that in a later lecture to
37:19 - let me go into data visualization but
37:21 - the peak of a histogram that's gonna
37:23 - show you the mode of the data the most
37:25 - occurring data a good another use of the
37:29 - mode will be if you look at employee
37:31 - income at a company because at a company
37:33 - you know you can again have the boss
37:34 - which takes off the mean and you can
37:37 - have you know higher level employees to
37:40 - which we kind of shift the median but if
37:42 - one third of your employees earn minimum
37:45 - wage
37:45 - that's gonna be the best average or say
37:49 - 40% of your employees earn minimum wage
37:51 - you're probably not your employees
37:52 - because that wouldn't be a very good
37:54 - system to have but a 40% of the
37:56 - employees at the company that you're
37:57 - looking at earning a minimum wage that's
38:00 - not a really good thing to have and if
38:03 - you look at the mode you'll easily see
38:05 - that the average in this case would be
38:07 - to earn minimum wage because that's what
38:09 - most people earn and sure you know the
38:12 - boss he or the CEO or something you know
38:15 - he may shift the mean up heavily and
38:17 - then the fact that you have higher ups
38:19 - if you look at the median value you may
38:21 - even well be too far you know too far to
38:26 - the right that you really don't consider
38:27 - these employees that all are in the same
38:29 - amount but you really want to get that
38:32 - description which is what you get here
38:34 - from the mode and then also the out kind
38:36 - of an of an election is where you use
38:37 - the mode for and sure sometimes you may
38:40 - only have two values sometimes you may
38:41 - have three but if you have different
38:44 - candidates and say you have five
38:46 - different candidates then the person
38:48 - with the most votes is gonna win the
38:50 - election because they have the most and
38:52 - so they are again you'll use the mode in
38:54 - this lecture we're gonna look at a
38:57 - spread of data and we're going to start
38:59 - off with looking at the terms range and
39:01 - domain then we're gonna move on to
39:03 - understanding what variance and standard
39:04 - deviation means and then finally we'll
39:07 - look at covariance as well as
39:08 - correlation all right so let's start off
39:11 - with a range and domain now let's start
39:15 - off with the range though so the range
39:16 - is basically the difference between the
39:18 - maximum and the minimum value in our
39:21 - data set so that's that's kind of simple
39:23 - to think about so let's just kind of go
39:26 - through this with a work example let's
39:28 - set up a company in the town and this is
39:30 - the only company in the town and the
39:32 - owner of the company earns a salary of
39:34 - 200k a year and then the employees you
39:38 - know they all have different salaries
39:39 - but the lowest employees or maybe the
39:41 - part-time workers they earn something
39:43 - like 50k a year so we've got data kind
39:47 - of ranging from 15k up to 200 K and so
39:51 - our range is the difference between the
39:53 - maximum and the minimum value in our DNA
39:54 - so we take 200 K and we subtract 15 K
39:58 - from it
39:59 - and we've got a range of 185 K in salary
40:03 - so that's how big our salary can change
40:07 - so it can if we start at 15 K it can go
40:10 - all the way up to 200 K so that's a
40:12 - hundred and eighty five K range of
40:14 - salary that people in this company can
40:16 - have all right and the domain is going
40:19 - to be the values that our data points
40:21 - can take on or the region that our data
40:24 - points lie in so if we look at this
40:27 - example again our domain is gonna start
40:30 - at 15 K and go up to 200 K so what the
40:34 - domain defines is it defines kind of
40:37 - starting and ending points or it defines
40:40 - a section in our data and so in this
40:44 - case the domain would define you know we
40:46 - would start at 15k and it would end at
40:48 - 200 K and what the domain tells us is
40:50 - that everything or all salaries within
40:54 - you know between 15k and 200 K that they
40:57 - are possible but within this domain or
41:00 - within this company it's not possible to
41:02 - have salaries outside of the glist
41:04 - domain so if our domain again is 15k to
41:06 - 200 K then we can't have a salary of 14
41:10 - K because that's outside of our domain
41:12 - and we also can't have a salary of 205 K
41:15 - because again that's outside of our
41:17 - domain so pretty much all salaries
41:20 - within 15 to 200 K are possible anything
41:24 - outside of the domain is not possible
41:26 - because that's no longer in our domain
41:28 - all right so let's move on and look at
41:31 - the variance and standard deviation and
41:34 - we'll talk about the variance first and
41:37 - what the variance tells us it pretty
41:39 - much tells us how much our data differs
41:41 - from the mean value and it looks at each
41:43 - mean value and it looks at how different
41:46 - each value is from the mean value and
41:49 - then it gives us the variance it does
41:51 - some calculation and we don't really
41:53 - need to know the formula it's more
41:54 - important right now just to understand
41:56 - the concept of variance and so what it
41:59 - variance really tells us is it tells us
42:00 - how much our data can fluctuate so if we
42:03 - have a high variance that means a lot of
42:06 - our values differ greatly from the mean
42:08 - value and that will make our very
42:10 - it's bigger if we have a low variance
42:12 - that means a lot of our values are very
42:15 - close to the mean value and so that will
42:17 - make our variance lower and now if we
42:20 - turn to the standard deviation the
42:22 - standard deviation is literally just the
42:24 - square root of the variance so if you
42:27 - understand one then you also understand
42:29 - the other and now we can combine this if
42:32 - we know the range of our data to kind of
42:35 - get a better feel for our data and so
42:37 - let's use an example where we have two
42:40 - different countries just countries a and
42:42 - B and they have the same mean height for
42:45 - women which in this case will say is 165
42:48 - centimeters or 5 feet 4 and we'll say
42:52 - that the range of heights for them could
42:55 - be identical so let's say they can range
42:57 - you know the range let's say it could be
42:59 - like 30 centimeters or something you can
43:01 - go anywhere from say 150 all the way up
43:05 - to 80 or we can even increase that and
43:07 - say like anywhere from as low as 140 up
43:09 - to like two meters or something like
43:11 - that but let's just keep the range for
43:13 - these the same and they both have the
43:15 - mean height now if country a has a
43:18 - standard deviation of five centimeters
43:20 - which is approximately two inches and
43:23 - country B has a standard deviation of 10
43:25 - centimeters which is approximately four
43:28 - interests then what you can expect
43:30 - knowing these values is that if you go
43:32 - into country a the people that you're
43:34 - gonna see are gonna be much more similar
43:38 - in height so our standard deviation is
43:40 - lower that means our values differ lower
43:43 - from the mean and so that means a lot of
43:45 - the women that you're gonna see are
43:47 - going to be very close to 165
43:50 - centimeters or 5 feet 4 plus minus 2
43:53 - inches so it's very what you can expect
43:55 - when you go to this company that when
43:56 - you go to this country is that everyone
43:59 - is gonna be or every a lot of the women
44:01 - are gonna be about that height whereas
44:03 - if you go to country B they have a much
44:06 - larger standard deviation and so you
44:09 - can't really expect everyone to be about
44:10 - 5'4 because it fluctuates a lot more and
44:14 - so if you go to that country you can
44:16 - expect to see a lot more women of
44:18 - different heights both taller and
44:20 - shorter than
44:22 - for all right and so that's how we can
44:25 - kind of use the variants in the standard
44:27 - deviation or the standard deviation to
44:30 - give us a little bit more perspective on
44:33 - our data and kind of allow us to infer
44:35 - some stuff about our data all right so
44:38 - let's talk about covariance and
44:40 - correlation and so covariance will or
44:44 - already has the name very incident but
44:47 - covariance is measured between two
44:49 - different variables and it pretty much
44:53 - measures if you have two variables so
44:56 - let's say we've got you know me drinking
44:59 - coffee in the morning and my general
45:02 - tiredness so if I use these two values
45:06 - and you know get data point so this is
45:08 - how much coffee I drank in the morning
45:10 - and this is how tired I feel this
45:12 - morning or something like that and so
45:13 - what the covariance does is it looks at
45:15 - how much one of these values differs or
45:19 - changes when I change the other one so
45:22 - what does that mean for example well if
45:24 - I drink more coffee what the covariance
45:26 - would look at is how much does my
45:28 - tiredness change so that's what you do
45:31 - with covariance you see you say I change
45:34 - one how much does that affect the other
45:36 - thing that I look at and our correlation
45:39 - is very similar to covariance so we kind
45:42 - of normalize the covariance by dividing
45:44 - by the standard deviation of each
45:46 - variable so what that means is we get
45:48 - the covariance for my drinking coffee
45:49 - versus feeling tired and then we would
45:52 - just divide by the standard deviation of
45:55 - me drinking coffee and a standard
45:56 - deviation of me feeling tired and so
45:59 - really what we're doing with the
46:01 - correlation is we're just kind of
46:02 - bringing it down to relative terms that
46:06 - would fit our data better so that's kind
46:09 - of the abstract idea the important thing
46:11 - to just keep in mind is that we're
46:12 - looking at one and we're seeing how much
46:14 - that changes and we're seeing how much
46:17 - that change affects the other one all
46:21 - right so there are different types of
46:22 - correlation values that we can have and
46:24 - they can range anywhere between negative
46:26 - 1 and 1 or so their domain is between
46:28 - negative 1 and 1 and a correlation of 1
46:31 - means a perfect positive correlation so
46:35 - that
46:35 - when one variable goes up the other goes
46:37 - up so for my coffee example that would
46:40 - be if I have coffee in the morning then
46:43 - I also feel more happy so the more
46:46 - coffee I have the more happy I feel and
46:49 - of course there's going to be a limit
46:50 - but let's say I only drink up to two
46:52 - cups of coffee or something like that
46:53 - and I can drink anything in between and
46:56 - the more I have the more happy I am
46:58 - about it so that would be a positive
47:00 - correlation the more I have of coffee
47:03 - the more I have of happiness and so they
47:06 - would kind of go up together
47:07 - and then when we get closer to zero the
47:12 - zero point is gonna mean no correlation
47:14 - to us so anything between zero and one
47:16 - is going to be a kind of slightly
47:18 - positive correlation it's not going to
47:19 - be a super strong and we'll actually see
47:21 - some examples on the next slide but yeah
47:25 - so anything between zero and one is
47:26 - going to be a kind of slight positive
47:27 - correlation not super strong and the
47:30 - closer you get to zero the more it means
47:32 - no correlation so an example for the
47:35 - zero case would be that it doesn't
47:37 - matter how much coffee I drink in the
47:38 - morning it's not gonna affect the
47:40 - whether they're unrelated one does not
47:42 - affect the other so I could drink you
47:45 - know one cup of coffee during a sunny
47:47 - day and one cup of coffee during the
47:49 - rainy day and it's not gonna change the
47:51 - weather it's not gonna affect the
47:52 - weather so they're pretty much
47:54 - uncorrelated and then we can also go
47:57 - down into the negative range and so the
48:00 - closer we get to negative one or if we
48:02 - reach exactly negative one that
48:03 - correlation of negative one means a
48:05 - perfectly negative correlation and so
48:08 - here we can take our example of coffee
48:10 - versus tiredness and so the more coffee
48:13 - I have the less tired I'm gonna be so
48:16 - coffee goes up and tiredness goes down
48:20 - so that's how we can kind of understand
48:22 - this correlation and it comes from the
48:25 - covariance so it was important to
48:27 - understand the covariance we usually use
48:29 - the correlation because the correlation
48:31 - because we divided by the standard
48:33 - deviation of each is much better fit to
48:36 - our data now there is one thing that's
48:38 - very important to remember and that's
48:40 - that correlation does not imply
48:42 - causation so just because two things are
48:45 - correlated that does not mean that
48:48 - one causes the other so a good example
48:50 - of this would be if I live in a climate
48:53 - where it's usually cloudy in the morning
48:55 - and I know it to be sunny in the
48:57 - afternoon but every morning when it's
48:59 - cloudy I drink coffee and then it
49:02 - becomes sunny in the afternoon that's
49:04 - not even though they may be correlated
49:06 - me drinking coffee and it becoming sunny
49:08 - it me drinking coffee does not cause it
49:11 - to be sunny that's just you know by
49:13 - chance it's just because it happens
49:15 - every day and by chance there's this
49:18 - kind of correlation that appears but
49:20 - that does not mean that me drinking
49:21 - coffee you know
49:23 - results in the weather getting better a
49:26 - causation would be me drinking coffee
49:29 - and me feeling less tired or me drinking
49:32 - coffee and me feeling happy about it
49:35 - because I like the taste those would be
49:37 - causations so that's an important thing
49:39 - to keep in mind just because things are
49:41 - correlated does not mean that one causes
49:43 - the other all right so let's see these
49:46 - things on a graph and so here we have
49:48 - the examples again that we've talked
49:49 - about but we can kind of see how the
49:51 - data would look like for different types
49:53 - of correlations and so we can see a
49:56 - perfectly the perfect correlation of one
49:59 - so one goes up the other goes up we can
50:02 - see on the left side and we pretty much
50:04 - get this really nice straight line so
50:06 - one value goes up the other value goes
50:09 - up with it and then the closer we reach
50:11 - zero the less related or the less
50:15 - correlation there is between them and
50:17 - then the more kind of variance we have
50:19 - in data so we'll notice for the case of
50:23 - perfect correlation which is the one or
50:25 - the case of perfect anti-correlation
50:27 - which is the minus one which again we
50:29 - had the example of more coffee less
50:31 - tired and in those cases you know we
50:33 - have a very nice thin line and our data
50:37 - doesn't jump around a lot but the closer
50:39 - we get to zero the less we can see you
50:42 - know one causing the other and the more
50:44 - we can see our data kind of spread out
50:46 - and so that's what correlation would
50:50 - look like in terms of graphics in this
50:53 - tutorial we're gonna go through
50:54 - quantiles and percentiles all right so
50:58 - let's get started
50:58 - so what our quantiles
51:01 - quantiles allow us to split our data
51:04 - into certain regions that if we're
51:06 - dealing with probability they all have
51:08 - the same probability of occurring or if
51:10 - we're just dealing with you know sizes
51:12 - of data we want to split our data into
51:14 - equal regions so that's what we can do
51:17 - with quantiles is just splitting
51:19 - everything up so that every time we
51:21 - split it you know we have equal amounts
51:24 - of data all right and so an example of a
51:28 - quantile would be something known as a
51:31 - quartile and so that's when we split our
51:34 - data into four equal regions hence the
51:37 - name quartile so a quantile is the
51:39 - general name for doing this
51:41 - splitting procedure and then if we say
51:43 - quartile that means we're doing
51:45 - quantiles but for four equal regions and
51:48 - so this is something that you'd probably
51:50 - often see unlike university admissions
51:51 - pages or something like that and they
51:53 - say the top 25 percent of our applicants
51:56 - have at least a test score of like 90
51:59 - percent or something you know and then
52:00 - they would say the bottom 25 percent for
52:03 - applicants or our admission or admitted
52:06 - students or something like that have a
52:07 - test score that is I don't know 70
52:10 - percent or 75 percent or something like
52:11 - that and then the median test score is
52:15 - 85 percent so that's how you would go
52:18 - about quartiles is that you would have
52:20 - you know the lower 25% the middle 25 to
52:25 - 50 then you've got the 50 to 75 and then
52:28 - you've got the top 25 percent so the 75%
52:31 - to 100 and so you've got these four
52:33 - equal regions which also include your
52:35 - minimum value at the very bottom your
52:37 - maximum at the very top and in the
52:39 - middle you've got your median values so
52:42 - that's the value directly in the middle
52:44 - it's because you're splitting it up into
52:46 - four equal regions and so the value that
52:49 - separates the second quantile which
52:52 - would be the 25 to 50 from the third
52:55 - quartile which would be from 50 to 75
52:58 - that value there would be the median
53:00 - value all right and so if we go into
53:03 - percentiles so percentiles that may have
53:07 - been a name that you you've probably
53:08 - heard before percentiles again an
53:10 - example of a quantile but instead of
53:14 - saying you know like a quartile we do it
53:16 - for for a percentile
53:18 - I mean splitting it into 100 equal
53:20 - segments
53:21 - hence the percentiles of the perks name
53:25 - at the beginning though that's that's
53:27 - kind of where or the percent you may
53:29 - have noticed percent means out of 100 or
53:32 - so that's if you are familiar with
53:34 - percent and that's also the same kind of
53:37 - reasoning where this comes from and so
53:38 - we've got percentiles which means
53:41 - splitting into you 100 equal segments
53:44 - and so on an example of this is often
53:48 - used in test scores so if you've ever
53:52 - taken something like the SATs or
53:54 - something like that then you get a test
53:56 - score but you also get a percentile and
53:59 - the reason I've done that is it's to
54:01 - judge not you versus the test but you
54:04 - versus everyone else and so if it's a
54:06 - difficult test than something like
54:09 - getting a test score of 60% but you're
54:13 - in the 95th percentile means your score
54:16 - is actually a lot better and so what you
54:18 - can say with percentiles for example is
54:20 - that every percentile that you're in
54:22 - means you're better than you know that's
54:25 - many other people so for example if you
54:28 - reach the 99th percentile that means
54:30 - you're better than 99% of the people
54:32 - that took the test the 95th percentile
54:34 - would be 90 you're better than 95% of
54:37 - the people that take the test or
54:38 - something like that and so that's why
54:40 - percentiles are often used for tests and
54:43 - they're often used for normalization
54:44 - because they allow you to take into
54:47 - consideration you know these factors of
54:48 - like is it a difficult test is an easier
54:51 - test maybe more people are scoring
54:52 - higher so they don't really judge you
54:55 - directly versus the test but they
54:58 - normalize you against everyone else that
55:01 - took the test so you take the test you
55:03 - get a score and then um the percentile
55:07 - checks where that score lies relative to
55:11 - everyone else and so these percentiles
55:13 - they allow you to give a good
55:15 - normalization and they allow you to do
55:16 - great comparisons because they allow you
55:19 - to kind of eliminate some of these
55:21 - factors of test difficulty and of course
55:24 - you know there can always be luck
55:25 - involved and stuff and that may not get
55:27 - filtered out on and
55:28 - visual basis but if you do this for a
55:30 - lot of students and that's also why it's
55:32 - done in these kind of big standardized
55:33 - tests is that you get a percentile along
55:36 - with your score so that you understand
55:39 - if you know maybe if your score is lower
55:41 - but the test was really hard you can
55:44 - still see you know I I did really well
55:45 - because people found this test really
55:47 - hard and it was even harder for them
55:50 - than it was for me in this tutorial
55:52 - we're going to talk about the importance
55:54 - of data visualization all right so what
55:58 - we're going to talk about is first we're
56:00 - gonna look at the role that the computer
56:02 - plays kind of for us and what role the
56:05 - computer is actually made for then we're
56:07 - gonna look at what role the human should
56:10 - play in terms of data science then we're
56:12 - going to look at presenting data and
56:15 - finally we'll talk about interpreting
56:17 - data alright so let's get started and
56:20 - talk about the role that the computer
56:22 - plays no computer is much much faster at
56:26 - calculating than human because that's
56:27 - what it's made for it's made for
56:30 - crunching numbers it's made for doing
56:32 - fast calculations you know if you think
56:35 - about how faster computers are there in
56:36 - the gigahertz range so Giga means
56:39 - billions so they just do billions of
56:42 - things every second and so they're
56:44 - really good for doing repetitive things
56:46 - because they can do them so fast and
56:49 - then we can give them these logical
56:51 - tasks in terms of programming and we
56:54 - give them a structure and they just do
56:57 - it and they can do it over and over and
56:58 - over again they're not gonna mess up I
57:00 - can just repeat the same thing they
57:02 - won't get tired of it and they're really
57:05 - good and they're really fast at doing
57:07 - these things so that's the role that the
57:09 - computer should play for you it should
57:11 - be kind of a means to get these hard
57:14 - number crunching and all of these things
57:16 - done so there's there's really no need
57:18 - for you to kind of work out all this
57:20 - complicated math because your computer
57:21 - can do it much better and much faster
57:24 - than you and it's also less prone to
57:27 - error if you code it correctly so that's
57:30 - kind of the only part where you come in
57:31 - and it's only gonna mess up if you mess
57:33 - up but generally our computer does
57:35 - exactly what we tell it to do and it's
57:37 - really good and it's
57:38 - really fast at it now what role should a
57:41 - human play in terms of data science well
57:44 - humans have naturally developed to
57:47 - identify patterns and we've done this
57:49 - first for survival so that if we're
57:52 - walking around somewhere and we see a I
57:55 - don't know a big predator or hiding that
57:58 - we can identify that pattern of the
58:01 - predator and we can kind of pick it out
58:03 - even though it's trying to camouflage
58:04 - itself so humans by nature have become
58:08 - very very good at identifying patterns
58:10 - and you can also see this if you look at
58:13 - the clouds and you see things where you
58:14 - see animal shapes and the clouds or
58:16 - other things so those patterns aren't
58:18 - actually there but humans have become so
58:20 - good at identifying patterns we can see
58:23 - things in many many places and so that's
58:26 - what humans are really really good at
58:28 - we're able to look at things and we're
58:30 - able to pick out patterns now another
58:33 - thing that's really good for humans is
58:35 - we are very creative and through their
58:38 - creativity we can also use memory and
58:41 - bring it outside knowledge and we can
58:43 - also use a general understanding so
58:45 - these are all things that computers
58:47 - can't do so computers are kind of a
58:50 - means of getting stuff to us but once
58:52 - it's actually there it's our job to use
58:55 - our pattern recognition abilities and of
58:58 - course you can train machine learning
59:00 - algorithms for specific patterns later
59:01 - on or specific cases and make them
59:04 - really good at that but generally if you
59:05 - don't know exactly what's gonna come
59:07 - then our or your first step as a data
59:10 - scientist would be to try to identify
59:12 - these patterns use your creativity use
59:15 - your memory you know bring in all of
59:16 - these different things use all of these
59:18 - different things that make you human and
59:19 - use all of that on the data all of these
59:22 - things that a computer just doesn't have
59:24 - any access to okay
59:27 - so usually you know you're considering
59:29 - all this the best way to do all this
59:32 - would be in terms of data visualization
59:33 - so you can't just show spreadsheets with
59:38 - a bunch of numbers that won't really
59:39 - help you because looking at numbers it's
59:41 - really hard to pick out patterns the
59:44 - best way to do it would just be to plot
59:46 - values and then if we have these visuals
59:48 - in front of us then you know we can
59:50 - really identify
59:51 - we can see things go up and down and you
59:54 - know we can see them fluctuating and we
59:55 - can see them make very thin lines we can
59:58 - just look at a graph and we can just see
60:00 - things and of course you know we need a
60:02 - little bit of practice to understand
60:04 - what that graph is trying to tell us
60:06 - but once we understand the graph and in
60:09 - general then you know we can look at new
60:11 - grass and we can just see things so we
60:13 - can start to see patterns and they may
60:16 - not always be true but that doesn't mean
60:18 - you know and we can't pick them out and
60:20 - then that's later on you would also do
60:22 - some testing trying to see if those
60:23 - patterns are true if they make sense but
60:25 - generally data visualization is very
60:27 - good for this because it allows you to
60:29 - invoke all of your human characteristics
60:33 - the things that are really good that you
60:35 - know make us human the things that we
60:38 - talked about and the last slide all the
60:40 - things like the computer can't do and
60:43 - sometimes you know you if you deal just
60:46 - with just these numbers it's data
60:49 - visualization is for you and one sense
60:51 - so that you can see these things and try
60:53 - to pick them out I use them later on but
60:55 - also if you're trying to show these
60:57 - things to other people so maybe you have
61:00 - to do a presentation in a kind of
61:01 - summary then you want to make sure that
61:03 - your data visualizations are good
61:05 - because the people that are going to be
61:07 - looking at it are much much less trained
61:09 - looking at data and analyzing data than
61:12 - you are and so if you try to convey them
61:14 - a message and just show them a big
61:15 - spreadsheet with numbers and just point
61:17 - out like here look look look these
61:19 - numbers you know they pop up and they're
61:21 - gonna be like what are you talking about
61:22 - so that's why it's really important to
61:25 - have really good data visualization
61:26 - skills one of them is to enable you to
61:29 - do your job but the other part of it is
61:31 - to show it to other people and to kind
61:34 - of help you convey information to them
61:37 - you know and of course we talked about
61:40 - statistical values and statistical
61:41 - values are very important and they can
61:44 - give us a kind of good idea about the
61:47 - data and what's going on inside of the
61:48 - data but visualizing data is just taking
61:51 - it to the next level and statistical
61:52 - values aren't enough there they can give
61:55 - us you know they can help us they can
61:57 - support us they can give us ideas but if
61:59 - we really want to understand what's
62:01 - going on sometimes we just have to take
62:02 - a look at what's going on
62:05 - and of course they are it's also
62:07 - important to make sure you choose the
62:08 - right visualizations and everything
62:10 - because other times you know may just
62:12 - look extremely weird but just this skill
62:15 - of being able to present data both for
62:17 - yourself as well as for other people is
62:19 - very very important for a data
62:22 - scientists and then we go over to
62:25 - interpreting data and we've kind of
62:27 - touched on this in the last section
62:28 - already but really with data
62:29 - visualization it just allows you to see
62:32 - this data and it allows you to apply
62:35 - some reasoning to the system and so you
62:36 - can if you look at data either you see
62:39 - something which is great you know that
62:41 - means you can try to test something see
62:44 - if it's actually there or you don't see
62:46 - anything and that also tells you
62:47 - something that you aren't really able to
62:50 - pick out a pattern so that there isn't
62:51 - there isn't anything obvious that's
62:53 - going on there may be something
62:54 - underlying that's more complicated but
62:57 - obvious to the user you know it's not
62:59 - there and so all of these things allow
63:02 - you to you know kind of easily or much
63:05 - more easily analyze your data and kind
63:07 - of prepare what are you gonna do after
63:08 - that so this data visualization it
63:11 - really gives you a deep deep
63:13 - understanding of what's going on with
63:15 - your data and then when we interpret
63:17 - this data and we look at these
63:19 - visualizations you know maybe you see
63:21 - dips and you know maybe you see some
63:24 - hills somewhere we can try to understand
63:27 - all of this by bringing in our outside
63:29 - knowledge so again what the human is
63:30 - really good at we can you know bring in
63:33 - the context of things you know maybe
63:35 - people are going out to lunch here and
63:37 - so that's why activity decreases or
63:39 - maybe everyone is coming to work in the
63:41 - morning and so that's why activity
63:42 - increases compared to you know 6 a.m. so
63:45 - all of these things we can bring in all
63:48 - of this context we can bring in all of
63:49 - this understanding to try to interpret
63:52 - the data try to better understand what's
63:55 - going on and then of course we're gonna
63:58 - see hopefully some trends or patterns of
64:02 - course like I said these may not always
64:04 - be there so we're actually so good at
64:06 - pattern recognition that we can see
64:09 - sometimes patterns that aren't really
64:10 - there and so a good example again of
64:12 - this would be just looking at the clouds
64:14 - in the sky and you can see animal
64:16 - patterns maybe but that's
64:18 - really not there that's just our minds
64:20 - you know identifying all of these
64:21 - patterns and so yeah that's that's
64:25 - pretty much why data visualization is so
64:27 - important to a data scientist it's
64:30 - because this whole you human aspect is
64:32 - it's just key in data science it's key
64:36 - and data analytics to be able to
64:38 - understand what's in front of you to be
64:40 - able to understand these this outside
64:42 - knowledge to be able to contextualize
64:43 - this creativity that's really key to a
64:47 - good data scientist and a computer can
64:50 - help you with all of this the computer
64:51 - can help you you know do the number
64:53 - crunching a computer can help you set up
64:55 - the visualizations and it can plot
64:57 - whatever you want for it but ultimately
64:58 - it's up to you to choose the right
65:00 - visualizations to do to look at the data
65:02 - to be able to communicate the
65:05 - visualization as well all of those
65:06 - things are up to you and so that's why
65:09 - the human is so so important in data
65:11 - science in this tutorial we're going to
65:14 - look at one variable graph so we're
65:16 - actually going to see some of the types
65:18 - of graphs that we can do you know that
65:20 - we talked about in our last tutorial
65:22 - where we just looked at the importance
65:24 - of data visualization so now we're gonna
65:25 - go into data visualization and look at
65:28 - the types of grass that you may want to
65:31 - use or that you may want to choose from
65:33 - all right and so the graphs that we're
65:36 - gonna look out in terms of one variable
65:37 - graphs are gonna be histograms bar plots
65:40 - and pie charts so let's get started with
65:43 - histograms now we can see an example of
65:47 - a histogram on the right but what's
65:49 - really cool about histograms is that it
65:51 - shows us the distribution of the data
65:53 - and it shows us the distribution across
65:55 - all the values in our data and so it
65:58 - shows us what happens the least and it
65:59 - also shows us what happens the most and
66:03 - histograms it they let us see where our
66:05 - data is concentrated and they also let
66:08 - us see how its distributed and so the
66:10 - through this it kind of shows a general
66:11 - behavior and so really what histogram is
66:15 - is it looks at each value and it just
66:17 - looks at how often the value has
66:19 - occurred and so what we see here for
66:21 - example is that around 0 you know we
66:24 - have the most occurrence of whatever
66:25 - value we're looking at and as we move to
66:28 - the left and as we move to the right
66:29 - these values start to
66:31 - drop off so they start to become less
66:33 - frequent and so that's what histogram
66:36 - shows us they the istagram shows us a
66:38 - kind of frequency how often these things
66:40 - occur and so there are different types
66:43 - of histograms that you can encounter or
66:45 - I mean generally a histogram is just
66:48 - this plotting of frequency versus your
66:51 - value and so there are different ways
66:53 - that this histogram can look like one of
66:55 - them is the one that we've just seen
66:57 - which is a normal distribution or it's
66:59 - called Gaussian like histogram because
67:01 - it follows this Gaussian distribution or
67:03 - this normal distribution that you know
67:05 - but we can also have like an
67:07 - exponentially decaying value so we start
67:11 - off very high and the further we get
67:13 - away from that initial value the quicker
67:16 - it's then it gonna decrease and you can
67:17 - actually compare that to the Gaussian
67:19 - like or to the normal distribution so
67:21 - the normal distribution looks more of
67:23 - like a bell it kind of goes up and then
67:25 - curves down slowly whereas the
67:27 - exponential it cuts off very fast and
67:29 - then kind of slows down later on so they
67:34 - do have different behaviors and then of
67:36 - course you know we can also get not just
67:39 - one peak like we see in this first case
67:42 - and the Gaussian like distribution but
67:44 - we can also get things like two peaks or
67:47 - we can even get three peaks or more we
67:48 - can have very large extended peaks and
67:51 - so our histograms there are means of
67:55 - showing us how this data is distributed
67:56 - there are means of showing us you know
67:58 - what things occur most frequently where
68:01 - is our data concentrated but that don't
68:04 - that doesn't mean that they're gonna
68:05 - have to have a specific value and so
68:08 - they're or your specific shape so there
68:10 - are many different shapes that our
68:11 - histograms can take on and depending on
68:13 - what shape that you get that also tells
68:15 - us something very different about our
68:17 - data all right so the next one variable
68:22 - plot that we'll look at is going to be
68:23 - bar plots and so what bar plots do is
68:27 - they may look a little bit similar to
68:29 - histograms at first but they are very
68:31 - different in some sense because bar
68:33 - plots allow us to compare across
68:35 - different groups and so that's what we
68:37 - see on the x-axis down there is we look
68:41 - at different groups and so we use the
68:43 - same
68:43 - em but we can compare that variable over
68:47 - different groups and so if we look at
68:49 - that in example so what we see on the
68:51 - right here is we look at different
68:53 - countries and what we show is we show
68:55 - the average income tax and so we see
68:58 - that country B for example has the
69:00 - highest average income tax whereas
69:02 - country D has the lowest income tax so
69:07 - through this you know we're still only
69:08 - looking at the income tax variable but
69:11 - we are able to compare us over different
69:13 - groups over different categories if you
69:15 - will so other examples would be if you
69:18 - look at control groups and test groups
69:20 - or if you're doing some like medical
69:22 - study or maybe some psychology study or
69:25 - something like that you always want to
69:26 - have your control group and then you can
69:28 - have different types of test groups and
69:30 - then you can plot each of these groups
69:32 - as a bar plot and you can look at the
69:34 - same variable but you can look how that
69:36 - changes over the different groups
69:38 - another example would be something like
69:41 - comparing male versus female heights so
69:43 - you've got one group that's male the
69:45 - other group that's female and you can
69:46 - just plot their average height and then
69:49 - the tax the income tax of different
69:51 - countries which is what we seen on the
69:53 - right over here all right and so the
69:56 - last one variable graph that we're gonna
69:57 - look at is gonna be pie charts and what
70:00 - pie charts are allowed to do is they
70:02 - allow us to section up our data on the
70:04 - and then we can kind of split it into
70:06 - percentiles and because of this we can
70:08 - see what our data is made up of so the
70:12 - whole pie corresponds to a hundred
70:14 - percent and then we kind of cut it down
70:16 - at different slices and through that
70:19 - slicing and then hopefully also color
70:21 - coding like we've done here and maybe
70:22 - even labeling or most definitely
70:24 - labeling so that you know what slice
70:26 - corresponds to what value we're able to
70:29 - see what categories you know or what
70:32 - what categories our data is made up of
70:34 - and so we can see what is most prominent
70:37 - but we can also see what is at least
70:39 - prominent in all of these things and
70:41 - then again here we can see also
70:43 - distributions not as well as in the
70:45 - histogram but we can still see
70:47 - distributions in terms of dominance in
70:49 - terms of how many groups there are is
70:51 - the data spread evenly is it you know
70:54 - heavily concentrated in one part of the
70:58 - pie all of these things allow you know
71:01 - is that's what we're able to do with pie
71:02 - charts we get this nice kind of group
71:04 - overview of one variable so examples of
71:09 - this would be you can look at NASA D
71:12 - distribution in a university and so you
71:14 - can have a pie chart and just each slice
71:16 - of pie which is to represent a different
71:17 - ethnicity and depending on you know how
71:21 - much of our percentage they make up the
71:22 - total University profile that's how big
71:25 - the slice of pie would be and so you can
71:27 - see dominance of some ethnicities as
71:30 - well as you know minorities but you can
71:33 - also see just by how many slices that
71:36 - are you can see how many different
71:37 - ethnicity groups there are and another
71:39 - example would be you can split up star
71:42 - reviews for a product so rather than you
71:44 - know looking at the average mm star
71:47 - review you can also just use a pie chart
71:49 - and you can see how many of my reviews
71:51 - are 5 stars how many of them were 4
71:52 - stars 3 2 and 1
71:55 - and so there you can again also get this
71:57 - nice different overview of how the
72:00 - review system would work now we're going
72:03 - to talk about two variable graphs so the
72:07 - graphs that we're gonna look at are
72:08 - gonna be scatter plots line graphs 2d
72:12 - histograms or two-dimensional instagrams
72:13 - and box and whisker plots alright so
72:18 - let's start off with scatter plots now
72:20 - for a scatter plot what we're doing is
72:23 - we're really scattering all of our data
72:25 - points onto a graph and so pretty much
72:29 - every data point that we have we kind of
72:30 - put a little dot onto it on the graph
72:33 - and scatter plots are great because they
72:36 - allow us to see spread of data between
72:38 - two variables so we're always plotting
72:40 - one variable on the x-axis and another
72:42 - variable on the y-axis and it just
72:45 - pretty much allows us to see how the
72:47 - data is distributed for these two
72:49 - variables and then through that we can
72:51 - also see more dense areas we can also
72:53 - see some sparse areas and we can also
72:56 - look at correlations so maybe you
72:59 - remember in the lecture we talked about
73:01 - correlations we were able to see through
73:04 - scatter plots where those correlations
73:05 - where or
73:07 - weren't any correlation so all of these
73:09 - things that's what scatter plots are
73:11 - really really nice for in scatter plots
73:14 - of course we can also use them to have
73:16 - like we see here little clusters so not
73:19 - everything needs to be connected by a
73:21 - line or a curve maybe something is more
73:23 - like a circle and so that's what scatter
73:26 - plots can show us too they can kind of
73:27 - show us these groupings and we see one
73:30 - cluster here but maybe you know you have
73:32 - bigger plots and then there would be
73:33 - smaller you know like ten little
73:36 - different groupings for different things
73:38 - so it's got our plots are really great
73:39 - for that because they just show us where
73:42 - the data points are located for these
73:44 - two variables and then we can you
73:46 - ourself see you know like how how do
73:49 - these look like do does one variable
73:50 - affect the other is there may be certain
73:52 - groupings that we can see where our
73:54 - dense areas where it's sparse where are
73:57 - things concentrated you know is
73:59 - everything spread up all over the place
74:01 - is it very very narrow and only in
74:03 - specific region scatter plots allow us
74:05 - to see all of these things very easily
74:07 - and so some examples where we could use
74:10 - scatter plots would be if we see if we
74:13 - look at the graph on the right we can
74:15 - look at something like a car price
74:16 - versus the number of cars sold so each
74:20 - of these data points pretty much
74:22 - represents a car that's been sold and
74:24 - then the x-axis tells us the price that
74:27 - the car has been sold at and the y-axis
74:29 - tells us the number of cars that that
74:34 - have been sold at this price and so what
74:36 - we see here for example very easily is
74:38 - that the more the car is priced the less
74:40 - it gets sold and then maybe you can
74:42 - think of that in terms of well the more
74:44 - its price maybe people don't want to buy
74:46 - such an expensive car maybe they found a
74:48 - cheaper version of it so maybe it's just
74:51 - a branding thing which is why it's more
74:53 - expensive
74:54 - maybe there's something just as good
74:55 - quality that's cheaper maybe people just
74:58 - don't have enough money so that's
75:00 - probably a big factor to that people
75:01 - just don't have enough money to buy
75:02 - these expensive cars and so that's why
75:05 - they drop off and so it may look a
75:08 - little bit different in terms of profits
75:09 - but the higher the car is priced the
75:12 - less we see it being sold so that's one
75:15 - example of a scatterplot then something
75:19 - else that we can look at
75:20 - is maybe the income versus years of
75:23 - education so only we would look at on
75:26 - the x-axis how many years someone has
75:29 - been educated and then we would look at
75:32 - that current income and that would just
75:33 - be a point on the on the graph and we
75:36 - can do that for many many different
75:37 - people and then we can see how different
75:40 - education for different people how that
75:41 - affects their current income so that's
75:43 - another thing where we can do a scatter
75:46 - plot for we can also go back to one of
75:49 - the earlier examples that we used very
75:51 - early on where we talked about people
75:53 - traveling to work and we can just plot
75:55 - the distance traveled versus the time it
75:58 - takes and travel to work and then we can
76:00 - see you know maybe some people travel
76:03 - faster it could be that some people
76:04 - travel the same distance but one takes
76:06 - longer than the other because one goes
76:08 - by car the other one goes by bike the
76:11 - other one takes public transport all of
76:13 - these things so all of that we can see
76:15 - in these scatter plots and just kind of
76:17 - take into account these different
76:18 - situations and see how that all looks
76:20 - for the more for the general population
76:23 - of our data or just generally for our
76:25 - data so scatter plots are really really
76:28 - great as a kind of first go-to just also
76:31 - identifying trends identifying regions
76:34 - and just giving a good overview of your
76:36 - data now the next thing that we'll look
76:39 - at is going to be line plots and line
76:41 - plots in some sense are kind of similar
76:44 - to scatter plots so we have the same
76:46 - bases of the X and the y axis but the
76:49 - points are connected and now it's very
76:51 - important to know when to choose line
76:53 - plots and want to choose scatter plots
76:55 - so line plots can carry a lot of
76:57 - advantages with them because this
76:59 - connectedness it makes it very easy for
77:01 - us to see trends because we can see
77:03 - where are these lines go not just trying
77:05 - to connect the points in our head you
77:07 - know like kind of connect the dots but
77:09 - that's exactly what I'm a line plot does
77:11 - is it connects the dots for us and so we
77:13 - can see these lines it's great if we
77:15 - want to see an evolution of something so
77:18 - maybe we want to see an evolution over
77:19 - time maybe you want to see an evolution
77:21 - over space and evolution with people
77:24 - something like that just if our data
77:25 - points are connected it's great to use a
77:28 - line plot so if we know that whatever
77:31 - happened before is connected to what
77:33 - happens and
77:34 - it's great to use line plots because
77:36 - line plots show us how things evolve
77:39 - because they're all connected as a line
77:40 - but if we're to do scatter plots and we
77:44 - just kind of plot points randomly and
77:46 - just because if we go back to or our
77:48 - kind of car sold car price example just
77:51 - because someone bought an expensive car
77:53 - or if we look at the expensive car and
77:54 - it's been bought say like five times and
77:57 - we look at a cheaper car it's and bought
77:58 - a hundred times there isn't really a
78:01 - logical connection to make between the
78:03 - two and so if we were to use line plots
78:05 - where we should use scatter plots really
78:07 - what we'd see is just a bunch of lines
78:08 - all over the place and so that's why
78:11 - it's important to kind of know when to
78:14 - use lime stalks and want to use scatter
78:15 - plots because it can be very very
78:17 - helpful if you use a scatter plot
78:19 - instead of a line plot it's gonna be a
78:21 - bit more confusing because you have to
78:22 - try to connect the dots yourself in your
78:24 - head but if you use a line plot instead
78:26 - of a scatter plot it's gonna look really
78:28 - weird because there's just lines all
78:30 - over the place and you can't really see
78:31 - anything so an example where we could
78:35 - use line plots is you have the typical
78:37 - distance versus time so you can look at
78:41 - you know how far someone or what time it
78:44 - is and then you know how far someone has
78:46 - traveled just a general curve of
78:47 - distance versus time that's very very
78:49 - common and you can look at the profit of
78:52 - a company versus the number of employees
78:54 - so the more employees they imply
78:56 - employee how does that change their
78:58 - profits so of course they have to pay
79:00 - the employees more but maybe the
79:02 - employees can also do more work and
79:04 - hopefully you know that kind of cancels
79:06 - out what you pay them and then increase
79:09 - this company profits and then what we
79:11 - can see on the right here is we can look
79:13 - at your creativity and how that changes
79:15 - with stress so you can see that the more
79:18 - stressed out you are the less creative
79:20 - you are and here it's also good to use a
79:22 - line plot because you kind of gradually
79:25 - advanced and stress and so each point
79:28 - and stress is kind of related and the
79:30 - higher you go up and stress the lower
79:32 - you go down in creativity and so there's
79:34 - this kind of relation where we can see
79:36 - this evolution so the more you get
79:38 - stressed out the less creative you
79:40 - become and so line plots are really nice
79:42 - here because there's not this chaotic
79:44 - movement everywhere but it's very nice
79:46 - and it's very easy
79:47 - to see this line it's very easy to
79:49 - follow okay so the next graph that we
79:53 - can talk about is 2-dimensional
79:55 - histograms now we've seen
79:57 - one-dimensional histograms in the last
79:59 - tutorial where we looked at the spread
80:01 - of data and we looked at the peaks and
80:04 - how you know things were distributed to
80:06 - the right and to the left but we can
80:07 - also do a 2-dimensional histogram and so
80:10 - what a 2-dimensional Instagram is it's a
80:12 - one-dimensional histogram but it's a
80:15 - pretty much a histogram for every single
80:18 - point of the other variable that we're
80:20 - looking at so really what these things
80:24 - allow us to see is they allow us to see
80:25 - how the different distributions of the
80:28 - two variable is relative to to another
80:30 - so we can see here for example in the
80:33 - red region that for those specific
80:35 - values them they happen a lot so that
80:38 - combination of values happens a lot and
80:41 - so we're able to kind of pinpoint these
80:43 - frequency occurrences again and we're
80:46 - also able to look at drop-offs but we're
80:49 - able to pinpoint that to two specific
80:51 - values now rather than just 1 which is
80:54 - what we did to the 2d histogram and
80:56 - these things are much harder to see in
80:58 - scatter plots because in scatter plots
81:00 - if we have a value occurring a hundred
81:02 - times it would just be the same dot and
81:05 - the dot wouldn't get bigger now of
81:06 - course you can make the dot bigger
81:07 - yourself if you wanted to or you could
81:10 - change the color or something like that
81:11 - but really if you do a scatter plot and
81:13 - the same thing happens a hundred times
81:15 - it's just gonna look like one dot
81:17 - whereas for two-dimensional histograms
81:20 - we can see that it's not just you know
81:24 - it's not just happening once but we can
81:26 - actually see the frequency of those
81:28 - variables or those those two variables
81:30 - together so an example of a
81:33 - two-dimensional histogram would be if we
81:35 - look at ticket prices versus tickets
81:37 - sold and so if you look at the lower
81:40 - left corner and we can kind of see this
81:41 - red peak so that's cheaper ticket prices
81:44 - but the tickets are also sold often so
81:47 - we know that tickets at that price are
81:49 - sold quite often and these could be you
81:53 - know like new rising brand bands these
81:55 - could be like you know you kind of
81:57 - standard bands that maybe you want to
81:58 - take someone on a day-to but you don't
82:00 - want to spend
82:01 - much money on a ticket but still a
82:02 - concert is a nice idea and so that's a
82:05 - good ticket price that sells a lot of
82:08 - tickets because it gives you the
82:09 - pleasure of the event without making it
82:12 - too expensive and then if you move more
82:14 - towards higher ticket prices and then if
82:17 - you move more towards more tickets sold
82:20 - then you can see that for high tickets
82:23 - high ticket prices which would be you
82:25 - know like these big bands then we can
82:27 - again see how many tickets we've sold so
82:30 - we can see that for you know a higher
82:33 - price and if we go up and ticket sold so
82:36 - if you want to see lots of tickets sold
82:37 - for a high price then the red Peaks are
82:40 - gonna give us all of these more famous
82:43 - artists so that's you know one kind of
82:45 - application but of course there are many
82:48 - many better ones it's just these things
82:51 - you know if you're in the moment and you
82:53 - you can kind of then you would realize
82:54 - oh this is when a two-dimensional
82:56 - histogram would be a great thing for me
82:58 - to use so a lot of these graphs they're
83:01 - great to know and once you're in the
83:03 - moment then it's much easier for you to
83:05 - pick out which graph would be best
83:07 - representative finally the last graph
83:10 - that we're gonna look at is gonna be a
83:11 - box-and-whisker plot and I want box and
83:15 - whisker plots allow us to do is they
83:16 - allow us to see the spread within our
83:19 - data so it's not just like a bar plot
83:21 - which just shows us one value but we can
83:23 - actually see the statistical spread so
83:26 - we can see median values which is what
83:28 - we see here we can see quartiles the
83:31 - little dots on the outside actually show
83:33 - us outliers and so what box and whisker
83:36 - plots allow us to do is they allow us to
83:37 - see the statistical information but they
83:40 - allow us to see it visually and that
83:42 - makes comparing across different groups
83:44 - which is what we're doing here much
83:46 - easier and so a good example of that
83:49 - would be if we look at ticket prices for
83:51 - football games for different teams so we
83:54 - have different teams and different teams
83:55 - of course use different stadiums and
83:57 - there they have different popularities
83:59 - and some teams may be much more
84:01 - expensive or the ticket prices may be
84:03 - much more expensive than other ones and
84:06 - so we can compare these ticket prices
84:08 - using box and whisker plots and then we
84:10 - can see you know what is the higher end
84:12 - of these
84:14 - so those are gonna be the more luxurious
84:15 - seats and then we go to the bottom and
84:17 - those are going to be the less luxurious
84:19 - seats probably the ones where you stand
84:21 - and then you have middle values
84:23 - depending on you know the standard seats
84:25 - and where you are in the stadium if
84:26 - you're close to the field if you're
84:28 - further away from the field but you're
84:30 - still sitting all of these things we can
84:32 - kind of see here and that's what gives
84:34 - us a spread we can compare that across
84:36 - different teams and we can see the
84:38 - spread across difference teams we can
84:40 - also see which teams are more expensive
84:41 - you know where do the prices vary the
84:45 - most for specific teams and maybe some
84:47 - teams have a super launch and then they
84:49 - have your you know standing places that
84:53 - are just much cheaper and so you would
84:55 - see a lot larger spread or maybe some
84:57 - teams just have you know only seats and
84:59 - see you'd see a much lower spread and so
85:01 - all of these things were able to compare
85:03 - using box-and-whisker plots over
85:05 - different groups in this tutorial we're
85:08 - going to talk about 3 and higher
85:10 - variable graphs so the graphs that we're
85:13 - gonna look at are is gonna be heat maps
85:15 - and then we'll also look at multi
85:17 - variable bar plots as well as how we can
85:19 - add more variables to some of the lower
85:21 - dimensional graphs that we've talked
85:22 - about earlier all right so let's start
85:26 - with heat maps now what heat maps allow
85:28 - us to do is they allow us to plot two
85:30 - variables against each other and the X
85:32 - and the y and they laws to show an
85:34 - intensity or a size or something like
85:36 - that in the Z direction or towards us so
85:40 - an example of this which is kind of what
85:43 - I've tried to illustrate on the right is
85:44 - a customer moving through a storm and so
85:48 - we can track the path of the customer in
85:50 - the X and y direction of the store so
85:52 - you can kind of get this bird's eye view
85:54 - and see where they move to and the
85:56 - darker spots actually tell us the
85:58 - positions where they spend more time at
86:00 - so we can see that they spend a little
86:03 - bit of time you know at the beginning
86:04 - they moved in and then they stopped
86:06 - lunch was what we see with dark spot
86:07 - being maybe they found like the candy
86:09 - aisle or something there was a specific
86:10 - piece of candy that they wanted and then
86:12 - they moved on and then they started to
86:15 - go towards the corner around the corner
86:17 - a little bit and maybe they reached the
86:18 - fruits in the vegetable section there
86:20 - and picked out several things and then
86:22 - they started to head towards the
86:24 - checkout counter which happens at the
86:26 - very end and they were moving at a more
86:28 - constant pays sometimes they stop to
86:30 - look a little bit but they just kind of
86:31 - continued moving on and so the three
86:34 - variables that we've shown here as we've
86:36 - shown their exposition in the store
86:37 - we've shown they're by position in the
86:39 - store and to their color we've also
86:41 - shown the time that they spend at each
86:43 - position so that's what we can use heat
86:46 - maps for and then another example the
86:49 - heat map would for example be if you
86:51 - take a flashlight and you move it over
86:53 - the screen and really what you're
86:55 - showing is the amount of time that
86:58 - you've shown the flashlight onto a
86:59 - specific region so that's kind of
87:01 - another example the heat map but usually
87:03 - heat map as the name implies it allows
87:06 - you to track positions and so it's very
87:08 - often used for things like tracking
87:10 - customers through stores or just
87:12 - tracking general people location where
87:14 - they like to spend their time and the
87:17 - intensity that you see in terms of the
87:19 - color is usually the amount of time that
87:21 - they spent there all right so we can
87:24 - also do multi variable bar plus a multi
87:27 - varied bar plot and so it is very
87:30 - similar to a single bar plot where we
87:32 - just plotted one value over different
87:35 - groups but rather than just plotting one
87:37 - we kind of cramped them together and we
87:39 - plot several and so an example of this
87:42 - would be that we plot you know goal
87:44 - scores
87:45 - I'm goal scored 14 the shots taken on
87:47 - goal as well as the shots on target and
87:50 - so we can see maybe there are teams that
87:52 - shoot less on goal without score less
87:55 - but that's because they also shoot less
87:57 - and therefore they also shoot less on
87:59 - target or maybe there are some teams
88:01 - that do score a lot and that's because
88:03 - they shoot a bunch but they just don't
88:05 - hit the target that often or maybe there
88:07 - are really good teams that score a lot
88:09 - and they also shoot a lot on target and
88:12 - so all of these things were able to then
88:14 - compare over different groups and so
88:17 - that's what we can use multi variable
88:19 - bar plots for if there are several
88:21 - variables that would give us a better
88:24 - understanding of the system than just
88:26 - looking at the variables in one at a
88:28 - time but it also be really cool if we
88:30 - could compare all of them then we could
88:31 - use multi variable bar plots for that
88:33 - and just plot them on the same bar plot
88:36 - and then we can see how they change you
88:38 - know within a group we can also see how
88:40 - they change over
88:41 - different groups okay and something that
88:45 - we can do is we can also just add extra
88:47 - dimensions to lower dimensional graphs
88:49 - that we've had and so we're kind of
88:50 - limited to three dimensions because
88:52 - that's the amount of space dimensions
88:54 - that we live in but if we take a scatter
88:56 - plot for example where we started off
88:58 - with just the X and the y axis and
89:00 - points located what we can do is we can
89:03 - actually add a third axis so we can take
89:05 - the X and the y and then we can add a Z
89:08 - and that gives us an extra depth
89:10 - dimension which is exactly what we see
89:11 - here so rather than just plotting unlike
89:13 - a two dimensional field unlike a plane
89:16 - we even actually plot it in a volume and
89:19 - so we can see this kind of scattered
89:21 - ball that we've done kind of kind of all
89:23 - that we've done here which is kind of
89:24 - located at the center of our plot and so
89:29 - this can be really cool because it
89:30 - allows us to see depth to the problem
89:33 - with this is that we have snapshots
89:36 - every time and so really we're looking
89:38 - at two-dimensional snapshots and so to
89:40 - get the best understanding of this we
89:43 - need to rotate our scatter plots or our
89:46 - plots as we do them so that we can also
89:47 - add in our depth perception because
89:50 - right now for looking at it it may look
89:52 - three-dimensional but really it's just a
89:54 - two-dimensional snapshot and to get the
89:57 - best understanding if our scatter plot
90:01 - is located more towards us and more
90:03 - towards the left or something like that
90:04 - or maybe it's just really high and close
90:07 - to us or maybe it's really low and far
90:09 - away to understand all of these things
90:11 - we need to be able to rotate our scatter
90:13 - plot so that we can see it from
90:15 - different angles which then gives us
90:17 - this depth perception and we can do the
90:19 - same thing with 3d line graphs so here
90:22 - we see an example of maybe the position
90:24 - of a skier as they're skiing down a hill
90:27 - and then we can kind of trace that
90:29 - through time and we see that they're
90:31 - kind of they're going down the hill in
90:33 - this nice exact motion as you should and
90:36 - we can just track their position over
90:38 - time so here we've added this extra
90:40 - dimension to the 3d line graph rather
90:42 - than just taking maybe a time and a
90:45 - position at a time or something like
90:47 - that we've added a second positions or
90:50 - actually even a third position so we've
90:51 - got the X to the one there's that
90:53 - position and then we just trace it
90:55 - and over time and so that gives us this
90:57 - whole line here and so that's how we can
91:00 - take these lower dimensional plots that
91:02 - we've looked at before and we can just
91:05 - add extra dimensions to them if we want
91:07 - as long as it's still easy to see as
91:09 - long as it makes sense what we're
91:10 - looking at yeah we're really just able
91:13 - to maybe just slap on another direction
91:16 - there and you know compare another
91:18 - variable in this tutorial we're going to
91:20 - touch on the third major section that is
91:23 - really great for data scientists or that
91:25 - should be an essential of data
91:26 - scientists which is the ability to
91:28 - program okay and so why do we program
91:33 - well there are different reasons why we
91:35 - want to be able to program the first one
91:37 - is going to be the ease of automation
91:38 - the second one will be the ability to
91:41 - customize and finally it's because there
91:43 - are many great external libraries for us
91:45 - to use that it would just make our job
91:47 - so much easier alright but so let's get
91:50 - started let's talk about the ease of
91:51 - automation for us what do I mean with
91:53 - that well being able to program it
91:56 - really allows you to prototype really
91:58 - fast allows us to automate things and it
92:01 - also gives us the extra benefit if if we
92:03 - have something in our mind we can just
92:05 - take that and kind of put it into the
92:08 - computer by programming it and so we're
92:11 - able to automate everything very fast
92:13 - and we don't have to do these repetitive
92:14 - tasks
92:15 - you know maybe copy pasting stuff into
92:18 - or from Excel or all these things and if
92:21 - we just want to repeat something or we
92:23 - want to quickly change something up and
92:25 - just change a small thing we don't have
92:26 - to do a lot of stuff we can just change
92:29 - that in our code and then click play and
92:31 - let the computer take care of all of
92:33 - that for us rather than us having to do
92:35 - everything manually so it's very easy
92:37 - for us to automate things um and also
92:40 - for doing reports it's very easy to
92:42 - automatically create these reports you
92:45 - know all you have to do is set up your
92:47 - program to deal with the data that
92:49 - you're going to give it and then I can
92:51 - automatically create reports every week
92:53 - and the reports can be different because
92:55 - you give a different data and it should
92:57 - still look the same but the data the
92:59 - values can be different and so that will
93:01 - just automatically create all these
93:03 - reports for you and you don't have to do
93:05 - that all yourself the program does it
93:06 - for you
93:08 - but you've built the program and you're
93:10 - giving it this different data so you're
93:11 - still doing all of the analysis it's
93:13 - just you get to skip the part of copy
93:15 - pasting and like looking across and
93:17 - taking over the values and doing all the
93:19 - formatting of just doing the same report
93:22 - over and over and over again all of that
93:24 - is taken care of for you and all you
93:26 - have to do is just put in the right data
93:28 - you know write out everything that you
93:29 - want to do and then click play and let
93:32 - the computer handle all that for you
93:33 - because remember that's what the
93:35 - computer is doing and good at doing
93:37 - doing these repetitive tasks okay we
93:40 - also want to be able to program because
93:42 - it really allows us to customize it's
93:44 - very easy once we go into data analysis
93:48 - and when we see things that we get these
93:50 - ideas that we want to expand or
93:52 - different directions that we want to
93:53 - progress our analysis into and being
93:55 - able to program it really just allows us
93:58 - to take all that and put it as a code
93:59 - and just choose that direction and we
94:02 - can very easily dive much deeper into
94:05 - our analysis and discover things fast
94:06 - because it's up to us to where we want
94:09 - to go and so this ability to customize
94:12 - with programming it's it's very very
94:13 - important because we're not reliant on
94:16 - anything else we're not reliant on you
94:19 - know some software and maybe it breaks
94:21 - down or maybe we don't know how to
94:22 - perfectly use it and we have to read the
94:24 - manual and read a like a Help section
94:26 - and know we know how to program and we
94:29 - just type down exactly what we want to
94:30 - do exactly where we want to take it
94:32 - exactly what we want to see and we can
94:35 - customize very very fast with that we
94:37 - can also prototype very very fast with
94:38 - that and maybe if a visualization is not
94:41 - working to turn a scatterplot into a
94:43 - line plot it's very easy you just change
94:45 - one word so all of these things are very
94:47 - very easy to do with programming because
94:49 - we have all that power at our fingertips
94:51 - and we can just you know change
94:53 - everything that we're looking at
94:55 - everything that's being calculated maybe
94:56 - we want to calculate an extra thing and
94:58 - take out something else because it's
94:59 - irrelevant all of these things were able
95:02 - to customize and all of that we can do
95:04 - because we're able to program so really
95:07 - what we're doing is we're making the
95:09 - data ours so we're taking full control
95:11 - of the data we're taking full control of
95:13 - where we want to go with our analysis
95:16 - what we want to see and what we want to
95:18 - show all right
95:21 - so let's talk about first libraries but
95:24 - also give you two great Python libraries
95:26 - that you should you know maybe feel
95:28 - comfortable with or that you should
95:29 - maybe consider using for data analysis
95:31 - so first of all what are libraries will
95:34 - libraries are pieces of code have been
95:36 - pre-written by others that you can just
95:38 - take in and use and so a very good
95:42 - example of this is something known as a
95:44 - math library and so that has all the
95:46 - square root functions taking to the
95:47 - power you know taking the exponential
95:50 - the sine the cosine all of these things
95:52 - that you know and you want to use but
95:55 - you don't want to program yourself so
95:56 - like it pretty much avoids that middle
95:59 - step of you having to program the
96:01 - equation to calculate a sine because all
96:03 - of these things those are things that we
96:04 - don't want to do we don't want to get
96:06 - distracted from our target we want to be
96:08 - able to do exactly what we want to do
96:09 - without having the program completely
96:12 - other stuff and so that's what libraries
96:14 - are great for they're developed for by
96:15 - the community for everyone to use you
96:18 - know everyone is helping each other and
96:20 - these libraries they just bring a lot of
96:23 - power with it and so one of these
96:25 - libraries is called pandas and pandas is
96:28 - pretty much like Excel but it allows us
96:31 - to do or we can do programming with it
96:33 - which just makes it so much better
96:34 - because we can do things so fast with it
96:37 - we can do all this customization we can
96:38 - do all this automation whereas you know
96:40 - like Excel if you give it too much stuff
96:42 - too much to run it would just start to
96:44 - crash because it has to handle all of
96:45 - this other things all these other visual
96:47 - things you know the UI and there's a lot
96:49 - more it's a lot it's not a structure as
96:52 - well whereas in programming the program
96:54 - you know your computer just goes through
96:56 - everything step-by-step it doesn't have
96:57 - to take care of all of these
96:58 - visualization things it just does the
97:01 - calculations down below but we can still
97:04 - do all sorts of data management with
97:06 - them so we can shift our data around we
97:09 - can drop columns we can split things up
97:11 - you know we can split things up our row
97:13 - we can pick out certain rows we can even
97:15 - do statistical calculations on our data
97:17 - so we can say you know hey calculate the
97:19 - mean for this we don't even have to you
97:22 - know make our own formula for
97:23 - calculating the mean or for calculating
97:24 - the standard deviation or for
97:26 - calculating correlation between
97:28 - different columns all of that can be
97:31 - done with pandas with just a you know
97:33 - a couple of key words and so it's really
97:35 - easy to do data analysis with it because
97:38 - all of the functions that are there and
97:40 - we know exactly what we want to do but
97:42 - we don't have to write the code for all
97:44 - of it so if you wanted to look at
97:45 - correlations we just say hey pandas do
97:48 - correlations rather than having to you
97:50 - know code all the correlations for
97:53 - ourselves and doing you know coding that
97:55 - whole algorithm and that makes it really
97:56 - easy and really fast to get results and
97:59 - to get to where you're heading because
98:01 - you don't have to go into any of these
98:03 - mineral places you can pretty much just
98:04 - skip the middleman of having to you know
98:07 - write all of those algorithm to yourself
98:09 - and you can just use them so that you
98:11 - have your start you have your idea you
98:14 - know exactly what you want to do and you
98:15 - can do exactly that to get to your goal
98:18 - the other library that is very cool
98:22 - would be matplotlib which is what I use
98:24 - a lot for data visualization it allows
98:26 - me to create graphs allows me to
98:28 - visualize my data allows a bunch of
98:31 - customization so I can really just move
98:33 - everything around in it I can move my
98:35 - spines I can turn things on and off you
98:37 - know all of these things are very easy
98:40 - to do with MATLAB there's a lot of great
98:44 - customization that I'm able to do with
98:46 - it so these are like kind of two basic
98:48 - Python libraries that you should
98:50 - probably maybe get to know em or you can
98:53 - look at some of my other courses and one
98:55 - of them pandas would deal with the data
98:57 - analysis part and matplotlib would help
98:59 - you deal with the data visualization
99:01 - part of it so that's it that's a super
99:06 - basic breakdown of the three main
99:07 - components of the otherwise vague term
99:09 - data science if any of this has piqued
99:12 - your interest then you may have a data
99:14 - science future ahead of you and I
99:15 - encourage you to continue to pursue your
99:17 - interest if you want to learn more from
99:19 - me I've got a blog on my website coding
99:21 - with max comm that dies more into
99:23 - different topics related to data science
99:25 - you can also get access to some of the
99:27 - resources such as cheat sheets and
99:29 - workbooks that I've compiled for you
99:30 - there if you're serious about learning
99:32 - data science you can also check out my
99:34 - courses on data science which are
99:36 - designed to teach you all you need to
99:37 - know about data science even if you have
99:39 - no prior experience of course if you
99:42 - have any questions that aren't answered
99:44 - at my website you can always feel free
99:45 - to reach out
99:46 - me personally

Cleaned transcript:

hey everyone and welcome to my mini course on the essentials of data science this mini course provides a super basic looking to data science what it is and the three main components that make up data science data science is a very mainstream word like it's thrown around a lot but its actual definition is quite vague this mini course is designed to help those of you who are curious about data science develop a better and more specific understanding of the topic there are definitely more advanced techniques within data science such as machine learning but even these can be traced back to the three essential components that we'll cover before we get straight into it I thought I'd quickly introduce myself my name is Max and I work as a data scientist after getting my degree in physics I find myself more and more drawn into the world of data science so instead of diving into the realm of physics research I taught myself all the tools and techniques a data scientist needs and shortly after landed my dream data science job I've since also started teaching data science to others and have been fortunate enough to teach what is currently over 9,000 students the skills of gathered and learned over the past five years of my data science journey so let's jump right into it so what is data science well data science is you can kind of summarize it in different ways but the main parts of it are transforming data into information and this is a really big step because a lot of people talk about you know data and big data and all these things but data by itself isn't really that useful until you can turn it into information and so if you just have a bunch of numbers appearing somewhere and it's just you know so much of it no one can make sense of that and that's where you need a data scientist to be able to transform all of these all of this vagueness and kind of this noise to that's going on and you need to be able to extract information from it and that's what a data scientist does now what you do with this with this information or how you get this information it's through analyzing your data so a big part of it would be you know cleaning things up doing some some processes on it and then you analyze once you've clean things up and that is one of the ways that you can then get information out of your data through this analysis and you can kind of continue on and you see trends and patterns and all types of correlations hopefully and all of these things again build up into this turning data into information component and then ultimately you also need to contextualize everything that you have so your computer can't do that for you you can Peter can kind of crunch the numbers and stuff but it's your responsibility also to make sense what's in front of you and even if you see something you just don't blindly trust it but you need to understand you know where am I at where am i coming from where is this data coming from you need to be able to contextualize these things and then of course be able to apply as well as understand them and so once you have this data you know it's great but turning it into an information into great information that you can use and directly apply that's where the real power lies and that's also kind of the role of a data scientist so that's what the data that's what data science pretty much is and so what is the data scientists do well we kind of already talked about this just a little bit but let's go over it again any more concrete examples um so a data scientist would for example get and process this raw data and then convert it into something a little bit cleaner so you can imagine kind of just like a data stream coming in and it's you have this measuring device and constantly is just measuring all sorts of data and because like nothing is really constant so everything will be fluctuating up and down and so a data scientist would be to kind of take all of this data it'd be to kind of clean it up a little bit you know maybe reduce this fluctuation that you know isn't supposed to be there that's just kind of background stuff going on and then put it into a format so that you can easily plot it against some things and then we already get to the next point that you know once this data is cleaner you can maybe do start doing some calculations on them figuring out the core statistical components you know like what is the average values of these what what am I really dealing with you know getting a first look at first understanding of what it actually is that you're tackling and then once you have this kind of understanding then you can start to do some visualize they which helped you as a data scientist maybe see some trends or patterns already but visualization was also really key because they let you show it to other people and there are great means of communication so they help both you as a data scientist as well as helping others when you try to convey this information to them all right and then finally you have to suggest some applications of the information so it's not really enough to just be able to look at it and say like yeah I see it goes up and down and that's that's good but what does that mean how does this transfer into something useful and that's also one of the key roles of a data scientist transferring information into knowledge and so you've got this data into information step but you also need to transfer this information into knowledge and those are two really powerful things that are worth a lot a lot and that's pretty much what a data scientist focuses on and then you can go further you know and take this data and do machine learning with it or something if you really understand what's going on or if you have some hypotheses of you know what could happen so you can take things a lot further but ultimately this kind of turning data into information and then into knowledge that's kind of your role all right so let's go into the essential techniques or the essential components of data science so the first essential component and we kind of touched on this already is statistics and basically we're gonna cover this later on but let's just give a kind of quick wrap down so in statistics need to understand different data types that you can encounter and so there are data can come in different ways and we'll go again into more detail with this later but it's not just you know you get a bunch of numbers data can come in very many different ways depending on the field that you're in and so you need to be prepared and you need to kind of be aware that data may not always just be a direct number for you then of course you need to understand some key statistical terms like you know the different types of means and also understanding fluctuations in data and the reason that this is important is because these key statistical terms give you an overview of how this data is behaving and depending on how the data is behaving you may want to approach it differently so if you know that your data is very clean there's a very little fluctuation then if you visualize things you can probably trust what's going on or if you want to maybe fit some curves to it or something but if you see there's a lot of fluctuation in your data visualizing it is going to be much more difficult because you just see jumps everywhere and you're not really sure which of this is actually true and which of this is caused by you know like some interference somewhere or someone is messed with my system and so all of these things will kind of be hinted to you through statistical terms so it's probably good that you know you're kind of comfortable with these things and that you can be able to get some meaning and meaning out of them all right and then finally it be in statistics to be able to you know split up and group or segment data points so that when you have this big data set you want to be able to you know maybe split it up into smaller things compare different regions look more into more detail into some things and maybe you know isolate two components because you know hey these things are probably going to be important the rest I don't really care about that much so being able to kind of pinpoint an isolate and meddle with the data a little bit so these are the kind of statistical components that we're gonna look into all right so the next big thing and we've already talked about this too is data visualization and we'll see why data visualization is a really key skill for data scientists and then we're also be gonna be covering different types of grass that you can use and how you can compare different number of variables so for example you can have one variable grass where you only look at one thing and you only want to look at this and you want to see how these how this changes you have your typical two variable grass which you probably know where you have this X and a yaxis and then you can kind of see how two variables relate to each other or you can have three variable or even higher variable graphs and where you plot maybe three different things or even more if you want as long as it makes sense next to each other so that you can compare multiple things at the same time all right and now we come to the other big thing that you're probably going to need as a data scientist which is going to be the ability to program now not every data scientist can do this but this is really really essential in my opinion to your role as a data scientist because knowing how to program is going to make your life so much easier if you know how to program you can kind of take your ideas and your thoughts and you can put them into actions in the computer and you can just automate everything you can customize things you can explore you can prototype you can test and you're not reliant on some you know application you don't have to master some application and if it doesn't work or if one feature isn't there you have to contact customer support and maybe it's not even possible and then you have to wait for an update or maybe something is bugged with programming there's just you're so much more reliant on yourself and you can really just do whatever it is you want to do and you're not reliant on other people or on the tools that other people have built for you but rather you can just pretty much go and you know just do what you want to do without there being major roadblocks and then we'll also look at some essential packages in Python so in programming you never want to reinvent the wheel you always want to start off where the last person left off and so the ability to program and be able to write simple programs you would need to teach yourself but you wouldn't need to write highly complex mathematical packages or data analysis packages those are already out there all you need to do is be able to download them and implement them in your code and they're gonna work you know they've been tested a lot there's a huge community's working on them on improving them and everything all of this is for the community and so the whole community kind of works together to improve it no one's really directly trying to make a lot of money off of it so they're not going to charge you all of these service fees and everything everyone's just trying to improve their package because if it improves everyone also benefits from it and so we'll look at some of the libraries or we'll talk about some libraries that you can use especially in Python and to help you along your way with data analysis and to become a successful data scientist in this chapter we're going to talk about statistical data types now we're going to look at the three different types of data which are summarized as numerical categorical and ordinal types of data now these are the types of data that we talked about before how you can't just expect your data to be cut be kind of numerical and so we'll see the miracle data but we'll also see the two other types of data that you may be you know encountering in your career as a data scientist all right so let's talk about numerical data first though numerical data is also known as quantitative data and it's pretty much things that you can kind of measure it's it's great numerical stuff that you can do math with you can compare it you know saying this Plus this makes sense he is greater than B these are you know all examples of numerical data numerical but data can we split up into two different segments one of them is going to be discrete and so discrete means the values only take on distinct numbers and an example of this would be you know IQ or something like that a measurement of IQ or if you do a coin toss the number of times that you toss heads so you can you know you can have 15 heads you can have 12 heads out of you know 20 coin tosses you can have 500 heads out of a thousand coin tosses or 500 out of 600 or all of these things but all of these are distinct numbers and now they don't have to be whole specifically but they do have to be distinct so that's that's the kind of very important part that you know there's a kind of step size that you're dealing with and of course you can still say hey you know flipping eight heads out of twenty is better than filling seven heads out of twenty so if you want to flip heads lettuce or flipping eight out of 20 is worse than flipping 7 out of 20 if you're going for as many tails as you can so all of these kind of comparisons that make sense so that's the discrete part of numerical data then we have the continuous part and now the continuous part is really that values can just take on any number and they're not unlimited by decimal place so a value that can you know can be like one point one and then the next value would be one point two that's not continuous that's still discrete because you have this step size of zero point one continuous means literally ever number from start to finish can be taken on and this doesn't mean that every possible number in the universe from negative infinity to plus infinity and all imaginary numbers and everything that comes with it that doesn't that that's not required for continuous it could really be that just every number between zero and one can be taken on so for example let's say you have a bottle of water and this bottle of water can hold one liter now if you fill your bottle up and it starts off empty and you fill it all the way up to the top the amount of water that you've had needed to take on every single number between zero and one because you can't just fill up water you know in kind of small increments of say hey I'm gonna put in 0.2 liters every single time because the water doesn't just you know teleport from A to B but when you're pouring in water it's more like we see in the stream here and the water level rises and Rises and Rises and so the amount of water that we have in our cup needs to take on every value between zero and one so that's an example of continuous data for but you see that you know we can be limited to zero and to be between zero and one we don't have to you know start at zero and go all the way up to infinity or something but it's just that the range that we're looking at every single number can can be applied or every single number can you know happen another good example would be the speed of a car if you start and you you know you're standing still and you're studying you're standing at a stoplight and then you want to accelerate in the speed limit us say you know 50 miles an hour or something to get to 50 miles an hour from your starting position your car has to take on every single speed in between and of course you won't see that you know on your spot on the speedometer it would say something like zero miles an hour one mile an hour you know maybe you can go to like it's going 0.1 0.2 0.3 or something like that so it may look discrete to you but that's not how your car is going your car doesn't say it like oh I'm gonna go in these step sizes of speed it's gonna accelerate gonna take on every value starting from zero going up to 50 miles an hour and you're gonna when you're in this transition you're gonna take on every single one of those speed values so that's how continuous data looks like and it's important to understand the difference between this discrete and continuous just because you may want to approach it differently now of course if we're dealing with computers our computers can't deal with infinite numbers in the decimal places we have to cut it off somewhere and so usually continuous data is gonna be rounded off at some point but it's still important for you to know that you're dealing with continuous data here rather than discrete so that you know hey there can still be other stuff in between here and or all of these things rather than you know having specific step sizes and all you see is just kind of a bunch of lines at every step size but you can expect that when you have continuous data that everything is just kind of filled filled up that everything can and may even well be in between certain places so that's that's kind of the important thing to note between discrete and continuous alright so the next type of data that we'll have is categorical now categorical data doesn't really have a mathematical meaning and you may also know it to be qualitative data um and categorical data it describes characteristics so a good example of this would be for example gender so here there is no real mathematical meaning to gender of course you know if you have good data you can say male is zero and female is one but you can't really compare the two numbers even though you assign numbers to them and you may just do this so that you can split it up later on there your computer can understand but it doesn't really make any sense to compare you can't say you know is male equal what you can say male is not equal to female but you can't really say is one greater than the other or is one approximately equal to the other those things don't really make sense because they're not welldefined what does that mean and you can't really add them up either you can't say male plus female but that doesn't it doesn't give you a third category or something so categories that you can't really apply math to them but there are nice ways to kind of split up or group your data and they provide these nice qualitative pieces of information that are still important it's just you can't really go that well about you know like plotting them on a line or something like that so those are important things to note with categorical data and then another example would for example be yeah ethnicity or you could also have nationality all of these things are examples of categorical types of data yeah I'm so like we said you can assign numbers to them but that's really just for your code so that it's easy to kind of split them up but you still can't really compare them how are you gonna compare nationalities there is really no definition for you know comparing one type of category to another alright and so the third type of data that you can encounter is something called ordinal data now ordinal data is a mixture of numerical and categorical data and a good example of this would be both tell ratings so you have you know star ratings 0 0 1 2 3 4 or 5 stars or maybe even 6 stars or you know whatever it is whatever the hotels go up to these days um but it's still not as straightforward to compare so I'm sure you've seen two different types of threestar hotels one of them you know had the bare minimums the beds were okay but it wasn't really anything special and then you had this threestar hotels that you could have sworn we're at least fourstar and so star ratings do make sense we can say you know a fourstar hotel is probably better than the three tier hotel because there have been standards there are standards for these things they have been checked you know if you go to a fourstar hotel you know what to kind of expect but still it's not completely defined so like you know coming back to this three star example it's very hard if you just say hey we're going to a threestar Hotel it's very hard to know exactly what to expect because there are different parts of threestar hotels there are threestar hotels that have developed onto like have a swimming pool maybe or something like that and then there are those threestar hotels that are really more like hostels or something that I've just made it past the to start place and so there it's much harder to kind of define or to know what to expect now if you take averages of these star systems though then you do get a much better idea of what's going on so if you have you know consumer reviews or something like that and you say Oh from you know 500 reviews our hotel has an average rating of like 3.8 then you know that the three star hotel that you're looking at is pretty much a four star hotel it feels like a four star hotel even though it may not have all of those qualifying characteristics that's the kind of feel you get from it whereas from another three star hotel you may have a rating of like 2.9 or something and there you know oh you know this hotel is more towards the lower end of the three star some people may not even consider it to be three stars and of course you know this rating may be a little bit biased because they went to a different three hard star hotel first and then they went to this one and they were expecting something completely else from the three star hotel so they said this can't be three stars this is two stars but it's because of the way that the ranking system is defined underneath and everything and so when we have these averages of these ordinal numbers then they kind of start to make a little bit more sense alright so let's go over a small exercise and see if we can identify what type of data we're dealing with so the first thing we'll look at is gonna be the survey response to happiness now you have people filling out a survey and then this and then one of the questions is you know how would you rate your happiness and it's gonna be bad neutral good or excellent what type of data with this be well this would be an ordinal type of data because it's still in a form of categories and you're asking for the subjective opinion but it does make sense so you can still compare them you can say excellent is greater than good good is greater than neutral neutral is greater than bad but what exactly does it mean to be good and excellent you know where do different people draw the line for this there's it's still a little bit of vagueness involved but generally it does make sense and you can compare it and if you have a lot of surveys and you averaged them the values you're gonna get are probably going to be very well representative or at least pretty good representative all right so if we look at the next thing which is going to be the height of a child what type of data is that now we can say it's probably numerical and well it actually most definitely is numerical so the height of a child is a numerical value but let's go a little bit deeper and say is the height of a child discrete or is the height of a child continuous well even though when you measure height you get something like you know five foot five foot three or 160 centimeters or something like that it's not a discrete value because to get that height you have to have reached every single height before and so even though at the moment you may be measuring it you're kind of rounding it off to how much your measuring tape can measure so like your measuring tape is kind of limiting the height but if you had a super super precise measuring instrument you could measure not just you know five foot three or something like that you could really go into detail with the inches and the decimal places and there and everything kind of going on so the height of a child would be a numerical data type but it would be continuous all right now let's take about talk about the weight of an adult do you expect the weight of an adult to be either discrete or continuous so we can probably agree that it's numerical because it's a weight value it's it's pretty much defined to be a number and what do you expect it to be discrete or continuous well the right answer here is gonna be continuous again because to reach a certain weight they would have had to have reached every single weight in between before so again the weight is something that we can consider to be continuous all right and so finally let's look at the number of coins in your wallet again we can already by the name it says a number of coins so we can probably agree that this is a numerical type of data but the number of coins in your wallet would that be discrete or continuous well the answer would be discrete because it doesn't really matter what's your anoint your coins are they could be 50 cent pieces that could be 25 cent pieces ten or five or ones or anything you know like a two or something like that but they're not going to be but the number of coins that you're gonna have we're gonna sum up to a whole number so you can have one coin you can have two you can have three all of these things but you can't have infinite fractions of a coin you can't have say you know the square root of two number of coins that doesn't really make sense so you have a defined step size you have one coin and then if you have a second coin then you have to you get a third coin meaning of three you're going in step sizes of one so for the number of coins in your wallet we'd be having discrete numerical data in this tutorial we're going to talk about the different types of averages now we're going to see the three different types of averages which is the mean the median and the mode alright let's get started so we'll start off with the mean now the mean is the typical average that you know and really what the mean is is you just sum all of your values up and then you divide them by the total number of values that you have now the great pros of the mean is that it's very easy to understand it makes sense we just have everything we have and just kind of add it all up and then divided by what we have and that should give us a good representation of what is the average and it also takes into account all of the data so since we're adding everything up and then but dividing by how much data we have we're taking into consideration every single data point now there are some problems with this so one of the problems is that the mean may not always be the best description and we'll see why when we look at examples for when we should use the median and the mode and the mean is also very heavily affected by outliers so since we're taking everything into consideration if we have big outliers that's really gonna change how our mean looks like so if we just have normal values you know between like one and five and all of a sudden we have like 10,000 in there that's really gonna affect our mean so mean is heavily influenced by outliers and the bigger the outlier more the mean is influenced by it all right so let's see some examples of the mean we'll go through a worked example first and we can see our data set here which is just a bunch of numbers and what we're gonna do to calculate the mean is we're just gonna take every single one of these numbers and we're gonna add them up and we can see the total result that we get here and then the next thing we're gonna do is we're gonna take this total result we're gonna count the amount of data points that we have and we're gonna divide one by the other which then gives us our mean as we can see here so that's an example calculation of the mean but let's see some example applications of the means so when would we use it well good application would say if you look at the time it takes you to walk to the supermarket so sometimes you walk a little bit faster and maybe it takes you 20 minutes to get there sometimes you walk a little bit slower it takes you 25 but on average it takes you somewhere like 22 or maybe 22 and a half minutes or something like that so if you say I'm gonna go to the supermarket you're like it's gonna take me this much time to get there another good example of the mean would be exam score for a class so to get a good understanding of how people do in an exam or in a class you can look at the mean exam score last year and since our exam scores are kind of in a smaller range a mean is gonna be good to use it because you can get anything between 0 and 100 but realistically speaking no one's probably going to get a zero so your range is even smaller and so you're less affected by outliers and you kind of know how hard a class is gonna be just by being you know able to compare their means so if you look at one class and it's mean is higher than the other but they have a large number of students or something then you can probably say hey it's easier to get a good grade here or something like that or maybe you know some of these it's more simpler overviews without diving too deep into it alright another good example of the mean would be to say how much chocolate do you require when you get this kind of sweet craving and you're not gonna say like oh you know I require one chocolate bar two chocolate bars but like you're gonna say Oh on average you know I require you know maybe threequarters of a chocolate bar and sometimes I may want a little bit more because I feel like it and when I start eating chocolate I crave it even more sometimes you know I have it at first and like the tasters doesn't sit right with me right now and so I have a little bit less but these are kind of the amount of things so like if you have this craving you know either you say oh I'm gonna try to be strong or you like hmm well I know this feeling and I know if I eat about you know threequarters of a bar of chocolate or something I'm gonna feel good my craving is gonna be satisfied so you kind of know what to expect so these are some of the examples for how we would deal with a mean well when we would use mean all right so let's look at the next thing which is going to be the median now the median represents the middle value in your debt data says now if you have an even number of data points you don't really have a middle value and so in that case the meeting is gonna be the mean of the two values so it's going to be the two meeting values added together and then divided by two so the pros of using a median value is that the median can sometimes be more accurate than the mean and we'll see some examples of this the median also evenly splits your data so you're not really you know affected by the mean in the sense that if you have an outlier in the mean and it drags everything to the right it could be that your outlier drags things so far to the right that all of your data is to the left of the mean and only the outliers to the right so that would be an extreme case but that can happen whereas the median you know it's always located directly in the center of your data and the median also doesn't care about outliers so if you have huge outliers at the beginning and at the end it doesn't really care because outliers by definition aren't very common because they're outliers and so if you have them at the beginning or house them at the end they're gonna be very few in number which makes them outliers and therefore the median doesn't really care about outliers that much a con though is that the median doesn't really give you much information on the rest of the data sure you know you know what's at the center but you don't know how does everything we behave you only know where is the center of our data so let's see some examples well do a working example first where we see our data set here and we can count how many values we have is we go from left to right then we can say we've got 1 2 3 4 5 6 7 8 9 10 11 12 and 13 data points so we've got an odd number and so our median value our center value is going to be the seventh data point because it's 6 from the beginning and it's also 6 from the end so it's equally spaced both from the beginning and from the end and so that's why we see our median value here is 26 it's located directly in the center now what is the median useful for well the median is often used if you look at you know household incomes for a country because if you were to use the moon then these billionaires they would just completely you know they would give you a false description of what really an average household income is because normally if you have you know like an average value and you can say oh the average household income from this family would be say $40,000 or something like that or that would be the median value but if you were to use the mean instead then all of the billionaires and all the millionaires in the country they would change that household income and then you would say oh you know the average household income per family would look like 60k and that's a bad representation because that doesn't actually give you a realistic look at what the average household family has and the average household family really does it's you know centered at like 40k and sure there are people below and there few people be high but that's what's in the middle whereas if you were to use the mean instead for your average you would kind of get this inflated household income which wouldn't be representative to the rest of your and the rest of the country another good example of the median would be the distance that people cover to get to work so if you look at this in terms of you know kilometers then you can say like oh you know some people they walk to work and it's like you know one kilometer at most so something like that and then you can expect people to travel most people travel around three kilometers to work and sure there are some you know that travel much further because they want to live outside of the city and there are some that travel very very short distances because they have a house right next to the office where their house is the office or something like that depending on where you're working but then you can look at you know like we're in the middle how do people travel to work what time or what distance do they need to cover and so that would be another good use of the median and a meeting another good meeting value is what do you usually spend when you buy a new item of clothing and so sure you know sometimes may go to that expensive clothing store and you could get a jacket that costs I don't know north of a couple hundred euros or dollars whatever system you want to use and sometimes you can go to a secondhand store and get it for very cheap but usually if you go into stores a jacket I don't know maybe cost you like a hundred dollars or something like that and so you know if you go out you can expect to pay about $100 no not really you know taking that much accountant what story going in so most of the stores that you're gonna visit are gonna have that price for the jacket so that would be another good use for the median all right let's look at the third type of average that we can do which is the mode now the mode looks at the most common value in your data and it's not really defined if there are several most common values but if there's only one most occurring value then that's what your mode would be and so we'll see an example of this in a second to the pros of using the mode is that it's not only applicable to numerical data so if you look at categories for example then you can say hey we've got five people from the US you know and two from Canada and one from France and you know that the mode is gonna be the US because there are five people from the US so mode is the great average that's not only applicable to numerical data in this sense but you can technically also apply it to categories or to ordinal numbers if you wanted so that you can say the most common country that we have were the the average kind of country that we would expect tear is the US and sure there are other countries but the average or the most common one is gonna be the u.s. in this case so yeah and then of course and the other Pro is that we allow to see what's most common what pops up the most so that's a great use of the mode if there are cases when you know recurring values happen a lot which is the case for discrete numbers for example so in discrete numbers values recur often and so it's good to use the mode icon of the mode it's gonna be that it doesn't really again give you good understanding the rest of the data similar to what we had for the median but also it's not really applicable if you just have a bunch of different types of data then there isn't really gonna be a mode if there's not enough of each data it's not really good to use the mode you don't want to you know have thousands of data points and the most reoccurring value it reoccurs like three times that's not good you want to use the mode for situations where data re occurs often so like we saw the country example but let's actually see a worked example but also some other examples for the mode so the worked example here would be again we take our data set and we can count how many times different numbers appear and so if we go through the numbers we'll see that twenty six occurs the most and so that's gonna be our mode here so we've got 22 and 25 that both occurred twice but 26 occurs three times and so 26 is gonna be our Millah it's gonna be our most occurring value now the mode is gonna be useful for things like the peak of a histogram so if you draw this histogram and if you don't know what a histogram is don't worry we'll cover that in a later lecture to let me go into data visualization but the peak of a histogram that's gonna show you the mode of the data the most occurring data a good another use of the mode will be if you look at employee income at a company because at a company you know you can again have the boss which takes off the mean and you can have you know higher level employees to which we kind of shift the median but if one third of your employees earn minimum wage that's gonna be the best average or say 40% of your employees earn minimum wage you're probably not your employees because that wouldn't be a very good system to have but a 40% of the employees at the company that you're looking at earning a minimum wage that's not a really good thing to have and if you look at the mode you'll easily see that the average in this case would be to earn minimum wage because that's what most people earn and sure you know the boss he or the CEO or something you know he may shift the mean up heavily and then the fact that you have higher ups if you look at the median value you may even well be too far you know too far to the right that you really don't consider these employees that all are in the same amount but you really want to get that description which is what you get here from the mode and then also the out kind of an of an election is where you use the mode for and sure sometimes you may only have two values sometimes you may have three but if you have different candidates and say you have five different candidates then the person with the most votes is gonna win the election because they have the most and so they are again you'll use the mode in this lecture we're gonna look at a spread of data and we're going to start off with looking at the terms range and domain then we're gonna move on to understanding what variance and standard deviation means and then finally we'll look at covariance as well as correlation all right so let's start off with a range and domain now let's start off with the range though so the range is basically the difference between the maximum and the minimum value in our data set so that's that's kind of simple to think about so let's just kind of go through this with a work example let's set up a company in the town and this is the only company in the town and the owner of the company earns a salary of 200k a year and then the employees you know they all have different salaries but the lowest employees or maybe the parttime workers they earn something like 50k a year so we've got data kind of ranging from 15k up to 200 K and so our range is the difference between the maximum and the minimum value in our DNA so we take 200 K and we subtract 15 K from it and we've got a range of 185 K in salary so that's how big our salary can change so it can if we start at 15 K it can go all the way up to 200 K so that's a hundred and eighty five K range of salary that people in this company can have all right and the domain is going to be the values that our data points can take on or the region that our data points lie in so if we look at this example again our domain is gonna start at 15 K and go up to 200 K so what the domain defines is it defines kind of starting and ending points or it defines a section in our data and so in this case the domain would define you know we would start at 15k and it would end at 200 K and what the domain tells us is that everything or all salaries within you know between 15k and 200 K that they are possible but within this domain or within this company it's not possible to have salaries outside of the glist domain so if our domain again is 15k to 200 K then we can't have a salary of 14 K because that's outside of our domain and we also can't have a salary of 205 K because again that's outside of our domain so pretty much all salaries within 15 to 200 K are possible anything outside of the domain is not possible because that's no longer in our domain all right so let's move on and look at the variance and standard deviation and we'll talk about the variance first and what the variance tells us it pretty much tells us how much our data differs from the mean value and it looks at each mean value and it looks at how different each value is from the mean value and then it gives us the variance it does some calculation and we don't really need to know the formula it's more important right now just to understand the concept of variance and so what it variance really tells us is it tells us how much our data can fluctuate so if we have a high variance that means a lot of our values differ greatly from the mean value and that will make our very it's bigger if we have a low variance that means a lot of our values are very close to the mean value and so that will make our variance lower and now if we turn to the standard deviation the standard deviation is literally just the square root of the variance so if you understand one then you also understand the other and now we can combine this if we know the range of our data to kind of get a better feel for our data and so let's use an example where we have two different countries just countries a and B and they have the same mean height for women which in this case will say is 165 centimeters or 5 feet 4 and we'll say that the range of heights for them could be identical so let's say they can range you know the range let's say it could be like 30 centimeters or something you can go anywhere from say 150 all the way up to 80 or we can even increase that and say like anywhere from as low as 140 up to like two meters or something like that but let's just keep the range for these the same and they both have the mean height now if country a has a standard deviation of five centimeters which is approximately two inches and country B has a standard deviation of 10 centimeters which is approximately four interests then what you can expect knowing these values is that if you go into country a the people that you're gonna see are gonna be much more similar in height so our standard deviation is lower that means our values differ lower from the mean and so that means a lot of the women that you're gonna see are going to be very close to 165 centimeters or 5 feet 4 plus minus 2 inches so it's very what you can expect when you go to this company that when you go to this country is that everyone is gonna be or every a lot of the women are gonna be about that height whereas if you go to country B they have a much larger standard deviation and so you can't really expect everyone to be about 5'4 because it fluctuates a lot more and so if you go to that country you can expect to see a lot more women of different heights both taller and shorter than for all right and so that's how we can kind of use the variants in the standard deviation or the standard deviation to give us a little bit more perspective on our data and kind of allow us to infer some stuff about our data all right so let's talk about covariance and correlation and so covariance will or already has the name very incident but covariance is measured between two different variables and it pretty much measures if you have two variables so let's say we've got you know me drinking coffee in the morning and my general tiredness so if I use these two values and you know get data point so this is how much coffee I drank in the morning and this is how tired I feel this morning or something like that and so what the covariance does is it looks at how much one of these values differs or changes when I change the other one so what does that mean for example well if I drink more coffee what the covariance would look at is how much does my tiredness change so that's what you do with covariance you see you say I change one how much does that affect the other thing that I look at and our correlation is very similar to covariance so we kind of normalize the covariance by dividing by the standard deviation of each variable so what that means is we get the covariance for my drinking coffee versus feeling tired and then we would just divide by the standard deviation of me drinking coffee and a standard deviation of me feeling tired and so really what we're doing with the correlation is we're just kind of bringing it down to relative terms that would fit our data better so that's kind of the abstract idea the important thing to just keep in mind is that we're looking at one and we're seeing how much that changes and we're seeing how much that change affects the other one all right so there are different types of correlation values that we can have and they can range anywhere between negative 1 and 1 or so their domain is between negative 1 and 1 and a correlation of 1 means a perfect positive correlation so that when one variable goes up the other goes up so for my coffee example that would be if I have coffee in the morning then I also feel more happy so the more coffee I have the more happy I feel and of course there's going to be a limit but let's say I only drink up to two cups of coffee or something like that and I can drink anything in between and the more I have the more happy I am about it so that would be a positive correlation the more I have of coffee the more I have of happiness and so they would kind of go up together and then when we get closer to zero the zero point is gonna mean no correlation to us so anything between zero and one is going to be a kind of slightly positive correlation it's not going to be a super strong and we'll actually see some examples on the next slide but yeah so anything between zero and one is going to be a kind of slight positive correlation not super strong and the closer you get to zero the more it means no correlation so an example for the zero case would be that it doesn't matter how much coffee I drink in the morning it's not gonna affect the whether they're unrelated one does not affect the other so I could drink you know one cup of coffee during a sunny day and one cup of coffee during the rainy day and it's not gonna change the weather it's not gonna affect the weather so they're pretty much uncorrelated and then we can also go down into the negative range and so the closer we get to negative one or if we reach exactly negative one that correlation of negative one means a perfectly negative correlation and so here we can take our example of coffee versus tiredness and so the more coffee I have the less tired I'm gonna be so coffee goes up and tiredness goes down so that's how we can kind of understand this correlation and it comes from the covariance so it was important to understand the covariance we usually use the correlation because the correlation because we divided by the standard deviation of each is much better fit to our data now there is one thing that's very important to remember and that's that correlation does not imply causation so just because two things are correlated that does not mean that one causes the other so a good example of this would be if I live in a climate where it's usually cloudy in the morning and I know it to be sunny in the afternoon but every morning when it's cloudy I drink coffee and then it becomes sunny in the afternoon that's not even though they may be correlated me drinking coffee and it becoming sunny it me drinking coffee does not cause it to be sunny that's just you know by chance it's just because it happens every day and by chance there's this kind of correlation that appears but that does not mean that me drinking coffee you know results in the weather getting better a causation would be me drinking coffee and me feeling less tired or me drinking coffee and me feeling happy about it because I like the taste those would be causations so that's an important thing to keep in mind just because things are correlated does not mean that one causes the other all right so let's see these things on a graph and so here we have the examples again that we've talked about but we can kind of see how the data would look like for different types of correlations and so we can see a perfectly the perfect correlation of one so one goes up the other goes up we can see on the left side and we pretty much get this really nice straight line so one value goes up the other value goes up with it and then the closer we reach zero the less related or the less correlation there is between them and then the more kind of variance we have in data so we'll notice for the case of perfect correlation which is the one or the case of perfect anticorrelation which is the minus one which again we had the example of more coffee less tired and in those cases you know we have a very nice thin line and our data doesn't jump around a lot but the closer we get to zero the less we can see you know one causing the other and the more we can see our data kind of spread out and so that's what correlation would look like in terms of graphics in this tutorial we're gonna go through quantiles and percentiles all right so let's get started so what our quantiles quantiles allow us to split our data into certain regions that if we're dealing with probability they all have the same probability of occurring or if we're just dealing with you know sizes of data we want to split our data into equal regions so that's what we can do with quantiles is just splitting everything up so that every time we split it you know we have equal amounts of data all right and so an example of a quantile would be something known as a quartile and so that's when we split our data into four equal regions hence the name quartile so a quantile is the general name for doing this splitting procedure and then if we say quartile that means we're doing quantiles but for four equal regions and so this is something that you'd probably often see unlike university admissions pages or something like that and they say the top 25 percent of our applicants have at least a test score of like 90 percent or something you know and then they would say the bottom 25 percent for applicants or our admission or admitted students or something like that have a test score that is I don't know 70 percent or 75 percent or something like that and then the median test score is 85 percent so that's how you would go about quartiles is that you would have you know the lower 25% the middle 25 to 50 then you've got the 50 to 75 and then you've got the top 25 percent so the 75% to 100 and so you've got these four equal regions which also include your minimum value at the very bottom your maximum at the very top and in the middle you've got your median values so that's the value directly in the middle it's because you're splitting it up into four equal regions and so the value that separates the second quantile which would be the 25 to 50 from the third quartile which would be from 50 to 75 that value there would be the median value all right and so if we go into percentiles so percentiles that may have been a name that you you've probably heard before percentiles again an example of a quantile but instead of saying you know like a quartile we do it for for a percentile I mean splitting it into 100 equal segments hence the percentiles of the perks name at the beginning though that's that's kind of where or the percent you may have noticed percent means out of 100 or so that's if you are familiar with percent and that's also the same kind of reasoning where this comes from and so we've got percentiles which means splitting into you 100 equal segments and so on an example of this is often used in test scores so if you've ever taken something like the SATs or something like that then you get a test score but you also get a percentile and the reason I've done that is it's to judge not you versus the test but you versus everyone else and so if it's a difficult test than something like getting a test score of 60% but you're in the 95th percentile means your score is actually a lot better and so what you can say with percentiles for example is that every percentile that you're in means you're better than you know that's many other people so for example if you reach the 99th percentile that means you're better than 99% of the people that took the test the 95th percentile would be 90 you're better than 95% of the people that take the test or something like that and so that's why percentiles are often used for tests and they're often used for normalization because they allow you to take into consideration you know these factors of like is it a difficult test is an easier test maybe more people are scoring higher so they don't really judge you directly versus the test but they normalize you against everyone else that took the test so you take the test you get a score and then um the percentile checks where that score lies relative to everyone else and so these percentiles they allow you to give a good normalization and they allow you to do great comparisons because they allow you to kind of eliminate some of these factors of test difficulty and of course you know there can always be luck involved and stuff and that may not get filtered out on and visual basis but if you do this for a lot of students and that's also why it's done in these kind of big standardized tests is that you get a percentile along with your score so that you understand if you know maybe if your score is lower but the test was really hard you can still see you know I I did really well because people found this test really hard and it was even harder for them than it was for me in this tutorial we're going to talk about the importance of data visualization all right so what we're going to talk about is first we're gonna look at the role that the computer plays kind of for us and what role the computer is actually made for then we're gonna look at what role the human should play in terms of data science then we're going to look at presenting data and finally we'll talk about interpreting data alright so let's get started and talk about the role that the computer plays no computer is much much faster at calculating than human because that's what it's made for it's made for crunching numbers it's made for doing fast calculations you know if you think about how faster computers are there in the gigahertz range so Giga means billions so they just do billions of things every second and so they're really good for doing repetitive things because they can do them so fast and then we can give them these logical tasks in terms of programming and we give them a structure and they just do it and they can do it over and over and over again they're not gonna mess up I can just repeat the same thing they won't get tired of it and they're really good and they're really fast at doing these things so that's the role that the computer should play for you it should be kind of a means to get these hard number crunching and all of these things done so there's there's really no need for you to kind of work out all this complicated math because your computer can do it much better and much faster than you and it's also less prone to error if you code it correctly so that's kind of the only part where you come in and it's only gonna mess up if you mess up but generally our computer does exactly what we tell it to do and it's really good and it's really fast at it now what role should a human play in terms of data science well humans have naturally developed to identify patterns and we've done this first for survival so that if we're walking around somewhere and we see a I don't know a big predator or hiding that we can identify that pattern of the predator and we can kind of pick it out even though it's trying to camouflage itself so humans by nature have become very very good at identifying patterns and you can also see this if you look at the clouds and you see things where you see animal shapes and the clouds or other things so those patterns aren't actually there but humans have become so good at identifying patterns we can see things in many many places and so that's what humans are really really good at we're able to look at things and we're able to pick out patterns now another thing that's really good for humans is we are very creative and through their creativity we can also use memory and bring it outside knowledge and we can also use a general understanding so these are all things that computers can't do so computers are kind of a means of getting stuff to us but once it's actually there it's our job to use our pattern recognition abilities and of course you can train machine learning algorithms for specific patterns later on or specific cases and make them really good at that but generally if you don't know exactly what's gonna come then our or your first step as a data scientist would be to try to identify these patterns use your creativity use your memory you know bring in all of these different things use all of these different things that make you human and use all of that on the data all of these things that a computer just doesn't have any access to okay so usually you know you're considering all this the best way to do all this would be in terms of data visualization so you can't just show spreadsheets with a bunch of numbers that won't really help you because looking at numbers it's really hard to pick out patterns the best way to do it would just be to plot values and then if we have these visuals in front of us then you know we can really identify we can see things go up and down and you know we can see them fluctuating and we can see them make very thin lines we can just look at a graph and we can just see things and of course you know we need a little bit of practice to understand what that graph is trying to tell us but once we understand the graph and in general then you know we can look at new grass and we can just see things so we can start to see patterns and they may not always be true but that doesn't mean you know and we can't pick them out and then that's later on you would also do some testing trying to see if those patterns are true if they make sense but generally data visualization is very good for this because it allows you to invoke all of your human characteristics the things that are really good that you know make us human the things that we talked about and the last slide all the things like the computer can't do and sometimes you know you if you deal just with just these numbers it's data visualization is for you and one sense so that you can see these things and try to pick them out I use them later on but also if you're trying to show these things to other people so maybe you have to do a presentation in a kind of summary then you want to make sure that your data visualizations are good because the people that are going to be looking at it are much much less trained looking at data and analyzing data than you are and so if you try to convey them a message and just show them a big spreadsheet with numbers and just point out like here look look look these numbers you know they pop up and they're gonna be like what are you talking about so that's why it's really important to have really good data visualization skills one of them is to enable you to do your job but the other part of it is to show it to other people and to kind of help you convey information to them you know and of course we talked about statistical values and statistical values are very important and they can give us a kind of good idea about the data and what's going on inside of the data but visualizing data is just taking it to the next level and statistical values aren't enough there they can give us you know they can help us they can support us they can give us ideas but if we really want to understand what's going on sometimes we just have to take a look at what's going on and of course they are it's also important to make sure you choose the right visualizations and everything because other times you know may just look extremely weird but just this skill of being able to present data both for yourself as well as for other people is very very important for a data scientists and then we go over to interpreting data and we've kind of touched on this in the last section already but really with data visualization it just allows you to see this data and it allows you to apply some reasoning to the system and so you can if you look at data either you see something which is great you know that means you can try to test something see if it's actually there or you don't see anything and that also tells you something that you aren't really able to pick out a pattern so that there isn't there isn't anything obvious that's going on there may be something underlying that's more complicated but obvious to the user you know it's not there and so all of these things allow you to you know kind of easily or much more easily analyze your data and kind of prepare what are you gonna do after that so this data visualization it really gives you a deep deep understanding of what's going on with your data and then when we interpret this data and we look at these visualizations you know maybe you see dips and you know maybe you see some hills somewhere we can try to understand all of this by bringing in our outside knowledge so again what the human is really good at we can you know bring in the context of things you know maybe people are going out to lunch here and so that's why activity decreases or maybe everyone is coming to work in the morning and so that's why activity increases compared to you know 6 a.m. so all of these things we can bring in all of this context we can bring in all of this understanding to try to interpret the data try to better understand what's going on and then of course we're gonna see hopefully some trends or patterns of course like I said these may not always be there so we're actually so good at pattern recognition that we can see sometimes patterns that aren't really there and so a good example again of this would be just looking at the clouds in the sky and you can see animal patterns maybe but that's really not there that's just our minds you know identifying all of these patterns and so yeah that's that's pretty much why data visualization is so important to a data scientist it's because this whole you human aspect is it's just key in data science it's key and data analytics to be able to understand what's in front of you to be able to understand these this outside knowledge to be able to contextualize this creativity that's really key to a good data scientist and a computer can help you with all of this the computer can help you you know do the number crunching a computer can help you set up the visualizations and it can plot whatever you want for it but ultimately it's up to you to choose the right visualizations to do to look at the data to be able to communicate the visualization as well all of those things are up to you and so that's why the human is so so important in data science in this tutorial we're going to look at one variable graph so we're actually going to see some of the types of graphs that we can do you know that we talked about in our last tutorial where we just looked at the importance of data visualization so now we're gonna go into data visualization and look at the types of grass that you may want to use or that you may want to choose from all right and so the graphs that we're gonna look out in terms of one variable graphs are gonna be histograms bar plots and pie charts so let's get started with histograms now we can see an example of a histogram on the right but what's really cool about histograms is that it shows us the distribution of the data and it shows us the distribution across all the values in our data and so it shows us what happens the least and it also shows us what happens the most and histograms it they let us see where our data is concentrated and they also let us see how its distributed and so the through this it kind of shows a general behavior and so really what histogram is is it looks at each value and it just looks at how often the value has occurred and so what we see here for example is that around 0 you know we have the most occurrence of whatever value we're looking at and as we move to the left and as we move to the right these values start to drop off so they start to become less frequent and so that's what histogram shows us they the istagram shows us a kind of frequency how often these things occur and so there are different types of histograms that you can encounter or I mean generally a histogram is just this plotting of frequency versus your value and so there are different ways that this histogram can look like one of them is the one that we've just seen which is a normal distribution or it's called Gaussian like histogram because it follows this Gaussian distribution or this normal distribution that you know but we can also have like an exponentially decaying value so we start off very high and the further we get away from that initial value the quicker it's then it gonna decrease and you can actually compare that to the Gaussian like or to the normal distribution so the normal distribution looks more of like a bell it kind of goes up and then curves down slowly whereas the exponential it cuts off very fast and then kind of slows down later on so they do have different behaviors and then of course you know we can also get not just one peak like we see in this first case and the Gaussian like distribution but we can also get things like two peaks or we can even get three peaks or more we can have very large extended peaks and so our histograms there are means of showing us how this data is distributed there are means of showing us you know what things occur most frequently where is our data concentrated but that don't that doesn't mean that they're gonna have to have a specific value and so they're or your specific shape so there are many different shapes that our histograms can take on and depending on what shape that you get that also tells us something very different about our data all right so the next one variable plot that we'll look at is going to be bar plots and so what bar plots do is they may look a little bit similar to histograms at first but they are very different in some sense because bar plots allow us to compare across different groups and so that's what we see on the xaxis down there is we look at different groups and so we use the same em but we can compare that variable over different groups and so if we look at that in example so what we see on the right here is we look at different countries and what we show is we show the average income tax and so we see that country B for example has the highest average income tax whereas country D has the lowest income tax so through this you know we're still only looking at the income tax variable but we are able to compare us over different groups over different categories if you will so other examples would be if you look at control groups and test groups or if you're doing some like medical study or maybe some psychology study or something like that you always want to have your control group and then you can have different types of test groups and then you can plot each of these groups as a bar plot and you can look at the same variable but you can look how that changes over the different groups another example would be something like comparing male versus female heights so you've got one group that's male the other group that's female and you can just plot their average height and then the tax the income tax of different countries which is what we seen on the right over here all right and so the last one variable graph that we're gonna look at is gonna be pie charts and what pie charts are allowed to do is they allow us to section up our data on the and then we can kind of split it into percentiles and because of this we can see what our data is made up of so the whole pie corresponds to a hundred percent and then we kind of cut it down at different slices and through that slicing and then hopefully also color coding like we've done here and maybe even labeling or most definitely labeling so that you know what slice corresponds to what value we're able to see what categories you know or what what categories our data is made up of and so we can see what is most prominent but we can also see what is at least prominent in all of these things and then again here we can see also distributions not as well as in the histogram but we can still see distributions in terms of dominance in terms of how many groups there are is the data spread evenly is it you know heavily concentrated in one part of the pie all of these things allow you know is that's what we're able to do with pie charts we get this nice kind of group overview of one variable so examples of this would be you can look at NASA D distribution in a university and so you can have a pie chart and just each slice of pie which is to represent a different ethnicity and depending on you know how much of our percentage they make up the total University profile that's how big the slice of pie would be and so you can see dominance of some ethnicities as well as you know minorities but you can also see just by how many slices that are you can see how many different ethnicity groups there are and another example would be you can split up star reviews for a product so rather than you know looking at the average mm star review you can also just use a pie chart and you can see how many of my reviews are 5 stars how many of them were 4 stars 3 2 and 1 and so there you can again also get this nice different overview of how the review system would work now we're going to talk about two variable graphs so the graphs that we're gonna look at are gonna be scatter plots line graphs 2d histograms or twodimensional instagrams and box and whisker plots alright so let's start off with scatter plots now for a scatter plot what we're doing is we're really scattering all of our data points onto a graph and so pretty much every data point that we have we kind of put a little dot onto it on the graph and scatter plots are great because they allow us to see spread of data between two variables so we're always plotting one variable on the xaxis and another variable on the yaxis and it just pretty much allows us to see how the data is distributed for these two variables and then through that we can also see more dense areas we can also see some sparse areas and we can also look at correlations so maybe you remember in the lecture we talked about correlations we were able to see through scatter plots where those correlations where or weren't any correlation so all of these things that's what scatter plots are really really nice for in scatter plots of course we can also use them to have like we see here little clusters so not everything needs to be connected by a line or a curve maybe something is more like a circle and so that's what scatter plots can show us too they can kind of show us these groupings and we see one cluster here but maybe you know you have bigger plots and then there would be smaller you know like ten little different groupings for different things so it's got our plots are really great for that because they just show us where the data points are located for these two variables and then we can you ourself see you know like how how do these look like do does one variable affect the other is there may be certain groupings that we can see where our dense areas where it's sparse where are things concentrated you know is everything spread up all over the place is it very very narrow and only in specific region scatter plots allow us to see all of these things very easily and so some examples where we could use scatter plots would be if we see if we look at the graph on the right we can look at something like a car price versus the number of cars sold so each of these data points pretty much represents a car that's been sold and then the xaxis tells us the price that the car has been sold at and the yaxis tells us the number of cars that that have been sold at this price and so what we see here for example very easily is that the more the car is priced the less it gets sold and then maybe you can think of that in terms of well the more its price maybe people don't want to buy such an expensive car maybe they found a cheaper version of it so maybe it's just a branding thing which is why it's more expensive maybe there's something just as good quality that's cheaper maybe people just don't have enough money so that's probably a big factor to that people just don't have enough money to buy these expensive cars and so that's why they drop off and so it may look a little bit different in terms of profits but the higher the car is priced the less we see it being sold so that's one example of a scatterplot then something else that we can look at is maybe the income versus years of education so only we would look at on the xaxis how many years someone has been educated and then we would look at that current income and that would just be a point on the on the graph and we can do that for many many different people and then we can see how different education for different people how that affects their current income so that's another thing where we can do a scatter plot for we can also go back to one of the earlier examples that we used very early on where we talked about people traveling to work and we can just plot the distance traveled versus the time it takes and travel to work and then we can see you know maybe some people travel faster it could be that some people travel the same distance but one takes longer than the other because one goes by car the other one goes by bike the other one takes public transport all of these things so all of that we can see in these scatter plots and just kind of take into account these different situations and see how that all looks for the more for the general population of our data or just generally for our data so scatter plots are really really great as a kind of first goto just also identifying trends identifying regions and just giving a good overview of your data now the next thing that we'll look at is going to be line plots and line plots in some sense are kind of similar to scatter plots so we have the same bases of the X and the y axis but the points are connected and now it's very important to know when to choose line plots and want to choose scatter plots so line plots can carry a lot of advantages with them because this connectedness it makes it very easy for us to see trends because we can see where are these lines go not just trying to connect the points in our head you know like kind of connect the dots but that's exactly what I'm a line plot does is it connects the dots for us and so we can see these lines it's great if we want to see an evolution of something so maybe we want to see an evolution over time maybe you want to see an evolution over space and evolution with people something like that just if our data points are connected it's great to use a line plot so if we know that whatever happened before is connected to what happens and it's great to use line plots because line plots show us how things evolve because they're all connected as a line but if we're to do scatter plots and we just kind of plot points randomly and just because if we go back to or our kind of car sold car price example just because someone bought an expensive car or if we look at the expensive car and it's been bought say like five times and we look at a cheaper car it's and bought a hundred times there isn't really a logical connection to make between the two and so if we were to use line plots where we should use scatter plots really what we'd see is just a bunch of lines all over the place and so that's why it's important to kind of know when to use lime stalks and want to use scatter plots because it can be very very helpful if you use a scatter plot instead of a line plot it's gonna be a bit more confusing because you have to try to connect the dots yourself in your head but if you use a line plot instead of a scatter plot it's gonna look really weird because there's just lines all over the place and you can't really see anything so an example where we could use line plots is you have the typical distance versus time so you can look at you know how far someone or what time it is and then you know how far someone has traveled just a general curve of distance versus time that's very very common and you can look at the profit of a company versus the number of employees so the more employees they imply employee how does that change their profits so of course they have to pay the employees more but maybe the employees can also do more work and hopefully you know that kind of cancels out what you pay them and then increase this company profits and then what we can see on the right here is we can look at your creativity and how that changes with stress so you can see that the more stressed out you are the less creative you are and here it's also good to use a line plot because you kind of gradually advanced and stress and so each point and stress is kind of related and the higher you go up and stress the lower you go down in creativity and so there's this kind of relation where we can see this evolution so the more you get stressed out the less creative you become and so line plots are really nice here because there's not this chaotic movement everywhere but it's very nice and it's very easy to see this line it's very easy to follow okay so the next graph that we can talk about is 2dimensional histograms now we've seen onedimensional histograms in the last tutorial where we looked at the spread of data and we looked at the peaks and how you know things were distributed to the right and to the left but we can also do a 2dimensional histogram and so what a 2dimensional Instagram is it's a onedimensional histogram but it's a pretty much a histogram for every single point of the other variable that we're looking at so really what these things allow us to see is they allow us to see how the different distributions of the two variable is relative to to another so we can see here for example in the red region that for those specific values them they happen a lot so that combination of values happens a lot and so we're able to kind of pinpoint these frequency occurrences again and we're also able to look at dropoffs but we're able to pinpoint that to two specific values now rather than just 1 which is what we did to the 2d histogram and these things are much harder to see in scatter plots because in scatter plots if we have a value occurring a hundred times it would just be the same dot and the dot wouldn't get bigger now of course you can make the dot bigger yourself if you wanted to or you could change the color or something like that but really if you do a scatter plot and the same thing happens a hundred times it's just gonna look like one dot whereas for twodimensional histograms we can see that it's not just you know it's not just happening once but we can actually see the frequency of those variables or those those two variables together so an example of a twodimensional histogram would be if we look at ticket prices versus tickets sold and so if you look at the lower left corner and we can kind of see this red peak so that's cheaper ticket prices but the tickets are also sold often so we know that tickets at that price are sold quite often and these could be you know like new rising brand bands these could be like you know you kind of standard bands that maybe you want to take someone on a dayto but you don't want to spend much money on a ticket but still a concert is a nice idea and so that's a good ticket price that sells a lot of tickets because it gives you the pleasure of the event without making it too expensive and then if you move more towards higher ticket prices and then if you move more towards more tickets sold then you can see that for high tickets high ticket prices which would be you know like these big bands then we can again see how many tickets we've sold so we can see that for you know a higher price and if we go up and ticket sold so if you want to see lots of tickets sold for a high price then the red Peaks are gonna give us all of these more famous artists so that's you know one kind of application but of course there are many many better ones it's just these things you know if you're in the moment and you you can kind of then you would realize oh this is when a twodimensional histogram would be a great thing for me to use so a lot of these graphs they're great to know and once you're in the moment then it's much easier for you to pick out which graph would be best representative finally the last graph that we're gonna look at is gonna be a boxandwhisker plot and I want box and whisker plots allow us to do is they allow us to see the spread within our data so it's not just like a bar plot which just shows us one value but we can actually see the statistical spread so we can see median values which is what we see here we can see quartiles the little dots on the outside actually show us outliers and so what box and whisker plots allow us to do is they allow us to see the statistical information but they allow us to see it visually and that makes comparing across different groups which is what we're doing here much easier and so a good example of that would be if we look at ticket prices for football games for different teams so we have different teams and different teams of course use different stadiums and there they have different popularities and some teams may be much more expensive or the ticket prices may be much more expensive than other ones and so we can compare these ticket prices using box and whisker plots and then we can see you know what is the higher end of these so those are gonna be the more luxurious seats and then we go to the bottom and those are going to be the less luxurious seats probably the ones where you stand and then you have middle values depending on you know the standard seats and where you are in the stadium if you're close to the field if you're further away from the field but you're still sitting all of these things we can kind of see here and that's what gives us a spread we can compare that across different teams and we can see the spread across difference teams we can also see which teams are more expensive you know where do the prices vary the most for specific teams and maybe some teams have a super launch and then they have your you know standing places that are just much cheaper and so you would see a lot larger spread or maybe some teams just have you know only seats and see you'd see a much lower spread and so all of these things were able to compare using boxandwhisker plots over different groups in this tutorial we're going to talk about 3 and higher variable graphs so the graphs that we're gonna look at are is gonna be heat maps and then we'll also look at multi variable bar plots as well as how we can add more variables to some of the lower dimensional graphs that we've talked about earlier all right so let's start with heat maps now what heat maps allow us to do is they allow us to plot two variables against each other and the X and the y and they laws to show an intensity or a size or something like that in the Z direction or towards us so an example of this which is kind of what I've tried to illustrate on the right is a customer moving through a storm and so we can track the path of the customer in the X and y direction of the store so you can kind of get this bird's eye view and see where they move to and the darker spots actually tell us the positions where they spend more time at so we can see that they spend a little bit of time you know at the beginning they moved in and then they stopped lunch was what we see with dark spot being maybe they found like the candy aisle or something there was a specific piece of candy that they wanted and then they moved on and then they started to go towards the corner around the corner a little bit and maybe they reached the fruits in the vegetable section there and picked out several things and then they started to head towards the checkout counter which happens at the very end and they were moving at a more constant pays sometimes they stop to look a little bit but they just kind of continued moving on and so the three variables that we've shown here as we've shown their exposition in the store we've shown they're by position in the store and to their color we've also shown the time that they spend at each position so that's what we can use heat maps for and then another example the heat map would for example be if you take a flashlight and you move it over the screen and really what you're showing is the amount of time that you've shown the flashlight onto a specific region so that's kind of another example the heat map but usually heat map as the name implies it allows you to track positions and so it's very often used for things like tracking customers through stores or just tracking general people location where they like to spend their time and the intensity that you see in terms of the color is usually the amount of time that they spent there all right so we can also do multi variable bar plus a multi varied bar plot and so it is very similar to a single bar plot where we just plotted one value over different groups but rather than just plotting one we kind of cramped them together and we plot several and so an example of this would be that we plot you know goal scores I'm goal scored 14 the shots taken on goal as well as the shots on target and so we can see maybe there are teams that shoot less on goal without score less but that's because they also shoot less and therefore they also shoot less on target or maybe there are some teams that do score a lot and that's because they shoot a bunch but they just don't hit the target that often or maybe there are really good teams that score a lot and they also shoot a lot on target and so all of these things were able to then compare over different groups and so that's what we can use multi variable bar plots for if there are several variables that would give us a better understanding of the system than just looking at the variables in one at a time but it also be really cool if we could compare all of them then we could use multi variable bar plots for that and just plot them on the same bar plot and then we can see how they change you know within a group we can also see how they change over different groups okay and something that we can do is we can also just add extra dimensions to lower dimensional graphs that we've had and so we're kind of limited to three dimensions because that's the amount of space dimensions that we live in but if we take a scatter plot for example where we started off with just the X and the y axis and points located what we can do is we can actually add a third axis so we can take the X and the y and then we can add a Z and that gives us an extra depth dimension which is exactly what we see here so rather than just plotting unlike a two dimensional field unlike a plane we even actually plot it in a volume and so we can see this kind of scattered ball that we've done kind of kind of all that we've done here which is kind of located at the center of our plot and so this can be really cool because it allows us to see depth to the problem with this is that we have snapshots every time and so really we're looking at twodimensional snapshots and so to get the best understanding of this we need to rotate our scatter plots or our plots as we do them so that we can also add in our depth perception because right now for looking at it it may look threedimensional but really it's just a twodimensional snapshot and to get the best understanding if our scatter plot is located more towards us and more towards the left or something like that or maybe it's just really high and close to us or maybe it's really low and far away to understand all of these things we need to be able to rotate our scatter plot so that we can see it from different angles which then gives us this depth perception and we can do the same thing with 3d line graphs so here we see an example of maybe the position of a skier as they're skiing down a hill and then we can kind of trace that through time and we see that they're kind of they're going down the hill in this nice exact motion as you should and we can just track their position over time so here we've added this extra dimension to the 3d line graph rather than just taking maybe a time and a position at a time or something like that we've added a second positions or actually even a third position so we've got the X to the one there's that position and then we just trace it and over time and so that gives us this whole line here and so that's how we can take these lower dimensional plots that we've looked at before and we can just add extra dimensions to them if we want as long as it's still easy to see as long as it makes sense what we're looking at yeah we're really just able to maybe just slap on another direction there and you know compare another variable in this tutorial we're going to touch on the third major section that is really great for data scientists or that should be an essential of data scientists which is the ability to program okay and so why do we program well there are different reasons why we want to be able to program the first one is going to be the ease of automation the second one will be the ability to customize and finally it's because there are many great external libraries for us to use that it would just make our job so much easier alright but so let's get started let's talk about the ease of automation for us what do I mean with that well being able to program it really allows you to prototype really fast allows us to automate things and it also gives us the extra benefit if if we have something in our mind we can just take that and kind of put it into the computer by programming it and so we're able to automate everything very fast and we don't have to do these repetitive tasks you know maybe copy pasting stuff into or from Excel or all these things and if we just want to repeat something or we want to quickly change something up and just change a small thing we don't have to do a lot of stuff we can just change that in our code and then click play and let the computer take care of all of that for us rather than us having to do everything manually so it's very easy for us to automate things um and also for doing reports it's very easy to automatically create these reports you know all you have to do is set up your program to deal with the data that you're going to give it and then I can automatically create reports every week and the reports can be different because you give a different data and it should still look the same but the data the values can be different and so that will just automatically create all these reports for you and you don't have to do that all yourself the program does it for you but you've built the program and you're giving it this different data so you're still doing all of the analysis it's just you get to skip the part of copy pasting and like looking across and taking over the values and doing all the formatting of just doing the same report over and over and over again all of that is taken care of for you and all you have to do is just put in the right data you know write out everything that you want to do and then click play and let the computer handle all that for you because remember that's what the computer is doing and good at doing doing these repetitive tasks okay we also want to be able to program because it really allows us to customize it's very easy once we go into data analysis and when we see things that we get these ideas that we want to expand or different directions that we want to progress our analysis into and being able to program it really just allows us to take all that and put it as a code and just choose that direction and we can very easily dive much deeper into our analysis and discover things fast because it's up to us to where we want to go and so this ability to customize with programming it's it's very very important because we're not reliant on anything else we're not reliant on you know some software and maybe it breaks down or maybe we don't know how to perfectly use it and we have to read the manual and read a like a Help section and know we know how to program and we just type down exactly what we want to do exactly where we want to take it exactly what we want to see and we can customize very very fast with that we can also prototype very very fast with that and maybe if a visualization is not working to turn a scatterplot into a line plot it's very easy you just change one word so all of these things are very very easy to do with programming because we have all that power at our fingertips and we can just you know change everything that we're looking at everything that's being calculated maybe we want to calculate an extra thing and take out something else because it's irrelevant all of these things were able to customize and all of that we can do because we're able to program so really what we're doing is we're making the data ours so we're taking full control of the data we're taking full control of where we want to go with our analysis what we want to see and what we want to show all right so let's talk about first libraries but also give you two great Python libraries that you should you know maybe feel comfortable with or that you should maybe consider using for data analysis so first of all what are libraries will libraries are pieces of code have been prewritten by others that you can just take in and use and so a very good example of this is something known as a math library and so that has all the square root functions taking to the power you know taking the exponential the sine the cosine all of these things that you know and you want to use but you don't want to program yourself so like it pretty much avoids that middle step of you having to program the equation to calculate a sine because all of these things those are things that we don't want to do we don't want to get distracted from our target we want to be able to do exactly what we want to do without having the program completely other stuff and so that's what libraries are great for they're developed for by the community for everyone to use you know everyone is helping each other and these libraries they just bring a lot of power with it and so one of these libraries is called pandas and pandas is pretty much like Excel but it allows us to do or we can do programming with it which just makes it so much better because we can do things so fast with it we can do all this customization we can do all this automation whereas you know like Excel if you give it too much stuff too much to run it would just start to crash because it has to handle all of this other things all these other visual things you know the UI and there's a lot more it's a lot it's not a structure as well whereas in programming the program you know your computer just goes through everything stepbystep it doesn't have to take care of all of these visualization things it just does the calculations down below but we can still do all sorts of data management with them so we can shift our data around we can drop columns we can split things up you know we can split things up our row we can pick out certain rows we can even do statistical calculations on our data so we can say you know hey calculate the mean for this we don't even have to you know make our own formula for calculating the mean or for calculating the standard deviation or for calculating correlation between different columns all of that can be done with pandas with just a you know a couple of key words and so it's really easy to do data analysis with it because all of the functions that are there and we know exactly what we want to do but we don't have to write the code for all of it so if you wanted to look at correlations we just say hey pandas do correlations rather than having to you know code all the correlations for ourselves and doing you know coding that whole algorithm and that makes it really easy and really fast to get results and to get to where you're heading because you don't have to go into any of these mineral places you can pretty much just skip the middleman of having to you know write all of those algorithm to yourself and you can just use them so that you have your start you have your idea you know exactly what you want to do and you can do exactly that to get to your goal the other library that is very cool would be matplotlib which is what I use a lot for data visualization it allows me to create graphs allows me to visualize my data allows a bunch of customization so I can really just move everything around in it I can move my spines I can turn things on and off you know all of these things are very easy to do with MATLAB there's a lot of great customization that I'm able to do with it so these are like kind of two basic Python libraries that you should probably maybe get to know em or you can look at some of my other courses and one of them pandas would deal with the data analysis part and matplotlib would help you deal with the data visualization part of it so that's it that's a super basic breakdown of the three main components of the otherwise vague term data science if any of this has piqued your interest then you may have a data science future ahead of you and I encourage you to continue to pursue your interest if you want to learn more from me I've got a blog on my website coding with max comm that dies more into different topics related to data science you can also get access to some of the resources such as cheat sheets and workbooks that I've compiled for you there if you're serious about learning data science you can also check out my courses on data science which are designed to teach you all you need to know about data science even if you have no prior experience of course if you have any questions that aren't answered at my website you can always feel free to reach out me personally
