With timestamps:

00:00 - hey this is Andrew Brown over here on
00:02 - free cocam bringing you another free
00:04 - Cloud certification and this time it's
00:07 - the hashicorp terraform associate
00:09 - version three and the way we're going to
00:11 - achieve certification is through lecture
00:14 - content Hands-On labs and as always I
00:17 - provide you a free practice exam and so
00:20 - at the end of the day you're going to
00:21 - get that certification and you could put
00:23 - it on your resume on your LinkedIn to
00:25 - demonstrate that devops skills and try
00:27 - to go get that cloud or devops role
00:29 - you've been looking for or trying to
00:31 - upgrade to so if you like the materials
00:35 - here a great way to support more content
00:37 - like this is to look at the paid
00:39 - additional materials it will also help
00:42 - you increase the odds on your exam and
00:45 - it also really does help out and support
00:47 - the production of more of this kind of
00:49 - content and if you are not familiar with
00:52 - me I produce a lot of different kinds of
00:54 - cloud certification courses like AWS
00:57 - Azure kubernetes you name it I've taught
01:00 - it and so you're in really good hands
01:03 - and we'll see you in class soon ciao
01:06 - foreign
01:06 - [Music]
01:11 - everybody it's Andrew Brown and welcome
01:13 - to the start of our journey and we're
01:15 - asking the most important question first
01:17 - which is what is terraform and I just
01:19 - want to tell you that I'm on screen now
01:21 - but I'm going to vanish here shortly and
01:23 - stay out of the way so that you can see
01:25 - the full content but I just wanted to
01:27 - know you to know that I'm here with you
01:29 - the entire way okay so the terraform
01:32 - associate certification is a specialty
01:34 - certification in terraform terraform is
01:37 - a technology produced by hashicorp and
01:40 - it's specifically for infrastructures of
01:42 - code and it's a declarative
01:44 - infrastructure as a code and it's a
01:45 - cloud agnostic infrastructure as a code
01:47 - we will dive into all of this in great
01:50 - detail in the introduction section and
01:52 - just notice that I put an asterisk there
01:54 - on declarative because there is
01:56 - something special about terraform that
01:58 - we will discover if you are considering
02:01 - the terraform associate then you most
02:03 - likely are looking for a devops role you
02:07 - want to automate infrastructure or
02:08 - writing scripts you want to work with
02:10 - multiple Cloud providers or you know you
02:14 - enjoy designing iterating on end-to-end
02:16 - infrastructure life cycle so if this
02:18 - sounds like anything that you are
02:19 - interested in then you would probably
02:21 - want to take this certification I want
02:24 - to tell you that terraform is one of the
02:27 - most in-demand skills for devops rules
02:29 - today and it's becoming quickly the
02:32 - industry standard just because it is so
02:34 - flexible and works with all providers
02:36 - and goes beyond a lot of these other
02:39 - tools and the terraform associate exam
02:42 - itself isn't that difficult
02:44 - uh but I would say that the concept of
02:47 - learning terraform is a bit tricky
02:49 - because uh you know it's not something
02:51 - that you can just go do the lecture
02:53 - content uh and and do the lab content I
02:56 - had to do a mix of it uh so in this
02:58 - course you'll see me do lecture lab
03:00 - lecture lab because I'm trying to
03:02 - solidify the knowledge as soon as we do
03:04 - that this is not the format that I use
03:06 - for my other courses it's just because
03:08 - with terraform it requires patience it
03:11 - is a silical learning process to
03:13 - understand so just uh stick with it and
03:16 - by the end of it you will be really good
03:18 - with terraform uh you know and so that's
03:21 - that there so let's talk about our
03:23 - multi-cloud roadmap I'm going to get out
03:24 - of the way so we have a little bit more
03:26 - room
03:27 - um and so you know what I would
03:29 - recommend uh is that you start with an
03:32 - Associate certification so just getting
03:34 - my pen tool out here uh if I can get it
03:36 - here here we have the Google's Ace
03:40 - um the cloud engineer or maybe some
03:42 - level of AWS uh associate certification
03:46 - I personally think the sysops is the
03:48 - best pairing for terraform or the Azure
03:51 - administrator if you're going for Azure
03:53 - and quite possibly learning more than
03:56 - two would be very beneficial but of
03:58 - course whatever your primary provider
03:59 - you're using is where you're going to
04:01 - benefit with uh terraform and you really
04:04 - should learn this stuff before you do
04:06 - terraform it is super hard to learn both
04:09 - cloud and terraform at the same time you
04:12 - should have that Foundation before you
04:13 - tackle onto terraform and so there's a
04:16 - lot of different paths for multi-cloud
04:18 - and just to kind of give you an idea of
04:19 - all the different ways you can go you
04:22 - know you can go from associate to either
04:24 - Vault and to the Vault professional if
04:26 - you're looking at a security background
04:28 - but it's very common for people to get
04:30 - the terraform and then go for
04:32 - uh Vault afterwards but you know it's up
04:35 - to you to which path you want to take
04:37 - how long do you have to study to pass
04:40 - this exam well uh it's a spectrum based
04:43 - on where your background is so let's
04:44 - take a look at beginners first so a
04:46 - beginner to me would be someone that's
04:48 - never written IC uh they have not
04:50 - previously focused on automating
04:51 - infrastructure they might may not hold
04:54 - an associate level certification so
04:55 - you're adding those additional hours or
04:57 - trying to make up the difference you
04:59 - could be looking at 30 hours or more if
05:02 - you're already experienced with writing
05:05 - IAC but maybe just not terraform maybe
05:07 - you know Azure bicep or cloud formation
05:09 - you already work in devops you're
05:12 - already comfortable writing scripts and
05:14 - you hold associate level certification
05:16 - knowledge of you know a major cloud
05:18 - provider then you're looking at
05:20 - something like 12 hours but you know if
05:22 - you're looking for a general study guide
05:24 - somewhere in between I would recommend
05:26 - between one to two hours a day for 14
05:29 - days and you'll be in a really good
05:31 - place by then you know what does it take
05:33 - to pass this exam well there is a
05:36 - lecture content and I have a lot of it
05:39 - um you know the thing is that
05:41 - the exam itself is very practical it's
05:44 - not like AWS aws's exams where it's very
05:49 - um uh Theory based at a conceptual level
05:51 - this one is very much how do we use this
05:54 - technology and so the lecture content is
05:57 - there to really support the lab content
05:59 - and you really really need to do the lab
06:02 - content uh because that's the nature of
06:04 - this exam
06:06 - um and to make this a lot easier I do
06:08 - recommend taking some practice exams we
06:11 - have a free practice exam and we also
06:13 - have uh many more practice exams if you
06:17 - take all these Pax exams and you've done
06:18 - the labs prior to that you're going to
06:20 - be in really good shape to pass in terms
06:23 - of the content outline
06:25 - um I can't remember how many domains
06:26 - we'll see how many there are but we have
06:28 - one so understand infrastructure as code
06:30 - so I see Concepts understand the purpose
06:32 - of terraform
06:34 - understand terraform Basics the use of
06:36 - terraform outside core workflows
06:38 - interact with terraform modules
06:40 - use the core terraform workflow
06:42 - Implement and maintain State regenerate
06:45 - and modify configuration
06:46 - and understand terraform Cloud
06:48 - capabilities so yeah nine domains uh
06:52 - something that's different about uh the
06:53 - hashicorp certifications is they do not
06:55 - provide distribution of domains what do
06:58 - I mean by that well they're not weighted
07:00 - right so it's not like uh we know that
07:03 - uh like eight is I'm going to have a
07:07 - particular weighting that's higher but
07:08 - we can look at the exam guide outline to
07:11 - see generally how many questions we
07:12 - probably would so we could kind of infer
07:14 - our own waiting but they do not provide
07:16 - it so I would just say it's not known
07:18 - but we'll take our best guess when we
07:20 - look at the full exam guide outline
07:23 - where do you take this exam well you can
07:25 - take it in an in-person test center or
07:27 - online from the convenience of your own
07:28 - home I do believe that the test center
07:31 - that hashicorp is using is PSI or PSI
07:34 - online and understand that this is a
07:37 - proctored exam so someone is supervising
07:39 - you watching you monitoring you as you
07:41 - take the exam so that you uh that
07:43 - there's no funny business happening
07:44 - there's no cheating and to ensure that
07:47 - uh you know that you gain gain that
07:50 - knowledge in a reputable way so just
07:52 - understand that in terms of the grading
07:55 - you need to get about 70 percent to pass
07:57 - or round that it uses scaled scoring uh
08:01 - is it possible for you to fail if you've
08:02 - got exactly 70 percent it might be so
08:06 - always aim to get higher than 70 percent
08:10 - um and so I always say aim for a target
08:12 - of you know 10 to 15 above what the
08:15 - score is if you're getting that on your
08:17 - prax exams then you're going to be in
08:19 - good shape in terms of the response
08:21 - types they don't tell you exactly how
08:23 - many questions there are but I've always
08:25 - observed there's 57 questions and so you
08:28 - know based on that calculation I feel
08:30 - that you have 70 17 questions you can
08:32 - get wrong there are no penalties for
08:34 - wrong questions so always answer your
08:37 - questions do not leave any blank the
08:39 - format of the questions is multiple
08:40 - choice and multiple answer and then
08:43 - sometimes you get a fill in the blank so
08:44 - type a one word answer most likely it's
08:48 - going to be a command right so or a flag
08:50 - for a command so you definitely have to
08:53 - know the technical components of
08:55 - terraform okay the duration of the exam
08:57 - is one hour so that means you get about
08:59 - a minute to answer per questions the
09:01 - questions are very short format so it's
09:04 - not like you have to read a ton of text
09:06 - to figure out what's going on the exam
09:08 - time is 60 Minutes the seat time is
09:11 - actually 90 minutes so when we say C
09:13 - time referring to the amount of time you
09:15 - should allocate for the exam so that
09:18 - means that would include things like
09:19 - time to review the instructions show uh
09:22 - show the online proctored your workspace
09:24 - to make sure there's nothing going funny
09:26 - on with your environment read and accept
09:29 - the NDA complete the exam provide
09:32 - feedback at the end and I'm going to
09:34 - tell you you really do want to get for
09:38 - your exam much sooner than you think
09:40 - because it is a very stressful process
09:42 - and things tend to always go wrong when
09:45 - when you uh when you don't show up early
09:47 - enough okay so just make sure you do
09:49 - that if you do pass this exam it's going
09:51 - to be valid for 24 months so that's two
09:54 - years before recertification and the
09:56 - last thing I just want to talk about is
09:58 - um well maybe not the last thing I got
10:00 - two more slides here for you but this
10:01 - course is going to be designed around
10:02 - the
10:04 - 1.1.6.0 specification of terraform
10:07 - and even when I'm making this course as
10:10 - of today 1.60 is an alpha this will be
10:13 - in the future so 1.60 will be out but I
10:17 - like to try to give you more knowledge
10:19 - in the future even if it's not an exam
10:22 - just so that you are prepared and this
10:24 - course does not go stale sooner
10:26 - terraform is always incrementing
10:29 - inversion so you know when you study you
10:31 - always want to go back three minor
10:33 - versions since I'm showing 1.60 it
10:35 - doesn't make a whole lot of sense but if
10:36 - you're let's say you're on 1.54 you'd
10:40 - want to do one you want to make sure you
10:41 - know terraform for a range of versions
10:44 - going a few versions back and so so you
10:47 - know I will be showing you things that
10:49 - may be deprecated but are still uh but
10:52 - might still be in use based on the
10:53 - version that people are using so just
10:55 - understand that
10:58 - um and again you know these these
10:59 - certifications are or the terraform
11:01 - certification is heavily dependent on
11:03 - your practical knowledge so if you are
11:05 - taking the time to apply the knowledge
11:07 - uh this version difference differencing
11:09 - is not going to make a big difference
11:10 - okay
11:12 - um so just make sure you know you put
11:14 - the time in with the labs
11:16 - um now this is the third version of the
11:19 - certification and so I just kind of want
11:21 - to tell you that not a whole lot has
11:24 - changed between version zero zero two
11:26 - and zero zero three uh the one of the
11:29 - big differences is they change the badge
11:31 - design why I don't know uh is it better
11:34 - who cares
11:36 - um but uh it is a different looking
11:38 - badge
11:39 - um one thing is that there were
11:41 - superficial name changes to the outlines
11:43 - of the domain so basically all the
11:45 - domains are the same they just kind of
11:47 - did some tweaks there they did kind of
11:50 - cut some content out in the uh the like
11:52 - first uh first first two domains because
11:55 - those ones were just more General
11:56 - concept of knowledge and so they slim
11:58 - those down I'm leaving that content in
12:01 - this course because I think it's very
12:03 - valuable to know more rounded knowledge
12:06 - there so you're going to be over
12:07 - prepared for those first two domains
12:09 - there used to be this thing called
12:12 - provisioners it's still in terraform but
12:14 - the thing is that it's just no longer
12:16 - needed to know in the exam so this is
12:19 - about doing remote execution annoying
12:21 - all the provisioners and so I mean local
12:25 - execute and remote execute are things
12:26 - you need to learn and definitely
12:28 - something that you will use on the job
12:30 - but knowing how to provision and use a
12:32 - lot of Provisions is no longer a focus
12:34 - there
12:35 - there's this thing called null resource
12:37 - that we learn about and now they have a
12:40 - new thing called terraform data so that
12:42 - is a evolution of terraform data so
12:44 - we'll still learn about null resource
12:46 - but we'll also learn terraform data
12:48 - where it makes more sense to use
12:51 - uh you know terraform Tate had taint has
12:53 - been replaced with uh just a flag uh
12:56 - called hyphen hyphen uh uh replace uh on
12:59 - the terraform plan and we have a few
13:01 - more others like that so refresh has a
13:03 - flag
13:05 - um and uh the thing was is that when I
13:07 - made this exam the first time they were
13:09 - already talking about doing this so This
13:10 - exam is already
13:12 - um my previous one is up to date with
13:15 - the current version of zero zero three
13:18 - if that if that's surprising here uh
13:21 - terraform workspace is no longer part of
13:23 - the exam
13:25 - um I would still cover terraform
13:26 - workspace uh you know if we come across
13:28 - it because I still think again it's
13:30 - practical knowledge that you should know
13:33 - um connecting to terraform Cloud now
13:35 - uses its own cloud block instead of
13:37 - remote block
13:38 - um I believe that we can still use
13:40 - remote block here and I will definitely
13:41 - test that in the in the
13:45 - um in the uh the labs in this course so
13:48 - you know it's good to know both of them
13:49 - but the focus will be using uh Cloud
13:51 - block
13:53 - um we have the lock file so the lock.hcl
13:56 - files are new
13:58 - um I mean they weren't new when I made
14:00 - the previous exam so they were already
14:01 - in there so again I already had this
14:03 - content here
14:05 - um but I'm just pointing out that that's
14:07 - something that they're focusing on uh
14:08 - within the certification here
14:11 - um you need to know how to Mark data as
14:12 - being sensitive again that's something I
14:14 - had in the older exam but one major
14:17 - thing is terraform cloud has a new UI
14:19 - and it looks like there's a lot more
14:20 - functionality so in terms of the old
14:23 - exam or a course that I produce and this
14:26 - one I'm definitely going to have to
14:28 - reshoot all of terraform cloud and go
14:30 - deeper into it there's obviously a few
14:32 - different functionalities that have been
14:34 - added like the terraform Cloud block the
14:35 - terraform data block
14:37 - um but you know for the most part
14:38 - there's not a whole lot that has changed
14:40 - so the majority of this will be very
14:42 - similar to the last one but I'm just
14:43 - touching up and improving lab content
14:46 - where we can and hopefully adding a lot
14:49 - more additional content to expand the
14:51 - terraform knowledge that I wasn't able
14:53 - to do the first time around so hopefully
14:55 - that gives you a good idea of what
14:57 - you're getting yourself into uh but yeah
14:59 - we will proceed forward to looking at
15:01 - the exam guide
15:03 - foreign
15:07 - Brown and welcome back as we are taking
15:10 - a look at the exam guide uh for the
15:13 - hashicorp terraform associate
15:15 - certification I want to tell you uh
15:18 - throughout this course I'm going to show
15:20 - you where I get things so I will be
15:23 - going to Google I will be typing in
15:25 - where things are it's not because I
15:28 - don't know where things are I'm doing
15:29 - that for your benefits so that you build
15:31 - up the skill to know how to find things
15:33 - just the way that I would go find things
15:35 - and I'll be very transparent about that
15:37 - so for this one all I did was go into
15:38 - Google and type in terraform exam guide
15:42 - and so I found it here this is also the
15:45 - place where you can register for the
15:46 - exam so if you click this it should load
15:49 - up certain metrics I'll make a pop-up
15:50 - you have to authenticate it I'm not
15:52 - showing that here right now but when you
15:54 - are ready to register for the exam you
15:56 - can go ahead and do that you'll notice
15:58 - they also have this button here called
16:00 - prepare for the exam they have their own
16:02 - study guide here it's very text based
16:05 - heavy I do believe that somewhere in
16:07 - here there is a way to launch tutorials
16:10 - and this will launch sandbox
16:13 - environments I think through instruct at
16:14 - least the last time I checked those are
16:17 - great if you don't have an environment
16:19 - set up what I want to do with you is I
16:21 - want I want you to set everything up in
16:24 - your own environment because I want you
16:26 - to have those Real World skills so you
16:28 - can use this stuff adjacent to this
16:31 - course I've gone through all this
16:32 - material here I'm trying to cover things
16:34 - that aren't in here and try to make sure
16:37 - that we are doing things without guard
16:39 - rails without the bowling bumpers
16:41 - because I want you get that Real World
16:43 - Experience okay but I do want to point
16:45 - out that this is here and you can use it
16:48 - um and it's okay so let's scroll down
16:50 - and take a look at our exam guide here
16:54 - and so here they say we have some
16:56 - prerequisites so they say basic terminal
16:58 - skills that makes sense we're going to
17:00 - be doing a lot of stuff uh in terminal
17:03 - basic understanding of on-premise and
17:05 - Cloud architecture uh I think what they
17:07 - really mean is do you know how to use
17:09 - AWS you know how to use Azure gcp what
17:11 - is your major uh cloud provider or or
17:14 - stuff like that um now I keep talking or
17:17 - focusing on AWS Azure gcp but understand
17:20 - that terraform can be used for anything
17:22 - as long as there is a provider for it it
17:25 - can provision on almost anything okay
17:27 - and that's why they're being very
17:29 - generic in their description this says
17:32 - the product version tested is terraform
17:33 - 1.00 and higher so it shows you that
17:38 - this is still even though it's the zero
17:40 - zero three it's still really the zero
17:41 - zero two exam with some minor tweaks but
17:44 - just understand in this course we're
17:46 - going to go well beyond this because I'm
17:48 - just future proofing you and making sure
17:49 - you have Real World skills let's scroll
17:51 - on down here
17:53 - and let's just it's about renewing your
17:55 - certification so if you hold an
17:57 - unexpired terraform associate 002
18:00 - certification
18:01 - uh you can take the new one starting 18
18:04 - months after your previous exam if you
18:06 - hold an unexpired one you can take the
18:07 - new exam starting 18 months after your
18:10 - previous exam uh if you hold an expired
18:12 - one you're eligible to recertify at any
18:14 - time I really like this because what
18:16 - happens for me with certifications not a
18:18 - problem for you but problem for me is
18:20 - that I will sit a certification and then
18:23 - nine months later the new one comes out
18:24 - and I can't sit the new one and tell you
18:26 - about it so it looks like we've gotten a
18:28 - bit of flexibility there and again I'm
18:30 - on video here I will get out of the way
18:32 - um it's just that we're in the uh these
18:34 - earlier videos and I want to just hang
18:35 - out here with you okay going down below
18:38 - we can confirm it's the one hour
18:40 - duration this is seventy dollars it
18:43 - might vary based on your location and
18:44 - other stuff you I just don't want to
18:46 - tell you that 70 I want you to go
18:48 - through the process and find out
18:49 - yourself but that's probably what it's
18:51 - going to cost you
18:53 - um there is no free retake included
18:56 - um some certifications like CompTIA you
18:58 - are basically or uh the kubernetes ones
19:01 - from looks Foundation you basically get
19:03 - a retake so you're basically paying a
19:06 - love for two and they call it a free
19:08 - retake which it really isn't free but uh
19:10 - I think this is okay
19:12 - um I think it's fine there's no retake
19:14 - it's in English expires in two years we
19:16 - covered that before let's take a look at
19:18 - the exam objectives so the first one is
19:19 - understand infrastructure as a code and
19:21 - Concepts they used to have a bunch of
19:23 - junk in here
19:24 - um and honestly I didn't even know what
19:26 - they were talking about when they said
19:27 - that I remember I had to comb through uh
19:31 - the study guide and try to watch uh
19:33 - articles and stuff like that but I think
19:35 - they realized
19:36 - that it was junk uh that they were
19:39 - trying to uh impart too much conceptual
19:41 - stuff and they cut back this one here
19:43 - same thing with two
19:45 - it doesn't show us the comparison of the
19:47 - old one at some point on this website
19:49 - they showed the comparative between zero
19:51 - zero two and zero zero three
19:53 - but all I'm saying is that they cut back
19:55 - here I have a bit more content on this
19:57 - in the course it's not going to hurt you
19:58 - to watch it it's just going to help you
19:59 - understand it but you're not going to be
20:01 - tested 100 on this stuff the other thing
20:04 - I want to note is that for each point
20:05 - that is here each subdomain or or Point
20:08 - whatever you want to call it they're
20:10 - going to ask you a question on this is
20:11 - very different uh way of Designing uh an
20:15 - exam uh other exams like AWS they will
20:18 - they will list a bunch of stuff but they
20:20 - say it might not be on the exam or it
20:22 - might have stuff that are that's outside
20:24 - of it so you just have to broadly study
20:26 - and uh you'll over over study for the
20:31 - content because you just don't know what
20:32 - you're going to get uh get on the exam
20:34 - for hashicorp exams they're very fair if
20:38 - you know each of these points you can
20:40 - expect to see them generally on the exam
20:42 - and that's how you're going to know that
20:45 - you are ready if you if you know all
20:46 - these things in this course we're going
20:48 - to go beyond that because again I want
20:49 - you to have those Real World skills but
20:51 - just feel confidence in knowing every
20:52 - single point Point here going down here
20:55 - understand terraform Basics install and
20:58 - version terraform providers so that is
21:00 - what we will be doing a lot of in this
21:02 - because we're going to at least touch
21:04 - more than one provider in this course
21:07 - I'm not going to go in great detail on
21:09 - uh the cloud infrastructure part of it
21:12 - because you're already supposed to know
21:13 - it
21:14 - um and I'm going to leave that for other
21:16 - things doing future projects for
21:17 - specific uh for for specific Cloud
21:20 - providers we're focused here on
21:21 - terraform in this course not the
21:23 - underlying providers but we do use
21:25 - multiple ones here describe plug-in
21:27 - based architecture write terraform
21:29 - configuration using multiple providers
21:31 - describe how terraform finds and fetches
21:33 - providers so you can see there is a a
21:36 - lot of stuff about providers not to be
21:39 - confused with provisioners I said
21:40 - earlier that provisioners is no longer
21:42 - covered in this certification course but
21:44 - again the materials here so you can
21:46 - learn it for real world practice use
21:49 - terraform outside of core of core
21:51 - workflows I think this used to be like
21:52 - you use terraform CLI outside of core
21:55 - workflows so they made a small tweak
21:57 - there so it says destroy describe when
21:59 - to use terraform import to import
22:01 - existing infrastructure into your
22:02 - terraform State terraform import is
22:04 - super super powerful going over to other
22:07 - providers uh you know for a long time
22:09 - AWS did not have an import option and so
22:12 - the idea is that by having this import
22:14 - we can bring an infrastructure that was
22:17 - not necessarily there before we have
22:19 - terraform state to view our terraform
22:21 - State something that you're going to
22:22 - find unique to terraform is State
22:25 - Management it's something that's super
22:27 - important and it's probably the hardest
22:28 - Concept in terraform because when you
22:31 - use something like cloud formation or
22:33 - Azure bicep the state is managed by
22:37 - services on those providers
22:40 - there isn't a managed service
22:42 - managed service on those providers and
22:45 - so you have to decide where you want to
22:48 - put your State uh and one example would
22:50 - be terraform cloud and that's one that
22:52 - we do use in this in this course here
22:54 - describe one to enable verbose logging
22:57 - and what the outcome is so you have to
22:59 - know how to debug things here which is
23:01 - great interact with terraform module so
23:03 - contrast and use different module Source
23:05 - options including public terraform
23:07 - module registry interact with modules
23:10 - inputs and outputs describe variable
23:12 - scope and module child modules set
23:14 - module versions modules is a way of
23:16 - creating reusable code
23:19 - uh we are going to use uh public
23:22 - libraries as well as uh make our own
23:25 - modules making modules is not as hard as
23:27 - you would imagine but they can get very
23:30 - complex uh so you know we're not going
23:31 - to go super Advanced into modules but we
23:33 - are going to make sure we can write our
23:35 - own and and use public ones use the
23:38 - terraform uh use the terraform workflow
23:41 - so this is something we're going to have
23:43 - to know a lot about which is just the
23:46 - general life cycle workflow of working
23:48 - with infrastructure as code so we have a
23:50 - knit validate plan apply destroy format
23:53 - plan it apply are the ones we're going
23:54 - to be using a lot of there is a lot of
23:57 - trickery with the init so that's
23:59 - something else that we'll do there as
24:00 - well Implement and maintain state so
24:03 - maintaining State working with State
24:05 - super super important so we'll look at
24:07 - how it works with local state state
24:10 - locking handling back-end Cloud
24:12 - Integrations authentication methods uh
24:14 - you know they're talking about managed
24:16 - providers like terraform Cloud
24:18 - the different between remote State
24:20 - back-end options manage resource drift
24:22 - and terraform State terraform is super
24:24 - good at drift and fixing drift it's so
24:29 - good at remediation compared to other
24:33 - IEC tools and that's why it is such a
24:36 - popular tool to use describe back-end
24:38 - block and Cloud integration
24:40 - configuration understand secret
24:41 - management and state files then we have
24:43 - regenerate modify configuration so
24:45 - demonstrate the use of variable
24:47 - variables and outputs describe secure
24:49 - secret injection best practices
24:50 - understand the use of collection and
24:52 - structural types create and
24:54 - differentiate resource and data
24:56 - configuration use resource addressing
24:58 - and resource parameters to connect
25:00 - resources together
25:01 - use HCL and terraform functions to write
25:03 - configuration describe built-in
25:05 - dependency management
25:07 - and the last one here is understand
25:09 - terraform Cloud capabilities so explain
25:11 - how terraform clouds helps to manage
25:12 - infrastructure describe how terraform
25:14 - Cloud enables collaboration government
25:15 - governance I'm going to tell you right
25:18 - now we're going to probably do more
25:19 - terraform Cloud than we we need to it's
25:21 - just because when I made this course the
25:23 - first time I I just lightly did
25:25 - terraform Cloud just enough to pass the
25:27 - exam I have the time to do a little bit
25:29 - more there I would like to do that for
25:31 - your own benefit and so we will expand
25:33 - on that a bit more but you can see this
25:35 - is mostly about terraform the technology
25:38 - not necessarily terraform Cloud the uh
25:40 - the service if you're confused about
25:42 - terraform and terraform Cloud uh again
25:45 - we'll explain that in this course and
25:46 - make sure it's very clear what the
25:48 - difference is one other thing I wanted
25:50 - to notice that you do have some sample
25:51 - questions here so you can go through
25:53 - here and you can just see that the
25:55 - questions are very straightforward and
25:58 - they're just like this they're very
26:00 - simple uh but you know you do have to
26:03 - know
26:04 - you do have to know what you're looking
26:05 - at and see like here they're showing
26:06 - code so you can see you have to choose
26:08 - code and you might get a code block so
26:11 - it is very focused on the Practical
26:12 - component of it it's less about the
26:15 - conceptual okay but yeah hopefully that
26:18 - gives you an idea of what we're getting
26:20 - into and we'll see in the next one okay
26:21 - ciao foreign
26:27 - hey this is Andrew Brown from exam Pro
26:29 - and what I want to do is walk you
26:30 - through a few of our practices and
26:32 - questions just to give you an idea of
26:34 - what it will be like on the real exam
26:36 - and where we might have had to make some
26:37 - adjustments to help your study so what
26:40 - you'd have to do to access this prax
26:42 - exam is you'd have to be signed up and
26:44 - logged in to the exam Pro platform make
26:46 - a way over to the hashicorp terraform
26:49 - course except the free tier or pay for
26:51 - full access but once you go there you'll
26:54 - scroll all the way down to the bottom
26:55 - and you should see three or four
26:57 - products exams at the time of writing
26:58 - this we're still writing the questions
26:59 - so that's why they're not shown in the
27:01 - video here but what I want you to do is
27:02 - to go to the first practice exam and
27:04 - notice that there are 57 questions you
27:06 - get an hour on on the exam here and we
27:10 - have a breakdown based on domain now the
27:12 - percentage is not something that uh
27:13 - terraform or hashicorp provides so we
27:16 - just had to break it down based on the
27:18 - coverage of questions that we saw in the
27:20 - exam guide outline and so that should be
27:22 - accurate enough and that's kind of what
27:23 - it felt like on the exam so I don't
27:25 - think that's going to be a problem if we
27:27 - click into here we're just going to look
27:28 - at some of the questions I'll talk
27:30 - around them so the first one here is we
27:31 - have how do you create a workspace and
27:33 - it's showing us a bunch of CLI commands
27:35 - and so on the exam you do need to know
27:38 - um uh you know CLI commands and the
27:40 - difference of them and the questions can
27:41 - be as simple as this where you're just
27:43 - choosing the option and some are obvious
27:45 - distractors like there isn't there is no
27:47 - one called terraform workspace Branch
27:49 - okay so just understand that you not
27:51 - just need to know the conceptual ideas
27:53 - behind terraform but also it in practice
27:56 - okay
27:57 - another one here would be the terraform
27:59 - registry can search based on the
28:00 - following Search terms we have an option
28:02 - to choose multiple questions and so this
28:04 - is something that you will see on the
28:06 - exam where you're choosing multiples of
28:08 - something I didn't get a lot on my exam
28:10 - but I cannot say for certain like how
28:11 - many questions would show up like this
28:14 - um but you know they're not really that
28:15 - hard to figure out okay and this
28:18 - question is about
28:19 - um a tool or sorry uh the public
28:22 - terraform registry website and that is
28:24 - just a uh a public-facing website if we
28:28 - go to
28:29 - registry.terraform.io here it's this
28:30 - website here so it's not just the
28:33 - tooling of terraform itself but it's the
28:35 - ecosystem around it so terraform Cloud
28:36 - the terraform registry things like that
28:39 - another type of question you will see
28:40 - and I think it's over here is what they
28:43 - will do is they'll ask you to fill in
28:45 - the blank now we don't have that support
28:46 - in our platform just as of yet but the
28:48 - idea is they'll say like okay uh we'll
28:51 - ask you a question or we'll even give
28:52 - you
28:53 - um maybe they'll have like underscores
28:55 - they'll say fill in this thing and
28:56 - you'll literally have to type type the
28:58 - answer in but the answer is going to be
28:59 - like a one word answer so on the exam I
29:02 - literally had a question which was like
29:03 - where is the API stored and it was
29:05 - actually terraformed at TF state but I
29:07 - did not know I could not recall the name
29:09 - of it which is kind of embarrassing but
29:11 - uh you know that is the level of
29:13 - fill-ins that you'll have to do and
29:15 - you're very likely to see some code on
29:17 - the on the exam two so if I just click
29:20 - through here really quickly you may see
29:22 - a code block okay and you might have to
29:24 - decipher it so that's the difficulty
29:26 - exam I would not say this is a heart
29:28 - exam but you just have to understand the
29:31 - scope of those kind of questions and
29:32 - make sure that you have well-rounded
29:34 - study in both practical and conceptual
29:37 - concepts of terraform so hopefully that
29:38 - helps you out okay
29:40 - [Music]
29:43 - everybody there it's Andrew Brown and I
29:46 - just wanted to tell you about the
29:48 - content that you're going through
29:50 - because honestly between the zero zero
29:52 - two and zero zero three there was not
29:54 - much to update
29:56 - um and so you know the key differences
29:57 - is the versions of terraform and the
30:00 - versions of the providers that you are
30:02 - using
30:03 - um and for the most part everything
30:04 - worked out perfectly fine I thought that
30:07 - I'd have to reshoot all of the lab
30:09 - content but it turns out nope barely
30:12 - nothing has changed what has changed and
30:15 - I want to point this out early on is
30:17 - that when you are specifying a version
30:20 - for the provider just go use at least
30:22 - version five zero you can use an older
30:25 - version if you want to follow along but
30:27 - uh you know I think it's better to be
30:29 - more um up to date if you can the
30:32 - version that we were using prior in the
30:34 - follow alongs was version three again
30:37 - there are no major changes that will
30:39 - break anything
30:41 - um so at least there shouldn't be but I
30:43 - ran through these Labs my cloud support
30:45 - engineer ran through these Labs so we're
30:47 - pretty confident you're going to be in
30:48 - good shape otherwise if they weren't I
30:50 - would go re-record them but I just
30:52 - wanted to point out those two things uh
30:55 - there so hopefully you know that makes
30:57 - sense and you're going to be in good
30:59 - shape okay now I did say that we're
31:02 - scoping things around terraform 1.6.0
31:05 - and again there's not much to call out
31:07 - for that the biggest thing that I think
31:09 - that 1.6.0 might bring would be testing
31:12 - and even if I looked into it and it just
31:15 - wasn't where I thought it was going to
31:16 - be so I did not include it at least at
31:18 - this time in uh this uh this this course
31:21 - and again this is me going uh above and
31:24 - beyond because I'm trying to just future
31:25 - proof the contents of this course and
31:27 - future proof uh stuff that I believe
31:29 - that is coming to terraform form but
31:31 - yeah you should be in good shape and you
31:34 - know if there are any changes on exam
31:36 - Pro we're very proactive of having those
31:38 - differences there so if you do run into
31:39 - anything that's giving you any kind of
31:42 - issue they're going to be on the the
31:43 - main learning platform there okay if if
31:45 - for whatever reason there's minor
31:47 - updates or things that are found out but
31:49 - yeah you'll be in good shape and have
31:51 - fun on your journey learning terraform
31:54 - ciao
31:55 - [Music]
31:59 - hey this is Andrew Brown from exam Pro
32:01 - and we are looking at what is
32:02 - infrastructure as code and before we
32:04 - talk about that we need to talk about
32:05 - the problem with manual configuration so
32:08 - manually configuring your Cloud
32:09 - infrastructure allows you to easily
32:11 - start using new cloud service offerings
32:13 - to quickly prototype architectures
32:15 - however it comes with a few downsides so
32:17 - it's easy to misconfigure a service
32:19 - through human error it's hard to manage
32:21 - the expected state of the configuration
32:23 - for compliance it's hard to transfer
32:25 - configuration knowledge to other team
32:27 - members and so this is why
32:29 - infrastructure code is going to really
32:30 - help us out so infrastructure is code
32:33 - commonly abbreviated to IAC and you'll
32:35 - see that a lot in this course allows you
32:37 - to write a configuration script to
32:39 - automate creating updating or destroying
32:42 - Cloud infrastructure notice I gave great
32:44 - emphasis on automate or automation
32:46 - because that is really key to
32:48 - infrastructure as code IEC could also be
32:51 - thought of as a blueprint of your
32:52 - infrastructure IEC allows you to easily
32:55 - share version or inventory your Cloud
32:57 - infrastructure and just to kind of get
32:59 - your visualization imagine you write a
33:01 - script and that's going to provision and
33:04 - launch a bunch of cloud services that
33:06 - are all interconnected okay
33:08 - [Music]
33:14 - all right so we're taking a look at
33:15 - popular IAC tools and so of course this
33:18 - course is about terraform but by
33:20 - understanding um all the options out
33:22 - there if you understand why we're using
33:23 - terraform uh and one thing that is very
33:26 - important to understand is the
33:27 - difference between declarative and
33:28 - imperative IAC tools those are the broad
33:31 - categories that we see for IAC so let's
33:34 - start with declarative so the idea here
33:37 - is what you see is what you get
33:38 - everything's explicit it's more verbose
33:40 - but there's zero chance of
33:42 - misconfiguration and this all relies on
33:44 - the fact that they use a scripting
33:45 - language such as Json yaml XML in the
33:48 - case of terraform they have their own
33:49 - language called HCL but the way these
33:52 - languages are structured is that they're
33:54 - very verbose and there's not a lot of
33:56 - programming logic involved so for Azure
33:59 - we have arm templates and Azure
34:01 - blueprints for AWS we have cloud
34:03 - formation for Google we have Cloud
34:05 - deployment manager and there there is of
34:07 - course terraform which has many cloud
34:08 - service providers such as AWS Azure gcp
34:11 - kubernetes and a lot more
34:13 - but these are all in the declarative
34:15 - category
34:16 - on the right hand side we have
34:18 - imperative so you say what you want and
34:20 - the rest is filled in everything here is
34:21 - implicit it's less verbose but you could
34:24 - end up with misconfiguration and when I
34:26 - say that it's that like if you were to
34:28 - find
34:29 - um let's say a virtual machine you might
34:30 - not have to provide every single uh
34:33 - option that you would normally do and it
34:35 - would fill in the rest but if you
34:36 - weren't aware of what it was doing
34:37 - that's where you could end up with
34:38 - misconfiguration uh though I would say
34:41 - that imperative tools generally try to
34:43 - always uh have their defaults as best
34:46 - practices so you're not usually in a bad
34:48 - position uh but you know you might end
34:50 - up with something you don't expect
34:52 - imperative can do more than declarative
34:54 - so there's just some very hard
34:56 - limitations with declarative languages
34:59 - so there's just cases where you want to
35:01 - do imperative and the idea here is
35:04 - imperative languages use programming
35:06 - language you know like python Ruby
35:08 - JavaScript golang you know whatever it
35:10 - is uh there's likely an SDK for it and
35:14 - so it's just a lot more programmer
35:16 - friendly a lot of developers like
35:18 - imperative tools so AWS has their own
35:21 - called Cloud development kit cdk and it
35:24 - technically only supports AWS I say
35:27 - technically because hashicorp has a very
35:29 - cool library that allows you to generate
35:31 - out terraform HCL files which allows you
35:33 - to work with anything but when we're
35:35 - just talking about cdk on its own it's
35:36 - just for AWS then you have plumy it
35:39 - supports AWS Azure gcp and kubernetes so
35:43 - it can do a lot so why would you choose
35:45 - with your team to use declarative over
35:47 - imperative well it just really depends
35:49 - on your your team right so like if
35:52 - they're all used to if they're all
35:53 - administrators and they're used to using
35:55 - Json yaml and they're not good with
35:56 - programming languages that is one reason
35:58 - why you might want to use declarative
36:00 - over imperative the other thing is just
36:02 - you know you prefer to know exactly
36:05 - every single thing that was defined
36:07 - right you don't want anything left up to
36:09 - a chance and so that is another reason
36:12 - why you might want to use declarative
36:14 - but both are great options it's just
36:16 - really depends depends on your team's
36:17 - knowledge and what your goals are okay
36:20 - [Music]
36:24 - so we just looked at imperative and
36:26 - declarative but I just want to clarify
36:27 - that terraform even though it's a
36:28 - declarative language it has
36:30 - imperative-like features so I've coined
36:31 - the phrase declarative plus and so
36:33 - terraform kind of gives you the best of
36:35 - both worlds so you have declarative and
36:37 - imperative and then the three types so
36:38 - our yaml Json XML we have terraform
36:41 - language which actually utilizes HCL
36:43 - underneath and then you have programming
36:45 - languages on the right hand side like
36:46 - Ruby python JavaScript what it have you
36:49 - right so when we're looking at yaml or
36:51 - Json these are very limited languages or
36:55 - scripting languages where uh you know
36:57 - you don't really have any kind of
36:59 - complex data types you probably don't
37:01 - have a whole lot of robust functions but
37:04 - in some cases you can extend That Base
37:06 - Behavior so in the case of cloud
37:08 - formation which uses yaml or Json files
37:11 - they have a concept called macros so you
37:13 - can extend it a bit but again it's very
37:15 - inflexible and so a lot of people are
37:18 - led to go and use cdk so terraform is
37:21 - great because it kind of has a lot of
37:23 - stuff you'd see in programming languages
37:24 - like for Loops Dynamic blocks locals it
37:28 - also has complex data structures and a
37:30 - lot of functions around using those data
37:32 - structures and so it allows you to stay
37:34 - in that declarative world but having the
37:36 - stuff that you generally need when
37:37 - you're in the parative world when you're
37:39 - in the imperative side the idea is that
37:42 - the language is what you're utilizing so
37:44 - you can do anything that the program
37:45 - language allows you to do but I just
37:48 - wanted to kind of show you that
37:49 - terraform sits in the middle okay
37:51 - [Music]
37:55 - hey it's Andrew Brown from exam Pro and
37:57 - we are looking at infrastructure life
37:59 - cycle so what is infrastructure
38:01 - lifecycle it's the idea of having
38:03 - clearly defined and distinct work phases
38:05 - which are used by devops Engineers to
38:07 - plan design build test deliver maintain
38:10 - and retire Cloud infrastructure where
38:12 - we're talking about like sdlc so
38:15 - software development life cycle there's
38:16 - usually a really great visual that I can
38:18 - show for you but for infrastructure
38:20 - lifecycle especially Cloud
38:21 - infrastructure lifecycle there isn't
38:23 - something that is well defined which is
38:26 - weird by the definition but I think that
38:28 - there's just nobody's agreed up on one
38:31 - yet or nobody's made the graphic yet so
38:33 - I just don't have anything to show you
38:34 - for that but I just want you to get
38:36 - familiar with the term infrastructure
38:37 - life cycle because you're likely to hear
38:39 - it again but one particular
38:41 - infrastructure life cycle that is pretty
38:43 - common is ones that talk about day zero
38:46 - day one and day two so the idea here is
38:49 - this is a simplified way to describe
38:51 - phases of infrastructure life cycle so
38:53 - when we say we are on day Zero we are
38:55 - planning and designing our
38:57 - infrastructure on day one we are
39:00 - developing and iterating it so we might
39:01 - be uh you know deploying or provisioning
39:04 - it and actually testing it uh in the
39:06 - cloud and then day two is actually when
39:08 - we go live with real production users
39:10 - and maintain it and the idea of
39:12 - mentioning day zero one and two is to
39:14 - say Well when does IAC start and the
39:17 - idea is it starts on Day Zero okay the
39:20 - days do not literally mean a 24 hour day
39:22 - it's just a broad way of defining where
39:25 - in the infrastructure project we would
39:27 - be okay
39:28 - [Music]
39:33 - so after defining what infrastructure
39:36 - life cycle is what advantage or what an
39:39 - advancement are we going to have when we
39:41 - add IAC to our infrastructure lifecycle
39:43 - well the first thing we're going to get
39:44 - is reliability so IC makes changes
39:47 - impotent consistent repeatable and
39:50 - predictable I'm going to give extra
39:51 - attention here to impotent because it is
39:53 - a very strange English word but no
39:56 - matter how many times you run your IC
39:58 - you will always end up with the same
40:00 - state that is expected that is a very
40:02 - important concept of IEC whereas if you
40:05 - use configuration management there's no
40:06 - guarantee of that that's why you use
40:08 - terraform over something like ansible
40:10 - okay you have manageability so enable
40:13 - mutation via code revise with minimal
40:16 - changes and then you have sensibility so
40:18 - avoid financial and reputational losses
40:21 - to even loss of life when considering
40:23 - government and Military dependencies on
40:25 - infrastructure so there you go
40:27 - [Music]
40:32 - okay so it impotent is a very important
40:35 - concept to infrastructure as code and so
40:38 - we're going to give it a little bit more
40:39 - attention I wouldn't stress out about
40:41 - the pronunciation uh there's more than
40:43 - one way to pronounce it in English and
40:45 - I've probably even said it wrong uh in
40:47 - the previous slide so uh just be uh
40:51 - forgiving on that part okay but the idea
40:53 - is that let's stage a scenario between a
40:57 - non-itipotent example and an independent
40:59 - example so when I deploy my IAC config
41:03 - file it will provision and launch two
41:05 - virtual machines that is what I'm
41:06 - expecting okay and that is what I get
41:09 - but what happens when I go and I update
41:12 - this infrastructure code file saying
41:14 - maybe I want to increase the size of the
41:16 - VMS or some of the configuration I
41:18 - deploy that again when it's
41:20 - non-edepotent what will end up happening
41:23 - is I will end up with two additional
41:25 - virtual machines with the new
41:26 - configuration and the old ones will be
41:28 - there and so this is something you might
41:30 - not want because you just want to have a
41:33 - file that says exactly the state that
41:35 - you expect okay
41:37 - so when we have something that is Idi
41:39 - potent the idea is we will go and we
41:42 - will Define our two virtual machines and
41:45 - we will get our two virtual machines but
41:46 - we go and we update that file and we
41:49 - deploy again and what happens this time
41:51 - is it just ends up modifying the
41:53 - original virtual machines or if it
41:56 - really can't and it has to it might
41:57 - delete them and recreate them but the
41:59 - idea is that we end up in a state of
42:01 - exactly what we want so in the first
42:03 - case we expect it to but we ended up
42:05 - with four but with the independent uh
42:08 - case we expected to and we always end up
42:10 - with two so hopefully that makes that
42:13 - very clear okay
42:14 - [Music]
42:19 - hey this is Andrew Brown from exam Pro
42:21 - and what I want to do here is concretely
42:23 - Define the difference between
42:24 - provisioning deployment and
42:26 - orchestration now in practice sometimes
42:29 - these have overlapping responsibility so
42:31 - you might say provisioning when you
42:33 - really mean deployment or vice versa
42:35 - it's not a big deal uh we all get kind
42:38 - of mixed up about it but I did want to
42:40 - just take the time to make sure that we
42:42 - understand what these things are
42:43 - supposed to mean okay so the First on
42:45 - our list here is provisioning so to
42:47 - prepare a server with systems data and
42:49 - software and then make it ready for
42:51 - Network operation if you're using a
42:53 - configuration management tool you are
42:55 - most likely provisioning because that's
42:56 - what these tools do so puppet ansible
42:58 - Chef bash scripts Powershell or cloudnit
43:01 - so you can provision a server when you
43:03 - launch a cloud service and configure it
43:05 - you are provisioning it okay then you
43:08 - have deployments the deployment is the
43:10 - act of delivering a version of your
43:12 - application to run a provision server
43:15 - deployment could be performed via AWS
43:17 - code pipeline harness which is a
43:19 - third-party deployment tool Jenkins
43:22 - GitHub action Circle CI there's a lot
43:24 - more other providers out there then you
43:26 - have orchestration so orchestration is
43:28 - the active coordinating multiple systems
43:30 - or Services orchestration is a common
43:33 - term when working with microservices
43:34 - containers and kubernetes so
43:36 - orchestration could be done with
43:38 - kubernetes salt or fabric so if you're
43:40 - working with containers generally like
43:42 - you use the word orchestration
43:44 - especially with kubernetes because
43:45 - you're working with thousands of
43:47 - microservices okay so you know hopefully
43:50 - that helps you know the difference
43:52 - between the three again it's not a big
43:53 - deal if you don't perfectly know them
43:55 - but there you go
43:57 - [Music]
44:01 - hey this is Andrew Brown from exam Pro
44:03 - and we are taking a look at
44:04 - configuration drift so this is when
44:06 - provision infrastructure has an
44:08 - unexpected configuration change due to
44:11 - team members manually adjusting
44:13 - configuration options malicious actors
44:15 - so maybe they're trying to cause
44:17 - downtime or breach data or side effects
44:20 - from apis sdks or CLI so you've written
44:24 - some code that uses a CLI and a bash
44:26 - script and it does something you did not
44:28 - expect to happen so here an example
44:31 - could be imagine you have a server like
44:33 - a database and a junior developer turns
44:36 - off delete on termination for your
44:38 - production database this could be a
44:40 - problem where let's say there's an
44:42 - accidental deletion of the database this
44:45 - feature would protect the database from
44:47 - deletion but if it's turned off you
44:48 - don't have that right so configuration
44:50 - drift going unnoticed could be a loss or
44:53 - breach of cloud services and residing
44:55 - data will result in Interruption of
44:57 - services or unexpected downtime so
44:59 - there's a lot of
45:00 - downsides to to neglecting or not
45:03 - noticing configuration drift so what can
45:05 - we do about this so how to detect so
45:08 - there's three things detect
45:10 - um we can fix it and then prevent it
45:12 - okay so to detect configuration drift if
45:14 - you have a compliance Tool uh it can
45:17 - detect misconfiguration so it was config
45:19 - can do that as your policies can do that
45:21 - gcp security health analytics can do
45:23 - that some of these are constrained to
45:26 - security things not just configuration
45:29 - in general but there are tools there for
45:32 - all the cloud service providers there is
45:35 - built-in support for drift detection for
45:37 - it was cloud formation it's called cloud
45:38 - formation drift detection other
45:41 - providers don't necessarily have that if
45:44 - you're using terraform which is this
45:45 - which is all this course is about you
45:48 - have the terraform State files which
45:50 - says what the state of things should be
45:52 - so that's how you could detect
45:53 - configuration drift how to correct
45:56 - configuration drift well compliance
45:58 - tools can remediate so again it is
46:00 - config you can create a custom Lambda to
46:02 - say hey when this happens then do this
46:05 - so set the configuration back into place
46:07 - with terraform you can use the refresh
46:09 - and plan command which we'll look at in
46:12 - detail in this course or you can
46:14 - manually correct it so if the option was
46:16 - changed you could do that not
46:18 - recommended to do that
46:19 - another thing would be tearing down and
46:21 - setting up the infrastructure again
46:22 - because that would bring it back into
46:24 - its original state that could be a risky
46:27 - thing to do depending on how you have
46:29 - things set up or could be it could be
46:31 - fine right then there's prevention so
46:34 - um this is a the important thing and
46:36 - kind of why we're talking about
46:37 - configuration drift which is all about
46:39 - immutable infrastructure so always
46:40 - create and just destroy never reuse so
46:43 - that might be blue green deployment
46:44 - strategies servers are never modified
46:47 - they are all they're just always
46:49 - deployed with a new version the way you
46:51 - would do that would be baking Ami images
46:53 - or containers via AWS image Builder or
46:56 - hashicor Packer or a build server like
46:59 - gcp Cloud run or code build like AWS but
47:03 - the idea is that you're not modifying
47:05 - after they're deployed you'd have that
47:06 - image already ready to go another thing
47:09 - you could use is git Ops so you would
47:11 - Version Control your IAC like within
47:14 - GitHub or something like that and you
47:16 - would peer review every single uh change
47:19 - the a pull request to the infrastructure
47:21 - so hopefully that gives you an idea of
47:23 - things we can do to tackle configuration
47:26 - drift okay
47:27 - [Music]
47:31 - we were just talking about immutable
47:33 - infrastructure but I just want to give
47:35 - it a bit more attention here so the idea
47:38 - is
47:39 - um we are going to first develop our
47:42 - infrastructure as a code file terraform
47:44 - cloudformation what have you and then
47:46 - we're going to go ahead and deploy that
47:48 - so we'll end up with our own virtual
47:50 - machine and that virtual machine needs
47:52 - to be configured so you need to install
47:53 - packages and things like that that's
47:55 - where Cloud init would come into play
47:57 - ansible puppet Chef salt whatever
47:59 - configuration management tool you want
48:01 - to use the problem here is that there's
48:04 - no guarantee that that configuration is
48:05 - going to stay in place so that's where
48:08 - immutable infrastructure comes into play
48:10 - so we develop our infrastructure as a
48:13 - code file terraform cloud formation and
48:16 - then we're going to go ahead and do our
48:17 - configuration by building a virtual
48:20 - machine or building a container so we
48:22 - can use something like Packer and then
48:24 - the idea is once we are happy with our
48:26 - configuration what we're going to do is
48:29 - bake that image and put it in an image
48:31 - repository and then that image is going
48:34 - to be referenced when we do our deploy
48:36 - and so that's going to make sure that
48:37 - our infrastructure is always immutable
48:39 - okay
48:40 - [Music]
48:44 - hey this is Andrew Brown from exam Pro
48:46 - and we are taking a look at the concept
48:48 - or methodology of git Ops so this is
48:51 - when you take infrastructure as code and
48:53 - you use a git repository to introduce a
48:56 - formal process to review and accept
48:58 - changes to infrastructure code and once
49:00 - that code is accepted it automatically
49:02 - triggers a deploy and changes that
49:04 - infrastructure so here's my illustration
49:07 - through it so the idea is you would have
49:08 - a terraform file and you would place
49:11 - that in something like GitHub you would
49:13 - apply your commits and when you're ready
49:15 - you'd make a pull request you would
49:17 - merge that pull request into the main
49:19 - branch or whichever branch is set up for
49:21 - production and that could trigger
49:23 - something like GitHub actions and GitHub
49:26 - actions would then trigger a terraform
49:28 - plan and and accept it or maybe you have
49:31 - to manually intervene to say Okay I
49:33 - accept these changes but then it would
49:35 - roll out those changes now terraform
49:37 - does have their own and it's pretty darn
49:39 - similar but I thought mine was a bit
49:40 - easier to read but the idea is you have
49:42 - your git repository you have your pull
49:45 - request this is pulling from terraform
49:47 - Cloud because you can have files and
49:50 - state managed there so that is another
49:53 - means to do it but that's generally how
49:55 - it works okay
49:58 - foreign
49:59 - [Music]
50:00 - so we were just looking at immutable
50:02 - infrastructure but what I want to do is
50:04 - just kind of cement in your head things
50:05 - that you should be asking yourself as a
50:08 - devops engineer so that you kind of lean
50:10 - towards that immutable uh kind of way of
50:14 - thinking and so this is mostly going to
50:16 - be applicable for virtual machines but
50:18 - let's just ask some questions of things
50:20 - we should be thinking about so what's
50:22 - going to happen if we deploy our virtual
50:24 - machine and there is a physical failure
50:26 - of the hardware by the provider so this
50:29 - can sometimes happen on AWS where they
50:30 - have two status checks that have to
50:32 - complete before a virtual machine is
50:34 - ready sometimes they fail and so you
50:36 - know your infrastructure is not ready to
50:38 - graded or damaged right then you have
50:41 - application failure so you have this
50:43 - post installation script maybe to
50:45 - install your application and there's
50:48 - either a bug so introduced by developer
50:50 - or maybe there's just a dependency and
50:54 - it's changed and so it's breaking your
50:56 - app what happens when you need to deploy
50:58 - in a hurry what have happens in worst
51:01 - case scenarios where you have accidental
51:03 - deletion compromised by malicious actor
51:05 - need to change regions maybe there's a
51:06 - region outage and so the thing is is
51:09 - that when you look at these things what
51:11 - happens when multiples of these happen
51:13 - at the same time because that's the
51:14 - problem where you know it's like okay I
51:16 - have something wrong with my application
51:18 - code but I also have uh you know now we
51:21 - also have a region down and so you don't
51:24 - want to be dealing with more than one
51:25 - problem at the same time and so that's
51:26 - we're going to have an issue of agility
51:28 - in terms of deployment another thing
51:30 - that is overlooked is there's no
51:32 - guarantee of one to one if you are
51:34 - configuring your code after deployment
51:36 - because if you were to deploy a virtual
51:40 - machine
51:41 - and installed all the dependencies and
51:45 - then you to were to deploy a virtual
51:46 - machine literally a minute later one of
51:48 - those dependencies could have a minor
51:50 - revision and so that would be deployed
51:52 - with that one minor revision so they
51:54 - would look very similar but they aren't
51:55 - one to one so by introducing golden
51:57 - images which is an immutable
51:59 - infrastructure idea you get a guarantee
52:01 - of one one to one with your Fleet you
52:03 - have increased Assurance of consistency
52:04 - security you have you can speed up your
52:07 - deployments the reason why you have an
52:08 - improvement of security is because at
52:10 - that stage you could
52:12 - um you could perform kind of Security
52:14 - checks and things like that there on
52:15 - that image before you roll it out so I
52:18 - don't know um I would just say that I
52:20 - would recommend that you go with the
52:22 - immutable infrastructure or baking your
52:24 - images when you can if you're using VMS
52:25 - okay
52:26 - [Music]
52:30 - hey this is Andrew Brown from exam Pro
52:32 - and we're going to take a look here at
52:33 - what is hashicorp so hashicorp is who
52:36 - creates terraform and they are a company
52:38 - specializing in managed open source
52:40 - tools used to support the deployment and
52:41 - development of large-scale service
52:43 - oriented software installations and they
52:45 - have their own cloud platform called the
52:47 - hashicorp cloud platform hcp and it's a
52:50 - unified platform to access hashicorp
52:52 - various products so uh the main thing is
52:55 - that it's Cloud agnostic so hashicorp
52:57 - makes it really easy to build across
52:58 - cloud and they have support for all the
53:01 - three main providers so AWS gcp Azure
53:03 - I'm sure they have more support like
53:05 - kubernetes and things like that they're
53:07 - highly suited for multi-cloud workloads
53:09 - or cross-cloud workloads and they have a
53:12 - lot of products that will help you out
53:13 - there so let's go through them quickly
53:15 - so first we have boundary this is secure
53:17 - remote access to systems based on
53:19 - trusted identity this is console this is
53:21 - a full featured service mesh for secure
53:23 - service segmentation across any cloud or
53:25 - runtime environment you have Nomad this
53:27 - is scheduling and deployment of tasks
53:29 - across worker nodes in a cluster you
53:31 - have Packer which is a tool for building
53:33 - virtual machine images that will be
53:35 - later deployed or they will place them
53:37 - in a image repository then you have
53:39 - terraform which is infrastructure as
53:41 - code software which enables provisioning
53:43 - and adapting virtual infrastructure
53:45 - across all major providers then you have
53:47 - terraform cloud and this is just a place
53:49 - to store and manage your IAC State files
53:53 - and things like that with a team or just
53:55 - in the cloud by yourself we have vagrant
53:57 - so building and building and maintenance
53:59 - of reproducible software development
54:01 - environments via virtualization
54:03 - technology we have Vault so secret
54:05 - management identity based access
54:07 - encrypting application data auditing of
54:09 - Secrets for application systems and
54:11 - users and lastly we have Waypoint a
54:14 - modern workflow to build deploy and
54:15 - release across multiple platforms so
54:19 - there you go
54:20 - [Music]
54:24 - hey this is Andrew Brown from exam Pro
54:26 - and we are looking at what is terraform
54:28 - so terraform is an open source and Cloud
54:30 - agnostic infrastructure as a code tool
54:32 - and terraform uses declarative
54:34 - configuration files and the
54:36 - configuration files are written in the
54:38 - hashicorp configuration language HCL and
54:41 - so that's what you can see on the right
54:43 - hand side we'll generally call it the
54:45 - terraform language which we'll talk
54:46 - about later but notable features of
54:48 - terraform are installable modules plan
54:51 - and predict changes dependency graphing
54:53 - State Management and provisioning
54:55 - infrastructure in familiar languages
54:57 - that's something you could do via AWS
54:59 - cdk so I wouldn't say it's core to
55:02 - terraform but that's what they listed on
55:04 - their websites that's why I put in there
55:05 - and terraform registry which has over 1
55:07 - 000 plus providers okay so there we go
55:11 - [Music]
55:15 - so we were just looking at terraform but
55:18 - what is terraform Cloud well it's a
55:20 - software as a service offering for
55:21 - remote State Storage Version Control
55:23 - Integrations flexible workflows and
55:26 - allows you to collaborate on
55:27 - infrastructure changes within a single
55:29 - unified web portal and this is all
55:31 - accessible via terraform.io and the
55:35 - first thing you'll have to do is create
55:36 - yourself an account on terraform i o but
55:38 - it's free to start with and they
55:39 - actually have a very generous free tier
55:41 - that allows for team collaboration for
55:43 - the first five users of your
55:45 - organization that's not part of the
55:46 - team's plan that's part of the free plan
55:48 - and in the majority of cases you really
55:50 - should be using terraform Cloud as your
55:52 - remote backend even if you are an
55:54 - individual just because you know it
55:57 - makes experience so much better the only
55:59 - case that you might not want to use
56:00 - terraform cloud is if you have a very
56:03 - large company that's trying to meet
56:04 - particular regulatory requirements and
56:07 - it's not that terraform Cloud does not
56:09 - meet them but sometimes there's just a
56:11 - long procurement process so in the
56:13 - meantime you would have to use something
56:15 - like standard remote back end or
56:16 - Atlantis or maybe you need to
56:18 - investigate terraform Enterprise I do
56:20 - want to note that terraform cloud and
56:22 - terraform Enterprise is the underlying
56:24 - software known as terraform platform
56:26 - it's not something you're going to ever
56:27 - have direct access to but just to
56:30 - clarify that terminology okay
56:32 - [Music]
56:37 - so what I want to do is just set you up
56:39 - with understanding the terraform life
56:41 - cycle this is not necessarily uh
56:44 - described in the documentation anywhere
56:45 - but it's something that is inherently
56:47 - known when you're working with terraform
56:50 - uh and it's definitely not uh inclusive
56:53 - with every single command that can be
56:55 - ran but the ones that you're going to
56:56 - counter most often so at the start
56:58 - you're going to be writing or updating
57:00 - your terraform configuration file okay
57:02 - and from there the first thing you'll
57:04 - want to do is initialize your projects
57:07 - and or if you need to pull the latest
57:10 - providers and modules you're going to
57:11 - use terraform indit to do that as well
57:13 - from there you're going to use plan so
57:15 - plan allows you to speculate what will
57:17 - change or generate a saved execution
57:19 - plan that you could use later on when
57:22 - you run plan validate happens
57:23 - automatically but you could also run
57:25 - this separately and ensures types and
57:27 - values are valid ensures the required
57:29 - attributes are present within your
57:31 - configuration file from there if
57:33 - everything is good you're going to
57:34 - execute your execution plan by running
57:37 - terraform apply you can also from this
57:40 - point use terraform apply to destroy
57:42 - infrastructure so if you have things set
57:44 - up there's actually a flag for it or you
57:45 - can use the Alias the terraform destroy
57:47 - command and then you know as you work
57:50 - you're just going to keep updating your
57:51 - code and that is the terraform life
57:53 - cycle so you know hopefully this gives
57:55 - you kind of a a snapshot of what the
57:58 - workflow will be and I mean we'll be
58:00 - covering it tons and tons of times over
58:02 - in this course okay foreign
58:04 - [Music]
58:08 - hey this is Andrew Brown from exam Pro
58:10 - and we are taking a look at change
58:12 - automation but to understand that we
58:14 - need to first talk about change
58:15 - management so this is a standard
58:17 - approach to apply change and resolving
58:19 - conflicts brought about by change in the
58:21 - context of IAC change management is the
58:24 - procedure that will be followed when
58:25 - resources are modified and applied via
58:27 - configuration scripts so what is change
58:29 - automation then it is a way of
58:31 - automatically creating a consistent
58:33 - systematic and predictable way of
58:35 - managing change requests via control and
58:37 - policies notice and I should have
58:39 - probably emphasized this is change
58:40 - requests saying I'm going to change
58:42 - these resources terraform uses change
58:45 - Automation in the form of execution
58:46 - plans and resource graphs which will
58:48 - look at detail those two things in
58:51 - upcoming slides and apply review complex
58:53 - change sets so a change set is a
58:55 - collection of commits that represents
58:57 - changes made to a versioning repository
58:59 - and for IEC uses change sets so you can
59:03 - see what has changed by who over time so
59:06 - when I say versioning repository that
59:08 - doesn't necessarily mean get and if
59:11 - you're using get Ops I suppose you could
59:12 - consider your chain sets being committed
59:14 - to that but something like cloud
59:16 - formation when you apply a change you
59:19 - actually have to accept a change Set uh
59:21 - and so the version repository is part of
59:23 - AWS and so um it will terraform you just
59:26 - kind of accept it in place it's not
59:28 - necessarily on your local machine but I
59:31 - guess reflecting your state file okay so
59:33 - change automation allows you to know
59:34 - exactly what terraform will change and
59:36 - in what order avoiding many possible
59:38 - human errors a change automation is
59:40 - essential to any IAC tool they all have
59:43 - it okay so there we go
59:44 - [Music]
59:49 - this is Andrew Brown from exam Pro and
59:51 - we are taking a look at execution plans
59:53 - so this is a manual review of what will
59:55 - add change or destroy before you apply
59:57 - changes and so let's say you type in
59:59 - terraform apply it's not just going to
60:01 - go ahead and do that it's going to have
60:03 - you uh type in yes or accept the value
60:05 - but what you can do is see the resources
60:08 - or configuration settings that will be
60:09 - added changed or destroyed and it will
60:11 - summarize them at the bottom and then
60:13 - you'll have to type something like yes
60:15 - in order to accept the changes okay
60:17 - [Music]
60:21 - something else I want to show you is
60:23 - that you can actually visualize your
60:25 - execution Plans by using the terraform
60:27 - graph command and terraform will output
60:29 - a graph of his file you'll have to have
60:31 - graph Vis installed but Graphics is an
60:33 - open source tool for drawing graphs
60:35 - specified in the dot language scripts
60:37 - having the file name extension of GV so
60:41 - I believe this is cross-platform it's
60:42 - open source but once it's installed in
60:45 - your machine you can run terraform graph
60:47 - and here this is Linux so we're using a
60:49 - pipe to say okay pass it over to graphis
60:51 - which is Dot and that is going to then
60:54 - create an SVG file you can just open
60:56 - that in your browser and the idea is
60:58 - you're going to get this graph which
60:59 - kind of shows you the relationship of
61:00 - the resources here but we'll talk about
61:03 - the these relationships in the next
61:05 - slide here which is a resource graph
61:07 - okay
61:07 - [Music]
61:12 - let's take a look here at the resource
61:14 - graph so terraform builds a dependency
61:16 - graph from the terraform configurations
61:17 - and walks this graph to generate plans
61:20 - refresh rate and more when you use
61:22 - terraform graph this is a visual
61:24 - representation or presentation of the
61:26 - dependency graph if you're wondering
61:28 - what a dependency graph is in
61:29 - mathematics it's a directed graph
61:31 - representing dependencies of several
61:33 - objects towards each other so it's
61:34 - pretty much like nodes with
61:37 - relationships between other nodes so
61:39 - that is one that I generate out from
61:41 - terraform and so there's a few different
61:43 - types here we have a resource node that
61:45 - represents a single resource a resource
61:47 - meta node represents a group of
61:49 - resources but does not represent any
61:51 - action on its own and provider
61:53 - configuration nodes that represents the
61:54 - time to fully configure a provider will
61:57 - you need to know this for the exam
61:58 - probably not do you need to know this in
62:00 - great detail probably not because
62:02 - there's a lot to the resource graph but
62:04 - the idea here is just kind of like
62:05 - terraform saying just so you know we're
62:07 - using a graph database and graph
62:09 - databases are very well suited for this
62:11 - kind of stuff and that's why terraform
62:14 - is very good at figuring out conflicts
62:17 - and things like that okay
62:19 - foreign
62:22 - [Music]
62:24 - from exam Pro and we are taking a look
62:26 - at terraform use cases and the idea here
62:28 - is not necessarily because it's going to
62:30 - show up in the exam but the idea is to
62:32 - give you a business use case or to
62:33 - highlight the features as to why you'd
62:35 - want to be using terraform and the first
62:37 - one here is that it has exotic providers
62:39 - so terraform supports a variety of
62:42 - providers outside of gcp AWS and Azure
62:44 - and sometimes is the only provider
62:46 - terraform is open source and extendable
62:48 - so any API could be used to create IC
62:51 - tooling of any kind of cloud platform or
62:52 - technology so you can make your own
62:54 - provider there's some interesting ones
62:55 - that they have like Heroku or even
62:57 - Spotify playlists I have my own platform
62:59 - called teacher seat and I want to have
63:01 - IAC for my platform and so this is what
63:04 - I'm going to be using terraform for for
63:06 - multi-tier applications terraform by
63:08 - default makes it easy to divide large
63:10 - and complex applications into isolate
63:12 - configuration script modules you'll
63:13 - notice in this course that when you have
63:16 - a bunch of terraform files they're all
63:17 - treated as one so that makes it really
63:19 - easy to split up your uh your projects
63:22 - or your your infrastructure so so it has
63:24 - a complexity advantage over Cloud native
63:26 - IC tools for its flexibility while
63:28 - retaining Simplicity over imperative
63:30 - tools then we have disposable
63:32 - environments this is not unique to
63:34 - terraform it's any kind of ISE tool but
63:36 - easily stand up an environment for a
63:37 - software demo or a temporary developer
63:39 - environment resource schedulers so
63:41 - terraform is not just defined to
63:43 - infrastructure of cloud resources but
63:45 - can be used to set Dynamic schedules for
63:48 - Docker containers Hadoop spark and other
63:51 - software tools you can provision your
63:53 - own scheduling grid and the last one
63:55 - here is multi-cloud deployment terraform
63:57 - is cloud agnostic and allows a single
64:00 - configuration to be used to manage
64:02 - multiple writers and to even handle
64:04 - cross-cloud dependencies and that is a
64:06 - big deal and is a very unique offering
64:08 - to terraform okay
64:10 - [Music]
64:14 - let's take a look here at terraform core
64:16 - and terraform plugins so terraform is
64:19 - logically split into two main parts
64:21 - terraform core which uses remote
64:23 - procedure calls RPC to communicate with
64:25 - terraform plugins and terraform plugins
64:27 - so expose an implementation for a
64:30 - specific service or provisioner
64:32 - something that's interesting to know is
64:34 - just terraform core is written in go
64:37 - um you know you probably will never
64:39 - encounter it but it's just a fact okay
64:41 - and so here's the graphic that terraform
64:43 - uses to kind of like explain terraform
64:46 - core versus terraform plugins and how
64:49 - they all relate so here's the terraform
64:51 - core and here are the plugins notice we
64:54 - have providers here which will cover
64:56 - provisioners uh and there's just this is
64:59 - the group for plugins overall
65:01 - um but yeah that's about it we'll show
65:03 - up an exam probably not but it's good to
65:05 - understand from a top level view the
65:08 - split between these two things okay
65:09 - [Music]
65:14 - if you are new to terraform I just
65:16 - wanted you to be aware of an additional
65:18 - resource that you can use Beyond this
65:20 - course which is called terraform up and
65:22 - running so it's a a book and it has a
65:26 - deep dive into the internal workings of
65:27 - terraform and this is really great if
65:29 - you want to go beyond this course Beyond
65:31 - certification beyond the basics because
65:33 - what it will do is teach you about
65:34 - testing with terraform Cloud zero
65:37 - downtime deployment common terraform
65:39 - gotchas and compositions of production
65:42 - grade terraform code there's a lot more
65:44 - to it and this book in particular is
65:46 - written by Jim who's the co-founder of
65:48 - grunt work and we do have a whole
65:50 - section just on grunt work and the thing
65:53 - is I just want you to know about this
65:54 - resource you definitely don't need it to
65:57 - pass a certification or to have a good
65:59 - understanding or working of terraform
66:01 - but you know at some point you if you
66:03 - want more I just want to point you to
66:04 - that resource okay
66:06 - [Music]
66:10 - there's one other resource I want you to
66:12 - check out for terraform and this one is
66:14 - free and just online and it's the
66:16 - terraform best practices so it's an open
66:18 - book it's a get book so it's essentially
66:21 - a Wiki and it basically covers the best
66:24 - practices that are being used in the
66:25 - industry and so this is stuff that is
66:27 - separate from the terraform
66:28 - documentation it's just good practices
66:31 - you know if you're going to be using
66:33 - terraform professionally within the
66:35 - industry so I just wanted to make you
66:37 - aware of this resource and to go check
66:39 - it out okay
66:40 - foreign
66:43 - [Music]
67:24 - foreign
67:27 - [Music]
67:41 - hey this is Andrew Brown from exam Pro
67:43 - and we are taking a look at terraform
67:44 - provisioners so provisioners install
67:46 - software edit files and provision
67:48 - machines created with terraform and
67:50 - terraform allows you to work with two
67:51 - different provisioners we have Cloud net
67:53 - and Packer so Cloud init is an industry
67:55 - standard for cross-platform cloud
67:57 - instance initialization when you launch
68:00 - a VM on a cloud service provider you'll
68:02 - provide either a yaml or Bass script and
68:05 - so for the case of AWS what you'll have
68:07 - is this box called user data and so you
68:09 - can either put your yaml or Bass script
68:11 - in there it's the same if you're using
68:13 - Google or Azure they both have this box
68:15 - it might just not be called user data
68:17 - but that is using Cloud init underneath
68:19 - then you have Packer this is an
68:21 - automated image Builder service you
68:23 - provide a configuration file to create
68:24 - and provision the machine image and the
68:26 - image is then delivered to repository
68:28 - for use if you've ever heard of ec2
68:30 - image Builder it's a very similar
68:32 - service except that one's just for AWS I
68:34 - suppose for Google you can use Google
68:36 - Cloud run and even on AWS you could use
68:39 - um
68:40 - code build but uh Packer is great
68:42 - because it's Cloud agnostic so you're
68:44 - going to just build the image and then
68:45 - you can deliver it
68:47 - to any provider provisioners should be
68:49 - used as a last resort for the for more
68:52 - common situations there are better
68:53 - Alternatives this is a warning that
68:55 - hashnode puts out in their terraform
68:57 - provisioner section and so I wasn't
68:59 - really sure why they were saying this so
69:01 - I reached out to Anton and Anton uh if
69:04 - you don't know him he's an as Community
69:05 - hero just like myself and so he
69:08 - specializes in terraform like he wrote
69:11 - so many modules for the terraform AWS so
69:13 - he knows it pretty well and he says here
69:15 - the main reason is that provisioners
69:17 - will do something that won't be
69:18 - reflected in the terraform State and the
69:20 - better alternative for that one is to
69:23 - use cloud provider features like Cloud
69:24 - init scripts I think this comes back to
69:27 - immutability when we're looking at the
69:30 - fact that we want to
69:32 - lean towards doing an approach with
69:34 - Packer right we want to
69:36 - um uh bake our Baker machines or virtual
69:39 - machines and then deploy because that's
69:41 - going to be probably the better
69:43 - alternative so if we wanted to use cloud
69:45 - init the idea is we'd have to provide a
69:48 - cloudinet yaml file which is a a very
69:51 - particular format you can find them on
69:52 - the cloudinet website and the idea here
69:54 - is we have these run commands so this
69:56 - just like bash commands here to start
69:57 - and stop Apache we can install our
69:59 - packages here do an update do an upgrade
70:01 - we'll have to pass along our SSH key
70:04 - here that's a very important component
70:06 - to that once we have that file
70:08 - configured we can reference it as a
70:11 - template file over here call it user
70:13 - data and then we're going to pass it on
70:15 - to this section here for user data so
70:17 - that when we launch up this VM and this
70:19 - one in particular is for AWS that's
70:21 - going to pass it to that user data okay
70:23 - now you might be asking well where's all
70:25 - these other provisioners because there's
70:27 - a lot of other tools out there so
70:28 - terraform used to directly support
70:30 - third-party provisioning tools in the
70:32 - terraform language but they were
70:34 - deprecated because it was considered to
70:36 - be poor practice suggesting better
70:38 - Alternatives as we were just talking
70:39 - about so you might be asking where is
70:41 - Chef where is puppet where is salt and
70:44 - the thing is is that you can technically
70:45 - still use chef and puppet through Cloud
70:48 - init because cloudinit actually supports
70:50 - some dsls in there I've never used this
70:52 - before myself but it doesn't look too
70:54 - complicated but the idea is that there's
70:56 - just not direct support so you're not
70:58 - going to use it directly in the language
70:59 - you can use it through cloud in it if
71:01 - you really need it one thing I didn't
71:03 - see mentioned anywhere was ansible and
71:05 - this one's a little bit confusing
71:06 - because there's a lot a lot of videos
71:08 - online about terraform and ansible
71:10 - working very well together and they're
71:13 - complementary Technologies so ansible is
71:16 - a little bit different than these other
71:17 - ones because it does more than just
71:19 - configuration management so maybe that's
71:21 - the reason there
71:22 - um but anyway the point is is that
71:23 - there's no direct support for these
71:25 - anymore you got to use cloud in it and
71:27 - generally if you can use Packer instead
71:28 - when you're working with virtual
71:29 - machines okay
71:30 - [Music]
71:35 - hey this is Andrew Brown from exam Pro
71:37 - and we are taking a look at local exec
71:39 - which allows you to execute local
71:40 - commands after a resource is provisioned
71:43 - so the machine that is executing
71:45 - terraform so what's doing the terraform
71:47 - apply is where the command will execute
71:49 - and a local environment could be your
71:52 - local machine so your laptop or
71:54 - workstation a build server like gcp
71:56 - Cloud build a business code Builder
71:58 - Jenkins or terraform Cloud run
72:00 - environment so that is a single use
72:02 - Linux virtual machine so just an example
72:05 - and there's a lot of cases where you
72:07 - might want to automate but the idea here
72:09 - is after your provision a VM you need to
72:11 - supply the public IP to a third-party
72:14 - security service to add the VM IP
72:16 - address and you can accomplish this by
72:17 - using locally installed third-party
72:19 - cli's on your build server and so there
72:22 - is a bit of an overlapping
72:23 - responsibility between terraform outputs
72:25 - versus local exec because the idea is
72:27 - that by getting by getting data out
72:30 - after something is provisioned or
72:32 - something like that you can do something
72:34 - pragmatic but the idea here is terraform
72:36 - outputs allow you to Output results
72:38 - after running terraform apply local exec
72:40 - allows you to run any arbitrary commands
72:42 - on your local machine commonly used to
72:44 - trigger configuration management like
72:46 - ansible Chef or puppet okay
72:48 - [Music]
72:52 - let's take a look at some example code
72:54 - for a local exec so here we have a bunch
72:57 - of examples on the right hand side and
72:59 - so I just kind of want to walk through
73:00 - some of the commands that we can use but
73:02 - before we do that just let's take a
73:03 - quicker look here at the code so notice
73:05 - we have a resource like Ava's instance
73:07 - in web and then we are specifying a
73:09 - provisioner being a local exec and then
73:12 - we have a command that is being executed
73:14 - under there okay so hopefully that makes
73:16 - it pretty clear but let's just kind of
73:17 - work through the options we have
73:19 - available to us so the first is we have
73:20 - a command and this is required and this
73:22 - is the command you want to execute so
73:24 - notice that we are doing an echo there
73:27 - so it's whatever is possible uh there
73:30 - and I think by default it's using bash
73:32 - okay so if you're using Linux that's
73:34 - what it would be using we could also set
73:36 - a working directory we don't see an
73:37 - example there on the right hand side but
73:39 - if you wanted to say where the command
73:41 - will be executed that's something you
73:43 - could do so maybe you want it over here
73:45 - another thing is The Interpreter so this
73:47 - is the entry point for the command I
73:49 - think by default again it would probably
73:50 - use bash if you're on Linux machine but
73:52 - you could say use bash Ruby it was CLI
73:55 - Powershell whatever you want okay
73:57 - if you needed to pass environment
73:59 - variables in maybe you need a key and
74:01 - secret so the example here is you know
74:04 - we are printing out those keys and then
74:06 - putting them into a credentials XML file
74:09 - so that could be an example there okay
74:12 - [Music]
74:16 - hey this is Andrew Brown from exam Pro
74:18 - and we're taking a look at remote exec
74:20 - so this allows you to execute commands
74:22 - on a Target resource after a resources
74:24 - provision so the idea is you have a
74:26 - local machine executing terraform and so
74:29 - the idea is that when remote exact
74:31 - happens it has a script and it's sending
74:33 - that off to the Target so this case it
74:36 - could be a provision virtual machine and
74:38 - this is where the command is going to
74:39 - run so a remote execute is useful for
74:41 - provisioning a virtual machine with a
74:43 - simple set of commands for more complex
74:45 - tasks it's recommended to use cloud init
74:48 - and strongly recommended in all cases to
74:50 - bake golden images via Packer or uc2
74:52 - image Builder if you want to use
74:53 - something more complex like ansible or
74:55 - something
74:56 - [Music]
75:00 - let's take a look at an example of a
75:03 - remote exec script so here we have a
75:05 - couple and just to quickly go through it
75:07 - the idea is you define your resource so
75:09 - here it's just a virtual machine on AWS
75:12 - and we are provisioning our provisioner
75:14 - is going to be remote exact and so we're
75:17 - able to put these inline commands and
75:18 - say okay let's run puppet apply and then
75:21 - we'll use console join which is the CLI
75:22 - for hashicorp console so there are three
75:26 - different modes for a remote exec the
75:29 - first is inline list of command strings
75:30 - which is what we are seeing over here
75:33 - and then the other option is we can
75:36 - provide a script or scripts so the idea
75:39 - is that you would
75:41 - um well you just specify those locations
75:44 - and it would run it what's interesting
75:46 - here is that it doesn't say
75:49 - um like because we saw with local exec
75:51 - that we could use an interpreter and so
75:53 - it's my assumption that it's just going
75:55 - to use bash or it's going to use a
75:58 - script that is executable right where
76:00 - you have a shebang in the top there and
76:03 - so that's something you know I might
76:04 - test out it's not something that's going
76:06 - to be on the exam but maybe we'll just
76:08 - test out that theory because it's not in
76:09 - the documentation as of the time I'm
76:11 - recording this
76:12 - [Music]
76:16 - let's take a look at the file
76:18 - provisioner and this is used to copy
76:19 - files or directories from our local
76:21 - machine to the newly created resource so
76:24 - here we have some on the right as an
76:26 - example so again we have a virtual
76:28 - machine that we're deploying to AWS
76:30 - we've set the provisioner as file and we
76:33 - are specifying a source file and a
76:35 - destination so source is going to be the
76:37 - file that's on your local machine or
76:39 - whoever is the considered the local you
76:43 - might also want to provide content
76:44 - directly so in this example here you see
76:47 - that we're literally just giving it a
76:48 - string and then there's the destination
76:50 - where you want that file to be I don't
76:53 - have it shown in the code example here
76:55 - but there's a high chance that you would
76:57 - have to provide a connection block so
76:59 - that you could say okay I need to use
77:01 - SSH or
77:03 - winrm to gain access to that machine
77:06 - okay
77:07 - [Music]
77:11 - so we just mentioned that there's a
77:13 - connection block so it tells the
77:15 - provisioner or resource how to establish
77:17 - a connection so here is a big example on
77:20 - the right hand side so this is using the
77:22 - example for a provisioner file and here
77:25 - we are specifying our connection block
77:27 - and this one in particular is for SSH as
77:30 - you can see and there's a bunch of
77:31 - different parameters like the user the
77:33 - password the host you could also use a
77:36 - Bastion host I don't I'm not showing it
77:38 - here but if you're using SSH you could
77:40 - specify a bunch of keys in order to do
77:42 - that because maybe you need to go
77:43 - through a Bastion first
77:45 - for Windows Remote Management you also
77:48 - have that option down below okay
77:50 - [Music]
77:55 - hey this is Andrew Brown from exam Pro
77:57 - and we are taking a look at null
77:58 - resources so this is a placeholder for
78:00 - resources that have no specific
78:02 - Association to a provider it's a bit
78:05 - confusing but it makes sense once you
78:07 - run into some use cases for it so here
78:09 - is a big example where we have an AWS
78:13 - instance and we're defining a cluster
78:15 - and so we need a null resource here
78:18 - because we want to run this trigger and
78:21 - that's generally why you're going to be
78:22 - using null resources is to trigger a
78:25 - resource so triggers is a map of values
78:27 - which should cause this set of
78:28 - Provisions to re-run so values are meant
78:31 - to be interpolated references to
78:33 - variables or attributes of other
78:35 - resources and triggers are interesting
78:38 - because I think we also see them in
78:39 - terraform Cloud I'm not sure if this is
78:41 - the same kind of functionality but yeah
78:44 - that's in all resources okay
78:45 - [Music]
78:49 - all right let's take a look at terraform
78:51 - data so this is very very similar to
78:54 - null resource but the key difference
78:56 - here is that it does not require or the
78:59 - configuration of Provider because when
79:00 - you install null resource it actually
79:03 - installs a provider called null and so
79:07 - now it's just with this dare terraform
79:09 - data you can do something very similar
79:11 - like this with null resource and
79:13 - literally replace it with terraform data
79:15 - and for more or less it will do the same
79:17 - thing now it's not one to one because uh
79:20 - some of those parameters are a little
79:22 - bit different so instead of triggers we
79:24 - have triggers replace but more or less
79:27 - you know you can almost replace it and
79:31 - get the exact same result and you know I
79:34 - would recommend it over using null I was
79:37 - trying to figure out if there was a case
79:39 - where you'd want to use an all resource
79:41 - but I really could not determine that it
79:45 - did not seem like there was anything
79:46 - additional so yeah there you go it's as
79:49 - simple as that
79:50 - [Music]
80:01 - foreign
80:05 - [Music]
80:22 - hey this is Andrew Brown from exam Pro
80:23 - and we are taking a look at terraform
80:25 - providers so providers are terraform
80:27 - plugins that allow you to interact with
80:29 - cloud service providers like AWS Azure
80:31 - gcp software as a service provider so
80:34 - GitHub and Golia stripe or other apis
80:38 - such as kubernetes or postgres servers
80:40 - there's a lot there there's like over a
80:42 - thousand providers so providers are
80:44 - required for your terraform
80:45 - configuration file to work so you have
80:46 - to have at least one provider and
80:48 - providers can come in three different
80:50 - tiers we have the official one so
80:51 - published by the company that owns the
80:53 - provider technology or service verified
80:55 - so actively maintained up to date and
80:57 - compatible with both terraform provider
80:59 - communities so published by Community
81:00 - member but no guarantee of Maintenance
81:02 - up to date or compatibility providers
81:04 - are distributed separately from
81:05 - terraform and the plugin must be
81:07 - downloaded before use so if we do
81:09 - terraforming knit this will download the
81:11 - necessary plugin provided plugins listed
81:13 - in the terraform configuration file so
81:14 - there you go
81:15 - [Music]
81:20 - hey this is Andrew Brown from exam Pro
81:22 - and we are taking a look at the
81:23 - terraform registry so this is a website
81:26 - portal to browse download or publish
81:28 - available providers and modules and just
81:31 - remember providers and modules are
81:33 - plugins within terraform both of them
81:34 - okay so to get to this website we go to
81:38 - registry.terraform.io and everything
81:40 - published to the terraform registry is
81:42 - public facing so let's just distinguish
81:44 - between providers and modules and I feel
81:47 - that I should have given providers a
81:49 - little bit more attention in the uh in
81:51 - its own slide but I'll give it a clear
81:53 - distinction between providers and
81:54 - modules here so a provider is a plug-in
81:57 - that is a mapping to a cloud service
82:00 - provider's API so if you wanted to call
82:03 - individual API actions that is what the
82:05 - provider is providing to you when we're
82:08 - talking about modules a module actually
82:10 - relies on a provider plugin but a module
82:13 - is a group of configuration files that
82:15 - provide common configuration
82:16 - functionality this is going to help you
82:18 - enforce best practices reduce amount of
82:20 - code code reduced time to develop
82:22 - scripts so the way to think about it is
82:25 - imagine that you have to do something in
82:27 - your CSP like AWS and there's just
82:29 - common things that would go along with
82:31 - it so let's say you're launching a load
82:33 - bouncer Auto scaling group with ec2
82:34 - instances that's a bunch of services
82:36 - that you are just very common you'd have
82:38 - to configure it together so there could
82:39 - be a module that allows you to do all
82:42 - that with writing very little amount of
82:44 - code it will choose best practices when
82:46 - doing that okay
82:47 - [Music]
82:52 - let's take a look here at providers and
82:54 - modules within terraform registry really
82:55 - quickly so um here is the AWS one here
82:58 - and so I just want to point out that
83:00 - this official one is by hashicorp it's
83:02 - not by AWS but it does mean that it has
83:04 - uh proper support so you know it's going
83:06 - to have pretty much one-to-one mapping
83:08 - to the AWS API
83:10 - um and so it has really really good
83:12 - documentation now I complain about
83:14 - terraform not having great documentation
83:17 - for learning like their language but for
83:19 - the actual documentation of doing things
83:21 - practically they're really really good
83:23 - and here's just an example where we see
83:25 - app mesh and they just give you full
83:26 - examples for basically everything it's
83:28 - really great and if you need a code
83:31 - sample to get going like to actually
83:33 - install it within your configuration
83:35 - file it's right there over here so you
83:37 - can just go ahead and grab that for
83:39 - terraform modules it looks pretty
83:42 - similar so the idea is you get your
83:44 - module code on the right hand side here
83:46 - you want to check out the examples it's
83:48 - going to be dependent on who is
83:50 - developing these modules this one is
83:51 - made by Anton so he has lots and lots of
83:55 - really great examples and then you can
83:57 - see a list of dependent modules here
83:58 - under sub modules so it's not too
84:00 - complicated so there you go
84:02 - [Music]
84:06 - so we're taking a look at terraform
84:07 - registry which is a public registry but
84:10 - let's talk about private registry how
84:12 - would we do that well that's where we
84:13 - use terraform Cloud it allows you to
84:15 - publish private modules for your
84:16 - organization within the terraform Cloud
84:18 - private registry when creating a module
84:21 - you need to connect to a Version Control
84:22 - System of VCS and choose a repository so
84:25 - here you can see
84:27 - we can be using something like GitHub
84:29 - gitlab betbucket or azure devops
84:32 - and of course we're going to cover
84:34 - terraform Cloud a lot more further on in
84:37 - the course and it does definitely does
84:38 - more than just act as a private registry
84:41 - but I figured this is the best place to
84:43 - put it against the terraform registry
84:45 - okay
84:45 - [Music]
84:49 - let's take a look at how we would get a
84:51 - list of the current providers you are
84:53 - using so all you'd have to do is type in
84:55 - terraform providers and you'd get a full
84:56 - list this command is useful if you have
84:59 - a very complex
85:01 - architecture where you're using a lot of
85:03 - files and modules within terraform I
85:07 - wanted to just show this command just
85:09 - because I saw it on the exam and so it's
85:11 - just an easy point if you happen to get
85:13 - that question okay
85:14 - [Music]
85:18 - so we know we can set multiple providers
85:21 - of in our terraform configuration file
85:23 - but there are some variations here that
85:25 - you should know so one thing is is that
85:28 - if you need to have an alternate
85:29 - provider you can use this thing called
85:31 - Alias so if you just notice here there's
85:33 - the Alias this is useful if let's say
85:35 - you want to have resources within
85:38 - different regions of AWS is a very
85:40 - common use case when you want to
85:42 - reference uh what resource should use
85:45 - with provider you're going to have that
85:47 - little provider attribute and then
85:48 - you're just going to do what the name is
85:51 - of the provider followed by the Alias
85:54 - you can also set an alias provider for a
85:57 - parent module so notice here in the
86:00 - required providers we have this
86:02 - attribute here and we're using this
86:04 - configuration Alias and then if you need
86:07 - to set an alias provider for a child
86:09 - module but more or less you just need to
86:11 - remember these two up here okay for
86:12 - setting an alias
86:14 - [Music]
86:18 - hey this is Andrew Brown from exam Pro
86:20 - and we're giving closer attention to
86:22 - modules so a terraform module is a group
86:24 - of configuration files that provide
86:26 - common configuration functionality to
86:28 - enforce best practices reduce the amount
86:30 - of code and reduce the time to develop
86:32 - scripts I definitely had a lot of
86:34 - confusion understanding the difference
86:35 - between a provider and a module
86:37 - initially but the clear thing is that a
86:39 - provider is just an API mappings to the
86:43 - service okay so on the example here on
86:46 - the left we have AWS as a provider and
86:48 - the example is to show you if you had to
86:50 - create a VPC you'd have to specify many
86:52 - networking resources and just notice
86:55 - that I have the three ellipses there to
86:57 - suggest there is a lot more that you'd
86:58 - have to configure but by using a module
87:01 - and there's one called the AWS VPC
87:03 - module it basically has this short
87:05 - domain specific language
87:07 - that allows you to quickly provision a
87:10 - VPC so the easy way to remember modules
87:13 - is Imagine clicking a wizard that
87:14 - creates many Cloud resources like it
87:17 - able to have the VPC wizard that's
87:19 - basically the idea behind modules just
87:21 - to kind of give a better contrast to the
87:24 - value that modules have we'll look at
87:25 - the Azure provider so imagine you had to
87:27 - provision an Azure virtual machine this
87:29 - is how much code you'd have to write so
87:31 - it's going to vary based on providers so
87:33 - AWS does not require this much work it's
87:35 - very short gcp requires a little bit
87:38 - more work and for some reason Azure
87:39 - requires a lot so this is a case where
87:41 - you'd want to use a module so there's a
87:43 - module called compute and network module
87:45 - and it reduces the code to amount of
87:47 - this still a bit long but that's just
87:49 - what it is okay
87:51 - thank you
87:54 - [Music]
87:55 - all right let's talk about the fine line
87:57 - and this is understanding the gray areas
87:59 - of responsibility between terraform
88:00 - infrastructure as code and third-party
88:03 - configuration management tools like
88:05 - ansible so there are cases where when
88:08 - you get outside of AWS as your gcp you
88:11 - might see providers like for postgres
88:14 - database and you might say okay well
88:16 - what part of terraform should be
88:18 - automating it and so that's a little bit
88:21 - more complicated question because
88:22 - terraform does more than one thing so
88:24 - terraform has providers modules and
88:27 - provisioners and then on outside of that
88:29 - if we're not even using terraform we
88:30 - have third-party configuration
88:31 - management tools that we can use like
88:33 - ansible and the thing is is that you
88:36 - could have ansible do everything but
88:38 - that does not mean that you should have
88:39 - it do everything and with terraform at
88:42 - more or less most of these levels you
88:44 - can have them do everything but that
88:45 - doesn't mean that they should right so
88:47 - the idea is to try to figure out what
88:49 - should be where and how to define that
88:51 - so let's talk about creating a database
88:53 - so if we created a database that is like
88:55 - setting up a new service so that is
88:58 - going to be under the providers and so
89:00 - you'd use the postgres terraform
89:02 - provider to set up a database now you
89:04 - have users and so users are an entity
89:08 - they're not just like loose data so
89:10 - there's something that you can add
89:11 - remove add permissions to and we would
89:13 - treat them as entities and so it
89:15 - wouldn't necessarily be under the
89:16 - providers but that's a great place to
89:17 - put it under modules okay then you have
89:21 - your data so where would the data go
89:23 - well data is not necessarily an entity
89:26 - it's just a bunch of data so I would say
89:29 - that that is for provisioners that can
89:30 - run random scripts and then when we want
89:33 - to do things like backup tables to data
89:36 - warehouses or truncate data daily tables
89:40 - things that are repetitive tasks that is
89:42 - what we're going to use ansible for or a
89:44 - third-party configuration management
89:45 - tool outside of terraform you wouldn't
89:47 - have terraform to that stuff at all so
89:49 - when you have a task done one time to
89:51 - set up the database like seating data
89:53 - it's going to go to provisioners what
89:55 - you have repeatable tasks for ongoing
89:57 - maintenance it's going to be out as a
89:59 - third party provider and if you have
90:01 - something that is like identified as an
90:03 - identity like as a resource that you
90:05 - want to manage like Asset Management
90:07 - which are these things these are going
90:09 - to be over here in providers and modules
90:11 - I do want to point out that a
90:13 - provisioner can be using ansible but we
90:15 - would still want to use ansible or
90:17 - third-party configuration management
90:18 - tool isolate or separate to do these
90:21 - kind of things you do not want terraform
90:23 - running these okay
90:25 - foreign
90:28 - [Music]
90:37 - hey this is Andrew Brown from exam Pro
90:39 - and we are looking at Hashi Corp
90:41 - configuration files also known as
90:43 - terraform files that which contain the
90:45 - configuration information about
90:46 - providers and resources this is
90:48 - basically core to terraform and that's
90:50 - what we're doing so terraform files and
90:52 - in the extension of dot TF or TF Json
90:56 - and we'll talk about the Json case a
90:58 - little bit later but terraform files are
91:00 - written in the terraform language and so
91:03 - here is kind of an abstract way of
91:05 - looking at the language I know it's
91:06 - confusing here but don't worry we're
91:08 - going to reiterate on it to make more
91:09 - sense but terraform language consists of
91:11 - only a few basic elements you have
91:13 - blocks and so these are containers for
91:16 - other content and they represent an
91:18 - object so I'll have a block type which
91:20 - can have zero or more labels and a body
91:22 - you have a block label it's a name of a
91:24 - block you have arguments which is which
91:27 - is what you assign a value to a name so
91:29 - notice like we have assignments so we
91:31 - have identifier to an expression okay
91:33 - they will appear within block so here it
91:35 - is within a block as you can see
91:37 - um Expressions represent a value either
91:40 - literally or by referencing and
91:42 - combining other values they appear as
91:44 - values for arguments or within other
91:46 - Expressions you might come across
91:48 - hashicorp configuration language so HCL
91:50 - and this is the low level language for
91:52 - both the terraform language and
91:54 - alternative Json syntax I don't know if
91:56 - we'll be getting into it in this course
91:59 - um or if there's even an easy way to
92:00 - distinguish it because it's basically
92:01 - terraform language but just if you see
92:03 - HCL just think terraform language it's
92:05 - the easiest way to think about it okay
92:07 - [Music]
92:12 - let's take a look here at the alternate
92:14 - Json syntax so terraform supports
92:16 - alternate syntax that is Json compatible
92:18 - terraform expects Json syntax files to
92:20 - be named dot tf.json so we mentioned
92:23 - that earlier and so this is generally
92:24 - what it would look like okay the syntax
92:28 - is useful when generating portions of a
92:29 - configuration pragmatically since
92:31 - existing Json libraries can be used to
92:33 - prepare the generate configuration files
92:35 - and that's pretty much it would you want
92:37 - to work on this it's up to you
92:40 - um but uh yeah so that's the reason for
92:42 - this alternate syntax
92:43 - [Music]
92:47 - all right let's take a look at terraform
92:49 - settings so the terraform configuration
92:51 - block type terraform curly braces you'll
92:54 - see this within your configuration file
92:56 - is used to configure some behaviors of
92:58 - terraform itself so here is what it
93:01 - looks like and what's very common is
93:02 - you're going to see those required
93:03 - providers so there are different things
93:05 - that we can put in here so we can put
93:07 - the required version so this expects us
93:09 - to match to a particular version of
93:11 - terraform required providers this is the
93:14 - providers that will be pulled during the
93:16 - terraform init we can also do
93:18 - experiments here so these are
93:19 - experimental language features that the
93:21 - community can try and provide feedback
93:22 - on and then we have provider metadata so
93:25 - this is module specific information for
93:27 - providers okay
93:29 - [Music]
93:33 - hey this is Andrew Brown from exam Pro
93:35 - and we are taking a look at the
93:37 - hashicorp configuration language also
93:39 - known as HCL I'm going to tell you I was
93:42 - really confused at the start working
93:43 - with terraform because sometimes they
93:45 - mention things like hashicorp
93:47 - configuration files hashicorp
93:48 - configuration language terraform
93:50 - language and I could not discern you
93:52 - know what the difference was but so this
93:54 - is the idea here is to give you that
93:56 - Clarity okay so HCL is an open source
93:58 - toolkit for creating structured
94:00 - configuration languages that are both
94:02 - human and machine friendly for use of
94:05 - command line tools and it's an open
94:07 - source project so you can find it at
94:08 - github.com
94:10 - HCL so the idea is that they have this
94:12 - Baseline language that you can extend
94:15 - for your own use case so uh terraform is
94:18 - using it and so it uses a good like it
94:22 - uses the language itself but then it
94:23 - goes ahead and extends it by adding
94:25 - additional functionality for its
94:27 - specific use case and this HCL based
94:30 - language is not just for terraform it's
94:33 - used for hacker templates Vault policies
94:36 - boundary controllers and workers console
94:39 - configuration Waypoint application
94:41 - configuration Nomad job specification
94:44 - and this one isn't a hash Accord product
94:47 - but this is an open source project
94:48 - called Shipyard and you can use it for
94:50 - Shipyard blueprints surprisingly
94:52 - Sentinel which is a Hachi Corp policy as
94:55 - code server service does not use HCL but
95:00 - it has its own HC ACL custom language
95:03 - but the idea is that you know we're
95:06 - looking at mostly the use case is for
95:09 - hashicorp services but if you wanted to
95:12 - extend this language for your own use
95:14 - case you totally could and so I think
95:16 - that's really cool but hopefully that
95:18 - kind of distinguishes between HCL and
95:20 - terraform language okay
95:21 - [Music]
95:26 - hey this is Andrew Brown from exam Pro
95:28 - and we are taking a look at input
95:29 - variables so also known as terraform
95:32 - variables or just variables are
95:34 - parameters for terraform modules that is
95:36 - the way we get data in to our
95:38 - configuration scripts is via input
95:41 - variables so you can declare variables
95:43 - in either the root module or child
95:45 - modules and the way you define them is
95:48 - via this variables block there at the
95:51 - top and just to kind of go over the
95:53 - possible fields for that block we have
95:56 - the default option so the default option
95:58 - which is here is going to be the default
96:00 - variable if you do not set it
96:03 - for type this is an argument that
96:04 - specifies the value types that are
96:06 - accepted for the variable so this case
96:08 - up here we can see string and this one
96:10 - is a list
96:12 - for description this specifies the input
96:14 - variables documentation we don't see an
96:16 - example there I believe that is optional
96:18 - but it's always great to put a
96:19 - description in when you can there is a
96:21 - validation block so a block to Define
96:23 - validation rules usually in addition
96:25 - addition to type constraints so we don't
96:28 - see that here on the right hand side but
96:30 - the idea is that you know let's just
96:31 - make sure that there's less of a human
96:33 - error entering the wrong information you
96:35 - can also have sensitive this limits
96:37 - terraform UI output when the variable is
96:40 - used in the configuration and we will
96:42 - cover sensitive a lot more in this
96:44 - course outside of just this one slide
96:45 - okay
96:46 - [Music]
96:50 - let's take a look here at variable
96:52 - definition files and these allow you to
96:54 - set the values for multiple variables at
96:56 - once so variable definition files are
96:58 - named with the dot TF vars extension or
97:01 - if you want to use the alternative
97:02 - syntax it's the
97:03 - tfbars.json file by default if you have
97:07 - a file called
97:09 - terraform.tfrs within your project
97:11 - directory this will be automatically
97:12 - loaded so it's pretty common to make
97:14 - that file to create a definition file it
97:18 - just uses the terraform language so you
97:20 - would just assign
97:22 - values here you wouldn't make variable
97:24 - blocks but you just Define these um
97:27 - identifiers and give them values okay
97:30 - [Music]
97:35 - another way of loading input variables
97:38 - is via environment variables and this is
97:40 - very common uh way of loading them if
97:43 - you have your own CI CD process for
97:45 - terraform so if you're using terraform
97:46 - cloud or you're using some kind of build
97:49 - server that's going to be the primary
97:50 - way you're going to get variables into
97:53 - those build servers probably won't be
97:57 - doing this much locally but the way it
97:59 - works is that terraform will watch for
98:01 - any environment variable starting with
98:02 - TF underscore VAR underscore followed by
98:05 - the name this is very important to
98:07 - remember because it definitely will show
98:09 - up on the exam so let's say we want to
98:12 - do set a variable for an image ID so we
98:15 - do TF underscore VAR and then image ID
98:18 - probably most cases when you follow the
98:21 - name it's going to be a lowercase
98:22 - underscore I don't think you'd probably
98:24 - want to uppercase that stuff and you
98:26 - just set the value okay
98:27 - [Music]
98:32 - so there's a lot of ways for us to load
98:34 - input variables we just saw two so we
98:36 - saw terraform tfrs and environment
98:38 - variables but there's a lot more caveats
98:41 - to this so let's just run through them
98:42 - so we already covered uh terraform.tfrs
98:45 - the idea here is that if you create this
98:47 - file and it's in your project it will
98:49 - automatically be loaded when running
98:50 - terraform apply you can name other TFR
98:53 - files uh so I just called them use
98:55 - additional TFR files but they won't be
98:57 - loaded by default you'll have to use a
98:59 - command line to load them this is useful
99:01 - if you have like a Dev and prod
99:02 - environment and you want to swap those
99:04 - out now if you want to have files that
99:08 - auto load then you can just put the dot
99:10 - Auto here and give it any name you want
99:12 - this would be useful if let's say you
99:14 - had a very large terraform tfrs file and
99:16 - you wanted to break it up to make it
99:17 - more human readable you could do that
99:20 - then you have the hyphen VAR file flag
99:23 - when you're doing terraform apply or or
99:26 - plan and this is actually how you load
99:28 - up these additional variable files if
99:30 - you need to override a single value you
99:32 - you can use hyphen VAR so here I'm
99:34 - overriding the ec2 type to be T2 medium
99:36 - and then lastly here we have environment
99:38 - variables we covered this this is where
99:40 - it starts with TF underscore VAR
99:42 - underscore followed by the name and this
99:44 - is going to be very common when you are
99:46 - using Code build servers or runtimes to
99:49 - run this in a CI CD automated way now
99:52 - there's a precedence to which these get
99:54 - loaded meaning that that certain
99:57 - configurations of or input of variables
99:59 - will override other ones so as we go
100:01 - down this list these ones will override
100:03 - the previous one so at the top you have
100:04 - environment variables if you have a
100:06 - terraform tfrs file that will override
100:08 - the environment variables if you have
100:10 - the Json one that will override that one
100:12 - if you have auto files that will
100:14 - override the default tfrs file and then
100:18 - on the last list you have hyphen VAR and
100:19 - hyphen VAR file will override the rest
100:21 - so there you go in terms of the exam
100:24 - they're not going to ask you the
100:25 - president's here but you're going to
100:27 - need to know what VAR VAR file are
100:28 - environment variables are in this
100:30 - default line okay
100:32 - thank you foreign
100:34 - [Music]
100:36 - let's take a look here at output values
100:38 - which are computed values after a
100:40 - terraform apply is performed output
100:41 - values allow you to obtain information
100:43 - after resource provisioning such as a
100:46 - public IP address I'll put a file of
100:48 - values for chromatic integration
100:49 - cross-reference Stacks via outputs in a
100:52 - state file via terraform remote State
100:53 - and so here's an example of an outputs
100:56 - block so notice that there's a block and
101:00 - you specify some stuff there you can
101:01 - optionally provide a description it's
101:03 - not necessary but generally with outputs
101:05 - I would recommend putting that in there
101:07 - you can also Mark it as sensitive so it
101:09 - does not show in your terminal this is
101:12 - important if you're doing like logging
101:13 - stuff you don't want to compromise those
101:15 - values there but understand that output
101:18 - values even though they might not be
101:21 - outputted to your terminal or SD out
101:23 - they will be visible within the state
101:25 - file so if somebody opens up the state
101:27 - file they're going to be plainly visible
101:29 - there so just understand that sensitive
101:31 - does not protect the values there okay
101:34 - now in terms of how we would use the CLI
101:36 - with the output values if we type
101:38 - terraform output it's just going to
101:40 - print out all the values that are within
101:41 - the state file I don't show this in the
101:44 - example here but if you wanted to use a
101:47 - um a like bash command to parse Json you
101:52 - could extract them out and see they're
101:53 - just plainly in the Json okay if you
101:55 - need to get exactly a particular field
101:58 - you type in terraform output and Then
102:00 - followed by the name if you wanted an
102:02 - adjacent format all the output then you
102:04 - could give that flag I don't know if it
102:07 - would work with this one I actually
102:08 - didn't test I just thought about that
102:09 - here for this one here if you want the
102:12 - raw output of it meaning like if you
102:14 - output a string and you want it to be
102:16 - escaped or what have you then you could
102:18 - use it pragmatically by passing it to
102:20 - something like curl to do something but
102:22 - the idea with all these output values is
102:23 - that it's one way of inspecting but you
102:25 - could also use this in a configuration
102:27 - script or or something to do kind of
102:29 - like an after action okay
102:31 - [Music]
102:36 - all right so we're taking a look at
102:37 - local values also known as locals that
102:39 - assigns a name to an expression so you
102:41 - can use it multiple times within a
102:43 - module without repeating it so here what
102:46 - we're going to do is Define our local
102:47 - block up here and then the idea is that
102:50 - we're assigning these names or IDs
102:52 - expressions or values so that we can
102:55 - reuse them throughout our code notice
102:57 - that we can Define multiple local blocks
102:59 - in the same file and I just say this
103:02 - because like when you use required
103:03 - providers you're only allowed to have a
103:04 - single block but this case like with
103:06 - variables or locals you can have many
103:08 - and you could even Nest them within each
103:10 - other so notice down here we're
103:12 - referencing local within a local so
103:14 - that's totally possible and I imagine
103:16 - it's in the order to which it is
103:18 - specified we can do static values or
103:21 - computed values so we can actually
103:22 - here's a function write an expression
103:24 - and then it will output a value
103:27 - once a local value is declared you can
103:29 - reference it via the dot as local dot
103:33 - the name so here notice within our it
103:35 - was resource we have local and common
103:37 - tags I have to point this out but when
103:40 - you're referencing you use the singular
103:42 - local because you might get an exam
103:44 - question which shows you local dot or
103:46 - locals Dot and the trick here is you got
103:49 - to remember which one it is locals help
103:51 - can help dry up your code it is best
103:54 - practice to use local sparingly since
103:56 - it's uh in terraform it's intended to be
103:59 - declarative and overuse of locals can
104:01 - make it difficult to determine what the
104:04 - code is doing this call comes back to
104:06 - describing terraform as declarative plus
104:08 - where they give you functionality that's
104:10 - imperative like but the idea is that you
104:12 - know if you overuse these you can run
104:14 - into trouble okay
104:15 - [Music]
104:20 - hey it's Andrew Brown from exam Pro and
104:22 - we are taking a look at data sources for
104:25 - terraform so the idea here is you want
104:27 - information to find outside of terraform
104:29 - and it's defined by another separator
104:32 - from configuration or Modified by
104:34 - functions so the idea here is we are
104:37 - going to Define ourselves a data block
104:39 - and we have an external resource we're
104:41 - looking for so we're saying hey I want
104:43 - to see if I have an AWS Ami we're going
104:46 - to use these filters as a way of of kind
104:49 - of selecting it within our AWS account
104:51 - so we'd have a provider set up and so
104:53 - it'd be looking within that account to
104:55 - find it and it's even saying look for
104:57 - the most recent Ami okay and once we
105:00 - have found that data source we can just
105:03 - reference it so notice we're using data
105:05 - to reference it there so data AWS
105:08 - ami.web ID so there you go
105:11 - [Music]
105:16 - we're taking a look here at name values
105:18 - and these are built-in Expressions that
105:19 - reference uh various values you'll find
105:21 - your configuration scripts we do cover
105:23 - these in their respected sections but I
105:26 - wanted to consolidate them here in one
105:27 - place just so that you get a second
105:30 - chance to reinforce this information
105:32 - because Crux of questions of the exam
105:34 - could be based on knowing how the name
105:37 - values work so let's go through them the
105:39 - first is resources I'm going to get up
105:40 - my pen tool here and so the way
105:42 - resources work is that you start with
105:44 - the resource type so AWS instance and
105:47 - then you're going to do the name of it
105:48 - so there's nothing that uh
105:51 - starts before the left hand side of it
105:53 - so just remember it just starts with
105:54 - that resource type then you have input
105:56 - variables and that starts with VAR
105:58 - period so that's the singular VAR then
106:00 - we have local values and again that's
106:01 - singular so local period for child
106:04 - modules it starts with module period
106:05 - again singular for data sources it's
106:08 - going to be data singular just remember
106:09 - singular because they can have a matchup
106:12 - on the on the exam questions whether
106:14 - it'll be like data or datas for file
106:17 - system and workspace info we have
106:18 - path.module this is the path of module
106:20 - where the expression is placed we have
106:22 - path.root this is the path of the root
106:24 - module of the configuration we have path
106:26 - CWD this is the path of the current
106:28 - working directory and in practice the
106:31 - default CWD is the same as the roots so
106:33 - those would be technically the same we
106:35 - have terraform.workspace this is the
106:37 - name of the currently selected workspace
106:38 - then we have block local values these
106:41 - are things that appear within a body of
106:43 - a blocks so this could be within a
106:45 - resource provisioners things like that
106:47 - so we have if we're using the count meta
106:50 - argument we're going to get count and
106:51 - with that we'll have count dot index so
106:53 - we can say okay this is the fourth
106:56 - iteration of you know uh this this
106:59 - account Loop then we have for each and
107:02 - this allows us to have the key and the
107:04 - value so we can access that during our
107:05 - iterations we have self uh so selfless
107:08 - uh references information within
107:10 - provisioners or connections so it's just
107:13 - like a self-referencing thing name
107:14 - values resemble the attribute notation
107:17 - of map or object values but are not
107:19 - objects and do not act as objects you
107:21 - cannot use square brackets to access
107:22 - attributes of name values like an object
107:24 - so there you go
107:25 - [Music]
107:33 - foreign
107:36 - [Music]
107:54 - hey this is Andrew Brown from exam Pro
107:56 - and we are taking a look at resource
107:57 - meta arguments so the terraform language
107:59 - defines several meta-arguments which can
108:01 - be used with any resource type to change
108:03 - the behavior of resources and so we'll
108:06 - quickly go through the list here and
108:07 - then we will Deep dive on each so the
108:09 - first is depends on so this is for
108:10 - specifying explicit dependencies we have
108:12 - count which is for creating multiple
108:14 - resource instances according to account
108:16 - we have four each which is used to
108:18 - create multiple instances according to a
108:20 - map or set of strings provider so this
108:23 - is for selecting a non-default provider
108:24 - configuration life cycle this is for
108:27 - life cycle customizations provisioner
108:30 - this is and also for connections for
108:31 - taking extra actions after resource
108:34 - creation so there's the Quick List now
108:36 - let's jump into them
108:37 - [Music]
108:41 - all right the First Resource meta
108:43 - argument we want to look at here is
108:44 - called depends on and this is the order
108:46 - of which resources are provisioned and
108:47 - is important when resources depend on
108:49 - others before they are provisioned
108:51 - terraform implicitly can determine the
108:53 - order of provision of resources but
108:55 - there may be some cases where it cannot
108:57 - be determined or like the correct order
109:00 - so this is where you can be a bit more
109:01 - explicit so here we have some terraform
109:04 - configuration where we have an AWS
109:06 - instance and it relies on a policy and
109:09 - so what we're doing is we're setting an
109:10 - explicit depends on here so that it
109:13 - knows that it requires that now in a
109:15 - normal use case you would not have to do
109:16 - this but it's hard to find use cases
109:18 - where this happens but when it does
109:21 - become a problem you'll know because
109:22 - your resources will not provision
109:24 - correctly you'll get an error so there
109:25 - you go
109:26 - [Music]
109:30 - let's take a look here at the count
109:32 - resource meta argument and this is when
109:34 - you're managing a pool of objects so an
109:36 - example here would be a fleet of virtual
109:38 - machines where you want to use count so
109:41 - here on the right hand side we have an
109:43 - example of us using that in terraform so
109:45 - we can specify the amount of instances
109:47 - we want so here it is four and then
109:49 - we'll have access to this name value
109:51 - called count dot index so the tags will
109:55 - start at zero so it'll be server zero
109:57 - one two and three then just down below
110:01 - here I just want to show you that with
110:03 - count you can accept a numeric
110:05 - expression so you know if you had a
110:07 - variable that you had set as the subnet
110:09 - IDs or even just an arbitrary number
110:11 - like you want to have X amount of
110:12 - servers this would allow you to do that
110:15 - okay but just so you know those numbers
110:17 - must be whole and a number must be known
110:20 - before the configuration which you'd put
110:22 - in your input variables okay
110:24 - [Music]
110:29 - all right so let's take a look here at
110:30 - four each which is for iterating over
110:32 - resource meta arguments but it's
110:34 - slightly different because it allows you
110:37 - to map over Dynamic values giving you a
110:39 - little bit more flexibility so here's an
110:41 - example of us defining A4 each and
110:44 - notice that we have defined a map
110:45 - sometimes I call it an object because
110:47 - they're so similar but this is a map and
110:50 - the idea is that once you have your map
110:52 - defined with your 4-H you will now have
110:54 - access to these name values so you can
110:55 - do each dot key or each dot value to
110:57 - extract that out
110:59 - you can also just use it like with an
111:02 - array so here we have an array and then
111:04 - we use two set to turn it into a set
111:07 - which it will accept as well and then we
111:10 - can just pull out the key because there
111:11 - will be no value so just an example of
111:14 - with a map and then with something that
111:15 - looks like an array okay
111:17 - [Music]
111:21 - to understand the resource meta argument
111:24 - life cycle we need to understand how
111:27 - resource Behavior works and so when you
111:29 - execute your execution order via
111:31 - terraform apply it will perform one of
111:33 - the following to a resource so the most
111:36 - common one you'll see is a create so
111:38 - these are resources that exist in the
111:40 - configuration but are not associated
111:41 - with a real infrastructure object in the
111:44 - state the way you can tell it's creating
111:46 - it will have this nice little green plus
111:47 - sign the next one is destroy so
111:51 - resources that exist in the state but no
111:53 - longer exist in the configuration and so
111:55 - that's going to tear down your resources
111:57 - out of your Cloud providers this is
111:59 - represented by a minus symbol then you
112:01 - have update in place so the resources
112:04 - who arguments have changed so the idea
112:06 - here is that if you have a virtual
112:08 - machine and let's say you change the
112:09 - size of it it's not going to destroy it
112:11 - it's just going to modify its settings
112:13 - this is represented with a tilde and the
112:17 - last one here is destroy and recreate so
112:20 - resources who arguments have change but
112:22 - which cannot be updated in place due to
112:24 - remote API limitations so there are just
112:26 - some Cloud resources that always require
112:28 - destroy and recreate and this is
112:30 - something very easy to trigger if you
112:32 - are using the replace command or the
112:36 - older terraform tank command in order to
112:38 - replace a degraded or damaged instance
112:41 - so let's talk about life cycle so
112:44 - lifecycle blocks allow you to change
112:45 - what happens to resources on the create
112:47 - update and Destroy lifecycle blocks are
112:49 - nested within resources so here is a
112:52 - resource which is just an Azure Resource
112:54 - Group and within it we have a life cycle
112:56 - block and we're setting our first option
112:58 - here that's possible called the create
113:00 - before destroy so this is a Boolean and
113:02 - when replacing a resource first create
113:04 - the new resource before deleting it so
113:06 - the default is destroyed old first so
113:08 - this is more about just the order of How
113:09 - It's destroyed prevent destroy so
113:12 - ensures a resource is not destroyed then
113:14 - we have ignore changes and this is based
113:16 - off a list of attributes that you feed
113:18 - to it so don't change the resource on
113:20 - create update to store right if a change
113:22 - occurs for the listed attributes so
113:24 - maybe
113:25 - um maybe you uh you're just changing a
113:28 - tag and you say don't don't change uh
113:30 - like don't tear down create or do
113:32 - anything strange if we change a tag okay
113:34 - so there you go that's uh life cycles
113:37 - [Music]
113:41 - so we're looking at our last meta
113:43 - argument here which are resource
113:44 - providers and this goes along with the
113:46 - idea of an alias so here we are defining
113:48 - ourselves a provider in Google Cloud but
113:51 - there's a case where we might need to
113:52 - override the provider uh at a at a per
113:56 - resource level and the way we do that is
113:58 - by creating an additional provider and
114:00 - setting an alias and then here we could
114:02 - change something like the region and
114:04 - then once we have that set we can then
114:05 - reference our provider explicitly under
114:08 - a resource and so that's all there is to
114:10 - it definitely on your exam you will see
114:12 - a question about Alias or you'll see
114:14 - that example so definitely want to know
114:16 - how to do that okay
114:17 - [Music]
114:22 - thank you
114:24 - [Music]
114:41 - all right so we're starting our
114:43 - introduction here into terraform
114:44 - Expressions because there's a lot we can
114:46 - talk about here so expressions are used
114:48 - to refer to or Com or compute values
114:51 - within a configuration so terraform
114:53 - Expressions is a large topic and we'll
114:55 - be covering types and values strings and
114:57 - templates reference to values operators
114:59 - function calls conditional Expressions
115:02 - four Expressions Splat Dynamic blocks
115:06 - type constraints actually I don't think
115:08 - we covered type constraints just because
115:09 - there's nothing really to say about it
115:11 - but we definitely cover version
115:12 - constraints so yeah let's start off the
115:14 - section and go to it
115:15 - [Music]
115:19 - so we're taking a look here at types and
115:21 - values for expressions and so the result
115:23 - of an expression is a value and all
115:25 - values have types and so we have
115:27 - primitive types no type and complex
115:29 - structural collection types that last
115:31 - one is a bit more complicated than what
115:33 - we are presenting here we're going to
115:35 - simplify it and then cover it later okay
115:37 - so for primitive types we have strings
115:39 - so you have your double quotations which
115:42 - represent your string then you have
115:43 - numbers so it's going to be integers or
115:45 - floats then you have booleans so this is
115:48 - either true or false for no types we
115:50 - have null and so null is different in
115:53 - all different types of languages so it's
115:55 - very important to understand how it
115:56 - works and so null represents absence or
115:58 - Omission when you want to use the
116:00 - underlying default of a provider's
116:02 - resource configuration option so when
116:04 - you're saying null doesn't mean it's
116:05 - nothing it's going to be whatever the
116:07 - default is and the default also could be
116:09 - nothing it's just depending on what that
116:11 - is on the provider so for collection or
116:13 - for a collection types complex
116:15 - structural types we have list or Tuple
116:17 - and this generally looks like an array
116:19 - the then you have map and object and
116:21 - this looks like basically like a Json
116:23 - object or a ruby hash or I think they
116:26 - call it in Python a dictionary so that
116:29 - gives you an idea of the basic types but
116:31 - for this last one here because this I
116:33 - found really confusing list tuples map
116:35 - object we definitely explain this more
116:37 - in the course okay
116:38 - [Music]
116:42 - okay so we're giving a little bit more
116:43 - attention to the string type because
116:45 - there's a little bit more going on here
116:47 - so when quoting strings you got to use
116:49 - double quotes uh at one point terraform
116:51 - I believe supported single quotes I
116:53 - think it only Sports double quotes now
116:54 - and honestly you generally want to just
116:56 - use double quotes because double quotes
116:58 - always support Escape sequences this is
117:00 - pretty much standard across all
117:01 - programming languages but the idea here
117:04 - is you can do things like new line
117:05 - carriage return tab literal quotes
117:08 - literal backslashes Unicode characters
117:10 - both basic multilingual plane and
117:13 - supplementary planes there are some
117:15 - special Escape sequences this makes
117:17 - sense when we look at the next slide for
117:18 - string templates but there's these
117:21 - things where you can do interpolation
117:22 - and so you might not want to actually do
117:25 - them you might want to do it without and
117:28 - so if you just use double of the symbol
117:30 - that will allow you to do it then there
117:33 - is also the ability to have multi-line
117:34 - strings and we use hear DOC for that and
117:37 - so here Doc is a little bit different in
117:39 - all languages but here we're using Unix
117:40 - style so that means that we're going to
117:42 - start with these two two angled brackets
117:43 - to the left our opening angle brackets
117:46 - followed by some word that is all in
117:48 - uppercase it doesn't have to be eot it
117:51 - could be whatever you want I always like
117:53 - to type here Doc and then it has to end
117:55 - at the same indentation level with the
117:57 - same word all uppercase and then
117:59 - everything in between will be treated as
118:03 - um
118:04 - as multi-line the nice thing about this
118:05 - is that when you have this you can
118:07 - actually just use double quotes wherever
118:08 - you want because you don't have to
118:09 - escape them okay let's take a look at
118:11 - string templates because this is the
118:12 - real power of strings so the first is
118:15 - string interpolation and this allows you
118:17 - to evaluate an expression between the
118:19 - markers so the idea is instead of having
118:21 - to do double quotations and do plus
118:23 - signs to stitch together uh strings what
118:26 - you do is just do a dollar sign uh curly
118:29 - braces and then put the the expression
118:31 - or variable that you want uh to be
118:34 - converted okay then you have string
118:36 - directives and these are slightly
118:38 - different this allows you to evaluate an
118:40 - expression for a conditional logic
118:42 - between the markers so let's say we want
118:44 - to have an if else statement so if the
118:46 - name is blank
118:48 - then use VAR name or sorry if it's not
118:52 - blank then use the name provided
118:54 - otherwise put it as unnamed okay you can
118:58 - also use interpolation directives with
119:00 - hear docs so you know just to show that
119:03 - you can do it and then the last one
119:05 - thing here is you can strip out white
119:07 - space that would normally be left by
119:09 - directors blocks by providing a trailing
119:12 - tilde so just notice this little tilde
119:15 - here on the end because these do take up
119:16 - space so if you were to view it there'd
119:18 - just be an empty space there if you want
119:19 - that space to vanish then you just put
119:21 - that tilde on the end so there you go
119:24 - foreign
119:27 - let's take a look here at the possible
119:29 - operators that we can use within
119:31 - terraform expressions and so just a
119:33 - refresher operators are mathematical
119:34 - operations you can perform two numbers
119:36 - within Expressions I'm not going to show
119:39 - full examples here and the outputs of
119:41 - them because this is pretty common for
119:43 - programming or scripting languages and
119:45 - also the exam is not really going to
119:46 - focus on the use cases for these so it's
119:49 - just more so to tell you what is
119:51 - available too so you know what you can
119:52 - use the first is multiplication so you
119:55 - take two numbers and times them to get a
119:57 - larger number division so it uses a
120:00 - forward slash modulus and if you've
120:02 - never used modulus I really like this it
120:04 - allows you to see if something is
120:06 - divisible by a certain amount and then
120:07 - you get the remainder you have addition
120:09 - subtraction if you need to flip to a
120:12 - negative number you can just put a minus
120:13 - sign in front of it if you need to do
120:16 - equals its doubles if you want to do
120:18 - does not equal its exclamation equals
120:21 - then we have a less than so that's a
120:25 - open angled bracket less than or equal
120:27 - so that will be followed by an equal
120:29 - sign greater than is a closing angle
120:32 - bracket and Then followed by an equal
120:33 - sign for greater than or equal you have
120:35 - or which uses the double pipes you have
120:38 - n which uses the double ampersands if
120:40 - you need to flip a Boolean you can just
120:42 - put an exclamation in front of it so if
120:44 - it was true now it is false if it was
120:45 - false now is true I'm not sure what it
120:47 - would do for an all I would think that
120:49 - it would turn it to true but uh yeah so
120:52 - there you go
120:53 - foreign
120:58 - we're taking a look here at conditional
121:00 - expressions and this is pretty much the
121:01 - only way that you can do if-el
121:03 - statements within terraform but it works
121:05 - out fine and so it's actually using the
121:07 - ternary style of ill if else so what
121:09 - that looks like it's a single line so
121:11 - the it starts with a question mark so
121:13 - that's the if and then it's the True
121:15 - Value and then the colon represents the
121:17 - else and then you have your false value
121:19 - it's ternary because there's three
121:21 - things one two and three okay so that's
121:23 - the way I remember this thing it's not a
121:27 - a preferred way of doing Ethel
121:28 - statements in other languages because it
121:31 - is a little bit condensed but it makes
121:33 - sense when you're using scripting
121:34 - language and you're really restricted on
121:36 - per line actions so this is what it
121:38 - would look like in action so we'd have a
121:40 - variable that is a if a does not equal a
121:44 - blank then use the variable or set it to
121:47 - default a as a string so that's kind of
121:49 - an example there
121:50 - I'll just wipe that away there the
121:52 - return type of it of of the if and else
121:55 - must be the same type so if you have a
121:58 - number okay and the one if statement and
122:02 - then you have a string they have to be
122:03 - the same so uh obviously we want a
122:07 - string to be returned in both cases so
122:08 - what we'll do is use this built-in
122:10 - function to string to turn this into a
122:12 - string so that we're not going to run
122:14 - into any problems so there you go
122:16 - [Music]
122:20 - all right we're taking a look here at
122:22 - four expressions and so these allow you
122:24 - to iterate over a complex type and apply
122:26 - Transformations a four expression can
122:28 - accept as input list set Tuple map or an
122:31 - object I want to distinguish this
122:32 - between four each which is a resource
122:35 - meta argument which allows you to
122:36 - iterate over a a resource or a
122:40 - collection of resources that are similar
122:42 - but four expressions are for these
122:45 - primitive types or not these primitive
122:46 - types but these collection structural
122:48 - types that we talked about in types and
122:50 - values okay so here's an example of
122:53 - something we might want to do imagine we
122:54 - have a list of names and we want to
122:56 - iterate through our list and make them
122:58 - all uppercase so we could do that with
123:00 - this four so we have the four with the n
123:02 - and then we're providing the value of
123:04 - each item in our list it's easy to think
123:06 - of list or Tuple as an array so I'll
123:08 - just call it an array okay
123:10 - then you have a map and so this is where
123:13 - it has a key and value this is going to
123:14 - be for maps or objects and the idea is
123:17 - that we can then go apply
123:18 - Transformations and notice that we are
123:20 - returning only a single string so we're
123:22 - actually going to get back something
123:23 - like a tuple and so how does it decide
123:25 - whether it returns a um a array or
123:29 - something that looks like an object
123:30 - we'll explain that here in a moment the
123:32 - last one here is we have a list with an
123:34 - index so it's very similar to the first
123:35 - one but in this case we want to know the
123:38 - index here so imagine this says zero is
123:41 - Andrew one is Cindy two is Peter and it
123:46 - would come back as an array or list so
123:48 - let's talk about the return types the
123:49 - return types are defined by the um uh
123:52 - the braces or brackets that are around
123:55 - the actual expression so if you have
123:56 - square braces we're going to go back to
123:57 - Tuple so it's just think that array so
123:59 - for in this case where we had our list
124:02 - it was returning back a tuple okay
124:06 - if we have curly braces it's going to
124:07 - return an object so here we have a list
124:10 - so it's like an array that's coming in
124:12 - here and then we were specifying as the
124:14 - return uh this kind of object structure
124:16 - and so that's how we're going to get
124:18 - that so that's that there's one other
124:20 - thing we want to mention which has to do
124:22 - with
124:23 - um reducing or ordering so an if
124:25 - statement can be used to reduce the
124:27 - amount of elements returned so in this
124:30 - case what we're doing is we're using an
124:32 - if statement
124:33 - and so we're saying unless this is true
124:35 - so if this is true then return if it's
124:37 - not then return less of what is there so
124:41 - if there's any blank names that are in
124:43 - our list they just won't show up it'll
124:45 - just only show names that are actually
124:47 - there
124:48 - um then we have implicit element
124:49 - ordering so since terraform can convert
124:51 - an unordered type so map objects and
124:53 - sets to an order type list or tuples it
124:56 - will need to choose an implied ordering
124:58 - so for maps and objects they're stored
125:00 - by key A to Z set of strings stored by a
125:04 - strings A to Z everything else is going
125:06 - to be arbitrary ordering so there you go
125:08 - [Music]
125:12 - all right we're taking a look here at
125:14 - spy expressions and these provide a
125:15 - shorter expression for the four
125:17 - expression which we just looked at so
125:19 - what is the Splat operator a Splat
125:21 - operator is represented by an asterisk
125:22 - it originates from the Ruby language and
125:24 - Splats in terraform are used to roll up
125:27 - or soak up a bunch of iterations in a
125:29 - for expression so here is an example
125:32 - where it's for list sets or tuples so
125:34 - here we have a list and the idea is that
125:37 - we're iterating over this ID or in this
125:40 - game we're iterating over
125:42 - um its objects or sorry a array and then
125:46 - that array is containing a bunch of
125:48 - objects and so we're accessing the name
125:49 - within it and so instead of writing it
125:51 - like that we don't even have to use it
125:53 - for at all what we can do is put this
125:55 - asterisk here and this is going to
125:56 - equate to the same thing so here this is
125:58 - going to return all the IDS and in this
126:00 - case it's going to return a all the
126:02 - lists and allow us to access the
126:04 - interfaces along to the name okay
126:08 - so let's take a look at spy Expressions
126:10 - uh when we're applying them to lists so
126:13 - if the value is anything other than a
126:15 - null value then the Splat expression
126:16 - will transform it into a single element
126:18 - list if the value is null then the
126:20 - expression uh the then the Splat
126:22 - expression will return an empty Tuple
126:24 - and so this behavior is useful for
126:25 - modules that accept optional input
126:27 - variables whose default value is null to
126:30 - represent the absence of any value to
126:32 - adapt the variable value to work with
126:33 - other terraform language features that
126:35 - are designed to work with collections so
126:37 - I know that's a big mouthful it's just
126:39 - kind of like an edge case to these Spa
126:42 - Expressions this is not going to show up
126:43 - in the exam but I just wanted to show it
126:44 - to you in case you're interested here
126:46 - and just notice the spots being used
126:48 - over here okay
126:49 - foreign
126:53 - [Music]
126:54 - so we're taking a look here at Dynamic
126:56 - blocks and this allows you to
126:57 - dynamically construct repeatable nested
126:59 - blocks so I want to emphasize that this
127:00 - is a very powerful feature that can lead
127:03 - to abuse where your code becomes uh
127:05 - difficult to read but it's also very
127:07 - flexible it will absolutely show up in
127:08 - the exam so pay close attention on how
127:10 - this works so let's say you needed to
127:12 - create a bunch of Ingress rules for your
127:14 - ec2 security group and so this would
127:17 - lead to a lot of repeatable elements for
127:19 - rules within your resource and so what
127:22 - you can do with Dynamic blocks is you
127:24 - can Define objects locally so here I
127:26 - have my Ingress rules as an object so
127:28 - here's one and here is two and then
127:31 - using Dynamic block what I can do is use
127:34 - a 4-H to reference those Ingress rules
127:36 - and within this Dynamic Ingress block
127:39 - we'll have our content and this will
127:41 - specify the things that we're swapping
127:43 - out so the idea is that it will iterate
127:45 - over this and apply all those values
127:47 - there so it's something you can't do
127:49 - with a 4-H or account this is basically
127:51 - the the most advanced iteration but just
127:55 - understand if you remember this use case
127:56 - and it's very easy to understand or
127:58 - remember how to use it when you're doing
128:01 - an exam okay
128:02 - [Music]
128:05 - we're looking at version constraints so
128:08 - terraform utilizes semantic version for
128:10 - specifying terraform providers and
128:12 - module versions so semantic versioning
128:14 - is an open standard on how to define
128:16 - versioning for software management so
128:18 - you have your major minor and your patch
128:21 - and so here are examples or variants on
128:23 - this here so we have
128:25 - um you know where you see major minor
128:27 - then you can have this RC this rc1 or
128:30 - you could not have it or you can have
128:32 - beta and this can all be read about on
128:34 - the samver.org but just to quickly go
128:36 - through it
128:37 - major version is when you want to make
128:39 - incompatible API changes minor is when
128:42 - you add functionality that is backwards
128:44 - compatible in matter
128:46 - patch is when you make backwards
128:48 - compatible bug fixes there are
128:50 - additional labels for pre-release build
128:51 - metadata that are available as
128:53 - extensions so that's where we see those
128:56 - little additions there at the top a
128:59 - version straight is a string containing
129:01 - one or more conditions separated by
129:02 - commas so you have your equals or no
129:06 - operators or sorry your equals or no
129:09 - operators so match exact version of the
129:12 - number so it's either with the equals or
129:14 - not with the operator at all okay that's
129:17 - what I'm trying to write there excludes
129:18 - an exact number uh version so if we just
129:21 - said does not or will not be uh 1.0.0
129:26 - then you have a comparative ones so they
129:28 - have the version has to be greater or
129:30 - equal to 1.0.0
129:33 - um and then we have one with the tilde
129:35 - so allows only the rightmost version of
129:37 - the last number to increment so what
129:39 - this means is that the the last number
129:41 - here is only allowed to increment okay
129:45 - so let's talk about Progressive
129:46 - versioning because this kind of ties
129:47 - into semantic uh versioning but
129:50 - Progressive version is the practice of
129:51 - using the latest version to keep a
129:53 - proactive stance of security modernity
129:56 - and development agility and we like to
129:59 - describe this as practicing good hygiene
130:00 - when we're uh working with our code okay
130:03 - so by being up to date you're always
130:05 - pushing left on things that need to stay
130:08 - fixed or compatible you'll have to deal
130:11 - with smaller problems instead of dealing
130:12 - with a big problem later on run nightly
130:15 - builds is a good example where you might
130:17 - have golden images and the idea is to
130:19 - provide a warning signal just to kind of
130:21 - elaborate on that a nightly build is an
130:23 - automated workflow that occurs at night
130:25 - when developers are asleep so if the
130:27 - build breaks because A change is
130:29 - required for the code the developers
130:30 - will see this upon arrival in the
130:32 - morning and be able to budget
130:33 - accordingly so what I'm trying to get at
130:35 - is that when you are like
130:38 - putting in your providers especially if
130:40 - you copy from the terraform
130:42 - um
130:43 - the terraform website to get the
130:45 - providers and modules what they'll do is
130:47 - they'll actually have it set as the I'm
130:48 - just going to roll back here for a
130:49 - second but they'll actually have it set
130:51 - as the equals what I'm saying to you is
130:53 - you want to use something like a tilde
130:55 - or a greater than or equal sign so that
130:57 - you are staying Progressive okay so
131:00 - that's just one thing I want you to
131:01 - watch out for and we will talk about
131:02 - that when we go through the follow
131:04 - alongs okay
131:04 - [Music]
131:09 - hey it's Andrew Brown from exam Pro and
131:11 - we are moving on to our expression
131:12 - section starting with string templates
131:14 - let's learn all about that and we are
131:16 - going to have to CD into a new folder
131:18 - here
131:19 - so I have one called expressions and we
131:21 - will make ourselves a new file called
131:23 - main.tf we'll Define a local back end
131:28 - and I'm going to just Define a new
131:30 - variable
131:31 - I'm going to call this variable hello
131:34 - and I'm going to give it a type of
131:36 - string
131:39 - okay and that's all I'm going to do
131:41 - there and then what we're going to do is
131:42 - create ourselves a TF VAR file so we'll
131:45 - say
131:46 - terraform Dot tfvars and in there we'll
131:50 - just set hello
131:51 - to world
131:53 - and so what I want to do is enter
131:55 - terraform console
131:56 - okay this is going to allow us to just
131:58 - run arbitrary Expressions I want to show
131:59 - you how you quit it you just type exit
132:01 - and so we'll do is make a string so
132:03 - we'll just first do a Hello World
132:05 - I want to show you that you can put a uh
132:08 - a new line there and we'll get back a
132:10 - multi-line document this is a
132:12 - um this console doesn't allow for
132:13 - multiple lines so we can't write our own
132:15 - here doc but I can show you what it
132:16 - looks like
132:17 - and then we can interpolate a uh a
132:20 - variable there so we'll just say hello
132:23 - and notice we get hello world so that's
132:26 - how interpolation works it's not super
132:28 - complicated directives is a little bit
132:31 - different
132:32 - where we have string right so we can do
132:35 - instead this
132:37 - but the control word is a bit different
132:39 - because you're using the uh this um
132:43 - percentage sign the directives when
132:44 - you're doing something like an if else
132:46 - statement so what we could do
132:49 - is say something like
132:52 - um barsoon here
132:56 - okay
132:59 - and what I'm going to do is just exit
133:01 - out here clear because I don't know if
133:04 - it um it reloads the uh the variables
133:06 - there if you just change them on the Fly
133:08 - but what we'll do is we'll just say
133:10 - hello and we will write ourselves an if
133:14 - statement so we're going to say if VAR
133:16 - dot hello equals
133:21 - bar soon
133:23 - what it's going to do is then print out
133:26 - um
133:27 - it's going to instead print out Mars
133:30 - okay
133:33 - otherwise
133:36 - what we're going to get is
133:40 - um
133:41 - world okay
133:43 - you know what's really interesting is
133:45 - we're using the if and else
133:47 - here
133:49 - but I I could have swore that the only
133:51 - thing you had was ternary operators so
133:53 - like if you look at the conditional
133:55 - expressions
133:57 - notice here that it's doing this and
133:59 - it's not showing the documentation the
134:01 - FL so you know maybe maybe that's just
134:04 - for a one-liner and if else does exist
134:06 - for expressions and I might have missed
134:08 - that in the course but you cannot blame
134:10 - me if the documentation shows it like
134:12 - that okay
134:13 - so what I'm going to do here is just go
134:16 - ahead and hit enter
134:18 - and here we get hello Mars so that
134:20 - pretty much
134:21 - uh shows you how string interpolation
134:24 - works for both interpolation and
134:27 - directives we'll just type in exit and
134:29 - so that's all we want to do there okay
134:31 - [Music]
134:35 - all right so let's learn about four
134:37 - Expressions so four Expressions allow us
134:38 - to kind of iterate over something and do
134:40 - something fun with it and so what we're
134:43 - going to do is create ourselves some
134:46 - more complex types here so how about
134:49 - instead of like this was just hello a
134:50 - second ago but we'll change this over to
134:52 - Worlds and what I'm going to do is just
134:54 - list out a bunch of Worlds here from the
134:56 - uh the book uh John Carter books so we
134:59 - have bar soon we have
135:03 - jasum
135:05 - we have things like sesum
135:09 - okay and then we have whoops
135:13 - so assume and then we have something
135:16 - like cosume okay
135:18 - and so the idea here is now that we've
135:21 - defined that there we've got to go back
135:22 - to our main TF I'm just going to update
135:24 - this to the worlds this will just be a
135:28 - list
135:29 - all right and so what we'll do is make
135:32 - our way over to terraform cloud or sorry
135:34 - terraform console
135:35 - and we will try to do a four Loop here
135:38 - so I'm going to do Square braces four
135:41 - and we'll just say w in VAR dot worlds
135:46 - and then what we can do here is
135:50 - make a colon whoops
135:54 - okay and then type upper
135:57 - W and so that returns them all in
136:00 - uppercase there
136:02 - and if we were to use the Splat operator
136:04 - and technically this is something we
136:06 - want to move on to the next part
136:08 - but
136:09 - um yeah we'll leave it for the next
136:11 - video I'll just keep that separate so
136:12 - that is for just if we had a list
136:15 - imagine if we had this as the as an
136:18 - index here
136:23 - um or we'll say map
136:26 - because what we can do is actually map
136:27 - these two names
136:31 - so bring this down here
136:35 - and this would be Earth
136:38 - now you can use the colon or the equals
136:40 - it's just whatever you want to use here
136:42 - they're both supported actually this is
136:44 - an Earth this is Mars and then this one
136:46 - here is Earth
136:48 - and this one here would be
136:52 - Jupiter
136:54 - and then this one here would be Venus
136:59 - okay
137:01 - um and so I think we still need to
137:03 - Define it over here
137:05 - so I'm just going to say world's map
137:08 - and then what we can do here instead of
137:10 - having list we can say map
137:13 - and we'll try to iterate over this so
137:16 - it's going to be very similar except the
137:18 - difference is now we have a key and we
137:20 - have a value
137:23 - and so if we just want to return the
137:25 - names in capital we can just do K here
137:30 - oh that's the index uh what if we do
137:34 - oh you know why it's because
137:36 - um
137:36 - we have to do Worlds Map
137:39 - okay
137:40 - so reference to Undeclared variable map
137:43 - so we do have to exit and restart
137:50 - and oh sorry the input was complaining
137:52 - there so I'll just copy the one up here
137:54 - so I have to type it again
137:57 - nope it did not work as we thought okay
137:59 - so I do have to type it by hand
138:01 - kind of a pain but I guess that's just
138:03 - how it works so we'll say 4K V invar Dot
138:07 - worlds
138:08 - map
138:09 - and then we say upper
138:11 - B here
138:13 - okay or we could just say take the K
138:15 - here and get the other values now I
138:17 - didn't show you this a moment ago but if
138:19 - we do worlds here we can specify an
138:22 - index and an index would come first so
138:24 - it would be the value like the world the
138:27 - second and the index is first so notice
138:30 - that I is all a number the index of it
138:33 - and then the that is the value there
138:36 - um
138:37 - we could probably also return this as a
138:39 - map so notice that square braces are
138:41 - going to give you a list or and then
138:44 - curlers are going to give you map which
138:45 - kind of correspond to their actual data
138:47 - structure so if we wanted to turn this
138:49 - into the opposite here what we could do
138:52 - is just say uh we probably do string
138:54 - interpolation
138:56 - like this here and do I
138:58 - and then do equals or even maybe a colon
139:01 - here
139:02 - and then do the world like that
139:05 - and it didn't like the way I specified
139:06 - it so I'll try it like this instead
139:10 - extra characters after the line four
139:15 - so I don't see that wrong there just
139:19 - give me a moment I think um
139:23 - oh you know what it's we need to use in
139:25 - this case I think we have to do it this
139:27 - way
139:28 - okay so we use use the hash rocket so in
139:30 - that particular case you have to use the
139:32 - hash rocket that's what that symbol is
139:33 - called the equal zero
139:35 - um and so that's how we can get that
139:37 - value there so that pretty much outlines
139:40 - how to use
139:41 - um the for loops and next we're going to
139:43 - go probably look at the Splats okay so
139:46 - I'll see you back here in a moment I'm
139:48 - just going to exit this actually before
139:50 - we move on to Splats I just want to add
139:52 - one more thing to four Expressions which
139:53 - is filtering so we'll just go back here
139:56 - and get back into
139:58 - our terraform console here
140:01 - and what I'm going to do is just write
140:03 - another four
140:04 - and it probably would make sense to use
140:06 - the uh the the world's list we just did
140:09 - there so I'm going to do KV type in VAR
140:12 - world's map
140:14 - and so the idea here is that I only want
140:17 - the let's say we'll say the upper I only
140:21 - want the
140:22 - key value here but I would just say at
140:26 - the end here I can say if the V the
140:29 - value equals I can't remember what we
140:31 - set these as
140:33 - so this is key in value so if it is Mars
140:38 - I think it's double equals so if it is
140:40 - Mars
140:43 - then only return it that way or we could
140:45 - say the opposite say
140:47 - give me everything but Mars okay so I
140:50 - just wanted to show you you could use
140:51 - that if to do that filtering so I'm
140:53 - going to exit there and we'll move on to
140:55 - spots okay
140:56 - [Music]
141:00 - all right so we're moving on to Splats
141:02 - and what we'll have to do is create
141:04 - ourselves a new variable here I'm going
141:07 - to call this one world's
141:09 - Splat and this one is going to be a list
141:12 - and so if we go back up here to tfvars
141:15 - we'll make ourselves a new variable down
141:17 - here and we'll just call this one splat
141:19 - and it's going to be a list but it's
141:22 - going to contain inside of it a bunch of
141:24 - maps
141:25 - okay so we'll do pretty much this up
141:27 - here
141:30 - okay but what's going to happen here
141:32 - it's going to be slightly different
141:33 - where we are going to
141:36 - set what is the name
141:44 - so we'll just say like
141:46 - um
141:47 - Earth name
141:49 - that's actually Mars name so it's a Mars
141:51 - name here
141:53 - for all these
142:01 - and then over here these are going to be
142:07 - the Earth name
142:24 - so I think that is valid and what we're
142:27 - going to do here is just type in
142:29 - terraform console
142:31 - and if we wrote that correctly oh no we
142:33 - got an error so it says expected an
142:35 - equal sign to Mark the beginning of a
142:36 - new attribute value
142:39 - so I mean this should be okay
142:45 - uh oh you know what I think this Colon's
142:48 - just missing here
142:50 - put it up again
142:52 - there we go we're fine so if we just
142:54 - want to look at that variable I think we
142:55 - just type it in here and it might print
142:57 - it out if we're lucky
142:58 - yes so there it is
143:00 - um so what we're going to do here is use
143:04 - a Splat to get maybe the Mars name or
143:05 - something so if we used a for Loop what
143:07 - we'd have to probably write we could try
143:09 - this
143:10 - but we'd have to do four and then it
143:12 - would be for the actual map so say m for
143:16 - map in world's splat
143:19 - and then we would have to do m
143:23 - Dot Mars name
143:27 - and so a reference to the attribute
143:31 - by one axis treatment specifying the
143:33 - resource name
143:35 - so I mean that looks oh you know it's
143:37 - because we didn't write VAR okay
143:39 - I say we but it was really me so you
143:42 - know that's that but we could write this
143:43 - in a more concise way
143:49 - okay and so we use a splat
143:52 - Mars name
143:54 - okay so you know that's a lot more
143:56 - convenient if we're just trying to
143:58 - access variables like that
144:00 - um I think that if you're trying to do
144:01 - things like
144:04 - if you want to do upper here
144:07 - I think you still have to use A4
144:10 - expression
144:12 - okay I don't think you can do this we
144:14 - can try it but I really don't think that
144:16 - will work
144:24 - no and if we look at the documentation
144:26 - they don't show an example like that so
144:28 - you know it's not that bad but you can
144:31 - see that it's for a particular use case
144:32 - you can't use that for uh Maps or
144:35 - whatever the equivalent the other map is
144:37 - object but it's useful for this one
144:40 - particular use case okay
144:43 - [Music]
144:47 - hey it's Andrew Brown from exam Pro and
144:49 - we are on to the dynamic blocks follow
144:50 - along so this one should be uh pretty
144:52 - fun because it's uh quite a powerful
144:54 - feature so what I've done is I've
144:56 - created a new folder here called Dynamic
144:59 - blocks I'm going to make a new file here
145:00 - as always it's going to be main.tf and a
145:03 - really good example for this would
145:05 - probably be a database Security Group
145:07 - just because there's all those Ingress
145:08 - and out outgress or egress rules so what
145:13 - we're going to do is just Define our
145:14 - terraform settings block and I'm just
145:16 - going to pull up over here and make our
145:19 - way over to the registry for terraform
145:21 - and what we're going to do is go over to
145:23 - the AWS provider and go to the
145:26 - documentation and actually I first want
145:28 - to grab the provider itself because that
145:30 - is something very easy that we can do
145:32 - here we'll just move that on over so we
145:34 - can see what we're doing and paste that
145:37 - on in and we're going to have to Define
145:39 - our provider of course so we'll name
145:41 - that as AWS the profile is going to be
145:45 - defaults and our region will be us East
145:49 - one
145:50 - okay and so now what we need is to
145:53 - co-create ourselves a security group
145:56 - so we have of course done that
145:57 - previously here but
145:59 - let's pull up the uh documentation here
146:02 - I believe it was actually under VPC so
146:04 - let's just go down to VPC here and we
146:06 - will expand that and then underneath
146:08 - here there should be a AWS Security
146:10 - Group
146:11 - uh there it is and if we scroll on down
146:14 - there's the thing okay so what I'm going
146:17 - to do is copy uh this code here and go
146:20 - over and we'll just paste that on in and
146:23 - there is our security group so I
146:26 - remember that we had to have the
146:27 - description if you remember it
146:29 - complained about that
146:31 - so outgoing
146:34 - for everyone
146:36 - and we need to also have a few
146:39 - additional things
146:41 - we will just scroll on down here because
146:43 - it wanted the prefix list IDs
146:47 - okay
146:50 - remember we needed that I think there
146:53 - was like self false
146:56 - and there was like security groups
146:59 - I think it was actually AWS security
147:00 - groups in particular let's just double
147:02 - check to make sure that is the case
147:04 - it is called
147:08 - uh oh it's just security groups okay
147:15 - so
147:18 - we'll say self equals false
147:21 - we do not need cider block four here or
147:25 - six
147:27 - um we do not need this one here and it
147:30 - doesn't really matter what we set this
147:31 - to so it could be set to the main side
147:33 - or block that's totally fine but we are
147:35 - going to need to add a data source just
147:38 - like last time for the VPC
147:42 - so we'll say VPC we'll call that Main
147:44 - and I think it just needed the VPC ID it
147:47 - was as simple as that
147:50 - and so we will go over to AWS over to
147:54 - VPC
148:00 - and from there we are going to go to
148:04 - rvbcs and I will go grab that VPC ID
148:12 - Okay so we've grabbed our VPC ID and
148:15 - then we just need to name this as data
148:18 - and then we're going to name this as
148:19 - data we don't really care what the cider
148:21 - block is it's just again for
148:23 - um this demo purposes we don't need tags
148:26 - we'll take those out
148:27 - and
148:29 - um
148:30 - yeah everything else is fine okay so
148:33 - this now comes to the fact that we want
148:36 - to use Dynamic blocks before we do that
148:39 - let's just well I think I didn't leave
148:41 - the console there last but what we'll do
148:43 - here is
148:45 - just to our terraform inits
148:48 - and as that is pulling that stuff we're
148:51 - going to look up Dynamic blocks
148:55 - uh terraform
148:59 - so we'll go here and so Dynamic blocks
149:01 - is like way more powerful than um the
149:03 - four each where what we can do I'm just
149:06 - trying to
149:08 - find that example there but we have
149:11 - uh we have to set the dynamic part the
149:14 - 4-H you know what I'm pretty sure I have
149:15 - these in my slides so let's just use my
149:17 - slides as the reference here
149:22 - dynamic
149:23 - ah here it is okay so the idea is that
149:26 - we'll just set up a locals with all of
149:27 - our information here and then we will
149:29 - create this Dynamic block and then
149:30 - provide the content okay so I'm just
149:33 - going to move that off screen so I can
149:34 - see what I am doing here as we type it
149:36 - in and we'll see if we run into any
149:39 - problems
149:41 - um failed to query the available product
149:43 - for packages could not retrieve the list
149:44 - of the available versions for the
149:46 - provider uh not have a provider registry
149:49 - terraform name all models should specify
149:51 - the required providers so I'm not sure
149:54 - why it's complaining here but we'll
149:55 - scroll all the way to the top and the
149:57 - required providers is correctly set here
150:01 - so it shouldn't be a problem
150:06 - not sure what it doesn't like
150:12 - um so let's just type in terraform
150:13 - providers here
150:18 - the VPC
150:20 - um is VPC a module
150:22 - you know what it's probably because I
150:24 - didn't do AWS VPC that's probably my
150:26 - problem here
150:28 - terraforming net
150:30 - and as that's thinking there we'll just
150:32 - pull this on down and we'll start to
150:34 - make our locals block okay so we can go
150:37 - here make some locals and we'll do our
150:40 - Ingress
150:42 - and we'll just
150:45 - go like that
150:47 - and the idea is we can say Port whoops
150:50 - we can set the port like that 443
150:53 - we have to always have a description so
150:56 - we'll just set that as well so port
150:59 - 443 we can set
151:03 - as much as we want here so I'll just go
151:05 - ahead enter
151:08 - okay
151:10 - and
151:13 - I think that looks right yeah so we have
151:18 - one Ingress here and then we'll just
151:19 - copy this and make a comma
151:25 - vs code is not really formatting the way
151:27 - I wanted to and so we'll do port 80.
151:31 - and then down below we will need to
151:32 - specify
151:35 - hour
151:38 - um
151:39 - for each okay so that's going to be
151:42 - within our Dynamic block so what we're
151:43 - going to do is tab in here I'm going to
151:45 - say dynamic
151:48 - and we'll type it Ingress because that's
151:51 - a match for what we're doing
151:55 - um and then from there we can do our
151:57 - four each equals local Ingress
152:01 - and then we need to specify our content
152:03 - I don't really understand why it's
152:06 - called content and things like that but
152:07 - I just know that that's what we have to
152:08 - do and it's not really that big of a
152:10 - deal so
152:13 - we'll go here and paste that in we can
152:15 - take out our Ingress block there we know
152:18 - we're going to need self these all here
152:20 - but what's going to change
152:22 - are these ports so
152:25 - we will go here it will say Ingress
152:28 - Value Port and this will also be Ingress
152:31 - Value Port
152:32 - and then this will be Ingress value
152:35 - description
152:37 - if we really wanted to we could also set
152:39 - the protocol
152:42 - protocol Pro
152:45 - Tove call
152:47 - and this could be then TCP
152:57 - and so we would just say Ingress value
152:59 - protocol
153:05 - so it just saves us from repeating these
153:07 - over and over again if they're all the
153:08 - same
153:09 - there's a lot you can do with Dynamic
153:11 - blocks but honestly you shouldn't do
153:13 - anything
153:14 - too crazy
153:16 - we'll do our terraform plan and see if
153:17 - this works whoops
153:23 - bring that up there
153:26 - um an argument VPC ID as not expected
153:28 - here okay so
153:30 - that was me just guessing from memory
153:32 - and I guess I guessed wrong
153:35 - uh so what we'll do
153:38 - is we'll just look that up
153:42 - AWS VPC data source terraform
153:50 - oh it's just ID okay
153:54 - so what we'll do is just set ID here
153:58 - and then we'll just hit plan again
154:01 - and that should resolve our issue there
154:05 - uh inappropriate value for a tribute
154:08 - egress security groups is required okay
154:11 - that's fine
154:17 - well this one says doesn't say uh Syria
154:21 - groups
154:22 - and this one doesn't say Security Group
154:24 - so that's probably our problem here so
154:25 - we'll just hit terraform plan again
154:32 - and here it says this VPC ID does not
154:36 - exist probably what happened is they
154:37 - might be in the wrong region
154:39 - it's very common problem
154:41 - on AWS just because of the way their UI
154:43 - works
154:45 - if I can get this window over here and
154:48 - so this is because we're in USC's we're
154:50 - supposed to be in U.S east one here
155:00 - and I'm going to go up
155:02 - to here
155:04 - we'll save that
155:06 - let me hit terraform plan
155:17 - and we could probably like use the
155:19 - filter and also just say choose the
155:21 - default but it's just so easy to put
155:22 - that in like that so
155:26 - doesn't seem like we have any problems
155:27 - here so let's go ahead and execute let's
155:29 - just double check to make sure these
155:30 - values are correct
155:32 - so for the Ingress
155:36 - um Port 443 Port 443 it's probably just
155:38 - because I didn't update the description
155:41 - probably because of a copy paste job yep
155:44 - okay and let's just make sure this works
155:46 - so we'll say terraform apply Auto
155:48 - approve
156:01 - and we'll give it a moment
156:04 - and it's already created so it's that
156:06 - fast we can go here and take a look at
156:08 - it if we like
156:09 - it's not that big of a deal
156:13 - um so we should see it in here I just
156:16 - have so many
156:18 - uh junk security groups here this is a
156:20 - bit hard to find
156:21 - oh allow TLS is what we called it so
156:24 - here it is
156:25 - go to our inbound rules
156:28 - 80443 and that's pretty much it so
156:32 - terraform apply
156:35 - destroy Auto approve
156:39 - okay
156:46 - there we go
156:48 - [Music]
156:53 - all right so I want to talk about
156:54 - versioning very quickly here and so I
156:56 - have a new folder called versions I'm
156:58 - going to just make a new file called
156:59 - main.tf and we're going to create a
157:02 - terraform block but what we're also
157:04 - going to do is set required
157:07 - uh providers or sorry required uh we're
157:10 - not providers required version and so
157:13 - what this is going to do is say
157:14 - explicitly what version of terraform we
157:16 - want to use and I'm sending it this as
157:18 - 1.0.0 and I'm using this tilde Arrow if
157:21 - you're wondering you know what is the
157:23 - logic behind all those things I think
157:24 - it's all explained in the semantic or
157:26 - semver.org so if you want to learn more
157:28 - I strongly recommend you read through
157:30 - this to understand all the stuff inside
157:32 - and out highly applicable across the
157:34 - devosphere not just to terraform
157:37 - um but you know if we go over to
157:38 - terraform GitHub repository and we drop
157:41 - down the branches and go to tags here we
157:43 - can see all the versioning we are using
157:45 - version 1.0.0 and it all goes up to
157:49 - 1.1.0 Alpha which is not out yet and if
157:52 - you wanted to really know what's going
157:53 - on here you go to releases and you can
157:55 - read what they have done so here 1.0.7
157:58 - remove check for computer attribute
158:00 - prevent object types with optional
158:02 - attributes for ETC empty containers so
158:05 - when you're looking at the patch the
158:07 - patch which is the third number the the
158:09 - rightmost number that's going to keep
158:11 - you up to date in terms of security for
158:13 - the the major minor version that you
158:16 - have for the 1.0 and you absolutely
158:18 - always want to be using the latest and
158:19 - so that's what this tilde does it says
158:21 - take the far Road uh the the farthest
158:25 - number to the right and make sure that
158:26 - it's the latest version that has been
158:28 - published
158:29 - um and you know this comes back to my
158:31 - Progressive versioning slide which is if
158:33 - you want to have really good hygiene in
158:35 - terms of your devops we should be doing
158:37 - is at least setting the tilde for sure
158:39 - like this the tilde Arrow or I would
158:42 - even go as far as saying equals arrow
158:44 - and if you're really concerned about
158:47 - um you know not using the next major
158:48 - version you could say you will less than
158:50 - you know like less than
158:54 - um less than you know one point
158:57 - 2.0 even if it's not out that's a good
159:00 - indicator to say okay well I don't want
159:01 - to go too far ahead of time but if you
159:03 - want to have Progressive versioning you
159:05 - should really be setting it like this
159:06 - okay
159:07 - and this is going to be applicable for
159:10 - your image providers anything else so
159:12 - you know if we go over to
159:16 - if we go over to the registry
159:20 - and we choose
159:23 - whoops
159:25 - AWS and we drop this down here we have
159:28 - that required version as well so as you
159:30 - copy it in you're going to notice that
159:31 - it's actually hard coded but I would
159:33 - strongly recommend again
159:35 - if we go here
159:38 - and take this and at least at least do
159:41 - this
159:42 - and if you're really really being clever
159:45 - you could do that okay and these are
159:48 - also all in GitHub repositories as
159:50 - that's how everything works so you can
159:51 - go here and click and you can go over to
159:55 - the tags and see the versioning and you
159:57 - can go over to the releases and it's the
160:00 - same thing you can read about all the
160:01 - things that have changed okay and that's
160:04 - something that you should uh you know
160:05 - consider doing all right so that's all
160:08 - there really is to this I might want to
160:09 - show you one more thing and this one is
160:11 - with terraform Cloud so I'm going to go
160:12 - to terraform IO and we're going to open
160:15 - up our terraform cloud and I'm going to
160:17 - sign in I probably haven't signed in a
160:18 - while so probably ask oh nope no
160:19 - username password that's great what we
160:21 - can do is in a workspace we go to
160:22 - settings
160:23 - and is it Version Control no it is
160:26 - general and under here we can actually
160:29 - set the terraform version so if you
160:31 - happen to be working with a particular
160:32 - version you can go and say okay only use
160:35 - this version for terraform cloud and
160:38 - that will
160:39 - um that will not upgrade it'll just keep
160:41 - you there if you need for legacy reasons
160:43 - but again you know what you really
160:44 - should be doing is using that
160:47 - Progressive versioning doing nightly
160:49 - builds and discovering overnight that
160:51 - things are breaking so you can go fix
160:54 - those in the morning okay and that's it
160:57 - [Music]
161:01 - hey this is Andrew Brown from exam Pro
161:03 - and we are taking a look at terraform
161:05 - state so what is State well it's a
161:07 - particular condition of cloud resources
161:09 - at a specific time so give an example
161:12 - imagine we expect to have a virtual
161:14 - machine running Centos on AWS with a
161:16 - compute type of T2 micro that would be
161:19 - the state that we are expecting okay so
161:21 - how does terraform preserve State well
161:23 - when you provision infrastructure via
161:25 - terraform it will create a state file
161:27 - named terraform TF State it's very
161:30 - important to remember that name because
161:31 - it literally is an exam question the
161:33 - exact naming of that okay this state
161:35 - file is a Json data structure with a
161:37 - one-to-one mapping from resource
161:39 - instances to resource or to remote
161:41 - objects and if you're wondering what is
161:43 - a remote object versus a resource
161:46 - instance I cannot tell you I would
161:48 - imagine one is the representation of
161:50 - things that are deployed in the cloud
161:52 - and the other one are objects or or
161:55 - things represented in the state file but
161:57 - they don't clarify it so I just have to
161:58 - take a guess so this is kind of what the
162:00 - Json structure looks like like you can
162:02 - see you see resources this is describing
162:04 - like a type of instance and stuff like
162:06 - that there's not really any case for you
162:09 - to ever go through the terraform State
162:10 - file and look at it but we might take a
162:13 - peek just so that we get familiar as to
162:15 - what it is doing
162:16 - so just to kind of give it a diagram to
162:18 - help you visualize this imagine you have
162:20 - your configuration file so you have your
162:22 - main TF maybe a variables TF a TF bars
162:25 - to load in your variables and then you
162:27 - run a terraform apply command what it's
162:30 - doing is using the terraform API and
162:32 - it's going to create what we'll say
162:33 - these we'll call these remote objects
162:35 - but maybe these are resource instances
162:38 - um but it will go ahead and create those
162:40 - things and then those will get
162:41 - represented within a state file so the
162:44 - idea is that whatever is in the cloud is
162:47 - going to match what's in that file okay
162:50 - now there is a CLI commands for
162:53 - terraform State and it's good just to
162:55 - quickly go through them so we have
162:56 - terraform State list this will list
162:58 - resources in the state terraform State
163:00 - move this will move an item in the state
163:02 - terraform State pull pull current remote
163:04 - State and outputs to St out terraform
163:06 - State push so update remote States from
163:09 - a local state terraform State replace
163:11 - provider so replace a provider in the
163:13 - state terraform State removed so remove
163:15 - instances from the state terraform State
163:18 - shows so show a resource in the state
163:20 - some of these are a little bit
163:22 - interesting so we'll definitely look in
163:24 - Greater detail to move and some of these
163:26 - people just explore through our follow
163:28 - alongs okay
163:30 - foreign
163:33 - [Music]
163:35 - special attention to terraform State
163:37 - move because it's definitely on the exam
163:39 - uh and it is a little bit interesting to
163:42 - what it can do so terraform State moves
163:44 - allow you to rename existing resources
163:46 - move a resource into a module move a
163:49 - module into a module so if you were just
163:51 - to rename a resource or move it to
163:52 - another module and run terraform apply
163:54 - terraform will destroy and create that
163:56 - resource but State move allows you to
163:58 - just change the reference so you can
164:00 - avoid a create and Destroy action so an
164:02 - example for renaming a resource we would
164:04 - have terraform State move and then we
164:06 - would have the we would identify the old
164:08 - one so here we have packet device dot
164:11 - worker and we are renaming it to helper
164:14 - so it's we that's just how we're doing
164:16 - it okay if we wanted to move a resource
164:19 - into a module what we do is say
164:21 - something like packet device dot worker
164:24 - and then do
164:27 - module.worker.packetdevice.worker okay
164:28 - so the idea here is that we're moving it
164:30 - into this module here
164:33 - uh and I think we could probably even
164:35 - rename it at the same time but uh we're
164:37 - not doing that okay so move module into
164:39 - a module so here we have module app and
164:42 - then we're moving it into the parent one
164:44 - so we go module.parent module.app okay
164:47 - so what's important to remember for the
164:49 - exam is that terraform State move is
164:51 - when you want to rename existing
164:53 - resources they're not going to get into
164:54 - these more complicated use cases but
164:57 - that's how you rename a a resource okay
164:59 - [Music]
165:03 - okay let's talk about how we back up our
165:06 - state file so all terraform state
165:07 - subcommands that modify state will write
165:10 - a backup file so read-only commands will
165:12 - not modify it so imagine listen show
165:14 - will not cause a backup file to be
165:16 - created terraform will take the current
165:18 - state and store it in a file called
165:22 - terraform.tsstate.backup so this is what
165:24 - it would look like backups cannot be
165:26 - disabled this is by Design to enforce
165:28 - best practices for Recovery to get rid
165:30 - of the backup file you would need to
165:31 - manually delete the files so there you
165:34 - go
165:34 - [Music]
165:38 - foreign
165:42 - from exam Pro and we are taking a look
165:44 - at terraforming knit so it initializes
165:46 - your terraform project by downloading
165:48 - plug-in dependencies so providers and
165:50 - modules creating a DOT terraform
165:52 - directory so that's a hidden directory
165:54 - and creating a dependency lock file to
165:56 - enforce the expected versions for
165:57 - plugins in terraform itself so on the
165:59 - right hand side here we can see we have
166:01 - that hidden directory but also notice
166:03 - here that we have a DOT terraform
166:05 - lock.hcl that is our dependency lock
166:07 - file and so our dependencies are all
166:10 - going to end up within this sewers as
166:13 - providers that's the provider version
166:14 - there okay so terraform in it is
166:16 - generally the First Command you will run
166:18 - for a new terraform project if you
166:20 - modify or change dependencies run
166:22 - terraform in it again to have it apply
166:24 - the changes you need to know that for
166:26 - the exam because they will absolutely
166:27 - ask you that the First Command here is
166:29 - and these are ones with flags so you can
166:32 - just do terraform in it but we have some
166:33 - extra options so terraforming it hyphen
166:35 - upgrade upgrade all plugins to the
166:37 - latest version that complies with the
166:39 - configuration version constraint
166:40 - terraforma knit hyphen get plugins and I
166:44 - think it's supposed to be equals false
166:45 - there but skip plugin installation
166:47 - terraform init plug-in hyphen dir equals
166:51 - pass so Force plugin installation to
166:53 - read plugins from only target directory
166:55 - and then we have terraform init hyphen
166:57 - lock file so you can change the lock
166:58 - file mode it actually doesn't say what
167:00 - the modes are so I don't even know what
167:02 - you'd do in that case and I could not
167:04 - find any examples but it is an option I
167:07 - just want to make it very clear that
167:09 - there is a dependency lock file but
167:11 - there's also a state lock file and the
167:13 - way you know that they're different is
167:14 - that one has Dot Lock in it and the
167:16 - other one has dot TF State this one up
167:18 - here is for dependencies this one of
167:20 - course is for State a terraform and it
167:22 - does not create a state lock file that
167:23 - is going to happen when you do a
167:24 - terraform apply okay
167:27 - [Music]
167:31 - let's take a look at terraform get so
167:33 - terraform get command is used to
167:34 - download and update modules in the root
167:36 - module so when you're a developer you
167:38 - own terraform modules and you may need
167:40 - to frequently pull updated modules but
167:42 - you do not want to initialize your state
167:44 - or pull new provider binaries and so the
167:47 - idea here is terraform get is a
167:48 - lightweight way it's because it's only
167:51 - updating the modules it's not pulling
167:53 - providers in most cases you want to use
167:55 - terraform init with the exception of
167:56 - local module development this will not
167:59 - show up on the exam but I saw terraform
168:01 - getting I was just so confused about it
168:02 - so I just wanted to make sure I included
168:04 - it here okay
168:05 - [Music]
168:09 - okay so we're going to be looking at
168:10 - three CLI commands that are used to
168:12 - improve debugging configuration scripts
168:14 - the first is going to be terraform
168:15 - format this rewrites terraform
168:17 - configuration files to a standard format
168:19 - and style terraform validate this
168:21 - validates the syntax and arguments of
168:22 - terraform configuration files in a
168:24 - directory and then you have terraform
168:26 - console an interactive shell for
168:27 - evaluating terraform expressions and so
168:29 - let's go jump into these three okay
168:30 - [Music]
168:34 - all right let's take a look at terraform
168:36 - format so this command applies a subset
168:39 - of terraform language style conventions
168:41 - along with other minor adjustments for
168:43 - readability so terraform format will be
168:46 - by default look in the current directory
168:48 - and apply formatting to all your dot TF
168:51 - files so let's look at some examples of
168:53 - what it would format so the first is
168:54 - adjusting spacing two spaces indent so
168:57 - here we have something and it's over
168:58 - indented and so by running terraform
169:01 - format it fixes the indentation we can
169:04 - also get syntax errors so notice here
169:06 - that we have a problem and so what it's
169:09 - saying is is that this bracket okay
169:13 - is supposed to be up here okay but it's
169:16 - all it's down here uh and the last one
169:18 - here is we can do terraform format
169:20 - hyphen hyphen diff that's going to show
169:22 - what it would change okay so there you
169:24 - go
169:25 - [Music]
169:29 - let's take a look at terraform validate
169:31 - so this runs checks that verify whether
169:33 - configuration is syntactically valid and
169:36 - internally consistent regardless of the
169:38 - provided variables in existing state
169:40 - validate is useful for General
169:42 - verification of reusable modules
169:44 - including correctness of attribute names
169:45 - and value types so here's an example
169:48 - where I just had some code and there was
169:50 - a problem it's just saying you're
169:51 - missing your argument because for an AWS
169:53 - instance you always have to specify an
169:55 - instance type so when you run terraform
169:57 - plan or terraform ply validate will
169:59 - automatically be performed one thing I
170:01 - need to mention about terraform validate
170:03 - is that it does not go to external
170:06 - resources to check things are valid so
170:08 - if you have a a value and it's expecting
170:12 - a string that's all it's going to check
170:14 - for it's not going to check that the
170:15 - string is actually a proper uh like type
170:18 - of size so if it's supposed to be like a
170:20 - t2.micro and you write you know
170:22 - gobblegoop in there it's not going to
170:24 - know that that's not a valid type so but
170:27 - we do cover that in the follow along so
170:29 - I think we have like some practice exam
170:31 - questions that cover that use case okay
170:32 - [Music]
170:36 - we're taking a look here at terraform
170:38 - console and this is an interactive shell
170:40 - where you can evaluate expressions so
170:42 - the idea is you type in terraform
170:43 - console and what I can do is I can you
170:46 - know use like built-in functions and
170:49 - expressions so there I'm using Min and
170:51 - I've actually entered it in incorrectly
170:53 - so there it's throwing an error and here
170:55 - I'm using the correct way of using it so
170:57 - I get the output so this is a great way
170:59 - just to kind of test very simple things
171:01 - you can't do things like Define
171:02 - variables or or resources or Define
171:05 - providers but you if you need to figure
171:08 - out how the Expressions work before you
171:09 - apply them in your code this is a great
171:11 - place to do that okay
171:12 - [Music]
171:17 - all right let's talk about terraform
171:18 - plans so this command creates an
171:21 - execution plan also known as a terraform
171:23 - plan and it consists of reading the
171:26 - current state of an already existing
171:28 - remote object to make sure that the
171:30 - terraform state is up to date comparing
171:32 - the current configuration to the prior
171:34 - State and noting any differences
171:36 - proposing a set of change actions that
171:39 - should if applied make the remote
171:41 - objects match the configuration and so
171:43 - this is an example of one that's
171:45 - generated you're going to see it uh
171:47 - throughout this course multiple times so
171:49 - it's not going to be unique that's why I
171:50 - don't have to make that too big for you
171:52 - there terraform plan does not carry out
171:55 - the proposed changes that's going to be
171:57 - the responsibility of terraform apply
171:59 - and a terraform plan file if you happen
172:01 - to generate one out is a binary file so
172:03 - if you open it up it's just machine code
172:05 - you cannot make sense of it okay so when
172:08 - you run terraform apply you have
172:10 - speculative plans and save plans and so
172:13 - speculative plan plans is what's going
172:14 - to happen when you run terraform apply
172:16 - so the tear so terraform will output the
172:19 - description of the effect of the plan
172:21 - but without any intent to actually apply
172:24 - it when you have a save plan you're
172:26 - going to have this hyphen out flag to
172:29 - save it and you can name that file
172:30 - whatever you like and it will generate
172:33 - out that save plan file and again that's
172:34 - a binary file so you're not going to be
172:36 - able to see what it does and what you
172:37 - can do is then pass it along to
172:39 - terraform apply so you do terraform
172:41 - apply whatever the file name is and when
172:44 - you are using terraform apply what you
172:46 - have to understand is that it will not
172:48 - allow it will not ask to manually
172:51 - approve it as you normally would it
172:53 - would just be Auto approved so that's
172:56 - one thing you have to watch out when
172:57 - using those safe plans but you know I
172:59 - just wanted to make it concretely
173:00 - understood that terraform plan can
173:02 - generate at a file uh and it's not
173:04 - actually the one that's doing the apply
173:06 - okay I don't have it written in here but
173:09 - when you do terraform apply it also is
173:11 - running terraform validate as well okay
173:16 - thank you
173:19 - [Music]
173:20 - let's talk about terraform apply here so
173:22 - terraform apply command executes the
173:24 - actions proposed in an execution plan
173:27 - and it has two modes the automatic plan
173:29 - mode and the saved plan mode so for
173:32 - automatic plan mode that's just when you
173:33 - run terraform apply what it's going to
173:35 - do is execute the plan validate and then
173:38 - the apply uh you can or you have to
173:41 - manually approve the plan by writing yes
173:44 - but if you want to skip that process you
173:47 - can use the hyphen Auto approve flag to
173:50 - automatically approve the plan
173:52 - we just saw save plan mode like how it
173:54 - worked in the previous slide but let's
173:56 - cover it again so when you provide a
173:58 - file name to terraform to the save plan
173:59 - file it's going to be terraform apply
174:01 - file
174:02 - and it's going to perform exactly the
174:04 - steps specified by that plan file it
174:07 - does not prompt for approval so if you
174:08 - want to inspect a plan file before
174:10 - applying it you can use terraform show
174:13 - okay
174:14 - [Music]
174:22 - all right let's talk about managing
174:24 - resource drift so drift or configuration
174:26 - or infrastructure drift is when you're
174:28 - expected uh resources are in different
174:30 - state than your expected State and the
174:33 - way we can resolve drift are in three
174:34 - different ways in terraform we can
174:36 - replace resources so when a resource has
174:38 - become damaged or degraded that cannot
174:40 - be detected by terraform we can use the
174:43 - hyphen replace flag we can import
174:45 - resources so when an approved manual
174:47 - edition of a resource needs to be added
174:50 - to our state file so we use the import
174:52 - command and refresh state so when an
174:54 - approved manual configuration of a
174:56 - resource has been changed or removed
174:58 - we're going to use the refresh only flag
175:00 - to reflect the changes in our state file
175:02 - it's very important to know these three
175:04 - different ways they will all show up an
175:05 - exam and in practice you're going to
175:07 - need to know them okay
175:08 - foreign
175:12 - let's first here take a look at
175:14 - replacing resources so we can use the
175:16 - terraform tank command it is used to
175:18 - Mark a resource for replacement the next
175:19 - time you run apply and why would you
175:22 - want to Mark a resource for replacement
175:23 - well the idea is that um you know and
175:26 - here's the command here but a cloud
175:27 - resource becomes damaged or degraded and
175:29 - you just want to return the expected
175:31 - resource to a healthy state so that's
175:32 - the idea behind it and the unfortunate
175:34 - thing is that terraform taint was
175:36 - deprecated in version
175:38 - 0.152 however there is a better way of
175:41 - doing it now and so it is recommended to
175:43 - use the hyphen replace flag and
175:45 - providing it a resource address when
175:48 - you're doing a terraform apply so it's
175:50 - basically the exact same thing the
175:51 - reason why they made this change was so
175:54 - that
175:54 - um you actually have an opportunity to
175:56 - confirm your change beforehand because
175:58 - terraform tank would just run and this
176:00 - one down below will actually prompt you
176:02 - to say are you sure you want to do this
176:04 - okay but it's not complicated you just
176:06 - do a hyphen replace and then you use the
176:08 - resource address of the thing that you
176:10 - want to
176:11 - use that for and this can be used for
176:13 - both plan and apply the replace flag
176:16 - appears to only work for a single
176:18 - resource so you can't use multiple
176:19 - resources it's just one at a time and
176:21 - that's something that you should
176:22 - remember okay
176:23 - [Music]
176:27 - so we just saw a resource address and
176:30 - resource addressing is very important to
176:32 - know for the upcoming commands let's
176:34 - just give it a bit more attention here
176:35 - so resource address is a string that
176:37 - identifies zero or more resource
176:38 - instances in your configuration an
176:40 - address is composed of two parts so the
176:42 - module path and the resource path and
176:45 - just expand out that module path it
176:46 - would be module.module name module index
176:48 - and then on the resource spec this is
176:51 - resource type.resource name and then if
176:53 - there's multiple instances you give it
176:54 - an index so module path addresses a
176:57 - module within a tree of modules a
176:59 - resource spec address is a specific
177:01 - resource instance in the selected module
177:03 - so a module is the namespace of the
177:05 - module module name is user defined name
177:08 - of the module module index when the
177:11 - multiple so when there's multiple
177:14 - specifying index on the other side
177:16 - that's your resource type your resource
177:17 - name an instance ID most of the times
177:20 - you're going to be just working with
177:21 - resources but once you start getting to
177:24 - modules it becomes pretty simple it's
177:26 - always going to be module period because
177:30 - that's just I think that's the name of
177:32 - the name value so it's always going to
177:34 - be module Dot and then the module name
177:35 - but here we have a very simple example
177:37 - just for resource type so here if we had
177:40 - a resource called Abus instance and it
177:42 - was web and there was four of them and
177:44 - we wanted to select the third one we do
177:46 - AWS instance dot web Square braces three
177:49 - and that would get us the third virtual
177:50 - machine so there you go
177:52 - foreign
177:55 - [Music]
177:57 - terraform import and this is a command
177:59 - that is used to import existing
178:01 - resources into terraform so this is how
178:03 - you define it so you'd say what resource
178:06 - you want and you can just leave it blank
178:08 - so do you define a placeholder for your
178:09 - imported resource and configuration file
178:11 - and you can leave the body blank and
178:13 - fill it in after importing but it will
178:15 - not be autofilled so you do have to
178:17 - specify all the values okay so the idea
178:20 - here is you're going to do terraform
178:22 - import AWS instance dot example and then
178:24 - the name of the ID so that Maps over to
178:26 - the resource address and the ID okay the
178:29 - command can only import one resource at
178:31 - a time this sounds very similar to that
178:33 - other command we saw for replace not all
178:36 - resources are importable you need to
178:37 - check the bottom of the resource
178:38 - documentation for support okay
178:40 - [Music]
178:44 - okay so we're going to look at
178:45 - refreshing and so we're going to break
178:47 - this between the old command refresh and
178:49 - the new command refresh only across two
178:51 - slides so terraform refresh command
178:53 - reads the current settings from all
178:55 - managed remote objects and updates the
178:56 - terraform state to match so here we have
178:59 - the terraform refresh and I just want to
179:00 - point out that the terraform refresh is
179:04 - basically the Alias for terraform apply
179:05 - hyphen refresh only hyphen Auto auto
179:08 - approved so you technically have this
179:10 - functionality in the latest version it's
179:12 - just that you can't use the old Alias
179:14 - terraform refresh terraform refresh will
179:17 - not modify your real remote objects but
179:19 - will modify the terraform state so
179:22 - terraform refresh has been deprecated
179:23 - and the refresh only uh and with the
179:25 - refresh only flag like it's been
179:27 - replaced with it because it's not safe
179:29 - since it did not give you the
179:30 - opportunity to review proposed changes
179:32 - before updating the state file so that's
179:33 - why the reason they got rid of it let's
179:35 - take a look here at the refresh only
179:37 - mode so hyphen refresh only flag for
179:40 - terraform planner apply allows you to
179:42 - refresh and update your state file
179:43 - without making changes to your remote
179:45 - infrastructure just to really make this
179:48 - clear I want to give you a scenario and
179:51 - I want you to pay close attention here
179:52 - to understand the difference because
179:54 - this is so important on the exam and
179:55 - also extremely useful for your
179:57 - day-to-day operations so here's a
179:59 - scenario imagine you create a terraform
180:02 - script that deploys a virtual machine to
180:04 - AWS you ask an engineer to terminate the
180:07 - server and instead of updating the
180:09 - terraform script they mistakenly
180:10 - terminate the server via the AWS console
180:12 - because they don't know any better so
180:14 - what happens if you were to run a
180:16 - terraform apply versus with a refresh
180:19 - only flag so that's what we'll do with
180:21 - and without the flag so without the flag
180:23 - first terraform will notice that the VM
180:25 - is missing terraform will propose to
180:27 - create a new VM so the state file is
180:30 - going to be what's considered as correct
180:33 - and the changes and so changes to the
180:35 - infrastructure will be made to match the
180:37 - state file okay if we use terraform
180:40 - apply hyphen refresh only terraform will
180:42 - notice that the vmu provision is missing
180:45 - but with the refresh only flag it's
180:48 - going to know that the that the VM is
180:51 - missing it's an intentional okay so I
180:53 - have a couple spelling mistakes there
180:55 - but the idea is that it knows that the
180:57 - VM is supposed to not be there so
180:59 - terraform will propose to delete the VM
181:01 - from the state file so just the Json
181:03 - code from the state file so the state
181:05 - file is considered wrong and changes to
181:07 - the state file will be made to match the
181:09 - infrastructure so hopefully that makes
181:10 - it clear okay
181:12 - [Music]
181:15 - foreign
181:19 - [Music]
181:24 - how we would actually go about
181:26 - troubleshooting terraform so there are
181:28 - four types of Errors you can encounter
181:30 - with terraform uh the first is language
181:32 - error so terraform encounters a syntax
181:35 - error in your configuration for the
181:37 - terraform or HCL language you have state
181:39 - error so your resources States has
181:42 - changed from the expected state in your
181:44 - configuration file core errors so a bug
181:47 - that has occurred with the chord Library
181:49 - provider errors so the provider's API
181:51 - has changed or does not work as expected
181:54 - due to emerging edge cases and when we
181:56 - talk about what's easy for us to solve
181:58 - and what's hard well the first two are
182:00 - very easy and the other two are harder
182:02 - to solve so for language errors we can
182:04 - use format validate or version to
182:08 - resolve our language errors version
182:10 - would just be say hey what version are
182:12 - we using maybe we need to update it
182:14 - right validate with detect if
182:15 - something's wrong with
182:16 - um the uh the the syntax and format
182:19 - would fix formatting syntax but you know
182:22 - that probably wouldn't fix that much
182:23 - there for State errors the idea here is
182:26 - we might want to use refresh apply
182:29 - replace everything that we saw in the
182:31 - drift section for core errors we might
182:34 - want to go check out the log so TF
182:36 - underscore log is basically just the way
182:39 - of saying like hey these are where the
182:40 - log files are or is logs turned on we
182:42 - have a whole slide on that but really
182:45 - like all you're going to do is use the
182:47 - logs to find information and then report
182:49 - a GitHub issue since all terraform is on
182:53 - GitHub you just go there and then
182:55 - somebody would try to resolve it and the
182:58 - same thing with providers providers are
183:00 - all hosted on GitHub and so you would
183:02 - just use TF logs to try to find some
183:04 - information there but we'll take a look
183:06 - a greater look at TF log and how to you
183:10 - know get that information for the harder
183:12 - to solve cases okay
183:13 - [Music]
183:17 - okay so let's talk about how we would go
183:19 - about debugging terraform via the log
183:21 - file so terraform has detailed logs
183:23 - which can be enabled by setting the TF
183:25 - underscore log followed by the type
183:28 - environment you want to run so the
183:30 - variables that we have or the
183:33 - environments we can specify is Trace
183:35 - debug info warn error or Json Json will
183:39 - output logs at the trace level or higher
183:42 - and use parsable Json encoding as the
183:44 - formatting okay so logging can be
183:47 - enabled separately so you can do this
183:49 - via TF log core or you can get it at the
183:54 - TF log provider so if you just want core
183:56 - stuff or if you just want provider stuff
183:57 - you just set those environment variables
184:00 - and as we saw in the previous thing that
184:02 - there you know there was core errors and
184:04 - provider variables so that could be a
184:05 - good way to do that and so TF uh TF core
184:10 - TF log core and TF log provider take the
184:12 - same environment variables we see on the
184:14 - right hand side there Trace debug info
184:16 - Etc okay if you want to choose where you
184:19 - want to log things you just can set the
184:21 - TF log path I don't think I actually say
184:23 - where the default path is I think it's
184:25 - actually in the the project directory
184:27 - but if you want to override that you can
184:28 - I imagine it either takes an absolute
184:31 - path or a relative path and here's an
184:33 - example of a terraform log so this is
184:36 - for everything and so there you can see
184:39 - information I'm going to get my pen tool
184:41 - out here for a moment but you can see we
184:43 - have information about the provider this
184:45 - is using
184:46 - um there then there's some back-end
184:48 - local stuff so you know there's some
184:50 - information you're not expected to
184:52 - understand this information generally
184:54 - but you could go bring it to the
184:56 - provider but you could probably solve
184:57 - something you know if you were to read
184:59 - the core code or the provider is okay
185:02 - [Music]
185:06 - okay so we looked at TF log which is the
185:09 - terraform log but there's also a crash
185:11 - log and so if terraform ever crashes and
185:13 - basically this means it goes into panic
185:15 - because it uses the go runtime it saves
185:17 - a log file with the debug logs from the
185:19 - session as well as the Panic message and
185:21 - back Trace to the crash.log and so I
185:24 - imagine this is golang information so I
185:28 - don't use golang that often but you can
185:30 - see we have dot gopanic.go so I think
185:33 - that there's not much you can do with it
185:35 - so this is where you would just create a
185:37 - GitHub issue and pass it along to the
185:39 - terraform team because they're going to
185:40 - be able to make sense of it okay
185:42 - [Music]
185:46 - foreign
185:49 - [Music]
185:54 - so we're on to our module section uh so
185:57 - let's first talk about how we would go
185:58 - find a module I know we already saw this
186:00 - earlier when we were looking at the
186:01 - terraform registry but let's just cover
186:02 - it again and talk about some of the uh
186:05 - uh details of search okay so terraform
186:09 - modules can be publicly found in the
186:11 - terraform registry and so on the left
186:13 - hand side when you're under the modules
186:15 - within terraform registry you can filter
186:17 - your providers okay but another thing
186:20 - you can do is you can type in Search
186:23 - terms and you can do partial Search
186:24 - terms like Azure compute but what I
186:27 - really want you to know is that only
186:28 - verified modules will be displayed in
186:31 - Search terms and so I assume that means
186:33 - verified and also official ones and the
186:36 - reason I'm giving this extra emphasis is
186:38 - because it was an exam question so I
186:40 - just want you to know that only verified
186:42 - and official ones are going to show up
186:45 - when you search okay
186:48 - foreign
186:50 - let's talk about using modules and
186:52 - there's our public modules and private
186:55 - modules so public modules are going to
186:57 - be on the terraform registry and private
186:58 - modules are going to be in terraform
187:00 - cloud or I suppose terraform Enterprise
187:02 - so terraform registry is integrated
187:04 - directly into terraform so it makes it
187:06 - really easy to start using them so all
187:09 - you're going to do is use the module
187:11 - block so I'm just going to highlight
187:13 - that there then we have the name of our
187:15 - module we're providing the source of our
187:18 - module and then there's the version of
187:19 - our module terraform init command will
187:22 - download and cache any module referenced
187:24 - by a configuration now looking at
187:27 - private modules it looks very similar
187:30 - um it's just that the name is different
187:31 - so we're specifying the host name in
187:34 - front here and a namespace as well so to
187:37 - configure private module axis you need
187:39 - to authenticate against terraform Cloud
187:41 - via terraform login so that's something
187:44 - there we definitely cover that a lot in
187:47 - the Brax exam so just in case you know
187:50 - you know all the education is there
187:51 - alternate alternatively you can create a
187:54 - user API token and manually configure
187:56 - credentials into CLI to configure the
187:58 - file so there you go
188:00 - foreign
188:04 - let's talk about how we would go about
188:05 - publishing modules and this in
188:07 - particular is for the terraform registry
188:09 - so these are public modules so if we
188:12 - want to publish modules it supports
188:14 - versioning automatically generating
188:15 - documentation allowing uh users to
188:18 - browse the version histories showing
188:21 - examples and read Maze and all of these
188:24 - modules are actually going to be hosted
188:25 - on GitHub so the idea is you're going to
188:28 - put your module there first and once a
188:31 - module is registered to push updates you
188:33 - simply push new versions to properly
188:35 - form get tags you have to name the your
188:39 - your modules in a very particular way on
188:42 - GitHub so the thing is it has to start
188:44 - with terraform hyphen then the provider
188:46 - so AWS and then the name so hyphen VPC
188:49 - and the way you publish it on terraform
188:52 - registry is you have to connect and
188:54 - publish via your GitHub account so you
188:57 - just hit sign in with GitHub and it's
188:59 - just going to give you a drop down and
189:00 - you're just going to choose the repo and
189:02 - that's as simple as it is okay
189:04 - foreign
189:08 - all right let's talk about verified
189:09 - modules so these are reviewed by
189:11 - hashicorp and actively maintained by
189:13 - official contributors to stay up to date
189:15 - and compatible with both terraform and
189:17 - their respective providers so here's an
189:19 - example of a module from our friend
189:20 - Anton down below and as you can see it
189:23 - has a little badge that's how you know
189:24 - that it's verified so verified modules
189:27 - are expected to be actively maintained
189:28 - by hashicorp Partners verified badges
189:31 - aren't an indication of the flexibility
189:34 - or feature support but just to kind of
189:37 - go through some things here very simple
189:39 - modules can be verified just because
189:41 - they're great examples of modules
189:43 - unverified modules could be extremely
189:45 - high quality and actively maintained
189:47 - unverified modules shouldn't be assumed
189:49 - to be poor quality unverified means it
189:51 - hasn't been created by a hashicorp
189:54 - partner so you know that again it's not
189:56 - indicative of quality but it just means
189:59 - that it's gone through a bit of vetting
190:00 - okay
190:01 - [Music]
190:05 - all right let's take a look here at the
190:07 - standard module structure and this is a
190:08 - file and directory recommended for
190:10 - module development and this is the idea
190:12 - if you were to go and publish your own
190:14 - module this is what people would expect
190:15 - to see so if you had root modules that's
190:17 - what it'd be and you have nested module
190:19 - I want to point out that when you are
190:21 - running terraform you technically are
190:22 - creating modules even if you aren't
190:25 - intending them to publish them into the
190:26 - terraform registry but you know when you
190:29 - make a main.tf you've basically made
190:31 - your own root module okay so the primary
190:33 - entry point is the root module and these
190:36 - are required files in the root directory
190:37 - so your main.tf is the entry point file
190:40 - for your module variables TF is the
190:42 - variables that can be passed in
190:44 - outputs.tf are outputted values readme
190:47 - describes how the modules work license
190:49 - the license under which the module is
190:51 - available for NASA modules which are
190:53 - optional but must be contained in the
190:55 - modules directory a sub module that
190:58 - contains a readme is considered usable
190:59 - by external users a sub module that does
191:02 - not contain a readme is considered inter
191:04 - for only internal use and the idea is to
191:07 - avoid using relative paths when sourcing
191:09 - module blocks so hopefully that gives
191:11 - you an idea okay
191:12 - [Music]
191:20 - foreign
191:23 - [Music]
191:24 - let's talk about core terraform
191:26 - workflows and these have three steps
191:28 - write plan and apply so write plan and
191:30 - apply we saw this kind of in the
191:33 - terraform life cycle and the idea here
191:37 - is that you know it's just to try to
191:40 - describe what it's going to be for your
191:42 - team and requirements as you grow and
191:44 - you're utilizing this workflow so if
191:46 - you're talking about individual
191:47 - practitioners so a single person a team
191:50 - using OSS so they're not using they're
191:53 - using open source software using
191:54 - terraform but they're not using the
191:56 - terraform Cloud platform and then what
191:57 - it would be like if they're using the
191:59 - terraform Cloud platform in terms of
192:01 - this right plan apply you're going to
192:03 - see these examples don't perfectly fit
192:05 - here I am just presenting a summarized
192:08 - versions of the documentation and the
192:11 - reason why is because on the exam this
192:14 - is one of the sub domains that you need
192:17 - to know so I'm not saying that I think
192:20 - these are perfectly presented but I
192:22 - think that I have to cover them because
192:24 - they are in the exam and I you do learn
192:26 - something here so we will go through
192:28 - them okay
192:29 - [Music]
192:33 - so let's take a look at a terraform or
192:36 - team workflow for a single person an
192:38 - individual practitioner looking at the
192:40 - right step first so you're going to be
192:43 - writing your terraform configuration in
192:44 - your editor of choice on your computer
192:47 - um but the thing is you'll be storing
192:49 - your terraform code in something like
192:51 - GitHub even if you are an individual
192:53 - user you're going to be putting in git
192:54 - or GitHub or some kind of Version
192:55 - Control System you're going to be
192:57 - repeatedly running terraform plan or
192:59 - even possibly terraform validate to find
193:02 - syntax errors and the great thing about
193:04 - this is that you get this tight feedback
193:06 - loop between editing the code and
193:07 - running your test commands because it's
193:09 - all on your local machine we're not
193:10 - sending things off to build servers or
193:13 - other services so it's very fast and
193:16 - easy talking about the plan stage so
193:18 - when the developer is confident with
193:20 - their workflow in the right step that
193:22 - commits their code to their local
193:24 - repository this is the stage where it's
193:27 - a local limit it's not a remote commit
193:28 - they may be only using a single Branch
193:31 - so just probably working in Maine or if
193:33 - you're still using the old syntax Master
193:35 - Branch once their commit is written
193:38 - they'll proceed to apply that'll bring
193:40 - us to the apply stage so they will run
193:42 - terraform apply this is on your local
193:44 - machine it's not part of any other
193:46 - process you're just running terraform
193:47 - apply and it'll be prompted to review
193:49 - their plan after the review the final
193:52 - review they will approve the changes and
193:54 - await provisioning after a successful
193:56 - provision they will push their local
193:58 - commits to their remote repository so
194:01 - this is where you will then finally
194:02 - commit your code so there you go
194:05 - [Music]
194:10 - so we looked at what it would be like if
194:12 - we had a single person working with
194:13 - terraform let's talk about if it's a
194:15 - team and they're not using terraform
194:16 - Cloud they're just doing it uh the
194:18 - old-fashioned way okay so each team
194:20 - member writes code locally on their
194:22 - machine in their editor of choice as per
194:24 - usual a team member will store their
194:26 - code in a branch in their code
194:28 - repository whether it's a uh per feature
194:31 - per user per whatever is up to you
194:34 - branches help avoid conflicts while a
194:37 - member is working on their code but
194:39 - branches will allow an opportunity to
194:41 - resolve conflicts during a merge into
194:43 - main it's no different than working with
194:45 - you know code because that's what it is
194:47 - terraform plan can be used as a quick
194:50 - feedback loop for small teams so we
194:52 - still have that option but as your team
194:54 - grows larger a concerned over sensitive
194:56 - credentials becomes a concern and so
194:58 - this is where you may need to introduce
195:00 - a CI CD process so that it's it's going
195:04 - to be in control of the credential so
195:06 - the idea is that you don't run plan you
195:08 - just push to your branch and it can run
195:10 - it or it only happens on pull requests
195:12 - that's up to you know your team and how
195:14 - they decide to set it up when a branch
195:16 - is ready to be incorporated on pull
195:18 - requests an execution plan can be
195:20 - generated I guess when we say execution
195:22 - plan this could be a speculative plan
195:24 - okay so it's not something we're going
195:26 - to run it's just something we're going
195:27 - to review and displayed within the pull
195:29 - requests for review to apply the changes
195:31 - the merges need to be approved and
195:33 - merged which will kick off a code build
195:35 - server that will run terraform apply
195:37 - that's the apply stage there so this is
195:40 - all good but what we need to kind of
195:42 - highlight is all the work and labor that
195:44 - goes into setting up your own team if
195:46 - you're going to do it all from scratch
195:48 - without terraform Cloud so the devops
195:50 - team has to set up and maintain their
195:51 - own CI CD pipeline they have to figure
195:53 - out how to store the state files whether
195:55 - they're going to be in a standard back
195:58 - in a remote state or they're going to
196:00 - encrypt it and put them into the code
196:02 - repository which is not recommended they
196:05 - are limited in their access controls so
196:07 - they can't do granular actions to say
196:08 - okay I only want to allow this person to
196:11 - destroy and this person to apply it's
196:13 - not like that with get repos they have
196:16 - to figure out a way to safely store and
196:18 - inject secrets into their build server's
196:20 - runtime and that's not argue argue it's
196:23 - not very hard depending on the solution
196:24 - that you choose but it is a thing that
196:26 - they have to figure out they might need
196:28 - to manage multiple environments and this
196:30 - can create additional overhead because
196:32 - for each environment you'll have to
196:34 - create another ciccd pipeline okay so
196:37 - hopefully that gives you the idea of the
196:39 - effort here and this is going to set us
196:41 - up to say what terraform cloud is going
196:43 - to solve okay
196:44 - [Music]
196:49 - let's take a look at what our team
196:50 - workflow or our terraform workflow will
196:52 - be if we were using terraform clouds so
196:55 - 18 we'll use terraform Cloud as a remote
196:57 - back-end of course they were using uh
196:59 - their favorite editor as per usual
197:01 - working on their local machines to write
197:03 - that code the input variables will be
197:05 - stored on terraform Cloud instead of
197:07 - their local machine terraform cloud
197:08 - integrates with your version control
197:10 - system such as git to quickly set up a
197:12 - cicd pipeline a team member writes code
197:15 - to a branch it commits per usual so that
197:17 - doesn't change a pull request is created
197:20 - by a team member in terraform Cloud will
197:22 - generate the speculative or execution
197:24 - plan however you want to call it for
197:25 - review in your version control system
197:27 - the member can also review and comment
197:30 - on the plan in terraform Cloud after the
197:32 - pull request is merged terraform cloud
197:34 - in the terraform Cloud runtime sorry the
197:37 - terraform Cloud runtime will perform a
197:39 - terraform apply and a team member can
197:41 - confirm and apply the changes within the
197:43 - terraform Cloud UI okay so terraform
197:46 - Cloud streamlines a lot of the CI CD
197:48 - efforts storing it storing and securing
197:50 - sensitive credentials and makes it
197:52 - easier to go back and audit the history
197:54 - of multiple runs so in terms of the exam
197:57 - if and I didn't see any questions on
198:00 - this but I know they exist they're just
198:02 - going to be asking you
198:04 - you know which like they might describe
198:06 - something and say which kind of workflow
198:07 - does this fit and so if you generally
198:09 - know the difference between terraform
198:11 - Cloud working with the team open source
198:13 - software without terraform cloud and
198:15 - individual workflow it's not too hard
198:16 - you'll be okay all right
198:18 - [Music]
198:22 - foreign
198:25 - [Music]
198:26 - we're taking a look here at back ends
198:29 - and each terraform configuration can
198:30 - specify a back end which defines where
198:33 - and how operations are performed and
198:35 - where State snapshots are stored so
198:38 - terraform divides their backends into
198:39 - two types we have standard and enhanced
198:42 - first looking at standard this is where
198:44 - you can only store the state and it does
198:47 - not perform terraform operations such as
198:49 - terraform apply so to perform operations
198:52 - you have to use a CLI on your local
198:54 - machine and the reason why is that
198:57 - standard back ends are basically
198:58 - third-party backends so a standard back
199:00 - end could be AWS S3 and so you know this
199:04 - is a storage service it doesn't have the
199:06 - capabilities of pragmatically triggering
199:08 - things okay
199:09 - uh when we have when we're talking about
199:11 - enhanced back ends we can store both the
199:14 - state and perform terraform operations
199:17 - so enhanced backends are subdivided
199:20 - further so we have local so files and
199:22 - data are stored in a local machine
199:24 - executing terraform commands and remote
199:26 - so files and data are stored in the
199:28 - cloud so terraform Cloud the reason why
199:31 - they can perform terraform operations
199:32 - and when you look at local and remote
199:34 - local is your machine so of course it
199:37 - can execute terraform and then remote is
199:39 - terraform Cloud which has its own
199:41 - runtime environment it's basically a
199:43 - build server so it of course can do both
199:46 - those operations and that's how you're
199:48 - going to remember the difference between
199:49 - those two okay
199:50 - [Music]
199:55 - all right so we were just talking about
199:57 - standard and enhanced back ends and I
199:59 - was saying that standard back ends are
200:01 - basically third-party providers that is
200:03 - something other than terraform Cloud so
200:05 - let's take a look at what options we
200:07 - have available to us starting with the
200:09 - major cloud service providers so AWS has
200:12 - simple storage S3 Azure has block
200:16 - storage account notice it says Azure RM
200:18 - because that's just the name of what
200:20 - they call it I don't know what the RM
200:21 - stands for resource manager I imagine
200:23 - Google Cloud Storage is an option then
200:26 - we have Alibaba we have openstack we
200:30 - have 10 cent and then we have Manta
200:33 - which is part of joynet's cloud storage
200:35 - so I don't think a lot of people are
200:37 - going to remember joinet joynet was very
200:39 - popular provider like post or pre-2010
200:43 - so I remember them 10 cent is a Asia
200:47 - provider I think they were a texting
200:49 - service they're very popular but they're
200:51 - not the largest provider over in Asia
200:52 - Alibaba is and of course we have the the
200:55 - three major ones here and then openstack
200:58 - is for uh private Cloud okay then on the
201:01 - other side of it when we're looking at
201:02 - more exotic or things that aren't Cloud
201:05 - server providers we have
201:06 - um artifactory we have hashicorp console
201:10 - etcd postgres database kubernetes
201:13 - secrets and you can also use the ACP
201:15 - protocol
201:16 - now notice I have these little locks
201:18 - here that's indicating which have state
201:21 - locking which do not if you don't know
201:22 - what state locking is don't worry we'll
201:23 - talk about it here in a moment
201:26 - um would there be a question on the exam
201:27 - saying oh which service you know doesn't
201:30 - have state locking and the answer is no
201:32 - they would never ask that it's too
201:34 - minute but just notice that the only
201:37 - thing that doesn't have state locking is
201:38 - uh artifactory which I'm kind of
201:40 - surprised because it's a universal
201:42 - repository manager and there's the one
201:44 - case like with HP protocol where it's
201:46 - optional so it's not that you can't have
201:48 - it it's just that it's not it doesn't
201:50 - necessarily have to be there and in
201:52 - particular some the the state is or the
201:55 - Locking State locking is
201:57 - buy another service so for AWS it's
201:59 - dynamodb that is doing the state locking
202:01 - and then with Alibaba uh alibaba's cloud
202:04 - storage it's table store okay so uh you
202:07 - know there's not much to know here but
202:09 - uh you know it's just kind of
202:10 - interesting if you want to have a
202:12 - different kind of backend maybe you want
202:13 - to use postgres because you're really
202:14 - familiar with it you can actually store
202:15 - it there okay so let's take a look at
202:17 - what it would look like if we were to
202:18 - use a standard back end so here's an
202:20 - example for AWS since I think S3 is very
202:23 - popular so if you were to set up your
202:26 - back end so here I have a bucket here
202:29 - and I've have to name the state file so
202:32 - I call it State file and then I give it
202:33 - the region and there it is so the backup
202:36 - of a state file will reside on your
202:38 - local machine so the backup's not going
202:39 - to be an S3 configuring a standard back
202:42 - end does not require terraform cloud
202:43 - account or workspace because
202:47 - you know it's it's totally separate from
202:49 - it so that's something I wasn't sure
202:50 - when I was first using it was okay can I
202:52 - use a standard back end but I still have
202:53 - to have a terraform account or workspace
202:54 - and the answer is no all right
202:56 - [Music]
203:01 - all right so we're taking a look at
203:02 - enhanced back end so we're going to
203:03 - start with local and then move on to
203:05 - remote so for the local back end we
203:07 - store the state on the local file system
203:09 - and it locks the state using the systems
203:11 - API it also performs operations locally
203:14 - and when we say local we just mean a
203:16 - local machine we don't necessarily mean
203:17 - it has to be our workstation a code
203:19 - build server could also be considered a
203:22 - local machine okay it just means
203:24 - anything but terraform Cloud that is
203:25 - running the terraform code so by default
203:28 - you are using the backend State when you
203:30 - have not specified any kind of back end
203:33 - so normally you'd see a background
203:34 - defined in here we don't so it's going
203:37 - to just default to the local you can
203:39 - specify the back end with an argument
203:41 - local most people don't you just leave
203:42 - it blank and you can change the path to
203:45 - the local file
203:46 - a working directory so I think that if
203:48 - you were to specify you'd want to put
203:50 - the path
203:51 - in but generally again we keep that
203:53 - blank you can set a back end to
203:56 - reference another state files so you can
203:58 - read it outputted values this is a way
204:00 - of cross-referencing stacks so just
204:02 - notice that we have this thing that says
204:04 - terraform remote State we're going to
204:05 - repeat this later on in the course
204:07 - because this is a very important concept
204:10 - and I feel that it gets overlooked in
204:11 - the documentation but it has to do with
204:13 - local backends so the idea is that you
204:16 - could say hey I have this other file
204:18 - that has a back end and I'm just going
204:20 - to use data sources specify its backend
204:23 - and then point to its actual terraform
204:25 - State file okay
204:27 - foreign
204:30 - [Music]
204:31 - we're taking a look here at remote back
204:33 - ends for the enhanced back-end type and
204:35 - a remote back end uses the terraform
204:37 - platform which is either terraform cloud
204:39 - or terraform Enterprise
204:40 - by default I usually just say terraform
204:43 - Cloud when I'm referring to the
204:44 - terraform platform but just to
204:46 - understand there is a distinction
204:47 - between terraform cloud and terraform
204:48 - enterprise Enterprise being the
204:50 - on-premise
204:51 - offering okay so with a remote back end
204:54 - when terraform apply is performed via
204:56 - the CLI the terraform Cloud run
204:57 - environment is responsible for executing
204:59 - the operation so that's what you get
205:01 - when you get terraform cloud is you get
205:03 - this run environment so it's basically
205:04 - just a built-in code build server to run
205:08 - terraform commands for you one thing I
205:10 - really want you to know about remote
205:12 - back-ends because this really tripped me
205:13 - up uh when I was actually trying to make
205:16 - the follow along which is the fact that
205:18 - because the terraform Cloud run
205:20 - environment is the one exiting the
205:22 - command your provider credentials need
205:24 - to be configured in the environment
205:25 - variables in terraform Cloud so you know
205:28 - if you had a project and you configured
205:30 - it with um TF bars locally and then you
205:34 - were to swap out your remote backend
205:36 - it's not going to work the way you
205:38 - expect it to because
205:40 - um again the terraform Cloud run
205:41 - environment is not going to take your
205:43 - credentials and then move them to the
205:45 - cloud okay you have to do that yourself
205:47 - when using a remote backing you need to
205:49 - set a terraform Cloud workspace
205:53 - so you would go ahead and go to
205:56 - terraform cloud and just go create one
205:57 - you create one or multiple ones for a
205:59 - single project if you use a single
206:01 - workspace for a project you're just
206:03 - going to use the workspaces uh name and
206:06 - if you set multiple workspaces via
206:08 - prefet you can use a prefix okay and the
206:10 - way this prefix works is that you're
206:12 - going to say like my app or something
206:13 - and when you go to run terraform apply
206:16 - what it's going to do is prompt you to
206:18 - say which environment do you want to use
206:20 - so and this is what you've created in
206:22 - your terraform Cloud workspace you've
206:24 - created one called Dev you've created
206:25 - one called Product saying which
206:27 - workspace do you want to deploy to I
206:30 - want to know that you can only set
206:32 - either name or prefix you can't set both
206:34 - okay so just understand that
206:37 - [Music]
206:41 - all right so we're taking a look at the
206:43 - cloud backend
206:45 - um uh code block here and so this is
206:48 - very similar to terraform backend remote
206:51 - if we're specifying terraform as our
206:55 - back end but now instead of having to do
206:57 - backend remote we can just give it a
206:59 - cloud block and the reason for this is
207:03 - well I don't know you can still
207:11 - foreign
207:57 - all right let's take a look at the cloud
207:59 - backend block so when using terraform
208:01 - Cloud as a remote back-end State you
208:04 - should instead use the cloud block to
208:06 - configure its usage so uh previously in
208:09 - previous uh terraform versions it would
208:11 - look like this so you'd have terraform
208:13 - back and remote and the way you know
208:15 - it'd be using terraform cloud is that
208:16 - the hostname would be set as app.t
208:18 - terraform.io and so this has been
208:20 - changed so now that all you have to do
208:22 - is use this Cloud block and so you just
208:25 - don't specify that hostname and for the
208:27 - most part
208:28 - um uh you know the configurations
208:30 - between them are very similar so the
208:33 - only thing that we're seeing different
208:33 - is this prefix maybe that prefix is
208:35 - still there we'd have to double check
208:37 - the documentation on that but what's
208:38 - important to understand is that there's
208:40 - this Cloud block and it is the record
208:42 - amended way to do it now I do want to
208:44 - point out that I tested both and the
208:46 - remote the remote version still works so
208:48 - you can still do it this way if you're
208:50 - doing it the old school way and this is
208:52 - just an alternate way uh would they ever
208:55 - make it so you could not use the remote
208:56 - state in the future for uh terraform
208:58 - Cloud you have to use the block I don't
209:00 - know but I can tell you right now that
209:02 - they do have that cloud block
209:04 - so both are valid options and the latter
209:07 - of course being the recommended uh use
209:09 - one so yeah there you go
209:13 - thank you
209:16 - [Music]
209:17 - so since we're talking about back ends
209:19 - let's talk about back-end initialization
209:20 - in particular the back end hyphen config
209:23 - flag this is more of an exotic option
209:25 - but I figured we should go over it
209:27 - because it could appear on your exam so
209:29 - the flag for the back end config flag
209:32 - for terraform init can be used for
209:33 - partial back-end configuration so in
209:36 - situations where the back-end settings
209:37 - are dynamic or sensitive so they cannot
209:41 - be statically specified in your
209:43 - configuration file this is what you
209:44 - would do
209:46 - so here would be your main.tf and notice
209:49 - it says back in remote
209:51 - and it has no details in it
209:53 - so then what you do is you create a
209:55 - separate file called backend.hcl and now
209:57 - you're specifying the workspace the host
210:00 - name the organization and then uh with
210:03 - terraform and net you're going to then
210:04 - say Okay use this file as the backend
210:08 - information that we're going to inject
210:09 - into our backend remote so there you go
210:12 - [Music]
210:17 - okay we're taking a look here at
210:18 - terraform remote State and I give this a
210:20 - lot more attention in the course because
210:21 - I feel that it gets overlooked within
210:24 - the terraform documentation it's such a
210:26 - powerful feature and something that I'm
210:27 - used to having in cloudformation which
210:29 - is cross-referencing Stacks so I want to
210:30 - make sure that you know it too so
210:32 - terraform remote State data source
210:34 - retrieves the root module output values
210:36 - from another terraform configuration
210:38 - file using the latest State Snapshot
210:41 - from the remote back end so the idea is
210:43 - that you can reference a state file from
210:45 - somewhere else you can do it uh via a
210:48 - remote backend and a local backend so
210:50 - just take a look here we see data and
210:53 - the data sources terraform remote State
210:55 - and we're setting the back end as a
210:57 - remote on the right hand side here it is
210:59 - local and if it's a local back end we
211:01 - give the path to the TF State file if
211:04 - it's remote that means it's another
211:05 - workspace and terraform Cloud so we set
211:07 - the workspace that we want to access and
211:10 - then when we want to access those
211:12 - resources we're using data sources so we
211:14 - do data Dot and it's terraform remote
211:16 - State and then we specify it knows that
211:18 - it's no difference whether it's remote
211:20 - or local but you're going to be getting
211:21 - datas from outputs okay so only the root
211:25 - level output values from the remote
211:26 - State snapshots are exposed resource
211:29 - data and output values from nested
211:31 - modules are not accessible to make
211:33 - module outputs values accessible as a
211:37 - root module output values you must
211:39 - explicitly configure a pass-through in
211:41 - the root module so here's an example of
211:44 - us doing a pass-through so we have a
211:47 - module called app and it has a source
211:49 - and then we're just setting an output
211:51 - notice that we are just grabbing the
211:52 - value and passing it along
211:54 - I want to tell you about the alternative
211:55 - to terraform remote State because if you
211:58 - can you should use these as opposed to
212:00 - using terraform Road States so terraform
212:02 - remote state only exposes output values
212:04 - its users must have access to the entire
212:07 - State snapshot which often includes some
212:09 - sensitive information it's recommended
212:11 - explicitly uh it it's recommended to
212:14 - explicitly publishing data for external
212:16 - consumption to a separate location
212:18 - instead of accessing it via a remote
212:20 - state so what would be Alternatives well
212:23 - you've seen this because when we looked
212:25 - at data sources we were technically
212:26 - we're using Alternatives but the idea is
212:28 - that you are going to say AWS S3 bucket
212:31 - AWS rep 53 zones and these are kind of
212:34 - already set up to work with AWS or
212:37 - whichever provider okay so that's that
212:41 - there
212:42 - but uh yeah hopefully that's pretty
212:44 - clear so the idea is that when you can
212:46 - use these data sources because you know
212:49 - they're actually working off of live
212:51 - data right like it's hitting a resource
212:53 - it's not just looking at a state file
212:54 - that contains data okay
212:56 - [Music]
213:01 - so we had mentioned State locking just
213:03 - briefly when we were looking at standard
213:05 - back ends but let's go take a look in
213:07 - detail what these are because they're
213:08 - very important for your workflows so
213:10 - terraform will lock your state for all
213:12 - operations that could write State this
213:15 - prevents others from acquiring the lock
213:16 - and potentially corrupting your state so
213:19 - State locking happens automatically on
213:21 - all operations that could write State
213:22 - you won't see any message that it's
213:25 - happening if the state locking fails all
213:28 - right so terraform does not output when
213:30 - a lock is complete however if acquiring
213:33 - the lock is taking longer than expected
213:35 - terraform will output a status message
213:37 - so neither on failure and neither when
213:40 - it is complete just if it takes too long
213:42 - so there's a transient issue something
213:44 - with like a networking issue you can
213:46 - disable lock so what you do is use the
213:49 - hyphen lock flag but it's generally not
213:52 - recommended you can force and unlock
213:54 - there's cases where uh you know just
213:56 - does not unlock or add so what you'll
213:59 - have to do is use the force unlock
214:00 - camera and if you unlock the state when
214:03 - someone else is holding the lock it
214:05 - could cause multiple writers Force
214:07 - unlock should only be used to unlock
214:09 - your own lock in the situation where
214:12 - automatic unlocked failed to protect you
214:14 - the force unlock command requires a
214:16 - unique lock ID so terraform will output
214:19 - this lock ID if unlocking fails so this
214:22 - is what it would look like so we have
214:23 - terraform Force unlock and then whatever
214:25 - the ID is hyphen Force so yeah there's a
214:29 - lot going on here but yeah that's what
214:31 - it is
214:31 - [Music]
214:36 - all right so let's talk about protecting
214:38 - sensitive data so terraform State file
214:40 - can contain sensitive data so long-lived
214:42 - database credentials and is possible
214:44 - attack Vector for malicious actors and
214:47 - so when you're dealing with the local
214:48 - state when you're using local backend
214:51 - the state is stored in plain text Json
214:53 - files you need to be careful you do not
214:55 - share the state file with anyone you
214:57 - need to be careful you do not commit
214:58 - this file to your git repository when
215:00 - you're using a remote state with
215:01 - terraform Cloud the idea here is the
215:04 - save file is held in memory and is not
215:06 - persisted to disk the state file is
215:07 - encrypted at rest the state file is
215:10 - encrypted in transit with terraform
215:11 - Enterprise you have detailed audit
215:13 - logging for tampering evidence to take
215:14 - it one step further so you can just see
215:17 - that there's a lot of work that has to
215:18 - be done when you are using it locally
215:21 - but with terraform Cloud this is kind of
215:23 - the cell for terraform cloud is that
215:25 - it's just going to do everything
215:26 - possible to make that secure would it be
215:28 - secure to use a remote say with a
215:30 - third-party storage let's talk about
215:31 - that so you can store state with a
215:33 - various third-party back-ends but you
215:35 - need to be careful to review your
215:36 - backend's capabilities determine if you
215:38 - meet your security and compliance
215:40 - requirements some back-ends are not by
215:43 - default as secure as they could be so
215:44 - for example AWS S3 you could have you
215:47 - have to ensure encryption and versioning
215:49 - is turned on and you need to create a
215:51 - custom Trail for data events so you can
215:53 - get
215:54 - tamper evidence logging if you turn on
215:56 - data events for custom cloud trail
215:59 - events but one thing that if it's
216:01 - important to you is that you know if you
216:02 - use S3 it's not held in memory you know
216:04 - that'd be using a cloud HSM or KMS so
216:09 - you know you have to understand there
216:10 - are some trade-offs okay
216:12 - [Music]
216:17 - let's take a quick look here at
216:18 - terraform ignore files and if you know
216:20 - what git ignore files it's pretty much
216:21 - the same thing so when executing a
216:23 - remote plan or apply in a CLI driven run
216:25 - an archive of your configuration
216:27 - directory is uploaded to terraform cloud
216:29 - and so you could Define paths to ignore
216:31 - from upload via the dot terraform ignore
216:34 - file at the root of your configuration
216:36 - directory if this file is not present
216:38 - the archive will exclude the following
216:39 - by default so dot get dot terraform and
216:43 - Dot terraforming Nora works just like a
216:45 - DOT get ignore with the only difference
216:46 - is that you cannot have multiple dot
216:49 - terraform ignore files in subdirectories
216:50 - only the file in the root directory will
216:53 - be read so there you go and yes I know
216:56 - there's a double the okay so don't worry
216:58 - about that
216:59 - [Music]
217:03 - foreign
217:07 - foreign
217:10 - [Music]
217:19 - let's talk about resources so resources
217:22 - in configuration files represent
217:23 - infrastructure objects such as virtual
217:25 - machines databases virtual Network
217:26 - components and storage and so it pretty
217:28 - much looks like this a resource type is
217:30 - determines the kind of infrastructure
217:32 - object it is so here it says AWS
217:35 - instance and this would represent an AC
217:37 - AWS ec2 instance this is all defined
217:39 - within the providers documentation so
217:42 - you have to kind of look at what name
217:43 - they use to figure out what it is and
217:45 - even though you don't see provider
217:47 - explicitly set here a resource does
217:49 - belong to a provider and you can
217:52 - explicitly set it and you would do this
217:53 - when you'd want to set a resource
217:55 - outside the default provider that you
217:57 - have in your configuration file and so
218:00 - one little thing that I hadn't mentioned
218:02 - anywhere else and that's why I made this
218:03 - slide was to mention about special
218:05 - timeout nested blocks within resources
218:06 - so some resource types provide a special
218:08 - time on asset block argument that allows
218:10 - you to customize how long certain
218:12 - operations are allowed to take before
218:13 - being considered to have failed okay so
218:16 - there you go
218:17 - foreign
218:20 - [Music]
218:22 - let's talk about complex types so a
218:24 - complex type is a type that groups
218:26 - multiple values into a single value and
218:28 - complex types are represented by type
218:30 - Constructors but several of them are
218:33 - have shorthand keyword versions okay so
218:36 - there are two categories of complex
218:37 - types we have collection types for
218:39 - grouping similar values so list map set
218:41 - and structural types for grouping
218:43 - potentially to similar values so Tuple
218:46 - an object and it's now that we have an
218:48 - overview let's go jump into collection
218:49 - types and structural types
218:51 - [Music]
218:56 - a collection type allows multiple values
218:58 - of one other type to be grouped together
218:59 - as a single value and the type of value
219:02 - within a collection is called its
219:03 - element type the three kinds of
219:05 - collection types are list map and set
219:07 - and so looking at our first one here
219:10 - what we're doing is we are setting
219:12 - ourselves something that looks kind of
219:13 - like an array and it's these list type
219:15 - here and what we can do is use our index
219:17 - so the indices 0 to reference the first
219:20 - element which is Mars so that's going to
219:22 - make our username Mars for a map it's
219:25 - very similar to a ruby hash or
219:26 - singleness to Json object and the idea
219:29 - here is that it's very similar to the
219:31 - first except now we're doing a key and
219:33 - value and then we access it by based on
219:36 - the key name so plan B is going to
219:38 - return 50 USD okay
219:40 - we have set it is similar to a list but
219:43 - has no secondary index or preserved
219:45 - ordering
219:46 - all values must be of the same type and
219:49 - will be cast to match the first element
219:51 - okay so it's a great way to kind of have
219:55 - um well I guess no secondary index but
219:56 - yeah so you do two set and then it would
219:58 - turn into this okay
220:00 - [Music]
220:04 - all right let's take a look here at
220:05 - structural type so a structural type
220:07 - allows multiple values of several
220:09 - distinct types to be grouped together
220:10 - with a single value structural types
220:12 - require a schema as an argument to
220:14 - specify which types are allowed for
220:15 - which elements so this is what they're
220:18 - talking about when they say this schema
220:19 - so when you actually Define the variable
220:21 - notice where it says object and you are
220:23 - actually setting a is going to be a
220:25 - string and B is going to be a string
220:27 - there's this optional option which I
220:28 - think is right now in beta but hopefully
220:30 - by the time this course is out or it's
220:32 - the future you have that option there
220:34 - but just assume that they're all
220:35 - required so that's what they're talking
220:36 - about is that you are specifying exactly
220:38 - what you expect the schema to be okay so
220:42 - there are two kinds of structural types
220:44 - we have objects and tuples and they're
220:46 - going to look very familiar to maps and
220:48 - lists because they're pretty much the
220:49 - same but with explicit typing so object
220:51 - is a map with more explicit keying so
220:53 - this example we'd have name for string
220:55 - age for number and so that's what it
220:57 - would expect the data structure to be
220:58 - for Tuple multiple return types with a
221:00 - parameter so we can have string number
221:02 - or Boolean so so this is where we'd have
221:06 - a as a string 15 or true as a Boolean so
221:10 - you know there you go
221:12 - [Music]
221:16 - hey this is Andrew Brown from exam Pro
221:18 - and we're going to look at the
221:19 - collection and structural type so I have
221:22 - a new folder down below just in case we
221:25 - need to Define some things so I'm going
221:26 - to go here and just call this main.tf
221:31 - and we are just going to configure this
221:33 - for a local terraforms we'll just give
221:35 - the brackets there and so the idea is
221:37 - that we might have different kinds of
221:39 - variables
221:40 - and we had done this previously where we
221:43 - created a list and a map but we can do
221:45 - that again so we'll have like planet
221:48 - right
221:50 - so that's list and then we just default
221:53 - that to a value Mars
221:56 - Earth
221:58 - Moon
222:00 - and then we could also have you know
222:02 - plans here and that would be our map
222:04 - type
222:08 - okay and so here we'll just set it
222:14 - the curlies
222:17 - plan A
222:25 - Plan B
222:30 - plan C
222:43 - um
222:45 - so we'll do terraform console and so
222:46 - that should load these variables for us
222:49 - to use
222:51 - and so if I do var.plans
222:54 - I get that and if I do VAR dot planets
222:58 - uh didn't like what I did there input
223:01 - variable has not been declared
223:03 - I suppose just plan it there so I should
223:05 - have named that planets up here
223:08 - and so what we're going to do here is
223:10 - just go ahead and exit
223:12 - type clear
223:14 - I'm just going to expand this a bit
223:16 - bigger so we're taking over more of the
223:17 - screen and let's take a look at
223:19 - structural types so these require you to
223:21 - actually Define
223:22 - um
223:23 - parameters so what I'm going to do is go
223:25 - down below and we're going to do the
223:27 - object
223:29 - and object is very similar to the map so
223:32 - let's go down here
223:34 - plans object
223:38 - and so here what we do is we'd say type
223:43 - object
223:45 - and we would just have to Define some
223:47 - settings here
223:51 - um
223:54 - so we could say
223:59 - a is a string
224:03 - all right we'll see if that works
224:09 - the default value is now compatible with
224:11 - the variable type constraint attribute a
224:13 - is required
224:15 - so that's fine what we could do is just
224:18 - Define this as like plan A
224:23 - Plan B
224:25 - plan C
224:31 - and now if we just do VAR plans object
224:35 - when you are using this you know you
224:38 - might want to specify some different
224:39 - kinds here so you could just say like
224:42 - you say like plan here
224:45 - as soon as they plan name
224:48 - plan amount
224:52 - maybe it's like number
224:55 - and so then we'd say plan name
224:58 - plan amount
225:01 - basic
225:03 - maybe this will be 10.
225:09 - okay and we'll just uh
225:12 - type exit here and go back into
225:13 - terraform Cloud hopefully we don't get
225:15 - an error here so the plan amount is
225:17 - required so you know we can't have a
225:19 - spelling mistake here
225:23 - just do VAR plan here
225:28 - um
225:31 - well we named it correctly there and
225:32 - when we went up here and specified it I
225:34 - think we got it right plan object
225:38 - so
225:41 - tripler doesn't like here oh you know
225:43 - what we're not in terraform Cloud okay
225:44 - that's fair
225:47 - and we're still spelling this wrong
225:52 - oops
225:58 - okay so there we go we get our basic
226:00 - plan
226:02 - um and then we could do a tuple here so
226:07 - I don't know if I've ever defined a
226:08 - tuple before so let's just try it here
226:10 - and so we'll just say uh
226:13 - groceries or value or random
226:22 - type equals Tuple
226:32 - I'm just looking up if there's any kind
226:34 - of definition I can find here
226:44 - I'm not really finding anything but I'm
226:45 - just going to go Define this here
226:47 - because I thought maybe it needed like a
226:48 - schema or something but maybe it doesn't
226:50 - so we'll just say
226:51 - hello 22
226:54 - false okay
226:57 - terraform console
227:01 - dribble Constructor requires one
227:02 - argument specifying the element types as
227:04 - a list
227:06 - okay so if that's the case then what we
227:08 - could do is say string
227:10 - number
227:12 - Boolean
227:18 - the type Constructor requires one
227:20 - argument specifying the number of
227:22 - elements so clearly I'm doing this wrong
227:24 - so just give me a second I'll be back in
227:25 - a moment okay all right so I think the
227:27 - problem here was just that I need to
227:28 - make brackets here like this
227:31 - we'll give that a go
227:34 - boolean's not a valid option what if we
227:37 - try Bool
227:41 - okay we say VAR dot random
227:43 - good and so I'll just go ahead and exit
227:45 - that out I'm just going to see what
227:47 - happens if I change the order here so
227:48 - let's say I do instead of 22 here
227:51 - we go here
227:54 - okay so notice that you know we can have
227:56 - all sorts of Kinds but they have to
227:57 - match exactly the order that is there so
228:00 - yeah that's pretty much it so there you
228:02 - go
228:02 - [Music]
228:07 - the terraform language includes a number
228:09 - of built-in functions that you can call
228:11 - from within Expressions to transform
228:13 - your combined values so we have numeric
228:15 - string collection encoding file system
228:18 - date and time hash encrypto ipnetwork
228:22 - type conversions so we are going to go
228:25 - through all of these we might not go
228:26 - through every single function but we'll
228:28 - go through every single major category
228:30 - in terms of the exam the only thing
228:33 - that's going to show up might be string
228:35 - functions why they do this I don't know
228:37 - it's not a very good exam question but
228:38 - those might appear but I think that this
228:40 - is one of the strongest features of
228:42 - terraform over something like cloud
228:43 - formation and I really want to just show
228:46 - you the Gambit of them okay
228:48 - foreign
228:52 - [Music]
228:53 - let's take a look here at numeric
228:54 - functions starting with absolute so
228:56 - Returns the absolute value of the given
228:57 - number so 23 is 23 0 is 0 and if you get
229:00 - a negative number it's going to flip to
229:02 - the positive for 4. what it does is it
229:04 - rounds down to the nearest whole number
229:06 - so see where it says 4.9 becomes a 4.
229:08 - you have logs so it Returns the
229:11 - logarithmetic I can't say that word
229:13 - logarithm logarithm of a given number in
229:16 - a given base so log 50 comma 10 is going
229:19 - to give you that 16 comma 2 is going to
229:22 - give you 4 okay seal it it's where it
229:25 - will always round up so see where it
229:27 - says 5.1 and it goes all the way to 6.
229:29 - we have Min so take one or more numbers
229:31 - and return the smallest number from the
229:33 - set and Max take one or more numbers and
229:36 - return the greatest number of the set I
229:37 - don't have examples because that's
229:38 - pretty straightforward you know if
229:39 - there's a two and a four it's going to
229:41 - return the two in Min if it's a two and
229:42 - a four it's going to return the four for
229:44 - Max we have parse n so parse is the
229:47 - given string as a representation of an
229:49 - integer in the specified base and
229:51 - Returns the resulting number so if we
229:54 - have a hundred here in strings it's
229:56 - going to and we say comma 10 we're going
229:59 - to get 100 because that's the base
230:00 - system it's base system 10 base system
230:02 - 16 we can see letters in there right so
230:05 - it's able to translate that this is two
230:07 - so that's basically binary so zeros and
230:10 - ones so you get the idea there
230:12 - uh pow so calculates an exponent by
230:16 - raising its first argument to the power
230:19 - of the second argument so that's just
230:21 - the way of doing powers and then we have
230:22 - Signum so determine the sign of a number
230:25 - returning a number between negative one
230:27 - and one to represent the sign so there
230:30 - you go
230:31 - [Music]
230:36 - all right let's take a look here at
230:37 - string functions the first being chop so
230:39 - removes new line characters at the end
230:41 - of a string so you know if there's a
230:44 - hyphen n or sorry backslash n you don't
230:46 - want to see that there that's the way
230:47 - you get rid of it then you have formats
230:49 - it produces a string by formatting a
230:51 - number of other values according to the
230:52 - specification so here there are
230:55 - percentage Delights so this is
230:58 - representing a a digit so it's taking
231:00 - that number this says it's going to be
231:02 - formatted as a string okay
231:04 - format list so produce a list of strings
231:07 - by formatting a number of other values
231:09 - according to a specification string so
231:12 - here we have an array and then we have
231:15 - our specification so you can see it's
231:16 - substituting the name there
231:19 - um we'll look at indents so adds a given
231:22 - number of spaces to the beginnings of
231:23 - all but the first line in a given
231:25 - multi-string so here we have a string
231:29 - and what it's going to do is see where
231:32 - we have the interpolation here and then
231:34 - we have indent I know the the
231:36 - highlighting is not great because it's a
231:37 - single string but we have interpolation
231:39 - we have parentheses two so give it a a
231:42 - layer of two indentation and then it's
231:45 - going to break that up and give it
231:47 - indentation so we have join so produce a
231:50 - string by concatenating together all
231:52 - elements of a given list of strings with
231:53 - a given deliminator so use delimiters is
231:57 - double click or sorry it's a comma and
231:59 - so it's going to glue that together to
232:01 - make this okay
232:02 - if there's only a single one there just
232:04 - won't be any comma in there we can lower
232:07 - all the text it's pretty straightforward
232:09 - we have regular Expressions so that is
232:12 - an extremely powerful feature so here we
232:14 - have the regex I don't know what the
232:15 - regex format is uh maybe it's Pearl I'm
232:18 - not sure there's like a bunch of
232:21 - different types of regex Standards so
232:23 - you know do you have to figure that out
232:24 - so you know how to use it and then
232:26 - there's a regex all so applies to a
232:28 - regular expression to a string and
232:29 - returns a list of notches where this
232:31 - just is returning uh one okay
232:33 - We have replaced so search is a given
232:35 - string for another given substring and
232:37 - replaces each occurrence within a given
232:40 - replacement string this is just like the
232:42 - JavaScript replace we have split this is
232:45 - the opposite of join so if we want to
232:47 - split on the comma we specify comma here
232:49 - we have Str rev so string reverse so
232:52 - reverse is a string so hello becomes Ole
232:56 - we have sub ol
232:59 - sure I don't know
233:02 - um so substring so extracts a substring
233:04 - from a given string by offset and and
233:07 - length so we have a substring and we're
233:09 - saying we want one to four so we only
233:11 - want one two three four here okay
233:14 - because it starts at zero we have title
233:17 - so make a title okay so capitalize the H
233:19 - and the w we have trim removes the
233:22 - specified character from the start and
233:24 - end of the string so we don't want these
233:25 - and we tell it to remove those
233:27 - there's a lot of string functions uh so
233:29 - we have trim prefix so it removes the
233:32 - specified prefix from the start of the
233:34 - given string if the string does not
233:35 - start with the prefix the string is is
233:38 - returned and unchanged so here we say we
233:40 - want to get rid of hello in the front so
233:42 - we do that suffix is the opposite so we
233:45 - want to get a rid of world out of the
233:46 - suffix so we do that we have trim space
233:49 - so removes all types of white space from
233:51 - both the start and end of the line so it
233:53 - gets rid of the new lines and the spaces
233:55 - upper is going to put everything to
233:57 - Upper and there you go on the exam they
233:59 - probably will ask you uh like what
234:02 - string function does or which one does
234:04 - not do something so this is the only
234:06 - part of the built-in functions you have
234:07 - to know for the exam I don't think it's
234:09 - a very good exam question but it does
234:11 - appear there so you need to know it okay
234:13 - foreign
234:16 - [Music]
234:18 - functions and these are the most
234:20 - powerful built-in functions and there's
234:22 - a lot of them and I made sure to give
234:24 - you an example for each one because I
234:25 - really do want you to know these because
234:27 - this is the power of terraform the First
234:29 - on our list here is altru's returns true
234:31 - if all elements in a given collection
234:33 - are true are true or it also returns
234:36 - true if the collection is empty so it's
234:38 - either true true right or we have true
234:41 - false so because there's a false it's
234:42 - not going to be true so any true is very
234:45 - similar but there only has to be one
234:47 - that is true so if this is true and
234:50 - there's a false that's going to be true
234:51 - if it's blank it's going to be false
234:54 - okay
234:55 - we have chunkless splits a string list
234:58 - into fixed size chunks returning a list
235:00 - of lists so here we're telling it to
235:04 - chunk it every two so grab every two and
235:06 - make them into their own little array or
235:07 - list I suppose we have coalesce takes
235:10 - any number of arguments Returns the
235:11 - first one that isn't null or empty
235:13 - string if you're used to postgres you
235:15 - use this all the time but the idea is
235:17 - it's going to grab the a in this case
235:19 - it'll grab the B because that's blank in
235:21 - this case we'll grab the one because
235:22 - that's the first value we have coalesce
235:24 - list takes any number of list arguments
235:26 - and Returns the first one that isn't
235:28 - empty so very similar it's just using
235:30 - lists or if we want to call them array
235:31 - so the first one is available so it
235:33 - takes that one we have compact so it
235:36 - takes a list of strings and returns a a
235:38 - new list with an empty string elements
235:40 - removed so it's just going to get rid of
235:43 - that space there and we'll get ABC
235:46 - we have concat so it takes two or more
235:48 - lists and combines them into a single
235:50 - list so that's very convenient we have
235:52 - contain so determines whether a given
235:55 - list or set contains a given single
235:57 - value as one of its elements so does it
236:00 - have an A yes it does does it have a d
236:03 - no it does not we have distinct so takes
236:06 - a list and returns a new list with any
236:09 - duplicate elements removed so we just
236:12 - want to make sure we only have one of
236:14 - each so do we have any duplicates here
236:16 - we have two a's and two B's so we're
236:19 - going to end up with just a single list
236:22 - so only exactly one of each letter
236:25 - we have elements retrieves a single
236:27 - element from a list so get me the
236:29 - element at uh at three here so
236:33 - um wait retrieves a single element from
236:35 - a list
236:37 - okay well that's what it does you give
236:39 - it a three and it gives you an a I don't
236:41 - know why it's not clicking for me but I
236:43 - I'm not following through here index
236:45 - finds the element index for a given
236:48 - value in a list so we say where is B and
236:51 - the index of B is is one because it'd be
236:53 - zero and this would be one still really
236:55 - confused about this one
236:57 - flatten takes a list and replaces any
237:00 - elements that are are lists with a
237:03 - flattened sequence of list content so
237:04 - basically it says give me a bunch of
237:06 - eraser let's turn into one flat list
237:10 - uh Keys take a map and return a list
237:13 - containing the keys from the map so we
237:15 - just want the keys a c and d
237:18 - we want length this is pretty
237:20 - straightforward so what's the length of
237:22 - this zero this is two this is one
237:24 - because it's a one uh mapper one thing
237:27 - key value in there and if it's a string
237:30 - it's going to count the characters so
237:31 - there's five characters
237:33 - we have lookup so retrieves the value of
237:35 - a single element from a map
237:37 - given its key if the given key does not
237:40 - exist the given default value is
237:42 - returned instead
237:44 - so we say look up a and what we get is a
237:49 - y right look up C and it could not find
237:53 - C so by default give us what instead
237:57 - key a match Keys construct a new list by
237:59 - taking a subset of elements from one
238:01 - list whose indexes match the
238:03 - corresponding indexes of values in
238:05 - another list
238:06 - that sounds complicated let's read that
238:08 - one more time so constructs a new list
238:10 - by taking a subset of elements from one
238:14 - list who indexes match the corresponding
238:17 - index of values in another list that is
238:18 - confusing so we have one less than
238:21 - another one so we have this one here
238:25 - and we have us West Us East USD so we
238:27 - say okay we have uses so the elements
238:30 - here is two and three so give us two and
238:32 - three so that's what it does
238:34 - that was a that was a tricky I can't
238:36 - think of what you use that for but
238:37 - that's a interesting function merge
238:39 - takes an arbitrary number of maps or
238:42 - objects and returns a single map or
238:45 - object that contains a merged set of
238:46 - elements from all arguments
238:48 - so it just merges them together so it's
238:50 - just like concat
238:52 - or I suppose like flatten uh one takes a
238:55 - list set or Tuple values from with
238:58 - either zero or one element if the
239:00 - collection is empty one returns null
239:02 - otherwise one Returns the first element
239:04 - if there are two or more elements then
239:06 - one will uh one will return an error so
239:10 - it returns null on an empty List It
239:12 - Returns the first one and then here it
239:13 - says invalid function so it's just
239:15 - saying is there one right is it one or
239:17 - zero ranges generates a list of numbers
239:20 - using a start value a limit value and a
239:23 - step value so we say three and we get 0
239:26 - 1 and 2.
239:28 - during its a list of numbers using a
239:30 - start value limit value and a step value
239:32 - okay
239:34 - uh reverse so takes a sequence and
239:37 - produces
239:38 - res oh not reverse Reserve sorry Reserve
239:42 - takes a sequence and produces a number
239:44 - induced sequence of the same length with
239:47 - all the same elements as the given
239:49 - sequence but in reverse order oh it is
239:52 - reverse r e reverse I guess I spelled it
239:54 - wrong here sorry reverse one two three
239:57 - three two one just notice this is a
239:59 - spelling mistake okay
240:00 - uh set intersection so function takes
240:03 - multiple sets and produces a single set
240:05 - containing only the elements that all of
240:08 - the given sets have in common in other
240:10 - words it computes the intersection of
240:12 - the sets well it's tiring so from what I
240:15 - can tell it's like they all have B so
240:17 - give us B right
240:19 - set product functions find all the
240:21 - possible combinations of elements from
240:23 - all of the given sets by Computing the
240:26 - cardistarian product we're really
240:28 - getting into math here so we got app one
240:31 - and app2
240:32 - and so we got uh development develop
240:35 - okay so this continues on so it's going
240:37 - to say give me app one with development
240:38 - give me uh app two with development then
240:41 - Apple Mustang and then app2 with staging
240:43 - and etc etc because that's why I put the
240:46 - three dots there set subtract function
240:48 - returns a new set containing the
240:50 - elements from the a from the first set
240:52 - that are not present in the second set
240:54 - in other words it computes the relative
240:57 - complement of the first set in the
241:00 - second set
241:01 - uh it lost me there but it says set
241:03 - subtract so here I see a B and C A and C
241:07 - minus it you get B okay
241:09 - set Union function takes multiple sets
241:12 - and produces a single set containing the
241:13 - elements from all the given sets in
241:16 - other words it computes the union of the
241:18 - sets so it says set Union so we have
241:21 - a b b c and d and in the results we get
241:25 - d b c a so I guess
241:29 - um single set containing the elements
241:31 - from all the given so yeah yeah I guess
241:33 - it's just we get unique ones across the
241:35 - sets uh we have slice and notice like
241:38 - we're going through all these things
241:39 - it's like you probably won't use these
241:40 - more exotic ones so it's not a big deal
241:42 - if we don't nail them here but it's
241:43 - important that we go through these so
241:45 - that you know you just know all the
241:46 - options are here so slice extract some
241:48 - constructive consecutive elements from
241:51 - within a list so here we are saying one
241:54 - and three so we have B and C that's
241:56 - where they start index one
241:59 - um and then extract some consecutive
242:02 - elements from within a list one comma
242:05 - three
242:06 - okay
242:08 - sort takes a list of strings and returns
242:11 - a new list with those strings sorted
242:13 - lexicographically so we have e d a and x
242:17 - and so now they're alphabetical so a d e
242:20 - and X
242:21 - well I think this is the last one uh
242:24 - some takes a list of set numbers and
242:25 - Returns the sum of those values that's
242:27 - pretty straightforward add them all up
242:28 - transpose take a map of list of strings
242:31 - and swap the key and values to produce a
242:33 - new map a list of strings so kind of
242:36 - like inverts it values takes a map and
242:39 - returns a list containing the values of
242:41 - the map so we saw this earlier we got
242:43 - the keys this is where we just want to
242:44 - get the values zip map so construct a
242:46 - map from a list of keys and a
242:48 - corresponding list of values so we have
242:51 - a b one two and this turns it into a
242:53 - equal one b equals two I think I saw
242:55 - this on the exam so that one you might
242:57 - want to remember but yeah that's
242:58 - collection functions as you can imagine
243:00 - they're extremely powerful but they can
243:02 - also be really confusing so maybe just
243:04 - use them a little bit when you need to
243:05 - okay
243:06 - [Music]
243:10 - we're taking a look here at encoding and
243:12 - decoding functions so functions that
243:14 - will encode and decode for various
243:16 - formats so imagine we need to encode
243:19 - into base64 so we do hello world or
243:22 - imagine we give that encoded string and
243:25 - we want to decode it back to hello world
243:27 - that's what we can do so there's a lot
243:29 - of different encoding decoding functions
243:31 - most of them are the same they're just
243:32 - kind of variants so we're not going to
243:33 - go through every single one but I'll
243:35 - list them out so you know what they are
243:36 - so we have base64 encode Json encode
243:39 - text and code base64 yaml encode base64
243:42 - gzip URL encode base64 decode CSV decode
243:47 - Json decode text decode base64 yaml
243:51 - decode and just notice that you know
243:53 - these aren't one to one so there is one
243:55 - for this we have one for here uh we have
243:59 - one for yaml
244:00 - uh this is unique this is unique this is
244:04 - unique okay just so you can tell for
244:06 - your own code I think this one's a very
244:08 - common one that you'll use but the idea
244:10 - is that let's say you have hello world
244:11 - you want to replace that string with a
244:13 - uh whatever friendly for a URL right so
244:15 - it just encodes it okay it's very useful
244:18 - when you're making URL links so there
244:20 - you go
244:21 - [Music]
244:25 - we're taking a look here at file system
244:27 - functions so this has everything to do
244:28 - with the file system so the first is
244:30 - absolute path so the idea is you give it
244:32 - something that's relative and it's going
244:34 - to give you something absolute directory
244:36 - name so this is a string containing a
244:38 - file system path and removes the last
244:40 - portion from it so we don't need the
244:42 - file name so we just remove that off of
244:44 - there we have path expand so takes a
244:47 - fossils and path that might begin with a
244:49 - tilde and expands it into its absolute
244:53 - path so this would be like for home okay
244:57 - um base name so it takes a string
244:59 - containing a file system path and it's
245:00 - basically the opposite of directory name
245:02 - we just want the file here okay
245:04 - onto the next page here this file will
245:08 - read the contents of the file pretty
245:10 - straightforward we can check if a file
245:12 - exists so we just do file exists here we
245:15 - have file set so it enumerates a set of
245:17 - regular file names given a path and
245:20 - pattern file base64 so it reads the
245:23 - contents of a file at a given path and
245:25 - Returns the basics before encoding that
245:27 - might be good for images template file
245:29 - so reads the file at a given path and
245:32 - returns its content as a template using
245:34 - a supplied set of template variables so
245:37 - that's really useful if you want to do
245:39 - some kind of templating
245:40 - uh and just notice it's a two-step
245:42 - process so this is the template file the
245:44 - actual file itself and then we load it
245:46 - here it's called a DOT TPL so there you
245:49 - go
245:50 - [Music]
245:54 - we're taking a look at date and time
245:55 - functions the first is format date so
245:58 - the idea is that we provide a format
246:01 - that we want and then we give it a
246:03 - timestamp that is in the RFC 3339 format
246:06 - and we get a variety of different
246:08 - um formats out there we can add time so
246:11 - again it's going to be that RFC 3339
246:13 - format and we say add 10 minutes add one
246:16 - hour then we have timestamp so you it
246:19 - returns a UTC timestamp string in the
246:21 - RFC 3239 format so you just say
246:23 - timestamp it's I guess it would get
246:24 - right now and then you get it in that
246:26 - format okay
246:27 - [Music]
246:31 - let's take a look at hash and crypto
246:33 - functions so generates hashes and
246:35 - cryptographic strings so the most
246:37 - popular one out there would probably be
246:38 - B so here we just say hello world
246:40 - and we're going to get this thing here
246:42 - understand that a hash cannot be
246:45 - reversed so once it is turned uh into uh
246:48 - you know this format the only way you're
246:50 - going to be able to confirm the contents
246:51 - of it is to Hash something that is
246:54 - similar and then compare it against it
246:55 - okay so we have base64 Shaw 256 we have
247:00 - 512 we got B Crypt we have file Bay 64
247:03 - Shaw 256 file based 64 Shaw 512 file md5
247:07 - file Shaha one file Shaw 56 file Shaw
247:11 - 512 md5 RSA decrypt sha-1 Shaw to V6
247:17 - Shaw 512 uuid uid V5 so I only showed
247:21 - the one because you know it gets kind of
247:24 - boring to go through all these and
247:25 - really it's just going to be based on
247:27 - your use case what you're going to be
247:28 - using on a day-to-day basis is probably
247:30 - bcrypt md5 and you uids so there you go
247:34 - [Music]
247:38 - let's take a look at IP network
247:39 - functions these are the coolest
247:41 - functions I think that are built into
247:42 - terraform so we have cider host so what
247:45 - we can do is give ourselves a
247:47 - a address and then we can give it a
247:50 - subnet Mass size and we'll get back an
247:52 - IP address and so you can see we have
247:55 - this both in the ipv4 and the IPv6 we
247:58 - have cider net mask so here we are doing
248:02 - cidernet math so we just say forward
248:05 - slash 12 and it's going to translate it
248:06 - into the full ipv4 then we have cider
248:10 - subnet so this is just where we say Okay
248:12 - I want a subnet of a particular size so
248:15 - we say 172 1600 comma 4 2 and look it's
248:20 - going to give us 18 0 back doesn't make
248:23 - sense that's okay I mean networking is
248:25 - really hard but I just want you to know
248:26 - that these functions are here for you
248:28 - okay cider subnet calculates a sequence
248:31 - of consecutive IP addresses within a
248:32 - particular cider prefix so 4484 and then
248:36 - you get those sizes there okay
248:39 - [Music]
248:43 - all right we're on to type conversion
248:45 - function so the first we're looking at
248:46 - is can so can evaluates the given
248:48 - expression and returns a billion value
248:49 - indicating whether the expression
248:51 - produced a result without any error so
248:53 - can we use this right so we say
248:56 - local.food.bar and so you know if if
248:58 - this Foo wasn't defined then it would
249:00 - say false but apparently we've made it
249:02 - all the way to borrow okay
249:04 - we have defaults a specialized function
249:06 - intended for use with input variables
249:08 - whose type constraints are object types
249:10 - or collection of object types that
249:12 - include optional attributes and I don't
249:15 - show that one here because it's not that
249:16 - exciting but non-sensitive takes a
249:18 - sensitive value and returns a copy of
249:20 - that value with the sensitive markings
249:22 - removed therefore exposing the sensitive
249:24 - values so if we have an output here and
249:27 - we want to make it non-sensitive that's
249:29 - what we could do then sensitive as you
249:31 - imagine is just the opposite okay
249:35 - we have two Bool so converts its
249:38 - arguments to a Boolean value so if we
249:40 - have a string that's true we can turn it
249:42 - into a real Boolean value we have to map
249:44 - converts an argument to a map value to
249:46 - set converts it to a set to list
249:48 - converts it to a list to number converts
249:51 - it to a number string to string and then
249:54 - we last we have is try so evaluates all
249:56 - of its arguments expressions in turn and
249:58 - Returns the result of the first one that
250:01 - does not produce any errors the thing
250:02 - that's the hardest to figure out is set
250:05 - I cannot find really good examples or
250:07 - documentation on the use case of set
250:09 - there are some cases where you need to
250:10 - use sets which is an actual type but
250:12 - even talking to DA's and
250:14 - technical writers they weren't even sure
250:16 - themselves so this is not something
250:18 - you're going to come across very often
250:20 - but
250:21 - there's like one case where I saw it so
250:23 - I'll probably point that out when we do
250:24 - hit it okay
250:25 - [Music]
250:29 - hey this is Andrew Brown from exam Pro
250:31 - and we are going to go take a look at um
250:34 - built-in functions as soon as my
250:36 - terminal decides to be responsive I
250:38 - don't know why as soon as I start
250:39 - recording it decides to lock up so we'll
250:41 - just give it a moment there there we go
250:42 - and so I have a new folder there I
250:44 - figured we could just find some
250:45 - variables so that we don't have to uh
250:48 - you know constantly write stuff in so
250:51 - we'll just say main.tf
250:53 - we're going to go terraform here
250:57 - and so might be fun to you know kind of
251:01 - some kind of variable here and so I have
251:03 - off screen here all the functions so
251:05 - we're just going to kind of pick some at
251:06 - random here to play around with so we
251:08 - get some experience okay
251:10 - so just going through strings
251:14 - I think what we can do is Define like
251:16 - our strings so we just say Str here
251:18 - and we'll just say type equals string
251:22 - and we'll just say default here able to
251:24 - say hello
251:25 - world
251:27 - forward slash n
251:30 - something like that
251:31 - okay
251:33 - and then we'll do terraform console here
251:39 - I gotta remember to do it this way
251:45 - so we do var.str
251:47 - okay and so that accesses our string
251:49 - there
251:50 - maybe we might want to take out the new
251:51 - line for now
251:59 - so I'm just going to kind of pull this
252:01 - up over here
252:02 - look at some kind of things we can do
252:11 - okay maybe collapse that get that out of
252:14 - the way all right so there's a lot of
252:16 - string functions and on the exam they
252:18 - might actually ask you some which is in
252:20 - my opinion I don't I don't really like
252:21 - that but that's what they do
252:23 - and so you know we might want to look at
252:25 - something like split or something so
252:27 - here we could do
252:30 - hello world
252:33 - okay
252:36 - start that up again
252:38 - so we'll do split
252:41 - comma
252:42 - VAR Str okay and that would split that
252:45 - into a list
252:47 - we might want to do something
252:50 - like upper so I think we did that
252:53 - earlier where we did upper
252:59 - okay
253:00 - you might want to do trim remove specify
253:03 - characters from the start and end of the
253:05 - string so maybe we have this here
253:12 - and so we'll say trim
253:16 - VAR Str
253:19 - and whoops
253:21 - it's not what I wanted to do
253:24 - trim far Str
253:28 - UCT like that okay
253:31 - and there's again there's not a lot
253:33 - that's exciting here maybe we'll try a
253:35 - replace so we can do replace
253:40 - and we'll we want to replace we won't
253:42 - provide our string
253:43 - and then the substring that we're
253:45 - looking for so world
253:47 - replace that with bar soon which is Mars
253:50 - there we go
253:54 - so nothing super exciting over there
253:57 - what's more interesting are some things
253:59 - like these hash encryptos
254:01 - so something we might want to generate
254:02 - out is a uuid I think that we might be
254:05 - able to do this here so let's just see
254:06 - what happens if we try to call it like
254:08 - that
254:10 - clear
254:12 - to our form cloud
254:15 - oops terraform console that's what I
254:17 - meant to type
254:20 - and so functions can't be called in here
254:22 - which is totally fine
254:24 - so go back and just set that like that
254:28 - I just wanted to show you that
254:30 - so if we did uuid we would get that
254:33 - if we used bcrypt
254:37 - so I might say bcrypt
254:42 - hello world
254:49 - okay
254:51 - might be something interesting the IP
254:53 - network here
254:56 - so we might want to generate out a cider
254:58 - subnet
254:59 - right
255:02 - the typing conversions is something that
255:04 - you might come across a bit so we
255:05 - already saw that when we converted a set
255:07 - to a list and things like that
255:09 - so maybe we might want to convert
255:11 - something to a Boolean so we might say
255:13 - two Bool
255:15 - true
255:18 - okay
255:21 - these are pretty complicated the
255:22 - collections
255:24 - but we might have something that we want
255:25 - to do here so coalesce might be
255:27 - something that's interesting where we
255:28 - have an array so or a list I suppose
255:33 - so we might say like items
255:39 - and make that a list
255:44 - null null empty
255:47 - last okay
255:53 - bar items
255:55 - so we might say coal
255:58 - Plus
256:01 - okay
256:03 - and that didn't look like it pulled
256:05 - anything out of there to reform coalesce
256:07 - operation with this list of strings use
256:09 - this symbol so we could use that
256:12 - um
256:13 - to do that so that just kind of expands
256:15 - the arguments and so that what happened
256:18 - here is null didn't exist Alden exists
256:19 - this didn't exists so it pulled out last
256:21 - okay
256:24 - maybe we might want to just use keys
256:27 - maybe we might just want to use Keys
256:29 - here
256:46 - okay so it might sound like hello
256:52 - world
256:55 - goodbye
256:58 - Moon and remember we can do uh hash
257:01 - Rocket Arrow equals or colon it's just
257:03 - up to your preference I just wrote that
257:06 - in for whatever reason I'm used to using
257:07 - Ruby and that's what we use as hash
257:08 - Rockets that's the name of the symbol
257:10 - the equals Arrow
257:13 - um okay it didn't like that so I guess
257:15 - we do have to do it this way that's
257:16 - totally fine I'm not upset by that I
257:18 - thought it supported all three
257:21 - maybe it's like minus equals or
257:23 - something I don't know but what we'll do
257:25 - say is save our stuff
257:28 - and then what we can do here is do keys
257:31 - okay
257:34 - and it didn't look like it grabbed oh
257:37 - yeah I grabbed the keys that's fine okay
257:38 - and then we might say values
257:42 - all right
257:45 - um
257:46 - you know maybe we might want to try
257:48 - reverse that one's pretty clear
257:56 - one two three
258:01 - okay so nothing super complicated I
258:04 - wonder if absolute would work in here
258:05 - like the file system so we have absolute
258:07 - path
258:08 - I don't know if I don't know if this
258:10 - would produce anything here oh it does
258:11 - okay so we could ABS path
258:14 - say path dot root
258:16 - there you go
258:18 - okay so that pretty much gives you a
258:20 - general idea of built-in functions so
258:22 - there you go
258:23 - [Music]
258:27 - all right let's take a look here at
258:29 - terraform Cloud again but in Greater
258:31 - detail so terraform cloud is an
258:32 - application that helps teams use
258:34 - terraform together and so there is the
258:36 - UI there and terraform cloud is
258:38 - available as a hosted service on
258:39 - terraform terraform.io it's actually at
258:42 - the app.t terraform.io once you're
258:44 - logged in and it has a lot of different
258:46 - features so it can manage State files uh
258:49 - have a history of your previous runs a
258:51 - history of your previous States easy and
258:53 - secure variable injection tagging run
258:56 - trigger so chaining workspaces together
258:57 - specify any version terraform per
259:00 - workspace Global State sharing
259:01 - commenting on runs notifications via
259:04 - webhooks email and slack organization
259:06 - and workspace level permissions policy
259:09 - is code via Sentinel policy sets MFA
259:12 - single sign-on cost estimation
259:15 - Integrations with service now Splunk
259:17 - kubernetes and custom run tasks and that
259:21 - is not the limit to what it does but
259:22 - this is what I could fit on the slide
259:24 - okay
259:25 - [Music]
259:29 - let's take a quick look here at the
259:31 - terminology or anatomy of terraform
259:34 - clouds so we have an organization and
259:36 - with an organization we have our
259:38 - workspaces and a workspace represents a
259:41 - unique environment or stack then you
259:43 - have your teams these are composed of
259:44 - multiple members and a team can be
259:46 - assigned to multiple workspaces then you
259:49 - have runs a run represents a single run
259:51 - of the terraform-run environment that is
259:53 - operating on an execution plan runs can
259:55 - be triggered by like you your the UI
259:58 - itself or maybe like a git repo it could
260:00 - be API driven or CLI driven so there you
260:03 - go
260:04 - foreign
260:06 - [Music]
260:08 - so there are three types of cloud run
260:10 - workflows so when you create a workspace
260:11 - you have to choose a workflow and you
260:13 - have either Version Control workflow we
260:16 - have CLI driven workflow or API driven
260:19 - workflow okay so just going over them in
260:22 - Greater detail for the first one which
260:24 - is that version controlled workflow
260:26 - terraform cloud is integrated with a
260:28 - specific branch in your VCS so githubs
260:31 - via web hooks whenever pull requests are
260:33 - submitted for branch speculative plans
260:35 - are generated whatever a merge occurs to
260:38 - that Branch then a run is triggered on
260:40 - terraform Cloud then you have API driven
260:42 - so workspaces are not directly
260:43 - associated with the Version Control
260:45 - System repository and runs are not
260:49 - driven by web hooks on your VCS provider
260:52 - a third-party tool or system will
260:54 - trigger runs via uploading a
260:56 - configuration file via the terraform
260:58 - Cloud API so this configuration file is
261:02 - a bash script that is packaged in an
261:04 - archive and you're pushing it as a
261:06 - configuration version so you're
261:07 - basically creating configuration
261:09 - versions every time you do that then
261:11 - there's CLI driven and this is the way
261:12 - we're going to be using mostly in the
261:14 - course so runs are triggered by the user
261:17 - running terraform CLI commands so you'll
261:20 - run terraform apply and or plan locally
261:23 - on your machine it's going to just work
261:25 - as per usual okay
261:26 - [Music]
261:31 - let's take a look at organization level
261:33 - permissions which manage certain
261:34 - resources or settings across an
261:36 - organization so the first things that
261:39 - you can set would be something like
261:40 - manage policy so create edit delete the
261:42 - organization Central policies manage
261:44 - policy override so override soft
261:46 - mandatory policy checks manage
261:48 - workspaces so create administer all
261:50 - workspaces within an organization manage
261:52 - VCS settings so set of VCS providers and
261:55 - SSH Keys available within the
261:57 - organization and for an organization we
262:00 - have this concept of organization owners
262:01 - so every organization has at least one
262:04 - organization owner and you can have
262:05 - multiple this is a special role that has
262:07 - every available permission and some
262:09 - actions only available to owners so this
262:12 - could be publishing private modules
262:14 - invite users to organizations manage
262:16 - team memberships view all secret teams
262:18 - manage organization permissions manage
262:21 - all organization settings manage
262:23 - organization Billings delete
262:25 - organizations and manage agents so just
262:27 - understand that there are these special
262:29 - ones just for this organizational owner
262:32 - and then these are these other ones here
262:33 - that you can set for other types of
262:35 - organizational level permissions okay
262:37 - [Music]
262:41 - let's take a look here at workspace
262:43 - level permissions that allows you to
262:45 - manage resources and settings for a
262:47 - specific resource and we have granular
262:49 - ones and then we have pre-made
262:50 - permissions so let's go through the
262:51 - granular permissions first so these
262:53 - granular permissions you can apply to a
262:55 - user via a custom workspace permissions
262:58 - and so we have read runs queue plans
263:00 - apply runs lock and unlock workspaces
263:03 - download signal locks read variables
263:05 - read and write read State outputs read
263:08 - State versions read and write State
263:09 - versions and so the idea is that what
263:12 - you can do is just go and cherry pick
263:14 - out what you want to assemble your
263:17 - permissions for your user now if you
263:19 - want something a little bit easier to do
263:22 - you can use fixed permission sets and
263:24 - these are pre-made permissions for quick
263:26 - assignment and they're based on the read
263:27 - plan and write so we have read runs read
263:31 - variables read State versions for plans
263:33 - we have q plans read variables read
263:35 - State versions We have write so apply
263:37 - runs lock and unlock workspaces download
263:39 - setting unlocks read write variable read
263:42 - write State versions and then there are
263:45 - workspace admins and this is kind of
263:47 - like the organizational owner so a
263:49 - workspace admin is a special role that
263:51 - grants all level of permissions in some
263:53 - workspace admin only permissions those
263:55 - admin only permissions would be read and
263:57 - write workspace settings set or remove
264:00 - workspace permissions of any team and
264:02 - delete workspaces so there you go
264:04 - [Music]
264:08 - let's take a look here at API tokens so
264:10 - terraform Cloud supports three types of
264:12 - API tokens users teams and organization
264:14 - tokens so for organization API tokens
264:17 - they have permissions across the entire
264:18 - organization each organization can have
264:20 - one ballot API token at a time only
264:23 - organization owners can generate or
264:24 - revoke an organization token
264:26 - organization API tokens are designed for
264:28 - creating and configuring workspaces and
264:30 - teams they're not recommended as
264:31 - all-purpose interfaces to terraform
264:33 - Cloud so basically you just use them
264:35 - when you are setting up your
264:36 - organization for the first time and you
264:38 - want to do it pragmatically okay then
264:40 - you have Team API tokens so this allows
264:43 - access to workspaces that the team has
264:44 - access to without being tied to any
264:46 - specific user each team can have one
264:49 - valid API token at a time any member of
264:51 - a team could generate or revoke that
264:53 - team's token when a token is regenerated
264:55 - the previous token is immediately
264:58 - becomes invalid designed for performing
265:00 - API operations on the workspaces same
265:03 - access level to the workspace the team
265:05 - has to access to I would imagine this is
265:07 - when you're sending out your own custom
265:09 - CI CD pipelines or something like that
265:11 - I'm not really sure exactly the use case
265:13 - for team API tokens we have user API
265:16 - tokens the most flexible token type
265:18 - because they inherit permissions from
265:19 - the user they are associate could be for
265:22 - a real user or a machine user when you
265:24 - do terraform login this is what you're
265:26 - getting a a um a user API token okay
265:31 - foreign
265:34 - [Music]
265:35 - so I just wanted to quickly show you
265:37 - this axis levels chart that helps you
265:40 - understand uh what kind of permissions
265:42 - you were giving at the access level and
265:44 - notice there's implicit and then
265:45 - required or explicit permissions I'm
265:47 - assuming that this means that you need
265:49 - to assign those permissions to the user
265:50 - first before they'd have it so just
265:52 - because you have a user token doesn't
265:53 - mean you get all of these orange
265:55 - diamonds it's just the ones that you've
265:57 - assigned to that user or team where I
266:00 - believe that the organization you're
266:01 - going to run into a chance where you're
266:03 - going to have all these permissions by
266:05 - default whether you want them or not so
266:07 - just understand uh that you have to
266:10 - double check this before you use your
266:12 - tokens and that this chart exists okay
266:14 - [Music]
266:19 - all right so we covered private registry
266:20 - earlier in the course when we were
266:22 - looking at the terraform registry the
266:23 - public one but let's cover it again with
266:25 - a little bit different information so
266:26 - terraform Cloud allows you to publish
266:28 - private modules for your organization
266:29 - within terraform Cloud private registry
266:32 - and tour from Cloud's private module
266:34 - registry helps you share terraform
266:35 - modules across your organization include
266:38 - support for module versioning a
266:39 - searchable filterable list of available
266:41 - modules a configuration designer which I
266:44 - didn't find this thing but it sounds
266:45 - really cool all users in your
266:47 - organization can view your private
266:50 - module registry authentic for
266:52 - authentication you can either use a user
266:54 - token or a team token so I guess this
266:56 - would be the case where you might want
266:57 - to use a team token for authentication
266:59 - but the type of token you choose May
267:00 - Grant different permissions as we saw
267:02 - with the access levels just the slide
267:05 - prior using terraform login will obtain
267:07 - a user token just a reminder and to use
267:10 - a team token you'll need to manually set
267:12 - it in your terraform configuration CLI
267:14 - file okay
267:15 - [Music]
267:20 - so there's a feature within terraform
267:21 - Cloud that can do cost estimation and it
267:24 - is a feature that will give you a
267:25 - monthly cost of resources displayed
267:27 - alongside your runs this feature is only
267:29 - available starting at the teams and
267:31 - governance plan and above but the idea
267:33 - is that it will tell you for specific
267:35 - resources and give you a summary so
267:37 - notice here that we have some pricing
267:39 - I'm going to get my pen tool out but we
267:41 - have the overall cost and then it's
267:43 - broken down per resource and so you can
267:45 - see we have an hourly monthly and
267:47 - monthly Delta
267:49 - I don't know what the monthly Delta is
267:50 - but um you know it gives you kind of
267:52 - idea of cost you can use sentinel
267:54 - policies to assert the expectation that
267:56 - the resources are under a particular
267:57 - cost so that's just kind of a bonus
267:59 - there where you're like okay I want to
268:01 - assure my spend is this the only
268:02 - downside at least at the time right now
268:04 - for cost estimation is the amount of
268:07 - support it has so we have AWS Azure and
268:09 - gcp so these are the resources that it
268:11 - will support and so you have to look
268:13 - through here and say okay you know is
268:15 - there any resources I'm using outside of
268:17 - this that I really care about
268:19 - um and that so I think that if you're
268:20 - using like core services so like ec2
268:23 - instances load balancers things like
268:26 - that that should help you out so like we
268:28 - see AWS instance the load balancer the
268:30 - volume some cloudwatch logs ALB for
268:34 - Google it's just disk instance and
268:36 - database so yeah it's just really
268:38 - dependent on you know what's here so you
268:40 - know it may meet your needs or you might
268:42 - say okay this is not enough okay
268:44 - [Music]
268:49 - here's just a few options that I think
268:51 - are worth noting within the terraform
268:53 - Cloud workflows we have a whole section
268:55 - of workflows but I decided to put it
268:57 - over here just because let's talk about
268:58 - it one thing you can do within terraform
269:00 - cloud is set whatever version you want
269:02 - so you can go as far back as you want uh
269:04 - and this is great if you need to mix and
269:06 - match different workspaces because you
269:09 - have different stacks and they were
269:10 - built on different terraform versions
269:11 - and you're just not ready to upgrade
269:13 - them yet you can choose to share State
269:15 - globally across your organization for a
269:17 - particular workspace this could be
269:19 - really useful if you need to reference
269:20 - things wherever you can choose to Auto
269:22 - approve run so if you don't want to
269:24 - always do that manual approve you can do
269:27 - that this is great if you are looking
269:28 - for that kind of agile kind of workflow
269:31 - where if something is merged then it
269:33 - should be rolled out okay
269:35 - please
269:39 - let's talk about if we had to migrate
269:41 - our local state and we're using just the
269:43 - default one two terraform Cloud how
269:44 - would we do it so to migrate terraform
269:46 - projects it only uses the default
269:47 - workspace here from cloud it's pretty
269:49 - easy you're going to create a workspace
269:50 - and terraform Cloud you're going to
269:52 - replace your terraform configuration
269:53 - with the remote backend so if you have
269:55 - nothing it's using local and you just
269:57 - put in your remote State and then once
269:59 - you have that in there you do a
270:01 - terraform and knit and it's going to say
270:03 - hey do you want to copy the existing
270:04 - state you're going to type yes and once
270:05 - you've done that I believe you have to
270:07 - delete your old State file if you are
270:09 - migrating multiple
270:12 - um
270:12 - multiple environments or you're moving
270:15 - from a standard remote back end it's a
270:17 - little bit more complicated they
270:18 - definitely have guides in the docs but
270:20 - this is the pretty much standard one
270:22 - that you're going to come across when
270:23 - you're working very early and we'll
270:24 - definitely see this as we are using
270:27 - terraform in our follow alongs okay
270:30 - foreign
270:33 - I want to talk about what kind of
270:35 - Integrations we have for terraform for
270:37 - Version Control Systems so we have
270:39 - GitHub GitHub auth GitHub Enterprise get
270:41 - lab gitlab EEG and CE I assume that's
270:44 - Enterprise Edition and Community Edition
270:46 - bucket Cloud bitbucket Server and data
270:49 - center Azure devops service Azure devops
270:52 - server so it's very simple you're just
270:53 - going to choose from the one of the four
270:55 - right and then you're gonna just drop
270:57 - down and choose what variant it is there
270:58 - and connect your repo every single
271:02 - provider has different configuration
271:04 - settings so you might have to meet those
271:05 - depending on what they are you can get
271:07 - from private repos you might have to add
271:09 - your SSH key or something like that okay
271:12 - [Music]
271:16 - let's talk about terraform Cloud run
271:18 - environment so when terraform Cloud
271:20 - executes your terraform plan it runs
271:22 - them in its own run environment so what
271:25 - is a run environment a run environment
271:26 - is a virtual machine or container
271:27 - intended for the execution of code for a
271:29 - specific runtime environment a run
271:31 - environment is essentially a code build
271:32 - server so the terraform Cloud run
271:34 - environment is a single-use Linux
271:36 - machine running on the x86 or x64
271:39 - architecture and the details of its
271:41 - internal simple petition is not known it
271:43 - is possible to install software on it
271:45 - but the only issue is that we don't know
271:47 - what it is is a Debian is it Ubuntu you
271:48 - just can't tell terraform Cloud will
271:50 - inject the following environment
271:52 - variables automatically on each runtime
271:53 - so we have TFC run ID this is a unique
271:56 - identifier for the current run the
271:59 - workspace name the workspace slug so
272:02 - this is the organization followed by the
272:04 - workspace just going to get my pen tool
272:06 - to just kind of point out over here on
272:07 - the right hand side we have the
272:09 - configuration version and git Branch so
272:11 - you know if it is going to be on Main
272:13 - it's going to tell us that if it's going
272:15 - to be a particular version we'll know
272:16 - that as well we can get the shaw of the
272:19 - current commit there's that version and
272:21 - if you want to access these variables
272:23 - you just Define variable and the name
272:24 - and then you can access it throughout
272:26 - the code okay
272:28 - [Music]
272:32 - let's take a look here at terraform
272:33 - Cloud agents this is a paid feature of
272:35 - the business plan to allow terraform
272:37 - Cloud to communicate with isolated
272:38 - private or on-premise infrastructure
272:40 - it's kind of like an in-between uh
272:42 - between a terraform cloud and terraform
272:44 - Enterprise where you want to use
272:45 - terraform Cloud but you have uh
272:47 - on-premise infrastructure but you're not
272:48 - ready to move to terraform Enterprise so
272:51 - this is useful for on-premise
272:52 - infrastructure types such as vsphere
272:54 - nutanix and openstack the agent
272:57 - architecture is pole based so there are
272:59 - no inbound connectivities required any
273:01 - agent you provision will pull terraform
273:03 - Cloud for work and Carry Out execution
273:05 - of that work locally agents currently
273:07 - only support the x86 architecture or the
273:10 - x64-bit Linux operating system okay so
273:13 - you can also run the agent within Docker
273:16 - using the official terraform agent
273:18 - Docker container if you just prefer that
273:20 - over a VM agent supports terraform
273:22 - version 0.12 and above the system
273:26 - requires
273:27 - request the system requires I'm going to
273:30 - change that in the slide later on but
273:32 - the system requires at least four
273:35 - gigabytes of free to space for temporary
273:37 - temporary local copies and two gigabytes
273:40 - of memory needs access to make outbound
273:43 - requests so you need to have open port
273:45 - 443 for app terraform i o registry
273:49 - terraform i o releases hashicorp.com and
273:53 - um
273:54 - archivist.terra for my IO so there you
273:56 - go
273:56 - [Music]
274:01 - this is Andrew Brown from exam Pro and
274:02 - we are on to our terraform Cloud uh
274:04 - follow alongs now we already did
274:05 - terraform Cloud uh Version Control
274:07 - System earlier than I thought we were
274:09 - going to do so I'm going to remove from
274:10 - the list and what we'll do is focus on
274:11 - permissions and maybe the API tokens and
274:14 - things like that so what I want you to
274:16 - do and I've got some old tabs open here
274:17 - but I'm going to make my way over to uh
274:20 - terraform.io
274:22 - and I'm going to go log into terraform
274:24 - Cloud here
274:25 - and I don't think I've ever done this
274:27 - but I can upgrade to the trial count
274:29 - because the thing is is that when we are
274:30 - in our account here and we're trying to
274:32 - look at permissions and we're not using
274:35 - Force unlocking anymore I might just
274:37 - keep that around for a little bit but if
274:38 - we were to go to our user settings here
274:41 - we go to organizations
274:45 - um that might not be a very good example
274:47 - like I said I wanted like the
274:49 - organization settings here
274:52 - which would be
274:55 - maybe here yep up here and so you know
274:58 - when we go to our teams and our users
275:00 - our users everyone's being added as an
275:02 - owner we don't have like granular
275:03 - permissions and that's because we'd have
275:05 - to upgrade and so I figured this would
275:08 - be a good opportunity for me to just
275:09 - kind of upgrade to show you those uh
275:11 - more detailed uh role-based Access
275:12 - Control permissions just so you know
275:15 - where they are so I'm gonna go the
275:16 - upgrade now and notice that we're on the
275:18 - free plan and also take note because
275:20 - later on the course I talk about pricing
275:22 - or we've already already acrossed it but
275:25 - notice that we have a team plan and a
275:26 - team and governance plan this one's at
275:28 - twenty dollars and this one's at seventy
275:30 - dollars so you know this is not
275:32 - something that's reflected at least not
275:33 - right now on the terraform website and
275:36 - so it just looks like there's a team in
275:37 - governance plans for twenty dollars in
275:39 - this middle one's missing the key
275:41 - difference here is this one has Sentinel
275:42 - policies code but you can see on the
275:44 - free plan we are able to do
275:46 - team-based stuff
275:48 - let's go switch over to the trial plan
275:49 - I'm going to see if I can do this
275:51 - without entering a credit card in so
275:53 - here it says you're currently on trial
275:54 - planned I didn't have to enter anything
275:56 - in that's really great and so that means
275:58 - now I have all these Team Management
275:59 - options so if I go over to team
276:01 - management
276:02 - I can actually go ahead and create some
276:04 - teams
276:06 - uh so I'll just say like Developers
276:10 - okay
276:12 - and so now I have all these options so
276:14 - we can say this person if someone's in
276:16 - this team they're allowed to manage
276:17 - policies they're able to do that
276:19 - a visible team can be seen by every
276:22 - member or you can keep them secret we
276:24 - can generate team API tokens which I
276:27 - guess we could just like cover this as
276:28 - we do it but notice we can go here and
276:31 - that generates out that token that we
276:32 - can use I'm going to go ahead and delete
276:33 - that token
276:36 - um so nothing super exciting there you
276:38 - know it's not like that complicated
276:40 - if we want to set things on the
276:43 - workplace now if we go back to workplace
276:46 - or workspaces here
276:47 - and now we have Team access
276:50 - and notice I can go to add team uh
276:52 - permissions here
276:54 - and we can say select this team for
276:56 - their permissions
276:57 - and so these are these uh pre-built ones
276:59 - in
277:00 - um
277:01 - so we have read plan rights so these are
277:04 - those three predefined ones that we
277:06 - talked about previously and then we have
277:07 - down here like assign permissions for
277:09 - the admin of a workspace
277:11 - we are able to set customized
277:13 - permissions so if we toggle this
277:16 - um we should be able to do it I mean
277:17 - this looks like it's the same thing no I
277:19 - guess it's more granular so here I guess
277:21 - we have our granular permissions that we
277:23 - can set so for runs we can do read plan
277:25 - or reply
277:26 - Locker unlock a workspace
277:30 - send a locks things like that
277:33 - it's not super complicated
277:35 - if we want drain out API tokens for
277:38 - uh well there's the organizational one
277:41 - there's the teams one and then there's
277:42 - the user one so
277:44 - if we go to the organization
277:49 - we can see that we can generate out one
277:51 - here so I can say create an API token so
277:53 - there it is let's go ahead and delete
277:54 - that
277:55 - and if we go back to our teams
278:01 - we did this earlier but we can generate
278:03 - one here
278:06 - and then if you want to generate one for
278:07 - your users probably under user settings
278:09 - yeah so we generate tokens there as well
278:12 - okay
278:15 - so I mean again there's not a lot to
278:18 - talk about here but um yeah so I guess
278:20 - that really covers permissions and API
278:22 - tokens okay okay so that finished
278:24 - deploying there and so we can see our
278:26 - resources have been created but one
278:27 - thing that we didn't set was the prefix
278:30 - I'm actually interested to see that that
278:32 - worked properly but what I could do is
278:35 - say prefix
278:38 - and then do an underscore here and I
278:40 - don't know how that would affect it
278:47 - and this actually happened over in this
278:49 - repository here I'm actually using a
278:51 - hyphen so I'm going to just change that
278:52 - to that
279:03 - might have to do a terraform edit there
279:05 - migrate the state
279:13 - so that was a complete mistake on my
279:15 - part but I guess my thought was that I
279:17 - thought I had to have
279:19 - um this is still on Main and I guess
279:21 - we'd never really set up a production
279:22 - Branch but yeah so now when we have the
279:24 - prefix in it's actually going to prompt
279:25 - us for the other one so the currently
279:26 - selected workspaces are default does not
279:29 - exist and so Dev is showing up and
279:31 - notice that we can't deploy to main so I
279:33 - think the thing is is that if we wanted
279:35 - a production one we would just create
279:36 - that workspace and then it would reflect
279:38 - here so the way you make uh multiple
279:41 - workspaces here would actually have to
279:43 - make them all so we'd have to make a VCS
279:44 - terraform prod and I'm very certain that
279:47 - it would just show up here and then you
279:48 - would select the number that you'd want
279:50 - though what's interesting is the fact
279:52 - that we are in the dev branch and we
279:54 - have to say oh I want to deploy the dev
279:56 - one so that's kind of a little bit of a
279:59 - caveat there but I guess there's not
280:00 - really any way around it but I mean this
280:02 - pretty much
280:03 - you know explores what we need for
280:05 - multiple workspaces with terraform cloud
280:07 - and we did the remote ones and we're all
280:10 - good so there we go I guess the last
280:12 - thing here we should probably do is just
280:13 - clean up so if we go to terraform Dev
280:15 - here we're going to go down to
280:18 - destruction and we'll run a destroy plan
280:22 - here
280:25 - okay
280:28 - and once this is all done you know you
280:29 - can go ahead and just delete these
280:32 - repositories
280:34 - and notice this one is it has a private
280:36 - lock on it so oh because it's actually
280:38 - running right now so it's being locked
280:40 - so yep there we go so that's it
280:42 - [Music]
280:47 - all right now let's take a look at the
280:48 - terraform registry the private registry
280:50 - so just go over here and click on
280:52 - registry at the top and we can bring in
280:54 - public
280:55 - um
280:56 - public things here so I can just go here
280:57 - and type this in and we can hit add
281:00 - and so now
281:02 - um we just hit add to terraform cloud
281:05 - add to my organization and that's public
281:08 - facing but we could also add private
281:10 - facing modules
281:11 - so if we go back to our registry here
281:14 - just going to go ahead and uh
281:19 - down to publish here
281:21 - and we go to GitHub
281:23 - and I guess custom
281:25 - and so then I suppose we just have to
281:27 - enter all the stuff in here so as an
281:29 - optional display name for your V Version
281:31 - Control provider
281:33 - client IDs client secrets
281:38 - so it seems like there's a lot of work
281:40 - to do we'd have to set up the SSH key
281:41 - pair but I mean that's generally the
281:43 - details that you need to know for that
281:45 - okay
281:46 - just seems like a lot of work for us to
281:48 - set that up
281:49 - you know and the course is going to be
281:51 - like hey can you add a private module
281:52 - and be like yes okay
281:54 - so we'll go ahead and just remove this
281:56 - so you can add both public and private
281:58 - modules
282:00 - um you know so there you go
282:01 - [Music]
282:05 - I have mentioned terraform Enterprise so
282:07 - many times in this course but we've
282:09 - never really talked about in detail and
282:11 - now is our opportunity to do so so
282:13 - terraform Enterprise is the self-hosted
282:15 - distribution of terraform platform and I
282:17 - just want to point out sometimes I call
282:19 - the terraform platform terraform Cloud
282:21 - just because that's the more prominent
282:23 - uh version of it but terraform cloud is
282:25 - a separate product from terraform
282:28 - Enterprise it's just one is uh assassin
282:31 - the other one is self-hosted so
282:33 - terraform Enterprise offers a private
282:35 - instance of the terraform platform
282:36 - application with the benefits such as no
282:38 - resource limits with additional
282:40 - enterprise-grade architectural features
282:42 - such as audit logging so you do you'd
282:44 - have tamper evidence saml single sign-on
282:46 - and I'm sure there's a lot more other
282:48 - options there so let's just kind of look
282:50 - at the architecture really quickly on
282:52 - how this works so the first thing is you
282:53 - have the terraform platform which is
282:55 - going to be installed on a machine and
282:57 - in particular this is installed on Linux
282:59 - and it's specifically installed on
283:02 - Debian okay so I believe that is the
283:04 - Debian logo as far as as I remember if
283:06 - it's not we'll find it on the next slide
283:08 - if I'm wrong okay you're going to have
283:10 - to have some kind of storage and there's
283:12 - a few different options probably the
283:14 - most common is going to be on something
283:16 - like S3 but you can store it on the
283:19 - storage or on the disk itself you have
283:22 - to have a postgres database so that's
283:24 - part of the infrastructure because that
283:26 - is what the platform uses and you'll
283:29 - also have to have your own TLS
283:31 - certificate to access the machine
283:34 - but there are also cases where you know
283:36 - these are going through air gapped
283:37 - environments but the idea is that you
283:38 - have SSL or TLS it's like end-to-end
283:41 - encryption it goes all the way to the
283:42 - machine that's where it terminates okay
283:44 - you'll also need your terraform license
283:46 - so you'll have to plug that in once you
283:48 - start up the terraform platform say hey
283:50 - tell us the code so you can unlock this
283:53 - um this software for you to use on this
283:55 - dedicated machine okay
283:58 - foreign
284:00 - [Music]
284:02 - so the requirements for terraform
284:03 - Enterprises is going to highly vary
284:05 - based on your operational mode that you
284:07 - choose to run it in and that is really
284:08 - dependent on how data should be stored
284:10 - and when we're looking at the uh the
284:13 - architectural diagram that was uh the
284:15 - operational mode of external Services
284:17 - there's three types of operational nodes
284:19 - the first being external Services that's
284:21 - when you use postgres and then use cloud
284:24 - storage so in that example we're using
284:26 - S3 but you can use gcp Azure blob
284:28 - storage or Mino object storage but the
284:31 - idea is that postgres and the cloud
284:33 - storage are external they're not part of
284:34 - that Linux server okay then you have a
284:37 - mounted disk so this would just be
284:39 - having a a persisted disk attached to
284:42 - the VM so you know in the best case it's
284:46 - called EBS so this stores data in a
284:48 - separate directory on the host intended
284:50 - for external disk so that would be both
284:52 - the postgres database and the storage
284:53 - volume itself you know postgres is still
284:56 - a requirement and no matter what mode
284:58 - you use then you have demo so stores all
285:00 - data on the instance data can be backed
285:03 - up with snapshots not recommended for
285:04 - production use so this is where you have
285:07 - ethereal data so you know the data you
285:09 - know can vanish if you restart the
285:11 - machine unless you make physical
285:12 - snapshots
285:14 - another component is credentials ensure
285:16 - you have credentials to use Enterprise
285:18 - and have a secure connection so the
285:21 - first is we need the terraform
285:22 - Enterprise license so you obtain that
285:23 - from hashicorp and the other part is
285:25 - having a TLS certificate and private key
285:27 - so you need to prove uh you're the uh
285:30 - you own uh your own TLS certificate okay
285:34 - then we have the Linux instance so
285:35 - terraform Enterprises designed to run on
285:38 - Linux and it supports more than one
285:40 - version so you know I said it was only
285:42 - Debian but I guess there's a bunch I
285:44 - just forgot so we have Debian Ubuntu Red
285:46 - Hat Centos Amazon Linux there's a
285:50 - variety for those Oracle Linux so yeah I
285:54 - guess I just a big fan of Debian so
285:55 - that's I guess that was my my thinking
285:57 - there for Hardware requirements we have
285:59 - at least 10 gigabytes of disk space on
286:01 - the root volume at least 40 gigabytes of
286:04 - disk space for the docker data directory
286:06 - so that would be the VAR lib Docker at
286:09 - least eight gigabytes of the system
286:11 - memory and at least four CPU cores so
286:15 - there you go
286:17 - foreign
286:21 - let's talk about error gapped
286:23 - environments so what is an air gap an
286:24 - air gap or disconnected network is a
286:26 - network security measure employed on one
286:29 - or more computers to ensure that a
286:30 - secure computer network is physically
286:32 - isolated from unsecure networks so the
286:34 - public internet so it's no internet no
286:37 - outside connectivity Industries in the
286:39 - public sector so government military or
286:41 - large Enterprises finance and energy
286:43 - often employ air gap networks and so I
286:45 - want you to know that hashicorp
286:47 - terraform Enterprise supports an
286:48 - installation type of air gap
286:50 - environments okay so to install or
286:52 - update terraform Enterprise you will
286:54 - supply an air gap bundle which is an
286:56 - archive of a terraform Enterprise
286:57 - release version so that's how you would
287:00 - um you know provided okay
287:01 - [Music]
287:06 - so let's take a look at terraform Cloud
287:07 - features and pricing so I just want to
287:10 - quickly go through it here so we have
287:12 - three models we have the open source
287:14 - software so OSS we have the cloud
287:17 - offerings and the self-hosted offerings
287:18 - I know these tiers we have free teams
287:21 - and governance technically it's teams
287:24 - and then teams and governance so they're
287:27 - two separate plans but this is the way
287:29 - they display it in their marketing
287:30 - content but it really is a separate two
287:32 - separate tiers in there you have
287:34 - business and then Enterprise which is
287:35 - considered self-hosted so in terms of
287:37 - feature set
287:38 - across the board you have IAC
287:41 - workspaces variables runs resource
287:45 - graphs providers modules the public
287:47 - module registry which is terraform
287:48 - registry workspace is a bit odd because
287:51 - there are terraform Cloud workspaces
287:53 - right
287:54 - and then you have local workspaces so
287:57 - technically those should be broken up
287:58 - into two separate things or named
288:01 - differently but that's just how it is
288:03 - with terraform so you know just asterisk
288:05 - on that workspaces there for the free
288:07 - tier you get remote state or sorry for
288:10 - everything outside of the open source
288:12 - you get remote State vs VSC connection
288:14 - so that's Version Control State
288:16 - connection so connecting to GitHub or or
288:19 - git lab or whatever workspace management
288:21 - secure variable storage remote runs
288:24 - private module registry once we get into
288:27 - Cloud we get Team Management Sentinel
288:29 - policy as code management cost
288:30 - estimation the reason why I have that in
288:32 - Red is because on the exam it could ask
288:34 - you when is Sentinel policy available is
288:37 - it available at what level and the thing
288:39 - is it goes from teams and governments
288:42 - all the way to the Enterprise level now
288:44 - technically there is again one called
288:47 - teams and there's teams and governance
288:49 - so it's part of teams and governance not
288:50 - part of teams okay
288:53 - uh once we get into business this is
288:55 - where we start to get single sign-on and
288:56 - audit logging so you know if you need it
288:59 - in the cloud or if you need it
289:00 - self-hosted both options are available
289:03 - in the business we have the you can have
289:06 - the self-hosted agents for configuration
289:09 - designer servicenow integration you have
289:11 - it for those uh as well in terms of how
289:15 - many runs you can have this is very
289:17 - important because this is how many this
289:19 - is going to put a bottleneck in terms of
289:20 - your infrastructure rights on the free
289:22 - Terry you can have one current run of a
289:25 - workspace and teams you could have two
289:28 - and then at the business level and
289:29 - Beyond its unlimited current runs for uh
289:33 - how you would actually interact with um
289:36 - terraform you know this is going to be
289:37 - through the local CLI for the open
289:39 - source software for these it's Cloud
289:42 - meaning that
289:43 - um it's Cloud that is triggering the
289:46 - execution commands and then self-hosted
289:48 - it's not in the cloud it's on that
289:49 - private machine okay
289:51 - uh then we have support So for support
289:54 - it's all community so that's just going
289:57 - reaching out to DA's maybe there's a
289:59 - slack Channel I believe that they have a
290:02 - form so they have like a form where you
290:04 - can ask questions and then they have
290:06 - these layers like bronze silver and gold
290:08 - I could not determine what these are
290:11 - like what is offered in them and the odd
290:14 - thing is is that you know there's a
290:16 - silver and gold but it's offered both at
290:17 - business and Enterprise so I don't know
290:19 - if like you can upgrade to from silver
290:21 - to gold so it's optional or you always
290:23 - get silver and gold could not get
290:25 - clarification I tried asking the sales
290:26 - team no one would tell me so I think you
290:28 - have to really be deep in that sales
290:30 - funnel to find out in terms of pricing
290:33 - it's zero to up to five users so the
290:36 - thing is and this is really confusing
290:38 - about terraform cloud and they really
290:40 - shouldn't have called it teams up here
290:42 - but you can start using terraform Cloud
290:44 - for free up to five users as a team okay
290:48 - so just negate the fact that it's not
290:50 - called teams what they're saying is that
290:52 - teams is really about getting a
290:56 - base workspace Remote Manager which is
290:58 - actually our RBA like
291:01 - our ABC controls
291:03 - uh role-based access controls so that's
291:06 - the whole point of using teams so if you
291:08 - need that and that's when you're at five
291:09 - that's going to use it but you can use
291:11 - it in the free tier as a team and you it
291:13 - absolutely should once you get to the
291:16 - teams plan it's going to be twenty
291:17 - dollars a month and then if you need
291:19 - teams and governance it's actually like
291:21 - seven dollars a month so again it's kind
291:23 - of like a bit misleading how they've
291:25 - labeled this out but if you go and open
291:27 - up teams Cloud you can see what the
291:29 - actual packages are
291:31 - for uh business that self-hosted your
291:34 - contact and sales so I have no idea what
291:36 - the cost is there so there you go
291:38 - [Music]
291:42 - all right we're taking a look here at
291:43 - workspaces so workspaces allow you to
291:45 - manage multiple environments or
291:47 - alternate State files such as
291:48 - development reproduction and there are
291:50 - two variants of the workspace we have
291:52 - CLI workspaces a way of managing
291:54 - alternate State files locally or via
291:56 - remote back-ends and then we have
291:58 - terraform Cloud workspaces that act like
292:01 - completely separate working directories
292:02 - I'm going to tell you these two are
292:04 - confusing because they don't exactly
292:06 - work the same way but they have the same
292:08 - name and originally workspaces were
292:10 - called environments and so you know when
292:12 - you're using terraform Cloud it makes a
292:13 - lot of sense to call them environments
292:14 - and the CLI workspace it's just a little
292:17 - bit different so you know I'm not sure
292:19 - if I'm going to do a great job
292:20 - explaining the difference of these
292:21 - things you really have to go through the
292:22 - motion of it to really get the hang of
292:24 - it but I'll do the best I can here okay
292:26 - so think of workspaces as being similar
292:29 - to having different branches in a git
292:30 - repo workspaces are technically the
292:32 - equivalent to renaming your state file
292:35 - okay so in terraform 0.9 they used to be
292:38 - workspaces used to be called
292:39 - environments but people got confused
292:41 - which I have no video why but you know
292:44 - that's what it is now so by default you
292:47 - already have a single workspace in your
292:48 - local backend called default and the
292:51 - default workspace can never be deleted
292:53 - so even if you don't think you're using
292:55 - workspaces you absolutely are even the
292:57 - first time you use terraform at least in
292:59 - the CLI workspace okay
293:01 - [Music]
293:05 - let's get a little bit into the
293:07 - internals this isn't really that much
293:08 - detail but depending if you are on a
293:11 - local or remote back end changes how the
293:13 - state file is stored so if you're on a
293:15 - local state or a remote State it's going
293:17 - to be different so uh terraform stores
293:19 - the the workspace States in a folder
293:21 - called
293:23 - terraform.tfstate.d on the road State
293:25 - the workspace file are stored directly
293:28 - in the configured backend in practice
293:31 - individuals or very small teams will
293:33 - have been have known to commit these
293:35 - files to the repos but using a remote
293:37 - backend instead is recommended when
293:39 - there are multiple collaborators so I
293:41 - guess there's not really much to say
293:42 - here but just understand that when you
293:45 - have a local state file it's going to be
293:46 - in that terraform TF State D and then
293:48 - when it's remote State you don't have to
293:50 - worry about it okay
293:51 - [Music]
293:55 - let's talk about interpolation with
293:58 - current workspaces so you can reference
294:00 - the current workspace name via the
294:02 - terraform.workspace named value so we
294:05 - saw that in the lineup way earlier in
294:07 - the course so the idea here is that if
294:09 - you wanted to
294:11 - um see if the default like let's say you
294:14 - want to say am I in the default
294:15 - workspace then return five as opposed to
294:17 - one because maybe you're very
294:20 - comfortable spinning up more in the
294:21 - default than whether it was something
294:23 - else and just another example maybe you
294:26 - want to use it to apply the name of the
294:29 - workspace as a tag so here that would
294:31 - actually give this virtual machine in
294:33 - AWS the name web hyphen whatever it is
294:35 - production or development so there you
294:37 - go
294:39 - foreign
294:42 - let's talk about multiple workspaces so
294:45 - a terraform configuration has a back end
294:47 - that defines how operations are executed
294:49 - and where persistent data is stored so
294:51 - like the terraform state so multiple
294:53 - workspaces are currently supported by
294:55 - the following backends Azure RM console
294:59 - cos GCS so that's Google Cloud Storage
295:02 - kubernetes local Manta postgres remote
295:06 - S3 they're not going to ask you this on
295:08 - the exam which ones are supported but
295:10 - you know for your own purposes if you
295:12 - want to use multiple workspaces with a a
295:15 - standard back end you probably want to
295:16 - know which ones certain back ends
295:18 - support multiple name workspaces
295:20 - allowing multiple states to be
295:21 - associated with a single configuration
295:24 - that the configuration still has only
295:27 - one back end but multiple distinct
295:29 - instances of the configuration to be
295:30 - deployed without configuring a new back
295:32 - end or changing authentication
295:34 - credentials why would you want to use
295:35 - multiple workspaces for something like a
295:38 - standard
295:39 - um
295:40 - a standard back end well the idea here
295:43 - is that you know if let's say you're
295:44 - using terraform cloud and you've reached
295:47 - your limit of five users and it just
295:49 - gets too expensive to go to the sex user
295:51 - where you have to pay for all of them uh
295:54 - you know then the thing is is that you
295:55 - know this is an option for you it's just
295:57 - kind of like another option out there
295:58 - until you are ready to pay for terraform
296:00 - Cloud at the next tier up so that's the
296:02 - reason why I'm mentioning it here for
296:04 - you okay
296:05 - [Music]
296:09 - all right let's quickly walk through the
296:11 - terraform Cloud workspace and the
296:12 - easiest ways to just show you a
296:13 - screenshots so you create a workspace on
296:16 - terraform Cloud so first you'll create
296:17 - an organization mine's called exam Pro
296:19 - and within that you'll create multiple
296:21 - workspaces from there you'll click into
296:23 - your workspace and you'll see uh like
296:26 - previous run States variable settings
296:27 - we'll click into runs from runs what
296:30 - we'll get is a list of what happened
296:32 - previously we can click into one of
296:34 - those and we can see our plan and our
296:37 - apply we can leave a comment on each run
296:40 - that has happened if we if we just want
296:42 - to expand the plan and apply here for
296:44 - plan we will see all the details of what
296:47 - it would change and then apply is it
296:49 - actually setting up that infrastructure
296:51 - and whether it was successful or not
296:53 - notice you can also download Sentinel
296:56 - unlock files we'll come and talk about
296:57 - that later when we get to our Central
296:59 - section we can also see a history of
297:01 - previously held States so these are
297:04 - snapshots of that infrastructure
297:07 - and so you can click into there and
297:08 - exactly see what it looks like this is
297:10 - useful if you want to go and download it
297:12 - if you were to need it so here's a diff
297:16 - of what changed since the last state
297:17 - okay and of course you can download that
297:20 - stuff so you know hopefully that gives
297:21 - you an idea of what you can do with
297:22 - terraform cloud workspaces
297:24 - foreign
297:28 - [Music]
297:29 - let's talk about terraform Cloud run
297:31 - triggers so terraform Cloud provides a
297:34 - way to connect your workspaces to one or
297:36 - more workspaces via run triggers within
297:38 - your organization known as source
297:41 - workspaces so run triggers allows runs
297:44 - to queue automatically in your workspace
297:47 - on successful apply of runs in any of
297:50 - your source workspaces and you can
297:51 - connect each workspace to up to 20
297:54 - source workspaces so run triggers are
297:56 - designed for workspaces that rely on
297:58 - information or infrastructure produced
298:00 - by other workspaces if a terraform
298:02 - configuration uses data sources to read
298:04 - values that might be changed by another
298:06 - workspace run triggers lets you
298:08 - explicitly specify the external
298:10 - dependencies so the idea is just allow
298:12 - you to say okay I have one workspace I
298:15 - I've triggered that I wanted now to do
298:17 - that so this is really great if you have
298:18 - a bunch of uh of environments or or
298:22 - Stacks that are reliant on each other
298:24 - and you want it to kind of have a chain
298:26 - reaction the reason I'm mentioning run
298:28 - triggers is a I think it's a cool
298:30 - feature and B Because triggers is
298:33 - something that is also uh something else
298:36 - when we're looking at provisioners and I
298:38 - just wanted to just clarify that there's
298:40 - run triggers from terraform cloud and
298:42 - then there's triggers that are for
298:44 - um well I said provisioners I really
298:46 - mean null resources they have triggers
298:48 - in that okay so it's not going to show
298:50 - up an example it's just a good to know
298:52 - feature I just want to make sure there's
298:53 - no confusion with the other triggers
298:55 - [Music]
298:59 - let's take a look at some of the
299:01 - terraform workspace CLI commands that we
299:03 - have available to us the first starting
299:04 - with terraform workspace list so list
299:06 - all the existing workspaces and the
299:08 - current workspace is indicated by an
299:10 - asterisk so that is our current
299:12 - workspace there terraform workspace show
299:14 - show the current workspace so right now
299:16 - we're working in development terraform
299:18 - workspace select switch to a Target
299:20 - workspace so here we could say select
299:22 - default and now we're in the default
299:24 - terraform workspace new so create and
299:26 - switch to a new workspace and then we
299:28 - have terraform workspace delete so
299:30 - delete a Target workspace now
299:32 - understand that this is affecting your
299:35 - local ones for the CLI commands Okay but
299:39 - um yeah so this would actually show up
299:41 - in the exam they might ask you like you
299:43 - know which is Select and what does list
299:46 - do and things like that so make sure you
299:48 - know these commands Okay
299:49 - [Music]
299:54 - all right so I just wanted to contrast
299:55 - against the local or CLI driven
299:58 - workflows via the terraform Cloud
300:00 - workflows because there's this great uh
300:02 - table chart that's from the
300:04 - documentation that I want to show you so
300:06 - to our firm cloud workspaces and local
300:08 - working directories serve the same
300:09 - purposes but they store their data
300:12 - differently so just looking here we'll
300:15 - go down to components here so for
300:16 - terraform configuration it's going to be
300:18 - on disk for local for terraform cloud in
300:20 - linked Version Control repositories or
300:22 - periodically uploaded via the API or CLI
300:26 - we have variable values so this is where
300:29 - we use tfrs and when we're in terraform
300:31 - Cloud it's in the actual workspace the
300:33 - terraform Cloud workspace and so that
300:35 - means that we are setting environment
300:36 - variables to propagate that into our
300:38 - code or inject those variables into our
300:40 - code on execution for State it's on disk
300:43 - or in a remote back end and in the
300:46 - workspace for terraform Cloud it's
300:48 - actually in the workspace credentials
300:50 - and secrets are in Shell environments or
300:51 - our internet prompts and workspace
300:53 - they're stored ascent the variables
300:54 - these are environment variables again so
300:56 - there you go
300:57 - [Music]
301:02 - hey this is Andrew Brown from exam Pro
301:03 - and we are on to our terraform Cloud uh
301:05 - follow alongs now we already did
301:06 - terraform Cloud uh Version Control
301:08 - System earlier than I thought we were
301:10 - going to do so I'm going to remove from
301:11 - the list and what we'll do is focus on
301:13 - permissions and maybe the API tokens and
301:15 - things like that so what I want you to
301:17 - do and I've got some old tabs open here
301:18 - I'm going to make my way over to uh
301:21 - terraform.io
301:23 - and I'm going to go log into terraform
301:25 - Cloud here
301:26 - and I don't think I've ever done this
301:28 - but I can upgrade to the trial account
301:30 - because the thing is is that when we are
301:31 - in our account here and we're trying to
301:33 - look at permissions and we're not using
301:36 - Force unlocking anymore I might just
301:38 - keep that around for a little bit but if
301:39 - we were to go to our user settings here
301:42 - we go to organizations
301:46 - um that might not be a very good example
301:49 - I guess I wanted like the organization
301:50 - settings here
301:53 - which would be
301:56 - maybe here yep up here and so you know
301:59 - when we go to our teams and our users
302:01 - our users everyone's being added as an
302:03 - owner we don't have like granular
302:04 - permissions and that's because we'd have
302:06 - to upgrade and so I figured this would
302:09 - be a good opportunity for me to just
302:10 - kind of upgrade to show you those uh
302:12 - more detailed uh role-based Access
302:13 - Control permissions just so you know
302:16 - where they are so I'm gonna go the
302:17 - upgrade now and notice that we're on the
302:19 - free plan and also take note because
302:21 - later on the course I talk about pricing
302:24 - or we've already already acrossed it but
302:26 - notice that we have a team plan and a
302:27 - team and governance plan this one's at
302:29 - 20 and this one's at seventy dollars so
302:32 - you know this is not something that's
302:33 - reflected at least not right now on the
302:35 - terraform website and so it just looks
302:38 - like there's a team in governance plans
302:39 - for twenty dollars in this middle one's
302:40 - missing the key difference here is this
302:43 - one has Sentinel policies code but you
302:44 - can see on the free plan we are able to
302:46 - do
302:47 - team-based stuff
302:48 - let's go switch over to the trial plan
302:50 - I'm going to see if I can do this
302:52 - without entering a credit card in so
302:54 - here it says you're currently on trial
302:55 - planned I didn't have to enter anything
302:57 - in that's really great and so that means
302:59 - now I have all these Team Management
303:00 - options so if I go over to team
303:02 - management
303:04 - um I can actually go ahead and create
303:05 - some teams
303:07 - uh so I'll just say like Developers
303:11 - okay
303:13 - and so now I have all these options so
303:15 - we can say this person if someone's in
303:17 - this team they're allowed to manage
303:18 - policies they're able to do that
303:20 - a visible team can be seen by every
303:23 - member or you can keep them secret we
303:25 - can generate team API tokens which I
303:28 - guess we could just like cover this as
303:30 - we do it but notice we can go here and
303:32 - that generates out that token that we
303:33 - can use I'm going to go ahead and delete
303:34 - that token
303:37 - um so nothing super exciting there you
303:39 - know it's not like that complicated
303:41 - if we want to set things on the
303:44 - workplace now if we go back to workplace
303:47 - or workspaces here
303:49 - and now we have Team access
303:51 - and notice I can go to add team
303:53 - permissions here
303:55 - and we can say select this team for
303:57 - their permissions and so these are these
303:59 - uh pre-built ones in
304:01 - um
304:02 - so we have read plan rights so these are
304:05 - those three predefined ones that we
304:07 - talked about previously and then we have
304:09 - down here like assign permissions for
304:10 - the admin of a workspace
304:12 - we are able to set customized
304:14 - permissions so if we toggle this
304:17 - um we should be able to do it I mean
304:18 - this looks like it's the same thing no I
304:21 - guess it's more granular so here I guess
304:22 - we have our granular permissions that we
304:24 - can set so for runs we can do read plan
304:26 - or reply
304:27 - Locker unlock a workspace
304:31 - send a locks things like that
304:34 - it's not super complicated
304:36 - if you want to drain out API tokens for
304:39 - uh well there's the organizational one
304:42 - there's the teams one and then there's
304:43 - the user one so
304:45 - if we go to the organization
304:50 - we can see that we can generate out one
304:52 - here so I can say create an API token so
304:54 - there it is just go ahead and delete
304:55 - that
304:56 - and if we go back to our teams
305:02 - we did this earlier but we can generate
305:04 - one here
305:07 - and then if you want to generate one for
305:08 - your user it's probably under user
305:09 - settings
305:11 - yeah so we generate tokens there as well
305:13 - okay
305:16 - so I mean again there's not a lot to
305:19 - talk about here but um yeah so I guess
305:21 - that really covers permissions and API
305:23 - tokens okay okay so that finished
305:25 - deploying there and so we can see our
305:27 - resources have been created but one
305:28 - thing that we didn't set was the prefix
305:31 - I'm actually interested to see that that
305:33 - worked properly but what I could do is
305:36 - say prefix
305:39 - and then do an underscore here and I
305:41 - don't know how that would affect it
305:48 - and this actually happened over in this
305:50 - repository here I'm actually using a
305:52 - hyphen so I'm going to just change that
305:53 - to that
306:04 - might have to do a terraform edit there
306:06 - migrate the state
306:14 - so that was a complete mistake on my
306:16 - part but I guess my thought was that I
306:18 - thought I had to have
306:20 - um this is still on Main and I guess
306:22 - we'd never really set up a production
306:23 - Branch but yeah so now when we have the
306:25 - prefix in it's actually going to prompt
306:26 - us for the other one so the currently
306:27 - selected workspaces are default does not
306:30 - exist and so Dev is showing up and
306:32 - notice that we can't deploy to main so I
306:34 - think the thing is is that if we wanted
306:36 - a production one we would just create
306:37 - that workspace and then it would reflect
306:39 - here so the way you make uh multiple
306:42 - workspaces here would actually have to
306:44 - make them all so we'd have to make a VCS
306:46 - terraform prod and I'm very certain that
306:48 - it would just show up here and then you
306:49 - would select the number that you'd want
306:51 - though what's interesting is the fact
306:53 - that we are in the dev branch and we
306:55 - have to say oh I want to deploy the dev
306:57 - one so that's kind of a little bit of a
307:00 - caveat there but I guess there's not
307:01 - really any way around it but I mean
307:03 - that's pretty much you know explores
307:05 - what we need for multiple workspaces
307:08 - with terraform cloud and we did the
307:09 - remote ones and we're all good so there
307:12 - we go I guess the last thing here we
307:13 - should probably do is just clean up so
307:15 - if we go to terraform Dev here uh we're
307:18 - going to go down to destruction and
307:21 - we'll run a destroy plan here
307:26 - okay
307:29 - and once this is all done you know you
307:31 - can go ahead and just delete these
307:33 - repositories
307:35 - and notice this one is it has a private
307:37 - lock on it so oh because it's actually
307:39 - running right now so it's being locked
307:41 - so yep there we go so that's it
307:43 - [Music]
307:48 - hey this is Andrew Brown from exam Pro
307:50 - and we are taking a look at Sentinel
307:51 - which is an embedded policies code
307:53 - framework integrated within the
307:54 - terraform platform so what is policies
307:57 - code when you write code to automate
308:00 - regulatory or governance policies and
308:03 - features of Sentinels include uh it that
308:05 - it's embedded so enable policy
308:07 - enforcement in the data path to actively
308:09 - reject violating Behavior instead of
308:12 - passively detecting so it's very active
308:15 - or proactive fine-grained condition
308:17 - based policies so make policy decisions
308:20 - based on the condition of other values
308:22 - multiple enforcement levels so advisory
308:24 - soft and hard mandatory levels allow
308:26 - policy writers to warn on or inject
308:29 - reject Behavior we have external
308:31 - information so Source external
308:33 - information to make holistic policy
308:35 - decisions we have multi-cloud compatible
308:38 - compatible so ensure infrastructure
308:40 - changes are within business and
308:42 - Regulatory policy across multiple
308:44 - providers and Sentinel is a paid service
308:46 - part of the team and governance upgrade
308:47 - package so Syrian team in governance
308:50 - it's available for that
308:51 - business and Enterprise okay
308:54 - [Music]
308:58 - let us expand a bit on the concept of
309:00 - policies code and relating to Sentinel
309:03 - so Sentinel is built around the idea and
309:04 - provides all the benefits of policy of
309:06 - code let's talk about the benefits we
309:08 - get with this so sandboxing the ability
309:10 - to create guardrails to avoid dangerous
309:12 - actions or remove the need of manual
309:14 - verification codification the policies
309:16 - are well documented exactly represent
309:17 - what is enforced Version Control easy to
309:20 - modify or iterate on policies with a
309:22 - chain of history of changes over time
309:24 - testing so syntax and behavior can
309:27 - easily be validated with Sentinel
309:28 - ensuring policies are configured as
309:30 - expected automation so policies existing
309:33 - as code allows you to allows you to
309:35 - direct integrate policies in various
309:37 - systems to Auto remediate and notify
309:40 - we're talking about senatal and policies
309:42 - code we have language so all Sentinel
309:45 - policies are written using the sender
309:47 - language this is designed to be
309:49 - non-programmer and programmer friendly
309:50 - and embeddable and safe for development
309:52 - Central provides a CLI for development
309:54 - and testing and for testing Central
309:56 - provides a test framework designed
309:58 - specifically for for automation so
310:00 - hopefully that gives you an idea of the
310:02 - benefits of policy code and in
310:03 - particular with Sentinel
310:04 - [Music]
310:08 - all right let's take a look at the
310:10 - Sentinel language and also just a broad
310:13 - uh range of of use cases that we could
310:16 - use these for so you can start thinking
310:17 - about how to start applying Sentinel the
310:19 - great thing is that there are a bunch of
310:21 - example policies provided by hashicorp
310:23 - so you can easily
310:25 - um you know start using them right away
310:26 - but let's go through the big list to
310:28 - kind of give you an idea where you would
310:29 - use policies code so for AWS maybe you'd
310:32 - want to restrict the owners of the AWS
310:34 - Ami to a data of the data source maybe
310:36 - you want to enforce mandatory tags on
310:38 - taggable AWS resources restrict
310:40 - availability zones used by ec2 instances
310:42 - disallow a
310:45 - 0.0.0.04.0 basically anywhere address
310:48 - out to the internet restrict instance
310:50 - types of ec2 so maybe you only want
310:52 - people using T2 micros require S3
310:54 - buckets to be private encrypted by KMS
310:56 - since that is a big
310:57 - um a big problem for people on AWS where
311:00 - their buckets get leaked require vpcs to
311:04 - have DNS host names enabled we're
311:06 - looking at gcp enforced mandatory labels
311:07 - on VMS disallow allow anywhere cider and
311:11 - force limits on gke clusters because
311:13 - those can get really expensive restrict
311:15 - machine types of VMS just like AWS for
311:17 - VMware required storage DRS on datastore
311:21 - clusters restrict size and type of
311:22 - virtual disks restrict CPU count memory
311:25 - of VMS restrict size of VM disks record
311:28 - NFS 4.1 and cure Burrows I never can say
311:32 - that properly on NAS data stores for
311:34 - Azure enforced mandatory tags of VMS
311:36 - restrict Publishers of VMS restrict VM
311:39 - images restrict the size of azure VMS
311:41 - enforce limits on AKs clusters restricts
311:44 - cider blocks of security groups for
311:46 - cloud agnostic allowed only say we can
311:50 - only use these allowed providers say or
311:53 - explicitly say what providers are not
311:55 - allowed limit proposed monthly costs
311:58 - prevent providers in non-root modules
312:00 - require all modules have version
312:02 - constraints require all resources be
312:04 - created in modules and private module
312:06 - registry use most recent versions of
312:09 - modules in a private module registry
312:11 - that's more so like about the tooling
312:13 - around modules
312:14 - now let's take a look at an example and
312:16 - this is one for restricting uh available
312:19 - zones on ec2 instances so like what data
312:21 - centers you're allowed to use and so we
312:24 - first import our language functions
312:25 - that's going to allow us to use
312:27 - particular uh feature functions in this
312:29 - we're going to specify our azs we're
312:32 - going to get all the virtual machines
312:34 - we're going to filter that and restrict
312:36 - the AZ for those VMS we're going to
312:39 - Define that rule to make it enforceable
312:40 - so there you go
312:43 - thank you
312:45 - [Music]
312:46 - all right let's take a look here with
312:48 - Sentinel with terraform so Central can
312:50 - be integrated with terraform via
312:51 - terraform Cloud as part of your IEC
312:52 - provision Pipeline and where it's going
312:54 - to sit is between plan and apply okay
312:59 - so the way you do it is you're going to
313:00 - have to create a policy set and apply
313:02 - these to the terraform workspace so it's
313:04 - not that complicated to get it hooked up
313:06 - so yeah that's all there is to it okay
313:09 - [Music]
313:13 - hey this is Andrew Brown from exam Pro
313:15 - and we're going to learn a bit about
313:17 - Sentinel with terraform I'm not going to
313:19 - say I'm amazing at it but we are going
313:20 - to stumble our way through and see what
313:21 - we can accomplish we know we can
313:23 - download Sentinel box and there's also
313:25 - the ability to set policy sets and I do
313:27 - know that there are a bunch of pre-made
313:29 - Sentinel policies so we go send no
313:32 - policies here terraform
313:35 - uh and we go examples uh there we are
313:39 - probably here
313:40 - there are a bunch of ones that we can go
313:42 - in here so I'm thinking that there's
313:43 - something that we can do here
313:46 - um but we'll have to figure our way
313:47 - through here because I actually haven't
313:48 - ran any um policies myself so we have
313:51 - these two environments I'm not using Dev
313:53 - anymore I'm done with this I'm going to
313:54 - go ahead and destroy that and we're
313:56 - going to go down to terraform destroy
313:58 - I'm pretty sure I don't have any running
314:00 - infrastructure actually I'm going to
314:01 - double check by going to the overview
314:02 - everything has been destroyed and so
314:05 - I'll go back over here and we're going
314:06 - to destroy this I'm going to type in VCS
314:09 - terraform Dev
314:14 - great if we go into this workplace or
314:17 - workspace nothing is provisioned right
314:19 - now so I want to get everything running
314:22 - again because last time we ran a destroy
314:26 - so I think that if we want to get this
314:28 - working it should be pretty easy I'm
314:30 - going to go back to
314:31 - our
314:32 - workflows file here
314:35 - and we're just going to revert some
314:36 - changes so I'm going to go back and
314:38 - change this to name
314:42 - and I'm just going to go whoops we're
314:44 - going to go into our 120 directory here
314:46 - and we're going to check out Main and
314:48 - that actually might just revert those
314:49 - changes there I don't think anything
314:50 - really changed much other than this part
314:52 - here
314:54 - and so what I'm going to do is just go
314:57 - Um
314:58 - make a minor change it doesn't matter
315:00 - what it is maybe a space
315:03 - get add all whoops
315:06 - git commit hyphen m
315:09 - changes
315:11 - get push
315:14 - I'll have to do a good pull here
315:18 - get push
315:21 - sorry get push
315:24 - and so what I want to see here is a
315:26 - trigger for the Run
315:30 - there we go and I'll see you here in a
315:31 - bit when it's provisioned okay all right
315:33 - so after a short little weight there it
315:34 - looks like our branches Ran So I think
315:37 - our resources are provisioned it's cool
315:40 - we actually have cost estimation I
315:42 - didn't have to do anything to turn that
315:43 - on we already have it notice that it's
315:45 - giving us an hourly of Zero 12 cents the
315:48 - monthly is going to be eight dollars in
315:50 - you know 35 cents there if there was
315:52 - more resources there we would obviously
315:54 - get that I assume that it would show up
315:55 - here in the top right corner so
315:59 - we're not really interested in the
316:00 - provision infrastructure but more so
316:02 - looking at these Sentinel locks so I'm
316:05 - going to go ahead and download them
316:06 - there and that's going to download as a
316:09 - um a zip
316:10 - or an archive of some sorts and so what
316:13 - I can do here
316:15 - is just unzip it so I'm just going to
316:17 - make a new folder
316:19 - here and we'll just call these um
316:23 - Sentinel marks
316:27 - okay I'm just going to open up the zip
316:29 - and so here's all the stuff in here so
316:31 - we have a variety of different files I
316:33 - think some of them might be redundant
316:34 - I'm not sure what we have to do with
316:36 - them but I'm just going to go ahead and
316:37 - grab these and drag them into the folder
316:39 - here
316:41 - okay and actually what I'm going to do
316:43 - is
316:45 - um I'm going to just make a new section
316:47 - in my folder here whoops
316:51 - just give me a second here
316:54 - we'll just open up the Explorer to
316:56 - anything
316:57 - yeah we have a folder right here
317:04 - because what I want to do is just drop
317:06 - those files in so we can just see them
317:07 - in vs code the contents of them
317:15 - there we go
317:16 - and so now I'm just going to go down to
317:18 - here
317:19 - and we'll take a look so we have
317:20 - Sentinel HCL
317:24 - all right and so that's just defining a
317:26 - bunch of mocks
317:28 - we have this Central File here
317:35 - so I was hoping when we open this it
317:36 - would be able to figure out what to do
317:38 - with this and I have no idea so you know
317:39 - what what I'm going to do is I'm just
317:41 - going to do a little bit of reading and
317:42 - I'm going to come back to you after I
317:44 - finish reading this okay all right so
317:46 - spending a little bit of time uh
317:48 - watching some stuff so I was just going
317:49 - through the Deep dive of Sentinel here
317:51 - uh and just going through the
317:52 - documentation and as far as I understand
317:54 - it looks like that you write policies
317:56 - and then you can also write tests for
317:58 - your policies to assert that your
317:59 - policies are doing what you expect them
318:01 - to do and I guess those uh Sentinel
318:04 - locks are written in a form of HCL but
318:07 - it is a little bit confusing because you
318:08 - get this folder with a bunch of stuff in
318:10 - it and it can be either written as Json
318:12 - or like this htl like format but as far
318:16 - as I can tell it's just saying what it's
318:18 - done is it's generated out these the
318:20 - current state of exactly what your
318:22 - infrastructure is and I think that it's
318:24 - going to check to see is it exactly what
318:26 - you expect it to be so I don't know if
318:29 - MOX is that very useful and might be a
318:31 - little bit too much for this particular
318:33 - course so I'm just going to say okay
318:35 - let's just kind of ignore locks because
318:38 - they're just a little bit too too
318:40 - difficult and out of scope here let's
318:42 - follow focus on trying to get a policy
318:45 - implemented so I'm going to go back over
318:47 - here and what I'm going to do is I know
318:49 - that if I go to settings
318:53 - I mean I've seen it before I just can't
318:55 - remember if it's under a workspace
318:57 - no it's I think it's at the organization
318:59 - level so we're gonna go to the settings
319:00 - here
319:01 - and there we have our policies so we
319:04 - here we can create new policies so
319:05 - managing individual policy terraforms
319:07 - deprecated policy sets now supports VCS
319:09 - integration with direct API uploads this
319:12 - provides a streamlined policy management
319:13 - experience policies which includes okay
319:15 - so this is the old way of doing it and
319:17 - so we'll go here and create a new policy
319:18 - set so connect a new policy set
319:22 - um okay so I guess what we have to do oh
319:25 - boy this is a lot different than I
319:27 - thought it was going to be so I thought
319:28 - it was just like we're going to go here
319:29 - and create it and then dump our code in
319:31 - which apparently that's what it is but
319:32 - it seems like we need to associate with
319:34 - the policy set so just give me a moment
319:36 - because I do want to show you the the
319:37 - most up-to-date way to do this I'll be
319:39 - back in a second all right all right so
319:41 - doing a little bit of reading here it
319:42 - looks like what we have to do is create
319:44 - ourselves a sendile.hcl file and this is
319:46 - going to say what policies we want to
319:48 - enforce so I assume this is basically
319:49 - the policy set as a file and here we
319:52 - specify the policies that we care about
319:55 - um I actually just want to go back to
319:57 - the files we were looking at earlier
319:58 - because we saw this HCL file so I guess
320:01 - this would technically be a policy set
320:03 - is that what we call that here but
320:05 - notice it says mock so these aren't
320:07 - policies per se these are just grouping
320:09 - mocks but in any case I think we'll have
320:13 - to create this file so what I'm going to
320:14 - try to do
320:15 - and I don't know this is going to work
320:17 - but we'll just stumble our way through
320:18 - here because it's the best way to learn
320:19 - is we're going to create ourselves our
320:22 - own Sentinel file here so we're going to
320:23 - say
320:24 - um
320:25 - Sentinel dot HCL
320:28 - and we're going to Define ourselves a
320:30 - policy
320:31 - this is going to be the one that we're
320:33 - going to use but I'm just going to grab
320:34 - it here notice there are different
320:35 - enforcement levels so
320:37 - um I don't really care we put in I just
320:39 - want to see that we can successfully get
320:40 - anything working here and I'm going to
320:42 - go back to the examples
320:45 - if we can go find that there so
320:48 - Sentinel
320:49 - policy examples and let's just go take
320:51 - one of those and see what we can do with
320:53 - it okay
320:56 - so if we scroll on down
320:58 - um
320:59 - this allows zero zero zero cider Block
321:01 - in the security group that seems like
321:03 - something that would be pretty relevant
321:04 - restrict instance type of ec2 instance
321:06 - that could be something as well that we
321:08 - could do
321:09 - so you know I just have to decide what
321:12 - it is we want to do here restrict owners
321:13 - so there's a few that are good here
321:14 - let's take this take a look at this one
321:16 - because I feel like this might be very
321:17 - simple
321:18 - so yeah this is perfect okay so what
321:20 - we'll do is we'll take uh this policy
321:22 - here so I wonder if I could just go
321:24 - download this file here it's probably
321:26 - like a download button
321:29 - well I can't find it so we'll just or
321:31 - maybe it's up here
321:32 - no okay we'll just create this by hand
321:35 - here so I'm going to go copy and it
321:38 - looks like we can just drop it in here
321:39 - so I'm just going to new
321:41 - file here
321:42 - and put that there and we will just go
321:45 - to Raw
321:50 - and we will go ahead and drop that on in
321:52 - there
321:54 - so I wish I had like sandal highlighting
321:56 - I don't know if there is such one for vs
321:58 - code if there is it'd be really nice so
322:00 - we would type in Sentinel
322:05 - um uh yes we do
322:08 - this one has more downloads so we'll go
322:11 - with that one
322:13 - no rating as of yet looks like it works
322:15 - so let's go give them a five star
322:19 - I think that's only fair because uh no
322:21 - one's done that yet
322:28 - might be a bit too hard to uh I've never
322:30 - written a review before but we'll go
322:31 - here and say works as expected
322:34 - thank you for this uh
322:37 - extension
322:41 - okay so what I'm going to do is go back
322:44 - over to here and so here we have some
322:46 - kinds now we're running a T2 micro I
322:49 - believe so this policy should cause it
322:52 - to fail and that's exactly what we want
322:54 - but I'm just going to go look up and
322:56 - down to see if it's all correct looks
322:57 - good to me so I think we'll have to
322:59 - change over here is the name so I'm just
323:00 - going to clear this out and we'll say
323:03 - restrict
323:05 - ec2 instance
323:07 - type
323:08 - we'll save that hard mandatory sounds
323:10 - really good to me
323:13 - um probably have to spell it right for
323:14 - it to work r-e-s yeah strict okay great
323:17 - and so what I'll do is just copy this up
323:20 - here
323:27 - okay and so we have our signal HCL file
323:31 - and it's referencing a local file now
323:32 - the question is you know can we use the
323:35 - same repository I assume we would be
323:37 - able to uh for our policy set but it
323:39 - almost seems like it might encourage you
323:40 - to have your policies separate from your
323:42 - repository that you're testing and that
323:44 - might be really good because let's say
323:45 - you have multiple workspaces or
323:47 - environments and they all require the
323:49 - same policy set you wouldn't want to
323:50 - have them in your code base like that
323:51 - but for the purposes of this we're just
323:54 - going to keep it simple I'm going to go
323:56 - ahead and open up terminal here and
323:59 - we're going to commit these uh these
324:00 - changes to our Repository
324:03 - and this will end up triggering a deploy
324:04 - even though we don't necessarily want
324:06 - that to happen but there's no way around
324:09 - that so get well I suppose we could just
324:12 - cancel it out but or not have the auto
324:13 - apply but I don't feel like changing
324:15 - that so we'll do get status here we'll
324:17 - go get add all git commit hyphen M uh
324:21 - simple policy here
324:26 - get push
324:28 - okay
324:30 - and so that's being pushed to our
324:32 - repository that's going to trigger a
324:34 - deploy and we don't care I I assume that
324:36 - it won't pick up the policy because we
324:37 - have to kick the policy set
324:39 - so
324:41 - um apparently use the API to upload your
324:42 - policy set which is kind of cool I
324:44 - suppose we could have done that but um
324:47 - well too late we probably should use VCS
324:50 - anyway you know what I mean so we'll go
324:52 - to GitHub here and we will find our
324:54 - terraform repository which is here
324:57 - um you know policy
325:00 - well we should probably name this right
325:02 - so we policy to enforce uh instance type
325:09 - I don't know if we need a description I
325:10 - guess we'll find it in a second here I
325:12 - guess we could have also put the policy
325:14 - in a um a subdirectory there that might
325:17 - have been okay to do
325:19 - it's going to default to the main branch
325:20 - which is fine policies enforced On All
325:22 - workspaces or policies and force on
325:24 - selected workspaces and we only have one
325:26 - but that's what we'll do down here so
325:28 - we'll say update
325:30 - the name is invalid
325:31 - oh uh it has to be like
325:34 - a proper name so restrict
325:39 - ec2
325:40 - now again this is a policy set so you
325:42 - could just say like
325:43 - um
325:44 - you know basic server policy
325:47 - set that'd probably be better and then
325:49 - you probably want to list to say what it
325:51 - does it restricts
325:52 - um ec2 instances instance type
325:56 - okay and we'll go down here and create
325:58 - that policy set
326:00 - and that looks like we're in good shape
326:02 - so we applied it um now will it actually
326:06 - happen on this run because it's already
326:07 - running I believe we're going to this
326:09 - workplace
326:10 - workspace I like to say workplace it's
326:12 - workspace and uh we go over here this is
326:15 - already planned and finished so what I
326:16 - want to do is just trigger another uh
326:20 - um deploy here so there's nothing
326:21 - changed
326:24 - so
326:25 - I'm not sure what we do here
326:28 - um I guess what we could do and actually
326:29 - this is something that I'm I don't know
326:30 - but like how would you trigger a replace
326:33 - on here because if we were doing let's
326:36 - go to plan and see what happens I wonder
326:38 - if we could do that in the plan here
326:40 - reasons for trigger
326:42 - do refresh only plan because one thing I
326:45 - was thinking about is like imagine I
326:46 - wanted to replace an element you can do
326:48 - that hyphen replace but I don't know how
326:49 - you do that through VCS but anyway what
326:52 - I'm going to do is just go change
326:53 - anything in our code
326:56 - um so it could just be a space it
326:57 - doesn't really matter
326:59 - get add plus git commit
327:03 - trigger uh change
327:06 - and we just want to observe
327:09 - the um
327:13 - the policy working okay
327:18 - so I'm just going to open this up here
327:20 - I'm not sure if it's going to show up in
327:22 - the plan section or the apply section so
327:24 - we'll just wait here to watch see the
327:25 - plan generate out
327:43 - and so the plan finished
327:45 - um we don't see any Sentinel uh Central
327:47 - being applied there
327:49 - apply will not run
327:52 - let's expand that there this looks fine
327:58 - I guess technically we didn't change
328:00 - anything so that probably is not very
328:01 - helpful so what I'm going to do is go
328:05 - and change a variable because maybe
328:06 - that's that's what's going to help here
328:08 - so we have a micro here which is fine
328:10 - we're just going to change this over to
328:11 - Nano
328:15 - that makes sense why I didn't do it so
328:18 - we'll go back over to runs and I'm going
328:19 - to trigger I'm going to start a plan so
328:22 - uh changed ec2 instance type
328:28 - we'll say Start Plan
328:52 - okay so we have one change which is fine
328:57 - we just okay so that part pass is going
328:59 - to go to cost estimation
329:03 - that passed it's going to apply it
329:05 - because remember we have um Auto approve
329:07 - on the server so it's not even going to
329:09 - ask us to confirm it and so I want to
329:11 - see if that policy is in place
329:27 - well it's running I'm just going to go
329:28 - review our policy here
329:31 - just to make sure it's not like the
329:32 - opposite saying like you cannot have
329:34 - these so include now a loud easy to do
329:36 - instance type so it's small medium or
329:38 - large so it really should quit out on
329:39 - this one here
329:45 - but it seems like it's working like it's
329:48 - not uh it's not picking up the policy
329:49 - but I'll see you hear it back in a bit
329:50 - okay all right so I didn't see the
329:53 - policy trigger there so I'm going to go
329:54 - back to policy sets and notice here it
329:56 - says zero workspaces which is unusual
329:57 - because I definitely selected one but
329:59 - maybe I didn't click through or hit uh
330:01 - add so I'm going to go down here and
330:03 - click this one again and maybe I didn't
330:05 - hit this button here
330:07 - okay and now I'll probably have to hit
330:09 - update um policy set before we do I just
330:11 - want to read about this these parameters
330:12 - are past the central runtime on
330:13 - performing policy checks so I guess I'd
330:15 - be like a way where you'd have a generic
330:17 - policy and then you could kind of put
330:18 - parameters in so that's kind of cool so
330:20 - I'm going to go back here and double
330:22 - check to make sure that we have a
330:23 - workspace set and so what we'll do is
330:25 - just change the variable again
330:29 - um so we will go to our variables here
330:32 - and I'm going to go change this back to
330:34 - a micro and so I think this time we are
330:37 - going to have better success okay so
330:39 - we'll hit save we'll go back up to runs
330:42 - we'll go and start a new plan uh change
330:45 - instance type
330:47 - again here
330:51 - and we will save that plan and so that
330:54 - plan is now running I will see you back
330:56 - here in a bit uh when we see that
330:57 - Sentinel policy I don't know when it
330:59 - triggers so I'll see you back here in a
331:00 - bit all right welcome back so after our
331:02 - cross estimation it did a policy check
331:03 - and you can see that it failed um and
331:05 - here the error says import TF plans
331:07 - function is not available so I'm not
331:10 - sure why that's happening so I think
331:12 - that um I mean our set failed but not
331:14 - for the reason we wanted to so I'm going
331:15 - to go investigate this I'll be back in a
331:17 - moment okay all right so uh what I've
331:19 - done here is I've gone and looked up uh
331:21 - like how to create a policy set and
331:23 - hashicorp learn has this example project
331:25 - here and if we go into its GitHub
331:29 - project and I go here you're going to
331:31 - notice that it it's like this apparently
331:33 - does basically the same thing restrict
331:34 - AWS instance type and apparently tag as
331:37 - well but it doesn't have the TF
331:39 - functions the TF plan functions here so
331:44 - um maybe we don't need that function in
331:46 - there and maybe the uh the example is
331:48 - just out of date at this time so import
331:50 - common functions
331:51 - for Sentinel
331:53 - okay but this one doesn't have it it
331:55 - does it does have it for mocks right
331:58 - um
331:59 - so maybe we just need to kind of like
332:02 - walk through this really quickly and see
332:04 - how we can fix this so the policy uses
332:06 - the Sentinel TF2 plan import to require
332:08 - that all ec2 instances have instance
332:11 - types planned under the loud list
332:13 - but I don't see that import there
332:17 - okay and it is in here
332:19 - so I guess what we'll do is just grab
332:21 - this one
332:23 - okay and I'm going to go ahead and just
332:25 - delete this one out here
332:27 - um
332:28 - again this isn't working I don't know if
332:30 - this would work with that one so I'm
332:32 - going to take it out
332:33 - this is pretty clear what this does so
332:35 - we'll just have that allowed types it's
332:37 - interesting like here it's underscore
332:39 - and then here it's like a title case
332:41 - there's some inconsistencies there so
332:43 - they have a lot of types as well
332:46 - um
332:47 - and I'm just seeing if there's like find
332:49 - resources in here
332:54 - so allow types rule to enforce the name
332:57 - tag
332:58 - so I don't care about that
333:00 - rule to restrict the instance type so
333:03 - I'm going to go ahead and grab this one
333:04 - here and let's just take a look at the
333:05 - differences here
333:10 - okay so instant type allowed rule all
333:12 - ec2 instances as
333:14 - that instance
333:16 - change after instance type a lot type so
333:19 - this is way way different
333:21 - um
333:23 - so I mean I fully don't understand this
333:25 - but I do know that this one
333:28 - it will probably work so I'm going to go
333:31 - down here
333:32 - we have count violations I'm not really
333:34 - worried about that
333:39 - and
333:40 - the rule is different
333:43 - like if I was really serious about this
333:45 - I'm sure I could you know figure out the
333:47 - logic here but again this is just for
333:48 - the purposes of us learning so we don't
333:50 - have to go too crazy here now this says
333:52 - instance type allowed and mandatory
333:53 - instance tags we're not dealing with
333:55 - tags here so I'm just going to say this
334:04 - okay and so I think this will produce
334:06 - what we want
334:07 - so allows those types
334:11 - I don't know if it had this in here
334:17 - get all instant types from the module
334:20 - I think we didn't put this in here so
334:22 - this might be kind of the equivalent
334:26 - ec2 instances filter TF plan resource
334:30 - changes
334:33 - okay
334:37 - contains a create or an update
334:41 - okay
334:44 - [Music]
334:44 - um
334:45 - I mean this isn't bad we technically
334:47 - have a name set so you know what I'm
334:49 - just going to grab this whole thing
334:50 - because then we're just going to have a
334:52 - much easier time we don't have to worry
334:53 - about it but it was nice to walk through
334:54 - that file very quickly because the name
334:57 - tag is set in our project a because we
334:59 - can see we can see that's the server
335:01 - name so what we'll do is we'll just go
335:04 - ahead and add this to our repository
335:06 - here and the great thing is that since
335:09 - it's the vs code or it's in the same
335:10 - Version Control System I would think
335:12 - that it would update in time so what
335:14 - we'll do is just do get add all git
335:17 - commit hyphen m
335:19 - fix the policy
335:22 - git push
335:27 - okay and we'll go back over here
335:34 - and we will see
335:37 - if the policy check happens and when it
335:39 - does happen it's actually
335:41 - airing out because we're not using the
335:43 - right instance size right that's what we
335:45 - want to see
335:48 - a little bit of trial error it's not a
335:50 - big deal I also read like over here that
335:52 - the Sentinel file for HCL only contains
335:55 - module and policies but then we saw a
335:56 - sentinel file or htl file that clearly
335:58 - had mocks in it so
336:01 - I mean maybe maybe it just only used
336:03 - locally maybe it's not intended for um
336:05 - production
336:07 - um so we'll go down here TF plan so it
336:10 - didn't pick it up okay so what I'm going
336:12 - to do is go back to my policy set and
336:14 - maybe it's just like the order of how
336:16 - this happened
336:17 - so see this says it was updated uh last
336:19 - five minutes ago
336:21 - updated it a minute ago so this could
336:23 - just be like a race case where
336:25 - um you know this ran before the other
336:28 - one so I'm going to try to execute this
336:30 - again start a new plan uh trigger plan
336:37 - and we'll see if that works now because
336:39 - again this said
336:41 - literally updated a minute ago so maybe
336:42 - it didn't pick it up
336:50 - so you can see why it would also be good
336:52 - to have your policy set in a separate
336:54 - repo because if you're deploying this
336:55 - you don't want to keep triggering your
336:57 - deploys
336:59 - so I think probably that's what you know
337:01 - we should have done I mean it's a lot
337:02 - extra work but you know this way you
337:03 - kind of understand why
337:06 - SO waiting on that plan run I really
337:08 - don't care about cost estimation I mean
337:09 - you could make a policy to check based
337:11 - on that I I'm assuming we just turned
337:13 - that off if we wanted to
337:16 - and we'll go over to cost estimation
337:18 - here yeah we can just disable it
337:21 - but the thing here is that it set our
337:23 - policy passed
337:25 - so we'll go here so the result means
337:28 - that all Central policies passed
337:30 - so restrict the instance type so
337:33 - description
337:34 - main rule that requires other rules to
337:36 - be true
337:39 - ruleton Force name tag is on all
337:41 - instances that's true rule to restrict
337:42 - the instance type
337:43 - so maybe we don't understand uh maybe
337:46 - this works in the opposite way oh the t2
337:48 - micros here okay so
337:51 - I just want to see it fail so what we'll
337:53 - do is go back up to our variables here
337:56 - and we'll go to our instance type
338:00 - and we'll just change this to Nano
338:03 - and we'll save that
338:05 - we'll go back over here to our runs
338:10 - oh this is still running the old one
338:11 - here that's fine we can just queue up
338:13 - another one here so we can just say
338:14 - start a new plan
338:16 - uh new instance type
338:23 - okay and if we go back over to here
338:27 - the last one wouldn't have done anything
338:28 - because the infrastructure would have
338:30 - been the same so
338:36 - the previous one we just did here right
338:38 - it would just been like oh no it's still
338:40 - trying to apply it so I guess there is a
338:41 - change
338:42 - maybe we changed the instance type last
338:44 - time I don't know
338:46 - so anyway I'll see you back here when
338:48 - this is completely done okay
338:49 - all right great so we got an error if we
338:51 - go into our instance type here
338:53 - right and we look at it we can see that
338:55 - it failed because uh it wasn't the right
338:57 - uh type so
339:00 - um I mean that's pretty interesting so
339:02 - the other thing I would say that we
339:03 - could do is also kind of check out mocks
339:06 - now because I kind of feel like I have a
339:07 - better grasp on it now that we have a
339:08 - test running so just thinking straight
339:10 - about it a mock really is a
339:12 - representation of the state of
339:14 - infrastructure at the time of so if we
339:16 - go back to our runs and we go to a
339:17 - successful run like the trigger plan
339:19 - here and this one was successful we
339:21 - could go to the plans here and then
339:22 - download these mock files so we do have
339:25 - the ones from prior and I think those
339:26 - are totally fine and valid to use so
339:29 - what if what we do is go back to our
339:31 - project over here and we have
339:35 - um
339:36 - the mock files over here but really
339:38 - where they need to be is within the
339:40 - workflow directory because looking at
339:42 - the documentation here
339:43 - what it's saying is that you get all
339:45 - these things and this basically
339:46 - represents the state of those mock files
339:48 - and then you need to make a test folder
339:50 - and then a test data folder and then
339:52 - there's gonna be something based on the
339:53 - name of the uh the mock file so what
339:55 - we'll do is we'll go
339:58 - up to this folder here and we'll say new
340:00 - folder test and then we'll make another
340:03 - new folder here test data
340:07 - those folders are files
340:10 - I think those are files so I'll delete
340:12 - that it's just out of habit to click the
340:15 - um
340:16 - the file there so we'll say new folder
340:18 - so we'll say test
340:20 - and then we'll say another new folder
340:21 - there
340:22 - test data
340:24 - okay and so we have our sendle file here
340:28 - so we need to have I think a similarly
340:31 - named one here so if we go back over
340:33 - here
340:35 - um this is Foo whatever so I think we
340:37 - need to have a folder in here because
340:39 - it's all based on convention and I just
340:40 - it's pretty not that hard to figure I
340:42 - don't have to read the docs to know that
340:43 - we'll just put that in here take out the
340:45 - word Sentinel
340:47 - and then I would assume that we need a
340:48 - file in here what's it called like this
340:50 - pass and fail so I'm going to just do a
340:52 - pass
340:53 - file new
340:55 - pass.hcl
340:58 - okay and then we have our test data so
341:00 - that was what we had down below here so
341:03 - I need to go grab that information
341:07 - I'm just looking for a folder where
341:10 - I might already have open here if I
341:12 - don't that's fine we'll just go ahead
341:13 - down below and just right click
341:16 - and reveal and explore
341:20 - we'll go over here
341:22 - and I need to move all these over so I
341:24 - just copy them over and we're going to
341:26 - go over to our terraform work
341:30 - flow here and I'm going to go here and
341:33 - paste that data in
341:35 - I don't know if these contain any kind
341:37 - of sensitive data because if they're
341:38 - based on the TF State file these might
341:40 - be something you don't want to share
341:41 - that might be a security vulnerability I
341:43 - don't know but I definitely won't have
341:45 - these available when I put this
341:46 - repository up for free so we have those
341:49 - files in the right place
341:53 - and we have all this stuff here so I I
341:56 - think that um like you notice it's not
341:59 - there so I'm assuming that we need to
342:00 - open up this file and copy into our main
342:02 - HCL file so we'll go down below here and
342:05 - then I think it's just a matter of
342:06 - copying all this stuff right
342:09 - we'll say cut
342:12 - and then we will go to
342:16 - um back up to here I suppose
342:20 - into our
342:22 - file it's getting a little bit confusing
342:24 - with all this stuff eh
342:27 - okay so that's in the right place our
342:29 - test data is there good here we are okay
342:31 - so what I'm going to do is just go down
342:33 - here and paste that in
342:37 - okay and so
342:39 - we didn't write any kind of pass
342:42 - data test
342:45 - so that's something we will need here
342:46 - I'm not sure what we'll get so we'll
342:48 - just scroll down here
342:50 - so you can find the contents of a
342:51 - pass.hcl
342:58 - it's not showing anything here so just
343:00 - give me a moment I'm going to see what
343:01 - we have to do for this this test okay
343:03 - all right so a little bit of Googling it
343:04 - looks like uh this one's on the same
343:06 - tracker so since we probably copied the
343:08 - mock data from this one or somewhere
343:10 - through here we could probably just go
343:11 - grab this so
343:13 - um this is pretty much what our pass
343:15 - file will look like
343:16 - so we'll go ahead and grab this here I
343:20 - don't know if we really need a fail to
343:22 - write a failing test I don't really care
343:23 - about that I just want to see anything
343:25 - pass here
343:26 - we'll paste that in here we do have to
343:27 - be sure that we are accessing our data
343:30 - correctly so if we're in test it's going
343:32 - to go up one directory to the
343:35 - terraform directory
343:37 - but wouldn't it have to then CD into
343:41 - uh test so I don't think that Source
343:44 - path is correct
343:47 - just going to double check that here
343:49 - they do have an example repositories
343:51 - let's take a look here what we have
343:55 - um
343:56 - yeah it's kind of odd so I think
343:59 - that
344:01 - if this is relevant it needs to go to
344:04 - test data
344:06 - because how else will it get there okay
344:09 - so we'll do that so test rules main
344:11 - equals true
344:14 - um
344:15 - okay so that's a pretty simple test
344:18 - and so I think the way we run tests is
344:19 - there's like a sentinel test
344:21 - thing here
344:23 - I don't know if we have Sentinel
344:24 - installed I don't think so
344:27 - so there's no Sentinel command
344:31 - so I guess that's something we're gonna
344:32 - have to install Sentinel
344:33 - [Music]
344:34 - um
344:35 - CLI terraform
344:38 - okay
344:39 - over here
344:42 - uh we're on technically Linux even
344:45 - though we're on Windows we're on Linux
344:46 - so here it's just saying uh download it
344:49 - and then put it in the correct path
344:52 - so install so we'll get the appropriate
344:54 - package here
344:57 - and we are technically on Linux
345:01 - and I guess we are 64-bit
345:08 - it's going to download here
345:11 - scroll up oh it is already downloading
345:12 - okay great and so I'm just going to go
345:14 - to my downloads
345:17 - and I'm going to open it up here
345:19 - so there it is and so I need to um
345:23 - get it into the user local bin here so
345:26 - I'm just going to first get it in
345:28 - anywhere so
345:30 - because I'm just working here I'm just
345:31 - going to go open this up so reveal in
345:33 - the Explorer
345:36 - okay
345:37 - and this is not where I want it to be
345:40 - I'm just dropping it here for the time
345:41 - being
345:47 - technically we could run it from there I
345:49 - don't think it'd be that big of a deal
345:51 - so I'm just going to go back to my vs
345:53 - code here
345:55 - and I'm going to just type signal
345:58 - Sentinel
345:59 - is there right
346:01 - yep it's there
346:03 - I'm not sure if it's executable but um
346:06 - I'm just going to type in Sentinel here
346:08 - Sentinel test
346:11 - okay so it doesn't think it's command so
346:13 - maybe I have to do like chamod U plus X
346:16 - that makes it executable on Linux
346:20 - so note command not found
346:22 - well heck I'm right there maybe I have
346:24 - to put a period forward slash like that
346:25 - okay there we go so I mean of course you
346:28 - don't want to leave it in here you and
346:30 - this would also end up in a repository
346:31 - so this will go to like your user local
346:33 - bin probably so
346:35 - I'm going to say like move sendle to
346:38 - user local bin
346:41 - and so now I should just be able to type
346:43 - Sentinel it should get picked up
346:45 - it does great so here I can do test
346:48 - and down below it says open test no such
346:52 - file or directory so it can't find the
346:54 - mock data notice that it's going into
346:57 - the test test data so that is no good
346:58 - for us we did say to go up a directory
347:01 - so maybe if I go up back one more like
347:03 - this
347:07 - would that work
347:09 - no let's go put back in what they
347:11 - actually had there which I have a hard
347:13 - time believing that would be correct
347:16 - so open mock okay so that's definitely
347:19 - not right okay and so
347:24 - personally I just want this to work so
347:26 - I'm just going to cheat
347:28 - this is absolutely what you should not
347:30 - do but you know like I don't be fiddle
347:32 - around with paths all day here
347:34 - and so I'm just going to give it an
347:35 - absolute path and see if that fixes our
347:37 - problem
347:39 - okay and so just say test data
347:42 - here
347:48 - um
347:51 - so that should absolutely work I'm just
347:53 - going to expand this here
347:55 - this is mock TF plan
347:59 - oh but it says pass in the name okay so
348:01 - the problem isn't that it's the fact
348:03 - that the mock data isn't named it's
348:04 - because the thing is you could download
348:05 - two different mocks right so you could
348:07 - have a state that is successful and
348:09 - failed and you'd probably want to rename
348:10 - them to say passed or failed so we don't
348:12 - necessarily have that so I think my
348:14 - original thing was correct where we had
348:16 - this test data
348:19 - and so here we just have to make sure we
348:20 - match the name so mock TF
348:22 - uh V2 is fine here
348:25 - okay again I don't understand the
348:27 - difference between all these files I
348:29 - definitely saw the documentation to
348:30 - explain them all so you know that might
348:32 - be something we want to read through
348:33 - here
348:34 - um so this is looking a little bit
348:35 - better so mock TF plan hyphen version 2
348:37 - Sentinel
348:40 - so that
348:41 - is correct
348:43 - but the director it doesn't like the
348:45 - direct it's going in that test again so
348:48 - again I can just go back up one more
348:49 - layer here
348:51 - okay
348:54 - there we go and it's passing so
348:57 - um yeah so that's all it takes to
348:59 - um do that again I think if we were to
349:01 - commit this to our code I don't think
349:02 - that these run so we can go like so we
349:05 - can just go add it and see what happens
349:06 - so we'll say get add
349:08 - git commit hyphen M validation
349:15 - and again I don't know if this mock data
349:18 - should be allowed to be committed into
349:19 - the Repository
349:21 - because we have a TF State file here
349:22 - right
349:31 - okay I don't know but I'm going to just
349:33 - do a push here to see what happens
349:36 - but again I I really think that we're
349:38 - probably not supposed to have it in
349:39 - there
349:41 - um so what we'll do
349:43 - is go back to our terraform i o
349:52 - sign in
349:56 - and we'll just see what happens here I
349:57 - mean we don't expect the uh this to pass
349:59 - because it's still using the wrong
350:01 - instance type but I was just curious to
350:03 - see if the mock would appear in any way
350:04 - here I don't think it does I think
350:06 - that's just something that you have to
350:07 - do uh beforehand and I think what you'd
350:09 - have is you'd have a pull request and
350:11 - the pull request could be used to run
350:13 - those unit tests because that's
350:14 - basically what it is okay so yeah that's
350:16 - exactly what I thought would happen but
350:18 - down below here it says the mock block
350:20 - is not supported so
350:24 - I wonder what you would do so if you
350:26 - can't have mocks in the file
350:29 - what would you do locally because you
350:31 - need to I guess the thing is is that the
350:34 - mock file the sentinel.hcl file would
350:36 - not be in this fold so you might have
350:39 - the central HCL file in your main
350:41 - repository for mocking right and if you
350:44 - committed it wouldn't run it because the
350:46 - policy set would actually be in another
350:47 - repository so I think that's how it's
350:49 - supposed to work so
350:50 - yeah I think really we want to have
350:52 - policy sets in their own repository like
350:55 - completely away from there because we're
350:56 - seeing we're running into a lot of
350:57 - problems but we pretty much accomplished
350:59 - what we wanted to do with Sentinel more
351:00 - than I thought we were going to do so
351:02 - that's pretty great so there you go
351:04 - um in terms of this we probably want to
351:06 - tear this down uh we do need to do
351:08 - something with vaults and stuff like
351:10 - that but I think that what we'll do is
351:12 - just tear this down and you know if we
351:14 - need to bring it back up we'll do that
351:16 - so I'm going to go to destruction here
351:18 - Ed
351:22 - we're gonna go ahead and just destroy
351:23 - the plan here
351:28 - okay
351:30 - and we're all now in good shape
351:33 - and so um yeah I'll see you in the next
351:36 - part okay
351:37 - but we're all done here for for Sentinel
351:39 - all right uh actually I guess we're not
351:41 - gone here just yet because it looks like
351:42 - our destroy run failed uh because we
351:44 - didn't pass here so
351:47 - um that is a bit of a problem so we'll
351:49 - have to go to the variables
351:51 - I guess it's a good Edge case to know
351:52 - about but um we'll go back and change
351:54 - this to a micro even though it's going
351:56 - to just tear it down anyway you know
351:58 - so we'll go and type in micro save
352:00 - variable and we'll go back to our runs
352:04 - we'll start a new plan we're sorry we'll
352:07 - go to settings here
352:08 - destruction
352:10 - cue the plan
352:13 - I'm just curious the community plan
352:15 - we'll redirect a new up output here
352:18 - okay cool um so I'm just going to type
352:20 - in VCS terraform again here
352:28 - okay and so
352:30 - this should work
352:33 - and I will come back and just confirm
352:35 - this with you okay so I'll be back in a
352:37 - second all right so the real reason we
352:39 - can't uh get rid of this is because we
352:40 - have those darn mocks in there so
352:44 - um
352:45 - what I'm going to do is go over to our
352:46 - signal file here
352:48 - um up to I mean we don't use this one so
352:50 - I'm gonna go ahead and delete that it's
352:51 - not even something that's going to
352:52 - happen and
352:55 - we need to update our
353:00 - HCL file here
353:02 - okay
353:04 - and I'm assuming that this supports uh
353:08 - this okay
353:10 - because this is not how we should be
353:12 - doing this
353:13 - um and here we go get add git commit
353:17 - hyphen m
353:22 - INE or change
353:25 - okay and this is going to trigger a run
353:28 - here
353:30 - but I really wanted to destroy
353:36 - so we'll just give it a moment there to
353:38 - start so we can kill it
353:42 - um
353:46 - did I not push
353:50 - oh maybe I didn't push
353:54 - and we'll go back here
353:56 - there's that run I'm going to go in here
353:59 - I want to stop it uh cancel run
354:04 - okay and so now what I'll do is go over
354:07 - to the here
354:09 - destroy this
354:13 - we'll run that okay we'll destroy that
354:18 - and I will again see if this is working
354:21 - and I'll see you back here in a moment
354:23 - okay all right so I just wanted to
354:24 - confirm there that everything is uh
354:26 - destroyed so we're all in good shape
354:27 - okay so uh yeah so we're actually done
354:30 - Sentinel now for real okay bye
354:32 - [Music]
354:37 - all right let's take a look here at
354:38 - hashicor Packer so it's a developer tool
354:41 - to provision a build image that will be
354:43 - stored in a repository using a build
354:45 - image before you deploy provides you
354:47 - with the following immutable
354:48 - infrastructure your VMS and your Fleet
354:51 - are all one-to-one in configuration
354:53 - faster deploys for multiple servers
354:55 - after each build earlier detection and
354:58 - intervention of package changes or
355:00 - deprecationable technology so let's take
355:02 - a look at what that workflow would look
355:03 - like so you'd have your code you commit
355:05 - it to your CI CD Pipeline and within
355:07 - that pipeline it would start up a build
355:09 - server running uh Packer and that would
355:12 - trigger a build image so you'd use a
355:14 - something to provision it with so you
355:16 - could use ansible or a variety of
355:17 - different provisioners within Packer and
355:20 - then Packer would then store it
355:22 - somewhere so maybe this would be Amazon
355:23 - machine image because you're deploying
355:25 - to AWS
355:26 - and then what you do is reference that
355:28 - image in your terraform code and when
355:31 - you provision it would get deployed to
355:33 - your
355:33 - CSP so this would be AWS in this case so
355:37 - packet configurations is a machine uh
355:40 - Packer configuration configures the
355:42 - machine via oops
355:59 - hey it's Andrew Brown from exam Pro and
356:01 - we are taking a look at hashicorp
356:02 - Packers so Packer is a developer tool to
356:04 - provision a build image that will be
356:05 - stored in a repository so using a build
356:08 - image before you deploy it's going to
356:10 - give you the following benefits
356:11 - immutable infrastructure your VMS and
356:13 - your Fleet are all one-to-one
356:14 - configuration faster deploys for
356:16 - multiple servers after each build
356:18 - earlier detection intervention of
356:20 - package changes or deprecation volt
356:22 - technology let's take a look at what
356:24 - that workflow would look like so first
356:25 - we'd have GitHub or or your git so
356:28 - wherever you commit your changes and
356:30 - from there that would trigger a CI CD
356:32 - Pipeline with within that cicd pipeline
356:35 - it would trigger a virtual machine so or
356:38 - a build server that's a running Packer
356:40 - and so that would trigger the build
356:41 - image process from there Packer would
356:44 - use some kind of provisioner like
356:45 - ansible to provision the image and then
356:48 - when it was done and and it was all good
356:50 - it would store it summer like in Amazon
356:52 - machine image once it is stored wherever
356:55 - you want it to go then in terraform you
356:57 - would just reference it using like a
356:58 - data source and then from there you
357:00 - could provision your resource okay so
357:03 - Packer configures a machine via a packer
357:06 - template and yes I know the E is missing
357:10 - um so sorry about that but Packer
357:12 - templates use the hashicorp
357:13 - configuration language HCL which we saw
357:15 - if you remember way earlier in the
357:18 - course and that's what we're going to
357:19 - review next is what that Packer template
357:21 - file looks like okay
357:22 - [Music]
357:27 - all right so Packer configures a machine
357:30 - or container via a packer template file
357:33 - and Packer template uses the hashic
357:35 - configuration language HCL so that's why
357:37 - it looks very familiar to terraform and
357:39 - a variety of other languages we've been
357:40 - looking at in this course and so what
357:43 - this file is doing is provisioning a
357:45 - virtual machine on AWS so here you can
357:47 - see that it's a TT micro and the US West
357:49 - 2 region that it's probably going to be
357:51 - installing Apache since it's named httpd
357:54 - and the way it's going to be created is
357:56 - via an EBS volumes let's talk about kind
357:59 - of the components that we're looking at
358:00 - here so when you have a packer template
358:02 - file you have to specify a source and
358:04 - this says where and what kind of image
358:06 - we are trying to build so the source is
358:08 - Amazon EBS so it's looking for an Ami
358:11 - image or it's being backed by that EBS
358:13 - volume there okay in this case it's an
358:16 - EBS back to Ami the image will be stored
358:18 - directly in AWS under the ec2 images and
358:21 - so we have the build step so the build
358:23 - allows us to provide configuration
358:25 - scripts Packers supports a wide range
358:27 - your provisioners so we have shaft
358:29 - puppet ansible power Powershell bash
358:32 - salt whatever you want basically has it
358:34 - and the post provisioners runs after the
358:37 - image is built so they can be used to
358:39 - upload artifacts or re-package them all
358:42 - right and the place where this is going
358:44 - to be stored is going to be on Amis okay
358:46 - so there you go
358:48 - [Music]
358:53 - let's look at how we actually integrate
358:55 - terraform and Packer together in terms
358:57 - of a CI CD workflow we kind of saw this
358:59 - in uh that overall graphic in the first
359:01 - uh Packer slide let's just kind of look
359:04 - at the code okay so to integrate Packer
359:06 - there are two steps they're going to
359:07 - build the image so Packer is not a
359:09 - service but a development tool so you
359:10 - need to manually run Packer or automate
359:12 - the building of images with a build
359:14 - server running Packer then the second
359:16 - part of that is referencing the image so
359:19 - once an image is built you can reference
359:21 - reference the image as a data source so
359:24 - if it's stored in Abus Ami we're going
359:26 - to just Source it from there and the way
359:29 - we select it is what we can do is say
359:31 - okay get us the most recent one and use
359:34 - this regular expression and the owner
359:36 - has to be us and and those kind of
359:39 - parameters to decide how to choose that
359:41 - image so that's all there is to it
359:43 - you're just using data sources to
359:44 - reference them after they've already
359:46 - been built okay
359:47 - [Music]
359:51 - hey this is Andrew Brown from exam Pro
359:53 - and we are taking a look at using Packer
359:56 - with terraform and mostly it's just
359:58 - about just using Packer uh and so what I
360:01 - want to accomplish here is to generate
360:03 - on an image and store that onto Amazon
360:05 - machine images and then load that into a
360:07 - terraform file or like reference it as a
360:09 - data source so I've never done this
360:11 - before but it should be fun and we'll
360:13 - figure this out so what we're first
360:15 - going to need to do is download Packer
360:17 - so notice in the top right corner we
360:19 - make your way to Packer however you want
360:20 - to and we'll go ahead and download and
360:23 - this one is for Windows it's a binary
360:25 - but we are going to be using Linux we've
360:28 - done this so many times these three two
360:29 - commands so I'm not going to do that
360:31 - again here but if you have yet to do so
360:33 - you can go and run that and so I'm going
360:35 - to go ahead and install Packer and once
360:37 - Packer is installed I will come back
360:40 - here and we will get to it okay all
360:42 - right so after a short little weight
360:43 - there Packer is installed and so what I
360:45 - want to do is go into my Packer folder
360:47 - here and I'm just going to run Packer
360:49 - and see what we get
360:53 - and so we have Packer build console fix
360:56 - format a knit so install missing plugins
360:59 - uh it looks kind of similar to terraform
361:01 - build images from a template that sounds
361:05 - kind of interesting so I think the first
361:06 - thing we're going to need to do is
361:07 - Define ourselves a template file so I
361:11 - remember I researched one and and put
361:14 - one in my uh slides here so let's make
361:16 - our way over there and see if we can
361:18 - kind of just like use our notes here as
361:20 - a reference so going down to this Packer
361:22 - file let's go ahead and just write one
361:24 - here uh I don't say what the name of the
361:27 - Packer file is that would probably help
361:29 - but I believe that they're just named as
361:31 - dot HCL files so what I'm going to do
361:34 - is go into this here and make a new file
361:38 - and we're going to say
361:39 - um
361:40 - uh I guess apache.htl since we are
361:43 - already very familiar with how to
361:44 - install Apache that seems like the
361:45 - easiest way to do it and again this is
361:48 - going to be very similar looking to
361:50 - terraform because it's
361:52 - you know all based on HCL so we'll do a
361:54 - type
361:57 - string
361:58 - and we are going to need some kind of
362:00 - default Ami so we can go grab the one
362:04 - we've been using all along here
362:07 - um I think we specified it
362:09 - we can just go back to count Count's
362:11 - always a good one to go to
362:14 - um so I just want to go and grab
362:18 - where is it
362:20 - um count count count where are you you
362:21 - see anybody see it
362:29 - I'm blanking today so I'm just going to
362:31 - grab it from AWS
362:33 - it's not a big deal
362:36 - I'm just pulling up AWS here we're going
362:38 - to make our way over to ec2
362:41 - and we're going to go ahead and launch
362:43 - ourselves a new server actually I could
362:45 - probably grab it from the old one no
362:47 - I'll launch a new one just in case you
362:48 - don't see anything there that might not
362:49 - be fair I'm going to go ahead and grab
362:51 - that Ami ID
362:53 - and I'll just move that off screen here
362:55 - for a moment and we're going to place in
362:57 - that am ID because I assume we want one
362:58 - to override then we're going to say
363:00 - locals uh app name I think the example I
363:04 - wrote here is is Apache because that is
363:06 - what Apache is is httpd not sure how
363:09 - they came up with that name but uh
363:10 - that's how they call it so we need to
363:13 - provide ourselves a source so we're
363:15 - going to do Amazon EBS
363:18 - httpdd
363:22 - notice that like the source is not
363:24 - called Data it's just called Source if
363:25 - we go over to the documentation here
363:28 - just what I want to show you here Docs
363:33 - if it ever loads
363:35 - come on docs you can do it
363:40 - so down below here or on the left hand
363:42 - side we have sources so I believe if we
363:44 - were to go over to here and go over to
363:47 - Amazon Ami
363:49 - someone says Amazon MI
363:52 - overview
363:56 - uh
363:58 - builders
364:01 - ec2
364:03 - EBS
364:12 - I'm just trying to find the same kind of
364:14 - information that it has there a
364:16 - it's not really doing what I want but
364:18 - anyway I know that this code is correct
364:20 - even though we can't seem to find this
364:22 - out probably just go type in Packer EBS
364:25 - Amazon EBS I really like to always refer
364:28 - to the documentation when I can here so
364:30 - it does say it's a builder
364:33 - Amazon abs
364:36 - source
364:41 - down below here we go
364:43 - all right so yeah
364:45 - um I don't understand this uh this
364:47 - Builder flag as of yet but uh we'll work
364:50 - our way through here and figure it out
364:51 - okay so I'm gonna go back and pull up my
364:54 - vs code here
364:56 - and we're gonna put curlies here
364:59 - and so we need our Mi name here
365:02 - so my server
365:05 - uh dollar sign local
365:08 - app name
365:10 - instance type
365:12 - T2 micro
365:15 - region this is going to be us East one
365:19 - Source Ami this is going to be the
365:23 - variable we set up above amiid
365:26 - then we are going to do SSH username
365:28 - that's going to be ec2 user that's the
365:31 - default that AWS always has
365:34 - uc2 user
365:36 - we can do some tags here not really
365:38 - necessary but it's good to probably give
365:40 - it a name right so we'll just say name
365:43 - Apache server
365:48 - and actually we could probably just do
365:50 - local.app name
365:52 - maybe instead
365:54 - and then we have our build step here so
365:56 - we're going to specify our sources and
365:59 - we're going to do
366:03 - source.amazon ebs.htpd
366:08 - and we're going to do provisioner
366:11 - Pro
366:13 - visioner
366:16 - shell
366:19 - and then we want to provide a script
366:22 - I think we can we can actually do it in
366:24 - line if we didn't want to do a script
366:25 - there but we know our script works so
366:27 - maybe we should just stick to that so
366:29 - I'm just going to call this
366:31 - userdata.sh because we already have that
366:33 - somewhere
366:34 - before so we'll do Post process we don't
366:37 - need a post processor so we just want to
366:39 - run that script
366:40 - um
366:41 - I believe we have that in our terraform
366:43 - workflow
366:45 - we go over there to our workflow
366:47 - wherever it is
366:50 - might also be under modules if we go
366:52 - into our module here
366:54 - didn't we create one there called user
366:56 - data
366:59 - oh that's a yaml file
367:02 - uh okay
367:04 - um I mean that's not a big deal we could
367:07 - probably just
367:09 - okay so we're not going to do it that
367:11 - way all right um
367:13 - if we're not going to do it this way we
367:14 - probably can provide inline things we
367:16 - don't probably have to do script equals
367:18 - so what I'm going to do is go back to
367:21 - the terraform documentation here or
367:24 - Packer documentation I should say
367:26 - and what I want to do is look at
367:27 - provisioners
367:29 - we're going to go look at Shell
367:31 - so it has this inline step and I assume
367:33 - that this is going to run in a
367:34 - sequential order so inline array of
367:36 - strings
367:38 - okay so what we will do here is we will
367:41 - type in inline
367:48 - and I've done this like a thousand times
367:50 - but I'm just going to go Google it
367:52 - Apache install AWS tutorial
367:56 - there's probably like one on the AWS
367:58 - website for it
368:02 - for like user data
368:07 - and this is pretty much has some of it
368:10 - here I was just kind of looking for
368:11 - these commands like the Yum install and
368:15 - the pseudosystem start
368:17 - so we're going to go ahead and grab that
368:21 - and then we're going to go
368:28 - and grab the next few lines here
368:36 - because we want to start and enable
368:38 - what's the three things that we need to
368:39 - do
368:42 - not complicated at all
368:46 - and so what I'm going to do is type in
368:49 - Packer build and see what happens now I
368:52 - didn't specify Ava's credentials or
368:53 - anything like that I assume it would
368:54 - pick up the defaults
368:56 - and we're going to go to the top here so
368:58 - it looks like we have to provide the
368:59 - template name so maybe we'll do Apache
369:02 - HCL here
369:07 - and it says
369:09 - error parsing Json invalid character V
369:12 - for the beginning of the value
369:15 - oh so it has to be
369:17 - pkr.hcl okay
369:22 - I'm really liking the user experience of
369:24 - the developer experience for these clis
369:25 - they're really good at telling us what's
369:26 - wrong with them
369:27 - PKR HCL if there's like a default file I
369:31 - don't know what it should be called
369:33 - uh so we got a bunch of Errors which is
369:35 - fine unsupported argument locals an
369:38 - argument locals is not expected here did
369:39 - you mean to define a Local's Block it's
369:41 - because I put an equals in front of it
369:43 - supposed to just be this
369:46 - not that we were really using locals for
369:47 - much here
369:54 - and looks like it is provisioning found
369:57 - in Ami it's going to use that as the The
369:58 - Source One creating a temporary key pair
370:01 - authorizing to Port 22
370:04 - uh name Packer Builder so I don't know
370:08 - if this uses I don't think it does but I
370:11 - don't know if it uses Amazon uh but
370:14 - because there's like ec2 Builder image
370:15 - there might be a way to use it with um
370:18 - Packer directly but I'm not sure how to
370:20 - do that
370:21 - it's going to go through here I'm just
370:22 - going to see to make sure it's not
370:23 - running a pipeline here is it image
370:26 - Pipelines
370:28 - no okay that's good but what I will do
370:30 - is go over to my ec2 here
370:34 - and what I want to go do okay so Packer
370:37 - Builders is running as a virtual machine
370:39 - so it's actually
370:40 - um uh going to spin up a VM and then
370:43 - bake the Ami that way which seems a lot
370:47 - better
370:49 - um we'll go over to our Mis and see when
370:50 - that happens there
370:55 - um let's just unlock another those that
370:57 - red stuff doesn't look good
370:59 - seems like it didn't really matter
371:02 - so the thing like AWS has an entire
371:05 - pipeline for ec2 image Builder but it
371:07 - does cost money to run where I kind of
371:09 - feel like if all Packer is doing is
371:12 - spinning up a virtual machine
371:13 - temporarily to make that image that's
371:14 - going to be a lot more cost effective
371:16 - I mean we could go look up what the cost
371:18 - is to use ec2 image Builder while we're
371:20 - watching this
371:24 - Builder can't seem to type today
371:28 - uh it's pricing I just want to know the
371:30 - pricing
371:37 - happy free
371:40 - oh is it there's a no cost I could have
371:42 - swore there was a cost for this
371:44 - no cost image Builders offered at no
371:46 - cost other than the cost of the
371:47 - underlying AWS resource I think the
371:49 - thing is that it's that when you use
371:53 - um ec2 image Builder you have to use of
371:55 - a particular size
371:58 - you know if you don't really use AWS
372:00 - anymore in Azure gcp I can understand
372:02 - why this is not much of an interest but
372:03 - I'm pretty sure
372:06 - if I go here
372:12 - that the size that you get for the image
372:16 - what size of
372:18 - each image does ec2 image Builder use
372:21 - because I remember it was like really
372:22 - really large un like unreasonably large
372:25 - and that was the cost involved in it
372:27 - can't find it today it's not a big deal
372:30 - but waiting for the Ami to become ready
372:32 - so if we go over to our Amis here and
372:35 - give us a refresh we can see that it is
372:37 - spinning so it is provisioning that Ami
372:40 - while that is going on what we can do is
372:42 - just start setting up the next part of
372:44 - this so
372:46 - um Within
372:48 - our Packer here we can say new file and
372:50 - I'm going to say main.tf I'm going to go
372:53 - as per usual and grab some default codes
372:56 - from our account example which is for
372:58 - right here
373:00 - okay copy that we're going to go all the
373:03 - way down to the ground here and
373:06 - going to go into the main TF here paste
373:08 - that on in
373:09 - and we probably want to keep the public
373:11 - IP around we actually don't really care
373:13 - but I'm putting it in any way I'm going
373:14 - to take out the tags oh I want to leave
373:16 - the name in so I'll just say like server
373:17 - packer
373:19 - okay server Apache packer
373:24 - and
373:26 - uh this is the thing that we want to
373:28 - replace out this all looks fine so this
373:30 - is what we need to figure out is our Ami
373:32 - here it's probably going to come in as a
373:33 - data source it has to come in as a data
373:35 - source and I'm pretty sure that's what I
373:37 - wrote
373:38 - in our documentation here so yeah AWS
373:41 - Ami example things like that so
373:43 - what we're going to do
373:45 - is Type in AWS
373:46 - am I
373:49 - Packer image
373:51 - and we'll just Define that data source
373:53 - so AWS Ami
373:57 - Packer image
373:59 - and we have executable users executable
374:03 - users equals self
374:06 - I'm not saying I know what all these
374:07 - options do but like you just go to the
374:09 - documentation you grab them you got
374:10 - something that works true name regex
374:14 - okay and so we would do something like
374:17 - start with the little carrot character
374:19 - and what did we name this this starts
374:23 - with uh my server hyphen
374:26 - probably would have helped if we named
374:27 - it with like something like
374:29 - packer in the name but I think that's
374:32 - fine
374:34 - um
374:36 - we might as well might might as well go
374:38 - the full name here
374:40 - and say httpd because that's technically
374:42 - what it's going to be
374:45 - we might want to match for more values
374:49 - here so
374:50 - I'm not sure I guess like we do that
374:55 - because sometimes it's like three digits
374:57 - or whatever but I don't know what Packer
374:58 - is going to do if we keep pushing
374:59 - additional ones I'm not really familiar
375:01 - with with that so we'll just say owner's
375:04 - equals self
375:06 - and so now that should be all set up to
375:09 - go as that is
375:11 - running it finished so that's all good
375:13 - we're going to say terraform init
375:17 - and here it says block definition must
375:20 - have a block content Eliminator
375:24 - so we have a small problem here
375:28 - it looks correct to me
375:32 - uh this is not right okay
375:38 - we'll see if we can knit this
375:44 - now whether our build image works
375:45 - properly I don't know
375:49 - it'd be really good to write like some
375:51 - tests for it I imagine that there is
375:53 - some kind of way to do that
375:56 - um
375:57 - I guess it'd be like the post-processor
375:59 - scripts maybe you'd want to do that
376:00 - where you'd want to use that as a means
376:03 - for
376:04 - testing
376:06 - I'm not really sure obviously different
376:08 - provisioners might have that kind of
376:10 - stuff built in so you know it might be
376:12 - just part of the provisioning tool you
376:14 - can use
376:16 - so it initialized here we're going to do
376:18 - a terraform plan
376:21 - because I'm hoping that it might
376:23 - complain about the data AWS Ami here if
376:25 - it does not exist properly and it did so
376:27 - your Curry return no results please
376:28 - change your search criteria and try
376:30 - again
376:31 - so however I wrote this is probably not
376:34 - correct so I will just take this out
376:36 - here
376:38 - try this
376:47 - data a to the same at Packer no results
376:51 - so what I'll do is go over to
376:54 - bc2 here and actually that's the only
376:55 - name that's here for the Ami so I guess
376:59 - I could just go here and grab the name
377:03 - but maybe that's not the problem oh no
377:06 - that might be fine so we'll just do this
377:13 - name reg X
377:17 - okay
377:18 - so let's go look up data AWS Ami
377:26 - ex couple users most recent name regex
377:29 - owners
377:31 - maybe we can just do like a filter here
377:34 - a regex to apply to an analyst returned
377:37 - by AWS this allows for more advanced
377:39 - filtering not supported by the AWS API
377:41 - this filtering is done locally on the
377:43 - AWS what returns
377:45 - so I suppose that is good but like I
377:48 - just need it to work
377:51 - so I'm going to try the filter instead
377:55 - and I'm actually going to put literally
377:57 - the name in my server httpd
378:00 - I'm going to take out the regex assuming
378:02 - that is the problem
378:09 - owners itself executable users itself
378:12 - um please change the criteria
378:16 - I don't know what executable users users
378:18 - actually does let's maybe look up what
378:19 - that is limit search to users with
378:21 - explicit launch permissions on the image
378:24 - is that required no so let's just take
378:27 - that out
378:30 - if more than one there isn't so let's
378:33 - just take that out for the time being
378:36 - who's the owner of this
378:37 - we're the owner right we have to be
378:40 - honors this IP address that must be us
378:43 - or sorry not IP but like our account
378:45 - number
378:47 - so I mean that should be fine
379:00 - incorrect attribute value type
379:03 - oh okay so that was fine so we'll do dot
379:05 - ID
379:10 - but you know if you're doing this like
379:12 - if you wanted a continuous pipeline
379:13 - you'd probably want to get the most
379:14 - recent and have a better regex
379:18 - um and so I'll do a terraform apply Auto
379:20 - approve and see if this works
379:46 - one thing I kind of Wonder is like with
379:47 - Packer how would you do like a
379:49 - versioning
379:56 - because that's what I'm not certain
379:57 - about so like I'm just kind of like
379:59 - looking through here and seeing what
380:00 - they would do for that I would imagine
380:03 - that uh you're probably supposed to like
380:05 - increment it and have it part of the
380:06 - name
380:07 - nothing's really speaking to me there
380:09 - but you know like
380:11 - the idea is that you want to have things
380:12 - like
380:13 - zero zero zero zero one zero two zero
380:16 - three
380:18 - but I imagine like there's some
380:19 - pragmatic way maybe there's like a
380:20 - built-in function or something that we
380:22 - can do to do that or what you do is you
380:24 - just have a variable probably that's
380:26 - actually what you probably do is you'd
380:28 - have like variable
380:30 - like version
380:32 - right
380:33 - string
380:37 - and then you probably set it and it
380:38 - would come through that way
380:42 - like you you'd set it over here it says
380:44 - our server has finished provisioning
380:46 - let's go C and take see if that actually
380:48 - worked we'll go up to ec2 instances here
380:52 - that is running
380:54 - copy that
380:57 - paste that in
381:03 - um the security group doesn't have any
381:05 - open ports right
381:10 - so it probably did work it's just we
381:13 - didn't create a security group with us
381:14 - so there are no open ports for us to
381:16 - check I'm not worried about this I don't
381:18 - care if it actually did work or not
381:20 - because we more or less followed all the
381:22 - steps there but I believe the reason
381:23 - it's not working like there is just
381:25 - because we don't have a security group
381:26 - but I just don't want to fiddle with
381:28 - that and put it into a state so that it
381:30 - does not match so anyway we're all done
381:33 - here so I'm going to do a terraform
381:35 - apply Auto approve
381:38 - destroy
381:43 - so there we go we accomplished that with
381:45 - Packer that pretty much wraps up all the
381:47 - main follow-ons for the course so
381:50 - hopefully that was a lot of fun
381:52 - um yeah we'll just continue on here
381:54 - [Music]
381:59 - all right so let's talk about
382:00 - terraforming console because you're
382:01 - going to hear console mentioned
382:03 - throughout the documentation and you
382:05 - might think it's critical to the exam
382:06 - but it's not so I just want to make sure
382:08 - we understand its relation to terraform
382:10 - so console is a service networking
382:12 - platform which provides service
382:13 - Discovery so central registry for
382:15 - services in the network it allows for
382:17 - direct communication so no single point
382:18 - of failure via load balancers it has a
382:21 - service mesh so managing Network traffic
382:22 - between Services a communication layer
382:24 - on top of your container application so
382:26 - think middleware it has application
382:28 - configuration capabilities so console is
382:31 - useful when you have a micro service or
382:33 - a service oriented architecture with
382:35 - hundreds of thousands of services so
382:37 - these are containerized apps or
382:39 - workloads and so the way console
382:42 - integrates with terraform is in the
382:43 - following ways it is a remote back end
382:45 - because console has a key value store
382:48 - and this is where you could store the
382:51 - state of your terraform files then also
382:54 - there's a console provider because you
382:56 - can use terraform to set up some things
382:58 - in console for you but there's not much
383:01 - else outside of that okay
383:03 - [Music]
383:08 - all right we're taking a look here at
383:10 - hashicor Vault so vault is a tool for
383:12 - securing accessing secrets from multiple
383:15 - secret data stores vault is deployed to
383:17 - a server where a vault admin can
383:19 - directly manage secrets and we have
383:21 - operators also known as developers can
383:23 - access Secrets via an API Vault provides
383:26 - a unified interface to any secret such
383:28 - as AWS Secrets console key values Google
383:30 - Cloud KMS Azure service principles it
383:34 - provides tights access control so just
383:37 - in time which is reducing surface
383:39 - attacks based on a range of time and
383:42 - just enough privilege so reducing
383:43 - surface attack by providing at least
383:45 - permissive permissions we can also
383:48 - record a detailed audit log so we have
383:50 - tamper evidence so this is kind of the
383:52 - idea of our little hash Decor fault
383:55 - stack so you have your secrets engines
383:57 - these are third-party services or sorry
383:59 - cloud services that actually store the
384:01 - secrets you have your Vault cluster
384:02 - which act as the adapter to your
384:04 - resources and the resources which are
384:06 - going to access them so again vault is
384:08 - deploy to Virtual machines in a cluster
384:10 - and vaults can be backed up via snapshot
384:13 - so if you do provision them and you're
384:15 - worried about the state of those vaults
384:17 - you can definitely save those for later
384:19 - okay
384:20 - [Music]
384:24 - let's take a look here at terraform and
384:26 - Vault how they would work together so
384:28 - when a developer is working with
384:29 - terraform and they need to deploy a
384:30 - provider like AWS they will need AWS
384:33 - credentials so AWS credentials are
384:35 - long-lived meaning a user generates a
384:37 - key in secret and they are usable until
384:39 - they are deleted so the Abus credentials
384:41 - reside on the developers local machine
384:42 - and so the machine is at risk of being
384:45 - compromised by malicious actors looking
384:47 - to steal this credentials so if we could
384:49 - provide credentials just in time expires
384:52 - or credentials after a short amount of
384:54 - time so short-lived we could reduce the
384:56 - attack surface area of the local machine
384:59 - and so this is where Vault comes in
385:00 - because Vault can be used to inject
385:02 - short-lived Secrets at the time of
385:04 - terraform apply so imagine you are you
385:08 - are the developer and you run your
385:11 - terraform apply at that point in time
385:13 - it's going to inject the secrets the way
385:15 - we do that is via data sources data
385:17 - source is always the way we get data
385:19 - into our terraform configuration file
385:21 - but let's look at that in Greater detail
385:22 - in the next slide here okay
385:25 - foreign
385:27 - [Music]
385:29 - let's take a look at how this Vault
385:30 - injection via data source works so a
385:32 - vault server is provisioned a vault
385:34 - engine is configured like AWS Secrets
385:36 - engine The Vault will create a machine
385:38 - user for AWS fault will generate a
385:41 - short-lived AWS credential for that
385:43 - machine user thought we'll manage and
385:45 - apply database policy and then within
385:47 - our terraform we can provide a data
385:49 - source to the Vault so that's what we're
385:51 - doing we're saying Vault Ibis access
385:53 - credentials and we are getting the
385:55 - output from our terraform remote State
385:56 - admin outputs backend and then from
386:00 - there we can reference them into AWS
386:02 - okay so when terraform applies run it
386:04 - will pull short-lived credentials to be
386:06 - used used for the scope of the duration
386:08 - of the current run every time you run
386:10 - apply you will get a new short lived
386:13 - credentials which is the whole point of
386:14 - the short-lived idea okay
386:17 - [Music]
386:21 - hey this is Andrew Brown from exam Pro
386:23 - and we are taking a look at Vault
386:26 - um and so the idea here is that we want
386:28 - to be able to inject secrets from vault
386:30 - in a secure manner for our local
386:32 - developer environments I really kind of
386:34 - wish I included this screenshot or this
386:36 - graphic within my slides I just found it
386:39 - as as of now because it does really
386:41 - represent all the types of secret
386:42 - engines and capabilities of Vault one
386:44 - thing in particular I wasn't aware of is
386:45 - that it has its own key value store so
386:48 - that's what we're going to be using
386:50 - we're going to keep it really simple
386:51 - here
386:52 - um but the first thing we're going to
386:53 - have to do is go ahead and install Vault
386:55 - so just down below I have a link here
386:57 - that I found and we'll go down below and
387:01 - it's not shouldn't be too hard to
387:03 - install so
387:05 - uh we are on Linux today I mean I'm on a
387:08 - Windows machine but I'm using Linux
387:10 - um as the windows subsystem there and so
387:13 - this is where we're going to start and
387:15 - grab our stuff so making my way over to
387:17 - vs code whoops
387:19 - um and
387:21 - I'm just trying to think should we use
387:22 - this for a new project probably so I'm
387:24 - going to just CD out here
387:28 - and I'm going to make my way into
387:30 - uh vault which apparently I don't have a
387:33 - folder for so I'm going to just go here
387:36 - and we're going to
387:39 - uh if I reveal and explore
387:46 - and we'll make a new one
387:50 - 200 volts
387:53 - okay and so
387:57 - we'll start first install something then
387:59 - we'll set up a project all right so
388:01 - um
388:02 - let's go through the installation
388:03 - process here okay so we'll go do a curl
388:07 - which is our first step
388:10 - and that's just going to grab the gpg I
388:12 - think we already have it because we did
388:14 - it for probably the the CLI 4
388:17 - terraform there but we'll just do it
388:19 - again there it doesn't hurt I'll add the
388:21 - repository again I think we already did
388:22 - this when we installed the CLI in the
388:24 - beginning of this course
388:27 - but we'll let it go again there I
388:28 - remember this takes a little bit of time
388:30 - so we'll just wait here for a bit
388:36 - all right so now we need to run the last
388:38 - command which is actually going to go
388:39 - ahead and install Vault here for us
388:41 - we'll just go ahead and grab that line
388:43 - and I'm going to go ahead and paste that
388:45 - on in
388:47 - I'm not sure if I grabbed that properly
388:49 - we'll try that one more time
388:51 - it uh I got my consoles on response so
388:54 - there we go okay
388:55 - just happens when I um I stop and start
388:57 - recording it just for some reason times
388:59 - out like that so I'll go ahead and hit
389:01 - enter there and that will go ahead and
389:02 - install our vaults and then after that
389:05 - we're going to have to start getting it
389:06 - running
389:07 - um there is again a tutorial to inject
389:09 - secrets I'm not going to stick one to
389:10 - one with it because it does come with a
389:13 - repository but I find that it is a
389:15 - little bit more work than we want to do
389:16 - here we just want to kind of get a basic
389:18 - example working and I just want to make
389:21 - our lives a little bit easier so I'm
389:22 - just going to modify it as we go here
389:25 - but uh yeah we'll just wait for that to
389:27 - install I'll see you back here in a
389:28 - moment okay all right so after a short
389:30 - little weight here I believe that vault
389:33 - is installed let's find out if it works
389:34 - so we'll type in Vault
389:36 - once I get the responsiveness back from
389:39 - my console here just giving it a moment
389:41 - great nope nope there we go Vault and so
389:45 - vault is there and so what we can do is
389:47 - start it up in a developer mode and I
389:50 - remember from here they actually had
389:51 - some pretty good instructions on the
389:52 - starting of that so
389:56 - um like the way they do this project and
389:57 - I have the repo here is that they
390:00 - um they provision Vault with a bunch of
390:03 - different things so I think they're
390:04 - using like S3 here and that would
390:06 - probably be a really common use case for
390:09 - this but I really want to simplify and I
390:11 - don't want to have to provision that
390:13 - terraform and cross-reference the stuff
390:15 - so we're just going to simplify that so
390:18 - I'm just looking for the command to
390:19 - start fault because I saw a good one
390:21 - here that was like vaults
390:25 - um ah here it is right there so Vault
390:27 - server hyphen dab that starts in the
390:28 - developer mode Dev root token ID there's
390:31 - something about like ceiling or
390:32 - unsealing stuff I don't know what that
390:34 - means but I assume that's a way of
390:35 - securing the Vault but we're going to go
390:36 - ahead ahead and just type that in so
390:38 - we're going to go Vault server hyphen
390:41 - Dev hyphen Dev root token ID and
390:44 - obviously you wouldn't want to do this
390:45 - for your production they call there's
390:46 - education I'm just going to stick with
390:48 - that to make our lives a bit easier and
390:49 - so what that's going to do is start up a
390:51 - vault server it is running on this port
390:54 - here so I suppose we should export that
390:57 - or or keep this because we'll probably
390:59 - have to reference it somehow notice we
391:01 - have this like unsealed key so the
391:03 - unsealed key and root token are
391:04 - displayed Below in case you want to seal
391:06 - or re-authenticate
391:08 - um developments should not be used in
391:09 - production so what I'm going to do
391:11 - is I'm just going to create a
391:14 - uh uh a readme file in our vault here so
391:20 - we'll just say new file read me because
391:22 - I just want to dump this stuff of course
391:23 - you know you should not share these with
391:25 - anybody but I just don't want to forget
391:27 - these while we're working through this
391:29 - so I'm going to go ahead and copy that
391:32 - and we will go ahead and save that
391:35 - and
391:36 - so
391:38 - what I want to do now oops
391:41 - did we lose our terminal
391:44 - did I close it
391:46 - okay I must have closed it so which one
391:49 - were we working in second third one
391:51 - which is it
391:53 - fourth okay it's the third one so
391:56 - don't be like me close out your old one
391:57 - so I'm just gonna close out these old
391:58 - ones so I'm less confused
392:02 - there we go and so it says that it
392:04 - started on this address here so I'm
392:06 - gonna go copy that address
392:08 - and we're going to open this up you can
392:10 - do everything via the CLI
392:14 - uh I just want to
392:17 - copy that there
392:19 - but they have a nice UI which is nice
392:20 - and so this is where we're going to put
392:21 - that token education and drop that down
392:24 - so there are some other options where
392:26 - there's a lot of options for
392:27 - authenticating but token is obviously
392:29 - the easiest probably not the most secure
392:30 - because the way we wrote it and notice
392:32 - that we have a couple things
392:33 - pre-installed so we have cubbyhole which
392:36 - is a per token private secret storage
392:38 - and then we have key value secret
392:40 - storage again I don't know much about
392:42 - these because this isn't a um
392:45 - this isn't a course on vault it's just
392:47 - kind of us showing a basic integration
392:49 - and more focus on the terraform side but
392:51 - here is where we can create our secrets
392:52 - we can of course use the CLI to do that
392:55 - and I think they showed in the getting
392:57 - started here
392:59 - and we don't have to do it this way I'd
393:02 - rather do it through your eye but you do
393:03 - like vault key key V put and then you
393:06 - put the name of your secret so here's
393:08 - secret forward slash hello and then the
393:10 - key and the value that's where the store
393:11 - I assume that this would go to the well
393:13 - this would specify we're using here so
393:16 - what we'll do is we'll go over here
393:18 - and we'll create ourselves a new secret
393:19 - because we're going to want to store
393:20 - something here so we want the path for
393:22 - the secret
393:23 - this is pretty common with um if you've
393:25 - ever used parameter store you have a
393:27 - path
393:28 - I don't know if it starts with a forward
393:29 - slash
393:30 - may not end in a forward slash probably
393:32 - can begin with it so I'm going to say
393:33 - AWS key because we'll do the key in the
393:36 - secret right so here
393:39 - oh okay cool cool so we can do forward
393:41 - slash AWS and then down below I would
393:44 - just add another one
393:45 - maybe I got to add each one at a time so
393:47 - we'll say key
393:49 - and I'll actually go grab our proper
393:51 - ones
393:53 - um oh I should have stopped that I'm
393:55 - going to
393:56 - start that up again
393:58 - okay and we'll add a plus there because
394:00 - everything lives in memory when you're
394:02 - in the dev one so you really don't want
394:04 - to shut that down or you'll have to redo
394:05 - all this from scratch so what I'm going
394:07 - to do is just go back
394:09 - here and drag this down a little bit
394:12 - more
394:14 - okay and I'm just gonna go see if I have
394:16 - to re-log in because I might have messed
394:17 - this all up
394:19 - yes I do so we'll type in education so
394:21 - we really don't want to stop running
394:22 - that server during the duration of this
394:25 - follow along okay and so we'll go back
394:28 - into secret here create a secret
394:31 - forward slash AWS
394:33 - uh what do you want is it Json no I
394:36 - don't think it matters
394:37 - if we can add two keys that's all that
394:39 - matters to me and so what I'm going to
394:41 - do
394:42 - is cat out
394:45 - credentials of course this is not the
394:46 - secure way of doing it so you know again
394:48 - don't show people these things and so I
394:50 - want this and I probably should match
394:52 - the name
394:53 - I'm gonna like type in the whole darn
394:54 - thing
394:56 - and we'll grab this
394:59 - oops
395:01 - I want to see that value is correct good
395:03 - we're going to add another one here this
395:04 - is going to be our axis Secrets or axis
395:08 - secret access key I really don't like
395:09 - how those have been named and we'll go
395:11 - ahead and grab on this
395:17 - and
395:18 - um I mean we don't really need to really
395:20 - store the region here but why not
395:22 - because we're doing all the rest to here
395:23 - we might as well just throw them all in
395:25 - here
395:27 - for fun
395:30 - and uh here it says maximum number of
395:32 - versions I don't need anything beyond
395:35 - one because we're not going to be
395:36 - updating these
395:38 - um require check and set so rights will
395:40 - only be allowed if the keys current
395:42 - version matches the version specified in
395:44 - the cas parameter not sure what that
395:46 - means maybe just like you're passing
395:47 - something along when you are doing
395:49 - something but uh I think this is all
395:51 - good
395:52 - you know what I'm just going to leave
395:53 - that back to 10 just in case I've made a
395:55 - mistake and we have to go debug that I'm
395:56 - going to go hit save and so there are
395:58 - secrets
396:00 - um and so what we want to do is be able
396:03 - to access them and so maybe this is our
396:05 - opportunity to learn the CLI here a bit
396:07 - so I have it pulled up on the left hand
396:09 - side and so what I'm going to do is type
396:10 - in vault key V get and we'll do AWS I
396:15 - don't know if we can start with the
396:15 - forward slash there I'm going to hit
396:17 - enter
396:19 - and
396:20 - um the server gave an HTTP response to
396:22 - an https client
396:24 - so I'm not sure
396:28 - why that's a problem because
396:30 - like I mean I understand that it started
396:32 - up in HT http
396:34 - but I mean I'm in development so you
396:37 - know what else am I going to really do
396:38 - here
396:39 - let's see if I can just scroll up here
396:41 - and if there's anything else
396:44 - um
396:45 - hmm
396:48 - and I could have swore that it installed
396:50 - a private key as we were doing this
396:51 - because I remember seeing that there
396:54 - was like a private key
397:00 - I could have swore there was one
397:01 - something but private key
397:03 - so I'm not sure what the problem is here
397:05 - I'll be back in a moment and I will
397:07 - resolve it okay
397:08 - so the suggestion I'm getting is that we
397:11 - need to
397:12 - um export a couple of environment
397:14 - variables
397:16 - so see here where it writes this so we
397:18 - say you need to set the following so
397:20 - maybe we will go through and set those
397:22 - so I'll go grab that there but here's
397:25 - the thing is like how do I run that
397:29 - because these are I think these are like
397:32 - not the same so I mean I can't run it
397:34 - over here can I
397:36 - I don't think so
397:38 - uh well I guess if we're doing key Vault
397:41 - value there maybe we can
397:45 - um still no good what if we export The
397:48 - Vault token
397:51 - I think we said it was education here
397:55 - um
397:59 - let's do Vault status
398:04 - so yeah I'm not sure how we're going to
398:05 - do it that way I mean it's not a really
398:07 - big deal because I don't think that we
398:09 - have to access it that way but notice
398:10 - here like as I was reading here you know
398:15 - they're just saying down below oh we had
398:17 - to set this and that so I'm not really
398:20 - sure
398:23 - what I would do here so the output is
398:25 - like this
398:26 - run these commands and it should do it
398:28 - again the error message can be similar
398:30 - to different problems so that or maybe
398:32 - I'm just specifying the key incorrectly
398:33 - and that's why it doesn't like it so
398:36 - [Music]
398:37 - um
398:38 - let's just type in Vault and see what we
398:39 - have here so Vault QV
398:42 - maybe if we do like a list can we get a
398:43 - list
398:45 - list the secrets
398:49 - um AWS
398:51 - AWS
398:53 - clear
398:57 - I'm not sure what parameter it wants
398:59 - there
399:01 - uh let's go look it up so let's say like
399:04 - tariff or was it vault key V list option
399:11 - seems to want another parameter here
399:13 - I'm going to scroll on down so Secret
399:17 - forward slash my app
399:22 - um folders are suffixed with the forward
399:24 - slash the input must be a folder list of
399:26 - a file will not return
399:29 - um do I have to put Secret in front of
399:31 - it
399:33 - Secret
399:38 - AWS
399:40 - no so I don't know what the issue is
399:42 - there I just would have been nice to use
399:44 - it via the CLI but the thing is is that
399:46 - again we don't need to use it that way
399:48 - we just need to
399:50 - um you know set it and and get it but I
399:53 - thought it would be fun to kind of see a
399:54 - lie there so now that we have those set
399:57 - the way we're going to extract out these
400:00 - values is by using a data source and so
400:03 - what I want to do is just create a new
400:06 - local project and I think we'd like to
400:08 - always pull from our account repo here
400:09 - so I'm going to go all the way up to
400:10 - here and I'm going to go grab the main
400:12 - and I'm just going to copy the contents
400:15 - there we're going to go all the way down
400:17 - to the ground and we're going to make a
400:20 - new
400:21 - main TF file here
400:24 - we're gonna go paste that on in
400:27 - and uh we just want my server
400:31 - we don't need an output it's fine
400:33 - this is all fine this is all fine but uh
400:36 - the one thing is we don't want to use
400:38 - our particular provider there so what
400:39 - I'm going to do
400:41 - um is I'm going to just open up our
400:47 - credentials file there
400:51 - and I'm just going to change this to
400:53 - something else like other so that it
400:55 - doesn't load that profile there
400:57 - okay I just
400:59 - take these out of here
401:02 - um I think we can leave that alone
401:05 - and I think that's everything so what I
401:08 - want to do now we don't need that count
401:10 - we'll get rid of that count
401:12 - we'll go check out the documentation or
401:15 - the code base here
401:17 - because it gives us a bit of an idea how
401:19 - we need to implement this
401:21 - we'll go over the operator
401:23 - we'll go over to the main
401:26 - and so they're setting some variables
401:27 - here like name region path things like
401:29 - that but again we want to grab it from
401:31 - The Source there actually
401:33 - cross-referencing it like this other
401:35 - they provision the admin and grabbing it
401:36 - that way I don't want to do it that way
401:38 - I wanted to use just the data source
401:39 - like this
401:41 - so
401:43 - I'm not sure how that's going to work so
401:46 - let's go look that up
401:54 - okay so here it says read it was
401:56 - credentials from an AWS secret back end
401:59 - and I'm not trying to do that I'm just
402:01 - trying to read them from the key vaults
402:03 - okay so we probably want faults
402:09 - generic secret would this be from Key
402:11 - vault
402:15 - this resource is primarily intended to
402:17 - be used with the generic secret back end
402:18 - but it is also compatible with any Vault
402:20 - endpoint that is provided
402:23 - but is that the key value one that's not
402:26 - clear to me
402:30 - um so I think it is
402:33 - so let's see if we can figure that out
402:34 - here so I'm just going to move that off
402:36 - screen here
402:37 - and we're going to add ourselves the
402:39 - data source so I guess we're really not
402:40 - following the other tutorial at all
402:42 - because it we literally have to use a
402:43 - different
402:44 - um
402:45 - key value there a
402:47 - so we'll say secrets and this is going
402:50 - to be like AWS
402:52 - credentials Maybe
402:55 - there's creds they don't have to worry
402:57 - about spelling mistakes and we need to
402:59 - specify a path notice it always starts
403:01 - with like secret I don't know if we
403:02 - always have to start it with secret so I
403:05 - will just say AWS here
403:08 - and there might be some additional
403:10 - options I'm just scrolling through to
403:11 - hear that so you have paths so this is
403:14 - the fully the full logical path from
403:16 - which to request the data to read data
403:18 - from generic secret back in Mountain
403:19 - Vault by default this should be prefix
403:21 - with secret forward slash so we do have
403:22 - to do that reading from other back ends
403:25 - as data sources possible consult each
403:27 - back-end documentation to see which
403:28 - endpoint supports the get version
403:31 - version of the secret to read we only
403:33 - have a single version so we don't have
403:35 - to specify that so technically that
403:38 - should be correct
403:40 - so what we will want to do now in our
403:42 - provider is specify all those options
403:44 - so again I'm just going back to the
403:46 - source code this is off screen but we
403:48 - need to set the region the access key
403:52 - and the secret key here
403:56 - and so this is going to be data and it's
403:59 - going to be
404:01 - Vault generic Secret
404:04 - and I guess it would be AWS
404:09 - and then we're accessing those things
404:10 - like region
404:13 - and so I'm going to go ahead and just
404:14 - copy that really quickly
404:20 - and we will go over back to our vault
404:23 - here because the names are over here
404:25 - so go grab that paste that in there
404:29 - we'll go grab that paste that in there
404:33 - and I'm just going to double check to
404:35 - make sure if I've made any mistakes
404:39 - this one it's showing it from the admin
404:41 - so it goes admin outputs but we're not
404:42 - outputting from anything we're just
404:43 - grabbing it from uh the Vault there so
404:46 - maybe what we need to do is just kind of
404:48 - review
404:49 - how this generic fault works
404:52 - so this does Data Vault generic and then
404:55 - it does data and then Square braces
405:00 - so I wonder if we always have to do data
405:03 - so for example The Vault there is a a
405:05 - key named auth token the value is a
405:07 - token that we need to keep Secret
405:09 - but yeah I don't understand is this a
405:11 - Json object or just a way of referencing
405:13 - it because it doesn't specify that so
405:15 - we'll just give it a try
405:17 - nothing hurts with trying right so we'll
405:19 - say data
405:21 - and this might again might not be the
405:22 - right way I don't know if it's single or
405:24 - doubles there it's doubles
405:27 - so I just wonder if that was like the
405:28 - one case where it's doubles
405:34 - okay and we will do this
405:38 - and so I think that that should
405:40 - maybe work
405:42 - don't know
405:43 - what I'm wondering is if I if I live
405:45 - with a forward slash would it have
405:46 - considered that and or is it now double
405:49 - but I don't think so because look here
405:50 - it looks like it's stripped it out
405:52 - because it just says AWS here so we got
405:53 - a secret since just AWS
405:55 - almost looks like there's a space in the
405:57 - front of it eh
405:58 - but it's not there so maybe there's not
406:00 - this is kind of like a little glitch so
406:04 - um
406:05 - we need to go and CD into this directory
406:08 - here
406:09 - and we just need to do a terraforming
406:11 - knit
406:13 - that's kind of interesting because like
406:15 - we haven't set up the provider
406:17 - I guess it's not going to happen until
406:18 - we actually use the provider so maybe
406:19 - it's not an issue just yet
406:23 - I'm curious to see if it pulls any kind
406:25 - of modules in for the vault generic
406:26 - Secret
406:29 - so we'll just give it a moment there to
406:30 - initialize
406:38 - okay so after there we can see that it
406:40 - did actually add vault in so it must be
406:42 - ready to take it from there
406:45 - um I'm going to do a terraform plan here
406:48 - and you know I'm going to just change
406:49 - this to like my server with vaults
406:53 - now remember it's not going to be able
406:54 - to pull from the um
406:58 - from our local credentials because we're
406:59 - not setting a profile and we overroad
407:01 - the default just in case
407:02 - so here it's saying a resource a data
407:04 - resource Vault generic secret AWS has
407:07 - not been declared in the root module
407:09 - um it hasn't I mean it looks like I did
407:12 - no maybe I typed it wrong so we'll go
407:16 - here I don't think it matters but I'll
407:20 - just put it above
407:21 - okay and I'm just going to double check
407:24 - to make sure nope it matches oh because
407:26 - it's eight of his creds that's fair
407:47 - um you didn't use the option o that's
407:48 - fine so my question will be will this
407:50 - correctly provision because we will not
407:52 - know until we uh use this right here I
407:56 - suppose if we try to use a data source
407:59 - for AWS that would probably also
408:01 - indicate whether it's working or not so
408:02 - maybe we should try doing that
408:04 - we do like data AWS VPC
408:08 - and then we just do like ID equals here
408:12 - because that would have to use the
408:13 - credentials right
408:15 - and so we'll just go well that's
408:18 - actually it's not specifying any of the
408:20 - the VPC here so maybe maybe we won't do
408:23 - that because it's just too much work
408:25 - um so what I'll do here
408:28 - is I'm going to do a terraform apply
408:31 - Auto approve
408:33 - and Let's cross our fingers and hope
408:35 - this works
408:43 - and while that is running what I'm going
408:45 - to do is just pull up my AWS environment
408:47 - here
408:56 - and apparently I'm not logged in so
408:58 - that'll give me a bit of time here to
408:59 - kind of catch up here while this is
409:00 - provisioning there
409:19 - and so it looks like it actually
409:21 - provisioned the server and if that's the
409:22 - case that means that our secrets are
409:24 - being pulled correctly right so if we go
409:26 - over to ec2 here
409:32 - and we go and check out this instance it
409:35 - is running so it worked
409:38 - um if we just want to do a sanity check
409:40 - to make sure it absolutely is working we
409:41 - can just introduce a bug into this
409:43 - so maybe we go here and we just say
409:48 - uh um I guess we'd have to make a new
409:50 - version create a new version and what
409:52 - I'm going to do is purposely introduce
409:53 - some mistakes so we're just going to put
409:54 - like an at sign here on the end we're
409:56 - going to save that and I'm going to make
409:59 - a minor change like Nano
410:01 - and so what I'm expecting is for this to
410:04 - fail let's see if it fails on the plan I
410:05 - don't think it will
410:10 - give it a fail in the apply and it does
410:13 - okay so the plan would tell us whether
410:14 - it didn't work or not so that clearly uh
410:17 - clearly means it absolutely is pulling
410:19 - from it especially when we're doing the
410:20 - plan
410:21 - so
410:24 - um I want to go back to
410:26 - our file there I just kind of lost the
410:28 - folder I'm just looking for it the I got
410:31 - too many um too many Chrome windows open
410:33 - here
410:35 - there it is okay so we'll go back here
410:37 - and we'll
410:39 - I wonder if we can just revert back to
410:40 - the previous version
410:44 - um see I don't know if I would delete
410:45 - there I don't want to I don't want to
410:47 - jinx it so I'm just going to go here
410:50 - and take out that at sign we're going to
410:52 - go ahead and save that and so that
410:53 - should be updated we're going to do
410:54 - terraform plan
411:04 - great and so what I want to do is just
411:06 - tear this down so we'll say terraform
411:08 - apply Auto approve and Destroy okay and
411:13 - while that is destroying I'm pretty
411:14 - pretty confident that's going to work
411:16 - I'm going to stop my Vault server oh
411:18 - wait
411:19 - is that going to still work did I get
411:21 - the credentials in time
411:22 - oh no I I made a big boo-boo okay so
411:27 - um
411:28 - I I Killed My Vault server before I was
411:31 - supposed to
411:34 - that's really embarrassing
411:36 - um anyway that's not a big deal because
411:37 - I kind of wanted to stop the server
411:39 - anyway
411:40 - but I want to go back into our it was
411:42 - credentials there and turn that back to
411:45 - defaults
411:46 - and I wanted to go back up here and just
411:48 - flip that back so that we can get rid of
411:50 - the server right so I don't want to kind
411:52 - of lose these for the tutorial so I'm
411:54 - just going to go here and just comment
411:56 - those out for a second
411:58 - profile defaults
412:02 - oops
412:04 - region
412:06 - Us East one
412:09 - and
412:10 - um we'll do that again that's
412:12 - embarrassing
412:19 - okay and I'm just going to preemptively
412:21 - I'm not going to save this file but I'm
412:22 - just going to do this for now
412:26 - um it's still trying to connect
412:28 - oh boy
412:32 - so
412:35 - just put these back in here
412:39 - because it's set to the Vault can I do a
412:41 - terraform refresh probably not
412:46 - no probably not what if I do a
412:48 - terraforming net because I did change
412:49 - like I was using Vault so maybe I just
412:51 - have to do that to fix that problem
412:54 - and let's try destroy again
413:03 - that was a big boo-boo on my part eh
413:06 - nope okay so let's go back over here
413:11 - and start it up again and I'm pretty
413:14 - sure there's like a way to back up your
413:16 - vaults like there's probably some kind
413:17 - of like snapshot or something
413:19 - um again I'm not that uh deep into it so
413:21 - I cannot tell you if that's the case
413:24 - um so I guess we'll just go back here
413:26 - and remake our secrets
413:30 - because it shouldn't have persisted
413:31 - right
413:33 - if it did I'd be so happy
413:35 - nope okay
413:38 - AWS we'll leave 10 in there and then
413:41 - we'll just have to copy all this stuff
413:42 - over again because of my
413:44 - bonehead mistake there so we have region
413:48 - which is Us East one
413:52 - U.S east one here
413:56 - and uh
414:03 - go over here
414:09 - well at least you know what to do if
414:11 - that happens to you okay
414:13 - I don't need the uh equal sign there
414:18 - go ahead and add this one
414:36 - okay and what we're going to do is go
414:38 - ahead and save that
414:41 - and we'll just quit out of that we'll do
414:43 - a terraform plan
414:47 - since we know that that will pick it up
414:48 - right
414:54 - and uh we'll do terraform apply Auto
414:57 - approve destroy
415:00 - Okay so
415:02 - again this only applies to development
415:03 - but uh yeah don't kill your Vault server
415:06 - before you're done destroying okay
415:08 - so I'll see you back here in a moment
415:10 - all right so that infrastructure is
415:12 - destroyed we can go back to here and
415:14 - then we can stop our server and for your
415:16 - benefit I'm just going to bring back
415:18 - these in here
415:19 - so you don't have to worry about that
415:21 - and uh yeah we uh we accomplished Vault
415:24 - for injections now you might say well
415:25 - how would you do this with terraform
415:27 - Cloud well the thing is is that
415:28 - terraform Cloud already uses
415:30 - uh Vault Under the Hood when you store
415:32 - your environment variables there and the
415:34 - idea is that uh I suppose you don't need
415:36 - to pull them in from all those sources
415:38 - but I think that was one of my my
415:40 - questions I had when I was talking to
415:41 - one of the DA's which was like okay it's
415:43 - great that terraform cloud has
415:46 - um uh you know uses behind the scenes
415:48 - but what if I want that to live
415:49 - somewhere else but maybe that's not
415:51 - really necessary
415:53 - um because I don't know but yeah that's
415:55 - it so we're all done with vaults
416:00 - hey this is Andrew Brown from exam Pro
416:02 - and we are taking a look at Atlantis
416:04 - which is an open source developer tool
416:05 - to automate terraform pull requests
416:07 - which you can find at run atlantis.io so
416:09 - the idea is once this is installed on
416:11 - your GitHub and you merge a pull request
416:13 - then it's going to go ahead and do a
416:16 - terraform apply so this would be a way
416:18 - for you to do
416:20 - um get Ops or to automate your uh your
416:23 - infrastructure as code and the
416:25 - interesting thing is that hashicorp
416:27 - actually maintains this project they
416:29 - didn't originally build it was built by
416:31 - two people from another company and it
416:33 - wasn't that they did not want to use
416:35 - terraform Cloud which can do this but at
416:38 - the time I think they had a hard time at
416:40 - the company getting procurement because
416:41 - it was a very large company and so they
416:44 - had to build something so they built out
416:45 - this thing
416:46 - and anyway these two people end up
416:49 - getting hired by hashicorp and hashicorp
416:50 - maintains this project which is really
416:52 - nice because it is an alternative for
416:54 - terraform Cloud
416:56 - um but uh yeah that's all
416:59 - foreign
417:01 - [Music]
417:02 - let's take a look at cdk for terraform
417:04 - and so to understand this we need to
417:06 - First understand what is cdk so AWS
417:09 - Cloud development kit is an imperative
417:11 - infrastructure as code tool with sdks
417:13 - for your favorite language so the idea
417:15 - is that you can use something like
417:16 - typescript python Java c-sharp go and
417:20 - Ruby Ruby's definitely there that's the
417:22 - language I like to use AWS cdk is
417:24 - intended only for AWS Cloud resources
417:26 - because cdk generates a cloud formation
417:29 - so CFN templates this is known as
417:31 - synthesizing and uses that for IAC but
417:34 - cdk for terraform is a standalone
417:36 - project by hashicorp that allows you to
417:38 - use cdk but instead of CFN templates it
417:40 - generates out it's going to generate
417:41 - terraform templates and so basically
417:43 - anything terraform can do you can do it
417:45 - through cdk and that allows you to do
417:48 - interesting things like use cdk to
417:51 - provision Azure resources so that is
417:53 - very interesting uh and a great
417:56 - development that I think that they're
417:57 - doing
417:58 - [Music]
418:02 - hey this is Andrew Brown from exam Pro
418:04 - and we are taking a look at grunt work
418:06 - which is a software company that builds
418:07 - devops tools that extends or leverages
418:09 - terraform the reason we're talking about
418:11 - them is that they produce a couple of
418:13 - very popular open source tools that work
418:15 - with terraform and you're going to see
418:16 - their name because
418:18 - um uh you know the co-founders there are
418:19 - very active in the community uh Jim has
418:22 - wrote in a really good book on terraform
418:24 - so you know it's no surprise that uh
418:26 - they are present but it's worth giving
418:28 - them a mention so you know who they are
418:29 - uh the first thing I want to mention is
418:31 - the infrastructure is the code Library
418:32 - so these are a bunch of reusable battle
418:34 - tested production ready infrastructure
418:36 - code for AWS gcp Azure
418:38 - um and so they have some free ones there
418:40 - and some paid ones there then there's
418:42 - teragram so a thin wrapper that provides
418:44 - extra tools for keeping your
418:45 - configurations dry we have terror tests
418:48 - a testing framework for infrastructure
418:49 - provisioned with terraform we have grunt
418:52 - work Landing zones for AWS this is a
418:54 - multi-count security on AWS we have
418:56 - grunt work pipelines and then there's
418:58 - the grunt work reference architecture
419:00 - and so where we're going to focus our
419:02 - attention in here is just on Terra Grunt
419:04 - and Terra tasks because those are things
419:06 - I think are essential to know if you are
419:09 - using terraform because you know you'll
419:10 - run into those use cases where you might
419:12 - want to use them okay
419:13 - [Music]
419:18 - all right let's take a look here at
419:19 - teragram so this is a thin wrapper for
419:21 - terraform that provides extra tools for
419:23 - keeping your configuration dry working
419:25 - with multiple terraform modules managing
419:27 - remote State and this is accessible to
419:30 - tariff Terra
419:31 - grunt.gruntwork.io so the idea here is
419:34 - the concept of don't repeat yourself so
419:36 - it's a programming methodology to
419:38 - abstract repeated code into functions
419:40 - and modules or libraries and often in
419:42 - isolate files to reduce code complexity
419:44 - efforts and errors so the way that works
419:46 - is that you'll see these HCL files which
419:48 - are the Terra grunt code and they're
419:50 - actually named Terra grant.hcl and
419:52 - that's what's going to be used to
419:54 - abstract away or dry up your terraform
419:58 - files so here is an example of Terror
420:01 - run now Terra Grant does a lot of
420:02 - different things and you're going to
420:05 - find its use when you actually use
420:07 - terraform and practice and you run into
420:08 - these limitations in terraform and you
420:11 - go and I wish there was a way around it
420:13 - integrine like almost always solves that
420:15 - and so one example is being able to
420:17 - generate rate Dynamic providers and I
420:20 - don't mean like Dynamic values here in
420:22 - the sense that there's that Dynamic
420:24 - value feature of terraform but I just
420:27 - mean the fact that at the time of this
420:29 - it's very hard to inject or to write out
420:33 - providers so they have this generate
420:35 - function that allows you to get around
420:36 - that
420:37 - another really interesting thing is that
420:39 - Terra grunt supports better granular
420:41 - literary for modules by reducing lots of
420:44 - boilerplate uh the way they do this is
420:47 - is that you are referencing your
420:48 - terraform files uh via the source here
420:50 - okay so you're not including your
420:52 - modules within your code you're just
420:54 - referencing them and then you pass along
420:56 - their inputs and this is going to be
420:58 - very important when we look at wanting
421:00 - to write unit tests for your
421:01 - infrastructure because when you learn
421:03 - about how you test IAC you have to
421:06 - really break things down into smaller
421:07 - parts and if you have a lot of friction
421:09 - there it's going to make your team not
421:11 - want to adopt that or it's going to make
421:13 - that process really slow but again this
421:16 - is more like at scale or when you hit
421:17 - these kind of requirements okay
421:19 - oh
421:23 - [Music]
421:24 - all right let's take a look here at
421:26 - testing and terraform and so what we
421:27 - have here on the left hand side is our
421:29 - usual
421:30 - um pyramid that tells us the layers of
421:32 - testing and so I kind of want to walk
421:34 - through the layers there and talk about
421:36 - a bit of the tools that are available to
421:38 - the terraform community and you know the
421:40 - reason why we want to move up the
421:41 - pyramid here to get uh better tests and
421:44 - then we'll take a look at Terra test so
421:45 - at the bottom we have static analysis
421:47 - and this is where you test your code
421:48 - without deploying and you've been doing
421:49 - it all along when you do terraform
421:51 - validate terraform plan or you're using
421:53 - Sentinel you're doing static analysis
421:56 - and that just means that we're testing
421:58 - you know like the composition or the the
422:01 - shape of our code or like its outputs to
422:04 - what it says it should be doing okay but
422:06 - you can't catch all your problems there
422:08 - and that's where you move on to unit
422:09 - testing and unit testing uh you know
422:11 - traditionally means like in programming
422:13 - to test like a particular function its
422:15 - inputs and its outputs it's a little bit
422:18 - harder for infrastructure because
422:20 - um you know you have to have it
422:22 - connected to other things so it the
422:24 - definite sessions a little bit warped
422:25 - but the idea here and specifically with
422:27 - terraform is you're just testing a
422:28 - single module and that really says like
422:31 - okay well you need to really Pare down
422:33 - that module to be of the small scope and
422:36 - that's where you end up dividing your
422:37 - modules into very small units of work
422:40 - and so for tooling here we got Terra
422:42 - Test Kitchen uh terraform and inspec
422:46 - um and so uh yeah that's where that
422:48 - motivation came with um you know Terra
422:50 - Grande the last thing saying okay let's
422:51 - split them up into smaller stuff uh we
422:53 - have integration testing this is pretty
422:55 - much just using multiple
422:57 - um uh modules together you know so you
423:01 - say okay well I know that this Lambda
423:03 - function is working but do I know it
423:04 - works in conjunction with this sqsq or
423:06 - something like that then you have
423:08 - end-to-end testing and this is where
423:09 - you're testing basically like business
423:11 - use cases so it's not just saying okay
423:13 - from a technical perspective but from a
423:15 - business use case do or the customer use
423:17 - case do we meet the requirements here uh
423:20 - and this uh is very hard because what
423:22 - you have to actually do is set up a
423:23 - persistent test Network environment but
423:25 - once you have one you're going to be
423:27 - really good shape one example of a test
423:30 - environment and it is paid but
423:32 - groundwork has their own called the
423:33 - grunt work reference architecture uh but
423:36 - you know if you had to do it without
423:38 - that you'd have to just roll your own
423:39 - kind of environment
423:40 - so you know if you do want a good
423:43 - breakdown of all these different kinds
423:44 - uh you know Jim from grunt work has a
423:46 - complete talk on automated testing for
423:48 - infrastructure as a code I strongly
423:50 - recommend it because it really gives you
423:51 - a better scope than what I can cover
423:53 - here
423:54 - um but let's just go take a quick look
423:55 - at Terra test so Terra test allows you
423:57 - to perform unit tests and integration
423:58 - tests on your infrastructure it tests
424:01 - your infrastructure by temporarily
424:02 - deploying it validating the results then
424:04 - tearing down the test environment and so
424:06 - here's an example of what a a test
424:09 - function would look like in Terror test
424:11 - it is written in golang I know golang
424:13 - can be very hard to use but you don't
424:15 - need to know much about it if you you
424:17 - pretty much copy and paste it and just
424:19 - kind of tweak the values to get the
424:20 - result you want so you know hopefully
424:22 - that helps to tell you how you would
424:24 - test in terraform and you know that
424:25 - about Terra test okay

Cleaned transcript:

hey this is Andrew Brown over here on free cocam bringing you another free Cloud certification and this time it's the hashicorp terraform associate version three and the way we're going to achieve certification is through lecture content HandsOn labs and as always I provide you a free practice exam and so at the end of the day you're going to get that certification and you could put it on your resume on your LinkedIn to demonstrate that devops skills and try to go get that cloud or devops role you've been looking for or trying to upgrade to so if you like the materials here a great way to support more content like this is to look at the paid additional materials it will also help you increase the odds on your exam and it also really does help out and support the production of more of this kind of content and if you are not familiar with me I produce a lot of different kinds of cloud certification courses like AWS Azure kubernetes you name it I've taught it and so you're in really good hands and we'll see you in class soon ciao foreign everybody it's Andrew Brown and welcome to the start of our journey and we're asking the most important question first which is what is terraform and I just want to tell you that I'm on screen now but I'm going to vanish here shortly and stay out of the way so that you can see the full content but I just wanted to know you to know that I'm here with you the entire way okay so the terraform associate certification is a specialty certification in terraform terraform is a technology produced by hashicorp and it's specifically for infrastructures of code and it's a declarative infrastructure as a code and it's a cloud agnostic infrastructure as a code we will dive into all of this in great detail in the introduction section and just notice that I put an asterisk there on declarative because there is something special about terraform that we will discover if you are considering the terraform associate then you most likely are looking for a devops role you want to automate infrastructure or writing scripts you want to work with multiple Cloud providers or you know you enjoy designing iterating on endtoend infrastructure life cycle so if this sounds like anything that you are interested in then you would probably want to take this certification I want to tell you that terraform is one of the most indemand skills for devops rules today and it's becoming quickly the industry standard just because it is so flexible and works with all providers and goes beyond a lot of these other tools and the terraform associate exam itself isn't that difficult uh but I would say that the concept of learning terraform is a bit tricky because uh you know it's not something that you can just go do the lecture content uh and and do the lab content I had to do a mix of it uh so in this course you'll see me do lecture lab lecture lab because I'm trying to solidify the knowledge as soon as we do that this is not the format that I use for my other courses it's just because with terraform it requires patience it is a silical learning process to understand so just uh stick with it and by the end of it you will be really good with terraform uh you know and so that's that there so let's talk about our multicloud roadmap I'm going to get out of the way so we have a little bit more room um and so you know what I would recommend uh is that you start with an Associate certification so just getting my pen tool out here uh if I can get it here here we have the Google's Ace um the cloud engineer or maybe some level of AWS uh associate certification I personally think the sysops is the best pairing for terraform or the Azure administrator if you're going for Azure and quite possibly learning more than two would be very beneficial but of course whatever your primary provider you're using is where you're going to benefit with uh terraform and you really should learn this stuff before you do terraform it is super hard to learn both cloud and terraform at the same time you should have that Foundation before you tackle onto terraform and so there's a lot of different paths for multicloud and just to kind of give you an idea of all the different ways you can go you know you can go from associate to either Vault and to the Vault professional if you're looking at a security background but it's very common for people to get the terraform and then go for uh Vault afterwards but you know it's up to you to which path you want to take how long do you have to study to pass this exam well uh it's a spectrum based on where your background is so let's take a look at beginners first so a beginner to me would be someone that's never written IC uh they have not previously focused on automating infrastructure they might may not hold an associate level certification so you're adding those additional hours or trying to make up the difference you could be looking at 30 hours or more if you're already experienced with writing IAC but maybe just not terraform maybe you know Azure bicep or cloud formation you already work in devops you're already comfortable writing scripts and you hold associate level certification knowledge of you know a major cloud provider then you're looking at something like 12 hours but you know if you're looking for a general study guide somewhere in between I would recommend between one to two hours a day for 14 days and you'll be in a really good place by then you know what does it take to pass this exam well there is a lecture content and I have a lot of it um you know the thing is that the exam itself is very practical it's not like AWS aws's exams where it's very um uh Theory based at a conceptual level this one is very much how do we use this technology and so the lecture content is there to really support the lab content and you really really need to do the lab content uh because that's the nature of this exam um and to make this a lot easier I do recommend taking some practice exams we have a free practice exam and we also have uh many more practice exams if you take all these Pax exams and you've done the labs prior to that you're going to be in really good shape to pass in terms of the content outline um I can't remember how many domains we'll see how many there are but we have one so understand infrastructure as code so I see Concepts understand the purpose of terraform understand terraform Basics the use of terraform outside core workflows interact with terraform modules use the core terraform workflow Implement and maintain State regenerate and modify configuration and understand terraform Cloud capabilities so yeah nine domains uh something that's different about uh the hashicorp certifications is they do not provide distribution of domains what do I mean by that well they're not weighted right so it's not like uh we know that uh like eight is I'm going to have a particular weighting that's higher but we can look at the exam guide outline to see generally how many questions we probably would so we could kind of infer our own waiting but they do not provide it so I would just say it's not known but we'll take our best guess when we look at the full exam guide outline where do you take this exam well you can take it in an inperson test center or online from the convenience of your own home I do believe that the test center that hashicorp is using is PSI or PSI online and understand that this is a proctored exam so someone is supervising you watching you monitoring you as you take the exam so that you uh that there's no funny business happening there's no cheating and to ensure that uh you know that you gain gain that knowledge in a reputable way so just understand that in terms of the grading you need to get about 70 percent to pass or round that it uses scaled scoring uh is it possible for you to fail if you've got exactly 70 percent it might be so always aim to get higher than 70 percent um and so I always say aim for a target of you know 10 to 15 above what the score is if you're getting that on your prax exams then you're going to be in good shape in terms of the response types they don't tell you exactly how many questions there are but I've always observed there's 57 questions and so you know based on that calculation I feel that you have 70 17 questions you can get wrong there are no penalties for wrong questions so always answer your questions do not leave any blank the format of the questions is multiple choice and multiple answer and then sometimes you get a fill in the blank so type a one word answer most likely it's going to be a command right so or a flag for a command so you definitely have to know the technical components of terraform okay the duration of the exam is one hour so that means you get about a minute to answer per questions the questions are very short format so it's not like you have to read a ton of text to figure out what's going on the exam time is 60 Minutes the seat time is actually 90 minutes so when we say C time referring to the amount of time you should allocate for the exam so that means that would include things like time to review the instructions show uh show the online proctored your workspace to make sure there's nothing going funny on with your environment read and accept the NDA complete the exam provide feedback at the end and I'm going to tell you you really do want to get for your exam much sooner than you think because it is a very stressful process and things tend to always go wrong when when you uh when you don't show up early enough okay so just make sure you do that if you do pass this exam it's going to be valid for 24 months so that's two years before recertification and the last thing I just want to talk about is um well maybe not the last thing I got two more slides here for you but this course is going to be designed around the 1.1.6.0 specification of terraform and even when I'm making this course as of today 1.60 is an alpha this will be in the future so 1.60 will be out but I like to try to give you more knowledge in the future even if it's not an exam just so that you are prepared and this course does not go stale sooner terraform is always incrementing inversion so you know when you study you always want to go back three minor versions since I'm showing 1.60 it doesn't make a whole lot of sense but if you're let's say you're on 1.54 you'd want to do one you want to make sure you know terraform for a range of versions going a few versions back and so so you know I will be showing you things that may be deprecated but are still uh but might still be in use based on the version that people are using so just understand that um and again you know these these certifications are or the terraform certification is heavily dependent on your practical knowledge so if you are taking the time to apply the knowledge uh this version difference differencing is not going to make a big difference okay um so just make sure you know you put the time in with the labs um now this is the third version of the certification and so I just kind of want to tell you that not a whole lot has changed between version zero zero two and zero zero three uh the one of the big differences is they change the badge design why I don't know uh is it better who cares um but uh it is a different looking badge um one thing is that there were superficial name changes to the outlines of the domain so basically all the domains are the same they just kind of did some tweaks there they did kind of cut some content out in the uh the like first uh first first two domains because those ones were just more General concept of knowledge and so they slim those down I'm leaving that content in this course because I think it's very valuable to know more rounded knowledge there so you're going to be over prepared for those first two domains there used to be this thing called provisioners it's still in terraform but the thing is that it's just no longer needed to know in the exam so this is about doing remote execution annoying all the provisioners and so I mean local execute and remote execute are things you need to learn and definitely something that you will use on the job but knowing how to provision and use a lot of Provisions is no longer a focus there there's this thing called null resource that we learn about and now they have a new thing called terraform data so that is a evolution of terraform data so we'll still learn about null resource but we'll also learn terraform data where it makes more sense to use uh you know terraform Tate had taint has been replaced with uh just a flag uh called hyphen hyphen uh uh replace uh on the terraform plan and we have a few more others like that so refresh has a flag um and uh the thing was is that when I made this exam the first time they were already talking about doing this so This exam is already um my previous one is up to date with the current version of zero zero three if that if that's surprising here uh terraform workspace is no longer part of the exam um I would still cover terraform workspace uh you know if we come across it because I still think again it's practical knowledge that you should know um connecting to terraform Cloud now uses its own cloud block instead of remote block um I believe that we can still use remote block here and I will definitely test that in the in the um in the uh the labs in this course so you know it's good to know both of them but the focus will be using uh Cloud block um we have the lock file so the lock.hcl files are new um I mean they weren't new when I made the previous exam so they were already in there so again I already had this content here um but I'm just pointing out that that's something that they're focusing on uh within the certification here um you need to know how to Mark data as being sensitive again that's something I had in the older exam but one major thing is terraform cloud has a new UI and it looks like there's a lot more functionality so in terms of the old exam or a course that I produce and this one I'm definitely going to have to reshoot all of terraform cloud and go deeper into it there's obviously a few different functionalities that have been added like the terraform Cloud block the terraform data block um but you know for the most part there's not a whole lot that has changed so the majority of this will be very similar to the last one but I'm just touching up and improving lab content where we can and hopefully adding a lot more additional content to expand the terraform knowledge that I wasn't able to do the first time around so hopefully that gives you a good idea of what you're getting yourself into uh but yeah we will proceed forward to looking at the exam guide foreign Brown and welcome back as we are taking a look at the exam guide uh for the hashicorp terraform associate certification I want to tell you uh throughout this course I'm going to show you where I get things so I will be going to Google I will be typing in where things are it's not because I don't know where things are I'm doing that for your benefits so that you build up the skill to know how to find things just the way that I would go find things and I'll be very transparent about that so for this one all I did was go into Google and type in terraform exam guide and so I found it here this is also the place where you can register for the exam so if you click this it should load up certain metrics I'll make a popup you have to authenticate it I'm not showing that here right now but when you are ready to register for the exam you can go ahead and do that you'll notice they also have this button here called prepare for the exam they have their own study guide here it's very text based heavy I do believe that somewhere in here there is a way to launch tutorials and this will launch sandbox environments I think through instruct at least the last time I checked those are great if you don't have an environment set up what I want to do with you is I want I want you to set everything up in your own environment because I want you to have those Real World skills so you can use this stuff adjacent to this course I've gone through all this material here I'm trying to cover things that aren't in here and try to make sure that we are doing things without guard rails without the bowling bumpers because I want you get that Real World Experience okay but I do want to point out that this is here and you can use it um and it's okay so let's scroll down and take a look at our exam guide here and so here they say we have some prerequisites so they say basic terminal skills that makes sense we're going to be doing a lot of stuff uh in terminal basic understanding of onpremise and Cloud architecture uh I think what they really mean is do you know how to use AWS you know how to use Azure gcp what is your major uh cloud provider or or stuff like that um now I keep talking or focusing on AWS Azure gcp but understand that terraform can be used for anything as long as there is a provider for it it can provision on almost anything okay and that's why they're being very generic in their description this says the product version tested is terraform 1.00 and higher so it shows you that this is still even though it's the zero zero three it's still really the zero zero two exam with some minor tweaks but just understand in this course we're going to go well beyond this because I'm just future proofing you and making sure you have Real World skills let's scroll on down here and let's just it's about renewing your certification so if you hold an unexpired terraform associate 002 certification uh you can take the new one starting 18 months after your previous exam if you hold an unexpired one you can take the new exam starting 18 months after your previous exam uh if you hold an expired one you're eligible to recertify at any time I really like this because what happens for me with certifications not a problem for you but problem for me is that I will sit a certification and then nine months later the new one comes out and I can't sit the new one and tell you about it so it looks like we've gotten a bit of flexibility there and again I'm on video here I will get out of the way um it's just that we're in the uh these earlier videos and I want to just hang out here with you okay going down below we can confirm it's the one hour duration this is seventy dollars it might vary based on your location and other stuff you I just don't want to tell you that 70 I want you to go through the process and find out yourself but that's probably what it's going to cost you um there is no free retake included um some certifications like CompTIA you are basically or uh the kubernetes ones from looks Foundation you basically get a retake so you're basically paying a love for two and they call it a free retake which it really isn't free but uh I think this is okay um I think it's fine there's no retake it's in English expires in two years we covered that before let's take a look at the exam objectives so the first one is understand infrastructure as a code and Concepts they used to have a bunch of junk in here um and honestly I didn't even know what they were talking about when they said that I remember I had to comb through uh the study guide and try to watch uh articles and stuff like that but I think they realized that it was junk uh that they were trying to uh impart too much conceptual stuff and they cut back this one here same thing with two it doesn't show us the comparison of the old one at some point on this website they showed the comparative between zero zero two and zero zero three but all I'm saying is that they cut back here I have a bit more content on this in the course it's not going to hurt you to watch it it's just going to help you understand it but you're not going to be tested 100 on this stuff the other thing I want to note is that for each point that is here each subdomain or or Point whatever you want to call it they're going to ask you a question on this is very different uh way of Designing uh an exam uh other exams like AWS they will they will list a bunch of stuff but they say it might not be on the exam or it might have stuff that are that's outside of it so you just have to broadly study and uh you'll over over study for the content because you just don't know what you're going to get uh get on the exam for hashicorp exams they're very fair if you know each of these points you can expect to see them generally on the exam and that's how you're going to know that you are ready if you if you know all these things in this course we're going to go beyond that because again I want you to have those Real World skills but just feel confidence in knowing every single point Point here going down here understand terraform Basics install and version terraform providers so that is what we will be doing a lot of in this because we're going to at least touch more than one provider in this course I'm not going to go in great detail on uh the cloud infrastructure part of it because you're already supposed to know it um and I'm going to leave that for other things doing future projects for specific uh for for specific Cloud providers we're focused here on terraform in this course not the underlying providers but we do use multiple ones here describe plugin based architecture write terraform configuration using multiple providers describe how terraform finds and fetches providers so you can see there is a a lot of stuff about providers not to be confused with provisioners I said earlier that provisioners is no longer covered in this certification course but again the materials here so you can learn it for real world practice use terraform outside of core of core workflows I think this used to be like you use terraform CLI outside of core workflows so they made a small tweak there so it says destroy describe when to use terraform import to import existing infrastructure into your terraform State terraform import is super super powerful going over to other providers uh you know for a long time AWS did not have an import option and so the idea is that by having this import we can bring an infrastructure that was not necessarily there before we have terraform state to view our terraform State something that you're going to find unique to terraform is State Management it's something that's super important and it's probably the hardest Concept in terraform because when you use something like cloud formation or Azure bicep the state is managed by services on those providers there isn't a managed service managed service on those providers and so you have to decide where you want to put your State uh and one example would be terraform cloud and that's one that we do use in this in this course here describe one to enable verbose logging and what the outcome is so you have to know how to debug things here which is great interact with terraform module so contrast and use different module Source options including public terraform module registry interact with modules inputs and outputs describe variable scope and module child modules set module versions modules is a way of creating reusable code uh we are going to use uh public libraries as well as uh make our own modules making modules is not as hard as you would imagine but they can get very complex uh so you know we're not going to go super Advanced into modules but we are going to make sure we can write our own and and use public ones use the terraform uh use the terraform workflow so this is something we're going to have to know a lot about which is just the general life cycle workflow of working with infrastructure as code so we have a knit validate plan apply destroy format plan it apply are the ones we're going to be using a lot of there is a lot of trickery with the init so that's something else that we'll do there as well Implement and maintain state so maintaining State working with State super super important so we'll look at how it works with local state state locking handling backend Cloud Integrations authentication methods uh you know they're talking about managed providers like terraform Cloud the different between remote State backend options manage resource drift and terraform State terraform is super good at drift and fixing drift it's so good at remediation compared to other IEC tools and that's why it is such a popular tool to use describe backend block and Cloud integration configuration understand secret management and state files then we have regenerate modify configuration so demonstrate the use of variable variables and outputs describe secure secret injection best practices understand the use of collection and structural types create and differentiate resource and data configuration use resource addressing and resource parameters to connect resources together use HCL and terraform functions to write configuration describe builtin dependency management and the last one here is understand terraform Cloud capabilities so explain how terraform clouds helps to manage infrastructure describe how terraform Cloud enables collaboration government governance I'm going to tell you right now we're going to probably do more terraform Cloud than we we need to it's just because when I made this course the first time I I just lightly did terraform Cloud just enough to pass the exam I have the time to do a little bit more there I would like to do that for your own benefit and so we will expand on that a bit more but you can see this is mostly about terraform the technology not necessarily terraform Cloud the uh the service if you're confused about terraform and terraform Cloud uh again we'll explain that in this course and make sure it's very clear what the difference is one other thing I wanted to notice that you do have some sample questions here so you can go through here and you can just see that the questions are very straightforward and they're just like this they're very simple uh but you know you do have to know you do have to know what you're looking at and see like here they're showing code so you can see you have to choose code and you might get a code block so it is very focused on the Practical component of it it's less about the conceptual okay but yeah hopefully that gives you an idea of what we're getting into and we'll see in the next one okay ciao foreign hey this is Andrew Brown from exam Pro and what I want to do is walk you through a few of our practices and questions just to give you an idea of what it will be like on the real exam and where we might have had to make some adjustments to help your study so what you'd have to do to access this prax exam is you'd have to be signed up and logged in to the exam Pro platform make a way over to the hashicorp terraform course except the free tier or pay for full access but once you go there you'll scroll all the way down to the bottom and you should see three or four products exams at the time of writing this we're still writing the questions so that's why they're not shown in the video here but what I want you to do is to go to the first practice exam and notice that there are 57 questions you get an hour on on the exam here and we have a breakdown based on domain now the percentage is not something that uh terraform or hashicorp provides so we just had to break it down based on the coverage of questions that we saw in the exam guide outline and so that should be accurate enough and that's kind of what it felt like on the exam so I don't think that's going to be a problem if we click into here we're just going to look at some of the questions I'll talk around them so the first one here is we have how do you create a workspace and it's showing us a bunch of CLI commands and so on the exam you do need to know um uh you know CLI commands and the difference of them and the questions can be as simple as this where you're just choosing the option and some are obvious distractors like there isn't there is no one called terraform workspace Branch okay so just understand that you not just need to know the conceptual ideas behind terraform but also it in practice okay another one here would be the terraform registry can search based on the following Search terms we have an option to choose multiple questions and so this is something that you will see on the exam where you're choosing multiples of something I didn't get a lot on my exam but I cannot say for certain like how many questions would show up like this um but you know they're not really that hard to figure out okay and this question is about um a tool or sorry uh the public terraform registry website and that is just a uh a publicfacing website if we go to registry.terraform.io here it's this website here so it's not just the tooling of terraform itself but it's the ecosystem around it so terraform Cloud the terraform registry things like that another type of question you will see and I think it's over here is what they will do is they'll ask you to fill in the blank now we don't have that support in our platform just as of yet but the idea is they'll say like okay uh we'll ask you a question or we'll even give you um maybe they'll have like underscores they'll say fill in this thing and you'll literally have to type type the answer in but the answer is going to be like a one word answer so on the exam I literally had a question which was like where is the API stored and it was actually terraformed at TF state but I did not know I could not recall the name of it which is kind of embarrassing but uh you know that is the level of fillins that you'll have to do and you're very likely to see some code on the on the exam two so if I just click through here really quickly you may see a code block okay and you might have to decipher it so that's the difficulty exam I would not say this is a heart exam but you just have to understand the scope of those kind of questions and make sure that you have wellrounded study in both practical and conceptual concepts of terraform so hopefully that helps you out okay everybody there it's Andrew Brown and I just wanted to tell you about the content that you're going through because honestly between the zero zero two and zero zero three there was not much to update um and so you know the key differences is the versions of terraform and the versions of the providers that you are using um and for the most part everything worked out perfectly fine I thought that I'd have to reshoot all of the lab content but it turns out nope barely nothing has changed what has changed and I want to point this out early on is that when you are specifying a version for the provider just go use at least version five zero you can use an older version if you want to follow along but uh you know I think it's better to be more um up to date if you can the version that we were using prior in the follow alongs was version three again there are no major changes that will break anything um so at least there shouldn't be but I ran through these Labs my cloud support engineer ran through these Labs so we're pretty confident you're going to be in good shape otherwise if they weren't I would go rerecord them but I just wanted to point out those two things uh there so hopefully you know that makes sense and you're going to be in good shape okay now I did say that we're scoping things around terraform 1.6.0 and again there's not much to call out for that the biggest thing that I think that 1.6.0 might bring would be testing and even if I looked into it and it just wasn't where I thought it was going to be so I did not include it at least at this time in uh this uh this this course and again this is me going uh above and beyond because I'm trying to just future proof the contents of this course and future proof uh stuff that I believe that is coming to terraform form but yeah you should be in good shape and you know if there are any changes on exam Pro we're very proactive of having those differences there so if you do run into anything that's giving you any kind of issue they're going to be on the the main learning platform there okay if if for whatever reason there's minor updates or things that are found out but yeah you'll be in good shape and have fun on your journey learning terraform ciao hey this is Andrew Brown from exam Pro and we are looking at what is infrastructure as code and before we talk about that we need to talk about the problem with manual configuration so manually configuring your Cloud infrastructure allows you to easily start using new cloud service offerings to quickly prototype architectures however it comes with a few downsides so it's easy to misconfigure a service through human error it's hard to manage the expected state of the configuration for compliance it's hard to transfer configuration knowledge to other team members and so this is why infrastructure code is going to really help us out so infrastructure is code commonly abbreviated to IAC and you'll see that a lot in this course allows you to write a configuration script to automate creating updating or destroying Cloud infrastructure notice I gave great emphasis on automate or automation because that is really key to infrastructure as code IEC could also be thought of as a blueprint of your infrastructure IEC allows you to easily share version or inventory your Cloud infrastructure and just to kind of get your visualization imagine you write a script and that's going to provision and launch a bunch of cloud services that are all interconnected okay all right so we're taking a look at popular IAC tools and so of course this course is about terraform but by understanding um all the options out there if you understand why we're using terraform uh and one thing that is very important to understand is the difference between declarative and imperative IAC tools those are the broad categories that we see for IAC so let's start with declarative so the idea here is what you see is what you get everything's explicit it's more verbose but there's zero chance of misconfiguration and this all relies on the fact that they use a scripting language such as Json yaml XML in the case of terraform they have their own language called HCL but the way these languages are structured is that they're very verbose and there's not a lot of programming logic involved so for Azure we have arm templates and Azure blueprints for AWS we have cloud formation for Google we have Cloud deployment manager and there there is of course terraform which has many cloud service providers such as AWS Azure gcp kubernetes and a lot more but these are all in the declarative category on the right hand side we have imperative so you say what you want and the rest is filled in everything here is implicit it's less verbose but you could end up with misconfiguration and when I say that it's that like if you were to find um let's say a virtual machine you might not have to provide every single uh option that you would normally do and it would fill in the rest but if you weren't aware of what it was doing that's where you could end up with misconfiguration uh though I would say that imperative tools generally try to always uh have their defaults as best practices so you're not usually in a bad position uh but you know you might end up with something you don't expect imperative can do more than declarative so there's just some very hard limitations with declarative languages so there's just cases where you want to do imperative and the idea here is imperative languages use programming language you know like python Ruby JavaScript golang you know whatever it is uh there's likely an SDK for it and so it's just a lot more programmer friendly a lot of developers like imperative tools so AWS has their own called Cloud development kit cdk and it technically only supports AWS I say technically because hashicorp has a very cool library that allows you to generate out terraform HCL files which allows you to work with anything but when we're just talking about cdk on its own it's just for AWS then you have plumy it supports AWS Azure gcp and kubernetes so it can do a lot so why would you choose with your team to use declarative over imperative well it just really depends on your your team right so like if they're all used to if they're all administrators and they're used to using Json yaml and they're not good with programming languages that is one reason why you might want to use declarative over imperative the other thing is just you know you prefer to know exactly every single thing that was defined right you don't want anything left up to a chance and so that is another reason why you might want to use declarative but both are great options it's just really depends depends on your team's knowledge and what your goals are okay so we just looked at imperative and declarative but I just want to clarify that terraform even though it's a declarative language it has imperativelike features so I've coined the phrase declarative plus and so terraform kind of gives you the best of both worlds so you have declarative and imperative and then the three types so our yaml Json XML we have terraform language which actually utilizes HCL underneath and then you have programming languages on the right hand side like Ruby python JavaScript what it have you right so when we're looking at yaml or Json these are very limited languages or scripting languages where uh you know you don't really have any kind of complex data types you probably don't have a whole lot of robust functions but in some cases you can extend That Base Behavior so in the case of cloud formation which uses yaml or Json files they have a concept called macros so you can extend it a bit but again it's very inflexible and so a lot of people are led to go and use cdk so terraform is great because it kind of has a lot of stuff you'd see in programming languages like for Loops Dynamic blocks locals it also has complex data structures and a lot of functions around using those data structures and so it allows you to stay in that declarative world but having the stuff that you generally need when you're in the parative world when you're in the imperative side the idea is that the language is what you're utilizing so you can do anything that the program language allows you to do but I just wanted to kind of show you that terraform sits in the middle okay hey it's Andrew Brown from exam Pro and we are looking at infrastructure life cycle so what is infrastructure lifecycle it's the idea of having clearly defined and distinct work phases which are used by devops Engineers to plan design build test deliver maintain and retire Cloud infrastructure where we're talking about like sdlc so software development life cycle there's usually a really great visual that I can show for you but for infrastructure lifecycle especially Cloud infrastructure lifecycle there isn't something that is well defined which is weird by the definition but I think that there's just nobody's agreed up on one yet or nobody's made the graphic yet so I just don't have anything to show you for that but I just want you to get familiar with the term infrastructure life cycle because you're likely to hear it again but one particular infrastructure life cycle that is pretty common is ones that talk about day zero day one and day two so the idea here is this is a simplified way to describe phases of infrastructure life cycle so when we say we are on day Zero we are planning and designing our infrastructure on day one we are developing and iterating it so we might be uh you know deploying or provisioning it and actually testing it uh in the cloud and then day two is actually when we go live with real production users and maintain it and the idea of mentioning day zero one and two is to say Well when does IAC start and the idea is it starts on Day Zero okay the days do not literally mean a 24 hour day it's just a broad way of defining where in the infrastructure project we would be okay so after defining what infrastructure life cycle is what advantage or what an advancement are we going to have when we add IAC to our infrastructure lifecycle well the first thing we're going to get is reliability so IC makes changes impotent consistent repeatable and predictable I'm going to give extra attention here to impotent because it is a very strange English word but no matter how many times you run your IC you will always end up with the same state that is expected that is a very important concept of IEC whereas if you use configuration management there's no guarantee of that that's why you use terraform over something like ansible okay you have manageability so enable mutation via code revise with minimal changes and then you have sensibility so avoid financial and reputational losses to even loss of life when considering government and Military dependencies on infrastructure so there you go okay so it impotent is a very important concept to infrastructure as code and so we're going to give it a little bit more attention I wouldn't stress out about the pronunciation uh there's more than one way to pronounce it in English and I've probably even said it wrong uh in the previous slide so uh just be uh forgiving on that part okay but the idea is that let's stage a scenario between a nonitipotent example and an independent example so when I deploy my IAC config file it will provision and launch two virtual machines that is what I'm expecting okay and that is what I get but what happens when I go and I update this infrastructure code file saying maybe I want to increase the size of the VMS or some of the configuration I deploy that again when it's nonedepotent what will end up happening is I will end up with two additional virtual machines with the new configuration and the old ones will be there and so this is something you might not want because you just want to have a file that says exactly the state that you expect okay so when we have something that is Idi potent the idea is we will go and we will Define our two virtual machines and we will get our two virtual machines but we go and we update that file and we deploy again and what happens this time is it just ends up modifying the original virtual machines or if it really can't and it has to it might delete them and recreate them but the idea is that we end up in a state of exactly what we want so in the first case we expect it to but we ended up with four but with the independent uh case we expected to and we always end up with two so hopefully that makes that very clear okay hey this is Andrew Brown from exam Pro and what I want to do here is concretely Define the difference between provisioning deployment and orchestration now in practice sometimes these have overlapping responsibility so you might say provisioning when you really mean deployment or vice versa it's not a big deal uh we all get kind of mixed up about it but I did want to just take the time to make sure that we understand what these things are supposed to mean okay so the First on our list here is provisioning so to prepare a server with systems data and software and then make it ready for Network operation if you're using a configuration management tool you are most likely provisioning because that's what these tools do so puppet ansible Chef bash scripts Powershell or cloudnit so you can provision a server when you launch a cloud service and configure it you are provisioning it okay then you have deployments the deployment is the act of delivering a version of your application to run a provision server deployment could be performed via AWS code pipeline harness which is a thirdparty deployment tool Jenkins GitHub action Circle CI there's a lot more other providers out there then you have orchestration so orchestration is the active coordinating multiple systems or Services orchestration is a common term when working with microservices containers and kubernetes so orchestration could be done with kubernetes salt or fabric so if you're working with containers generally like you use the word orchestration especially with kubernetes because you're working with thousands of microservices okay so you know hopefully that helps you know the difference between the three again it's not a big deal if you don't perfectly know them but there you go hey this is Andrew Brown from exam Pro and we are taking a look at configuration drift so this is when provision infrastructure has an unexpected configuration change due to team members manually adjusting configuration options malicious actors so maybe they're trying to cause downtime or breach data or side effects from apis sdks or CLI so you've written some code that uses a CLI and a bash script and it does something you did not expect to happen so here an example could be imagine you have a server like a database and a junior developer turns off delete on termination for your production database this could be a problem where let's say there's an accidental deletion of the database this feature would protect the database from deletion but if it's turned off you don't have that right so configuration drift going unnoticed could be a loss or breach of cloud services and residing data will result in Interruption of services or unexpected downtime so there's a lot of downsides to to neglecting or not noticing configuration drift so what can we do about this so how to detect so there's three things detect um we can fix it and then prevent it okay so to detect configuration drift if you have a compliance Tool uh it can detect misconfiguration so it was config can do that as your policies can do that gcp security health analytics can do that some of these are constrained to security things not just configuration in general but there are tools there for all the cloud service providers there is builtin support for drift detection for it was cloud formation it's called cloud formation drift detection other providers don't necessarily have that if you're using terraform which is this which is all this course is about you have the terraform State files which says what the state of things should be so that's how you could detect configuration drift how to correct configuration drift well compliance tools can remediate so again it is config you can create a custom Lambda to say hey when this happens then do this so set the configuration back into place with terraform you can use the refresh and plan command which we'll look at in detail in this course or you can manually correct it so if the option was changed you could do that not recommended to do that another thing would be tearing down and setting up the infrastructure again because that would bring it back into its original state that could be a risky thing to do depending on how you have things set up or could be it could be fine right then there's prevention so um this is a the important thing and kind of why we're talking about configuration drift which is all about immutable infrastructure so always create and just destroy never reuse so that might be blue green deployment strategies servers are never modified they are all they're just always deployed with a new version the way you would do that would be baking Ami images or containers via AWS image Builder or hashicor Packer or a build server like gcp Cloud run or code build like AWS but the idea is that you're not modifying after they're deployed you'd have that image already ready to go another thing you could use is git Ops so you would Version Control your IAC like within GitHub or something like that and you would peer review every single uh change the a pull request to the infrastructure so hopefully that gives you an idea of things we can do to tackle configuration drift okay we were just talking about immutable infrastructure but I just want to give it a bit more attention here so the idea is um we are going to first develop our infrastructure as a code file terraform cloudformation what have you and then we're going to go ahead and deploy that so we'll end up with our own virtual machine and that virtual machine needs to be configured so you need to install packages and things like that that's where Cloud init would come into play ansible puppet Chef salt whatever configuration management tool you want to use the problem here is that there's no guarantee that that configuration is going to stay in place so that's where immutable infrastructure comes into play so we develop our infrastructure as a code file terraform cloud formation and then we're going to go ahead and do our configuration by building a virtual machine or building a container so we can use something like Packer and then the idea is once we are happy with our configuration what we're going to do is bake that image and put it in an image repository and then that image is going to be referenced when we do our deploy and so that's going to make sure that our infrastructure is always immutable okay hey this is Andrew Brown from exam Pro and we are taking a look at the concept or methodology of git Ops so this is when you take infrastructure as code and you use a git repository to introduce a formal process to review and accept changes to infrastructure code and once that code is accepted it automatically triggers a deploy and changes that infrastructure so here's my illustration through it so the idea is you would have a terraform file and you would place that in something like GitHub you would apply your commits and when you're ready you'd make a pull request you would merge that pull request into the main branch or whichever branch is set up for production and that could trigger something like GitHub actions and GitHub actions would then trigger a terraform plan and and accept it or maybe you have to manually intervene to say Okay I accept these changes but then it would roll out those changes now terraform does have their own and it's pretty darn similar but I thought mine was a bit easier to read but the idea is you have your git repository you have your pull request this is pulling from terraform Cloud because you can have files and state managed there so that is another means to do it but that's generally how it works okay foreign so we were just looking at immutable infrastructure but what I want to do is just kind of cement in your head things that you should be asking yourself as a devops engineer so that you kind of lean towards that immutable uh kind of way of thinking and so this is mostly going to be applicable for virtual machines but let's just ask some questions of things we should be thinking about so what's going to happen if we deploy our virtual machine and there is a physical failure of the hardware by the provider so this can sometimes happen on AWS where they have two status checks that have to complete before a virtual machine is ready sometimes they fail and so you know your infrastructure is not ready to graded or damaged right then you have application failure so you have this post installation script maybe to install your application and there's either a bug so introduced by developer or maybe there's just a dependency and it's changed and so it's breaking your app what happens when you need to deploy in a hurry what have happens in worst case scenarios where you have accidental deletion compromised by malicious actor need to change regions maybe there's a region outage and so the thing is is that when you look at these things what happens when multiples of these happen at the same time because that's the problem where you know it's like okay I have something wrong with my application code but I also have uh you know now we also have a region down and so you don't want to be dealing with more than one problem at the same time and so that's we're going to have an issue of agility in terms of deployment another thing that is overlooked is there's no guarantee of one to one if you are configuring your code after deployment because if you were to deploy a virtual machine and installed all the dependencies and then you to were to deploy a virtual machine literally a minute later one of those dependencies could have a minor revision and so that would be deployed with that one minor revision so they would look very similar but they aren't one to one so by introducing golden images which is an immutable infrastructure idea you get a guarantee of one one to one with your Fleet you have increased Assurance of consistency security you have you can speed up your deployments the reason why you have an improvement of security is because at that stage you could um you could perform kind of Security checks and things like that there on that image before you roll it out so I don't know um I would just say that I would recommend that you go with the immutable infrastructure or baking your images when you can if you're using VMS okay hey this is Andrew Brown from exam Pro and we're going to take a look here at what is hashicorp so hashicorp is who creates terraform and they are a company specializing in managed open source tools used to support the deployment and development of largescale service oriented software installations and they have their own cloud platform called the hashicorp cloud platform hcp and it's a unified platform to access hashicorp various products so uh the main thing is that it's Cloud agnostic so hashicorp makes it really easy to build across cloud and they have support for all the three main providers so AWS gcp Azure I'm sure they have more support like kubernetes and things like that they're highly suited for multicloud workloads or crosscloud workloads and they have a lot of products that will help you out there so let's go through them quickly so first we have boundary this is secure remote access to systems based on trusted identity this is console this is a full featured service mesh for secure service segmentation across any cloud or runtime environment you have Nomad this is scheduling and deployment of tasks across worker nodes in a cluster you have Packer which is a tool for building virtual machine images that will be later deployed or they will place them in a image repository then you have terraform which is infrastructure as code software which enables provisioning and adapting virtual infrastructure across all major providers then you have terraform cloud and this is just a place to store and manage your IAC State files and things like that with a team or just in the cloud by yourself we have vagrant so building and building and maintenance of reproducible software development environments via virtualization technology we have Vault so secret management identity based access encrypting application data auditing of Secrets for application systems and users and lastly we have Waypoint a modern workflow to build deploy and release across multiple platforms so there you go hey this is Andrew Brown from exam Pro and we are looking at what is terraform so terraform is an open source and Cloud agnostic infrastructure as a code tool and terraform uses declarative configuration files and the configuration files are written in the hashicorp configuration language HCL and so that's what you can see on the right hand side we'll generally call it the terraform language which we'll talk about later but notable features of terraform are installable modules plan and predict changes dependency graphing State Management and provisioning infrastructure in familiar languages that's something you could do via AWS cdk so I wouldn't say it's core to terraform but that's what they listed on their websites that's why I put in there and terraform registry which has over 1 000 plus providers okay so there we go so we were just looking at terraform but what is terraform Cloud well it's a software as a service offering for remote State Storage Version Control Integrations flexible workflows and allows you to collaborate on infrastructure changes within a single unified web portal and this is all accessible via terraform.io and the first thing you'll have to do is create yourself an account on terraform i o but it's free to start with and they actually have a very generous free tier that allows for team collaboration for the first five users of your organization that's not part of the team's plan that's part of the free plan and in the majority of cases you really should be using terraform Cloud as your remote backend even if you are an individual just because you know it makes experience so much better the only case that you might not want to use terraform cloud is if you have a very large company that's trying to meet particular regulatory requirements and it's not that terraform Cloud does not meet them but sometimes there's just a long procurement process so in the meantime you would have to use something like standard remote back end or Atlantis or maybe you need to investigate terraform Enterprise I do want to note that terraform cloud and terraform Enterprise is the underlying software known as terraform platform it's not something you're going to ever have direct access to but just to clarify that terminology okay so what I want to do is just set you up with understanding the terraform life cycle this is not necessarily uh described in the documentation anywhere but it's something that is inherently known when you're working with terraform uh and it's definitely not uh inclusive with every single command that can be ran but the ones that you're going to counter most often so at the start you're going to be writing or updating your terraform configuration file okay and from there the first thing you'll want to do is initialize your projects and or if you need to pull the latest providers and modules you're going to use terraform indit to do that as well from there you're going to use plan so plan allows you to speculate what will change or generate a saved execution plan that you could use later on when you run plan validate happens automatically but you could also run this separately and ensures types and values are valid ensures the required attributes are present within your configuration file from there if everything is good you're going to execute your execution plan by running terraform apply you can also from this point use terraform apply to destroy infrastructure so if you have things set up there's actually a flag for it or you can use the Alias the terraform destroy command and then you know as you work you're just going to keep updating your code and that is the terraform life cycle so you know hopefully this gives you kind of a a snapshot of what the workflow will be and I mean we'll be covering it tons and tons of times over in this course okay foreign hey this is Andrew Brown from exam Pro and we are taking a look at change automation but to understand that we need to first talk about change management so this is a standard approach to apply change and resolving conflicts brought about by change in the context of IAC change management is the procedure that will be followed when resources are modified and applied via configuration scripts so what is change automation then it is a way of automatically creating a consistent systematic and predictable way of managing change requests via control and policies notice and I should have probably emphasized this is change requests saying I'm going to change these resources terraform uses change Automation in the form of execution plans and resource graphs which will look at detail those two things in upcoming slides and apply review complex change sets so a change set is a collection of commits that represents changes made to a versioning repository and for IEC uses change sets so you can see what has changed by who over time so when I say versioning repository that doesn't necessarily mean get and if you're using get Ops I suppose you could consider your chain sets being committed to that but something like cloud formation when you apply a change you actually have to accept a change Set uh and so the version repository is part of AWS and so um it will terraform you just kind of accept it in place it's not necessarily on your local machine but I guess reflecting your state file okay so change automation allows you to know exactly what terraform will change and in what order avoiding many possible human errors a change automation is essential to any IAC tool they all have it okay so there we go this is Andrew Brown from exam Pro and we are taking a look at execution plans so this is a manual review of what will add change or destroy before you apply changes and so let's say you type in terraform apply it's not just going to go ahead and do that it's going to have you uh type in yes or accept the value but what you can do is see the resources or configuration settings that will be added changed or destroyed and it will summarize them at the bottom and then you'll have to type something like yes in order to accept the changes okay something else I want to show you is that you can actually visualize your execution Plans by using the terraform graph command and terraform will output a graph of his file you'll have to have graph Vis installed but Graphics is an open source tool for drawing graphs specified in the dot language scripts having the file name extension of GV so I believe this is crossplatform it's open source but once it's installed in your machine you can run terraform graph and here this is Linux so we're using a pipe to say okay pass it over to graphis which is Dot and that is going to then create an SVG file you can just open that in your browser and the idea is you're going to get this graph which kind of shows you the relationship of the resources here but we'll talk about the these relationships in the next slide here which is a resource graph okay let's take a look here at the resource graph so terraform builds a dependency graph from the terraform configurations and walks this graph to generate plans refresh rate and more when you use terraform graph this is a visual representation or presentation of the dependency graph if you're wondering what a dependency graph is in mathematics it's a directed graph representing dependencies of several objects towards each other so it's pretty much like nodes with relationships between other nodes so that is one that I generate out from terraform and so there's a few different types here we have a resource node that represents a single resource a resource meta node represents a group of resources but does not represent any action on its own and provider configuration nodes that represents the time to fully configure a provider will you need to know this for the exam probably not do you need to know this in great detail probably not because there's a lot to the resource graph but the idea here is just kind of like terraform saying just so you know we're using a graph database and graph databases are very well suited for this kind of stuff and that's why terraform is very good at figuring out conflicts and things like that okay foreign from exam Pro and we are taking a look at terraform use cases and the idea here is not necessarily because it's going to show up in the exam but the idea is to give you a business use case or to highlight the features as to why you'd want to be using terraform and the first one here is that it has exotic providers so terraform supports a variety of providers outside of gcp AWS and Azure and sometimes is the only provider terraform is open source and extendable so any API could be used to create IC tooling of any kind of cloud platform or technology so you can make your own provider there's some interesting ones that they have like Heroku or even Spotify playlists I have my own platform called teacher seat and I want to have IAC for my platform and so this is what I'm going to be using terraform for for multitier applications terraform by default makes it easy to divide large and complex applications into isolate configuration script modules you'll notice in this course that when you have a bunch of terraform files they're all treated as one so that makes it really easy to split up your uh your projects or your your infrastructure so so it has a complexity advantage over Cloud native IC tools for its flexibility while retaining Simplicity over imperative tools then we have disposable environments this is not unique to terraform it's any kind of ISE tool but easily stand up an environment for a software demo or a temporary developer environment resource schedulers so terraform is not just defined to infrastructure of cloud resources but can be used to set Dynamic schedules for Docker containers Hadoop spark and other software tools you can provision your own scheduling grid and the last one here is multicloud deployment terraform is cloud agnostic and allows a single configuration to be used to manage multiple writers and to even handle crosscloud dependencies and that is a big deal and is a very unique offering to terraform okay let's take a look here at terraform core and terraform plugins so terraform is logically split into two main parts terraform core which uses remote procedure calls RPC to communicate with terraform plugins and terraform plugins so expose an implementation for a specific service or provisioner something that's interesting to know is just terraform core is written in go um you know you probably will never encounter it but it's just a fact okay and so here's the graphic that terraform uses to kind of like explain terraform core versus terraform plugins and how they all relate so here's the terraform core and here are the plugins notice we have providers here which will cover provisioners uh and there's just this is the group for plugins overall um but yeah that's about it we'll show up an exam probably not but it's good to understand from a top level view the split between these two things okay if you are new to terraform I just wanted you to be aware of an additional resource that you can use Beyond this course which is called terraform up and running so it's a a book and it has a deep dive into the internal workings of terraform and this is really great if you want to go beyond this course Beyond certification beyond the basics because what it will do is teach you about testing with terraform Cloud zero downtime deployment common terraform gotchas and compositions of production grade terraform code there's a lot more to it and this book in particular is written by Jim who's the cofounder of grunt work and we do have a whole section just on grunt work and the thing is I just want you to know about this resource you definitely don't need it to pass a certification or to have a good understanding or working of terraform but you know at some point you if you want more I just want to point you to that resource okay there's one other resource I want you to check out for terraform and this one is free and just online and it's the terraform best practices so it's an open book it's a get book so it's essentially a Wiki and it basically covers the best practices that are being used in the industry and so this is stuff that is separate from the terraform documentation it's just good practices you know if you're going to be using terraform professionally within the industry so I just wanted to make you aware of this resource and to go check it out okay foreign foreign hey this is Andrew Brown from exam Pro and we are taking a look at terraform provisioners so provisioners install software edit files and provision machines created with terraform and terraform allows you to work with two different provisioners we have Cloud net and Packer so Cloud init is an industry standard for crossplatform cloud instance initialization when you launch a VM on a cloud service provider you'll provide either a yaml or Bass script and so for the case of AWS what you'll have is this box called user data and so you can either put your yaml or Bass script in there it's the same if you're using Google or Azure they both have this box it might just not be called user data but that is using Cloud init underneath then you have Packer this is an automated image Builder service you provide a configuration file to create and provision the machine image and the image is then delivered to repository for use if you've ever heard of ec2 image Builder it's a very similar service except that one's just for AWS I suppose for Google you can use Google Cloud run and even on AWS you could use um code build but uh Packer is great because it's Cloud agnostic so you're going to just build the image and then you can deliver it to any provider provisioners should be used as a last resort for the for more common situations there are better Alternatives this is a warning that hashnode puts out in their terraform provisioner section and so I wasn't really sure why they were saying this so I reached out to Anton and Anton uh if you don't know him he's an as Community hero just like myself and so he specializes in terraform like he wrote so many modules for the terraform AWS so he knows it pretty well and he says here the main reason is that provisioners will do something that won't be reflected in the terraform State and the better alternative for that one is to use cloud provider features like Cloud init scripts I think this comes back to immutability when we're looking at the fact that we want to lean towards doing an approach with Packer right we want to um uh bake our Baker machines or virtual machines and then deploy because that's going to be probably the better alternative so if we wanted to use cloud init the idea is we'd have to provide a cloudinet yaml file which is a a very particular format you can find them on the cloudinet website and the idea here is we have these run commands so this just like bash commands here to start and stop Apache we can install our packages here do an update do an upgrade we'll have to pass along our SSH key here that's a very important component to that once we have that file configured we can reference it as a template file over here call it user data and then we're going to pass it on to this section here for user data so that when we launch up this VM and this one in particular is for AWS that's going to pass it to that user data okay now you might be asking well where's all these other provisioners because there's a lot of other tools out there so terraform used to directly support thirdparty provisioning tools in the terraform language but they were deprecated because it was considered to be poor practice suggesting better Alternatives as we were just talking about so you might be asking where is Chef where is puppet where is salt and the thing is is that you can technically still use chef and puppet through Cloud init because cloudinit actually supports some dsls in there I've never used this before myself but it doesn't look too complicated but the idea is that there's just not direct support so you're not going to use it directly in the language you can use it through cloud in it if you really need it one thing I didn't see mentioned anywhere was ansible and this one's a little bit confusing because there's a lot a lot of videos online about terraform and ansible working very well together and they're complementary Technologies so ansible is a little bit different than these other ones because it does more than just configuration management so maybe that's the reason there um but anyway the point is is that there's no direct support for these anymore you got to use cloud in it and generally if you can use Packer instead when you're working with virtual machines okay hey this is Andrew Brown from exam Pro and we are taking a look at local exec which allows you to execute local commands after a resource is provisioned so the machine that is executing terraform so what's doing the terraform apply is where the command will execute and a local environment could be your local machine so your laptop or workstation a build server like gcp Cloud build a business code Builder Jenkins or terraform Cloud run environment so that is a single use Linux virtual machine so just an example and there's a lot of cases where you might want to automate but the idea here is after your provision a VM you need to supply the public IP to a thirdparty security service to add the VM IP address and you can accomplish this by using locally installed thirdparty cli's on your build server and so there is a bit of an overlapping responsibility between terraform outputs versus local exec because the idea is that by getting by getting data out after something is provisioned or something like that you can do something pragmatic but the idea here is terraform outputs allow you to Output results after running terraform apply local exec allows you to run any arbitrary commands on your local machine commonly used to trigger configuration management like ansible Chef or puppet okay let's take a look at some example code for a local exec so here we have a bunch of examples on the right hand side and so I just kind of want to walk through some of the commands that we can use but before we do that just let's take a quicker look here at the code so notice we have a resource like Ava's instance in web and then we are specifying a provisioner being a local exec and then we have a command that is being executed under there okay so hopefully that makes it pretty clear but let's just kind of work through the options we have available to us so the first is we have a command and this is required and this is the command you want to execute so notice that we are doing an echo there so it's whatever is possible uh there and I think by default it's using bash okay so if you're using Linux that's what it would be using we could also set a working directory we don't see an example there on the right hand side but if you wanted to say where the command will be executed that's something you could do so maybe you want it over here another thing is The Interpreter so this is the entry point for the command I think by default again it would probably use bash if you're on Linux machine but you could say use bash Ruby it was CLI Powershell whatever you want okay if you needed to pass environment variables in maybe you need a key and secret so the example here is you know we are printing out those keys and then putting them into a credentials XML file so that could be an example there okay hey this is Andrew Brown from exam Pro and we're taking a look at remote exec so this allows you to execute commands on a Target resource after a resources provision so the idea is you have a local machine executing terraform and so the idea is that when remote exact happens it has a script and it's sending that off to the Target so this case it could be a provision virtual machine and this is where the command is going to run so a remote execute is useful for provisioning a virtual machine with a simple set of commands for more complex tasks it's recommended to use cloud init and strongly recommended in all cases to bake golden images via Packer or uc2 image Builder if you want to use something more complex like ansible or something let's take a look at an example of a remote exec script so here we have a couple and just to quickly go through it the idea is you define your resource so here it's just a virtual machine on AWS and we are provisioning our provisioner is going to be remote exact and so we're able to put these inline commands and say okay let's run puppet apply and then we'll use console join which is the CLI for hashicorp console so there are three different modes for a remote exec the first is inline list of command strings which is what we are seeing over here and then the other option is we can provide a script or scripts so the idea is that you would um well you just specify those locations and it would run it what's interesting here is that it doesn't say um like because we saw with local exec that we could use an interpreter and so it's my assumption that it's just going to use bash or it's going to use a script that is executable right where you have a shebang in the top there and so that's something you know I might test out it's not something that's going to be on the exam but maybe we'll just test out that theory because it's not in the documentation as of the time I'm recording this let's take a look at the file provisioner and this is used to copy files or directories from our local machine to the newly created resource so here we have some on the right as an example so again we have a virtual machine that we're deploying to AWS we've set the provisioner as file and we are specifying a source file and a destination so source is going to be the file that's on your local machine or whoever is the considered the local you might also want to provide content directly so in this example here you see that we're literally just giving it a string and then there's the destination where you want that file to be I don't have it shown in the code example here but there's a high chance that you would have to provide a connection block so that you could say okay I need to use SSH or winrm to gain access to that machine okay so we just mentioned that there's a connection block so it tells the provisioner or resource how to establish a connection so here is a big example on the right hand side so this is using the example for a provisioner file and here we are specifying our connection block and this one in particular is for SSH as you can see and there's a bunch of different parameters like the user the password the host you could also use a Bastion host I don't I'm not showing it here but if you're using SSH you could specify a bunch of keys in order to do that because maybe you need to go through a Bastion first for Windows Remote Management you also have that option down below okay hey this is Andrew Brown from exam Pro and we are taking a look at null resources so this is a placeholder for resources that have no specific Association to a provider it's a bit confusing but it makes sense once you run into some use cases for it so here is a big example where we have an AWS instance and we're defining a cluster and so we need a null resource here because we want to run this trigger and that's generally why you're going to be using null resources is to trigger a resource so triggers is a map of values which should cause this set of Provisions to rerun so values are meant to be interpolated references to variables or attributes of other resources and triggers are interesting because I think we also see them in terraform Cloud I'm not sure if this is the same kind of functionality but yeah that's in all resources okay all right let's take a look at terraform data so this is very very similar to null resource but the key difference here is that it does not require or the configuration of Provider because when you install null resource it actually installs a provider called null and so now it's just with this dare terraform data you can do something very similar like this with null resource and literally replace it with terraform data and for more or less it will do the same thing now it's not one to one because uh some of those parameters are a little bit different so instead of triggers we have triggers replace but more or less you know you can almost replace it and get the exact same result and you know I would recommend it over using null I was trying to figure out if there was a case where you'd want to use an all resource but I really could not determine that it did not seem like there was anything additional so yeah there you go it's as simple as that foreign hey this is Andrew Brown from exam Pro and we are taking a look at terraform providers so providers are terraform plugins that allow you to interact with cloud service providers like AWS Azure gcp software as a service provider so GitHub and Golia stripe or other apis such as kubernetes or postgres servers there's a lot there there's like over a thousand providers so providers are required for your terraform configuration file to work so you have to have at least one provider and providers can come in three different tiers we have the official one so published by the company that owns the provider technology or service verified so actively maintained up to date and compatible with both terraform provider communities so published by Community member but no guarantee of Maintenance up to date or compatibility providers are distributed separately from terraform and the plugin must be downloaded before use so if we do terraforming knit this will download the necessary plugin provided plugins listed in the terraform configuration file so there you go hey this is Andrew Brown from exam Pro and we are taking a look at the terraform registry so this is a website portal to browse download or publish available providers and modules and just remember providers and modules are plugins within terraform both of them okay so to get to this website we go to registry.terraform.io and everything published to the terraform registry is public facing so let's just distinguish between providers and modules and I feel that I should have given providers a little bit more attention in the uh in its own slide but I'll give it a clear distinction between providers and modules here so a provider is a plugin that is a mapping to a cloud service provider's API so if you wanted to call individual API actions that is what the provider is providing to you when we're talking about modules a module actually relies on a provider plugin but a module is a group of configuration files that provide common configuration functionality this is going to help you enforce best practices reduce amount of code code reduced time to develop scripts so the way to think about it is imagine that you have to do something in your CSP like AWS and there's just common things that would go along with it so let's say you're launching a load bouncer Auto scaling group with ec2 instances that's a bunch of services that you are just very common you'd have to configure it together so there could be a module that allows you to do all that with writing very little amount of code it will choose best practices when doing that okay let's take a look here at providers and modules within terraform registry really quickly so um here is the AWS one here and so I just want to point out that this official one is by hashicorp it's not by AWS but it does mean that it has uh proper support so you know it's going to have pretty much onetoone mapping to the AWS API um and so it has really really good documentation now I complain about terraform not having great documentation for learning like their language but for the actual documentation of doing things practically they're really really good and here's just an example where we see app mesh and they just give you full examples for basically everything it's really great and if you need a code sample to get going like to actually install it within your configuration file it's right there over here so you can just go ahead and grab that for terraform modules it looks pretty similar so the idea is you get your module code on the right hand side here you want to check out the examples it's going to be dependent on who is developing these modules this one is made by Anton so he has lots and lots of really great examples and then you can see a list of dependent modules here under sub modules so it's not too complicated so there you go so we're taking a look at terraform registry which is a public registry but let's talk about private registry how would we do that well that's where we use terraform Cloud it allows you to publish private modules for your organization within the terraform Cloud private registry when creating a module you need to connect to a Version Control System of VCS and choose a repository so here you can see we can be using something like GitHub gitlab betbucket or azure devops and of course we're going to cover terraform Cloud a lot more further on in the course and it does definitely does more than just act as a private registry but I figured this is the best place to put it against the terraform registry okay let's take a look at how we would get a list of the current providers you are using so all you'd have to do is type in terraform providers and you'd get a full list this command is useful if you have a very complex architecture where you're using a lot of files and modules within terraform I wanted to just show this command just because I saw it on the exam and so it's just an easy point if you happen to get that question okay so we know we can set multiple providers of in our terraform configuration file but there are some variations here that you should know so one thing is is that if you need to have an alternate provider you can use this thing called Alias so if you just notice here there's the Alias this is useful if let's say you want to have resources within different regions of AWS is a very common use case when you want to reference uh what resource should use with provider you're going to have that little provider attribute and then you're just going to do what the name is of the provider followed by the Alias you can also set an alias provider for a parent module so notice here in the required providers we have this attribute here and we're using this configuration Alias and then if you need to set an alias provider for a child module but more or less you just need to remember these two up here okay for setting an alias hey this is Andrew Brown from exam Pro and we're giving closer attention to modules so a terraform module is a group of configuration files that provide common configuration functionality to enforce best practices reduce the amount of code and reduce the time to develop scripts I definitely had a lot of confusion understanding the difference between a provider and a module initially but the clear thing is that a provider is just an API mappings to the service okay so on the example here on the left we have AWS as a provider and the example is to show you if you had to create a VPC you'd have to specify many networking resources and just notice that I have the three ellipses there to suggest there is a lot more that you'd have to configure but by using a module and there's one called the AWS VPC module it basically has this short domain specific language that allows you to quickly provision a VPC so the easy way to remember modules is Imagine clicking a wizard that creates many Cloud resources like it able to have the VPC wizard that's basically the idea behind modules just to kind of give a better contrast to the value that modules have we'll look at the Azure provider so imagine you had to provision an Azure virtual machine this is how much code you'd have to write so it's going to vary based on providers so AWS does not require this much work it's very short gcp requires a little bit more work and for some reason Azure requires a lot so this is a case where you'd want to use a module so there's a module called compute and network module and it reduces the code to amount of this still a bit long but that's just what it is okay thank you all right let's talk about the fine line and this is understanding the gray areas of responsibility between terraform infrastructure as code and thirdparty configuration management tools like ansible so there are cases where when you get outside of AWS as your gcp you might see providers like for postgres database and you might say okay well what part of terraform should be automating it and so that's a little bit more complicated question because terraform does more than one thing so terraform has providers modules and provisioners and then on outside of that if we're not even using terraform we have thirdparty configuration management tools that we can use like ansible and the thing is is that you could have ansible do everything but that does not mean that you should have it do everything and with terraform at more or less most of these levels you can have them do everything but that doesn't mean that they should right so the idea is to try to figure out what should be where and how to define that so let's talk about creating a database so if we created a database that is like setting up a new service so that is going to be under the providers and so you'd use the postgres terraform provider to set up a database now you have users and so users are an entity they're not just like loose data so there's something that you can add remove add permissions to and we would treat them as entities and so it wouldn't necessarily be under the providers but that's a great place to put it under modules okay then you have your data so where would the data go well data is not necessarily an entity it's just a bunch of data so I would say that that is for provisioners that can run random scripts and then when we want to do things like backup tables to data warehouses or truncate data daily tables things that are repetitive tasks that is what we're going to use ansible for or a thirdparty configuration management tool outside of terraform you wouldn't have terraform to that stuff at all so when you have a task done one time to set up the database like seating data it's going to go to provisioners what you have repeatable tasks for ongoing maintenance it's going to be out as a third party provider and if you have something that is like identified as an identity like as a resource that you want to manage like Asset Management which are these things these are going to be over here in providers and modules I do want to point out that a provisioner can be using ansible but we would still want to use ansible or thirdparty configuration management tool isolate or separate to do these kind of things you do not want terraform running these okay foreign hey this is Andrew Brown from exam Pro and we are looking at Hashi Corp configuration files also known as terraform files that which contain the configuration information about providers and resources this is basically core to terraform and that's what we're doing so terraform files and in the extension of dot TF or TF Json and we'll talk about the Json case a little bit later but terraform files are written in the terraform language and so here is kind of an abstract way of looking at the language I know it's confusing here but don't worry we're going to reiterate on it to make more sense but terraform language consists of only a few basic elements you have blocks and so these are containers for other content and they represent an object so I'll have a block type which can have zero or more labels and a body you have a block label it's a name of a block you have arguments which is which is what you assign a value to a name so notice like we have assignments so we have identifier to an expression okay they will appear within block so here it is within a block as you can see um Expressions represent a value either literally or by referencing and combining other values they appear as values for arguments or within other Expressions you might come across hashicorp configuration language so HCL and this is the low level language for both the terraform language and alternative Json syntax I don't know if we'll be getting into it in this course um or if there's even an easy way to distinguish it because it's basically terraform language but just if you see HCL just think terraform language it's the easiest way to think about it okay let's take a look here at the alternate Json syntax so terraform supports alternate syntax that is Json compatible terraform expects Json syntax files to be named dot tf.json so we mentioned that earlier and so this is generally what it would look like okay the syntax is useful when generating portions of a configuration pragmatically since existing Json libraries can be used to prepare the generate configuration files and that's pretty much it would you want to work on this it's up to you um but uh yeah so that's the reason for this alternate syntax all right let's take a look at terraform settings so the terraform configuration block type terraform curly braces you'll see this within your configuration file is used to configure some behaviors of terraform itself so here is what it looks like and what's very common is you're going to see those required providers so there are different things that we can put in here so we can put the required version so this expects us to match to a particular version of terraform required providers this is the providers that will be pulled during the terraform init we can also do experiments here so these are experimental language features that the community can try and provide feedback on and then we have provider metadata so this is module specific information for providers okay hey this is Andrew Brown from exam Pro and we are taking a look at the hashicorp configuration language also known as HCL I'm going to tell you I was really confused at the start working with terraform because sometimes they mention things like hashicorp configuration files hashicorp configuration language terraform language and I could not discern you know what the difference was but so this is the idea here is to give you that Clarity okay so HCL is an open source toolkit for creating structured configuration languages that are both human and machine friendly for use of command line tools and it's an open source project so you can find it at github.com HCL so the idea is that they have this Baseline language that you can extend for your own use case so uh terraform is using it and so it uses a good like it uses the language itself but then it goes ahead and extends it by adding additional functionality for its specific use case and this HCL based language is not just for terraform it's used for hacker templates Vault policies boundary controllers and workers console configuration Waypoint application configuration Nomad job specification and this one isn't a hash Accord product but this is an open source project called Shipyard and you can use it for Shipyard blueprints surprisingly Sentinel which is a Hachi Corp policy as code server service does not use HCL but it has its own HC ACL custom language but the idea is that you know we're looking at mostly the use case is for hashicorp services but if you wanted to extend this language for your own use case you totally could and so I think that's really cool but hopefully that kind of distinguishes between HCL and terraform language okay hey this is Andrew Brown from exam Pro and we are taking a look at input variables so also known as terraform variables or just variables are parameters for terraform modules that is the way we get data in to our configuration scripts is via input variables so you can declare variables in either the root module or child modules and the way you define them is via this variables block there at the top and just to kind of go over the possible fields for that block we have the default option so the default option which is here is going to be the default variable if you do not set it for type this is an argument that specifies the value types that are accepted for the variable so this case up here we can see string and this one is a list for description this specifies the input variables documentation we don't see an example there I believe that is optional but it's always great to put a description in when you can there is a validation block so a block to Define validation rules usually in addition addition to type constraints so we don't see that here on the right hand side but the idea is that you know let's just make sure that there's less of a human error entering the wrong information you can also have sensitive this limits terraform UI output when the variable is used in the configuration and we will cover sensitive a lot more in this course outside of just this one slide okay let's take a look here at variable definition files and these allow you to set the values for multiple variables at once so variable definition files are named with the dot TF vars extension or if you want to use the alternative syntax it's the tfbars.json file by default if you have a file called terraform.tfrs within your project directory this will be automatically loaded so it's pretty common to make that file to create a definition file it just uses the terraform language so you would just assign values here you wouldn't make variable blocks but you just Define these um identifiers and give them values okay another way of loading input variables is via environment variables and this is very common uh way of loading them if you have your own CI CD process for terraform so if you're using terraform cloud or you're using some kind of build server that's going to be the primary way you're going to get variables into those build servers probably won't be doing this much locally but the way it works is that terraform will watch for any environment variable starting with TF underscore VAR underscore followed by the name this is very important to remember because it definitely will show up on the exam so let's say we want to do set a variable for an image ID so we do TF underscore VAR and then image ID probably most cases when you follow the name it's going to be a lowercase underscore I don't think you'd probably want to uppercase that stuff and you just set the value okay so there's a lot of ways for us to load input variables we just saw two so we saw terraform tfrs and environment variables but there's a lot more caveats to this so let's just run through them so we already covered uh terraform.tfrs the idea here is that if you create this file and it's in your project it will automatically be loaded when running terraform apply you can name other TFR files uh so I just called them use additional TFR files but they won't be loaded by default you'll have to use a command line to load them this is useful if you have like a Dev and prod environment and you want to swap those out now if you want to have files that auto load then you can just put the dot Auto here and give it any name you want this would be useful if let's say you had a very large terraform tfrs file and you wanted to break it up to make it more human readable you could do that then you have the hyphen VAR file flag when you're doing terraform apply or or plan and this is actually how you load up these additional variable files if you need to override a single value you you can use hyphen VAR so here I'm overriding the ec2 type to be T2 medium and then lastly here we have environment variables we covered this this is where it starts with TF underscore VAR underscore followed by the name and this is going to be very common when you are using Code build servers or runtimes to run this in a CI CD automated way now there's a precedence to which these get loaded meaning that that certain configurations of or input of variables will override other ones so as we go down this list these ones will override the previous one so at the top you have environment variables if you have a terraform tfrs file that will override the environment variables if you have the Json one that will override that one if you have auto files that will override the default tfrs file and then on the last list you have hyphen VAR and hyphen VAR file will override the rest so there you go in terms of the exam they're not going to ask you the president's here but you're going to need to know what VAR VAR file are environment variables are in this default line okay thank you foreign let's take a look here at output values which are computed values after a terraform apply is performed output values allow you to obtain information after resource provisioning such as a public IP address I'll put a file of values for chromatic integration crossreference Stacks via outputs in a state file via terraform remote State and so here's an example of an outputs block so notice that there's a block and you specify some stuff there you can optionally provide a description it's not necessary but generally with outputs I would recommend putting that in there you can also Mark it as sensitive so it does not show in your terminal this is important if you're doing like logging stuff you don't want to compromise those values there but understand that output values even though they might not be outputted to your terminal or SD out they will be visible within the state file so if somebody opens up the state file they're going to be plainly visible there so just understand that sensitive does not protect the values there okay now in terms of how we would use the CLI with the output values if we type terraform output it's just going to print out all the values that are within the state file I don't show this in the example here but if you wanted to use a um a like bash command to parse Json you could extract them out and see they're just plainly in the Json okay if you need to get exactly a particular field you type in terraform output and Then followed by the name if you wanted an adjacent format all the output then you could give that flag I don't know if it would work with this one I actually didn't test I just thought about that here for this one here if you want the raw output of it meaning like if you output a string and you want it to be escaped or what have you then you could use it pragmatically by passing it to something like curl to do something but the idea with all these output values is that it's one way of inspecting but you could also use this in a configuration script or or something to do kind of like an after action okay all right so we're taking a look at local values also known as locals that assigns a name to an expression so you can use it multiple times within a module without repeating it so here what we're going to do is Define our local block up here and then the idea is that we're assigning these names or IDs expressions or values so that we can reuse them throughout our code notice that we can Define multiple local blocks in the same file and I just say this because like when you use required providers you're only allowed to have a single block but this case like with variables or locals you can have many and you could even Nest them within each other so notice down here we're referencing local within a local so that's totally possible and I imagine it's in the order to which it is specified we can do static values or computed values so we can actually here's a function write an expression and then it will output a value once a local value is declared you can reference it via the dot as local dot the name so here notice within our it was resource we have local and common tags I have to point this out but when you're referencing you use the singular local because you might get an exam question which shows you local dot or locals Dot and the trick here is you got to remember which one it is locals help can help dry up your code it is best practice to use local sparingly since it's uh in terraform it's intended to be declarative and overuse of locals can make it difficult to determine what the code is doing this call comes back to describing terraform as declarative plus where they give you functionality that's imperative like but the idea is that you know if you overuse these you can run into trouble okay hey it's Andrew Brown from exam Pro and we are taking a look at data sources for terraform so the idea here is you want information to find outside of terraform and it's defined by another separator from configuration or Modified by functions so the idea here is we are going to Define ourselves a data block and we have an external resource we're looking for so we're saying hey I want to see if I have an AWS Ami we're going to use these filters as a way of of kind of selecting it within our AWS account so we'd have a provider set up and so it'd be looking within that account to find it and it's even saying look for the most recent Ami okay and once we have found that data source we can just reference it so notice we're using data to reference it there so data AWS ami.web ID so there you go we're taking a look here at name values and these are builtin Expressions that reference uh various values you'll find your configuration scripts we do cover these in their respected sections but I wanted to consolidate them here in one place just so that you get a second chance to reinforce this information because Crux of questions of the exam could be based on knowing how the name values work so let's go through them the first is resources I'm going to get up my pen tool here and so the way resources work is that you start with the resource type so AWS instance and then you're going to do the name of it so there's nothing that uh starts before the left hand side of it so just remember it just starts with that resource type then you have input variables and that starts with VAR period so that's the singular VAR then we have local values and again that's singular so local period for child modules it starts with module period again singular for data sources it's going to be data singular just remember singular because they can have a matchup on the on the exam questions whether it'll be like data or datas for file system and workspace info we have path.module this is the path of module where the expression is placed we have path.root this is the path of the root module of the configuration we have path CWD this is the path of the current working directory and in practice the default CWD is the same as the roots so those would be technically the same we have terraform.workspace this is the name of the currently selected workspace then we have block local values these are things that appear within a body of a blocks so this could be within a resource provisioners things like that so we have if we're using the count meta argument we're going to get count and with that we'll have count dot index so we can say okay this is the fourth iteration of you know uh this this account Loop then we have for each and this allows us to have the key and the value so we can access that during our iterations we have self uh so selfless uh references information within provisioners or connections so it's just like a selfreferencing thing name values resemble the attribute notation of map or object values but are not objects and do not act as objects you cannot use square brackets to access attributes of name values like an object so there you go foreign hey this is Andrew Brown from exam Pro and we are taking a look at resource meta arguments so the terraform language defines several metaarguments which can be used with any resource type to change the behavior of resources and so we'll quickly go through the list here and then we will Deep dive on each so the first is depends on so this is for specifying explicit dependencies we have count which is for creating multiple resource instances according to account we have four each which is used to create multiple instances according to a map or set of strings provider so this is for selecting a nondefault provider configuration life cycle this is for life cycle customizations provisioner this is and also for connections for taking extra actions after resource creation so there's the Quick List now let's jump into them all right the First Resource meta argument we want to look at here is called depends on and this is the order of which resources are provisioned and is important when resources depend on others before they are provisioned terraform implicitly can determine the order of provision of resources but there may be some cases where it cannot be determined or like the correct order so this is where you can be a bit more explicit so here we have some terraform configuration where we have an AWS instance and it relies on a policy and so what we're doing is we're setting an explicit depends on here so that it knows that it requires that now in a normal use case you would not have to do this but it's hard to find use cases where this happens but when it does become a problem you'll know because your resources will not provision correctly you'll get an error so there you go let's take a look here at the count resource meta argument and this is when you're managing a pool of objects so an example here would be a fleet of virtual machines where you want to use count so here on the right hand side we have an example of us using that in terraform so we can specify the amount of instances we want so here it is four and then we'll have access to this name value called count dot index so the tags will start at zero so it'll be server zero one two and three then just down below here I just want to show you that with count you can accept a numeric expression so you know if you had a variable that you had set as the subnet IDs or even just an arbitrary number like you want to have X amount of servers this would allow you to do that okay but just so you know those numbers must be whole and a number must be known before the configuration which you'd put in your input variables okay all right so let's take a look here at four each which is for iterating over resource meta arguments but it's slightly different because it allows you to map over Dynamic values giving you a little bit more flexibility so here's an example of us defining A4 each and notice that we have defined a map sometimes I call it an object because they're so similar but this is a map and the idea is that once you have your map defined with your 4H you will now have access to these name values so you can do each dot key or each dot value to extract that out you can also just use it like with an array so here we have an array and then we use two set to turn it into a set which it will accept as well and then we can just pull out the key because there will be no value so just an example of with a map and then with something that looks like an array okay to understand the resource meta argument life cycle we need to understand how resource Behavior works and so when you execute your execution order via terraform apply it will perform one of the following to a resource so the most common one you'll see is a create so these are resources that exist in the configuration but are not associated with a real infrastructure object in the state the way you can tell it's creating it will have this nice little green plus sign the next one is destroy so resources that exist in the state but no longer exist in the configuration and so that's going to tear down your resources out of your Cloud providers this is represented by a minus symbol then you have update in place so the resources who arguments have changed so the idea here is that if you have a virtual machine and let's say you change the size of it it's not going to destroy it it's just going to modify its settings this is represented with a tilde and the last one here is destroy and recreate so resources who arguments have change but which cannot be updated in place due to remote API limitations so there are just some Cloud resources that always require destroy and recreate and this is something very easy to trigger if you are using the replace command or the older terraform tank command in order to replace a degraded or damaged instance so let's talk about life cycle so lifecycle blocks allow you to change what happens to resources on the create update and Destroy lifecycle blocks are nested within resources so here is a resource which is just an Azure Resource Group and within it we have a life cycle block and we're setting our first option here that's possible called the create before destroy so this is a Boolean and when replacing a resource first create the new resource before deleting it so the default is destroyed old first so this is more about just the order of How It's destroyed prevent destroy so ensures a resource is not destroyed then we have ignore changes and this is based off a list of attributes that you feed to it so don't change the resource on create update to store right if a change occurs for the listed attributes so maybe um maybe you uh you're just changing a tag and you say don't don't change uh like don't tear down create or do anything strange if we change a tag okay so there you go that's uh life cycles so we're looking at our last meta argument here which are resource providers and this goes along with the idea of an alias so here we are defining ourselves a provider in Google Cloud but there's a case where we might need to override the provider uh at a at a per resource level and the way we do that is by creating an additional provider and setting an alias and then here we could change something like the region and then once we have that set we can then reference our provider explicitly under a resource and so that's all there is to it definitely on your exam you will see a question about Alias or you'll see that example so definitely want to know how to do that okay thank you all right so we're starting our introduction here into terraform Expressions because there's a lot we can talk about here so expressions are used to refer to or Com or compute values within a configuration so terraform Expressions is a large topic and we'll be covering types and values strings and templates reference to values operators function calls conditional Expressions four Expressions Splat Dynamic blocks type constraints actually I don't think we covered type constraints just because there's nothing really to say about it but we definitely cover version constraints so yeah let's start off the section and go to it so we're taking a look here at types and values for expressions and so the result of an expression is a value and all values have types and so we have primitive types no type and complex structural collection types that last one is a bit more complicated than what we are presenting here we're going to simplify it and then cover it later okay so for primitive types we have strings so you have your double quotations which represent your string then you have numbers so it's going to be integers or floats then you have booleans so this is either true or false for no types we have null and so null is different in all different types of languages so it's very important to understand how it works and so null represents absence or Omission when you want to use the underlying default of a provider's resource configuration option so when you're saying null doesn't mean it's nothing it's going to be whatever the default is and the default also could be nothing it's just depending on what that is on the provider so for collection or for a collection types complex structural types we have list or Tuple and this generally looks like an array the then you have map and object and this looks like basically like a Json object or a ruby hash or I think they call it in Python a dictionary so that gives you an idea of the basic types but for this last one here because this I found really confusing list tuples map object we definitely explain this more in the course okay okay so we're giving a little bit more attention to the string type because there's a little bit more going on here so when quoting strings you got to use double quotes uh at one point terraform I believe supported single quotes I think it only Sports double quotes now and honestly you generally want to just use double quotes because double quotes always support Escape sequences this is pretty much standard across all programming languages but the idea here is you can do things like new line carriage return tab literal quotes literal backslashes Unicode characters both basic multilingual plane and supplementary planes there are some special Escape sequences this makes sense when we look at the next slide for string templates but there's these things where you can do interpolation and so you might not want to actually do them you might want to do it without and so if you just use double of the symbol that will allow you to do it then there is also the ability to have multiline strings and we use hear DOC for that and so here Doc is a little bit different in all languages but here we're using Unix style so that means that we're going to start with these two two angled brackets to the left our opening angle brackets followed by some word that is all in uppercase it doesn't have to be eot it could be whatever you want I always like to type here Doc and then it has to end at the same indentation level with the same word all uppercase and then everything in between will be treated as um as multiline the nice thing about this is that when you have this you can actually just use double quotes wherever you want because you don't have to escape them okay let's take a look at string templates because this is the real power of strings so the first is string interpolation and this allows you to evaluate an expression between the markers so the idea is instead of having to do double quotations and do plus signs to stitch together uh strings what you do is just do a dollar sign uh curly braces and then put the the expression or variable that you want uh to be converted okay then you have string directives and these are slightly different this allows you to evaluate an expression for a conditional logic between the markers so let's say we want to have an if else statement so if the name is blank then use VAR name or sorry if it's not blank then use the name provided otherwise put it as unnamed okay you can also use interpolation directives with hear docs so you know just to show that you can do it and then the last one thing here is you can strip out white space that would normally be left by directors blocks by providing a trailing tilde so just notice this little tilde here on the end because these do take up space so if you were to view it there'd just be an empty space there if you want that space to vanish then you just put that tilde on the end so there you go foreign let's take a look here at the possible operators that we can use within terraform expressions and so just a refresher operators are mathematical operations you can perform two numbers within Expressions I'm not going to show full examples here and the outputs of them because this is pretty common for programming or scripting languages and also the exam is not really going to focus on the use cases for these so it's just more so to tell you what is available too so you know what you can use the first is multiplication so you take two numbers and times them to get a larger number division so it uses a forward slash modulus and if you've never used modulus I really like this it allows you to see if something is divisible by a certain amount and then you get the remainder you have addition subtraction if you need to flip to a negative number you can just put a minus sign in front of it if you need to do equals its doubles if you want to do does not equal its exclamation equals then we have a less than so that's a open angled bracket less than or equal so that will be followed by an equal sign greater than is a closing angle bracket and Then followed by an equal sign for greater than or equal you have or which uses the double pipes you have n which uses the double ampersands if you need to flip a Boolean you can just put an exclamation in front of it so if it was true now it is false if it was false now is true I'm not sure what it would do for an all I would think that it would turn it to true but uh yeah so there you go foreign we're taking a look here at conditional expressions and this is pretty much the only way that you can do ifel statements within terraform but it works out fine and so it's actually using the ternary style of ill if else so what that looks like it's a single line so the it starts with a question mark so that's the if and then it's the True Value and then the colon represents the else and then you have your false value it's ternary because there's three things one two and three okay so that's the way I remember this thing it's not a a preferred way of doing Ethel statements in other languages because it is a little bit condensed but it makes sense when you're using scripting language and you're really restricted on per line actions so this is what it would look like in action so we'd have a variable that is a if a does not equal a blank then use the variable or set it to default a as a string so that's kind of an example there I'll just wipe that away there the return type of it of of the if and else must be the same type so if you have a number okay and the one if statement and then you have a string they have to be the same so uh obviously we want a string to be returned in both cases so what we'll do is use this builtin function to string to turn this into a string so that we're not going to run into any problems so there you go all right we're taking a look here at four expressions and so these allow you to iterate over a complex type and apply Transformations a four expression can accept as input list set Tuple map or an object I want to distinguish this between four each which is a resource meta argument which allows you to iterate over a a resource or a collection of resources that are similar but four expressions are for these primitive types or not these primitive types but these collection structural types that we talked about in types and values okay so here's an example of something we might want to do imagine we have a list of names and we want to iterate through our list and make them all uppercase so we could do that with this four so we have the four with the n and then we're providing the value of each item in our list it's easy to think of list or Tuple as an array so I'll just call it an array okay then you have a map and so this is where it has a key and value this is going to be for maps or objects and the idea is that we can then go apply Transformations and notice that we are returning only a single string so we're actually going to get back something like a tuple and so how does it decide whether it returns a um a array or something that looks like an object we'll explain that here in a moment the last one here is we have a list with an index so it's very similar to the first one but in this case we want to know the index here so imagine this says zero is Andrew one is Cindy two is Peter and it would come back as an array or list so let's talk about the return types the return types are defined by the um uh the braces or brackets that are around the actual expression so if you have square braces we're going to go back to Tuple so it's just think that array so for in this case where we had our list it was returning back a tuple okay if we have curly braces it's going to return an object so here we have a list so it's like an array that's coming in here and then we were specifying as the return uh this kind of object structure and so that's how we're going to get that so that's that there's one other thing we want to mention which has to do with um reducing or ordering so an if statement can be used to reduce the amount of elements returned so in this case what we're doing is we're using an if statement and so we're saying unless this is true so if this is true then return if it's not then return less of what is there so if there's any blank names that are in our list they just won't show up it'll just only show names that are actually there um then we have implicit element ordering so since terraform can convert an unordered type so map objects and sets to an order type list or tuples it will need to choose an implied ordering so for maps and objects they're stored by key A to Z set of strings stored by a strings A to Z everything else is going to be arbitrary ordering so there you go all right we're taking a look here at spy expressions and these provide a shorter expression for the four expression which we just looked at so what is the Splat operator a Splat operator is represented by an asterisk it originates from the Ruby language and Splats in terraform are used to roll up or soak up a bunch of iterations in a for expression so here is an example where it's for list sets or tuples so here we have a list and the idea is that we're iterating over this ID or in this game we're iterating over um its objects or sorry a array and then that array is containing a bunch of objects and so we're accessing the name within it and so instead of writing it like that we don't even have to use it for at all what we can do is put this asterisk here and this is going to equate to the same thing so here this is going to return all the IDS and in this case it's going to return a all the lists and allow us to access the interfaces along to the name okay so let's take a look at spy Expressions uh when we're applying them to lists so if the value is anything other than a null value then the Splat expression will transform it into a single element list if the value is null then the expression uh the then the Splat expression will return an empty Tuple and so this behavior is useful for modules that accept optional input variables whose default value is null to represent the absence of any value to adapt the variable value to work with other terraform language features that are designed to work with collections so I know that's a big mouthful it's just kind of like an edge case to these Spa Expressions this is not going to show up in the exam but I just wanted to show it to you in case you're interested here and just notice the spots being used over here okay foreign so we're taking a look here at Dynamic blocks and this allows you to dynamically construct repeatable nested blocks so I want to emphasize that this is a very powerful feature that can lead to abuse where your code becomes uh difficult to read but it's also very flexible it will absolutely show up in the exam so pay close attention on how this works so let's say you needed to create a bunch of Ingress rules for your ec2 security group and so this would lead to a lot of repeatable elements for rules within your resource and so what you can do with Dynamic blocks is you can Define objects locally so here I have my Ingress rules as an object so here's one and here is two and then using Dynamic block what I can do is use a 4H to reference those Ingress rules and within this Dynamic Ingress block we'll have our content and this will specify the things that we're swapping out so the idea is that it will iterate over this and apply all those values there so it's something you can't do with a 4H or account this is basically the the most advanced iteration but just understand if you remember this use case and it's very easy to understand or remember how to use it when you're doing an exam okay we're looking at version constraints so terraform utilizes semantic version for specifying terraform providers and module versions so semantic versioning is an open standard on how to define versioning for software management so you have your major minor and your patch and so here are examples or variants on this here so we have um you know where you see major minor then you can have this RC this rc1 or you could not have it or you can have beta and this can all be read about on the samver.org but just to quickly go through it major version is when you want to make incompatible API changes minor is when you add functionality that is backwards compatible in matter patch is when you make backwards compatible bug fixes there are additional labels for prerelease build metadata that are available as extensions so that's where we see those little additions there at the top a version straight is a string containing one or more conditions separated by commas so you have your equals or no operators or sorry your equals or no operators so match exact version of the number so it's either with the equals or not with the operator at all okay that's what I'm trying to write there excludes an exact number uh version so if we just said does not or will not be uh 1.0.0 then you have a comparative ones so they have the version has to be greater or equal to 1.0.0 um and then we have one with the tilde so allows only the rightmost version of the last number to increment so what this means is that the the last number here is only allowed to increment okay so let's talk about Progressive versioning because this kind of ties into semantic uh versioning but Progressive version is the practice of using the latest version to keep a proactive stance of security modernity and development agility and we like to describe this as practicing good hygiene when we're uh working with our code okay so by being up to date you're always pushing left on things that need to stay fixed or compatible you'll have to deal with smaller problems instead of dealing with a big problem later on run nightly builds is a good example where you might have golden images and the idea is to provide a warning signal just to kind of elaborate on that a nightly build is an automated workflow that occurs at night when developers are asleep so if the build breaks because A change is required for the code the developers will see this upon arrival in the morning and be able to budget accordingly so what I'm trying to get at is that when you are like putting in your providers especially if you copy from the terraform um the terraform website to get the providers and modules what they'll do is they'll actually have it set as the I'm just going to roll back here for a second but they'll actually have it set as the equals what I'm saying to you is you want to use something like a tilde or a greater than or equal sign so that you are staying Progressive okay so that's just one thing I want you to watch out for and we will talk about that when we go through the follow alongs okay hey it's Andrew Brown from exam Pro and we are moving on to our expression section starting with string templates let's learn all about that and we are going to have to CD into a new folder here so I have one called expressions and we will make ourselves a new file called main.tf we'll Define a local back end and I'm going to just Define a new variable I'm going to call this variable hello and I'm going to give it a type of string okay and that's all I'm going to do there and then what we're going to do is create ourselves a TF VAR file so we'll say terraform Dot tfvars and in there we'll just set hello to world and so what I want to do is enter terraform console okay this is going to allow us to just run arbitrary Expressions I want to show you how you quit it you just type exit and so we'll do is make a string so we'll just first do a Hello World I want to show you that you can put a uh a new line there and we'll get back a multiline document this is a um this console doesn't allow for multiple lines so we can't write our own here doc but I can show you what it looks like and then we can interpolate a uh a variable there so we'll just say hello and notice we get hello world so that's how interpolation works it's not super complicated directives is a little bit different where we have string right so we can do instead this but the control word is a bit different because you're using the uh this um percentage sign the directives when you're doing something like an if else statement so what we could do is say something like um barsoon here okay and what I'm going to do is just exit out here clear because I don't know if it um it reloads the uh the variables there if you just change them on the Fly but what we'll do is we'll just say hello and we will write ourselves an if statement so we're going to say if VAR dot hello equals bar soon what it's going to do is then print out um it's going to instead print out Mars okay otherwise what we're going to get is um world okay you know what's really interesting is we're using the if and else here but I I could have swore that the only thing you had was ternary operators so like if you look at the conditional expressions notice here that it's doing this and it's not showing the documentation the FL so you know maybe maybe that's just for a oneliner and if else does exist for expressions and I might have missed that in the course but you cannot blame me if the documentation shows it like that okay so what I'm going to do here is just go ahead and hit enter and here we get hello Mars so that pretty much uh shows you how string interpolation works for both interpolation and directives we'll just type in exit and so that's all we want to do there okay all right so let's learn about four Expressions so four Expressions allow us to kind of iterate over something and do something fun with it and so what we're going to do is create ourselves some more complex types here so how about instead of like this was just hello a second ago but we'll change this over to Worlds and what I'm going to do is just list out a bunch of Worlds here from the uh the book uh John Carter books so we have bar soon we have jasum we have things like sesum okay and then we have whoops so assume and then we have something like cosume okay and so the idea here is now that we've defined that there we've got to go back to our main TF I'm just going to update this to the worlds this will just be a list all right and so what we'll do is make our way over to terraform cloud or sorry terraform console and we will try to do a four Loop here so I'm going to do Square braces four and we'll just say w in VAR dot worlds and then what we can do here is make a colon whoops okay and then type upper W and so that returns them all in uppercase there and if we were to use the Splat operator and technically this is something we want to move on to the next part but um yeah we'll leave it for the next video I'll just keep that separate so that is for just if we had a list imagine if we had this as the as an index here um or we'll say map because what we can do is actually map these two names so bring this down here and this would be Earth now you can use the colon or the equals it's just whatever you want to use here they're both supported actually this is an Earth this is Mars and then this one here is Earth and this one here would be Jupiter and then this one here would be Venus okay um and so I think we still need to Define it over here so I'm just going to say world's map and then what we can do here instead of having list we can say map and we'll try to iterate over this so it's going to be very similar except the difference is now we have a key and we have a value and so if we just want to return the names in capital we can just do K here oh that's the index uh what if we do oh you know why it's because um we have to do Worlds Map okay so reference to Undeclared variable map so we do have to exit and restart and oh sorry the input was complaining there so I'll just copy the one up here so I have to type it again nope it did not work as we thought okay so I do have to type it by hand kind of a pain but I guess that's just how it works so we'll say 4K V invar Dot worlds map and then we say upper B here okay or we could just say take the K here and get the other values now I didn't show you this a moment ago but if we do worlds here we can specify an index and an index would come first so it would be the value like the world the second and the index is first so notice that I is all a number the index of it and then the that is the value there um we could probably also return this as a map so notice that square braces are going to give you a list or and then curlers are going to give you map which kind of correspond to their actual data structure so if we wanted to turn this into the opposite here what we could do is just say uh we probably do string interpolation like this here and do I and then do equals or even maybe a colon here and then do the world like that and it didn't like the way I specified it so I'll try it like this instead extra characters after the line four so I don't see that wrong there just give me a moment I think um oh you know what it's we need to use in this case I think we have to do it this way okay so we use use the hash rocket so in that particular case you have to use the hash rocket that's what that symbol is called the equal zero um and so that's how we can get that value there so that pretty much outlines how to use um the for loops and next we're going to go probably look at the Splats okay so I'll see you back here in a moment I'm just going to exit this actually before we move on to Splats I just want to add one more thing to four Expressions which is filtering so we'll just go back here and get back into our terraform console here and what I'm going to do is just write another four and it probably would make sense to use the uh the the world's list we just did there so I'm going to do KV type in VAR world's map and so the idea here is that I only want the let's say we'll say the upper I only want the key value here but I would just say at the end here I can say if the V the value equals I can't remember what we set these as so this is key in value so if it is Mars I think it's double equals so if it is Mars then only return it that way or we could say the opposite say give me everything but Mars okay so I just wanted to show you you could use that if to do that filtering so I'm going to exit there and we'll move on to spots okay all right so we're moving on to Splats and what we'll have to do is create ourselves a new variable here I'm going to call this one world's Splat and this one is going to be a list and so if we go back up here to tfvars we'll make ourselves a new variable down here and we'll just call this one splat and it's going to be a list but it's going to contain inside of it a bunch of maps okay so we'll do pretty much this up here okay but what's going to happen here it's going to be slightly different where we are going to set what is the name so we'll just say like um Earth name that's actually Mars name so it's a Mars name here for all these and then over here these are going to be the Earth name so I think that is valid and what we're going to do here is just type in terraform console and if we wrote that correctly oh no we got an error so it says expected an equal sign to Mark the beginning of a new attribute value so I mean this should be okay uh oh you know what I think this Colon's just missing here put it up again there we go we're fine so if we just want to look at that variable I think we just type it in here and it might print it out if we're lucky yes so there it is um so what we're going to do here is use a Splat to get maybe the Mars name or something so if we used a for Loop what we'd have to probably write we could try this but we'd have to do four and then it would be for the actual map so say m for map in world's splat and then we would have to do m Dot Mars name and so a reference to the attribute by one axis treatment specifying the resource name so I mean that looks oh you know it's because we didn't write VAR okay I say we but it was really me so you know that's that but we could write this in a more concise way okay and so we use a splat Mars name okay so you know that's a lot more convenient if we're just trying to access variables like that um I think that if you're trying to do things like if you want to do upper here I think you still have to use A4 expression okay I don't think you can do this we can try it but I really don't think that will work no and if we look at the documentation they don't show an example like that so you know it's not that bad but you can see that it's for a particular use case you can't use that for uh Maps or whatever the equivalent the other map is object but it's useful for this one particular use case okay hey it's Andrew Brown from exam Pro and we are on to the dynamic blocks follow along so this one should be uh pretty fun because it's uh quite a powerful feature so what I've done is I've created a new folder here called Dynamic blocks I'm going to make a new file here as always it's going to be main.tf and a really good example for this would probably be a database Security Group just because there's all those Ingress and out outgress or egress rules so what we're going to do is just Define our terraform settings block and I'm just going to pull up over here and make our way over to the registry for terraform and what we're going to do is go over to the AWS provider and go to the documentation and actually I first want to grab the provider itself because that is something very easy that we can do here we'll just move that on over so we can see what we're doing and paste that on in and we're going to have to Define our provider of course so we'll name that as AWS the profile is going to be defaults and our region will be us East one okay and so now what we need is to cocreate ourselves a security group so we have of course done that previously here but let's pull up the uh documentation here I believe it was actually under VPC so let's just go down to VPC here and we will expand that and then underneath here there should be a AWS Security Group uh there it is and if we scroll on down there's the thing okay so what I'm going to do is copy uh this code here and go over and we'll just paste that on in and there is our security group so I remember that we had to have the description if you remember it complained about that so outgoing for everyone and we need to also have a few additional things we will just scroll on down here because it wanted the prefix list IDs okay remember we needed that I think there was like self false and there was like security groups I think it was actually AWS security groups in particular let's just double check to make sure that is the case it is called uh oh it's just security groups okay so we'll say self equals false we do not need cider block four here or six um we do not need this one here and it doesn't really matter what we set this to so it could be set to the main side or block that's totally fine but we are going to need to add a data source just like last time for the VPC so we'll say VPC we'll call that Main and I think it just needed the VPC ID it was as simple as that and so we will go over to AWS over to VPC and from there we are going to go to rvbcs and I will go grab that VPC ID Okay so we've grabbed our VPC ID and then we just need to name this as data and then we're going to name this as data we don't really care what the cider block is it's just again for um this demo purposes we don't need tags we'll take those out and um yeah everything else is fine okay so this now comes to the fact that we want to use Dynamic blocks before we do that let's just well I think I didn't leave the console there last but what we'll do here is just to our terraform inits and as that is pulling that stuff we're going to look up Dynamic blocks uh terraform so we'll go here and so Dynamic blocks is like way more powerful than um the four each where what we can do I'm just trying to find that example there but we have uh we have to set the dynamic part the 4H you know what I'm pretty sure I have these in my slides so let's just use my slides as the reference here dynamic ah here it is okay so the idea is that we'll just set up a locals with all of our information here and then we will create this Dynamic block and then provide the content okay so I'm just going to move that off screen so I can see what I am doing here as we type it in and we'll see if we run into any problems um failed to query the available product for packages could not retrieve the list of the available versions for the provider uh not have a provider registry terraform name all models should specify the required providers so I'm not sure why it's complaining here but we'll scroll all the way to the top and the required providers is correctly set here so it shouldn't be a problem not sure what it doesn't like um so let's just type in terraform providers here the VPC um is VPC a module you know what it's probably because I didn't do AWS VPC that's probably my problem here terraforming net and as that's thinking there we'll just pull this on down and we'll start to make our locals block okay so we can go here make some locals and we'll do our Ingress and we'll just go like that and the idea is we can say Port whoops we can set the port like that 443 we have to always have a description so we'll just set that as well so port 443 we can set as much as we want here so I'll just go ahead enter okay and I think that looks right yeah so we have one Ingress here and then we'll just copy this and make a comma vs code is not really formatting the way I wanted to and so we'll do port 80. and then down below we will need to specify hour um for each okay so that's going to be within our Dynamic block so what we're going to do is tab in here I'm going to say dynamic and we'll type it Ingress because that's a match for what we're doing um and then from there we can do our four each equals local Ingress and then we need to specify our content I don't really understand why it's called content and things like that but I just know that that's what we have to do and it's not really that big of a deal so we'll go here and paste that in we can take out our Ingress block there we know we're going to need self these all here but what's going to change are these ports so we will go here it will say Ingress Value Port and this will also be Ingress Value Port and then this will be Ingress value description if we really wanted to we could also set the protocol protocol Pro Tove call and this could be then TCP and so we would just say Ingress value protocol so it just saves us from repeating these over and over again if they're all the same there's a lot you can do with Dynamic blocks but honestly you shouldn't do anything too crazy we'll do our terraform plan and see if this works whoops bring that up there um an argument VPC ID as not expected here okay so that was me just guessing from memory and I guess I guessed wrong uh so what we'll do is we'll just look that up AWS VPC data source terraform oh it's just ID okay so what we'll do is just set ID here and then we'll just hit plan again and that should resolve our issue there uh inappropriate value for a tribute egress security groups is required okay that's fine well this one says doesn't say uh Syria groups and this one doesn't say Security Group so that's probably our problem here so we'll just hit terraform plan again and here it says this VPC ID does not exist probably what happened is they might be in the wrong region it's very common problem on AWS just because of the way their UI works if I can get this window over here and so this is because we're in USC's we're supposed to be in U.S east one here and I'm going to go up to here we'll save that let me hit terraform plan and we could probably like use the filter and also just say choose the default but it's just so easy to put that in like that so doesn't seem like we have any problems here so let's go ahead and execute let's just double check to make sure these values are correct so for the Ingress um Port 443 Port 443 it's probably just because I didn't update the description probably because of a copy paste job yep okay and let's just make sure this works so we'll say terraform apply Auto approve and we'll give it a moment and it's already created so it's that fast we can go here and take a look at it if we like it's not that big of a deal um so we should see it in here I just have so many uh junk security groups here this is a bit hard to find oh allow TLS is what we called it so here it is go to our inbound rules 80443 and that's pretty much it so terraform apply destroy Auto approve okay there we go all right so I want to talk about versioning very quickly here and so I have a new folder called versions I'm going to just make a new file called main.tf and we're going to create a terraform block but what we're also going to do is set required uh providers or sorry required uh we're not providers required version and so what this is going to do is say explicitly what version of terraform we want to use and I'm sending it this as 1.0.0 and I'm using this tilde Arrow if you're wondering you know what is the logic behind all those things I think it's all explained in the semantic or semver.org so if you want to learn more I strongly recommend you read through this to understand all the stuff inside and out highly applicable across the devosphere not just to terraform um but you know if we go over to terraform GitHub repository and we drop down the branches and go to tags here we can see all the versioning we are using version 1.0.0 and it all goes up to 1.1.0 Alpha which is not out yet and if you wanted to really know what's going on here you go to releases and you can read what they have done so here 1.0.7 remove check for computer attribute prevent object types with optional attributes for ETC empty containers so when you're looking at the patch the patch which is the third number the the rightmost number that's going to keep you up to date in terms of security for the the major minor version that you have for the 1.0 and you absolutely always want to be using the latest and so that's what this tilde does it says take the far Road uh the the farthest number to the right and make sure that it's the latest version that has been published um and you know this comes back to my Progressive versioning slide which is if you want to have really good hygiene in terms of your devops we should be doing is at least setting the tilde for sure like this the tilde Arrow or I would even go as far as saying equals arrow and if you're really concerned about um you know not using the next major version you could say you will less than you know like less than um less than you know one point 2.0 even if it's not out that's a good indicator to say okay well I don't want to go too far ahead of time but if you want to have Progressive versioning you should really be setting it like this okay and this is going to be applicable for your image providers anything else so you know if we go over to if we go over to the registry and we choose whoops AWS and we drop this down here we have that required version as well so as you copy it in you're going to notice that it's actually hard coded but I would strongly recommend again if we go here and take this and at least at least do this and if you're really really being clever you could do that okay and these are also all in GitHub repositories as that's how everything works so you can go here and click and you can go over to the tags and see the versioning and you can go over to the releases and it's the same thing you can read about all the things that have changed okay and that's something that you should uh you know consider doing all right so that's all there really is to this I might want to show you one more thing and this one is with terraform Cloud so I'm going to go to terraform IO and we're going to open up our terraform cloud and I'm going to sign in I probably haven't signed in a while so probably ask oh nope no username password that's great what we can do is in a workspace we go to settings and is it Version Control no it is general and under here we can actually set the terraform version so if you happen to be working with a particular version you can go and say okay only use this version for terraform cloud and that will um that will not upgrade it'll just keep you there if you need for legacy reasons but again you know what you really should be doing is using that Progressive versioning doing nightly builds and discovering overnight that things are breaking so you can go fix those in the morning okay and that's it hey this is Andrew Brown from exam Pro and we are taking a look at terraform state so what is State well it's a particular condition of cloud resources at a specific time so give an example imagine we expect to have a virtual machine running Centos on AWS with a compute type of T2 micro that would be the state that we are expecting okay so how does terraform preserve State well when you provision infrastructure via terraform it will create a state file named terraform TF State it's very important to remember that name because it literally is an exam question the exact naming of that okay this state file is a Json data structure with a onetoone mapping from resource instances to resource or to remote objects and if you're wondering what is a remote object versus a resource instance I cannot tell you I would imagine one is the representation of things that are deployed in the cloud and the other one are objects or or things represented in the state file but they don't clarify it so I just have to take a guess so this is kind of what the Json structure looks like like you can see you see resources this is describing like a type of instance and stuff like that there's not really any case for you to ever go through the terraform State file and look at it but we might take a peek just so that we get familiar as to what it is doing so just to kind of give it a diagram to help you visualize this imagine you have your configuration file so you have your main TF maybe a variables TF a TF bars to load in your variables and then you run a terraform apply command what it's doing is using the terraform API and it's going to create what we'll say these we'll call these remote objects but maybe these are resource instances um but it will go ahead and create those things and then those will get represented within a state file so the idea is that whatever is in the cloud is going to match what's in that file okay now there is a CLI commands for terraform State and it's good just to quickly go through them so we have terraform State list this will list resources in the state terraform State move this will move an item in the state terraform State pull pull current remote State and outputs to St out terraform State push so update remote States from a local state terraform State replace provider so replace a provider in the state terraform State removed so remove instances from the state terraform State shows so show a resource in the state some of these are a little bit interesting so we'll definitely look in Greater detail to move and some of these people just explore through our follow alongs okay foreign special attention to terraform State move because it's definitely on the exam uh and it is a little bit interesting to what it can do so terraform State moves allow you to rename existing resources move a resource into a module move a module into a module so if you were just to rename a resource or move it to another module and run terraform apply terraform will destroy and create that resource but State move allows you to just change the reference so you can avoid a create and Destroy action so an example for renaming a resource we would have terraform State move and then we would have the we would identify the old one so here we have packet device dot worker and we are renaming it to helper so it's we that's just how we're doing it okay if we wanted to move a resource into a module what we do is say something like packet device dot worker and then do module.worker.packetdevice.worker okay so the idea here is that we're moving it into this module here uh and I think we could probably even rename it at the same time but uh we're not doing that okay so move module into a module so here we have module app and then we're moving it into the parent one so we go module.parent module.app okay so what's important to remember for the exam is that terraform State move is when you want to rename existing resources they're not going to get into these more complicated use cases but that's how you rename a a resource okay okay let's talk about how we back up our state file so all terraform state subcommands that modify state will write a backup file so readonly commands will not modify it so imagine listen show will not cause a backup file to be created terraform will take the current state and store it in a file called terraform.tsstate.backup so this is what it would look like backups cannot be disabled this is by Design to enforce best practices for Recovery to get rid of the backup file you would need to manually delete the files so there you go foreign from exam Pro and we are taking a look at terraforming knit so it initializes your terraform project by downloading plugin dependencies so providers and modules creating a DOT terraform directory so that's a hidden directory and creating a dependency lock file to enforce the expected versions for plugins in terraform itself so on the right hand side here we can see we have that hidden directory but also notice here that we have a DOT terraform lock.hcl that is our dependency lock file and so our dependencies are all going to end up within this sewers as providers that's the provider version there okay so terraform in it is generally the First Command you will run for a new terraform project if you modify or change dependencies run terraform in it again to have it apply the changes you need to know that for the exam because they will absolutely ask you that the First Command here is and these are ones with flags so you can just do terraform in it but we have some extra options so terraforming it hyphen upgrade upgrade all plugins to the latest version that complies with the configuration version constraint terraforma knit hyphen get plugins and I think it's supposed to be equals false there but skip plugin installation terraform init plugin hyphen dir equals pass so Force plugin installation to read plugins from only target directory and then we have terraform init hyphen lock file so you can change the lock file mode it actually doesn't say what the modes are so I don't even know what you'd do in that case and I could not find any examples but it is an option I just want to make it very clear that there is a dependency lock file but there's also a state lock file and the way you know that they're different is that one has Dot Lock in it and the other one has dot TF State this one up here is for dependencies this one of course is for State a terraform and it does not create a state lock file that is going to happen when you do a terraform apply okay let's take a look at terraform get so terraform get command is used to download and update modules in the root module so when you're a developer you own terraform modules and you may need to frequently pull updated modules but you do not want to initialize your state or pull new provider binaries and so the idea here is terraform get is a lightweight way it's because it's only updating the modules it's not pulling providers in most cases you want to use terraform init with the exception of local module development this will not show up on the exam but I saw terraform getting I was just so confused about it so I just wanted to make sure I included it here okay okay so we're going to be looking at three CLI commands that are used to improve debugging configuration scripts the first is going to be terraform format this rewrites terraform configuration files to a standard format and style terraform validate this validates the syntax and arguments of terraform configuration files in a directory and then you have terraform console an interactive shell for evaluating terraform expressions and so let's go jump into these three okay all right let's take a look at terraform format so this command applies a subset of terraform language style conventions along with other minor adjustments for readability so terraform format will be by default look in the current directory and apply formatting to all your dot TF files so let's look at some examples of what it would format so the first is adjusting spacing two spaces indent so here we have something and it's over indented and so by running terraform format it fixes the indentation we can also get syntax errors so notice here that we have a problem and so what it's saying is is that this bracket okay is supposed to be up here okay but it's all it's down here uh and the last one here is we can do terraform format hyphen hyphen diff that's going to show what it would change okay so there you go let's take a look at terraform validate so this runs checks that verify whether configuration is syntactically valid and internally consistent regardless of the provided variables in existing state validate is useful for General verification of reusable modules including correctness of attribute names and value types so here's an example where I just had some code and there was a problem it's just saying you're missing your argument because for an AWS instance you always have to specify an instance type so when you run terraform plan or terraform ply validate will automatically be performed one thing I need to mention about terraform validate is that it does not go to external resources to check things are valid so if you have a a value and it's expecting a string that's all it's going to check for it's not going to check that the string is actually a proper uh like type of size so if it's supposed to be like a t2.micro and you write you know gobblegoop in there it's not going to know that that's not a valid type so but we do cover that in the follow along so I think we have like some practice exam questions that cover that use case okay we're taking a look here at terraform console and this is an interactive shell where you can evaluate expressions so the idea is you type in terraform console and what I can do is I can you know use like builtin functions and expressions so there I'm using Min and I've actually entered it in incorrectly so there it's throwing an error and here I'm using the correct way of using it so I get the output so this is a great way just to kind of test very simple things you can't do things like Define variables or or resources or Define providers but you if you need to figure out how the Expressions work before you apply them in your code this is a great place to do that okay all right let's talk about terraform plans so this command creates an execution plan also known as a terraform plan and it consists of reading the current state of an already existing remote object to make sure that the terraform state is up to date comparing the current configuration to the prior State and noting any differences proposing a set of change actions that should if applied make the remote objects match the configuration and so this is an example of one that's generated you're going to see it uh throughout this course multiple times so it's not going to be unique that's why I don't have to make that too big for you there terraform plan does not carry out the proposed changes that's going to be the responsibility of terraform apply and a terraform plan file if you happen to generate one out is a binary file so if you open it up it's just machine code you cannot make sense of it okay so when you run terraform apply you have speculative plans and save plans and so speculative plan plans is what's going to happen when you run terraform apply so the tear so terraform will output the description of the effect of the plan but without any intent to actually apply it when you have a save plan you're going to have this hyphen out flag to save it and you can name that file whatever you like and it will generate out that save plan file and again that's a binary file so you're not going to be able to see what it does and what you can do is then pass it along to terraform apply so you do terraform apply whatever the file name is and when you are using terraform apply what you have to understand is that it will not allow it will not ask to manually approve it as you normally would it would just be Auto approved so that's one thing you have to watch out when using those safe plans but you know I just wanted to make it concretely understood that terraform plan can generate at a file uh and it's not actually the one that's doing the apply okay I don't have it written in here but when you do terraform apply it also is running terraform validate as well okay thank you let's talk about terraform apply here so terraform apply command executes the actions proposed in an execution plan and it has two modes the automatic plan mode and the saved plan mode so for automatic plan mode that's just when you run terraform apply what it's going to do is execute the plan validate and then the apply uh you can or you have to manually approve the plan by writing yes but if you want to skip that process you can use the hyphen Auto approve flag to automatically approve the plan we just saw save plan mode like how it worked in the previous slide but let's cover it again so when you provide a file name to terraform to the save plan file it's going to be terraform apply file and it's going to perform exactly the steps specified by that plan file it does not prompt for approval so if you want to inspect a plan file before applying it you can use terraform show okay all right let's talk about managing resource drift so drift or configuration or infrastructure drift is when you're expected uh resources are in different state than your expected State and the way we can resolve drift are in three different ways in terraform we can replace resources so when a resource has become damaged or degraded that cannot be detected by terraform we can use the hyphen replace flag we can import resources so when an approved manual edition of a resource needs to be added to our state file so we use the import command and refresh state so when an approved manual configuration of a resource has been changed or removed we're going to use the refresh only flag to reflect the changes in our state file it's very important to know these three different ways they will all show up an exam and in practice you're going to need to know them okay foreign let's first here take a look at replacing resources so we can use the terraform tank command it is used to Mark a resource for replacement the next time you run apply and why would you want to Mark a resource for replacement well the idea is that um you know and here's the command here but a cloud resource becomes damaged or degraded and you just want to return the expected resource to a healthy state so that's the idea behind it and the unfortunate thing is that terraform taint was deprecated in version 0.152 however there is a better way of doing it now and so it is recommended to use the hyphen replace flag and providing it a resource address when you're doing a terraform apply so it's basically the exact same thing the reason why they made this change was so that um you actually have an opportunity to confirm your change beforehand because terraform tank would just run and this one down below will actually prompt you to say are you sure you want to do this okay but it's not complicated you just do a hyphen replace and then you use the resource address of the thing that you want to use that for and this can be used for both plan and apply the replace flag appears to only work for a single resource so you can't use multiple resources it's just one at a time and that's something that you should remember okay so we just saw a resource address and resource addressing is very important to know for the upcoming commands let's just give it a bit more attention here so resource address is a string that identifies zero or more resource instances in your configuration an address is composed of two parts so the module path and the resource path and just expand out that module path it would be module.module name module index and then on the resource spec this is resource type.resource name and then if there's multiple instances you give it an index so module path addresses a module within a tree of modules a resource spec address is a specific resource instance in the selected module so a module is the namespace of the module module name is user defined name of the module module index when the multiple so when there's multiple specifying index on the other side that's your resource type your resource name an instance ID most of the times you're going to be just working with resources but once you start getting to modules it becomes pretty simple it's always going to be module period because that's just I think that's the name of the name value so it's always going to be module Dot and then the module name but here we have a very simple example just for resource type so here if we had a resource called Abus instance and it was web and there was four of them and we wanted to select the third one we do AWS instance dot web Square braces three and that would get us the third virtual machine so there you go foreign terraform import and this is a command that is used to import existing resources into terraform so this is how you define it so you'd say what resource you want and you can just leave it blank so do you define a placeholder for your imported resource and configuration file and you can leave the body blank and fill it in after importing but it will not be autofilled so you do have to specify all the values okay so the idea here is you're going to do terraform import AWS instance dot example and then the name of the ID so that Maps over to the resource address and the ID okay the command can only import one resource at a time this sounds very similar to that other command we saw for replace not all resources are importable you need to check the bottom of the resource documentation for support okay okay so we're going to look at refreshing and so we're going to break this between the old command refresh and the new command refresh only across two slides so terraform refresh command reads the current settings from all managed remote objects and updates the terraform state to match so here we have the terraform refresh and I just want to point out that the terraform refresh is basically the Alias for terraform apply hyphen refresh only hyphen Auto auto approved so you technically have this functionality in the latest version it's just that you can't use the old Alias terraform refresh terraform refresh will not modify your real remote objects but will modify the terraform state so terraform refresh has been deprecated and the refresh only uh and with the refresh only flag like it's been replaced with it because it's not safe since it did not give you the opportunity to review proposed changes before updating the state file so that's why the reason they got rid of it let's take a look here at the refresh only mode so hyphen refresh only flag for terraform planner apply allows you to refresh and update your state file without making changes to your remote infrastructure just to really make this clear I want to give you a scenario and I want you to pay close attention here to understand the difference because this is so important on the exam and also extremely useful for your daytoday operations so here's a scenario imagine you create a terraform script that deploys a virtual machine to AWS you ask an engineer to terminate the server and instead of updating the terraform script they mistakenly terminate the server via the AWS console because they don't know any better so what happens if you were to run a terraform apply versus with a refresh only flag so that's what we'll do with and without the flag so without the flag first terraform will notice that the VM is missing terraform will propose to create a new VM so the state file is going to be what's considered as correct and the changes and so changes to the infrastructure will be made to match the state file okay if we use terraform apply hyphen refresh only terraform will notice that the vmu provision is missing but with the refresh only flag it's going to know that the that the VM is missing it's an intentional okay so I have a couple spelling mistakes there but the idea is that it knows that the VM is supposed to not be there so terraform will propose to delete the VM from the state file so just the Json code from the state file so the state file is considered wrong and changes to the state file will be made to match the infrastructure so hopefully that makes it clear okay foreign how we would actually go about troubleshooting terraform so there are four types of Errors you can encounter with terraform uh the first is language error so terraform encounters a syntax error in your configuration for the terraform or HCL language you have state error so your resources States has changed from the expected state in your configuration file core errors so a bug that has occurred with the chord Library provider errors so the provider's API has changed or does not work as expected due to emerging edge cases and when we talk about what's easy for us to solve and what's hard well the first two are very easy and the other two are harder to solve so for language errors we can use format validate or version to resolve our language errors version would just be say hey what version are we using maybe we need to update it right validate with detect if something's wrong with um the uh the the syntax and format would fix formatting syntax but you know that probably wouldn't fix that much there for State errors the idea here is we might want to use refresh apply replace everything that we saw in the drift section for core errors we might want to go check out the log so TF underscore log is basically just the way of saying like hey these are where the log files are or is logs turned on we have a whole slide on that but really like all you're going to do is use the logs to find information and then report a GitHub issue since all terraform is on GitHub you just go there and then somebody would try to resolve it and the same thing with providers providers are all hosted on GitHub and so you would just use TF logs to try to find some information there but we'll take a look a greater look at TF log and how to you know get that information for the harder to solve cases okay okay so let's talk about how we would go about debugging terraform via the log file so terraform has detailed logs which can be enabled by setting the TF underscore log followed by the type environment you want to run so the variables that we have or the environments we can specify is Trace debug info warn error or Json Json will output logs at the trace level or higher and use parsable Json encoding as the formatting okay so logging can be enabled separately so you can do this via TF log core or you can get it at the TF log provider so if you just want core stuff or if you just want provider stuff you just set those environment variables and as we saw in the previous thing that there you know there was core errors and provider variables so that could be a good way to do that and so TF uh TF core TF log core and TF log provider take the same environment variables we see on the right hand side there Trace debug info Etc okay if you want to choose where you want to log things you just can set the TF log path I don't think I actually say where the default path is I think it's actually in the the project directory but if you want to override that you can I imagine it either takes an absolute path or a relative path and here's an example of a terraform log so this is for everything and so there you can see information I'm going to get my pen tool out here for a moment but you can see we have information about the provider this is using um there then there's some backend local stuff so you know there's some information you're not expected to understand this information generally but you could go bring it to the provider but you could probably solve something you know if you were to read the core code or the provider is okay okay so we looked at TF log which is the terraform log but there's also a crash log and so if terraform ever crashes and basically this means it goes into panic because it uses the go runtime it saves a log file with the debug logs from the session as well as the Panic message and back Trace to the crash.log and so I imagine this is golang information so I don't use golang that often but you can see we have dot gopanic.go so I think that there's not much you can do with it so this is where you would just create a GitHub issue and pass it along to the terraform team because they're going to be able to make sense of it okay foreign so we're on to our module section uh so let's first talk about how we would go find a module I know we already saw this earlier when we were looking at the terraform registry but let's just cover it again and talk about some of the uh uh details of search okay so terraform modules can be publicly found in the terraform registry and so on the left hand side when you're under the modules within terraform registry you can filter your providers okay but another thing you can do is you can type in Search terms and you can do partial Search terms like Azure compute but what I really want you to know is that only verified modules will be displayed in Search terms and so I assume that means verified and also official ones and the reason I'm giving this extra emphasis is because it was an exam question so I just want you to know that only verified and official ones are going to show up when you search okay foreign let's talk about using modules and there's our public modules and private modules so public modules are going to be on the terraform registry and private modules are going to be in terraform cloud or I suppose terraform Enterprise so terraform registry is integrated directly into terraform so it makes it really easy to start using them so all you're going to do is use the module block so I'm just going to highlight that there then we have the name of our module we're providing the source of our module and then there's the version of our module terraform init command will download and cache any module referenced by a configuration now looking at private modules it looks very similar um it's just that the name is different so we're specifying the host name in front here and a namespace as well so to configure private module axis you need to authenticate against terraform Cloud via terraform login so that's something there we definitely cover that a lot in the Brax exam so just in case you know you know all the education is there alternate alternatively you can create a user API token and manually configure credentials into CLI to configure the file so there you go foreign let's talk about how we would go about publishing modules and this in particular is for the terraform registry so these are public modules so if we want to publish modules it supports versioning automatically generating documentation allowing uh users to browse the version histories showing examples and read Maze and all of these modules are actually going to be hosted on GitHub so the idea is you're going to put your module there first and once a module is registered to push updates you simply push new versions to properly form get tags you have to name the your your modules in a very particular way on GitHub so the thing is it has to start with terraform hyphen then the provider so AWS and then the name so hyphen VPC and the way you publish it on terraform registry is you have to connect and publish via your GitHub account so you just hit sign in with GitHub and it's just going to give you a drop down and you're just going to choose the repo and that's as simple as it is okay foreign all right let's talk about verified modules so these are reviewed by hashicorp and actively maintained by official contributors to stay up to date and compatible with both terraform and their respective providers so here's an example of a module from our friend Anton down below and as you can see it has a little badge that's how you know that it's verified so verified modules are expected to be actively maintained by hashicorp Partners verified badges aren't an indication of the flexibility or feature support but just to kind of go through some things here very simple modules can be verified just because they're great examples of modules unverified modules could be extremely high quality and actively maintained unverified modules shouldn't be assumed to be poor quality unverified means it hasn't been created by a hashicorp partner so you know that again it's not indicative of quality but it just means that it's gone through a bit of vetting okay all right let's take a look here at the standard module structure and this is a file and directory recommended for module development and this is the idea if you were to go and publish your own module this is what people would expect to see so if you had root modules that's what it'd be and you have nested module I want to point out that when you are running terraform you technically are creating modules even if you aren't intending them to publish them into the terraform registry but you know when you make a main.tf you've basically made your own root module okay so the primary entry point is the root module and these are required files in the root directory so your main.tf is the entry point file for your module variables TF is the variables that can be passed in outputs.tf are outputted values readme describes how the modules work license the license under which the module is available for NASA modules which are optional but must be contained in the modules directory a sub module that contains a readme is considered usable by external users a sub module that does not contain a readme is considered inter for only internal use and the idea is to avoid using relative paths when sourcing module blocks so hopefully that gives you an idea okay foreign let's talk about core terraform workflows and these have three steps write plan and apply so write plan and apply we saw this kind of in the terraform life cycle and the idea here is that you know it's just to try to describe what it's going to be for your team and requirements as you grow and you're utilizing this workflow so if you're talking about individual practitioners so a single person a team using OSS so they're not using they're using open source software using terraform but they're not using the terraform Cloud platform and then what it would be like if they're using the terraform Cloud platform in terms of this right plan apply you're going to see these examples don't perfectly fit here I am just presenting a summarized versions of the documentation and the reason why is because on the exam this is one of the sub domains that you need to know so I'm not saying that I think these are perfectly presented but I think that I have to cover them because they are in the exam and I you do learn something here so we will go through them okay so let's take a look at a terraform or team workflow for a single person an individual practitioner looking at the right step first so you're going to be writing your terraform configuration in your editor of choice on your computer um but the thing is you'll be storing your terraform code in something like GitHub even if you are an individual user you're going to be putting in git or GitHub or some kind of Version Control System you're going to be repeatedly running terraform plan or even possibly terraform validate to find syntax errors and the great thing about this is that you get this tight feedback loop between editing the code and running your test commands because it's all on your local machine we're not sending things off to build servers or other services so it's very fast and easy talking about the plan stage so when the developer is confident with their workflow in the right step that commits their code to their local repository this is the stage where it's a local limit it's not a remote commit they may be only using a single Branch so just probably working in Maine or if you're still using the old syntax Master Branch once their commit is written they'll proceed to apply that'll bring us to the apply stage so they will run terraform apply this is on your local machine it's not part of any other process you're just running terraform apply and it'll be prompted to review their plan after the review the final review they will approve the changes and await provisioning after a successful provision they will push their local commits to their remote repository so this is where you will then finally commit your code so there you go so we looked at what it would be like if we had a single person working with terraform let's talk about if it's a team and they're not using terraform Cloud they're just doing it uh the oldfashioned way okay so each team member writes code locally on their machine in their editor of choice as per usual a team member will store their code in a branch in their code repository whether it's a uh per feature per user per whatever is up to you branches help avoid conflicts while a member is working on their code but branches will allow an opportunity to resolve conflicts during a merge into main it's no different than working with you know code because that's what it is terraform plan can be used as a quick feedback loop for small teams so we still have that option but as your team grows larger a concerned over sensitive credentials becomes a concern and so this is where you may need to introduce a CI CD process so that it's it's going to be in control of the credential so the idea is that you don't run plan you just push to your branch and it can run it or it only happens on pull requests that's up to you know your team and how they decide to set it up when a branch is ready to be incorporated on pull requests an execution plan can be generated I guess when we say execution plan this could be a speculative plan okay so it's not something we're going to run it's just something we're going to review and displayed within the pull requests for review to apply the changes the merges need to be approved and merged which will kick off a code build server that will run terraform apply that's the apply stage there so this is all good but what we need to kind of highlight is all the work and labor that goes into setting up your own team if you're going to do it all from scratch without terraform Cloud so the devops team has to set up and maintain their own CI CD pipeline they have to figure out how to store the state files whether they're going to be in a standard back in a remote state or they're going to encrypt it and put them into the code repository which is not recommended they are limited in their access controls so they can't do granular actions to say okay I only want to allow this person to destroy and this person to apply it's not like that with get repos they have to figure out a way to safely store and inject secrets into their build server's runtime and that's not argue argue it's not very hard depending on the solution that you choose but it is a thing that they have to figure out they might need to manage multiple environments and this can create additional overhead because for each environment you'll have to create another ciccd pipeline okay so hopefully that gives you the idea of the effort here and this is going to set us up to say what terraform cloud is going to solve okay let's take a look at what our team workflow or our terraform workflow will be if we were using terraform clouds so 18 we'll use terraform Cloud as a remote backend of course they were using uh their favorite editor as per usual working on their local machines to write that code the input variables will be stored on terraform Cloud instead of their local machine terraform cloud integrates with your version control system such as git to quickly set up a cicd pipeline a team member writes code to a branch it commits per usual so that doesn't change a pull request is created by a team member in terraform Cloud will generate the speculative or execution plan however you want to call it for review in your version control system the member can also review and comment on the plan in terraform Cloud after the pull request is merged terraform cloud in the terraform Cloud runtime sorry the terraform Cloud runtime will perform a terraform apply and a team member can confirm and apply the changes within the terraform Cloud UI okay so terraform Cloud streamlines a lot of the CI CD efforts storing it storing and securing sensitive credentials and makes it easier to go back and audit the history of multiple runs so in terms of the exam if and I didn't see any questions on this but I know they exist they're just going to be asking you you know which like they might describe something and say which kind of workflow does this fit and so if you generally know the difference between terraform Cloud working with the team open source software without terraform cloud and individual workflow it's not too hard you'll be okay all right foreign we're taking a look here at back ends and each terraform configuration can specify a back end which defines where and how operations are performed and where State snapshots are stored so terraform divides their backends into two types we have standard and enhanced first looking at standard this is where you can only store the state and it does not perform terraform operations such as terraform apply so to perform operations you have to use a CLI on your local machine and the reason why is that standard back ends are basically thirdparty backends so a standard back end could be AWS S3 and so you know this is a storage service it doesn't have the capabilities of pragmatically triggering things okay uh when we have when we're talking about enhanced back ends we can store both the state and perform terraform operations so enhanced backends are subdivided further so we have local so files and data are stored in a local machine executing terraform commands and remote so files and data are stored in the cloud so terraform Cloud the reason why they can perform terraform operations and when you look at local and remote local is your machine so of course it can execute terraform and then remote is terraform Cloud which has its own runtime environment it's basically a build server so it of course can do both those operations and that's how you're going to remember the difference between those two okay all right so we were just talking about standard and enhanced back ends and I was saying that standard back ends are basically thirdparty providers that is something other than terraform Cloud so let's take a look at what options we have available to us starting with the major cloud service providers so AWS has simple storage S3 Azure has block storage account notice it says Azure RM because that's just the name of what they call it I don't know what the RM stands for resource manager I imagine Google Cloud Storage is an option then we have Alibaba we have openstack we have 10 cent and then we have Manta which is part of joynet's cloud storage so I don't think a lot of people are going to remember joinet joynet was very popular provider like post or pre2010 so I remember them 10 cent is a Asia provider I think they were a texting service they're very popular but they're not the largest provider over in Asia Alibaba is and of course we have the the three major ones here and then openstack is for uh private Cloud okay then on the other side of it when we're looking at more exotic or things that aren't Cloud server providers we have um artifactory we have hashicorp console etcd postgres database kubernetes secrets and you can also use the ACP protocol now notice I have these little locks here that's indicating which have state locking which do not if you don't know what state locking is don't worry we'll talk about it here in a moment um would there be a question on the exam saying oh which service you know doesn't have state locking and the answer is no they would never ask that it's too minute but just notice that the only thing that doesn't have state locking is uh artifactory which I'm kind of surprised because it's a universal repository manager and there's the one case like with HP protocol where it's optional so it's not that you can't have it it's just that it's not it doesn't necessarily have to be there and in particular some the the state is or the Locking State locking is buy another service so for AWS it's dynamodb that is doing the state locking and then with Alibaba uh alibaba's cloud storage it's table store okay so uh you know there's not much to know here but uh you know it's just kind of interesting if you want to have a different kind of backend maybe you want to use postgres because you're really familiar with it you can actually store it there okay so let's take a look at what it would look like if we were to use a standard back end so here's an example for AWS since I think S3 is very popular so if you were to set up your back end so here I have a bucket here and I've have to name the state file so I call it State file and then I give it the region and there it is so the backup of a state file will reside on your local machine so the backup's not going to be an S3 configuring a standard back end does not require terraform cloud account or workspace because you know it's it's totally separate from it so that's something I wasn't sure when I was first using it was okay can I use a standard back end but I still have to have a terraform account or workspace and the answer is no all right all right so we're taking a look at enhanced back end so we're going to start with local and then move on to remote so for the local back end we store the state on the local file system and it locks the state using the systems API it also performs operations locally and when we say local we just mean a local machine we don't necessarily mean it has to be our workstation a code build server could also be considered a local machine okay it just means anything but terraform Cloud that is running the terraform code so by default you are using the backend State when you have not specified any kind of back end so normally you'd see a background defined in here we don't so it's going to just default to the local you can specify the back end with an argument local most people don't you just leave it blank and you can change the path to the local file a working directory so I think that if you were to specify you'd want to put the path in but generally again we keep that blank you can set a back end to reference another state files so you can read it outputted values this is a way of crossreferencing stacks so just notice that we have this thing that says terraform remote State we're going to repeat this later on in the course because this is a very important concept and I feel that it gets overlooked in the documentation but it has to do with local backends so the idea is that you could say hey I have this other file that has a back end and I'm just going to use data sources specify its backend and then point to its actual terraform State file okay foreign we're taking a look here at remote back ends for the enhanced backend type and a remote back end uses the terraform platform which is either terraform cloud or terraform Enterprise by default I usually just say terraform Cloud when I'm referring to the terraform platform but just to understand there is a distinction between terraform cloud and terraform enterprise Enterprise being the onpremise offering okay so with a remote back end when terraform apply is performed via the CLI the terraform Cloud run environment is responsible for executing the operation so that's what you get when you get terraform cloud is you get this run environment so it's basically just a builtin code build server to run terraform commands for you one thing I really want you to know about remote backends because this really tripped me up uh when I was actually trying to make the follow along which is the fact that because the terraform Cloud run environment is the one exiting the command your provider credentials need to be configured in the environment variables in terraform Cloud so you know if you had a project and you configured it with um TF bars locally and then you were to swap out your remote backend it's not going to work the way you expect it to because um again the terraform Cloud run environment is not going to take your credentials and then move them to the cloud okay you have to do that yourself when using a remote backing you need to set a terraform Cloud workspace so you would go ahead and go to terraform cloud and just go create one you create one or multiple ones for a single project if you use a single workspace for a project you're just going to use the workspaces uh name and if you set multiple workspaces via prefet you can use a prefix okay and the way this prefix works is that you're going to say like my app or something and when you go to run terraform apply what it's going to do is prompt you to say which environment do you want to use so and this is what you've created in your terraform Cloud workspace you've created one called Dev you've created one called Product saying which workspace do you want to deploy to I want to know that you can only set either name or prefix you can't set both okay so just understand that all right so we're taking a look at the cloud backend um uh code block here and so this is very similar to terraform backend remote if we're specifying terraform as our back end but now instead of having to do backend remote we can just give it a cloud block and the reason for this is well I don't know you can still foreign all right let's take a look at the cloud backend block so when using terraform Cloud as a remote backend State you should instead use the cloud block to configure its usage so uh previously in previous uh terraform versions it would look like this so you'd have terraform back and remote and the way you know it'd be using terraform cloud is that the hostname would be set as app.t terraform.io and so this has been changed so now that all you have to do is use this Cloud block and so you just don't specify that hostname and for the most part um uh you know the configurations between them are very similar so the only thing that we're seeing different is this prefix maybe that prefix is still there we'd have to double check the documentation on that but what's important to understand is that there's this Cloud block and it is the record amended way to do it now I do want to point out that I tested both and the remote the remote version still works so you can still do it this way if you're doing it the old school way and this is just an alternate way uh would they ever make it so you could not use the remote state in the future for uh terraform Cloud you have to use the block I don't know but I can tell you right now that they do have that cloud block so both are valid options and the latter of course being the recommended uh use one so yeah there you go thank you so since we're talking about back ends let's talk about backend initialization in particular the back end hyphen config flag this is more of an exotic option but I figured we should go over it because it could appear on your exam so the flag for the back end config flag for terraform init can be used for partial backend configuration so in situations where the backend settings are dynamic or sensitive so they cannot be statically specified in your configuration file this is what you would do so here would be your main.tf and notice it says back in remote and it has no details in it so then what you do is you create a separate file called backend.hcl and now you're specifying the workspace the host name the organization and then uh with terraform and net you're going to then say Okay use this file as the backend information that we're going to inject into our backend remote so there you go okay we're taking a look here at terraform remote State and I give this a lot more attention in the course because I feel that it gets overlooked within the terraform documentation it's such a powerful feature and something that I'm used to having in cloudformation which is crossreferencing Stacks so I want to make sure that you know it too so terraform remote State data source retrieves the root module output values from another terraform configuration file using the latest State Snapshot from the remote back end so the idea is that you can reference a state file from somewhere else you can do it uh via a remote backend and a local backend so just take a look here we see data and the data sources terraform remote State and we're setting the back end as a remote on the right hand side here it is local and if it's a local back end we give the path to the TF State file if it's remote that means it's another workspace and terraform Cloud so we set the workspace that we want to access and then when we want to access those resources we're using data sources so we do data Dot and it's terraform remote State and then we specify it knows that it's no difference whether it's remote or local but you're going to be getting datas from outputs okay so only the root level output values from the remote State snapshots are exposed resource data and output values from nested modules are not accessible to make module outputs values accessible as a root module output values you must explicitly configure a passthrough in the root module so here's an example of us doing a passthrough so we have a module called app and it has a source and then we're just setting an output notice that we are just grabbing the value and passing it along I want to tell you about the alternative to terraform remote State because if you can you should use these as opposed to using terraform Road States so terraform remote state only exposes output values its users must have access to the entire State snapshot which often includes some sensitive information it's recommended explicitly uh it it's recommended to explicitly publishing data for external consumption to a separate location instead of accessing it via a remote state so what would be Alternatives well you've seen this because when we looked at data sources we were technically we're using Alternatives but the idea is that you are going to say AWS S3 bucket AWS rep 53 zones and these are kind of already set up to work with AWS or whichever provider okay so that's that there but uh yeah hopefully that's pretty clear so the idea is that when you can use these data sources because you know they're actually working off of live data right like it's hitting a resource it's not just looking at a state file that contains data okay so we had mentioned State locking just briefly when we were looking at standard back ends but let's go take a look in detail what these are because they're very important for your workflows so terraform will lock your state for all operations that could write State this prevents others from acquiring the lock and potentially corrupting your state so State locking happens automatically on all operations that could write State you won't see any message that it's happening if the state locking fails all right so terraform does not output when a lock is complete however if acquiring the lock is taking longer than expected terraform will output a status message so neither on failure and neither when it is complete just if it takes too long so there's a transient issue something with like a networking issue you can disable lock so what you do is use the hyphen lock flag but it's generally not recommended you can force and unlock there's cases where uh you know just does not unlock or add so what you'll have to do is use the force unlock camera and if you unlock the state when someone else is holding the lock it could cause multiple writers Force unlock should only be used to unlock your own lock in the situation where automatic unlocked failed to protect you the force unlock command requires a unique lock ID so terraform will output this lock ID if unlocking fails so this is what it would look like so we have terraform Force unlock and then whatever the ID is hyphen Force so yeah there's a lot going on here but yeah that's what it is all right so let's talk about protecting sensitive data so terraform State file can contain sensitive data so longlived database credentials and is possible attack Vector for malicious actors and so when you're dealing with the local state when you're using local backend the state is stored in plain text Json files you need to be careful you do not share the state file with anyone you need to be careful you do not commit this file to your git repository when you're using a remote state with terraform Cloud the idea here is the save file is held in memory and is not persisted to disk the state file is encrypted at rest the state file is encrypted in transit with terraform Enterprise you have detailed audit logging for tampering evidence to take it one step further so you can just see that there's a lot of work that has to be done when you are using it locally but with terraform Cloud this is kind of the cell for terraform cloud is that it's just going to do everything possible to make that secure would it be secure to use a remote say with a thirdparty storage let's talk about that so you can store state with a various thirdparty backends but you need to be careful to review your backend's capabilities determine if you meet your security and compliance requirements some backends are not by default as secure as they could be so for example AWS S3 you could have you have to ensure encryption and versioning is turned on and you need to create a custom Trail for data events so you can get tamper evidence logging if you turn on data events for custom cloud trail events but one thing that if it's important to you is that you know if you use S3 it's not held in memory you know that'd be using a cloud HSM or KMS so you know you have to understand there are some tradeoffs okay let's take a quick look here at terraform ignore files and if you know what git ignore files it's pretty much the same thing so when executing a remote plan or apply in a CLI driven run an archive of your configuration directory is uploaded to terraform cloud and so you could Define paths to ignore from upload via the dot terraform ignore file at the root of your configuration directory if this file is not present the archive will exclude the following by default so dot get dot terraform and Dot terraforming Nora works just like a DOT get ignore with the only difference is that you cannot have multiple dot terraform ignore files in subdirectories only the file in the root directory will be read so there you go and yes I know there's a double the okay so don't worry about that foreign foreign let's talk about resources so resources in configuration files represent infrastructure objects such as virtual machines databases virtual Network components and storage and so it pretty much looks like this a resource type is determines the kind of infrastructure object it is so here it says AWS instance and this would represent an AC AWS ec2 instance this is all defined within the providers documentation so you have to kind of look at what name they use to figure out what it is and even though you don't see provider explicitly set here a resource does belong to a provider and you can explicitly set it and you would do this when you'd want to set a resource outside the default provider that you have in your configuration file and so one little thing that I hadn't mentioned anywhere else and that's why I made this slide was to mention about special timeout nested blocks within resources so some resource types provide a special time on asset block argument that allows you to customize how long certain operations are allowed to take before being considered to have failed okay so there you go foreign let's talk about complex types so a complex type is a type that groups multiple values into a single value and complex types are represented by type Constructors but several of them are have shorthand keyword versions okay so there are two categories of complex types we have collection types for grouping similar values so list map set and structural types for grouping potentially to similar values so Tuple an object and it's now that we have an overview let's go jump into collection types and structural types a collection type allows multiple values of one other type to be grouped together as a single value and the type of value within a collection is called its element type the three kinds of collection types are list map and set and so looking at our first one here what we're doing is we are setting ourselves something that looks kind of like an array and it's these list type here and what we can do is use our index so the indices 0 to reference the first element which is Mars so that's going to make our username Mars for a map it's very similar to a ruby hash or singleness to Json object and the idea here is that it's very similar to the first except now we're doing a key and value and then we access it by based on the key name so plan B is going to return 50 USD okay we have set it is similar to a list but has no secondary index or preserved ordering all values must be of the same type and will be cast to match the first element okay so it's a great way to kind of have um well I guess no secondary index but yeah so you do two set and then it would turn into this okay all right let's take a look here at structural type so a structural type allows multiple values of several distinct types to be grouped together with a single value structural types require a schema as an argument to specify which types are allowed for which elements so this is what they're talking about when they say this schema so when you actually Define the variable notice where it says object and you are actually setting a is going to be a string and B is going to be a string there's this optional option which I think is right now in beta but hopefully by the time this course is out or it's the future you have that option there but just assume that they're all required so that's what they're talking about is that you are specifying exactly what you expect the schema to be okay so there are two kinds of structural types we have objects and tuples and they're going to look very familiar to maps and lists because they're pretty much the same but with explicit typing so object is a map with more explicit keying so this example we'd have name for string age for number and so that's what it would expect the data structure to be for Tuple multiple return types with a parameter so we can have string number or Boolean so so this is where we'd have a as a string 15 or true as a Boolean so you know there you go hey this is Andrew Brown from exam Pro and we're going to look at the collection and structural type so I have a new folder down below just in case we need to Define some things so I'm going to go here and just call this main.tf and we are just going to configure this for a local terraforms we'll just give the brackets there and so the idea is that we might have different kinds of variables and we had done this previously where we created a list and a map but we can do that again so we'll have like planet right so that's list and then we just default that to a value Mars Earth Moon and then we could also have you know plans here and that would be our map type okay and so here we'll just set it the curlies plan A Plan B plan C um so we'll do terraform console and so that should load these variables for us to use and so if I do var.plans I get that and if I do VAR dot planets uh didn't like what I did there input variable has not been declared I suppose just plan it there so I should have named that planets up here and so what we're going to do here is just go ahead and exit type clear I'm just going to expand this a bit bigger so we're taking over more of the screen and let's take a look at structural types so these require you to actually Define um parameters so what I'm going to do is go down below and we're going to do the object and object is very similar to the map so let's go down here plans object and so here what we do is we'd say type object and we would just have to Define some settings here um so we could say a is a string all right we'll see if that works the default value is now compatible with the variable type constraint attribute a is required so that's fine what we could do is just Define this as like plan A Plan B plan C and now if we just do VAR plans object when you are using this you know you might want to specify some different kinds here so you could just say like you say like plan here as soon as they plan name plan amount maybe it's like number and so then we'd say plan name plan amount basic maybe this will be 10. okay and we'll just uh type exit here and go back into terraform Cloud hopefully we don't get an error here so the plan amount is required so you know we can't have a spelling mistake here just do VAR plan here um well we named it correctly there and when we went up here and specified it I think we got it right plan object so tripler doesn't like here oh you know what we're not in terraform Cloud okay that's fair and we're still spelling this wrong oops okay so there we go we get our basic plan um and then we could do a tuple here so I don't know if I've ever defined a tuple before so let's just try it here and so we'll just say uh groceries or value or random type equals Tuple I'm just looking up if there's any kind of definition I can find here I'm not really finding anything but I'm just going to go Define this here because I thought maybe it needed like a schema or something but maybe it doesn't so we'll just say hello 22 false okay terraform console dribble Constructor requires one argument specifying the element types as a list okay so if that's the case then what we could do is say string number Boolean the type Constructor requires one argument specifying the number of elements so clearly I'm doing this wrong so just give me a second I'll be back in a moment okay all right so I think the problem here was just that I need to make brackets here like this we'll give that a go boolean's not a valid option what if we try Bool okay we say VAR dot random good and so I'll just go ahead and exit that out I'm just going to see what happens if I change the order here so let's say I do instead of 22 here we go here okay so notice that you know we can have all sorts of Kinds but they have to match exactly the order that is there so yeah that's pretty much it so there you go the terraform language includes a number of builtin functions that you can call from within Expressions to transform your combined values so we have numeric string collection encoding file system date and time hash encrypto ipnetwork type conversions so we are going to go through all of these we might not go through every single function but we'll go through every single major category in terms of the exam the only thing that's going to show up might be string functions why they do this I don't know it's not a very good exam question but those might appear but I think that this is one of the strongest features of terraform over something like cloud formation and I really want to just show you the Gambit of them okay foreign let's take a look here at numeric functions starting with absolute so Returns the absolute value of the given number so 23 is 23 0 is 0 and if you get a negative number it's going to flip to the positive for 4. what it does is it rounds down to the nearest whole number so see where it says 4.9 becomes a 4. you have logs so it Returns the logarithmetic I can't say that word logarithm logarithm of a given number in a given base so log 50 comma 10 is going to give you that 16 comma 2 is going to give you 4 okay seal it it's where it will always round up so see where it says 5.1 and it goes all the way to 6. we have Min so take one or more numbers and return the smallest number from the set and Max take one or more numbers and return the greatest number of the set I don't have examples because that's pretty straightforward you know if there's a two and a four it's going to return the two in Min if it's a two and a four it's going to return the four for Max we have parse n so parse is the given string as a representation of an integer in the specified base and Returns the resulting number so if we have a hundred here in strings it's going to and we say comma 10 we're going to get 100 because that's the base system it's base system 10 base system 16 we can see letters in there right so it's able to translate that this is two so that's basically binary so zeros and ones so you get the idea there uh pow so calculates an exponent by raising its first argument to the power of the second argument so that's just the way of doing powers and then we have Signum so determine the sign of a number returning a number between negative one and one to represent the sign so there you go all right let's take a look here at string functions the first being chop so removes new line characters at the end of a string so you know if there's a hyphen n or sorry backslash n you don't want to see that there that's the way you get rid of it then you have formats it produces a string by formatting a number of other values according to the specification so here there are percentage Delights so this is representing a a digit so it's taking that number this says it's going to be formatted as a string okay format list so produce a list of strings by formatting a number of other values according to a specification string so here we have an array and then we have our specification so you can see it's substituting the name there um we'll look at indents so adds a given number of spaces to the beginnings of all but the first line in a given multistring so here we have a string and what it's going to do is see where we have the interpolation here and then we have indent I know the the highlighting is not great because it's a single string but we have interpolation we have parentheses two so give it a a layer of two indentation and then it's going to break that up and give it indentation so we have join so produce a string by concatenating together all elements of a given list of strings with a given deliminator so use delimiters is double click or sorry it's a comma and so it's going to glue that together to make this okay if there's only a single one there just won't be any comma in there we can lower all the text it's pretty straightforward we have regular Expressions so that is an extremely powerful feature so here we have the regex I don't know what the regex format is uh maybe it's Pearl I'm not sure there's like a bunch of different types of regex Standards so you know do you have to figure that out so you know how to use it and then there's a regex all so applies to a regular expression to a string and returns a list of notches where this just is returning uh one okay We have replaced so search is a given string for another given substring and replaces each occurrence within a given replacement string this is just like the JavaScript replace we have split this is the opposite of join so if we want to split on the comma we specify comma here we have Str rev so string reverse so reverse is a string so hello becomes Ole we have sub ol sure I don't know um so substring so extracts a substring from a given string by offset and and length so we have a substring and we're saying we want one to four so we only want one two three four here okay because it starts at zero we have title so make a title okay so capitalize the H and the w we have trim removes the specified character from the start and end of the string so we don't want these and we tell it to remove those there's a lot of string functions uh so we have trim prefix so it removes the specified prefix from the start of the given string if the string does not start with the prefix the string is is returned and unchanged so here we say we want to get rid of hello in the front so we do that suffix is the opposite so we want to get a rid of world out of the suffix so we do that we have trim space so removes all types of white space from both the start and end of the line so it gets rid of the new lines and the spaces upper is going to put everything to Upper and there you go on the exam they probably will ask you uh like what string function does or which one does not do something so this is the only part of the builtin functions you have to know for the exam I don't think it's a very good exam question but it does appear there so you need to know it okay foreign functions and these are the most powerful builtin functions and there's a lot of them and I made sure to give you an example for each one because I really do want you to know these because this is the power of terraform the First on our list here is altru's returns true if all elements in a given collection are true are true or it also returns true if the collection is empty so it's either true true right or we have true false so because there's a false it's not going to be true so any true is very similar but there only has to be one that is true so if this is true and there's a false that's going to be true if it's blank it's going to be false okay we have chunkless splits a string list into fixed size chunks returning a list of lists so here we're telling it to chunk it every two so grab every two and make them into their own little array or list I suppose we have coalesce takes any number of arguments Returns the first one that isn't null or empty string if you're used to postgres you use this all the time but the idea is it's going to grab the a in this case it'll grab the B because that's blank in this case we'll grab the one because that's the first value we have coalesce list takes any number of list arguments and Returns the first one that isn't empty so very similar it's just using lists or if we want to call them array so the first one is available so it takes that one we have compact so it takes a list of strings and returns a a new list with an empty string elements removed so it's just going to get rid of that space there and we'll get ABC we have concat so it takes two or more lists and combines them into a single list so that's very convenient we have contain so determines whether a given list or set contains a given single value as one of its elements so does it have an A yes it does does it have a d no it does not we have distinct so takes a list and returns a new list with any duplicate elements removed so we just want to make sure we only have one of each so do we have any duplicates here we have two a's and two B's so we're going to end up with just a single list so only exactly one of each letter we have elements retrieves a single element from a list so get me the element at uh at three here so um wait retrieves a single element from a list okay well that's what it does you give it a three and it gives you an a I don't know why it's not clicking for me but I I'm not following through here index finds the element index for a given value in a list so we say where is B and the index of B is is one because it'd be zero and this would be one still really confused about this one flatten takes a list and replaces any elements that are are lists with a flattened sequence of list content so basically it says give me a bunch of eraser let's turn into one flat list uh Keys take a map and return a list containing the keys from the map so we just want the keys a c and d we want length this is pretty straightforward so what's the length of this zero this is two this is one because it's a one uh mapper one thing key value in there and if it's a string it's going to count the characters so there's five characters we have lookup so retrieves the value of a single element from a map given its key if the given key does not exist the given default value is returned instead so we say look up a and what we get is a y right look up C and it could not find C so by default give us what instead key a match Keys construct a new list by taking a subset of elements from one list whose indexes match the corresponding indexes of values in another list that sounds complicated let's read that one more time so constructs a new list by taking a subset of elements from one list who indexes match the corresponding index of values in another list that is confusing so we have one less than another one so we have this one here and we have us West Us East USD so we say okay we have uses so the elements here is two and three so give us two and three so that's what it does that was a that was a tricky I can't think of what you use that for but that's a interesting function merge takes an arbitrary number of maps or objects and returns a single map or object that contains a merged set of elements from all arguments so it just merges them together so it's just like concat or I suppose like flatten uh one takes a list set or Tuple values from with either zero or one element if the collection is empty one returns null otherwise one Returns the first element if there are two or more elements then one will uh one will return an error so it returns null on an empty List It Returns the first one and then here it says invalid function so it's just saying is there one right is it one or zero ranges generates a list of numbers using a start value a limit value and a step value so we say three and we get 0 1 and 2. during its a list of numbers using a start value limit value and a step value okay uh reverse so takes a sequence and produces res oh not reverse Reserve sorry Reserve takes a sequence and produces a number induced sequence of the same length with all the same elements as the given sequence but in reverse order oh it is reverse r e reverse I guess I spelled it wrong here sorry reverse one two three three two one just notice this is a spelling mistake okay uh set intersection so function takes multiple sets and produces a single set containing only the elements that all of the given sets have in common in other words it computes the intersection of the sets well it's tiring so from what I can tell it's like they all have B so give us B right set product functions find all the possible combinations of elements from all of the given sets by Computing the cardistarian product we're really getting into math here so we got app one and app2 and so we got uh development develop okay so this continues on so it's going to say give me app one with development give me uh app two with development then Apple Mustang and then app2 with staging and etc etc because that's why I put the three dots there set subtract function returns a new set containing the elements from the a from the first set that are not present in the second set in other words it computes the relative complement of the first set in the second set uh it lost me there but it says set subtract so here I see a B and C A and C minus it you get B okay set Union function takes multiple sets and produces a single set containing the elements from all the given sets in other words it computes the union of the sets so it says set Union so we have a b b c and d and in the results we get d b c a so I guess um single set containing the elements from all the given so yeah yeah I guess it's just we get unique ones across the sets uh we have slice and notice like we're going through all these things it's like you probably won't use these more exotic ones so it's not a big deal if we don't nail them here but it's important that we go through these so that you know you just know all the options are here so slice extract some constructive consecutive elements from within a list so here we are saying one and three so we have B and C that's where they start index one um and then extract some consecutive elements from within a list one comma three okay sort takes a list of strings and returns a new list with those strings sorted lexicographically so we have e d a and x and so now they're alphabetical so a d e and X well I think this is the last one uh some takes a list of set numbers and Returns the sum of those values that's pretty straightforward add them all up transpose take a map of list of strings and swap the key and values to produce a new map a list of strings so kind of like inverts it values takes a map and returns a list containing the values of the map so we saw this earlier we got the keys this is where we just want to get the values zip map so construct a map from a list of keys and a corresponding list of values so we have a b one two and this turns it into a equal one b equals two I think I saw this on the exam so that one you might want to remember but yeah that's collection functions as you can imagine they're extremely powerful but they can also be really confusing so maybe just use them a little bit when you need to okay we're taking a look here at encoding and decoding functions so functions that will encode and decode for various formats so imagine we need to encode into base64 so we do hello world or imagine we give that encoded string and we want to decode it back to hello world that's what we can do so there's a lot of different encoding decoding functions most of them are the same they're just kind of variants so we're not going to go through every single one but I'll list them out so you know what they are so we have base64 encode Json encode text and code base64 yaml encode base64 gzip URL encode base64 decode CSV decode Json decode text decode base64 yaml decode and just notice that you know these aren't one to one so there is one for this we have one for here uh we have one for yaml uh this is unique this is unique this is unique okay just so you can tell for your own code I think this one's a very common one that you'll use but the idea is that let's say you have hello world you want to replace that string with a uh whatever friendly for a URL right so it just encodes it okay it's very useful when you're making URL links so there you go we're taking a look here at file system functions so this has everything to do with the file system so the first is absolute path so the idea is you give it something that's relative and it's going to give you something absolute directory name so this is a string containing a file system path and removes the last portion from it so we don't need the file name so we just remove that off of there we have path expand so takes a fossils and path that might begin with a tilde and expands it into its absolute path so this would be like for home okay um base name so it takes a string containing a file system path and it's basically the opposite of directory name we just want the file here okay onto the next page here this file will read the contents of the file pretty straightforward we can check if a file exists so we just do file exists here we have file set so it enumerates a set of regular file names given a path and pattern file base64 so it reads the contents of a file at a given path and Returns the basics before encoding that might be good for images template file so reads the file at a given path and returns its content as a template using a supplied set of template variables so that's really useful if you want to do some kind of templating uh and just notice it's a twostep process so this is the template file the actual file itself and then we load it here it's called a DOT TPL so there you go we're taking a look at date and time functions the first is format date so the idea is that we provide a format that we want and then we give it a timestamp that is in the RFC 3339 format and we get a variety of different um formats out there we can add time so again it's going to be that RFC 3339 format and we say add 10 minutes add one hour then we have timestamp so you it returns a UTC timestamp string in the RFC 3239 format so you just say timestamp it's I guess it would get right now and then you get it in that format okay let's take a look at hash and crypto functions so generates hashes and cryptographic strings so the most popular one out there would probably be B so here we just say hello world and we're going to get this thing here understand that a hash cannot be reversed so once it is turned uh into uh you know this format the only way you're going to be able to confirm the contents of it is to Hash something that is similar and then compare it against it okay so we have base64 Shaw 256 we have 512 we got B Crypt we have file Bay 64 Shaw 256 file based 64 Shaw 512 file md5 file Shaha one file Shaw 56 file Shaw 512 md5 RSA decrypt sha1 Shaw to V6 Shaw 512 uuid uid V5 so I only showed the one because you know it gets kind of boring to go through all these and really it's just going to be based on your use case what you're going to be using on a daytoday basis is probably bcrypt md5 and you uids so there you go let's take a look at IP network functions these are the coolest functions I think that are built into terraform so we have cider host so what we can do is give ourselves a a address and then we can give it a subnet Mass size and we'll get back an IP address and so you can see we have this both in the ipv4 and the IPv6 we have cider net mask so here we are doing cidernet math so we just say forward slash 12 and it's going to translate it into the full ipv4 then we have cider subnet so this is just where we say Okay I want a subnet of a particular size so we say 172 1600 comma 4 2 and look it's going to give us 18 0 back doesn't make sense that's okay I mean networking is really hard but I just want you to know that these functions are here for you okay cider subnet calculates a sequence of consecutive IP addresses within a particular cider prefix so 4484 and then you get those sizes there okay all right we're on to type conversion function so the first we're looking at is can so can evaluates the given expression and returns a billion value indicating whether the expression produced a result without any error so can we use this right so we say local.food.bar and so you know if if this Foo wasn't defined then it would say false but apparently we've made it all the way to borrow okay we have defaults a specialized function intended for use with input variables whose type constraints are object types or collection of object types that include optional attributes and I don't show that one here because it's not that exciting but nonsensitive takes a sensitive value and returns a copy of that value with the sensitive markings removed therefore exposing the sensitive values so if we have an output here and we want to make it nonsensitive that's what we could do then sensitive as you imagine is just the opposite okay we have two Bool so converts its arguments to a Boolean value so if we have a string that's true we can turn it into a real Boolean value we have to map converts an argument to a map value to set converts it to a set to list converts it to a list to number converts it to a number string to string and then we last we have is try so evaluates all of its arguments expressions in turn and Returns the result of the first one that does not produce any errors the thing that's the hardest to figure out is set I cannot find really good examples or documentation on the use case of set there are some cases where you need to use sets which is an actual type but even talking to DA's and technical writers they weren't even sure themselves so this is not something you're going to come across very often but there's like one case where I saw it so I'll probably point that out when we do hit it okay hey this is Andrew Brown from exam Pro and we are going to go take a look at um builtin functions as soon as my terminal decides to be responsive I don't know why as soon as I start recording it decides to lock up so we'll just give it a moment there there we go and so I have a new folder there I figured we could just find some variables so that we don't have to uh you know constantly write stuff in so we'll just say main.tf we're going to go terraform here and so might be fun to you know kind of some kind of variable here and so I have off screen here all the functions so we're just going to kind of pick some at random here to play around with so we get some experience okay so just going through strings I think what we can do is Define like our strings so we just say Str here and we'll just say type equals string and we'll just say default here able to say hello world forward slash n something like that okay and then we'll do terraform console here I gotta remember to do it this way so we do var.str okay and so that accesses our string there maybe we might want to take out the new line for now so I'm just going to kind of pull this up over here look at some kind of things we can do okay maybe collapse that get that out of the way all right so there's a lot of string functions and on the exam they might actually ask you some which is in my opinion I don't I don't really like that but that's what they do and so you know we might want to look at something like split or something so here we could do hello world okay start that up again so we'll do split comma VAR Str okay and that would split that into a list we might want to do something like upper so I think we did that earlier where we did upper okay you might want to do trim remove specify characters from the start and end of the string so maybe we have this here and so we'll say trim VAR Str and whoops it's not what I wanted to do trim far Str UCT like that okay and there's again there's not a lot that's exciting here maybe we'll try a replace so we can do replace and we'll we want to replace we won't provide our string and then the substring that we're looking for so world replace that with bar soon which is Mars there we go so nothing super exciting over there what's more interesting are some things like these hash encryptos so something we might want to generate out is a uuid I think that we might be able to do this here so let's just see what happens if we try to call it like that clear to our form cloud oops terraform console that's what I meant to type and so functions can't be called in here which is totally fine so go back and just set that like that I just wanted to show you that so if we did uuid we would get that if we used bcrypt so I might say bcrypt hello world okay might be something interesting the IP network here so we might want to generate out a cider subnet right the typing conversions is something that you might come across a bit so we already saw that when we converted a set to a list and things like that so maybe we might want to convert something to a Boolean so we might say two Bool true okay these are pretty complicated the collections but we might have something that we want to do here so coalesce might be something that's interesting where we have an array so or a list I suppose so we might say like items and make that a list null null empty last okay bar items so we might say coal Plus okay and that didn't look like it pulled anything out of there to reform coalesce operation with this list of strings use this symbol so we could use that um to do that so that just kind of expands the arguments and so that what happened here is null didn't exist Alden exists this didn't exists so it pulled out last okay maybe we might want to just use keys maybe we might just want to use Keys here okay so it might sound like hello world goodbye Moon and remember we can do uh hash Rocket Arrow equals or colon it's just up to your preference I just wrote that in for whatever reason I'm used to using Ruby and that's what we use as hash Rockets that's the name of the symbol the equals Arrow um okay it didn't like that so I guess we do have to do it this way that's totally fine I'm not upset by that I thought it supported all three maybe it's like minus equals or something I don't know but what we'll do say is save our stuff and then what we can do here is do keys okay and it didn't look like it grabbed oh yeah I grabbed the keys that's fine okay and then we might say values all right um you know maybe we might want to try reverse that one's pretty clear one two three okay so nothing super complicated I wonder if absolute would work in here like the file system so we have absolute path I don't know if I don't know if this would produce anything here oh it does okay so we could ABS path say path dot root there you go okay so that pretty much gives you a general idea of builtin functions so there you go all right let's take a look here at terraform Cloud again but in Greater detail so terraform cloud is an application that helps teams use terraform together and so there is the UI there and terraform cloud is available as a hosted service on terraform terraform.io it's actually at the app.t terraform.io once you're logged in and it has a lot of different features so it can manage State files uh have a history of your previous runs a history of your previous States easy and secure variable injection tagging run trigger so chaining workspaces together specify any version terraform per workspace Global State sharing commenting on runs notifications via webhooks email and slack organization and workspace level permissions policy is code via Sentinel policy sets MFA single signon cost estimation Integrations with service now Splunk kubernetes and custom run tasks and that is not the limit to what it does but this is what I could fit on the slide okay let's take a quick look here at the terminology or anatomy of terraform clouds so we have an organization and with an organization we have our workspaces and a workspace represents a unique environment or stack then you have your teams these are composed of multiple members and a team can be assigned to multiple workspaces then you have runs a run represents a single run of the terraformrun environment that is operating on an execution plan runs can be triggered by like you your the UI itself or maybe like a git repo it could be API driven or CLI driven so there you go foreign so there are three types of cloud run workflows so when you create a workspace you have to choose a workflow and you have either Version Control workflow we have CLI driven workflow or API driven workflow okay so just going over them in Greater detail for the first one which is that version controlled workflow terraform cloud is integrated with a specific branch in your VCS so githubs via web hooks whenever pull requests are submitted for branch speculative plans are generated whatever a merge occurs to that Branch then a run is triggered on terraform Cloud then you have API driven so workspaces are not directly associated with the Version Control System repository and runs are not driven by web hooks on your VCS provider a thirdparty tool or system will trigger runs via uploading a configuration file via the terraform Cloud API so this configuration file is a bash script that is packaged in an archive and you're pushing it as a configuration version so you're basically creating configuration versions every time you do that then there's CLI driven and this is the way we're going to be using mostly in the course so runs are triggered by the user running terraform CLI commands so you'll run terraform apply and or plan locally on your machine it's going to just work as per usual okay let's take a look at organization level permissions which manage certain resources or settings across an organization so the first things that you can set would be something like manage policy so create edit delete the organization Central policies manage policy override so override soft mandatory policy checks manage workspaces so create administer all workspaces within an organization manage VCS settings so set of VCS providers and SSH Keys available within the organization and for an organization we have this concept of organization owners so every organization has at least one organization owner and you can have multiple this is a special role that has every available permission and some actions only available to owners so this could be publishing private modules invite users to organizations manage team memberships view all secret teams manage organization permissions manage all organization settings manage organization Billings delete organizations and manage agents so just understand that there are these special ones just for this organizational owner and then these are these other ones here that you can set for other types of organizational level permissions okay let's take a look here at workspace level permissions that allows you to manage resources and settings for a specific resource and we have granular ones and then we have premade permissions so let's go through the granular permissions first so these granular permissions you can apply to a user via a custom workspace permissions and so we have read runs queue plans apply runs lock and unlock workspaces download signal locks read variables read and write read State outputs read State versions read and write State versions and so the idea is that what you can do is just go and cherry pick out what you want to assemble your permissions for your user now if you want something a little bit easier to do you can use fixed permission sets and these are premade permissions for quick assignment and they're based on the read plan and write so we have read runs read variables read State versions for plans we have q plans read variables read State versions We have write so apply runs lock and unlock workspaces download setting unlocks read write variable read write State versions and then there are workspace admins and this is kind of like the organizational owner so a workspace admin is a special role that grants all level of permissions in some workspace admin only permissions those admin only permissions would be read and write workspace settings set or remove workspace permissions of any team and delete workspaces so there you go let's take a look here at API tokens so terraform Cloud supports three types of API tokens users teams and organization tokens so for organization API tokens they have permissions across the entire organization each organization can have one ballot API token at a time only organization owners can generate or revoke an organization token organization API tokens are designed for creating and configuring workspaces and teams they're not recommended as allpurpose interfaces to terraform Cloud so basically you just use them when you are setting up your organization for the first time and you want to do it pragmatically okay then you have Team API tokens so this allows access to workspaces that the team has access to without being tied to any specific user each team can have one valid API token at a time any member of a team could generate or revoke that team's token when a token is regenerated the previous token is immediately becomes invalid designed for performing API operations on the workspaces same access level to the workspace the team has to access to I would imagine this is when you're sending out your own custom CI CD pipelines or something like that I'm not really sure exactly the use case for team API tokens we have user API tokens the most flexible token type because they inherit permissions from the user they are associate could be for a real user or a machine user when you do terraform login this is what you're getting a a um a user API token okay foreign so I just wanted to quickly show you this axis levels chart that helps you understand uh what kind of permissions you were giving at the access level and notice there's implicit and then required or explicit permissions I'm assuming that this means that you need to assign those permissions to the user first before they'd have it so just because you have a user token doesn't mean you get all of these orange diamonds it's just the ones that you've assigned to that user or team where I believe that the organization you're going to run into a chance where you're going to have all these permissions by default whether you want them or not so just understand uh that you have to double check this before you use your tokens and that this chart exists okay all right so we covered private registry earlier in the course when we were looking at the terraform registry the public one but let's cover it again with a little bit different information so terraform Cloud allows you to publish private modules for your organization within terraform Cloud private registry and tour from Cloud's private module registry helps you share terraform modules across your organization include support for module versioning a searchable filterable list of available modules a configuration designer which I didn't find this thing but it sounds really cool all users in your organization can view your private module registry authentic for authentication you can either use a user token or a team token so I guess this would be the case where you might want to use a team token for authentication but the type of token you choose May Grant different permissions as we saw with the access levels just the slide prior using terraform login will obtain a user token just a reminder and to use a team token you'll need to manually set it in your terraform configuration CLI file okay so there's a feature within terraform Cloud that can do cost estimation and it is a feature that will give you a monthly cost of resources displayed alongside your runs this feature is only available starting at the teams and governance plan and above but the idea is that it will tell you for specific resources and give you a summary so notice here that we have some pricing I'm going to get my pen tool out but we have the overall cost and then it's broken down per resource and so you can see we have an hourly monthly and monthly Delta I don't know what the monthly Delta is but um you know it gives you kind of idea of cost you can use sentinel policies to assert the expectation that the resources are under a particular cost so that's just kind of a bonus there where you're like okay I want to assure my spend is this the only downside at least at the time right now for cost estimation is the amount of support it has so we have AWS Azure and gcp so these are the resources that it will support and so you have to look through here and say okay you know is there any resources I'm using outside of this that I really care about um and that so I think that if you're using like core services so like ec2 instances load balancers things like that that should help you out so like we see AWS instance the load balancer the volume some cloudwatch logs ALB for Google it's just disk instance and database so yeah it's just really dependent on you know what's here so you know it may meet your needs or you might say okay this is not enough okay here's just a few options that I think are worth noting within the terraform Cloud workflows we have a whole section of workflows but I decided to put it over here just because let's talk about it one thing you can do within terraform cloud is set whatever version you want so you can go as far back as you want uh and this is great if you need to mix and match different workspaces because you have different stacks and they were built on different terraform versions and you're just not ready to upgrade them yet you can choose to share State globally across your organization for a particular workspace this could be really useful if you need to reference things wherever you can choose to Auto approve run so if you don't want to always do that manual approve you can do that this is great if you are looking for that kind of agile kind of workflow where if something is merged then it should be rolled out okay please let's talk about if we had to migrate our local state and we're using just the default one two terraform Cloud how would we do it so to migrate terraform projects it only uses the default workspace here from cloud it's pretty easy you're going to create a workspace and terraform Cloud you're going to replace your terraform configuration with the remote backend so if you have nothing it's using local and you just put in your remote State and then once you have that in there you do a terraform and knit and it's going to say hey do you want to copy the existing state you're going to type yes and once you've done that I believe you have to delete your old State file if you are migrating multiple um multiple environments or you're moving from a standard remote back end it's a little bit more complicated they definitely have guides in the docs but this is the pretty much standard one that you're going to come across when you're working very early and we'll definitely see this as we are using terraform in our follow alongs okay foreign I want to talk about what kind of Integrations we have for terraform for Version Control Systems so we have GitHub GitHub auth GitHub Enterprise get lab gitlab EEG and CE I assume that's Enterprise Edition and Community Edition bucket Cloud bitbucket Server and data center Azure devops service Azure devops server so it's very simple you're just going to choose from the one of the four right and then you're gonna just drop down and choose what variant it is there and connect your repo every single provider has different configuration settings so you might have to meet those depending on what they are you can get from private repos you might have to add your SSH key or something like that okay let's talk about terraform Cloud run environment so when terraform Cloud executes your terraform plan it runs them in its own run environment so what is a run environment a run environment is a virtual machine or container intended for the execution of code for a specific runtime environment a run environment is essentially a code build server so the terraform Cloud run environment is a singleuse Linux machine running on the x86 or x64 architecture and the details of its internal simple petition is not known it is possible to install software on it but the only issue is that we don't know what it is is a Debian is it Ubuntu you just can't tell terraform Cloud will inject the following environment variables automatically on each runtime so we have TFC run ID this is a unique identifier for the current run the workspace name the workspace slug so this is the organization followed by the workspace just going to get my pen tool to just kind of point out over here on the right hand side we have the configuration version and git Branch so you know if it is going to be on Main it's going to tell us that if it's going to be a particular version we'll know that as well we can get the shaw of the current commit there's that version and if you want to access these variables you just Define variable and the name and then you can access it throughout the code okay let's take a look here at terraform Cloud agents this is a paid feature of the business plan to allow terraform Cloud to communicate with isolated private or onpremise infrastructure it's kind of like an inbetween uh between a terraform cloud and terraform Enterprise where you want to use terraform Cloud but you have uh onpremise infrastructure but you're not ready to move to terraform Enterprise so this is useful for onpremise infrastructure types such as vsphere nutanix and openstack the agent architecture is pole based so there are no inbound connectivities required any agent you provision will pull terraform Cloud for work and Carry Out execution of that work locally agents currently only support the x86 architecture or the x64bit Linux operating system okay so you can also run the agent within Docker using the official terraform agent Docker container if you just prefer that over a VM agent supports terraform version 0.12 and above the system requires request the system requires I'm going to change that in the slide later on but the system requires at least four gigabytes of free to space for temporary temporary local copies and two gigabytes of memory needs access to make outbound requests so you need to have open port 443 for app terraform i o registry terraform i o releases hashicorp.com and um archivist.terra for my IO so there you go this is Andrew Brown from exam Pro and we are on to our terraform Cloud uh follow alongs now we already did terraform Cloud uh Version Control System earlier than I thought we were going to do so I'm going to remove from the list and what we'll do is focus on permissions and maybe the API tokens and things like that so what I want you to do and I've got some old tabs open here but I'm going to make my way over to uh terraform.io and I'm going to go log into terraform Cloud here and I don't think I've ever done this but I can upgrade to the trial count because the thing is is that when we are in our account here and we're trying to look at permissions and we're not using Force unlocking anymore I might just keep that around for a little bit but if we were to go to our user settings here we go to organizations um that might not be a very good example like I said I wanted like the organization settings here which would be maybe here yep up here and so you know when we go to our teams and our users our users everyone's being added as an owner we don't have like granular permissions and that's because we'd have to upgrade and so I figured this would be a good opportunity for me to just kind of upgrade to show you those uh more detailed uh rolebased Access Control permissions just so you know where they are so I'm gonna go the upgrade now and notice that we're on the free plan and also take note because later on the course I talk about pricing or we've already already acrossed it but notice that we have a team plan and a team and governance plan this one's at twenty dollars and this one's at seventy dollars so you know this is not something that's reflected at least not right now on the terraform website and so it just looks like there's a team in governance plans for twenty dollars in this middle one's missing the key difference here is this one has Sentinel policies code but you can see on the free plan we are able to do teambased stuff let's go switch over to the trial plan I'm going to see if I can do this without entering a credit card in so here it says you're currently on trial planned I didn't have to enter anything in that's really great and so that means now I have all these Team Management options so if I go over to team management I can actually go ahead and create some teams uh so I'll just say like Developers okay and so now I have all these options so we can say this person if someone's in this team they're allowed to manage policies they're able to do that a visible team can be seen by every member or you can keep them secret we can generate team API tokens which I guess we could just like cover this as we do it but notice we can go here and that generates out that token that we can use I'm going to go ahead and delete that token um so nothing super exciting there you know it's not like that complicated if we want to set things on the workplace now if we go back to workplace or workspaces here and now we have Team access and notice I can go to add team uh permissions here and we can say select this team for their permissions and so these are these uh prebuilt ones in um so we have read plan rights so these are those three predefined ones that we talked about previously and then we have down here like assign permissions for the admin of a workspace we are able to set customized permissions so if we toggle this um we should be able to do it I mean this looks like it's the same thing no I guess it's more granular so here I guess we have our granular permissions that we can set so for runs we can do read plan or reply Locker unlock a workspace send a locks things like that it's not super complicated if we want drain out API tokens for uh well there's the organizational one there's the teams one and then there's the user one so if we go to the organization we can see that we can generate out one here so I can say create an API token so there it is let's go ahead and delete that and if we go back to our teams we did this earlier but we can generate one here and then if you want to generate one for your users probably under user settings yeah so we generate tokens there as well okay so I mean again there's not a lot to talk about here but um yeah so I guess that really covers permissions and API tokens okay okay so that finished deploying there and so we can see our resources have been created but one thing that we didn't set was the prefix I'm actually interested to see that that worked properly but what I could do is say prefix and then do an underscore here and I don't know how that would affect it and this actually happened over in this repository here I'm actually using a hyphen so I'm going to just change that to that might have to do a terraform edit there migrate the state so that was a complete mistake on my part but I guess my thought was that I thought I had to have um this is still on Main and I guess we'd never really set up a production Branch but yeah so now when we have the prefix in it's actually going to prompt us for the other one so the currently selected workspaces are default does not exist and so Dev is showing up and notice that we can't deploy to main so I think the thing is is that if we wanted a production one we would just create that workspace and then it would reflect here so the way you make uh multiple workspaces here would actually have to make them all so we'd have to make a VCS terraform prod and I'm very certain that it would just show up here and then you would select the number that you'd want though what's interesting is the fact that we are in the dev branch and we have to say oh I want to deploy the dev one so that's kind of a little bit of a caveat there but I guess there's not really any way around it but I mean this pretty much you know explores what we need for multiple workspaces with terraform cloud and we did the remote ones and we're all good so there we go I guess the last thing here we should probably do is just clean up so if we go to terraform Dev here we're going to go down to destruction and we'll run a destroy plan here okay and once this is all done you know you can go ahead and just delete these repositories and notice this one is it has a private lock on it so oh because it's actually running right now so it's being locked so yep there we go so that's it all right now let's take a look at the terraform registry the private registry so just go over here and click on registry at the top and we can bring in public um public things here so I can just go here and type this in and we can hit add and so now um we just hit add to terraform cloud add to my organization and that's public facing but we could also add private facing modules so if we go back to our registry here just going to go ahead and uh down to publish here and we go to GitHub and I guess custom and so then I suppose we just have to enter all the stuff in here so as an optional display name for your V Version Control provider client IDs client secrets so it seems like there's a lot of work to do we'd have to set up the SSH key pair but I mean that's generally the details that you need to know for that okay just seems like a lot of work for us to set that up you know and the course is going to be like hey can you add a private module and be like yes okay so we'll go ahead and just remove this so you can add both public and private modules um you know so there you go I have mentioned terraform Enterprise so many times in this course but we've never really talked about in detail and now is our opportunity to do so so terraform Enterprise is the selfhosted distribution of terraform platform and I just want to point out sometimes I call the terraform platform terraform Cloud just because that's the more prominent uh version of it but terraform cloud is a separate product from terraform Enterprise it's just one is uh assassin the other one is selfhosted so terraform Enterprise offers a private instance of the terraform platform application with the benefits such as no resource limits with additional enterprisegrade architectural features such as audit logging so you do you'd have tamper evidence saml single signon and I'm sure there's a lot more other options there so let's just kind of look at the architecture really quickly on how this works so the first thing is you have the terraform platform which is going to be installed on a machine and in particular this is installed on Linux and it's specifically installed on Debian okay so I believe that is the Debian logo as far as as I remember if it's not we'll find it on the next slide if I'm wrong okay you're going to have to have some kind of storage and there's a few different options probably the most common is going to be on something like S3 but you can store it on the storage or on the disk itself you have to have a postgres database so that's part of the infrastructure because that is what the platform uses and you'll also have to have your own TLS certificate to access the machine but there are also cases where you know these are going through air gapped environments but the idea is that you have SSL or TLS it's like endtoend encryption it goes all the way to the machine that's where it terminates okay you'll also need your terraform license so you'll have to plug that in once you start up the terraform platform say hey tell us the code so you can unlock this um this software for you to use on this dedicated machine okay foreign so the requirements for terraform Enterprises is going to highly vary based on your operational mode that you choose to run it in and that is really dependent on how data should be stored and when we're looking at the uh the architectural diagram that was uh the operational mode of external Services there's three types of operational nodes the first being external Services that's when you use postgres and then use cloud storage so in that example we're using S3 but you can use gcp Azure blob storage or Mino object storage but the idea is that postgres and the cloud storage are external they're not part of that Linux server okay then you have a mounted disk so this would just be having a a persisted disk attached to the VM so you know in the best case it's called EBS so this stores data in a separate directory on the host intended for external disk so that would be both the postgres database and the storage volume itself you know postgres is still a requirement and no matter what mode you use then you have demo so stores all data on the instance data can be backed up with snapshots not recommended for production use so this is where you have ethereal data so you know the data you know can vanish if you restart the machine unless you make physical snapshots another component is credentials ensure you have credentials to use Enterprise and have a secure connection so the first is we need the terraform Enterprise license so you obtain that from hashicorp and the other part is having a TLS certificate and private key so you need to prove uh you're the uh you own uh your own TLS certificate okay then we have the Linux instance so terraform Enterprises designed to run on Linux and it supports more than one version so you know I said it was only Debian but I guess there's a bunch I just forgot so we have Debian Ubuntu Red Hat Centos Amazon Linux there's a variety for those Oracle Linux so yeah I guess I just a big fan of Debian so that's I guess that was my my thinking there for Hardware requirements we have at least 10 gigabytes of disk space on the root volume at least 40 gigabytes of disk space for the docker data directory so that would be the VAR lib Docker at least eight gigabytes of the system memory and at least four CPU cores so there you go foreign let's talk about error gapped environments so what is an air gap an air gap or disconnected network is a network security measure employed on one or more computers to ensure that a secure computer network is physically isolated from unsecure networks so the public internet so it's no internet no outside connectivity Industries in the public sector so government military or large Enterprises finance and energy often employ air gap networks and so I want you to know that hashicorp terraform Enterprise supports an installation type of air gap environments okay so to install or update terraform Enterprise you will supply an air gap bundle which is an archive of a terraform Enterprise release version so that's how you would um you know provided okay so let's take a look at terraform Cloud features and pricing so I just want to quickly go through it here so we have three models we have the open source software so OSS we have the cloud offerings and the selfhosted offerings I know these tiers we have free teams and governance technically it's teams and then teams and governance so they're two separate plans but this is the way they display it in their marketing content but it really is a separate two separate tiers in there you have business and then Enterprise which is considered selfhosted so in terms of feature set across the board you have IAC workspaces variables runs resource graphs providers modules the public module registry which is terraform registry workspace is a bit odd because there are terraform Cloud workspaces right and then you have local workspaces so technically those should be broken up into two separate things or named differently but that's just how it is with terraform so you know just asterisk on that workspaces there for the free tier you get remote state or sorry for everything outside of the open source you get remote State vs VSC connection so that's Version Control State connection so connecting to GitHub or or git lab or whatever workspace management secure variable storage remote runs private module registry once we get into Cloud we get Team Management Sentinel policy as code management cost estimation the reason why I have that in Red is because on the exam it could ask you when is Sentinel policy available is it available at what level and the thing is it goes from teams and governments all the way to the Enterprise level now technically there is again one called teams and there's teams and governance so it's part of teams and governance not part of teams okay uh once we get into business this is where we start to get single signon and audit logging so you know if you need it in the cloud or if you need it selfhosted both options are available in the business we have the you can have the selfhosted agents for configuration designer servicenow integration you have it for those uh as well in terms of how many runs you can have this is very important because this is how many this is going to put a bottleneck in terms of your infrastructure rights on the free Terry you can have one current run of a workspace and teams you could have two and then at the business level and Beyond its unlimited current runs for uh how you would actually interact with um terraform you know this is going to be through the local CLI for the open source software for these it's Cloud meaning that um it's Cloud that is triggering the execution commands and then selfhosted it's not in the cloud it's on that private machine okay uh then we have support So for support it's all community so that's just going reaching out to DA's maybe there's a slack Channel I believe that they have a form so they have like a form where you can ask questions and then they have these layers like bronze silver and gold I could not determine what these are like what is offered in them and the odd thing is is that you know there's a silver and gold but it's offered both at business and Enterprise so I don't know if like you can upgrade to from silver to gold so it's optional or you always get silver and gold could not get clarification I tried asking the sales team no one would tell me so I think you have to really be deep in that sales funnel to find out in terms of pricing it's zero to up to five users so the thing is and this is really confusing about terraform cloud and they really shouldn't have called it teams up here but you can start using terraform Cloud for free up to five users as a team okay so just negate the fact that it's not called teams what they're saying is that teams is really about getting a base workspace Remote Manager which is actually our RBA like our ABC controls uh rolebased access controls so that's the whole point of using teams so if you need that and that's when you're at five that's going to use it but you can use it in the free tier as a team and you it absolutely should once you get to the teams plan it's going to be twenty dollars a month and then if you need teams and governance it's actually like seven dollars a month so again it's kind of like a bit misleading how they've labeled this out but if you go and open up teams Cloud you can see what the actual packages are for uh business that selfhosted your contact and sales so I have no idea what the cost is there so there you go all right we're taking a look here at workspaces so workspaces allow you to manage multiple environments or alternate State files such as development reproduction and there are two variants of the workspace we have CLI workspaces a way of managing alternate State files locally or via remote backends and then we have terraform Cloud workspaces that act like completely separate working directories I'm going to tell you these two are confusing because they don't exactly work the same way but they have the same name and originally workspaces were called environments and so you know when you're using terraform Cloud it makes a lot of sense to call them environments and the CLI workspace it's just a little bit different so you know I'm not sure if I'm going to do a great job explaining the difference of these things you really have to go through the motion of it to really get the hang of it but I'll do the best I can here okay so think of workspaces as being similar to having different branches in a git repo workspaces are technically the equivalent to renaming your state file okay so in terraform 0.9 they used to be workspaces used to be called environments but people got confused which I have no video why but you know that's what it is now so by default you already have a single workspace in your local backend called default and the default workspace can never be deleted so even if you don't think you're using workspaces you absolutely are even the first time you use terraform at least in the CLI workspace okay let's get a little bit into the internals this isn't really that much detail but depending if you are on a local or remote back end changes how the state file is stored so if you're on a local state or a remote State it's going to be different so uh terraform stores the the workspace States in a folder called terraform.tfstate.d on the road State the workspace file are stored directly in the configured backend in practice individuals or very small teams will have been have known to commit these files to the repos but using a remote backend instead is recommended when there are multiple collaborators so I guess there's not really much to say here but just understand that when you have a local state file it's going to be in that terraform TF State D and then when it's remote State you don't have to worry about it okay let's talk about interpolation with current workspaces so you can reference the current workspace name via the terraform.workspace named value so we saw that in the lineup way earlier in the course so the idea here is that if you wanted to um see if the default like let's say you want to say am I in the default workspace then return five as opposed to one because maybe you're very comfortable spinning up more in the default than whether it was something else and just another example maybe you want to use it to apply the name of the workspace as a tag so here that would actually give this virtual machine in AWS the name web hyphen whatever it is production or development so there you go foreign let's talk about multiple workspaces so a terraform configuration has a back end that defines how operations are executed and where persistent data is stored so like the terraform state so multiple workspaces are currently supported by the following backends Azure RM console cos GCS so that's Google Cloud Storage kubernetes local Manta postgres remote S3 they're not going to ask you this on the exam which ones are supported but you know for your own purposes if you want to use multiple workspaces with a a standard back end you probably want to know which ones certain back ends support multiple name workspaces allowing multiple states to be associated with a single configuration that the configuration still has only one back end but multiple distinct instances of the configuration to be deployed without configuring a new back end or changing authentication credentials why would you want to use multiple workspaces for something like a standard um a standard back end well the idea here is that you know if let's say you're using terraform cloud and you've reached your limit of five users and it just gets too expensive to go to the sex user where you have to pay for all of them uh you know then the thing is is that you know this is an option for you it's just kind of like another option out there until you are ready to pay for terraform Cloud at the next tier up so that's the reason why I'm mentioning it here for you okay all right let's quickly walk through the terraform Cloud workspace and the easiest ways to just show you a screenshots so you create a workspace on terraform Cloud so first you'll create an organization mine's called exam Pro and within that you'll create multiple workspaces from there you'll click into your workspace and you'll see uh like previous run States variable settings we'll click into runs from runs what we'll get is a list of what happened previously we can click into one of those and we can see our plan and our apply we can leave a comment on each run that has happened if we if we just want to expand the plan and apply here for plan we will see all the details of what it would change and then apply is it actually setting up that infrastructure and whether it was successful or not notice you can also download Sentinel unlock files we'll come and talk about that later when we get to our Central section we can also see a history of previously held States so these are snapshots of that infrastructure and so you can click into there and exactly see what it looks like this is useful if you want to go and download it if you were to need it so here's a diff of what changed since the last state okay and of course you can download that stuff so you know hopefully that gives you an idea of what you can do with terraform cloud workspaces foreign let's talk about terraform Cloud run triggers so terraform Cloud provides a way to connect your workspaces to one or more workspaces via run triggers within your organization known as source workspaces so run triggers allows runs to queue automatically in your workspace on successful apply of runs in any of your source workspaces and you can connect each workspace to up to 20 source workspaces so run triggers are designed for workspaces that rely on information or infrastructure produced by other workspaces if a terraform configuration uses data sources to read values that might be changed by another workspace run triggers lets you explicitly specify the external dependencies so the idea is just allow you to say okay I have one workspace I I've triggered that I wanted now to do that so this is really great if you have a bunch of uh of environments or or Stacks that are reliant on each other and you want it to kind of have a chain reaction the reason I'm mentioning run triggers is a I think it's a cool feature and B Because triggers is something that is also uh something else when we're looking at provisioners and I just wanted to just clarify that there's run triggers from terraform cloud and then there's triggers that are for um well I said provisioners I really mean null resources they have triggers in that okay so it's not going to show up an example it's just a good to know feature I just want to make sure there's no confusion with the other triggers let's take a look at some of the terraform workspace CLI commands that we have available to us the first starting with terraform workspace list so list all the existing workspaces and the current workspace is indicated by an asterisk so that is our current workspace there terraform workspace show show the current workspace so right now we're working in development terraform workspace select switch to a Target workspace so here we could say select default and now we're in the default terraform workspace new so create and switch to a new workspace and then we have terraform workspace delete so delete a Target workspace now understand that this is affecting your local ones for the CLI commands Okay but um yeah so this would actually show up in the exam they might ask you like you know which is Select and what does list do and things like that so make sure you know these commands Okay all right so I just wanted to contrast against the local or CLI driven workflows via the terraform Cloud workflows because there's this great uh table chart that's from the documentation that I want to show you so to our firm cloud workspaces and local working directories serve the same purposes but they store their data differently so just looking here we'll go down to components here so for terraform configuration it's going to be on disk for local for terraform cloud in linked Version Control repositories or periodically uploaded via the API or CLI we have variable values so this is where we use tfrs and when we're in terraform Cloud it's in the actual workspace the terraform Cloud workspace and so that means that we are setting environment variables to propagate that into our code or inject those variables into our code on execution for State it's on disk or in a remote back end and in the workspace for terraform Cloud it's actually in the workspace credentials and secrets are in Shell environments or our internet prompts and workspace they're stored ascent the variables these are environment variables again so there you go hey this is Andrew Brown from exam Pro and we are on to our terraform Cloud uh follow alongs now we already did terraform Cloud uh Version Control System earlier than I thought we were going to do so I'm going to remove from the list and what we'll do is focus on permissions and maybe the API tokens and things like that so what I want you to do and I've got some old tabs open here I'm going to make my way over to uh terraform.io and I'm going to go log into terraform Cloud here and I don't think I've ever done this but I can upgrade to the trial account because the thing is is that when we are in our account here and we're trying to look at permissions and we're not using Force unlocking anymore I might just keep that around for a little bit but if we were to go to our user settings here we go to organizations um that might not be a very good example I guess I wanted like the organization settings here which would be maybe here yep up here and so you know when we go to our teams and our users our users everyone's being added as an owner we don't have like granular permissions and that's because we'd have to upgrade and so I figured this would be a good opportunity for me to just kind of upgrade to show you those uh more detailed uh rolebased Access Control permissions just so you know where they are so I'm gonna go the upgrade now and notice that we're on the free plan and also take note because later on the course I talk about pricing or we've already already acrossed it but notice that we have a team plan and a team and governance plan this one's at 20 and this one's at seventy dollars so you know this is not something that's reflected at least not right now on the terraform website and so it just looks like there's a team in governance plans for twenty dollars in this middle one's missing the key difference here is this one has Sentinel policies code but you can see on the free plan we are able to do teambased stuff let's go switch over to the trial plan I'm going to see if I can do this without entering a credit card in so here it says you're currently on trial planned I didn't have to enter anything in that's really great and so that means now I have all these Team Management options so if I go over to team management um I can actually go ahead and create some teams uh so I'll just say like Developers okay and so now I have all these options so we can say this person if someone's in this team they're allowed to manage policies they're able to do that a visible team can be seen by every member or you can keep them secret we can generate team API tokens which I guess we could just like cover this as we do it but notice we can go here and that generates out that token that we can use I'm going to go ahead and delete that token um so nothing super exciting there you know it's not like that complicated if we want to set things on the workplace now if we go back to workplace or workspaces here and now we have Team access and notice I can go to add team permissions here and we can say select this team for their permissions and so these are these uh prebuilt ones in um so we have read plan rights so these are those three predefined ones that we talked about previously and then we have down here like assign permissions for the admin of a workspace we are able to set customized permissions so if we toggle this um we should be able to do it I mean this looks like it's the same thing no I guess it's more granular so here I guess we have our granular permissions that we can set so for runs we can do read plan or reply Locker unlock a workspace send a locks things like that it's not super complicated if you want to drain out API tokens for uh well there's the organizational one there's the teams one and then there's the user one so if we go to the organization we can see that we can generate out one here so I can say create an API token so there it is just go ahead and delete that and if we go back to our teams we did this earlier but we can generate one here and then if you want to generate one for your user it's probably under user settings yeah so we generate tokens there as well okay so I mean again there's not a lot to talk about here but um yeah so I guess that really covers permissions and API tokens okay okay so that finished deploying there and so we can see our resources have been created but one thing that we didn't set was the prefix I'm actually interested to see that that worked properly but what I could do is say prefix and then do an underscore here and I don't know how that would affect it and this actually happened over in this repository here I'm actually using a hyphen so I'm going to just change that to that might have to do a terraform edit there migrate the state so that was a complete mistake on my part but I guess my thought was that I thought I had to have um this is still on Main and I guess we'd never really set up a production Branch but yeah so now when we have the prefix in it's actually going to prompt us for the other one so the currently selected workspaces are default does not exist and so Dev is showing up and notice that we can't deploy to main so I think the thing is is that if we wanted a production one we would just create that workspace and then it would reflect here so the way you make uh multiple workspaces here would actually have to make them all so we'd have to make a VCS terraform prod and I'm very certain that it would just show up here and then you would select the number that you'd want though what's interesting is the fact that we are in the dev branch and we have to say oh I want to deploy the dev one so that's kind of a little bit of a caveat there but I guess there's not really any way around it but I mean that's pretty much you know explores what we need for multiple workspaces with terraform cloud and we did the remote ones and we're all good so there we go I guess the last thing here we should probably do is just clean up so if we go to terraform Dev here uh we're going to go down to destruction and we'll run a destroy plan here okay and once this is all done you know you can go ahead and just delete these repositories and notice this one is it has a private lock on it so oh because it's actually running right now so it's being locked so yep there we go so that's it hey this is Andrew Brown from exam Pro and we are taking a look at Sentinel which is an embedded policies code framework integrated within the terraform platform so what is policies code when you write code to automate regulatory or governance policies and features of Sentinels include uh it that it's embedded so enable policy enforcement in the data path to actively reject violating Behavior instead of passively detecting so it's very active or proactive finegrained condition based policies so make policy decisions based on the condition of other values multiple enforcement levels so advisory soft and hard mandatory levels allow policy writers to warn on or inject reject Behavior we have external information so Source external information to make holistic policy decisions we have multicloud compatible compatible so ensure infrastructure changes are within business and Regulatory policy across multiple providers and Sentinel is a paid service part of the team and governance upgrade package so Syrian team in governance it's available for that business and Enterprise okay let us expand a bit on the concept of policies code and relating to Sentinel so Sentinel is built around the idea and provides all the benefits of policy of code let's talk about the benefits we get with this so sandboxing the ability to create guardrails to avoid dangerous actions or remove the need of manual verification codification the policies are well documented exactly represent what is enforced Version Control easy to modify or iterate on policies with a chain of history of changes over time testing so syntax and behavior can easily be validated with Sentinel ensuring policies are configured as expected automation so policies existing as code allows you to allows you to direct integrate policies in various systems to Auto remediate and notify we're talking about senatal and policies code we have language so all Sentinel policies are written using the sender language this is designed to be nonprogrammer and programmer friendly and embeddable and safe for development Central provides a CLI for development and testing and for testing Central provides a test framework designed specifically for for automation so hopefully that gives you an idea of the benefits of policy code and in particular with Sentinel all right let's take a look at the Sentinel language and also just a broad uh range of of use cases that we could use these for so you can start thinking about how to start applying Sentinel the great thing is that there are a bunch of example policies provided by hashicorp so you can easily um you know start using them right away but let's go through the big list to kind of give you an idea where you would use policies code so for AWS maybe you'd want to restrict the owners of the AWS Ami to a data of the data source maybe you want to enforce mandatory tags on taggable AWS resources restrict availability zones used by ec2 instances disallow a 0.0.0.04.0 basically anywhere address out to the internet restrict instance types of ec2 so maybe you only want people using T2 micros require S3 buckets to be private encrypted by KMS since that is a big um a big problem for people on AWS where their buckets get leaked require vpcs to have DNS host names enabled we're looking at gcp enforced mandatory labels on VMS disallow allow anywhere cider and force limits on gke clusters because those can get really expensive restrict machine types of VMS just like AWS for VMware required storage DRS on datastore clusters restrict size and type of virtual disks restrict CPU count memory of VMS restrict size of VM disks record NFS 4.1 and cure Burrows I never can say that properly on NAS data stores for Azure enforced mandatory tags of VMS restrict Publishers of VMS restrict VM images restrict the size of azure VMS enforce limits on AKs clusters restricts cider blocks of security groups for cloud agnostic allowed only say we can only use these allowed providers say or explicitly say what providers are not allowed limit proposed monthly costs prevent providers in nonroot modules require all modules have version constraints require all resources be created in modules and private module registry use most recent versions of modules in a private module registry that's more so like about the tooling around modules now let's take a look at an example and this is one for restricting uh available zones on ec2 instances so like what data centers you're allowed to use and so we first import our language functions that's going to allow us to use particular uh feature functions in this we're going to specify our azs we're going to get all the virtual machines we're going to filter that and restrict the AZ for those VMS we're going to Define that rule to make it enforceable so there you go thank you all right let's take a look here with Sentinel with terraform so Central can be integrated with terraform via terraform Cloud as part of your IEC provision Pipeline and where it's going to sit is between plan and apply okay so the way you do it is you're going to have to create a policy set and apply these to the terraform workspace so it's not that complicated to get it hooked up so yeah that's all there is to it okay hey this is Andrew Brown from exam Pro and we're going to learn a bit about Sentinel with terraform I'm not going to say I'm amazing at it but we are going to stumble our way through and see what we can accomplish we know we can download Sentinel box and there's also the ability to set policy sets and I do know that there are a bunch of premade Sentinel policies so we go send no policies here terraform uh and we go examples uh there we are probably here there are a bunch of ones that we can go in here so I'm thinking that there's something that we can do here um but we'll have to figure our way through here because I actually haven't ran any um policies myself so we have these two environments I'm not using Dev anymore I'm done with this I'm going to go ahead and destroy that and we're going to go down to terraform destroy I'm pretty sure I don't have any running infrastructure actually I'm going to double check by going to the overview everything has been destroyed and so I'll go back over here and we're going to destroy this I'm going to type in VCS terraform Dev great if we go into this workplace or workspace nothing is provisioned right now so I want to get everything running again because last time we ran a destroy so I think that if we want to get this working it should be pretty easy I'm going to go back to our workflows file here and we're just going to revert some changes so I'm going to go back and change this to name and I'm just going to go whoops we're going to go into our 120 directory here and we're going to check out Main and that actually might just revert those changes there I don't think anything really changed much other than this part here and so what I'm going to do is just go Um make a minor change it doesn't matter what it is maybe a space get add all whoops git commit hyphen m changes get push I'll have to do a good pull here get push sorry get push and so what I want to see here is a trigger for the Run there we go and I'll see you here in a bit when it's provisioned okay all right so after a short little weight there it looks like our branches Ran So I think our resources are provisioned it's cool we actually have cost estimation I didn't have to do anything to turn that on we already have it notice that it's giving us an hourly of Zero 12 cents the monthly is going to be eight dollars in you know 35 cents there if there was more resources there we would obviously get that I assume that it would show up here in the top right corner so we're not really interested in the provision infrastructure but more so looking at these Sentinel locks so I'm going to go ahead and download them there and that's going to download as a um a zip or an archive of some sorts and so what I can do here is just unzip it so I'm just going to make a new folder here and we'll just call these um Sentinel marks okay I'm just going to open up the zip and so here's all the stuff in here so we have a variety of different files I think some of them might be redundant I'm not sure what we have to do with them but I'm just going to go ahead and grab these and drag them into the folder here okay and actually what I'm going to do is um I'm going to just make a new section in my folder here whoops just give me a second here we'll just open up the Explorer to anything yeah we have a folder right here because what I want to do is just drop those files in so we can just see them in vs code the contents of them there we go and so now I'm just going to go down to here and we'll take a look so we have Sentinel HCL all right and so that's just defining a bunch of mocks we have this Central File here so I was hoping when we open this it would be able to figure out what to do with this and I have no idea so you know what what I'm going to do is I'm just going to do a little bit of reading and I'm going to come back to you after I finish reading this okay all right so spending a little bit of time uh watching some stuff so I was just going through the Deep dive of Sentinel here uh and just going through the documentation and as far as I understand it looks like that you write policies and then you can also write tests for your policies to assert that your policies are doing what you expect them to do and I guess those uh Sentinel locks are written in a form of HCL but it is a little bit confusing because you get this folder with a bunch of stuff in it and it can be either written as Json or like this htl like format but as far as I can tell it's just saying what it's done is it's generated out these the current state of exactly what your infrastructure is and I think that it's going to check to see is it exactly what you expect it to be so I don't know if MOX is that very useful and might be a little bit too much for this particular course so I'm just going to say okay let's just kind of ignore locks because they're just a little bit too too difficult and out of scope here let's follow focus on trying to get a policy implemented so I'm going to go back over here and what I'm going to do is I know that if I go to settings I mean I've seen it before I just can't remember if it's under a workspace no it's I think it's at the organization level so we're gonna go to the settings here and there we have our policies so we here we can create new policies so managing individual policy terraforms deprecated policy sets now supports VCS integration with direct API uploads this provides a streamlined policy management experience policies which includes okay so this is the old way of doing it and so we'll go here and create a new policy set so connect a new policy set um okay so I guess what we have to do oh boy this is a lot different than I thought it was going to be so I thought it was just like we're going to go here and create it and then dump our code in which apparently that's what it is but it seems like we need to associate with the policy set so just give me a moment because I do want to show you the the most uptodate way to do this I'll be back in a second all right all right so doing a little bit of reading here it looks like what we have to do is create ourselves a sendile.hcl file and this is going to say what policies we want to enforce so I assume this is basically the policy set as a file and here we specify the policies that we care about um I actually just want to go back to the files we were looking at earlier because we saw this HCL file so I guess this would technically be a policy set is that what we call that here but notice it says mock so these aren't policies per se these are just grouping mocks but in any case I think we'll have to create this file so what I'm going to try to do and I don't know this is going to work but we'll just stumble our way through here because it's the best way to learn is we're going to create ourselves our own Sentinel file here so we're going to say um Sentinel dot HCL and we're going to Define ourselves a policy this is going to be the one that we're going to use but I'm just going to grab it here notice there are different enforcement levels so um I don't really care we put in I just want to see that we can successfully get anything working here and I'm going to go back to the examples if we can go find that there so Sentinel policy examples and let's just go take one of those and see what we can do with it okay so if we scroll on down um this allows zero zero zero cider Block in the security group that seems like something that would be pretty relevant restrict instance type of ec2 instance that could be something as well that we could do so you know I just have to decide what it is we want to do here restrict owners so there's a few that are good here let's take this take a look at this one because I feel like this might be very simple so yeah this is perfect okay so what we'll do is we'll take uh this policy here so I wonder if I could just go download this file here it's probably like a download button well I can't find it so we'll just or maybe it's up here no okay we'll just create this by hand here so I'm going to go copy and it looks like we can just drop it in here so I'm just going to new file here and put that there and we will just go to Raw and we will go ahead and drop that on in there so I wish I had like sandal highlighting I don't know if there is such one for vs code if there is it'd be really nice so we would type in Sentinel um uh yes we do this one has more downloads so we'll go with that one no rating as of yet looks like it works so let's go give them a five star I think that's only fair because uh no one's done that yet might be a bit too hard to uh I've never written a review before but we'll go here and say works as expected thank you for this uh extension okay so what I'm going to do is go back over to here and so here we have some kinds now we're running a T2 micro I believe so this policy should cause it to fail and that's exactly what we want but I'm just going to go look up and down to see if it's all correct looks good to me so I think we'll have to change over here is the name so I'm just going to clear this out and we'll say restrict ec2 instance type we'll save that hard mandatory sounds really good to me um probably have to spell it right for it to work res yeah strict okay great and so what I'll do is just copy this up here okay and so we have our signal HCL file and it's referencing a local file now the question is you know can we use the same repository I assume we would be able to uh for our policy set but it almost seems like it might encourage you to have your policies separate from your repository that you're testing and that might be really good because let's say you have multiple workspaces or environments and they all require the same policy set you wouldn't want to have them in your code base like that but for the purposes of this we're just going to keep it simple I'm going to go ahead and open up terminal here and we're going to commit these uh these changes to our Repository and this will end up triggering a deploy even though we don't necessarily want that to happen but there's no way around that so get well I suppose we could just cancel it out but or not have the auto apply but I don't feel like changing that so we'll do get status here we'll go get add all git commit hyphen M uh simple policy here get push okay and so that's being pushed to our repository that's going to trigger a deploy and we don't care I I assume that it won't pick up the policy because we have to kick the policy set so um apparently use the API to upload your policy set which is kind of cool I suppose we could have done that but um well too late we probably should use VCS anyway you know what I mean so we'll go to GitHub here and we will find our terraform repository which is here um you know policy well we should probably name this right so we policy to enforce uh instance type I don't know if we need a description I guess we'll find it in a second here I guess we could have also put the policy in a um a subdirectory there that might have been okay to do it's going to default to the main branch which is fine policies enforced On All workspaces or policies and force on selected workspaces and we only have one but that's what we'll do down here so we'll say update the name is invalid oh uh it has to be like a proper name so restrict ec2 now again this is a policy set so you could just say like um you know basic server policy set that'd probably be better and then you probably want to list to say what it does it restricts um ec2 instances instance type okay and we'll go down here and create that policy set and that looks like we're in good shape so we applied it um now will it actually happen on this run because it's already running I believe we're going to this workplace workspace I like to say workplace it's workspace and uh we go over here this is already planned and finished so what I want to do is just trigger another uh um deploy here so there's nothing changed so I'm not sure what we do here um I guess what we could do and actually this is something that I'm I don't know but like how would you trigger a replace on here because if we were doing let's go to plan and see what happens I wonder if we could do that in the plan here reasons for trigger do refresh only plan because one thing I was thinking about is like imagine I wanted to replace an element you can do that hyphen replace but I don't know how you do that through VCS but anyway what I'm going to do is just go change anything in our code um so it could just be a space it doesn't really matter get add plus git commit trigger uh change and we just want to observe the um the policy working okay so I'm just going to open this up here I'm not sure if it's going to show up in the plan section or the apply section so we'll just wait here to watch see the plan generate out and so the plan finished um we don't see any Sentinel uh Central being applied there apply will not run let's expand that there this looks fine I guess technically we didn't change anything so that probably is not very helpful so what I'm going to do is go and change a variable because maybe that's that's what's going to help here so we have a micro here which is fine we're just going to change this over to Nano that makes sense why I didn't do it so we'll go back over to runs and I'm going to trigger I'm going to start a plan so uh changed ec2 instance type we'll say Start Plan okay so we have one change which is fine we just okay so that part pass is going to go to cost estimation that passed it's going to apply it because remember we have um Auto approve on the server so it's not even going to ask us to confirm it and so I want to see if that policy is in place well it's running I'm just going to go review our policy here just to make sure it's not like the opposite saying like you cannot have these so include now a loud easy to do instance type so it's small medium or large so it really should quit out on this one here but it seems like it's working like it's not uh it's not picking up the policy but I'll see you hear it back in a bit okay all right so I didn't see the policy trigger there so I'm going to go back to policy sets and notice here it says zero workspaces which is unusual because I definitely selected one but maybe I didn't click through or hit uh add so I'm going to go down here and click this one again and maybe I didn't hit this button here okay and now I'll probably have to hit update um policy set before we do I just want to read about this these parameters are past the central runtime on performing policy checks so I guess I'd be like a way where you'd have a generic policy and then you could kind of put parameters in so that's kind of cool so I'm going to go back here and double check to make sure that we have a workspace set and so what we'll do is just change the variable again um so we will go to our variables here and I'm going to go change this back to a micro and so I think this time we are going to have better success okay so we'll hit save we'll go back up to runs we'll go and start a new plan uh change instance type again here and we will save that plan and so that plan is now running I will see you back here in a bit uh when we see that Sentinel policy I don't know when it triggers so I'll see you back here in a bit all right welcome back so after our cross estimation it did a policy check and you can see that it failed um and here the error says import TF plans function is not available so I'm not sure why that's happening so I think that um I mean our set failed but not for the reason we wanted to so I'm going to go investigate this I'll be back in a moment okay all right so uh what I've done here is I've gone and looked up uh like how to create a policy set and hashicorp learn has this example project here and if we go into its GitHub project and I go here you're going to notice that it it's like this apparently does basically the same thing restrict AWS instance type and apparently tag as well but it doesn't have the TF functions the TF plan functions here so um maybe we don't need that function in there and maybe the uh the example is just out of date at this time so import common functions for Sentinel okay but this one doesn't have it it does it does have it for mocks right um so maybe we just need to kind of like walk through this really quickly and see how we can fix this so the policy uses the Sentinel TF2 plan import to require that all ec2 instances have instance types planned under the loud list but I don't see that import there okay and it is in here so I guess what we'll do is just grab this one okay and I'm going to go ahead and just delete this one out here um again this isn't working I don't know if this would work with that one so I'm going to take it out this is pretty clear what this does so we'll just have that allowed types it's interesting like here it's underscore and then here it's like a title case there's some inconsistencies there so they have a lot of types as well um and I'm just seeing if there's like find resources in here so allow types rule to enforce the name tag so I don't care about that rule to restrict the instance type so I'm going to go ahead and grab this one here and let's just take a look at the differences here okay so instant type allowed rule all ec2 instances as that instance change after instance type a lot type so this is way way different um so I mean I fully don't understand this but I do know that this one it will probably work so I'm going to go down here we have count violations I'm not really worried about that and the rule is different like if I was really serious about this I'm sure I could you know figure out the logic here but again this is just for the purposes of us learning so we don't have to go too crazy here now this says instance type allowed and mandatory instance tags we're not dealing with tags here so I'm just going to say this okay and so I think this will produce what we want so allows those types I don't know if it had this in here get all instant types from the module I think we didn't put this in here so this might be kind of the equivalent ec2 instances filter TF plan resource changes okay contains a create or an update okay um I mean this isn't bad we technically have a name set so you know what I'm just going to grab this whole thing because then we're just going to have a much easier time we don't have to worry about it but it was nice to walk through that file very quickly because the name tag is set in our project a because we can see we can see that's the server name so what we'll do is we'll just go ahead and add this to our repository here and the great thing is that since it's the vs code or it's in the same Version Control System I would think that it would update in time so what we'll do is just do get add all git commit hyphen m fix the policy git push okay and we'll go back over here and we will see if the policy check happens and when it does happen it's actually airing out because we're not using the right instance size right that's what we want to see a little bit of trial error it's not a big deal I also read like over here that the Sentinel file for HCL only contains module and policies but then we saw a sentinel file or htl file that clearly had mocks in it so I mean maybe maybe it just only used locally maybe it's not intended for um production um so we'll go down here TF plan so it didn't pick it up okay so what I'm going to do is go back to my policy set and maybe it's just like the order of how this happened so see this says it was updated uh last five minutes ago updated it a minute ago so this could just be like a race case where um you know this ran before the other one so I'm going to try to execute this again start a new plan uh trigger plan and we'll see if that works now because again this said literally updated a minute ago so maybe it didn't pick it up so you can see why it would also be good to have your policy set in a separate repo because if you're deploying this you don't want to keep triggering your deploys so I think probably that's what you know we should have done I mean it's a lot extra work but you know this way you kind of understand why SO waiting on that plan run I really don't care about cost estimation I mean you could make a policy to check based on that I I'm assuming we just turned that off if we wanted to and we'll go over to cost estimation here yeah we can just disable it but the thing here is that it set our policy passed so we'll go here so the result means that all Central policies passed so restrict the instance type so description main rule that requires other rules to be true ruleton Force name tag is on all instances that's true rule to restrict the instance type so maybe we don't understand uh maybe this works in the opposite way oh the t2 micros here okay so I just want to see it fail so what we'll do is go back up to our variables here and we'll go to our instance type and we'll just change this to Nano and we'll save that we'll go back over here to our runs oh this is still running the old one here that's fine we can just queue up another one here so we can just say start a new plan uh new instance type okay and if we go back over to here the last one wouldn't have done anything because the infrastructure would have been the same so the previous one we just did here right it would just been like oh no it's still trying to apply it so I guess there is a change maybe we changed the instance type last time I don't know so anyway I'll see you back here when this is completely done okay all right great so we got an error if we go into our instance type here right and we look at it we can see that it failed because uh it wasn't the right uh type so um I mean that's pretty interesting so the other thing I would say that we could do is also kind of check out mocks now because I kind of feel like I have a better grasp on it now that we have a test running so just thinking straight about it a mock really is a representation of the state of infrastructure at the time of so if we go back to our runs and we go to a successful run like the trigger plan here and this one was successful we could go to the plans here and then download these mock files so we do have the ones from prior and I think those are totally fine and valid to use so what if what we do is go back to our project over here and we have um the mock files over here but really where they need to be is within the workflow directory because looking at the documentation here what it's saying is that you get all these things and this basically represents the state of those mock files and then you need to make a test folder and then a test data folder and then there's gonna be something based on the name of the uh the mock file so what we'll do is we'll go up to this folder here and we'll say new folder test and then we'll make another new folder here test data those folders are files I think those are files so I'll delete that it's just out of habit to click the um the file there so we'll say new folder so we'll say test and then we'll say another new folder there test data okay and so we have our sendle file here so we need to have I think a similarly named one here so if we go back over here um this is Foo whatever so I think we need to have a folder in here because it's all based on convention and I just it's pretty not that hard to figure I don't have to read the docs to know that we'll just put that in here take out the word Sentinel and then I would assume that we need a file in here what's it called like this pass and fail so I'm going to just do a pass file new pass.hcl okay and then we have our test data so that was what we had down below here so I need to go grab that information I'm just looking for a folder where I might already have open here if I don't that's fine we'll just go ahead down below and just right click and reveal and explore we'll go over here and I need to move all these over so I just copy them over and we're going to go over to our terraform work flow here and I'm going to go here and paste that data in I don't know if these contain any kind of sensitive data because if they're based on the TF State file these might be something you don't want to share that might be a security vulnerability I don't know but I definitely won't have these available when I put this repository up for free so we have those files in the right place and we have all this stuff here so I I think that um like you notice it's not there so I'm assuming that we need to open up this file and copy into our main HCL file so we'll go down below here and then I think it's just a matter of copying all this stuff right we'll say cut and then we will go to um back up to here I suppose into our file it's getting a little bit confusing with all this stuff eh okay so that's in the right place our test data is there good here we are okay so what I'm going to do is just go down here and paste that in okay and so we didn't write any kind of pass data test so that's something we will need here I'm not sure what we'll get so we'll just scroll down here so you can find the contents of a pass.hcl it's not showing anything here so just give me a moment I'm going to see what we have to do for this this test okay all right so a little bit of Googling it looks like uh this one's on the same tracker so since we probably copied the mock data from this one or somewhere through here we could probably just go grab this so um this is pretty much what our pass file will look like so we'll go ahead and grab this here I don't know if we really need a fail to write a failing test I don't really care about that I just want to see anything pass here we'll paste that in here we do have to be sure that we are accessing our data correctly so if we're in test it's going to go up one directory to the terraform directory but wouldn't it have to then CD into uh test so I don't think that Source path is correct just going to double check that here they do have an example repositories let's take a look here what we have um yeah it's kind of odd so I think that if this is relevant it needs to go to test data because how else will it get there okay so we'll do that so test rules main equals true um okay so that's a pretty simple test and so I think the way we run tests is there's like a sentinel test thing here I don't know if we have Sentinel installed I don't think so so there's no Sentinel command so I guess that's something we're gonna have to install Sentinel um CLI terraform okay over here uh we're on technically Linux even though we're on Windows we're on Linux so here it's just saying uh download it and then put it in the correct path so install so we'll get the appropriate package here and we are technically on Linux and I guess we are 64bit it's going to download here scroll up oh it is already downloading okay great and so I'm just going to go to my downloads and I'm going to open it up here so there it is and so I need to um get it into the user local bin here so I'm just going to first get it in anywhere so because I'm just working here I'm just going to go open this up so reveal in the Explorer okay and this is not where I want it to be I'm just dropping it here for the time being technically we could run it from there I don't think it'd be that big of a deal so I'm just going to go back to my vs code here and I'm going to just type signal Sentinel is there right yep it's there I'm not sure if it's executable but um I'm just going to type in Sentinel here Sentinel test okay so it doesn't think it's command so maybe I have to do like chamod U plus X that makes it executable on Linux so note command not found well heck I'm right there maybe I have to put a period forward slash like that okay there we go so I mean of course you don't want to leave it in here you and this would also end up in a repository so this will go to like your user local bin probably so I'm going to say like move sendle to user local bin and so now I should just be able to type Sentinel it should get picked up it does great so here I can do test and down below it says open test no such file or directory so it can't find the mock data notice that it's going into the test test data so that is no good for us we did say to go up a directory so maybe if I go up back one more like this would that work no let's go put back in what they actually had there which I have a hard time believing that would be correct so open mock okay so that's definitely not right okay and so personally I just want this to work so I'm just going to cheat this is absolutely what you should not do but you know like I don't be fiddle around with paths all day here and so I'm just going to give it an absolute path and see if that fixes our problem okay and so just say test data here um so that should absolutely work I'm just going to expand this here this is mock TF plan oh but it says pass in the name okay so the problem isn't that it's the fact that the mock data isn't named it's because the thing is you could download two different mocks right so you could have a state that is successful and failed and you'd probably want to rename them to say passed or failed so we don't necessarily have that so I think my original thing was correct where we had this test data and so here we just have to make sure we match the name so mock TF uh V2 is fine here okay again I don't understand the difference between all these files I definitely saw the documentation to explain them all so you know that might be something we want to read through here um so this is looking a little bit better so mock TF plan hyphen version 2 Sentinel so that is correct but the director it doesn't like the direct it's going in that test again so again I can just go back up one more layer here okay there we go and it's passing so um yeah so that's all it takes to um do that again I think if we were to commit this to our code I don't think that these run so we can go like so we can just go add it and see what happens so we'll say get add git commit hyphen M validation and again I don't know if this mock data should be allowed to be committed into the Repository because we have a TF State file here right okay I don't know but I'm going to just do a push here to see what happens but again I I really think that we're probably not supposed to have it in there um so what we'll do is go back to our terraform i o sign in and we'll just see what happens here I mean we don't expect the uh this to pass because it's still using the wrong instance type but I was just curious to see if the mock would appear in any way here I don't think it does I think that's just something that you have to do uh beforehand and I think what you'd have is you'd have a pull request and the pull request could be used to run those unit tests because that's basically what it is okay so yeah that's exactly what I thought would happen but down below here it says the mock block is not supported so I wonder what you would do so if you can't have mocks in the file what would you do locally because you need to I guess the thing is is that the mock file the sentinel.hcl file would not be in this fold so you might have the central HCL file in your main repository for mocking right and if you committed it wouldn't run it because the policy set would actually be in another repository so I think that's how it's supposed to work so yeah I think really we want to have policy sets in their own repository like completely away from there because we're seeing we're running into a lot of problems but we pretty much accomplished what we wanted to do with Sentinel more than I thought we were going to do so that's pretty great so there you go um in terms of this we probably want to tear this down uh we do need to do something with vaults and stuff like that but I think that what we'll do is just tear this down and you know if we need to bring it back up we'll do that so I'm going to go to destruction here Ed we're gonna go ahead and just destroy the plan here okay and we're all now in good shape and so um yeah I'll see you in the next part okay but we're all done here for for Sentinel all right uh actually I guess we're not gone here just yet because it looks like our destroy run failed uh because we didn't pass here so um that is a bit of a problem so we'll have to go to the variables I guess it's a good Edge case to know about but um we'll go back and change this to a micro even though it's going to just tear it down anyway you know so we'll go and type in micro save variable and we'll go back to our runs we'll start a new plan we're sorry we'll go to settings here destruction cue the plan I'm just curious the community plan we'll redirect a new up output here okay cool um so I'm just going to type in VCS terraform again here okay and so this should work and I will come back and just confirm this with you okay so I'll be back in a second all right so the real reason we can't uh get rid of this is because we have those darn mocks in there so um what I'm going to do is go over to our signal file here um up to I mean we don't use this one so I'm gonna go ahead and delete that it's not even something that's going to happen and we need to update our HCL file here okay and I'm assuming that this supports uh this okay because this is not how we should be doing this um and here we go get add git commit hyphen m INE or change okay and this is going to trigger a run here but I really wanted to destroy so we'll just give it a moment there to start so we can kill it um did I not push oh maybe I didn't push and we'll go back here there's that run I'm going to go in here I want to stop it uh cancel run okay and so now what I'll do is go over to the here destroy this we'll run that okay we'll destroy that and I will again see if this is working and I'll see you back here in a moment okay all right so I just wanted to confirm there that everything is uh destroyed so we're all in good shape okay so uh yeah so we're actually done Sentinel now for real okay bye all right let's take a look here at hashicor Packer so it's a developer tool to provision a build image that will be stored in a repository using a build image before you deploy provides you with the following immutable infrastructure your VMS and your Fleet are all onetoone in configuration faster deploys for multiple servers after each build earlier detection and intervention of package changes or deprecationable technology so let's take a look at what that workflow would look like so you'd have your code you commit it to your CI CD Pipeline and within that pipeline it would start up a build server running uh Packer and that would trigger a build image so you'd use a something to provision it with so you could use ansible or a variety of different provisioners within Packer and then Packer would then store it somewhere so maybe this would be Amazon machine image because you're deploying to AWS and then what you do is reference that image in your terraform code and when you provision it would get deployed to your CSP so this would be AWS in this case so packet configurations is a machine uh Packer configuration configures the machine via oops hey it's Andrew Brown from exam Pro and we are taking a look at hashicorp Packers so Packer is a developer tool to provision a build image that will be stored in a repository so using a build image before you deploy it's going to give you the following benefits immutable infrastructure your VMS and your Fleet are all onetoone configuration faster deploys for multiple servers after each build earlier detection intervention of package changes or deprecation volt technology let's take a look at what that workflow would look like so first we'd have GitHub or or your git so wherever you commit your changes and from there that would trigger a CI CD Pipeline with within that cicd pipeline it would trigger a virtual machine so or a build server that's a running Packer and so that would trigger the build image process from there Packer would use some kind of provisioner like ansible to provision the image and then when it was done and and it was all good it would store it summer like in Amazon machine image once it is stored wherever you want it to go then in terraform you would just reference it using like a data source and then from there you could provision your resource okay so Packer configures a machine via a packer template and yes I know the E is missing um so sorry about that but Packer templates use the hashicorp configuration language HCL which we saw if you remember way earlier in the course and that's what we're going to review next is what that Packer template file looks like okay all right so Packer configures a machine or container via a packer template file and Packer template uses the hashic configuration language HCL so that's why it looks very familiar to terraform and a variety of other languages we've been looking at in this course and so what this file is doing is provisioning a virtual machine on AWS so here you can see that it's a TT micro and the US West 2 region that it's probably going to be installing Apache since it's named httpd and the way it's going to be created is via an EBS volumes let's talk about kind of the components that we're looking at here so when you have a packer template file you have to specify a source and this says where and what kind of image we are trying to build so the source is Amazon EBS so it's looking for an Ami image or it's being backed by that EBS volume there okay in this case it's an EBS back to Ami the image will be stored directly in AWS under the ec2 images and so we have the build step so the build allows us to provide configuration scripts Packers supports a wide range your provisioners so we have shaft puppet ansible power Powershell bash salt whatever you want basically has it and the post provisioners runs after the image is built so they can be used to upload artifacts or repackage them all right and the place where this is going to be stored is going to be on Amis okay so there you go let's look at how we actually integrate terraform and Packer together in terms of a CI CD workflow we kind of saw this in uh that overall graphic in the first uh Packer slide let's just kind of look at the code okay so to integrate Packer there are two steps they're going to build the image so Packer is not a service but a development tool so you need to manually run Packer or automate the building of images with a build server running Packer then the second part of that is referencing the image so once an image is built you can reference reference the image as a data source so if it's stored in Abus Ami we're going to just Source it from there and the way we select it is what we can do is say okay get us the most recent one and use this regular expression and the owner has to be us and and those kind of parameters to decide how to choose that image so that's all there is to it you're just using data sources to reference them after they've already been built okay hey this is Andrew Brown from exam Pro and we are taking a look at using Packer with terraform and mostly it's just about just using Packer uh and so what I want to accomplish here is to generate on an image and store that onto Amazon machine images and then load that into a terraform file or like reference it as a data source so I've never done this before but it should be fun and we'll figure this out so what we're first going to need to do is download Packer so notice in the top right corner we make your way to Packer however you want to and we'll go ahead and download and this one is for Windows it's a binary but we are going to be using Linux we've done this so many times these three two commands so I'm not going to do that again here but if you have yet to do so you can go and run that and so I'm going to go ahead and install Packer and once Packer is installed I will come back here and we will get to it okay all right so after a short little weight there Packer is installed and so what I want to do is go into my Packer folder here and I'm just going to run Packer and see what we get and so we have Packer build console fix format a knit so install missing plugins uh it looks kind of similar to terraform build images from a template that sounds kind of interesting so I think the first thing we're going to need to do is Define ourselves a template file so I remember I researched one and and put one in my uh slides here so let's make our way over there and see if we can kind of just like use our notes here as a reference so going down to this Packer file let's go ahead and just write one here uh I don't say what the name of the Packer file is that would probably help but I believe that they're just named as dot HCL files so what I'm going to do is go into this here and make a new file and we're going to say um uh I guess apache.htl since we are already very familiar with how to install Apache that seems like the easiest way to do it and again this is going to be very similar looking to terraform because it's you know all based on HCL so we'll do a type string and we are going to need some kind of default Ami so we can go grab the one we've been using all along here um I think we specified it we can just go back to count Count's always a good one to go to um so I just want to go and grab where is it um count count count where are you you see anybody see it I'm blanking today so I'm just going to grab it from AWS it's not a big deal I'm just pulling up AWS here we're going to make our way over to ec2 and we're going to go ahead and launch ourselves a new server actually I could probably grab it from the old one no I'll launch a new one just in case you don't see anything there that might not be fair I'm going to go ahead and grab that Ami ID and I'll just move that off screen here for a moment and we're going to place in that am ID because I assume we want one to override then we're going to say locals uh app name I think the example I wrote here is is Apache because that is what Apache is is httpd not sure how they came up with that name but uh that's how they call it so we need to provide ourselves a source so we're going to do Amazon EBS httpdd notice that like the source is not called Data it's just called Source if we go over to the documentation here just what I want to show you here Docs if it ever loads come on docs you can do it so down below here or on the left hand side we have sources so I believe if we were to go over to here and go over to Amazon Ami someone says Amazon MI overview uh builders ec2 EBS I'm just trying to find the same kind of information that it has there a it's not really doing what I want but anyway I know that this code is correct even though we can't seem to find this out probably just go type in Packer EBS Amazon EBS I really like to always refer to the documentation when I can here so it does say it's a builder Amazon abs source down below here we go all right so yeah um I don't understand this uh this Builder flag as of yet but uh we'll work our way through here and figure it out okay so I'm gonna go back and pull up my vs code here and we're gonna put curlies here and so we need our Mi name here so my server uh dollar sign local app name instance type T2 micro region this is going to be us East one Source Ami this is going to be the variable we set up above amiid then we are going to do SSH username that's going to be ec2 user that's the default that AWS always has uc2 user we can do some tags here not really necessary but it's good to probably give it a name right so we'll just say name Apache server and actually we could probably just do local.app name maybe instead and then we have our build step here so we're going to specify our sources and we're going to do source.amazon ebs.htpd and we're going to do provisioner Pro visioner shell and then we want to provide a script I think we can we can actually do it in line if we didn't want to do a script there but we know our script works so maybe we should just stick to that so I'm just going to call this userdata.sh because we already have that somewhere before so we'll do Post process we don't need a post processor so we just want to run that script um I believe we have that in our terraform workflow we go over there to our workflow wherever it is might also be under modules if we go into our module here didn't we create one there called user data oh that's a yaml file uh okay um I mean that's not a big deal we could probably just okay so we're not going to do it that way all right um if we're not going to do it this way we probably can provide inline things we don't probably have to do script equals so what I'm going to do is go back to the terraform documentation here or Packer documentation I should say and what I want to do is look at provisioners we're going to go look at Shell so it has this inline step and I assume that this is going to run in a sequential order so inline array of strings okay so what we will do here is we will type in inline and I've done this like a thousand times but I'm just going to go Google it Apache install AWS tutorial there's probably like one on the AWS website for it for like user data and this is pretty much has some of it here I was just kind of looking for these commands like the Yum install and the pseudosystem start so we're going to go ahead and grab that and then we're going to go and grab the next few lines here because we want to start and enable what's the three things that we need to do not complicated at all and so what I'm going to do is type in Packer build and see what happens now I didn't specify Ava's credentials or anything like that I assume it would pick up the defaults and we're going to go to the top here so it looks like we have to provide the template name so maybe we'll do Apache HCL here and it says error parsing Json invalid character V for the beginning of the value oh so it has to be pkr.hcl okay I'm really liking the user experience of the developer experience for these clis they're really good at telling us what's wrong with them PKR HCL if there's like a default file I don't know what it should be called uh so we got a bunch of Errors which is fine unsupported argument locals an argument locals is not expected here did you mean to define a Local's Block it's because I put an equals in front of it supposed to just be this not that we were really using locals for much here and looks like it is provisioning found in Ami it's going to use that as the The Source One creating a temporary key pair authorizing to Port 22 uh name Packer Builder so I don't know if this uses I don't think it does but I don't know if it uses Amazon uh but because there's like ec2 Builder image there might be a way to use it with um Packer directly but I'm not sure how to do that it's going to go through here I'm just going to see to make sure it's not running a pipeline here is it image Pipelines no okay that's good but what I will do is go over to my ec2 here and what I want to go do okay so Packer Builders is running as a virtual machine so it's actually um uh going to spin up a VM and then bake the Ami that way which seems a lot better um we'll go over to our Mis and see when that happens there um let's just unlock another those that red stuff doesn't look good seems like it didn't really matter so the thing like AWS has an entire pipeline for ec2 image Builder but it does cost money to run where I kind of feel like if all Packer is doing is spinning up a virtual machine temporarily to make that image that's going to be a lot more cost effective I mean we could go look up what the cost is to use ec2 image Builder while we're watching this Builder can't seem to type today uh it's pricing I just want to know the pricing happy free oh is it there's a no cost I could have swore there was a cost for this no cost image Builders offered at no cost other than the cost of the underlying AWS resource I think the thing is that it's that when you use um ec2 image Builder you have to use of a particular size you know if you don't really use AWS anymore in Azure gcp I can understand why this is not much of an interest but I'm pretty sure if I go here that the size that you get for the image what size of each image does ec2 image Builder use because I remember it was like really really large un like unreasonably large and that was the cost involved in it can't find it today it's not a big deal but waiting for the Ami to become ready so if we go over to our Amis here and give us a refresh we can see that it is spinning so it is provisioning that Ami while that is going on what we can do is just start setting up the next part of this so um Within our Packer here we can say new file and I'm going to say main.tf I'm going to go as per usual and grab some default codes from our account example which is for right here okay copy that we're going to go all the way down to the ground here and going to go into the main TF here paste that on in and we probably want to keep the public IP around we actually don't really care but I'm putting it in any way I'm going to take out the tags oh I want to leave the name in so I'll just say like server packer okay server Apache packer and uh this is the thing that we want to replace out this all looks fine so this is what we need to figure out is our Ami here it's probably going to come in as a data source it has to come in as a data source and I'm pretty sure that's what I wrote in our documentation here so yeah AWS Ami example things like that so what we're going to do is Type in AWS am I Packer image and we'll just Define that data source so AWS Ami Packer image and we have executable users executable users equals self I'm not saying I know what all these options do but like you just go to the documentation you grab them you got something that works true name regex okay and so we would do something like start with the little carrot character and what did we name this this starts with uh my server hyphen probably would have helped if we named it with like something like packer in the name but I think that's fine um we might as well might might as well go the full name here and say httpd because that's technically what it's going to be we might want to match for more values here so I'm not sure I guess like we do that because sometimes it's like three digits or whatever but I don't know what Packer is going to do if we keep pushing additional ones I'm not really familiar with with that so we'll just say owner's equals self and so now that should be all set up to go as that is running it finished so that's all good we're going to say terraform init and here it says block definition must have a block content Eliminator so we have a small problem here it looks correct to me uh this is not right okay we'll see if we can knit this now whether our build image works properly I don't know it'd be really good to write like some tests for it I imagine that there is some kind of way to do that um I guess it'd be like the postprocessor scripts maybe you'd want to do that where you'd want to use that as a means for testing I'm not really sure obviously different provisioners might have that kind of stuff built in so you know it might be just part of the provisioning tool you can use so it initialized here we're going to do a terraform plan because I'm hoping that it might complain about the data AWS Ami here if it does not exist properly and it did so your Curry return no results please change your search criteria and try again so however I wrote this is probably not correct so I will just take this out here try this data a to the same at Packer no results so what I'll do is go over to bc2 here and actually that's the only name that's here for the Ami so I guess I could just go here and grab the name but maybe that's not the problem oh no that might be fine so we'll just do this name reg X okay so let's go look up data AWS Ami ex couple users most recent name regex owners maybe we can just do like a filter here a regex to apply to an analyst returned by AWS this allows for more advanced filtering not supported by the AWS API this filtering is done locally on the AWS what returns so I suppose that is good but like I just need it to work so I'm going to try the filter instead and I'm actually going to put literally the name in my server httpd I'm going to take out the regex assuming that is the problem owners itself executable users itself um please change the criteria I don't know what executable users users actually does let's maybe look up what that is limit search to users with explicit launch permissions on the image is that required no so let's just take that out if more than one there isn't so let's just take that out for the time being who's the owner of this we're the owner right we have to be honors this IP address that must be us or sorry not IP but like our account number so I mean that should be fine incorrect attribute value type oh okay so that was fine so we'll do dot ID but you know if you're doing this like if you wanted a continuous pipeline you'd probably want to get the most recent and have a better regex um and so I'll do a terraform apply Auto approve and see if this works one thing I kind of Wonder is like with Packer how would you do like a versioning because that's what I'm not certain about so like I'm just kind of like looking through here and seeing what they would do for that I would imagine that uh you're probably supposed to like increment it and have it part of the name nothing's really speaking to me there but you know like the idea is that you want to have things like zero zero zero zero one zero two zero three but I imagine like there's some pragmatic way maybe there's like a builtin function or something that we can do to do that or what you do is you just have a variable probably that's actually what you probably do is you'd have like variable like version right string and then you probably set it and it would come through that way like you you'd set it over here it says our server has finished provisioning let's go C and take see if that actually worked we'll go up to ec2 instances here that is running copy that paste that in um the security group doesn't have any open ports right so it probably did work it's just we didn't create a security group with us so there are no open ports for us to check I'm not worried about this I don't care if it actually did work or not because we more or less followed all the steps there but I believe the reason it's not working like there is just because we don't have a security group but I just don't want to fiddle with that and put it into a state so that it does not match so anyway we're all done here so I'm going to do a terraform apply Auto approve destroy so there we go we accomplished that with Packer that pretty much wraps up all the main followons for the course so hopefully that was a lot of fun um yeah we'll just continue on here all right so let's talk about terraforming console because you're going to hear console mentioned throughout the documentation and you might think it's critical to the exam but it's not so I just want to make sure we understand its relation to terraform so console is a service networking platform which provides service Discovery so central registry for services in the network it allows for direct communication so no single point of failure via load balancers it has a service mesh so managing Network traffic between Services a communication layer on top of your container application so think middleware it has application configuration capabilities so console is useful when you have a micro service or a service oriented architecture with hundreds of thousands of services so these are containerized apps or workloads and so the way console integrates with terraform is in the following ways it is a remote back end because console has a key value store and this is where you could store the state of your terraform files then also there's a console provider because you can use terraform to set up some things in console for you but there's not much else outside of that okay all right we're taking a look here at hashicor Vault so vault is a tool for securing accessing secrets from multiple secret data stores vault is deployed to a server where a vault admin can directly manage secrets and we have operators also known as developers can access Secrets via an API Vault provides a unified interface to any secret such as AWS Secrets console key values Google Cloud KMS Azure service principles it provides tights access control so just in time which is reducing surface attacks based on a range of time and just enough privilege so reducing surface attack by providing at least permissive permissions we can also record a detailed audit log so we have tamper evidence so this is kind of the idea of our little hash Decor fault stack so you have your secrets engines these are thirdparty services or sorry cloud services that actually store the secrets you have your Vault cluster which act as the adapter to your resources and the resources which are going to access them so again vault is deploy to Virtual machines in a cluster and vaults can be backed up via snapshot so if you do provision them and you're worried about the state of those vaults you can definitely save those for later okay let's take a look here at terraform and Vault how they would work together so when a developer is working with terraform and they need to deploy a provider like AWS they will need AWS credentials so AWS credentials are longlived meaning a user generates a key in secret and they are usable until they are deleted so the Abus credentials reside on the developers local machine and so the machine is at risk of being compromised by malicious actors looking to steal this credentials so if we could provide credentials just in time expires or credentials after a short amount of time so shortlived we could reduce the attack surface area of the local machine and so this is where Vault comes in because Vault can be used to inject shortlived Secrets at the time of terraform apply so imagine you are you are the developer and you run your terraform apply at that point in time it's going to inject the secrets the way we do that is via data sources data source is always the way we get data into our terraform configuration file but let's look at that in Greater detail in the next slide here okay foreign let's take a look at how this Vault injection via data source works so a vault server is provisioned a vault engine is configured like AWS Secrets engine The Vault will create a machine user for AWS fault will generate a shortlived AWS credential for that machine user thought we'll manage and apply database policy and then within our terraform we can provide a data source to the Vault so that's what we're doing we're saying Vault Ibis access credentials and we are getting the output from our terraform remote State admin outputs backend and then from there we can reference them into AWS okay so when terraform applies run it will pull shortlived credentials to be used used for the scope of the duration of the current run every time you run apply you will get a new short lived credentials which is the whole point of the shortlived idea okay hey this is Andrew Brown from exam Pro and we are taking a look at Vault um and so the idea here is that we want to be able to inject secrets from vault in a secure manner for our local developer environments I really kind of wish I included this screenshot or this graphic within my slides I just found it as as of now because it does really represent all the types of secret engines and capabilities of Vault one thing in particular I wasn't aware of is that it has its own key value store so that's what we're going to be using we're going to keep it really simple here um but the first thing we're going to have to do is go ahead and install Vault so just down below I have a link here that I found and we'll go down below and it's not shouldn't be too hard to install so uh we are on Linux today I mean I'm on a Windows machine but I'm using Linux um as the windows subsystem there and so this is where we're going to start and grab our stuff so making my way over to vs code whoops um and I'm just trying to think should we use this for a new project probably so I'm going to just CD out here and I'm going to make my way into uh vault which apparently I don't have a folder for so I'm going to just go here and we're going to uh if I reveal and explore and we'll make a new one 200 volts okay and so we'll start first install something then we'll set up a project all right so um let's go through the installation process here okay so we'll go do a curl which is our first step and that's just going to grab the gpg I think we already have it because we did it for probably the the CLI 4 terraform there but we'll just do it again there it doesn't hurt I'll add the repository again I think we already did this when we installed the CLI in the beginning of this course but we'll let it go again there I remember this takes a little bit of time so we'll just wait here for a bit all right so now we need to run the last command which is actually going to go ahead and install Vault here for us we'll just go ahead and grab that line and I'm going to go ahead and paste that on in I'm not sure if I grabbed that properly we'll try that one more time it uh I got my consoles on response so there we go okay just happens when I um I stop and start recording it just for some reason times out like that so I'll go ahead and hit enter there and that will go ahead and install our vaults and then after that we're going to have to start getting it running um there is again a tutorial to inject secrets I'm not going to stick one to one with it because it does come with a repository but I find that it is a little bit more work than we want to do here we just want to kind of get a basic example working and I just want to make our lives a little bit easier so I'm just going to modify it as we go here but uh yeah we'll just wait for that to install I'll see you back here in a moment okay all right so after a short little weight here I believe that vault is installed let's find out if it works so we'll type in Vault once I get the responsiveness back from my console here just giving it a moment great nope nope there we go Vault and so vault is there and so what we can do is start it up in a developer mode and I remember from here they actually had some pretty good instructions on the starting of that so um like the way they do this project and I have the repo here is that they um they provision Vault with a bunch of different things so I think they're using like S3 here and that would probably be a really common use case for this but I really want to simplify and I don't want to have to provision that terraform and crossreference the stuff so we're just going to simplify that so I'm just looking for the command to start fault because I saw a good one here that was like vaults um ah here it is right there so Vault server hyphen dab that starts in the developer mode Dev root token ID there's something about like ceiling or unsealing stuff I don't know what that means but I assume that's a way of securing the Vault but we're going to go ahead ahead and just type that in so we're going to go Vault server hyphen Dev hyphen Dev root token ID and obviously you wouldn't want to do this for your production they call there's education I'm just going to stick with that to make our lives a bit easier and so what that's going to do is start up a vault server it is running on this port here so I suppose we should export that or or keep this because we'll probably have to reference it somehow notice we have this like unsealed key so the unsealed key and root token are displayed Below in case you want to seal or reauthenticate um developments should not be used in production so what I'm going to do is I'm just going to create a uh uh a readme file in our vault here so we'll just say new file read me because I just want to dump this stuff of course you know you should not share these with anybody but I just don't want to forget these while we're working through this so I'm going to go ahead and copy that and we will go ahead and save that and so what I want to do now oops did we lose our terminal did I close it okay I must have closed it so which one were we working in second third one which is it fourth okay it's the third one so don't be like me close out your old one so I'm just gonna close out these old ones so I'm less confused there we go and so it says that it started on this address here so I'm gonna go copy that address and we're going to open this up you can do everything via the CLI uh I just want to copy that there but they have a nice UI which is nice and so this is where we're going to put that token education and drop that down so there are some other options where there's a lot of options for authenticating but token is obviously the easiest probably not the most secure because the way we wrote it and notice that we have a couple things preinstalled so we have cubbyhole which is a per token private secret storage and then we have key value secret storage again I don't know much about these because this isn't a um this isn't a course on vault it's just kind of us showing a basic integration and more focus on the terraform side but here is where we can create our secrets we can of course use the CLI to do that and I think they showed in the getting started here and we don't have to do it this way I'd rather do it through your eye but you do like vault key key V put and then you put the name of your secret so here's secret forward slash hello and then the key and the value that's where the store I assume that this would go to the well this would specify we're using here so what we'll do is we'll go over here and we'll create ourselves a new secret because we're going to want to store something here so we want the path for the secret this is pretty common with um if you've ever used parameter store you have a path I don't know if it starts with a forward slash may not end in a forward slash probably can begin with it so I'm going to say AWS key because we'll do the key in the secret right so here oh okay cool cool so we can do forward slash AWS and then down below I would just add another one maybe I got to add each one at a time so we'll say key and I'll actually go grab our proper ones um oh I should have stopped that I'm going to start that up again okay and we'll add a plus there because everything lives in memory when you're in the dev one so you really don't want to shut that down or you'll have to redo all this from scratch so what I'm going to do is just go back here and drag this down a little bit more okay and I'm just gonna go see if I have to relog in because I might have messed this all up yes I do so we'll type in education so we really don't want to stop running that server during the duration of this follow along okay and so we'll go back into secret here create a secret forward slash AWS uh what do you want is it Json no I don't think it matters if we can add two keys that's all that matters to me and so what I'm going to do is cat out credentials of course this is not the secure way of doing it so you know again don't show people these things and so I want this and I probably should match the name I'm gonna like type in the whole darn thing and we'll grab this oops I want to see that value is correct good we're going to add another one here this is going to be our axis Secrets or axis secret access key I really don't like how those have been named and we'll go ahead and grab on this and um I mean we don't really need to really store the region here but why not because we're doing all the rest to here we might as well just throw them all in here for fun and uh here it says maximum number of versions I don't need anything beyond one because we're not going to be updating these um require check and set so rights will only be allowed if the keys current version matches the version specified in the cas parameter not sure what that means maybe just like you're passing something along when you are doing something but uh I think this is all good you know what I'm just going to leave that back to 10 just in case I've made a mistake and we have to go debug that I'm going to go hit save and so there are secrets um and so what we want to do is be able to access them and so maybe this is our opportunity to learn the CLI here a bit so I have it pulled up on the left hand side and so what I'm going to do is type in vault key V get and we'll do AWS I don't know if we can start with the forward slash there I'm going to hit enter and um the server gave an HTTP response to an https client so I'm not sure why that's a problem because like I mean I understand that it started up in HT http but I mean I'm in development so you know what else am I going to really do here let's see if I can just scroll up here and if there's anything else um hmm and I could have swore that it installed a private key as we were doing this because I remember seeing that there was like a private key I could have swore there was one something but private key so I'm not sure what the problem is here I'll be back in a moment and I will resolve it okay so the suggestion I'm getting is that we need to um export a couple of environment variables so see here where it writes this so we say you need to set the following so maybe we will go through and set those so I'll go grab that there but here's the thing is like how do I run that because these are I think these are like not the same so I mean I can't run it over here can I I don't think so uh well I guess if we're doing key Vault value there maybe we can um still no good what if we export The Vault token I think we said it was education here um let's do Vault status so yeah I'm not sure how we're going to do it that way I mean it's not a really big deal because I don't think that we have to access it that way but notice here like as I was reading here you know they're just saying down below oh we had to set this and that so I'm not really sure what I would do here so the output is like this run these commands and it should do it again the error message can be similar to different problems so that or maybe I'm just specifying the key incorrectly and that's why it doesn't like it so um let's just type in Vault and see what we have here so Vault QV maybe if we do like a list can we get a list list the secrets um AWS AWS clear I'm not sure what parameter it wants there uh let's go look it up so let's say like tariff or was it vault key V list option seems to want another parameter here I'm going to scroll on down so Secret forward slash my app um folders are suffixed with the forward slash the input must be a folder list of a file will not return um do I have to put Secret in front of it Secret AWS no so I don't know what the issue is there I just would have been nice to use it via the CLI but the thing is is that again we don't need to use it that way we just need to um you know set it and and get it but I thought it would be fun to kind of see a lie there so now that we have those set the way we're going to extract out these values is by using a data source and so what I want to do is just create a new local project and I think we'd like to always pull from our account repo here so I'm going to go all the way up to here and I'm going to go grab the main and I'm just going to copy the contents there we're going to go all the way down to the ground and we're going to make a new main TF file here we're gonna go paste that on in and uh we just want my server we don't need an output it's fine this is all fine this is all fine but uh the one thing is we don't want to use our particular provider there so what I'm going to do um is I'm going to just open up our credentials file there and I'm just going to change this to something else like other so that it doesn't load that profile there okay I just take these out of here um I think we can leave that alone and I think that's everything so what I want to do now we don't need that count we'll get rid of that count we'll go check out the documentation or the code base here because it gives us a bit of an idea how we need to implement this we'll go over the operator we'll go over to the main and so they're setting some variables here like name region path things like that but again we want to grab it from The Source there actually crossreferencing it like this other they provision the admin and grabbing it that way I don't want to do it that way I wanted to use just the data source like this so I'm not sure how that's going to work so let's go look that up okay so here it says read it was credentials from an AWS secret back end and I'm not trying to do that I'm just trying to read them from the key vaults okay so we probably want faults generic secret would this be from Key vault this resource is primarily intended to be used with the generic secret back end but it is also compatible with any Vault endpoint that is provided but is that the key value one that's not clear to me um so I think it is so let's see if we can figure that out here so I'm just going to move that off screen here and we're going to add ourselves the data source so I guess we're really not following the other tutorial at all because it we literally have to use a different um key value there a so we'll say secrets and this is going to be like AWS credentials Maybe there's creds they don't have to worry about spelling mistakes and we need to specify a path notice it always starts with like secret I don't know if we always have to start it with secret so I will just say AWS here and there might be some additional options I'm just scrolling through to hear that so you have paths so this is the fully the full logical path from which to request the data to read data from generic secret back in Mountain Vault by default this should be prefix with secret forward slash so we do have to do that reading from other back ends as data sources possible consult each backend documentation to see which endpoint supports the get version version of the secret to read we only have a single version so we don't have to specify that so technically that should be correct so what we will want to do now in our provider is specify all those options so again I'm just going back to the source code this is off screen but we need to set the region the access key and the secret key here and so this is going to be data and it's going to be Vault generic Secret and I guess it would be AWS and then we're accessing those things like region and so I'm going to go ahead and just copy that really quickly and we will go over back to our vault here because the names are over here so go grab that paste that in there we'll go grab that paste that in there and I'm just going to double check to make sure if I've made any mistakes this one it's showing it from the admin so it goes admin outputs but we're not outputting from anything we're just grabbing it from uh the Vault there so maybe what we need to do is just kind of review how this generic fault works so this does Data Vault generic and then it does data and then Square braces so I wonder if we always have to do data so for example The Vault there is a a key named auth token the value is a token that we need to keep Secret but yeah I don't understand is this a Json object or just a way of referencing it because it doesn't specify that so we'll just give it a try nothing hurts with trying right so we'll say data and this might again might not be the right way I don't know if it's single or doubles there it's doubles so I just wonder if that was like the one case where it's doubles okay and we will do this and so I think that that should maybe work don't know what I'm wondering is if I if I live with a forward slash would it have considered that and or is it now double but I don't think so because look here it looks like it's stripped it out because it just says AWS here so we got a secret since just AWS almost looks like there's a space in the front of it eh but it's not there so maybe there's not this is kind of like a little glitch so um we need to go and CD into this directory here and we just need to do a terraforming knit that's kind of interesting because like we haven't set up the provider I guess it's not going to happen until we actually use the provider so maybe it's not an issue just yet I'm curious to see if it pulls any kind of modules in for the vault generic Secret so we'll just give it a moment there to initialize okay so after there we can see that it did actually add vault in so it must be ready to take it from there um I'm going to do a terraform plan here and you know I'm going to just change this to like my server with vaults now remember it's not going to be able to pull from the um from our local credentials because we're not setting a profile and we overroad the default just in case so here it's saying a resource a data resource Vault generic secret AWS has not been declared in the root module um it hasn't I mean it looks like I did no maybe I typed it wrong so we'll go here I don't think it matters but I'll just put it above okay and I'm just going to double check to make sure nope it matches oh because it's eight of his creds that's fair um you didn't use the option o that's fine so my question will be will this correctly provision because we will not know until we uh use this right here I suppose if we try to use a data source for AWS that would probably also indicate whether it's working or not so maybe we should try doing that we do like data AWS VPC and then we just do like ID equals here because that would have to use the credentials right and so we'll just go well that's actually it's not specifying any of the the VPC here so maybe maybe we won't do that because it's just too much work um so what I'll do here is I'm going to do a terraform apply Auto approve and Let's cross our fingers and hope this works and while that is running what I'm going to do is just pull up my AWS environment here and apparently I'm not logged in so that'll give me a bit of time here to kind of catch up here while this is provisioning there and so it looks like it actually provisioned the server and if that's the case that means that our secrets are being pulled correctly right so if we go over to ec2 here and we go and check out this instance it is running so it worked um if we just want to do a sanity check to make sure it absolutely is working we can just introduce a bug into this so maybe we go here and we just say uh um I guess we'd have to make a new version create a new version and what I'm going to do is purposely introduce some mistakes so we're just going to put like an at sign here on the end we're going to save that and I'm going to make a minor change like Nano and so what I'm expecting is for this to fail let's see if it fails on the plan I don't think it will give it a fail in the apply and it does okay so the plan would tell us whether it didn't work or not so that clearly uh clearly means it absolutely is pulling from it especially when we're doing the plan so um I want to go back to our file there I just kind of lost the folder I'm just looking for it the I got too many um too many Chrome windows open here there it is okay so we'll go back here and we'll I wonder if we can just revert back to the previous version um see I don't know if I would delete there I don't want to I don't want to jinx it so I'm just going to go here and take out that at sign we're going to go ahead and save that and so that should be updated we're going to do terraform plan great and so what I want to do is just tear this down so we'll say terraform apply Auto approve and Destroy okay and while that is destroying I'm pretty pretty confident that's going to work I'm going to stop my Vault server oh wait is that going to still work did I get the credentials in time oh no I I made a big booboo okay so um I I Killed My Vault server before I was supposed to that's really embarrassing um anyway that's not a big deal because I kind of wanted to stop the server anyway but I want to go back into our it was credentials there and turn that back to defaults and I wanted to go back up here and just flip that back so that we can get rid of the server right so I don't want to kind of lose these for the tutorial so I'm just going to go here and just comment those out for a second profile defaults oops region Us East one and um we'll do that again that's embarrassing okay and I'm just going to preemptively I'm not going to save this file but I'm just going to do this for now um it's still trying to connect oh boy so just put these back in here because it's set to the Vault can I do a terraform refresh probably not no probably not what if I do a terraforming net because I did change like I was using Vault so maybe I just have to do that to fix that problem and let's try destroy again that was a big booboo on my part eh nope okay so let's go back over here and start it up again and I'm pretty sure there's like a way to back up your vaults like there's probably some kind of like snapshot or something um again I'm not that uh deep into it so I cannot tell you if that's the case um so I guess we'll just go back here and remake our secrets because it shouldn't have persisted right if it did I'd be so happy nope okay AWS we'll leave 10 in there and then we'll just have to copy all this stuff over again because of my bonehead mistake there so we have region which is Us East one U.S east one here and uh go over here well at least you know what to do if that happens to you okay I don't need the uh equal sign there go ahead and add this one okay and what we're going to do is go ahead and save that and we'll just quit out of that we'll do a terraform plan since we know that that will pick it up right and uh we'll do terraform apply Auto approve destroy Okay so again this only applies to development but uh yeah don't kill your Vault server before you're done destroying okay so I'll see you back here in a moment all right so that infrastructure is destroyed we can go back to here and then we can stop our server and for your benefit I'm just going to bring back these in here so you don't have to worry about that and uh yeah we uh we accomplished Vault for injections now you might say well how would you do this with terraform Cloud well the thing is is that terraform Cloud already uses uh Vault Under the Hood when you store your environment variables there and the idea is that uh I suppose you don't need to pull them in from all those sources but I think that was one of my my questions I had when I was talking to one of the DA's which was like okay it's great that terraform cloud has um uh you know uses behind the scenes but what if I want that to live somewhere else but maybe that's not really necessary um because I don't know but yeah that's it so we're all done with vaults hey this is Andrew Brown from exam Pro and we are taking a look at Atlantis which is an open source developer tool to automate terraform pull requests which you can find at run atlantis.io so the idea is once this is installed on your GitHub and you merge a pull request then it's going to go ahead and do a terraform apply so this would be a way for you to do um get Ops or to automate your uh your infrastructure as code and the interesting thing is that hashicorp actually maintains this project they didn't originally build it was built by two people from another company and it wasn't that they did not want to use terraform Cloud which can do this but at the time I think they had a hard time at the company getting procurement because it was a very large company and so they had to build something so they built out this thing and anyway these two people end up getting hired by hashicorp and hashicorp maintains this project which is really nice because it is an alternative for terraform Cloud um but uh yeah that's all foreign let's take a look at cdk for terraform and so to understand this we need to First understand what is cdk so AWS Cloud development kit is an imperative infrastructure as code tool with sdks for your favorite language so the idea is that you can use something like typescript python Java csharp go and Ruby Ruby's definitely there that's the language I like to use AWS cdk is intended only for AWS Cloud resources because cdk generates a cloud formation so CFN templates this is known as synthesizing and uses that for IAC but cdk for terraform is a standalone project by hashicorp that allows you to use cdk but instead of CFN templates it generates out it's going to generate terraform templates and so basically anything terraform can do you can do it through cdk and that allows you to do interesting things like use cdk to provision Azure resources so that is very interesting uh and a great development that I think that they're doing hey this is Andrew Brown from exam Pro and we are taking a look at grunt work which is a software company that builds devops tools that extends or leverages terraform the reason we're talking about them is that they produce a couple of very popular open source tools that work with terraform and you're going to see their name because um uh you know the cofounders there are very active in the community uh Jim has wrote in a really good book on terraform so you know it's no surprise that uh they are present but it's worth giving them a mention so you know who they are uh the first thing I want to mention is the infrastructure is the code Library so these are a bunch of reusable battle tested production ready infrastructure code for AWS gcp Azure um and so they have some free ones there and some paid ones there then there's teragram so a thin wrapper that provides extra tools for keeping your configurations dry we have terror tests a testing framework for infrastructure provisioned with terraform we have grunt work Landing zones for AWS this is a multicount security on AWS we have grunt work pipelines and then there's the grunt work reference architecture and so where we're going to focus our attention in here is just on Terra Grunt and Terra tasks because those are things I think are essential to know if you are using terraform because you know you'll run into those use cases where you might want to use them okay all right let's take a look here at teragram so this is a thin wrapper for terraform that provides extra tools for keeping your configuration dry working with multiple terraform modules managing remote State and this is accessible to tariff Terra grunt.gruntwork.io so the idea here is the concept of don't repeat yourself so it's a programming methodology to abstract repeated code into functions and modules or libraries and often in isolate files to reduce code complexity efforts and errors so the way that works is that you'll see these HCL files which are the Terra grunt code and they're actually named Terra grant.hcl and that's what's going to be used to abstract away or dry up your terraform files so here is an example of Terror run now Terra Grant does a lot of different things and you're going to find its use when you actually use terraform and practice and you run into these limitations in terraform and you go and I wish there was a way around it integrine like almost always solves that and so one example is being able to generate rate Dynamic providers and I don't mean like Dynamic values here in the sense that there's that Dynamic value feature of terraform but I just mean the fact that at the time of this it's very hard to inject or to write out providers so they have this generate function that allows you to get around that another really interesting thing is that Terra grunt supports better granular literary for modules by reducing lots of boilerplate uh the way they do this is is that you are referencing your terraform files uh via the source here okay so you're not including your modules within your code you're just referencing them and then you pass along their inputs and this is going to be very important when we look at wanting to write unit tests for your infrastructure because when you learn about how you test IAC you have to really break things down into smaller parts and if you have a lot of friction there it's going to make your team not want to adopt that or it's going to make that process really slow but again this is more like at scale or when you hit these kind of requirements okay oh all right let's take a look here at testing and terraform and so what we have here on the left hand side is our usual um pyramid that tells us the layers of testing and so I kind of want to walk through the layers there and talk about a bit of the tools that are available to the terraform community and you know the reason why we want to move up the pyramid here to get uh better tests and then we'll take a look at Terra test so at the bottom we have static analysis and this is where you test your code without deploying and you've been doing it all along when you do terraform validate terraform plan or you're using Sentinel you're doing static analysis and that just means that we're testing you know like the composition or the the shape of our code or like its outputs to what it says it should be doing okay but you can't catch all your problems there and that's where you move on to unit testing and unit testing uh you know traditionally means like in programming to test like a particular function its inputs and its outputs it's a little bit harder for infrastructure because um you know you have to have it connected to other things so it the definite sessions a little bit warped but the idea here and specifically with terraform is you're just testing a single module and that really says like okay well you need to really Pare down that module to be of the small scope and that's where you end up dividing your modules into very small units of work and so for tooling here we got Terra Test Kitchen uh terraform and inspec um and so uh yeah that's where that motivation came with um you know Terra Grande the last thing saying okay let's split them up into smaller stuff uh we have integration testing this is pretty much just using multiple um uh modules together you know so you say okay well I know that this Lambda function is working but do I know it works in conjunction with this sqsq or something like that then you have endtoend testing and this is where you're testing basically like business use cases so it's not just saying okay from a technical perspective but from a business use case do or the customer use case do we meet the requirements here uh and this uh is very hard because what you have to actually do is set up a persistent test Network environment but once you have one you're going to be really good shape one example of a test environment and it is paid but groundwork has their own called the grunt work reference architecture uh but you know if you had to do it without that you'd have to just roll your own kind of environment so you know if you do want a good breakdown of all these different kinds uh you know Jim from grunt work has a complete talk on automated testing for infrastructure as a code I strongly recommend it because it really gives you a better scope than what I can cover here um but let's just go take a quick look at Terra test so Terra test allows you to perform unit tests and integration tests on your infrastructure it tests your infrastructure by temporarily deploying it validating the results then tearing down the test environment and so here's an example of what a a test function would look like in Terror test it is written in golang I know golang can be very hard to use but you don't need to know much about it if you you pretty much copy and paste it and just kind of tweak the values to get the result you want so you know hopefully that helps to tell you how you would test in terraform and you know that about Terra test okay
