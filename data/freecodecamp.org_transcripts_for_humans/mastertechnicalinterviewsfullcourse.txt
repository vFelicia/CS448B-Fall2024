With timestamps:

00:00 - Master technical interviews this course
00:02 - breaks down complex topics like data
00:05 - structures algorithms and interview
00:07 - strategies into easily digestible
00:10 - content par teaches this course he is an
00:13 - experienced engineer and he will teach
00:15 - you both the fundamentals and help you
00:18 - understand Advanced coding patterns and
00:20 - common pitfalls to avoid Hello friends
00:23 - hope you are having a fantastic day
00:24 - today I want to welcome you to a journey
00:27 - that will transform the way you approach
00:29 - technical interviews and my aim is to
00:31 - help you become significantly better at
00:33 - technical interviews I'm here to be your
00:36 - guide as someone who has walked through
00:38 - this path and knows the twist and turns
00:40 - every step of the way together we will
00:42 - unlock the secrets of technical
00:44 - interviews from the basics of bigo
00:46 - notation to the integrities of data
00:48 - structure and algorithms so before we
00:50 - move forward let me introduce myself my
00:52 - name is par and I'm based in Canada I
00:55 - have been in the tech industry for close
00:56 - to 10 years and I have worked at
00:58 - companies like Microsoft NOK Kia and
01:00 - Royal Bank of Canada I'm a big believer
01:02 - in technology and love Building
01:04 - Solutions and softwares last year I
01:07 - became dad of twin daughters and on the
01:09 - side I also run my own YouTube channel
01:11 - called destination Fang where I teach
01:13 - about data structure and algorithm
01:15 - related problems so now let's just get
01:17 - started with this
01:20 - course so first let's try to understand
01:23 - that what is going to be the format at
01:25 - any typical interview for any tech
01:27 - company usually during the interview
01:29 - process you can expect somewhere between
01:31 - 3 to six rounds of interviews and they
01:33 - are usually broken down into three main
01:35 - categories first category is the
01:37 - behavioral interview and the purpose of
01:39 - the behavioral interview is to check
01:42 - what kind of person you are are you a
01:44 - good culture fit do you work well with
01:46 - different people do you work well under
01:48 - pressure can you raise your concerns if
01:50 - you have any conflict between two people
01:52 - how can you handle that and these are
01:55 - the things companies wants to know
01:56 - before they hire you second type of
01:58 - interviews are system design design
02:00 - interviews and they are usually more
02:02 - emphasized for more senior level folks
02:05 - and if you are someone with like 10
02:06 - years or 20 years of experience that
02:08 - would be one of the most significant
02:10 - chunk of importance for any job that you
02:12 - are applying to but that doesn't mean
02:15 - that uh they are not going to be there
02:16 - for junior level folks there would still
02:19 - be some emphasis but not as great and
02:22 - usually those interviews tend to be
02:24 - open-ended where they ask you questions
02:26 - like if you have to build your own
02:27 - Twitter or your own Google how would you
02:29 - do that what are the things you would
02:31 - consider and then the conversation Dives
02:33 - deep into the vast sea of software
02:36 - Solutions and the third category is
02:39 - technical interviews which is going to
02:40 - be our main point of focus for now from
02:43 - now on T typically a technical interview
02:46 - lasts for somewhere between 45 to 60
02:48 - Minutes during this time interviewer
02:51 - usually ask one to two questions and
02:53 - once you have the solution in place they
02:55 - would judge the solution if solution
02:57 - seems to be good enough or fine they
03:00 - will ask you to write a preliminary code
03:02 - for that in any language of your choice
03:05 - but the thing is it's not quite as
03:07 - simple as it sounds there are lot of
03:10 - moving Parts in any technical interview
03:12 - usually a technical interview has a
03:15 - problem statement and that problem
03:16 - statement usually refers to some real
03:19 - life scenario and that problem statement
03:22 - needs to be solved using a computer
03:25 - program that we we are trying to build
03:27 - for that you would need two things for
03:29 - sure number one is data structures and
03:31 - data structure is nothing but a way to
03:33 - store the data inside the memory of the
03:35 - computer there are lot of different
03:37 - methods available uh so you will need to
03:40 - take care of data structure second thing
03:42 - is algorithm and algorithm is nothing
03:45 - but a set of instructions that a
03:47 - computer needs to follow in order to
03:49 - come up with a solution trust me there
03:51 - are lot of data structures and lot of
03:52 - algorithms and lot of different
03:54 - techniques that you have to understand
03:55 - but when you combine these two you get
03:58 - somewhat a solution but how would you
04:00 - know that whether your solution is a
04:02 - good solution or a bad one for that we
04:04 - actually need some way to measure that
04:07 - how effective our solution is and in
04:09 - order to do that in computer system we
04:11 - use something called Big O So Big O is a
04:14 - notion where we compute what is going to
04:17 - be the worst case scenario time and
04:19 - space complexity and depending on those
04:23 - results we make the decision that
04:25 - whether the solution or the option of
04:27 - solutions we have which one is the best
04:30 - and most optimal one and which one are
04:32 - suboptimal options so before we start
04:34 - going deeper into the realm of data
04:36 - structure and algorithm let's first
04:38 - understand that what are the measurement
04:40 - units how do we actually understand that
04:43 - this is a good
04:47 - solution okay so let's talk about big O
04:50 - big O is typically defined by a big O
04:53 - and in the bracket we are going to Mark
04:56 - the complexity of Any Given algorithm
04:58 - now usually when when we talk about Big
05:00 - O we are usually talking about two items
05:02 - and those two items are time complexity
05:05 - and space complexity and remember the
05:08 - purpose of Big O is to identify the
05:11 - efficiency of Any Given algorithm now uh
05:14 - there are couple of ways to measure the
05:17 - efficiency of Any Given algorithm but
05:19 - the most important consideration that we
05:21 - are always going to have is that we are
05:23 - going to consider the worst case
05:25 - scenario that in the worst case how
05:28 - efficiently our algorithm is going to
05:30 - perform on top of that we are also going
05:33 - to check that for any given algorithm
05:35 - let's say that currently we are dealing
05:37 - with five number of inputs uh so in with
05:40 - five number of inputs what is the
05:42 - efficiency now let's say that the number
05:44 - of inputs grow to 5 million in this case
05:48 - what is going to be the efficiency and
05:50 - that becomes the true measure of Any
05:52 - Given algorithm and there is also one
05:54 - more condition consideration while
05:56 - calculating big hope is that we don't
05:58 - care about Hardware or software
06:01 - abilities for any given particular
06:03 - solution so we are assuming that our
06:05 - algorithm is currently running on the
06:07 - best hardware or software available so
06:09 - that's why we eliminate those outside of
06:12 - our control entities and only we focus
06:14 - on the efficiency part of our algorithm
06:17 - so first uh and foremost time or space
06:21 - complexity is Big O of one now currently
06:24 - I'm only going to talk about time
06:26 - complexity because that is sort of like
06:28 - more important of course space
06:29 - complexity is also important but time
06:31 - complexity is usually where you will
06:33 - have to improve whenever you are
06:34 - building your solution now in terms of
06:37 - that uh I'm going to currently show you
06:39 - five different examples of different Big
06:41 - O's uh for all I'm explaining it using
06:44 - the time complexity but throughout this
06:47 - course we are going to be solving bunch
06:49 - of different technical interview
06:50 - problems and where I'm also going to
06:53 - explain you the what space and time
06:54 - complexity we are using and how do we
06:56 - calculate that so don't worry about
06:58 - anything we are we are going to cover
07:00 - all the topics uh for that is for sure
07:02 - now first and foremost the Big O
07:05 - notation is a constant time Big O
07:07 - notation that is usually defined by like
07:10 - like this where in the middle there is a
07:11 - big one present this simply means that
07:14 - the current operation does not depend on
07:17 - the given input size and uh one clear
07:20 - example if you want to put it in the
07:22 - real world is that let's say that you
07:24 - are currently shopping in some uh Plaza
07:27 - some shopping cart or some somewhere
07:29 - like that
07:29 - and you can see in front of you that uh
07:32 - you have the option to pick any item
07:34 - from the five available items so since
07:37 - you have the option to see these items
07:40 - and you are being asked that hey uh in
07:42 - the bracket number three there is a
07:43 - banana that you need to pick you can
07:45 - just directly walk in and pick that
07:47 - banana up and in this case you don't
07:49 - have to think anything you just B there
07:52 - fetch that data and you completed your
07:54 - operation so same way instead of five
07:57 - items let's say if there are 500 items
07:59 - and we are assuming that your eye vision
08:01 - is the best you are able to see
08:02 - everything so in that case uh even if
08:05 - the value is located at 499 place and I
08:07 - tell you that go and grab that you can
08:09 - still be able to go and grab that within
08:11 - the constant time so timing would not be
08:14 - impacted based on the growth of number
08:16 - of input size so in this kind of
08:18 - scenario we can consider that operation
08:21 - to have a constant time now next
08:23 - operation is bigo of end time now what
08:26 - does bigo of end time means is that the
08:29 - number of inputs as the number of input
08:31 - size grows the more time it takes for us
08:34 - to complete that task and the
08:36 - progression is essentially linear so
08:39 - let's say that uh this is the graph
08:41 - where we can see that the number of
08:43 - input size and the time it takes to
08:44 - complete the line is going to be a
08:47 - straight line that they are in
08:49 - proportion to each other and if we have
08:51 - to consider an example for uh this kind
08:54 - of scenario let's assume that currently
08:56 - uh you have 10 items that that are
08:59 - already placed in 10 different pots and
09:03 - now these pots they are covered with
09:04 - different lids and you have no way for
09:07 - know that what is currently present in
09:09 - each of the pot so if I ask you that uh
09:12 - from these 10 pots I want you to find a
09:15 - banana so in this case what would be
09:17 - your approach well you will definitely
09:19 - go to the first place and in the first
09:21 - place you will try to check that uh if
09:23 - the banana is present uh currently
09:25 - banana is not present here so you will
09:27 - check the next spot you will check the
09:29 - the next part again you will check the
09:30 - next Sport and eventually you would find
09:32 - a place where has a banana and you would
09:34 - return that in that scenario let's say
09:37 - that instead of 10 values if I put like
09:40 - 1 million pots then essentially you will
09:43 - have to open 1 million pots in order to
09:45 - find the banana so there is a direct
09:47 - correlation between the given input and
09:50 - the size so that's why this would be a
09:53 - good example for bigo of n time
09:56 - complexity where our solution is direct
09:59 - ly in correlation with the given number
10:01 - of input size next one is actually big
10:03 - of log n and this is a logarithmic time
10:06 - operation this is quite un interesting
10:10 - to understand what it happens in this
10:13 - type of operation is that with every
10:16 - step you make you essentially eliminate
10:19 - 50% of given input and same thing
10:22 - happens when you make the next step and
10:24 - same thing happens when you make the ne
10:26 - Next Step so say initially uh uh this is
10:30 - your entire input size when you make the
10:32 - first change the change is going to
10:34 - enable you to essentially get rid of
10:37 - this entire part so now you are only
10:39 - dealing with these number of input sizes
10:42 - with the next step you took again you
10:44 - eliminated half of them so you get rid
10:46 - of this part and then now you're only
10:48 - dealing with this much portion of the
10:50 - given input and same way if you keep on
10:52 - going and going and going eventually you
10:54 - would be able to find the solution you
10:56 - are looking for if we have to consider a
10:58 - practical example for this type of
11:00 - logarithmic time I told you that hey
11:04 - this is the phone book now in this phone
11:06 - book I want you to find the number of
11:08 - Patrick the plumber now for this in
11:11 - order to find the number of Patrick the
11:12 - plumber what will you do is you will
11:14 - open the book somewhere from the middle
11:17 - and let's say that you open uh at where
11:20 - character or alphabet m in the middle
11:22 - portion so essentially you can eliminate
11:25 - that from a to M this Patrick the
11:27 - plumber is not going to be present so
11:29 - you will essentially get rid of all of
11:31 - these pages so let's say that uh it's a
11:33 - 500 page phone book you essentially
11:35 - eliminated 250 pages in just one go and
11:38 - in the next iteration you only have to
11:40 - check for n to Z and again you try to
11:43 - open some middle page and then you would
11:45 - be end up with this a smaller subset
11:47 - size so with every increment of step you
11:51 - take you get almost 50% closer to your
11:55 - uh given answer and you are eliminating
11:57 - 50% of input sizes in that so that is
12:00 - defined as bigo of log n or logarithmic
12:03 - n time complexity well usually the
12:06 - constant time complexity is the fastest
12:08 - and second fastest is the logarithmic
12:10 - time complexity now the next sequence is
12:13 - going to be the combination of two items
12:16 - and that is going to be bigo of n log n
12:18 - so bigo of n log n is an operation where
12:23 - essentially let's say that this is the
12:24 - current input you are given initially
12:27 - first of all you are you will have to
12:28 - itate over all of these places in the
12:31 - input but once you do that then for the
12:34 - next set of instructions you only need
12:36 - to do it in the logarithmic time so for
12:38 - the next operation you are essentially
12:40 - again eliminating half of the given
12:42 - inputs with every single change you are
12:44 - trying to make and this is quite an
12:47 - interesting approach one of the good
12:49 - examples for this one could be that
12:50 - let's say that you are playing a card
12:52 - game with your friends now initially in
12:55 - your card game in your hand you receive
12:57 - five random cards but you are are a
12:59 - person who wants who likes to do things
13:01 - in more of like a sorted array or sorted
13:04 - way so your approach is that hey uh
13:07 - since the these are random values let me
13:09 - put them in a correct sequence so for
13:11 - that what would be your approach your
13:13 - approach would be that first you are
13:15 - going to put down the value number two
13:17 - and you will treat that two is the
13:18 - minimum number and this is the new sort
13:20 - of sequence that you are trying to make
13:22 - now in this case currently since this is
13:24 - empty you can put two anywhere so you
13:26 - will put two in the first place now you
13:28 - need to put value number 7 now again you
13:30 - know that 7 is greater than two so you
13:33 - put 7 on the right side of two now you
13:36 - need to put value number three you
13:38 - already know that all the values that
13:39 - are currently present in this array they
13:41 - are already going to be sorted because
13:43 - one by one you are sorting them now in
13:45 - order to put this value number three you
13:47 - will have to find the location where it
13:49 - should be the ideal location and ideal
13:51 - location would be between two and 7 the
13:54 - three should fall between two and 7 so
13:56 - what would you do you would first try to
13:58 - find the middle Point Middle Point is
13:59 - currently let's say uh 2 and 7 so you
14:03 - pick seven so which means you know that
14:04 - three needs to be on the left side of
14:06 - seven so again there is only one element
14:07 - so you know that three needs to be in
14:09 - the middle so once again you adjust the
14:12 - values and you are going to put three
14:14 - over here and then seven over here again
14:16 - you have value number one so once again
14:18 - you will have to make adjustments or you
14:19 - will have to identify that one needs to
14:21 - go in the beginning and again you are
14:23 - going to use the binary search approach
14:25 - the same approach we were using in the
14:27 - previous uh
14:29 - application or previous phone book
14:31 - example that we saw so let me just
14:33 - redraw all of this and this would be the
14:36 - sequence and now you have value number
14:37 - five you need to put so once again you
14:39 - will try to find the middle value and
14:41 - you find that the correct location for
14:42 - five is going to be this place and you
14:44 - will again going to put it over here so
14:47 - now after this after completing this
14:50 - example if you see the solution you
14:53 - currently have is actually now sorted so
14:56 - let's calculate the the complex for this
14:59 - well you had to go through each and
15:01 - every input in order to receive or
15:04 - complete the steps so definitely you did
15:06 - n work but even for every single element
15:10 - once you did or process that you also
15:13 - had to do some work in order to put it
15:14 - in the sorted place so for that you are
15:17 - not doing the N work you are actually
15:19 - doing the log n work so in this case the
15:22 - Big O is actually going to be Big O of n
15:25 - log n so these are typically the four
15:28 - four most popular Big O's um in terms of
15:31 - like any architect any technical
15:33 - interviews that you have to consider but
15:35 - apart from that we also have to worry
15:38 - about bigo of N squ and bigo of n cub
15:42 - and bigo of uh 2 to the power n and then
15:46 - there is the worst one and that is bigo
15:48 - of n factorial so let me just quickly
15:51 - explain these four of four of you for
15:53 - this so suppose in this case uh big of n
15:56 - Square you already you can already guess
15:57 - that for every every single element we
15:59 - will have to work with all the other
16:01 - elements so let's say that currently I
16:03 - have this value number X now I want to
16:06 - check that in the remaining portion does
16:08 - X is present or not so one by one I will
16:11 - have to check all of these values and
16:13 - since it is not present so then I can
16:16 - say that okay for in order to process
16:19 - one element I had to process all the
16:21 - other elements so essentially I did B of
16:23 - n Square work so or B of n cross n work
16:27 - and same would apply for all the
16:29 - subsequent examples as well and uh that
16:32 - is how we reach big of n Square time
16:34 - complexity this is also uh referred to
16:37 - as quadratic time complexity then for
16:39 - big of n Cube again you are adding one
16:42 - more n over here so let's say that you
16:45 - this step needs to be done as part of
16:48 - one of your algorithm and then once you
16:50 - get the process of this you again have
16:52 - to do n work or compare with all of
16:55 - these values and once again repeat the
16:57 - same exercise in this case case uh the
16:59 - time complexity is going to be big of n
17:01 - Cub now this one big of 2 to the^ N is a
17:05 - Time complexity where at every single
17:07 - location you have the option to process
17:09 - two values and among these two options
17:12 - depending on which option you took your
17:15 - complete computation path would change
17:17 - so in these kinds of scenario the
17:20 - typical uh calculation is going to be
17:22 - big of 2 to the power n uh and the last
17:26 - one is the factorial time complexity so
17:28 - factorial time complexity is where the
17:31 - input sizes grow exponentially with the
17:35 - increase in the number of input size and
17:37 - this is actually a huge restriction
17:38 - because these two time complexities are
17:41 - so bad that they can't even function and
17:44 - one of the very good example for this
17:46 - big of 2 to the power nend time
17:47 - complexity is actually traveling
17:49 - salesman problem um if you want go ahead
17:52 - and search about that it's a quite an
17:53 - interesting problem to study that gives
17:55 - you quite lot of idea on how
17:58 - computational how there are limitations
18:00 - to computations as well uh for the N
18:03 - factorial one of the very good example
18:04 - is to find permutations and combination
18:07 - for all the given input sizes that we
18:09 - are trying to deal with so this is what
18:12 - you need to understand regarding the
18:15 - time and space complexity and uh now
18:17 - let's try to start understanding that
18:20 - what are the data
18:23 - structures now we are going to talk
18:25 - about data structures the most important
18:28 - topic that you have to understand for
18:30 - any technical interview or computer
18:31 - science in general now when we talk
18:33 - about data structures data structure is
18:35 - nothing but a way for us to store the
18:37 - data inside the computer's memory so
18:40 - let's assume that these are all the
18:41 - memory blocks of Any Given computer so
18:44 - we have the option to store the data in
18:46 - like an entirely common box like this or
18:50 - we have the option to save the data
18:52 - where one node is present over here the
18:54 - connecting node is present somewhere
18:56 - over here its next connecting node is
18:57 - present some somewhere over here and so
18:59 - on and so forth we also have the option
19:02 - where we know the option of that this is
19:04 - one node and then this node can only be
19:06 - accessed through these two nodes or
19:08 - something like that and then there are
19:10 - also quite connected nodes as well plus
19:13 - there are some structures data
19:14 - structures like q and stack so data
19:17 - structures in itself is a huge and
19:19 - complex topic now let's try to break
19:22 - this down into categories so it helps us
19:25 - understand what type of data structures
19:27 - are and how they operate so if we have
19:30 - to create the categorization data
19:32 - structures are typically two types of
19:34 - data structures mainly first one is a
19:36 - primitive data structure and second one
19:38 - is a non-primitive data structure now
19:41 - these primitive data structures are the
19:43 - smallest unit of data that we can store
19:45 - inside the computer and this is your
19:48 - integer value or your character value or
19:51 - Boolean value typically all the values
19:53 - that we usually use in any compiler
19:56 - language so to store store the raw bits
19:59 - of data in the computer and lucky for us
20:03 - or that this is too preliminary that it
20:05 - is not considered for any technical
20:07 - interview but you must have encountered
20:10 - this if you are a programming person so
20:13 - now the next category is the
20:15 - nonprimitive types of data structure and
20:17 - that two has further
20:19 - subcategorization so in the
20:21 - non-primitive type of data structure the
20:23 - first of characterization is the linear
20:25 - data structure and second one is the
20:28 - nonlinear data structure now for the
20:30 - linear as the name suggest linear data
20:32 - structure defines as the data that are
20:35 - typically stored in a sequence or in a
20:38 - linear fashion so this includes
20:41 - array then uh link list
20:45 - stack and Q so these are the major
20:49 - categorization of the linear data
20:52 - structure now when we talk about
20:53 - nonlinear data structure this is
20:56 - essentially the data structure that that
20:58 - is in a weird shape uh where the
21:01 - connection or the hierarchy between any
21:04 - two nodes is quite deep and quite
21:07 - significant and this has some of the
21:10 - most interesting properties actually so
21:12 - that is uh trees and graphs now for the
21:16 - apart from trees and graphs uh there are
21:19 - many subtypes in each one of them and
21:22 - when we get to those topics we will
21:24 - discuss it in the in more detail but for
21:26 - now understand that these are the to
21:28 - generic subcategories now the there is
21:30 - also third unofficial category which is
21:33 - really important for us to learn and
21:34 - that is Hash based data structure so
21:37 - hash based data structure typically
21:39 - includes uh hash map and hash set and
21:42 - these will these are very powerful tools
21:45 - at our disposal that we can actually
21:47 - achieve quite an interesting uh output
21:50 - with these data structure so without any
21:53 - further Ado let's just get started with
21:55 - the linear data structure
22:00 - now arrays are a not only they are a
22:03 - linear data structure but arrays tend to
22:06 - be fixed in the size and there are some
22:08 - properties associated with arrays so
22:10 - first let's understand that typically uh
22:14 - let's assume that if this is the whole
22:16 - memory of the computer then if whenever
22:19 - we Define an array we have to give it a
22:21 - sum size uh and the size of an array
22:25 - usually tends to stay within a fixed
22:27 - Contin ous memory space inside any given
22:30 - computer as well so let's say that we
22:32 - create an array with the size five then
22:36 - there would be a memory space like this
22:38 - with five consecutive memory spaces are
22:41 - going to be located next to each other
22:44 - and this is how it would be represented
22:47 - in the memory now since we already know
22:50 - that there are going to be five
22:51 - continuous bits of memory uh one good
22:54 - thing about array is that if you want to
22:56 - access any element even from anywhere in
22:59 - the middle you can access it quite
23:01 - quickly and very fast so uh let me give
23:04 - you an example for that suppose uh this
23:07 - uh this is currently the whole chunk of
23:09 - memory for the given array now how would
23:12 - the fast access work is that we already
23:14 - know that what would be the initial
23:16 - location of this position in the array
23:18 - inside our memory I'm giving you like a
23:20 - detailed explanation to help you
23:23 - understand how does arrays work so let's
23:25 - say that the computer memory address
23:27 - like this portion is referred to as 100
23:30 - and for the Simplicity we are expecting
23:32 - that all of these nodes they are 100 in
23:35 - the size which means that this if this
23:38 - memory location is 100 then this
23:40 - location is at 200 then this location is
23:42 - at 300 and so on and so forth so let's
23:45 - say that uh I currently wanted to access
23:48 - the fourth element that is this element
23:50 - present inside the given array so do I
23:53 - have to do any additional research or
23:55 - any additional extra effort no why why
23:58 - because I can quickly come over here I
24:00 - can see that okay this starts at Value
24:01 - number 100 I want to access the fourth
24:04 - element which means fourth element has
24:06 - to be present at Lo value memory value
24:09 - number 400 and that we can access quite
24:12 - quickly so just because we learn about
24:15 - the bigo time complexity the retrival
24:18 - bigo time complexity for array is
24:19 - actually going to be bigo of one or
24:21 - constant and how typically we access the
24:24 - elements inside the array uh we use
24:27 - something called indexing so arrays
24:29 - let's say that this is an array of size
24:31 - five because we can store five elements
24:33 - in this usually it is going to be
24:35 - indexed starting with value number 0o so
24:37 - 0 1 2 3 and 4 this is going to this is
24:41 - how array is going to be represented and
24:43 - you can store any item in the array you
24:46 - can store either character or you can
24:48 - store integer you can store Boolean you
24:50 - can store even some some of your
24:52 - separate classes you created all the
24:54 - things you can store inside the array
24:56 - but uh in order order to access that you
24:58 - will have to use these index values so
25:01 - let's say that I put down the values as
25:03 - uh 5 15 3 1 and two now if I want to
25:08 - access that what is located on index
25:10 - number two or position number three why
25:13 - position number three because this is
25:14 - the first element this is second and
25:16 - this is third element and we have an
25:18 - index starting from zero so why am I
25:20 - pointing you out this because this tends
25:23 - to be a tricky thing and many times you
25:25 - would encounter in technical interviews
25:27 - that they would say that hey I have an
25:28 - array that starts with index one so that
25:31 - this is like a common trap that you
25:33 - sometimes can find yourself into so
25:35 - that's why make sure that what type of
25:37 - index you are using 99% of cases you are
25:40 - going to be using an array starting with
25:41 - index number
25:43 - zero now let's just go back uh again so
25:46 - in this case uh let's say that the name
25:49 - of this array is a so if I want to
25:51 - access this third element all I need to
25:53 - do is try to fetch the value that is
25:56 - located and on the second index position
25:58 - and this would give us the answer as
26:00 - value number three so retrival inside
26:03 - the array is quite quickly now let's see
26:05 - that what are the different operations
26:07 - we we have the ability to perform inside
26:09 - an array let's say that currently we
26:11 - have a blank array present and what are
26:13 - the things we can do so let's mark down
26:16 - the index values now first operation we
26:18 - can do is we have the ability to insert
26:20 - element inside inside any given array
26:23 - now inserting an element is actually
26:25 - quite quick uh because if you know know
26:28 - which index location you are inserting
26:30 - element into you can actually do it in
26:31 - within constant time so B go of one time
26:34 - you can insert element you can insert
26:36 - element to the end of the array you can
26:37 - insert element to the beginning of the
26:39 - array all you need to know is the index
26:41 - value and that's it now second thing we
26:43 - can do is we can retrive the G the
26:46 - inserted array as well and retrival is
26:48 - also quite quick we we just saw so that
26:50 - is also a constant time next operation
26:53 - we can do is we can find element inside
26:56 - the given array so let's say that how
26:58 - does finding inside the given array
27:00 - would actually work and uh this is a
27:03 - question for you guys that while I
27:05 - explain try to think that what should be
27:07 - the time complexity for this one uh
27:09 - ready so let's say that currently the
27:11 - values are 5 15 3 and 1 and I ask you
27:15 - that inside this given array I want to
27:17 - find that uh value number three where it
27:19 - is located so how would you do it
27:21 - approach is going to be quite simple the
27:23 - logical explanation is going to be that
27:25 - you go to the first element if it is
27:27 - three that's it if it is not three go to
27:29 - the next element again not three go to
27:31 - the next element okay this is three then
27:33 - retri the index position and that's how
27:36 - you find it now in this case what was
27:38 - the time complexity well the answer is
27:40 - quite obvious because we had to jump
27:42 - through all the values in order to find
27:43 - the value we are looking for it was big
27:45 - of n so logically why it was big of n
27:50 - because this is unsorted array so in the
27:53 - unsorted array always if you have to
27:55 - find any element it's going going to
27:57 - take big off end time but let me show
28:00 - you a quick uh interesting thing over
28:03 - here let's assume that I currently have
28:06 - a sorted array so 1 2 3 4 5 these are
28:09 - the elements I have and now I want to
28:11 - find that whether four is present or not
28:14 - so in this case what what is going to be
28:15 - the approach since I already know that
28:18 - this is a sorted array I'm going to
28:20 - first check for the middle element and
28:22 - again I can check what element is there
28:25 - pretty quickly because retrival is Big
28:27 - go of one so that is an important
28:29 - property so in this case I can see that
28:31 - this value is three the moment I realize
28:33 - that this value is three I can say for
28:35 - certainty that four is not going to be
28:38 - anywhere left of three because all the
28:40 - valents all the elements are going to be
28:42 - less than three and we have we are
28:44 - trying to find for the value number four
28:46 - that is actually greater than three so
28:48 - we can eliminate these two or these
28:50 - three elements with a single check again
28:54 - we will try to check for the middle
28:56 - element and we find Value number four
28:57 - and we can retrive that so if the array
29:00 - is unsorted the finding is going to take
29:02 - big off end time but if the array is
29:05 - sorted then in that case the finding is
29:07 - going to take because of log log and
29:09 - time and why because the method we just
29:12 - use is actually called binary search
29:15 - where we are dividing the all the
29:17 - elements in one half or the other half
29:20 - and then we are essentially making
29:22 - judgment on which direction to choose
29:24 - and find the answer in the most optimal
29:26 - manner so finding uh takes B of end time
29:30 - next question is deletion so deletion is
29:34 - also if you know what place you wants to
29:36 - delete it only takes big off one time
29:38 - because all you need to do is just go to
29:40 - that index and get rid of that value so
29:42 - deletion is also very quick inside the
29:44 - array now we all find quite interesting
29:48 - items about array let's see that what
29:50 - are some of the drawbacks of an array
29:52 - well the number one drawback of an array
29:54 - is that it is actually a continuous
29:56 - memory size
29:57 - and it is also a fixed memory size so
30:00 - what do I mean by fixed memory size
30:02 - because initially when we are defining
30:04 - an array we actually have to Define that
30:06 - what is going to be the size of an array
30:08 - and let's say if we exceed the size of
30:10 - that array then the operation becomes
30:13 - quite expensive uh let me give you an
30:15 - example so in this case suppose the
30:17 - array is 1 2 3 4 5 these are the five
30:19 - values now we realize that in the same
30:21 - array we need to add more elements so
30:24 - what behind the scenes procedure is
30:26 - going to be that
30:27 - there will be a new array created of
30:30 - size 10 and now in this new size 10
30:33 - array first it is going to shift all of
30:35 - these elements one by one and after that
30:38 - once the shifting is done then the next
30:41 - element that you wanted to add over here
30:43 - value number six would be added over
30:45 - here so previously when we have to
30:48 - insert any element inside the given
30:50 - array that was a bigo of one operation
30:53 - the moment we exceeded the size the
30:55 - operation became bigo of n operation uh
30:59 - because we had to repeat this whole
31:01 - process and that too when we did that
31:04 - what was also another fault with that is
31:07 - that currently all of this space is
31:10 - actually unused so we we are already
31:14 - running on a very important resource
31:16 - that is our computer's memory and we are
31:18 - leaving some values unused because they
31:20 - have not been filled yet so this is one
31:23 - of the biggest issue with the arrays now
31:26 - second issue with the array is that uh
31:29 - actually if you want to find any element
31:31 - then it takes bigo of end time because
31:33 - that you have no way for to understand
31:36 - that where any particular element is
31:37 - present so this is also another issue
31:40 - with an array but apart from that if we
31:42 - have to talk about benefits of an array
31:44 - well uh there are quite a few benefits
31:47 - actually if you believe it or not number
31:49 - one it's the simplest algorithm to
31:51 - understand or simplest data structure
31:53 - number two it is actually quite uh
31:56 - useful and and quite fast uh quite fast
31:59 - means that whenever you have to retrive
32:01 - any element from any particular index
32:03 - you can actually do it quite quite
32:05 - quickly uh allocation memory allocation
32:07 - is not an issue this works really well
32:11 - with other data structures when you are
32:13 - trying to solve some complex problems so
32:16 - when we get to the points of dynamic
32:18 - programming and Matrix manipulation we
32:21 - are going to learn quite a lot about
32:22 - arrays and we are going to use lot of
32:24 - arrays in many different scenarios now
32:27 - let's try to understand that how does a
32:29 - typical array problem work with an
32:31 - example and the example we are doing is
32:33 - actually the number one problem on the
32:35 - lead code and one of the most popular uh
32:37 - interview question that is two some
32:39 - problem so what problem statement
32:41 - suggest is that suppose we are given an
32:43 - unsorted array and uh in this case we
32:46 - have five elements so let's give some
32:48 - arbitrary values of these elements and
32:51 - in this case uh we are trying to
32:53 - identify that uh the we are also given a
32:57 - sum value so let's say that sum property
32:59 - is currently given as value number 17
33:02 - now we are trying to find that find a
33:05 - pair that actually has the answer as
33:08 - value number 17 and then return its
33:11 - index position so we are know that the
33:13 - answer is actually going to be in this
33:15 - case 2 and three because these are the
33:17 - 10 + 7 but let's see that what is going
33:20 - to be the approach that we need to take
33:22 - so this will give us a very good Insight
33:25 - on how does algorithms also work and how
33:27 - does time and space complexity works so
33:30 - let's see the first approach first
33:32 - approach is going to be our Brute Force
33:34 - approach or the most preliminary basic
33:36 - approach the idea we are going to use is
33:39 - that we will take any element we will
33:42 - minus it with 17 so whatever the
33:44 - remaining element is left we will try to
33:47 - see that in the remaining array does
33:48 - that remaining element is present or not
33:51 - uh so if we are considering five so
33:54 - let's assume that five is currently part
33:56 - of this two some so which means if five
33:59 - is part of this 17 that makes 17 then
34:02 - there has to be a remaining value 12
34:04 - present inside the remaining array and
34:07 - we all know if we have to find any value
34:09 - inside the array we can do it in B go of
34:11 - end time because this is an unsorted
34:13 - array so we are going to jump through
34:15 - all of these values to find Value number
34:17 - 12 but currently 12 is not present so
34:20 - because 12 is not present we can
34:22 - consider five not to be part of the
34:24 - answer then we will go back to Value
34:26 - number three once again 17 - 3 value is
34:29 - going to be 14 so we will try to see
34:31 - that whether 14 is present again 14 is
34:33 - also not present so we will get rate of
34:35 - three again for seven So currently we
34:38 - are considering value number seven which
34:40 - means for the sum we need to have value
34:42 - number 10 present somewhere and yes 10
34:45 - is present over here so in this case we
34:47 - did find the answer as 2 and three
34:49 - because we need to return the index
34:50 - value and we can return it quite quickly
34:53 - but if I have to ask you that what is
34:55 - going to be the time time complexity or
34:58 - the Big O for this given input what
35:00 - would be the answer it's quite obvious
35:03 - for any single element we have to search
35:06 - all the remaining elements and if we do
35:09 - or consider that in the worst case
35:11 - scenario essentially the time complexity
35:13 - is going to be biger of n Square so that
35:17 - let's see that can there be a better
35:19 - approach using the array to solve this
35:21 - problem and the answer is actually yes
35:24 - there is a much better approach and
35:26 - first let me give you a slightly better
35:28 - approach right so a better approach in
35:31 - this case would be that what if for the
35:34 - given input array we decide to sort that
35:37 - and if we sort this given input array we
35:40 - will find the values to be 1 3 5 7 and
35:44 - 10 now once we have these values stored
35:47 - all we need to do is uh we need to check
35:50 - that uh whether for Value number one if
35:53 - the subsequent pair the value number 10
35:56 - n is present or not and in this case
35:59 - since originally we need to find the
36:01 - index value when we create the Sorting
36:03 - we have to create actually a new array
36:05 - so this is an important piece of
36:08 - information so just Im Just a thing so
36:10 - now if we have value number one which
36:12 - means we are trying to find the sum to
36:14 - be 17 so then uh 17 minus 1 is going to
36:19 - be 16 so 16 needs to be present so since
36:23 - this is a sorted array we can actually
36:25 - find in log n time
36:27 - that whether 16 is present or not and
36:29 - all we need to do is we need to apply
36:31 - the binary search where we first check
36:33 - the middle value So currently this value
36:35 - number five so we make sure that 16 has
36:38 - to be somewhere on the right side but
36:39 - since it is not present over here we are
36:41 - not going to bother checking same thing
36:43 - we are going to check with for the value
36:45 - number three that again for Value number
36:48 - three if that is has to be part of the
36:49 - answer we can actually try to find the
36:52 - answer in log and time so to check
36:54 - whether value number 14 is present or
36:56 - not again that is also not present for
36:58 - five value number 12 is also not present
37:01 - but when we get to Value number seven
37:03 - actually the value number 10 is present
37:05 - and we can find this in log n time so
37:08 - what do what did we did we found out
37:11 - that the correct values we need are 7
37:13 - and 10 so once we have the solution we
37:16 - again need to go back to our original
37:18 - array because we need to return the
37:20 - index values so now once again we would
37:22 - search all of these values one more time
37:25 - to see where what are the index location
37:28 - and then return the values now let's try
37:30 - to calculate the time and space
37:32 - complexity in this case so for the time
37:34 - complexity what are the operations we
37:36 - did number one operation is that for the
37:38 - given input array we actually sorted
37:40 - this so once we sorted this given input
37:43 - array uh it took us bigo of n log n time
37:47 - to sort because based on the example I
37:48 - showed you earlier plus after sorting it
37:52 - we had to iterate over all of these
37:54 - elements to find that what is is the
37:56 - subsequent or remaining element that is
37:59 - present or not and this so iterating
38:02 - over all of these elements took us B go
38:04 - of end time and uh in order to find that
38:08 - for each one of them the subsequent
38:10 - element is present or not again it took
38:12 - us beo of log n time so again we did B
38:15 - of n log n so in total we did two times
38:18 - B go of 2 * n log n but the interesting
38:23 - thing about Big O is that all the
38:25 - constant values are not considered so we
38:28 - are not going to consider big two in
38:30 - this case and we will only consider this
38:32 - to be big off and login on top of it
38:35 - once we find the correct pair we again
38:37 - had to go back to our original array to
38:40 - find the uh appropriate index values so
38:43 - for that we also did Big O of n work but
38:47 - when we are generalizing the Big O we
38:50 - only care so whenever there is a plus
38:52 - operation or the additional task
38:55 - essentially our main main component is
38:57 - still heavily going to be dependent on
38:59 - big of n login because that is greater
39:02 - than big of n so we can also ignore this
39:05 - one and the time complexity is going to
39:07 - be big go of n log n in order to
39:09 - generate this now in this case space
39:12 - complexity is also an issue why because
39:15 - we had to create an additional new array
39:17 - for the sorted property and because the
39:21 - new arrays size would be dependent on
39:24 - the original size and the original size
39:27 - we are considering the value to be n
39:29 - because of that in this case the space
39:32 - complexity is also going to be bigger of
39:33 - n so I wanted to show you this approach
39:37 - to show you that how to calculate time
39:40 - and space complexity and what are the
39:42 - considerations we need to make so I hope
39:44 - you find that uh very useful and you
39:46 - find the idea now of course this
39:49 - solution is much better than our
39:50 - previous Pro Force solution which gave
39:52 - us the result of big of n square but
39:55 - still this is not the most optimal
39:57 - approach there are still optimal
39:59 - approaches available and the optimal
40:01 - approach uh let's see that how we are
40:03 - going to deal with it well actually I
40:06 - should not be showing it to you but I'll
40:08 - just show it to you for the optimal
40:10 - approach we are actually going to use
40:11 - another data structure called hashmap
40:13 - and when we get to that point we will
40:15 - I'll explain you in much higher detail
40:18 - that what an hashmap is but for now
40:21 - consider that hashmap is a key value
40:23 - pair uh data structure that looks like
40:26 - like this where you have a key and you
40:29 - have a value and if you know the key you
40:31 - can find the value associated in
40:34 - constant time we go off one time so it's
40:36 - very quick now let's just draw back our
40:39 - uh original array so I think the values
40:42 - were 5 1 7 10 and 3 and we are trying to
40:45 - find the sum for Value number 17 now
40:48 - again the approach is going to be that
40:50 - if let's assume that five needs to be
40:53 - the part of the answer so if five has to
40:55 - be part of the answer sir we need to
40:57 - make sure that value number 12 is
40:58 - present somewhere in the remaining array
41:01 - now currently we don't want to check the
41:03 - whole remaining array because if 12 is
41:05 - present eventually we would also
41:07 - encounter 12 somewhere down the road as
41:09 - well by the time we would have already
41:11 - processed value number five so what we
41:13 - are going to do is we are first check
41:15 - that whether 12 is present inside the
41:17 - hashmap or not currently it's not
41:19 - present in the hashmap if it is not
41:21 - present in the hashmap we are going to
41:23 - add an entry of key value pair over here
41:25 - where we we will add value number five
41:27 - as the key so this value and its
41:30 - subsequent index value as its value
41:32 - because we need to return this in the
41:34 - answer now again going back currently
41:37 - value number one if one has to be part
41:39 - of the answer then value number 16 has
41:41 - to be present but currently in the
41:42 - hashmap we don't have value number 16 so
41:45 - again we are going to add one more entry
41:47 - that is value number one and oh sorry
41:49 - for this five the initial entry is going
41:51 - to be zero because its index location is
41:53 - zero so for this one the index location
41:55 - is one 1 once again for this 7 we need
41:59 - to find the value number 10 but 10 is
42:01 - not currently present inside the hashmap
42:03 - and we are able to check all of these in
42:05 - big off one time so that's a great
42:07 - benefit now we are not able to check
42:09 - this one so what we will do is we will
42:11 - actually add entry number seven over
42:13 - here with the index value of two now
42:16 - let's add one more room and now we are
42:18 - at Value number 10 so if 10 has to be
42:20 - part of the answer then 7 needs to be
42:22 - present somewhere in the array and 7 is
42:25 - already present in the Dash map because
42:26 - we have already processed that value the
42:29 - moment we realize that all we need to do
42:31 - is grab the index element of 10 that is
42:34 - value number three and grab the index
42:36 - element of value number seven that we
42:38 - can find it from the hashmap over here
42:40 - and we can return return uh 3 and two as
42:43 - the answer that this is the index pair
42:46 - that makes us the two sum possible
42:48 - inside the given array and now let's
42:51 - break down the time and space complexity
42:53 - for this solution so of course time comp
42:56 - complexity actually is very fast in this
42:58 - case because we only have to iterate
43:00 - over the given input array just once and
43:03 - we would be able to find the array so
43:05 - the time complexity is actually going to
43:06 - be dependent on big of n the given
43:09 - number of input sizes which is much
43:11 - better compared to both our Brute Force
43:13 - approach and our sorting approach now in
43:16 - terms of space
43:18 - complexity uh we actually have to create
43:20 - an additional hash map and the size of
43:22 - the hash map is actually going to be the
43:24 - size of the array maximum in the worst
43:26 - case scenario so again the space
43:28 - complexity is also going to be bigger of
43:29 - N and this is how you actually solve
43:32 - this problem so now let's quickly try to
43:35 - understand the problem statement for two
43:37 - some problem that is I just explained it
43:39 - to you and the coding solution so we
43:42 - have a Java code over here and first of
43:44 - all we have the two some method where we
43:46 - need to return the index values for both
43:48 - the positions and in the input we are
43:49 - given the num nums array and the target
43:52 - value or our two sum now first of all we
43:55 - are initializing our hash map where we
43:57 - are going to store the values of the
44:00 - subsequent values we processed inside
44:02 - the given array and also their indices
44:05 - then we are simply going to run a for
44:07 - Loop to iterate over our given array
44:09 - first of all we will try to see that
44:11 - what is the complement value that we
44:13 - need to check and then we will we can do
44:15 - that by subtracting the current array
44:17 - position minus the target value once
44:19 - that happens we check that if the
44:22 - hashmap already contains that complement
44:24 - value or not if it it contains the
44:26 - compliment value we can return the index
44:28 - positions quickly if it does not contain
44:31 - then we are going to add that value in
44:33 - our hashmap and in the end I'm just
44:35 - adding uh an illegal argument exception
44:38 - that there is no toome solution but this
44:40 - is never going to be the case because we
44:41 - are explicitly told that there is always
44:43 - going to be exactly one solution so
44:46 - let's try to run this code and this code
44:49 - runs pretty quickly let's submit this
44:51 - code and our code runs quite efficiently
44:54 - compared to a lot of other Solutions
44:59 - now let's learn about the next data
45:01 - structure that is link list Now link
45:03 - list is quite an interesting data
45:05 - structure because it's not what array
45:09 - was at all uh in the array we actually
45:13 - had all the memories being stored in a
45:15 - continuous block and the size used to be
45:18 - fixed link list is actually complete
45:20 - opposite of this let's say that this is
45:22 - currently the memory then we would have
45:24 - a link list that would look look
45:26 - somewhere something like this it would
45:27 - be sprad out all across computer and the
45:30 - nodes would be connected with each other
45:33 - where one node would know the address of
45:35 - the other node and that is how we
45:37 - actually Traverse over any given link
45:39 - list so typically link list is a dynamic
45:42 - structure well of course it is a linear
45:44 - data structure but it is also dynamic in
45:47 - nature and uh typically a link list
45:50 - looks like this where we only have the
45:51 - information of the first element that is
45:53 - present inside the link list nothing
45:55 - more than that that but if we have to go
45:58 - and reach to any particular element we
46:01 - can actually do it by going sequentially
46:04 - to from that original first element to
46:06 - the last element and we would be able to
46:08 - find that value somewhere in between so
46:10 - typically a link list would look
46:12 - something like this where you have these
46:15 - memory blocks or these nodes and the
46:18 - first node is referred as the root of
46:20 - the link list and in every single node
46:23 - there is going to be a partition and
46:25 - what this partition defines is that this
46:28 - would have the memory location of the
46:31 - next element inside the link list so
46:34 - let's assume that currently we have this
46:36 - value number five and this is located at
46:38 - memory location 100 now this particular
46:41 - block is going to have the memory
46:43 - location of this block so let's say that
46:45 - this block is currently located
46:47 - somewhere randomly at Value number 600
46:49 - so that 600 would be stored over here
46:53 - once again let's give some arbitrary
46:55 - value over here so let's say that value
46:56 - number three is the value for this node
46:59 - next element it has is it could be
47:01 - anything it could be 300 and now at 300
47:03 - memory location we have another node
47:06 - that is present with value number seven
47:09 - um and same way it has the address for
47:12 - this next element so basically the
47:15 - structure of a link list looks something
47:18 - like this where we have the first
47:20 - element that points to the next that
47:23 - points to the next and that points to
47:24 - the next and the last element actually
47:27 - points to the null value and when we see
47:29 - an element pointing to the null value
47:32 - that defines that whether the given link
47:35 - list uh where it ended basically now for
47:39 - the link list it's actually uh there are
47:42 - three different types of Link list now
47:44 - what I just showed you this is called a
47:46 - singly link list and why singly link
47:48 - list because one element knows that what
47:51 - is going to be the element after that
47:53 - but any particular element has no idea
47:56 - that what is the element before me
47:58 - because it does not have that address so
48:00 - that is why this is referred as a singly
48:02 - link list where you have the idea of
48:04 - what the single next node is going to be
48:07 - in the iteration but there is also a dou
48:10 - link list and W link list as the name
48:13 - suggest it has the idea that who is the
48:15 - previous caller and who is going to be
48:16 - the next caller so the structure is
48:19 - usually like this where you have
48:21 - additional memory slots uh where we
48:24 - store the information so something that
48:26 - looks like this and uh once again so
48:30 - let's assume that this is currently the
48:32 - root node so even for the root node now
48:34 - in this case since root node is not
48:37 - being pointed by any other node this
48:40 - address is going to be null value and
48:42 - then we will have some value being
48:44 - associated with this so let's say 10 so
48:47 - 10 11 3 1 these are the values
48:50 - associated with the link list but now
48:53 - this 10 this portion is actually going
48:55 - to to contain the address of this
48:58 - element so it has the address 300 let's
49:01 - assume and we can also assume that this
49:04 - address is 50 so this value number 50
49:07 - would actually be stored over here that
49:10 - this second node would know that who is
49:12 - the first node that is calling them so
49:16 - when this node needs to go back or
49:18 - Traverse in the reverse order it can
49:20 - also do that so when traversing in the
49:22 - reverse order uh it will look something
49:25 - like this that this would actually point
49:26 - to this address and uh same way this has
49:29 - the address over here this has this
49:31 - address and this has this address and
49:33 - this is this address and in the end we
49:35 - have this last element that actually
49:37 - points to a null value and when we see
49:39 - last element pointing to the null value
49:41 - which means that the link list has ended
49:44 - or W link list has ended and when we see
49:46 - first element pointing to the null value
49:48 - which means that the W link list
49:50 - actually started there is one more link
49:53 - list that is called a circular link list
49:55 - and in the circular link list as the
49:57 - name suggest essentially there is a
49:59 - cycle that keeps on happening and uh how
50:03 - it operates is that usually if we
50:06 - consider it's an additional extended
50:07 - version of The W link list so let's say
50:10 - that currently we have a w link list
50:11 - where uh in the normal case scenario
50:14 - this W link list would be pointing to
50:16 - the null value in the first place but
50:18 - let's assume that that is not the case
50:19 - and currently let's just give some
50:20 - arbitary values 1 2 4 7 these are the
50:23 - values right now we know that that one
50:26 - is pointing towards two and two is
50:27 - pointing towards one same way this is
50:30 - relation is already stable now
50:33 - previously in the normal link list the
50:35 - last element its next node would be a
50:37 - null value but in this case the next
50:40 - node is actually going to point back to
50:42 - the very first value and same way this
50:44 - very first node is actually going to
50:46 - point back to the last element so that
50:48 - is why there is a circle circular nature
50:51 - happening inside the link list now
50:53 - understanding this let's see that what
50:54 - are the different operations we can
50:56 - perform on any given link list and for
50:58 - reference I'm just drawing a simple
51:00 - singly link list but same would be true
51:02 - for all the W link list and circular
51:05 - link list as well and uh let's define
51:08 - some arbitary values and currently this
51:11 - one is pointing towards null and uh
51:13 - currently this is going to be the root
51:15 - of our link list so we have the option
51:18 - to add values to the link list now if we
51:21 - have to add values to the link list the
51:24 - time complexity depends on where you are
51:26 - trying to add so let's say that if you
51:28 - are trying to add the link list to the
51:30 - root element and sometimes this is also
51:32 - referred as the head of the link list as
51:33 - well so let's say that you are trying to
51:35 - add elements to the root or the head
51:37 - element of the link list it's actually
51:39 - quite simple all you need to do is that
51:42 - you will first try to go to the root
51:43 - element you would see that what is the
51:46 - current memory address for this root
51:48 - element and then you would actually
51:50 - create another node and let's mark the
51:53 - value as nine you would point point this
51:55 - nine back to this root Two element and
51:58 - that's it now you have essentially
52:00 - created a new head element or the new
52:02 - first element where this is this becomes
52:05 - the root and this is being pointed by
52:08 - this value number nine or root so in
52:11 - this case uh you only have access to the
52:14 - next element so you give the next
52:17 - element of the previous head to the new
52:19 - head and this can be done in big of one
52:21 - time constant time operation same goes
52:24 - that if if you want to add an element
52:27 - somewhere in the middle well this the
52:29 - whole procedure is actually quite simple
52:32 - let me first show you the procedure and
52:33 - then we will talk about the time
52:34 - complexity well the procedure would be
52:37 - that let's say that I want to add a node
52:39 - number seven over here so what I would
52:41 - do is that currently this four is
52:44 - pointing to the one rather than doing
52:46 - that I'm going to Mark 4 do next or the
52:49 - next element that four is pointing to to
52:51 - 7 and then 7 do next to the previous
52:55 - element that four was pointing to so the
52:57 - value number one so we would have a
52:59 - temporary variable in between but
53:00 - essentially you get the idea what I'm
53:02 - trying to say and now this process only
53:05 - took big off one time but now the tricky
53:08 - part in this case is that in order to
53:10 - reach to the four we actually have to
53:12 - first go to Value number nine and then
53:14 - through nine we would do sequential
53:16 - jumps until we reach to Value number
53:18 - four and then we would be able to make
53:20 - this changes so if we have to make the
53:23 - change somewhere in the middle uh the
53:26 - time complexity is actually big of N and
53:28 - same goes for the end as well because if
53:31 - you have to add it into the end you will
53:33 - also have to update and go to the end
53:35 - and then that would also yield the time
53:37 - complexity of big of n but now there is
53:40 - there are some slight variation
53:42 - difference where if you have a w link
53:44 - list and you wanted to add to the last
53:46 - element maybe you can do it faster if
53:47 - you already have that information stored
53:49 - or you can go in the reverse order or in
53:51 - the circular link list you can do it
53:53 - quickly in the end but that these are
53:56 - rare anomalies that you are rarely going
53:58 - to encounter now let's see that if you
54:01 - have to delete an element how does it
54:03 - would work once again deletion process
54:06 - is quite simple that all you need to do
54:08 - is that let's say I want to delete this
54:10 - value number seven so what I would do is
54:12 - currently the next node that seven is
54:14 - pointing to I would ask four to point to
54:16 - that node and that's it seven has been
54:18 - deleted because now there is no way for
54:20 - us to reach to seven and so this the
54:23 - process in itself is quite easy but
54:26 - again the same question remains that in
54:29 - order to get to the value number four we
54:31 - will have to do all of these Hops and
54:33 - get there so if we have to do some
54:36 - deletion in the start it takes big off
54:38 - one time but in the middle it takes big
54:40 - off end time now let's see that what is
54:43 - the next operation we can do and that is
54:45 - finding an element inside the link list
54:47 - once again you get the idea you can find
54:49 - the element but once again in order to
54:51 - find the element you will have to
54:52 - Traverse through all of those these
54:54 - Hoopes in order ultimately till you
54:56 - reach that element so that two is going
54:58 - to be big go of end time and once again
55:01 - uh the last one is that you can also
55:03 - modify any existing element but in order
55:06 - to do that that also takes big off end
55:08 - time so essentially all the operations
55:11 - in the link list if they are done
55:12 - somewhere in the middle or the end of
55:14 - the link list it takes big off end time
55:16 - so now the question comes that why do we
55:19 - even care about link list why should we
55:21 - use it well one of the most important
55:23 - benefit is that it it's dynamic in
55:25 - nature so it keeps on growing and
55:27 - growing you don't have to worry about
55:29 - memory allocation size allocation
55:31 - because it can find sizes anywhere so
55:34 - anywhere there is an empty block of
55:35 - memory present link list can acquire
55:38 - that put it in the memory and do it on
55:41 - top of it swapping any two elements so
55:44 - if this pointing over here we can
55:46 - actually start pointing or add couple of
55:48 - new link list and then bring them back
55:50 - and then get rid of this uh list this is
55:53 - actually quite simple and quite easy so
55:55 - in many of the branching strategies this
55:58 - is actually quite helpful that uh you
56:00 - can actually create all sorts of like
56:02 - get a branch and repos and stuff like
56:04 - that using link list on top of it uh
56:06 - many times we are going to use just like
56:09 - arrays link list in tandem with other
56:12 - data structures so we will see that when
56:14 - we get to that point now let's talk
56:17 - about uh some of the examples of how
56:19 - typically we solve any problem inside a
56:22 - link list so one of the popular very
56:24 - popular problem is that we need to find
56:27 - the middle of the link list or middle
56:28 - element of the link list so how do we
56:31 - actually do that so let's assume that we
56:33 - are currently given a singly link list
56:35 - and we don't know that what is the size
56:38 - of this link list so how do we encounter
56:40 - that what would be the middle point for
56:42 - this one so one approach is that uh it's
56:46 - the simplest approach we actually start
56:48 - at the root value or at the head of the
56:50 - link list we keep on going to the next
56:52 - element until we reach to a point where
56:54 - the next element points to a null and
56:56 - the moment we reach that we would know
56:58 - the size of the link list so in this
57:00 - case we found out that the size of Link
57:02 - list is five so middle element is going
57:04 - to be the third element then once again
57:06 - we start once again from the root and
57:08 - let me use another color and then you we
57:10 - hop back and we reach to the middle
57:12 - element and then we say that okay this
57:14 - is the middle pointer of the link list
57:16 - so this this can be one of the examples
57:18 - so what is going to be the time
57:19 - complexity well time complexity is going
57:22 - to be big of n because we have to go
57:24 - through essenti all the inputs but there
57:26 - is also another better approach where
57:29 - once again time complexity is going to
57:31 - be biger of n but in practice it is
57:33 - going to be faster and that is that
57:35 - rather than making one hop you actually
57:38 - make two hops and how to do that well
57:41 - you can actually have two pointers so
57:44 - one pointer is a fast pointer and the
57:46 - second one is a slow pointer both start
57:48 - at the same time but slow pointer makes
57:50 - one jump and fast pointer makes two
57:52 - jumps so the moment Fast Point pointer
57:55 - reaches to the end of the link list the
57:57 - middle pointer or the slow pointer has
57:59 - to be in the middle and that you can
58:00 - return as the answer so in this case the
58:02 - time complexity would be big of n
58:04 - divided by 2 so overall since 2 is the
58:07 - constant value we would still write it
58:09 - as big of n but in practice this is
58:11 - going to be much faster compared to the
58:13 - other approaches so now let's try to
58:16 - understand the middle of the linkless
58:17 - problem and as the problem statement
58:19 - states that we are given the head of a
58:21 - singly link list and we need to return
58:23 - the middle node of the link list now
58:25 - this is the Java code for that and
58:27 - typically for the link list we are
58:29 - initializing two pointers for that first
58:32 - one is known as slow and second one is
58:34 - known as fast and currently both are
58:36 - located at the very first be uh
58:38 - beginning position of the link list now
58:39 - we run a v Loop that while fast is not
58:42 - equal to null and fast. next is not
58:44 - equal to null we are going to keep on
58:46 - moving the slow pointer to one jump so
58:48 - slow will go to the slow. next or the
58:51 - next element inside the link list and
58:53 - fast would go to fast do next do next so
58:56 - it would make two jumps at a time and in
58:59 - the end the moment this Loop ends we
59:01 - would be at a position where fast is at
59:03 - the last position or the next element to
59:05 - the fast is actually the null value in
59:07 - either case so slow has to be the middle
59:10 - pointer of the link list and we can
59:12 - actually return that so let's try to run
59:14 - this code and our solution works
59:16 - perfectly fine so let's submit this and
59:19 - our code runs with 100% efficiency so
59:22 - this is pretty good and uh all the code
59:24 - that I'm showing you would be posted in
59:26 - a gith up public repo so the link is
59:28 - going to be in the description so you
59:29 - would be able to check it out from
59:33 - there now let's see another data
59:35 - structure that is a
59:37 - stack now stack is once again very
59:41 - similar to an array or link list it's a
59:44 - linear data structure but uh the stack
59:47 - has a very specific property and that
59:50 - specific property is actually that stack
59:52 - is something like this uh you can
59:54 - consider it as like a test tube um in
59:57 - any lab or any sort of thing or a stack
60:00 - of plates this would be like a good
60:02 - example to understand what stack is
60:05 - where the value where you first store
60:08 - sto gets stored at the very bottom once
60:11 - that value is filled then the next value
60:13 - when you have to put in that would
60:15 - become at like the bottom to the uh
60:18 - second place and it will keep on going
60:21 - now when you have to take things out you
60:24 - will always take things out that are
60:26 - currently at the very top because you
60:29 - cannot reach to the bottom element
60:30 - because they are already Behind These
60:33 - memory lines so in order to reach to the
60:35 - bottom elements you will actually have
60:37 - to go through one by one for all the
60:39 - values so let's see this an example
60:41 - let's say that currently our stack is
60:42 - empty we are trying to fill in some
60:44 - values so let's say that we put down
60:46 - value number one first so one has to go
60:48 - at the very bottom now the we have we
60:51 - are putting value number two then three
60:52 - then four then five and then six So
60:54 - currently we have six elements inside
60:56 - our stack now when we start taking the
60:59 - values out actually the only value we
61:03 - can take out at this moment is value
61:05 - number six because that is the only
61:07 - value we have access to because this is
61:09 - like a test tube or a a stack of plates
61:12 - kind of a structure so that is why when
61:15 - we decide to take things out we are
61:17 - going to take value number six out first
61:20 - after taking value number six out then
61:22 - we we can start taking value number five
61:24 - out after five we will get to the value
61:27 - number four and so on and so forth so
61:29 - essentially the last element that was
61:32 - encountered or entered inside the stack
61:35 - would be the first element that is going
61:37 - to come out so this is this works on the
61:39 - Leo principle last in first out okay so
61:44 - and that's it this is what the whole
61:47 - stack is uh now if you have to see what
61:50 - are the operations you can do inside a
61:52 - stack uh you actually have
61:55 - some limited operations but they have
61:57 - very specific use cases so let's say
61:59 - that currently we have a stack like this
62:01 - 321 there are three elements so number
62:03 - first thing we can do is we can push
62:05 - value inside the stack because we
62:08 - already pushed these three values uh
62:10 - inside the stack so pushing element
62:12 - inside the stack is actually quite
62:14 - simple all you need to do is just push
62:16 - it and whichever is like sequentially
62:19 - available memory block so let's say that
62:21 - this is a stack like this so this would
62:23 - be the element that gets filled so this
62:26 - takes big off one time now you also have
62:29 - the option to pop a element out so when
62:31 - you pop an element out you only have
62:33 - access to just pop out the element that
62:36 - is currently located at the first pace
62:38 - so in this case you can only pop out
62:40 - this element and after that is done you
62:41 - will pop out this element so this also
62:44 - takes big off one time now the next
62:46 - option we have is that many times rather
62:49 - than popping one element out we can just
62:52 - check that what is the current element
62:54 - at the very top and that for that we
62:57 - usually do like a peak operation and
63:00 - this also takes big off one time so you
63:02 - would you must be thinking that hey this
63:04 - is super fast uh data structure so let's
63:08 - use this up to the fullest extent but uh
63:11 - this is very limited in memory size and
63:14 - also like the way data is being stored
63:17 - so if we when we start talking about
63:19 - additional operations if we have to find
63:22 - an element inside a stack that takes big
63:24 - off end time for obvious reasons because
63:26 - at one point we are only accessing one
63:28 - element out and let's say that the
63:30 - element we are trying to get out is
63:31 - actually located at the very bottom we
63:33 - won't be able to reach it until we reach
63:35 - all the elements if we have to once
63:37 - again delete any element once again it
63:39 - will take big of end time because we
63:41 - will have to first find that element so
63:43 - that also adds an additional layer of
63:46 - complexity and same goes for modify as
63:48 - well that that this also takes B go off
63:50 - end time so all of these things they are
63:53 - closed L correlated with each other now
63:56 - let's see that what are the operations
63:59 - we can do or what are the use cases of a
64:01 - stack so number one use case of a stack
64:04 - is that wherever you need to maintain a
64:06 - sequence in one order and the reverse
64:10 - order sequence has to be match in that
64:13 - case uh stack would be a great example
64:16 - and this is one of the very popular
64:18 - scenario for that where we are we want
64:21 - to check that the number of parentheses
64:23 - we have are they in the correct order or
64:25 - not and that can very easily be
64:27 - determined using a stack where all the
64:30 - parentheses that are coming in they also
64:33 - get out in the same manner and U if you
64:36 - want we can also try to do a quick
64:38 - example so let's say that currently we
64:40 - are trying to build a compiler and in
64:43 - our compiler we wants to check that all
64:45 - the parentheses that were opened they
64:48 - are closed in the same sequence so what
64:50 - we can do is okay the moment we open a
64:52 - parenthesis we are going to push an
64:55 - value inside the stack So currently
64:57 - stack is empty and let's say that these
64:59 - are the sequence of operation we are
65:00 - going to do right that first we are
65:02 - going to open a curly bracket then we
65:04 - are going to open a square bracket then
65:07 - a circular bracket and then we are going
65:09 - to close in the correct manner as well
65:12 - so the idea would be that first we open
65:14 - the bracket so we are going to add a
65:16 - value over here then once again open so
65:18 - add open so add now when we are closing
65:22 - the bracket we will remove the value and
65:26 - try to see that whether the bracket is
65:28 - of same kind or not so the first value
65:30 - we removed is a curly is a circular
65:33 - bracket and the value we are trying to
65:35 - close is also a circular bracket which
65:37 - means awesome so this sequencing was
65:40 - correct now uh the very first element
65:44 - currently is the square bracket open
65:47 - square bracket and now the bracket we
65:49 - are trying to close is also an open type
65:51 - of bracket so once again this is also a
65:53 - match so we can consider this and the
65:56 - last element is a curly bracket and a
65:58 - curly bracket so once again this is also
65:59 - a match so the whole solution work and
66:02 - now we are at the end of our parenthesis
66:05 - at that time we also check inside our
66:08 - stack and currently our stack is also
66:10 - empty which means all the brackets that
66:13 - were opened they got closed in the same
66:15 - manner let's assume that uh there is one
66:18 - more additional bracket over here in the
66:20 - beginning that this was the case so then
66:23 - after these three has been done we would
66:25 - still have one entry over here which
66:27 - would dictate that the parentheses were
66:29 - not opened and closed in the same manner
66:31 - and uh that would throw an error so this
66:34 - is actually the use case being used in
66:36 - many of the compilers as well so that's
66:38 - actually quite cool to understand that a
66:41 - simple data structure can give birth to
66:43 - such a wide variety or such a huge
66:46 - functionality now here is the problem
66:49 - statement for the valid parenthesis
66:50 - problem where we are given the string of
66:53 - opening and and closing brackets and we
66:55 - need to determine that whether it is a
66:57 - valid sequence or not so for that we are
67:00 - actually going to use a hashmap in this
67:02 - case where we are going to create the
67:03 - mapping of opening and closing brackets
67:06 - where all the closing brackets are going
67:08 - to be placed as the keys in the hashmap
67:11 - and their subsequent values would be
67:12 - their counterpart now let's move on to
67:15 - our is valid method where as an input we
67:17 - are given a string so first of all we
67:19 - will initialize our stack uh we are
67:22 - going to run a for Loop across the given
67:24 - string and we will see that whether this
67:26 - is a closing bracket or not if that is
67:28 - the closing bracket we would get the top
67:31 - element of the stack and if the stack is
67:34 - empty we can return false if it is not
67:36 - empty we will pop the element and we
67:38 - will compare it with the closing element
67:40 - so if they match that's fine if they
67:42 - don't match we can return false and if
67:44 - that is not the case if it is an opening
67:46 - bracket we will simply push the value
67:48 - inside the stack now in the end after
67:51 - this whole Loop has ended essentially a
67:53 - our stack should be empty if the stack
67:56 - is empty we can return true that the
67:57 - sequence is valid if it is not empty we
68:00 - can return false so let's try to run
68:02 - this
68:03 - code and seems like our solution is
68:06 - working as expected let's submit this
68:08 - code and our code runs pretty
68:10 - efficiently and you can imagine that how
68:13 - Stacks are actually serving a very
68:15 - critical functionality now let's try to
68:17 - think about another example of what a
68:20 - stack can do and that is a redo
68:23 - functionality so we all know that what a
68:25 - redo or undo functionality is basically
68:28 - if you are going through your Google web
68:31 - browser whenever you need to go back to
68:33 - the previous website you were at uh
68:36 - essentially a stack is being used and
68:38 - how it does is that let's say that
68:40 - initially you opened your Google So
68:42 - currently your stack is empty now you
68:45 - first go to the Facebook page so it will
68:47 - Mark the value as Facebook from Facebook
68:49 - you decided to go to the Instagram page
68:51 - from Instagram you go to the YouTube
68:53 - page and and from YouTube you go back to
68:55 - the Twitter page now at the Twitter you
68:57 - decide to hit that uh Arrow back button
69:00 - or the undo button the moment you hit
69:02 - back it is actually going to pop the
69:04 - value out so currently okay uh you are
69:07 - at the Twitter so previous element like
69:10 - the YouTube would be there okay now
69:12 - currently you are the Twitter you hit
69:14 - the element back so it is going to pop
69:15 - the first value out so first value
69:17 - popped out would be YouTube so it will
69:19 - take you to the YouTube page now from
69:21 - the YouTube you once again hit the arrow
69:23 - back so once again the Instagram page is
69:25 - going to come out now currently you are
69:28 - at the Instagram page and you have this
69:31 - value now from the Instagram page you
69:33 - decide to go to the let's say Uber page
69:36 - so now because you went to a new page
69:38 - there will be an entry for Uber being
69:40 - added over here now once again when you
69:42 - hit the undo button actually from The
69:44 - Uber page you would actually go back to
69:46 - the Facebook page so that's how these
69:49 - things would work and uh this is
69:52 - actually quite useful data structure in
69:54 - my
69:56 - opinion the last linear data structure
69:59 - that is a Q and Q is also very popular
70:03 - as the name suggest Q is actually quite
70:05 - simple where unlike stack we actually
70:10 - have both ends open but all the values
70:13 - are coming in from one end and going out
70:15 - from the other end so let's say that
70:18 - currently you have the cube and you have
70:20 - value number five come in so five would
70:22 - be the first candidate to get out then
70:25 - we have value number six coming so six
70:27 - would be the second candidate to get out
70:30 - same way all the subsequent elements
70:32 - that keeps on coming in they all would
70:34 - be stored in the same sequence of the
70:36 - sequence they came in so we have a value
70:39 - where we can NQ or where we can add
70:42 - values to the cube and where we have a
70:45 - position where we can DQ where the
70:47 - values go out of the cube and uh we all
70:51 - know the functionality of cube uh there
70:53 - are lot of real life systems where we
70:55 - need to have cues uh if we want to
70:58 - generate like some Network packet
71:00 - manufacturing or uh Network packet
71:03 - submission type of system definitely we
71:05 - are going to use because we want uh our
71:08 - let's say that we have a system a and we
71:10 - have a system B and we are sending some
71:12 - Network packets so we want Network B to
71:15 - receive the network packets in the same
71:16 - manner they were sent from Network a so
71:18 - for that on the B side we are actually
71:20 - going to create a cube and this cube is
71:22 - going to have the sequence IAL flow of
71:24 - the networks so now let's see that for
71:27 - the Q we already know the use case but
71:30 - first understand that what are the types
71:32 - of cues available so the number one type
71:34 - of que is actually the just a regular
71:36 - quebe then there is also priority Cube
71:40 - now what priority Q means is that this
71:43 - represents some real life scenario so
71:45 - let's assume that you are currently
71:48 - waiting at the DMV Center to make your
71:51 - driving license and currently the
71:53 - officer sitting there is asking for
71:55 - everyone in a sequential manner so
71:57 - currently all the people are standing in
71:59 - the line and of course the person who
72:01 - came the first would be the person
72:03 - reaching out to the DMV officer in the
72:05 - first manner but during this time DMV
72:08 - officer identify a pregnant lady or some
72:11 - person who had some disability so in
72:14 - that case this person would be the first
72:16 - person to go and meet to the officer and
72:19 - complete the task and this is the real
72:21 - example of how a priority looks like
72:24 - where it mostly operates as a normal
72:26 - queue unless you have some event that
72:29 - you can Define that would dictate that
72:32 - it has a higher priority so process that
72:34 - first and this is quite useful in many
72:37 - real life scenarios as well where let's
72:39 - say that in your phone you wants most of
72:41 - the stuff to happening in the sequential
72:43 - manner but what if there is something
72:45 - related to like payment fraud happening
72:47 - so you want to put first first priority
72:50 - for that and for that usually a priority
72:52 - queue gets implemented now let's see
72:55 - that what are the different operations
72:56 - you can do or you can perform on a given
72:59 - Cube so I'm drawing a preliminary basic
73:02 - q and uh we are going to have the values
73:05 - coming in from one end and going out of
73:06 - the other end so essentially the first
73:09 - value would be five that came in so the
73:12 - first value would be five that would be
73:14 - going out so Q operates on fif principle
73:18 - first in first out unlike stack that was
73:21 - working on Leo principle last in first
73:24 - out so that is that is a difference
73:26 - between them and you have to understand
73:28 - now uh in the Q we first have the option
73:31 - for NQ which means we are adding an
73:33 - value to the back and this process takes
73:36 - big off one time because it's a constant
73:38 - time operation we already know where we
73:39 - are heading same way for the DQ uh it
73:42 - also takes big off one time because
73:45 - again once again the operation is quite
73:46 - similar now on top of that in the Q we
73:49 - have the option to Peak that who is
73:51 - going to be the first value coming out
73:54 - so that does not actually comes out but
73:56 - we would know that this is the value
73:59 - then there is also another option to
74:01 - search inside the queue but searching
74:04 - like other data structure takes big off
74:06 - end time and by the way for peing would
74:07 - take big off one time now on top of that
74:10 - we can actually delete an element from
74:13 - the queue but we would rarely do that
74:15 - because we want to process those
74:16 - elements this also takes meig go off end
74:18 - time and that essentially that's it now
74:22 - I I think I already give you sufficient
74:24 - examples of how does a queue operate or
74:26 - how it looks like so you can actually
74:28 - imagine that uh how things work with the
74:31 - cube and one of the most popular data
74:33 - structures out there is actually trees
74:36 - so trees is not your everyday looking
74:39 - array or link list it's actually
74:41 - completely different uh first thing it
74:43 - is a hierarchical data structure second
74:45 - thing for the trees you actually have to
74:47 - consider some terminologies so typically
74:50 - a tree looks like this where it has a
74:52 - node in this node you can store some
74:55 - information so that information can be
74:57 - anything you can store an integer value
74:59 - you can store uh a character value or if
75:02 - you want you can store some class values
75:04 - as well so let's say that you created a
75:06 - class called person and in that class
75:08 - you have that first name last name and
75:10 - date of birth you can fill out all of
75:12 - the those information in this node but
75:14 - apart from that on top of storing all of
75:17 - this information let's say that you
75:18 - store that information in the majority
75:20 - part of the given tree node in the rest
75:23 - of the part you actually create the
75:26 - connections that it is connected to with
75:28 - other nodes and this is really important
75:31 - so one single tree you only have access
75:34 - to the root node but from this root node
75:37 - you can actually connect to multiple
75:39 - places inside the given tree so you can
75:41 - actually be connected with two more
75:43 - nodes that are below that under one of
75:46 - nodes you can be connected with three
75:48 - more or four more or any more number of
75:50 - nodes this node maybe only have one node
75:53 - then and this node has another node and
75:55 - this is how typically a tree progresses
75:58 - so when we are talking about trees we
76:00 - will have to first Define few important
76:02 - things so I already told you the number
76:04 - one thing that what a node is that node
76:07 - is basically the portion of tree that
76:09 - contains data that contains important
76:12 - information now next important
76:14 - information for that a tree needs is an
76:16 - edge and what does an edge represents so
76:19 - if we see or take a look at this picture
76:21 - Edge is essentially the o that connects
76:24 - any two node and there needs to be some
76:27 - relationship between them so typically
76:29 - in a tree you would always see a
76:31 - relationship like this where a tree is
76:34 - always under some other parent tree so
76:37 - in this case this root node is actually
76:40 - a parent node for these two subsequent
76:43 - nodes but also at the same time let's
76:45 - say that you have four more nodes over
76:46 - here then in this case for these nodes
76:49 - this becomes a grandparent and uh this
76:53 - becomes uh these two nodes becomes
76:55 - parents for these subsequent nodes so
76:57 - there is always a parent child
76:59 - relationship and that relationship is
77:01 - typically defined through an edge next
77:04 - we need to discuss that what a root
77:06 - means so root means the node that is
77:10 - that supersedes all the nodes so
77:12 - essentially the great great great great
77:14 - greatest grandparent essentially the
77:16 - very first node that becomes your entry
77:19 - point into the tree and this is defined
77:21 - as the root node now let's talk about
77:24 - that what does a leaf node means so Leaf
77:26 - node means that the node that does not
77:29 - have any children so let's say we have a
77:31 - tree that looks like this in this case
77:33 - we currently have a node this node is by
77:36 - default the root node and this tree is
77:38 - connected with these two edges to these
77:40 - two children but these two children does
77:42 - not have any subsequent children of
77:44 - their own so in this case uh these two
77:47 - nodes actually becomes the leaf node
77:49 - that we are trying to explain now let's
77:52 - talk about the concept of depth now what
77:55 - does a depth means inside a tree
77:57 - essentially for any given tree uh it is
78:01 - always placed in the layers that one
78:04 - root node has some children then these
78:06 - children have subsequent children of
78:09 - themselves as well there can be n number
78:11 - of Childrens and for the Simplicity sake
78:13 - I'm drawing two children for every
78:15 - single parent but there can be n number
78:17 - of children and in this case we can see
78:20 - that currently this root node is
78:23 - actually located at depth one or you can
78:26 - also consider it depth zero depending on
78:28 - what type of situation you're tackling
78:30 - they are just numbers but they would be
78:32 - the initial depth and then with every
78:34 - level you go down the number of depth
78:37 - increases by one so in this case this is
78:39 - located at depth one this is located at
78:41 - depth two so essentially depth can also
78:44 - be considered as level of parents or
78:48 - children uh that each one of them has
78:51 - and very close and very similar similar
78:53 - concept is of height so height basically
78:56 - defines that how deep a tree goes so in
79:00 - this case from the root node we actually
79:02 - go two levels down so we can consider
79:04 - the height of this tree to be two uh
79:07 - same way uh from any single separate
79:09 - node you can also calculate the height
79:11 - from that position as well and in this
79:13 - case the height would be one if we
79:15 - consider this smaller sub tree of a tree
79:18 - so these are the different terminology
79:20 - that you have to understand before we
79:21 - proceed with uh what a tree is now let's
79:25 - try to see that what are the different
79:27 - types of trees that are available and
79:29 - trust me there are lot of types of trees
79:32 - so first let's just start with the
79:34 - simplest trees and that is binary tree
79:36 - now what does binary tree defines well
79:39 - we all know the meaning of binary binary
79:41 - means either zero or one which means it
79:43 - means two so binary tree means that
79:46 - every single root node has exactly two
79:49 - children so in this case this would have
79:52 - two children same way these subsequent
79:54 - nodes would have two children of their
79:55 - each and so on and so forth and until we
79:58 - run out of the level so in this case
80:00 - let's say that this has two children and
80:03 - that's it so this is a binary tree why
80:06 - because by definition every single
80:08 - parent has exactly two children or no
80:11 - children at all so and that property is
80:13 - followed across all the nodes uh so
80:17 - binary tree is what you're are going to
80:19 - encounter mostly in your typical
80:22 - interviews and very closely and a a
80:25 - subset of this binary tree is actually
80:28 - binary search tree so what does binary
80:30 - search tree means that it follows all
80:33 - the properties that a binary tree has
80:35 - that every single node has exactly two
80:37 - children or no children at all but on
80:40 - top of that the binary search tree has
80:42 - an additional property where the values
80:46 - that are being represented in that those
80:49 - binary trees they are actually sorted
80:51 - with the condition that everything on
80:54 - the left is actually less than
80:57 - everything on the right uh and this
80:59 - property is followed throughout the
81:02 - entire tree so let me give you an
81:03 - example let's say that we currently have
81:06 - a tree that looks like this and
81:07 - currently the value of this root node is
81:09 - s then it it can only have children
81:13 - where the scenario is that everything on
81:15 - this left sub tree has to be less than
81:18 - seven if it is everything on this left
81:21 - sub tree is less than seven and
81:22 - everything on the right sub tree is
81:24 - greater than seven in that case we can
81:27 - Define this as a binary tree or sorry
81:29 - binary sear tree so let's say that we
81:31 - add two more nodes over here and these
81:33 - two nodes Define the values as that this
81:36 - one is value number five and this one is
81:38 - value number eight so far this follows
81:41 - the property of a binary search tree
81:43 - that is good for us now let's just take
81:45 - it one step forward as well so we have
81:47 - two more child over here in this case so
81:50 - in this case let's say that the value of
81:52 - this child is three and again value of
81:54 - this child is six is it still a binary
81:56 - tree yes why because let's follow the
81:58 - same property currently if we consider
82:01 - this parent node then this becomes the
82:03 - left sub Tree in left subtree all the
82:05 - values are less than value s so that is
82:08 - good now let's consider this node so
82:11 - this node is five its left is three and
82:13 - Its Right is six and that is also
82:15 - followed because left sub tree is less
82:17 - than five and right sub tree is greater
82:19 - than five so both properties match same
82:21 - way the right sub tree is currently
82:23 - greater than seven so this property also
82:25 - matches so in this case this would be a
82:28 - binary search tree and binary search
82:30 - tree has lot of potential and lot of
82:33 - application you can actually use it for
82:35 - sorting or you can use it for to store
82:38 - data or to go hierarchically down so we
82:41 - we will talk more about this when we go
82:43 - when we start talking about uh various
82:46 - uh scenarios where you can actually use
82:48 - the uh tree data structure now there is
82:50 - one more data structure that is called a
82:52 - AVL trees so what AVL trees is that AVL
82:56 - tree is actually a special kind of tree
82:58 - where not only it is a binary tree but
83:02 - apart from that it is also binary search
83:04 - tree and on top of that it is a balance
83:07 - tree so what does the balance tree means
83:10 - so let me give you first an example of a
83:12 - balance tree balance tree is any tree
83:15 - where all the nodes on the left side of
83:17 - sub tree and all the nodes on the right
83:19 - side of subtree are even so in this case
83:21 - let's say if I have a tree like this
83:23 - this is a balance tree if I have a tree
83:26 - like this where left node has two sub
83:28 - nodes and right node also has two sub
83:30 - nodes this is also balance tree so any
83:33 - symmetric tree is basically balance tree
83:35 - and AVL trees contains all of these
83:38 - three properties yeah so that is about
83:40 - AVL tree then there are all more
83:42 - specialized trees that is red black tree
83:45 - and there is also B trees but these are
83:47 - just too higher of the concepts but I'm
83:50 - just going to give you an example that
83:52 - red red black tree is actually a tree
83:55 - that has separate colors so some nodes
83:58 - are defined in a certain color and the
84:00 - other nodes are defined in the certain
84:02 - colors and depending on their
84:04 - positioning the colors are maintained so
84:07 - whenever you try to add new value uh it
84:10 - automatically maintains the colors and
84:12 - it automatically generates that what
84:15 - should be the next subsequent value
84:16 - based on those coloring groupings so the
84:19 - red black trees are great at sorting
84:21 - various items and various operations
84:23 - depending on the color property and B
84:25 - trees are multi-level balance and sorted
84:30 - uh tree data structure that can have
84:32 - more than two uh more than two children
84:36 - so it is actually much more complex
84:38 - topic and in its own uh it has actually
84:41 - lot of uh things that we can think about
84:44 - but we are not going to go deeper
84:45 - because that would be much that would be
84:47 - a topic for much higher level I just
84:49 - wanted to give you a brief overview for
84:51 - that now let's let's see that what are
84:53 - the operations we can do on a tree so
84:56 - the operations are quite simple we can
84:59 - do like searching we can also do sorting
85:02 - we can also do uh deletion and in
85:06 - insertion all of those things right but
85:09 - in order to do that uh we actually have
85:12 - to Traverse over the tree all the time
85:15 - and the most important operation that
85:17 - you will have to learn about is that how
85:20 - how the traversal Works inside a given
85:22 - tree so actually for trees there are
85:25 - typically three different ways you can
85:27 - Traverse over inside the given tree and
85:29 - that that are that in order traversal
85:32 - pre-order traversal and postorder
85:34 - traversal so how each each and every one
85:37 - of them is going to work well I actually
85:38 - have a separate video on that but if you
85:40 - want you can just check what I'm trying
85:42 - to explain right now what in order
85:45 - traversal means is that first we are
85:47 - going to visit the node then we are
85:49 - going to visit the left child and then
85:50 - we are going to visit the right right
85:52 - child child pre-order means that first
85:54 - we are going to visit the left child
85:55 - then we are going to visit the node and
85:57 - then we are going to visit the right
85:58 - child and post order means that first we
86:00 - visit left then we visit right and then
86:02 - we visit node so let's see this in
86:04 - action suppose we uh we are given a
86:07 - simple tree so I'm currently drawing a
86:09 - simple most basic tree and we will go
86:12 - through its values right so let's say
86:14 - the values are one then on the left is
86:16 - two and then Its Right is three and also
86:20 - on the right is four and on the left is
86:22 - five and on the right is six let's say
86:24 - that this is the type of tree that we
86:26 - are trying to generate now let's see
86:29 - that what would be the in order
86:30 - traversal would be for this part this
86:32 - type of tree well of course first we are
86:35 - going to visit the node so node in this
86:37 - case is going to be the root node and
86:39 - that is going to be one so the very
86:40 - first value we are going to go through
86:42 - is going to be value number one then we
86:44 - are going to see all the left sub tree
86:47 - So currently for the left subtree it
86:49 - only has node number two but again at
86:52 - node number two we are also going to
86:53 - visit this and then after visiting now
86:56 - currently for this node number two it
86:58 - does not have any left sub tree that we
86:59 - can visit so we are going to go into the
87:01 - right side and on the right sub tree we
87:03 - have value number three that we haven't
87:04 - visited so we are going to visit node
87:06 - number three after that again we are
87:08 - going to repeat the same process now in
87:09 - this case we already took care of this
87:11 - value this value and this value so now
87:13 - even for node number one we are going to
87:15 - go to the right sub Tre but for right
87:17 - sub tree again we are going to apply the
87:18 - same logic of node left and right so
87:21 - once again we we are first of all going
87:23 - to visit node number four and after that
87:25 - we are going to visit node number five
87:27 - and then we are going to visit node
87:28 - number six so we took care of all the
87:30 - nodes so this is how uh the traversal
87:33 - works for in order traversal now let's
87:35 - do the pre-order traversal and inside
87:38 - the pre-order traversal it's clearly see
87:41 - that we need to go to the left as much
87:43 - possible as we can so from the initial
87:45 - note do we have a left sub tree yes uh
87:47 - in the left sub tree we are going to go
87:49 - to this node now does this node has any
87:51 - left sub tree that we haven't checked no
87:53 - because this does not have a left sub
87:55 - tree then we can visit the node so while
87:57 - visiting the node the first node we are
87:59 - going to visit for the pre-order
88:01 - traversal let me just write it over here
88:03 - so the first node would be node number
88:04 - two now the next node we are going to
88:06 - visit is going to be the right subt tree
88:08 - of this node now for this three it does
88:10 - not have any children which means we
88:11 - will have to visit this node so we are
88:13 - going to visit node number three first
88:15 - after visiting these two now for this
88:17 - node number one we took care of the
88:19 - entire left sub tree so we can actually
88:21 - visit node number one now after visiting
88:23 - node number one we need to take care of
88:25 - the entire right subtree but again with
88:27 - the same logic of left node and right so
88:30 - again we are at this position now this
88:32 - does have a left node so we are going to
88:34 - visit five first then we are going to
88:36 - visit the node and then we are going to
88:38 - visit node number six so this would be
88:40 - the pre-order traversal for the given
88:42 - tree now let's see that what would be
88:44 - the postorder traversal for the given
88:46 - tree so in terms of post order traversal
88:49 - it is going to be actually quite simple
88:52 - uh again using the same logic we need to
88:55 - First go through every single left node
88:57 - then we need to go through every single
88:58 - right node and then only we will visit
89:00 - the existing node So currently for this
89:02 - one it does have a left node for this
89:04 - two it does not have a left node but it
89:05 - does have a right node so we are going
89:07 - to visit node number three first so in
89:09 - the post order traversal the first node
89:11 - we are going to visit is going to be
89:12 - node number three then the next node we
89:14 - are going to visit is going to be node
89:16 - number two and then we are going to
89:17 - visit node number uh one no we are not
89:19 - going to visit node number one right now
89:21 - because because node needs to be visited
89:23 - in the end and it still has right subt
89:25 - tree that we haven't checked so now we
89:27 - are going to visit the right subtree and
89:29 - this this portion now becomes the node
89:32 - and for this it also has a left node so
89:34 - now we are going to visit five then we
89:35 - are going to visit six then we are going
89:37 - to visit node number four and after
89:39 - completing both of these portion we are
89:41 - going to visit node number one in the
89:43 - end so this would be the full traversal
89:46 - for the given tree uh the in order
89:49 - pre-order and post order traval uh this
89:52 - is the most trickiest thing to
89:53 - understand for any single tree and I
89:56 - hope you find you find it useful now
89:58 - let's see that what is going to be the
90:00 - searching sorting deletion and insertion
90:02 - for the given tree so let's say that
90:04 - searching if we are given a normal tree
90:07 - then the searching is for sure going to
90:10 - take big of end time but if we are given
90:12 - a binary search tree in that case
90:14 - searching would be bigo of log n only
90:17 - because every single iteration we would
90:20 - be uh moving half of the element on one
90:24 - side and we we can focus steadily on the
90:28 - target so that is why binary search
90:29 - trees are so popular now let's talk
90:32 - about sorting uh so for sorting actually
90:35 - if we are given a binary search tree
90:37 - then sorting is actually constant uh
90:39 - sorry because of log and time because
90:41 - it's quite easy to do uh we only need to
90:44 - Traverse over over the given tree and uh
90:46 - many for many sorting algorithm binary
90:48 - search trees are being used deletion if
90:51 - if we know which node we have to delete
90:53 - then it's a constant time deletion
90:55 - operation but if we don't know the node
90:57 - and we have to search first then it
90:58 - becomes big go of n or log n depending
91:02 - on what type of tree we are given and
91:04 - same goes with the insertion that if we
91:06 - know that we we can insert any randomly
91:08 - then it's B go of one but if we cannot
91:12 - do it and we have to insert it at
91:13 - specific location then it's B of n or
91:16 - big of log n depending on where we are
91:19 - trying to insert and what type of tree
91:20 - we are given so this is everything you
91:23 - need to understand about trees but now
91:25 - let's see that what are the uses on how
91:29 - on and where we can actually use trees
91:31 - so number one use case for a tree is
91:33 - typically a database management system
91:36 - uh why database management system
91:38 - because number one binary search trees
91:41 - then AVL trees then red black trees then
91:44 - B trees all of these are huge and very
91:47 - powerful in separating all the elements
91:51 - so that's why they are quite popular
91:53 - whenever you are trying to build a data
91:55 - stru database on top of that they are
91:57 - really po really powerful when you are
91:59 - trying to index all the values and
92:02 - indexing and enabling fast data retrival
92:05 - can only be possible using the trees if
92:08 - you have to use uh anything for file
92:10 - systems or file management uh so because
92:13 - tree they are already in hierarchical
92:16 - nature and whenever you see your windows
92:18 - path or your something something you
92:20 - will always see something like C drive
92:22 - it has a file called programs it has a
92:24 - file called uh Java it has a file called
92:27 - bin something like that so this is a
92:30 - parent child relation where every single
92:32 - node is connected with the other node
92:34 - and uh you can actually go over that
92:36 - plus if you want to create like a syntax
92:39 - trees you can also do that using the
92:42 - trees why syntax trees because let's say
92:45 - that if you're trying to build a
92:47 - scenario or a compile or something where
92:50 - you want to show that what class is
92:52 - connected with what other class and you
92:54 - are trying to avoid any infinite Loop
92:56 - scenarios so in that case tree data
92:58 - structure would be a huge help and on
93:01 - top of that you can actually use trees
93:03 - to build priority cues as well so this
93:06 - is also a very good benefit to use you
93:09 - can actually do that using Heap and uh I
93:11 - won't be explaining the whole concept
93:14 - but just know that this can be done okay
93:17 - so now let's try to see uh some examples
93:20 - for the tree based questions so one of
93:22 - the very common example is that
93:24 - typically we are being asked to validate
93:25 - a binary search tree now we all know by
93:28 - definition that what a binary search
93:30 - tree is that essentially every single
93:32 - node that is on the left side of the
93:34 - tree is actually less than uh the node
93:37 - value and every single node on the right
93:39 - side of the sub tree is actually greater
93:41 - than the node value and this property
93:43 - has to be followed throughout the entir
93:45 - of tree so let me give you a couple of
93:48 - examples where we will try to see that
93:50 - which are some of the valid trees which
93:52 - are not valid trees and how we can solve
93:54 - this problem in an actual interview or
93:56 - for our practice so assume we are given
93:59 - a tree like this where the values are 1
94:01 - 2 3 4 and 5 and uh these are the
94:05 - connection of the nodes so in this case
94:07 - we can clearly see that this is a valid
94:10 - binary search tree why because this is
94:13 - the middle node node number three now if
94:15 - we see the left sub tree for this node
94:17 - is actually the values are 2 and 1 and
94:20 - both are small than value number three
94:22 - same way in the right side of the sub
94:24 - tree the values are four and five and
94:26 - again both are greater than that
94:28 - particular value now we have couple of
94:30 - more sub trees as well that we need to
94:32 - check and that is this one so first sub
94:34 - tree is that this value of two and the
94:37 - value of one so again since the one is
94:39 - less than two and it is on the left side
94:41 - of the two uh it is a valid path same
94:44 - goes for this four and five as well and
94:46 - in this case we can Define this to be a
94:48 - valid binary search tree but now let's
94:51 - consider a scenario that if we are given
94:53 - a tree like this suppose the values are
94:55 - 5 4 3 and then this one is 6 and then
94:58 - this one is 2 and uh these are the nodes
95:02 - that are currently connected now let's
95:04 - break them down sube by sub tree so
95:07 - let's consider first this value number
95:08 - three and value number two they are just
95:10 - uh simple or Leaf nodes so they don't
95:13 - mean anything now let's consider this
95:15 - sub tree is this a valid sub tree yes
95:17 - why because three is less than four and
95:19 - it is currently on the left child of
95:21 - four so that is true now let's consider
95:24 - this entire sub tree so this is also
95:26 - valid because both four and five three
95:28 - are smaller than value number five now
95:30 - let's consider this sub tree this is
95:32 - also valid scenario where six is
95:34 - actually uh higher and in the greater
95:37 - value so 2 is smaller than six so that
95:39 - is why it is on the left side but when
95:41 - we consider this whole portion then it
95:44 - fails and why it fails because the value
95:48 - number for Value number five the
95:49 - expectation is that everything that is
95:52 - on the right side of value number five
95:53 - which means this portion has to be
95:56 - greater than value number five but since
95:58 - this two is actually less than five so
96:00 - because of this we can Define this to be
96:03 - a wrong wrongly placed uh value so this
96:07 - is not a valid binary search Tre now the
96:10 - question is how can we actually find the
96:12 - solution for this type of problem uh for
96:15 - trees so one simple approach is that if
96:20 - we do an in order traversal for any
96:23 - binary search tree if the tree is valid
96:27 - we should get a sorted array or sorted
96:29 - values in return and let me give you an
96:32 - example for this let me for a moment
96:35 - make this a valid binary search
96:37 - Tre so the method for in order traversal
96:40 - is first we visit the left sub child
96:43 - then we visit the node we want to check
96:45 - and then we visit Its Right sub child or
96:47 - right child and we keep on repeating for
96:49 - all the sub trees so so essentially
96:52 - first of all we will start our journey
96:54 - at this root position so at the root
96:56 - position first we need to check that
96:58 - whether a left child exist or not and
97:00 - yes because left sh exist once again
97:02 - this becomes our current root node or
97:04 - current node we are working with again
97:06 - this also has a left sh so three would
97:07 - be the first value we would visit so
97:09 - let's mark three would be the first
97:11 - value we visited then we would go back
97:13 - to the root now this node has no other
97:16 - left Sub sub trial uh that has not been
97:19 - visited so we would visit value number
97:20 - four and then it does not have a right
97:22 - child so we will again go back and now
97:24 - for this five we took care of the entire
97:26 - left sub tree so we can mark five as
97:29 - visited as well and then we will go to
97:31 - the right side of the sub tree now in
97:32 - the right side of the sub tree for seven
97:34 - we still have a left node available
97:36 - which means we would first have to
97:38 - Traverse that so we would Traverse value
97:40 - number six and then we would go back and
97:42 - since this seven we took care of the
97:44 - left sub tree so now we will take care
97:46 - of value number seven and this is where
97:48 - we would end and now if you see this
97:50 - sequence this actually came out as a
97:52 - sorted uh values so this is all we need
97:56 - to do that whenever we need to uh run
97:59 - for a tree we simply need to do an in
98:01 - order traversal if all the values are in
98:04 - correct sorted manner then we can Define
98:06 - this to be a valid binary search tree if
98:09 - that is not the case we can Define it
98:10 - invalid and let's try to understand this
98:12 - with a very small example suppose we are
98:14 - given the values as uh 5 3 and 2 suppose
98:19 - this is the sequence of values now if we
98:20 - do order traversal in this one first for
98:23 - five we are going to visit the left
98:25 - child so we are going to visit value
98:26 - number three that is good then we would
98:28 - visit value number five and in the end
98:30 - we would visit the right side right sub
98:32 - tree that is value number two now up
98:34 - until this portion this was a valid
98:37 - binary search Tre but the moment two
98:39 - entered over here this this is no longer
98:41 - a sorted uh sequence so that's why we
98:44 - can Define that this is not a valid
98:46 - binary search tree and let's see the
98:48 - code for this one right now
98:52 - so this is the validate binary search
98:53 - tree problem and now let's see the Java
98:55 - solution for this approach we already
98:57 - know that we need to do an in order
98:59 - traversal in order to validate that
99:01 - whether given tree is valid or not and
99:03 - for that we are creating a helper method
99:05 - where first of all we are checking that
99:07 - if the given root is equal to null then
99:09 - we can return true if that is not the
99:11 - case we need to do the in order for the
99:13 - left sub tree of the given root and the
99:15 - right sub Tre of the given roote so we
99:17 - do this that we call our uh recursive
99:20 - method once again where we call the left
99:22 - subtree uh as an input and we try to see
99:25 - that what is going to be its answer so
99:27 - let's say that if this yields the answer
99:29 - as false uh then we can simply return
99:32 - false if that is not the case then we
99:34 - can move forward and we will check that
99:36 - if whether the previous element was null
99:39 - not equal to null and if the value of
99:41 - the root is less than the previous
99:43 - element then also we can return false
99:45 - which means in this scenario we
99:47 - identified an anomaly where there has
99:50 - been a mismatch between any two values
99:52 - and they are not currently sorted if
99:54 - that is not the case then we are going
99:56 - to Mark the previous node as the root of
99:59 - the value of the root we identified and
100:01 - then we are going to call the in order
100:03 - function once again on the right side of
100:05 - the sub tree so this is a very simple
100:07 - piece of code but it's actually very
100:09 - powerful and help us Traverse the tree
100:12 - in the correct manner recursively plus
100:14 - we are learning that uh what type of uh
100:17 - tree it is now let's submit this code
100:20 - and our code runs pretty fast compared
100:23 - to a lot of other Solutions so that's
100:25 - pretty
100:27 - good where graph is a very similar data
100:30 - structure to a tree uh and if we just
100:32 - talk about the terminology that we are
100:34 - going to use in the graph even in the
100:37 - graph we are going to have a node but in
100:39 - the graph we can also Define node as a
100:41 - vertex and that essentially represents
100:44 - the same circular dot that I just
100:46 - mentioned where you can store all sorts
100:48 - of information like integer or character
100:50 - Boolean or class value or whatever he
100:52 - wants to store you can store that inside
100:55 - but on top of that apart from that nodes
100:57 - node having that important data
100:59 - information it also has the information
101:01 - of other nodes that is that it is
101:04 - connected to in the current system and
101:07 - those other nodes can be n number of
101:09 - nodes on top of that those other nodes
101:12 - can also be connected inter internally
101:15 - as well and there are some scenarios
101:18 - where one node is connected with another
101:19 - node but another node is not connected
101:22 - with that node and that node might be
101:24 - connected with some other node and that
101:25 - some other node might be connected with
101:27 - that node as well so there are lot of
101:29 - different uh ways uh graphs can work now
101:33 - one key difference between a tree and a
101:36 - graph is that graphs are graphs can be
101:39 - cyclic in nature and what do I mean by
101:42 - cyclic that let's say that you have a
101:44 - node that is connected with another node
101:46 - it could be possible that is also
101:47 - connected with another node and that is
101:49 - also connected with the previous note
101:51 - and this type of configuration would not
101:53 - be present inside a tree this this can
101:56 - only be present or prevalent inside the
101:58 - graph and that is the the biggest
102:00 - difference between trees and graphs and
102:03 - that's why they have their own entire
102:05 - set of different con considerations and
102:07 - connections so now let's just go back to
102:10 - the basic terminology that we need to
102:12 - understand first we understood that what
102:13 - a node or Vex is or vertices is next
102:17 - thing uh that we have to consider is The
102:19 - Edge and Edge is the it means the same
102:22 - thing that that is the connection point
102:25 - between any two values uh that are next
102:27 - to each that are connected with each
102:29 - other so Edge means the connecting
102:31 - points now there is also the concept of
102:34 - adjacent uh adjacency or adjacent
102:37 - vertices what do I mean by adjacent
102:39 - vertices let's say I have a graph that
102:41 - looks like this and in this case uh
102:44 - currently let me Mark the values as a b
102:47 - c and d so in this case if I consider
102:49 - this node number c I can say that node D
102:53 - node B and let's mark this node as node
102:56 - e so B D and E are actually adjacent
103:00 - nodes to this node C because they're
103:02 - directly connected with that with an
103:04 - edge but if the this node is not
103:07 - actually connected with vertices then in
103:10 - this case this node C and A are they are
103:13 - not adjacent nodes to each other so this
103:16 - is what what do we mean by adjacent
103:18 - nodes now there is also a concept ccept
103:21 - of degree inside for any single vertex
103:24 - and what does a degree means that degree
103:27 - means that how many number of vertexes
103:29 - uh or connections that every single node
103:31 - has so let's say if I have a graph that
103:34 - looks like this in this case I have node
103:37 - a b and c so I can Define that this node
103:39 - only has one Edge so I can consider the
103:42 - degree of this node to be one in this
103:44 - case for this B it has the degree of two
103:46 - and in this case this C it has degree of
103:49 - one now there is also another concept of
103:51 - the total degree depending on the
103:54 - incoming and out
103:55 - outcoming edges as well and where does
103:58 - incoming and outcoming edges comes to
104:00 - place well we we will talk more about
104:03 - that when we discuss the type of graphs
104:05 - but remember that graphs can have a
104:07 - functionality where two one graph is
104:10 - connected with another graph but another
104:12 - graph is not connected so in this case
104:14 - if we Mark if we have a graph like this
104:16 - where a has an edge leading to the B but
104:19 - B does not have an edge leading to an a
104:22 - which means from a we can actually go to
104:25 - B but from B we cannot go back to a so
104:28 - in this case a would have an degree of
104:30 - one but B would have degree of zero in
104:33 - this case so that is that is the
104:35 - difference between these two uh this
104:38 - concept of degree for the graphs now
104:40 - let's see that what are the types of
104:42 - graphs that we we can deal with so
104:45 - number one type of graph is a directed
104:47 - graph and what does a directed graph
104:49 - means that I just showed it to you you
104:51 - that this is actually a directed graph
104:53 - where one node is actually connected
104:55 - with another node but it is not the vice
104:58 - versa is not true and the directed
105:00 - graphs can get really complicated as
105:02 - well it is not always going to be this
105:04 - simple or this similar and it could also
105:06 - be possible that there can be hundreds
105:08 - or even millions of nodes that are
105:10 - connected with each other in this
105:11 - fashion as well uh where we would have
105:13 - various degrees and various directions
105:16 - happening amongst different vertices
105:18 - there could be undirected graphs as as
105:20 - well and undirected graphs are actually
105:23 - a graph where two nodes share a common
105:26 - Edge so in this case rather than
105:28 - treating is as a single edge typically
105:30 - this is used to be like this where node
105:33 - a has an edge leading to node B and B
105:37 - has an edge leading to node a which
105:39 - means from B you can also come back to a
105:41 - and from a you can also go back to B but
105:43 - in this case typically we only show them
105:45 - using a single edge then whenever there
105:48 - is an edge without an arrow it defines
105:50 - that both nodes are connected with each
105:52 - other in the simplest Manner and there
105:54 - are there is a bidirected connection or
105:57 - an undirected connection now there is
105:59 - also consider uh also a concept of
106:02 - weighted graph and what does a weighted
106:05 - graph means that let's say that you have
106:08 - different nodes and different nodes had
106:10 - different connections and different
106:12 - connections have edges so edges carry
106:15 - weight as well let's say if I'm trying
106:17 - to plot a graph of a city now in this
106:20 - city uh this node represents the Young
106:24 - Street and this node represents the main
106:27 - street now these two streets are being
106:30 - represented and there is let's say there
106:32 - is also third street called Queen Street
106:35 - now there is a graph that looks like
106:37 - this but in this case it could be
106:39 - possible that this is this graph I'm
106:43 - defining this is defined as a road so it
106:45 - could be possible that from Young to
106:47 - main though there is a road there is
106:48 - some construction going on so because of
106:51 - that this Edge is actually weights five
106:53 - which means it takes 5 minutes from
106:55 - Young to go to main but it could be
106:57 - possible that from Young if we need to
106:59 - go to Queen it only takes 1 minute
107:01 - because there is no construction and
107:02 - from Queen there is only uh there is an
107:05 - edge going to main that also only takes
107:07 - 1 minute because there's no uh traffic
107:09 - so in this case because this Edge
107:12 - contains higher weight if we have to
107:14 - choose the shortest path between young
107:16 - and Main Street it it has to go through
107:19 - the queen Street and uh this would be
107:22 - the concept of a weighted graph this is
107:25 - really powerful especially for GPS
107:27 - system and the shortest path that we
107:29 - have to create uh between any two edges
107:31 - like Google Maps use this like crazy uh
107:34 - now there is also another concept of
107:36 - unweighted uh Edge and unweighted Edge
107:39 - is basically an edge that does not have
107:41 - any parameter uh so let's say that I'm
107:44 - creating a graph of just friends so
107:47 - currently a is friends with B and B is
107:49 - friends with c and C is also friends
107:51 - with a so in this casee I don't need to
107:53 - have any weight on the edge um they are
107:55 - all just friends and none of them are
107:57 - best friends so that's why it's a common
107:59 - relationship and U we can do whatever he
108:01 - wants to do then there is also concept
108:04 - of Click graphs and a cyclic graphs so
108:07 - cyclic and ayylic both means the same
108:10 - thing essentially this is a cyclic graph
108:13 - and let's say that if I did not had this
108:15 - Edge in this case then this would have
108:17 - been an ayylic graph where cylic graph
108:20 - has means that there exist a cycle
108:22 - between the nodes and a CLI graph means
108:24 - that there are no no Cycles happening so
108:27 - usually in ayli graphs there is a very
108:30 - popular concept of dag which is which
108:33 - means directed ayylic graph and directed
108:35 - asly graph means that every single node
108:38 - has an directed Edge so let's say that
108:40 - there this is node a node a is connected
108:42 - with node B and node B is connected with
108:44 - node C and C is connected with node D so
108:48 - this is an example of directed A
108:50 - basically graph where we see bunch of
108:52 - different edges but there are there are
108:54 - no issues with the graph now because
108:59 - graphs are a little bit trickier uh we
109:02 - have to take care of two things we have
109:04 - to take care of vertices and we also
109:06 - have to take care of edges to represent
109:08 - that what graph is connected with which
109:11 - so that is why uh even in order to
109:14 - represent a graph we need to have some
109:16 - different set of data structure so one
109:19 - possible data structure is an adjacency
109:21 - Matrix and another data possible data
109:24 - structure is an adjacency list so I'll
109:27 - I'll give you give you an explanation of
109:29 - both of them let's just have a demo
109:31 - graph uh that is a simple enough so
109:34 - let's just say we have a graph that a is
109:37 - connected with B and B is connected with
109:40 - C and C is connected with d and this is
109:44 - a graph right uh that we are trying to
109:46 - represent so if we have to create an
109:48 - adjacency Matrix what adjacency Matrix
109:51 - means is that we are actually going to
109:53 - have a 2X two or sorry M cross n Matrix
109:57 - where for every single vertices and
109:59 - edges we are going to have uh a matrix
110:02 - looking like this so we are going to
110:04 - have rows a b c d same way we are going
110:07 - to have columns marked as a b c d now
110:11 - currently uh all of the these four
110:14 - values will always be zero because node
110:17 - cannot be connected or cannot be its own
110:18 - neighbor now now let's say that
110:21 - currently a has a connection with B so
110:24 - we are talking about node a and its
110:27 - neighboring Edge to be B so in this case
110:29 - we would mark this value as one now B
110:31 - has a connection with C so node B has a
110:34 - connection with C so we would also Mark
110:35 - this value as one C has a connection
110:37 - with d so C to D we would mark it as one
110:40 - and D to uh and D does not have any
110:43 - connection which means this is going to
110:45 - be zero and all the other values they
110:47 - are going to be marked as zeros because
110:50 - they don't represent anything which
110:52 - means currently we have a graph that
110:54 - contains four nodes a b c d amongst
110:57 - these four nodes we only have connection
111:00 - between from A to B so that is why this
111:02 - is one but we do not have a connection
111:04 - from B to a so that is why this is
111:06 - defined as zero let's say that rather
111:08 - than this being a directed graph If This
111:10 - Were to be an undirected graph and we
111:13 - only have edges like these in this case
111:16 - in our adjacency Matrix we are going to
111:18 - represent values differently
111:20 - where uh even from B to a we are also
111:23 - going to Mark as an edge same way from C
111:26 - to B we are also going to mark an edge
111:29 - and same way uh D to C we are also going
111:32 - to mark an edge over here so all of
111:35 - these values would also be one in this
111:38 - case so this is the way on how we can
111:41 - represent graph in The adjacency Matrix
111:43 - Now adjacency list is a little bit
111:45 - different where adjacency list we
111:47 - actually have a hash map and I I know I
111:50 - haven't talk talk about hashing yet but
111:53 - inside a typical hash we have two values
111:55 - we have a key and we have some value
111:58 - associated with those that key so as a
112:00 - key we are actually going to have the
112:02 - four vertices that we are given so in
112:04 - this case it's a b c and d now for this
112:08 - we are going to mark that what are all
112:09 - the neighbors that a is connected with
112:12 - in this case currently a is only
112:13 - connected with B so we are going to have
112:16 - a value like B Associated for a same way
112:19 - currently B is actually connected with A
112:21 - and C both so for B we will have a value
112:24 - of a and C both and this is actually
112:27 - going to be a link list that where which
112:29 - represents that there can be n number of
112:32 - children associated with a sing or n
112:34 - number of neighbors associated with a
112:36 - single node same goes for C that from C
112:39 - it is connected with b and d and d is
112:42 - only connected with c and this is how it
112:44 - would be represented in adjacency list
112:47 - now the question is which one is better
112:50 - and which one is worse well in my
112:52 - opinion both does the job well but if
112:55 - you're dealing with a low number of
112:57 - edges then in that case it makes sense
113:00 - to use an adjacency list because it SP
113:03 - it uses less space uh meanwhile over
113:06 - here you see that there are more zeros
113:08 - than the number of ones but let's say
113:10 - that we have bunch of different edges
113:11 - that we are trying to work with
113:12 - something like this in this case it
113:14 - would make more sense to use an
113:16 - adjacency Matrix rather than using
113:18 - adjacency list so so these are the two
113:21 - ways on which we can actually use uh to
113:24 - represent graphs now what are the
113:26 - operations we can do on the graphs uh
113:29 - speaking of operations well the common
113:32 - operations are always going to be there
113:34 - that in terms of operations we would be
113:36 - able to insert we would be able to
113:37 - delete we would be able to modify we
113:40 - would be able to search there is no
113:43 - there is very little concept of sorting
113:45 - in this case because it is not very
113:47 - optimal for sorting but apart from that
113:49 - these these are all the things that we
113:51 - can do but in order to do that we can
113:53 - only do it by traversing over the given
113:56 - graph because we would not know that
113:58 - where we are traversing so we must have
114:01 - to Traverse and for Traverse we actually
114:03 - have two options we have the breath
114:04 - first search and we have the depth first
114:07 - search so I'm going to talk about both
114:09 - of them in a simplest manner uh if you
114:11 - want to know more about this uh I have
114:14 - created an entire separate videos on
114:17 - these two topics so that's why let me
114:19 - give you the basic idea that BFS
114:22 - represents breath first search what does
114:24 - breath first search means that we are
114:27 - actually going to search our neighbors
114:30 - first and before going to their
114:32 - neighbors and DFS means that depth first
114:34 - search what does depth for search means
114:37 - that we will pick a neighbor then we
114:40 - will pick one more neighbor for that
114:41 - neighbor then we will pick one more
114:42 - neighbor for that neighbor and we would
114:44 - keep on moving forward in that direction
114:47 - so let's try to see that in
114:50 - let's say that we have a graph that
114:51 - looks like this where we have bunch of
114:54 - different nodes that are closely
114:57 - connected with each other and we are
114:59 - trying to find some particular value
115:01 - right uh let me draw out bunch of
115:03 - different edges and with every single
115:06 - edge uh we would be able to reach to a
115:09 - certain conclusion about the given graph
115:12 - now let's say that this is the graph
115:14 - currently we have and we also have a
115:15 - cycle in in it now we are currently
115:18 - located at this node number a and we are
115:20 - trying to find this node number B and
115:23 - all of these nodes they can have their
115:24 - own subsequent separate values so if we
115:26 - are going in the BFS manner breath for
115:29 - search manner what we what we will start
115:31 - to do is let's say that this a is also
115:33 - the root node because even just like
115:36 - trees graphs also have the concept of
115:38 - root node so let's say that this a is
115:40 - the root node so from this a we know
115:43 - that what are the neighbors of a through
115:46 - either adjacency list or adjacency
115:47 - Matrix so we are going to use that in
115:49 - information and we will start traversing
115:52 - to all the neighbors so first we will go
115:53 - to this neighbor okay this is not value
115:55 - number B then we will go to this
115:57 - neighbor this is not value number B then
115:59 - we will go to this neighbor this is not
116:00 - value number B then we will go to this
116:02 - neighbor then we will go to this number
116:04 - we ex ex uh excluded all the
116:07 - possibilities for all the neighbors none
116:10 - of these neighbors were actually value
116:12 - number B so then we will pick one
116:15 - neighbor at R random and we would keep
116:17 - on moving forward so let's say we pick
116:19 - pick this neighbor again we go to its
116:22 - neighbor and again we go to its neighbor
116:24 - none of these yielded any good any
116:26 - particular good result so what we do we
116:29 - backtrack in that case and again from
116:31 - this a we would pick another neighbor so
116:33 - let's say we pick this neighbor this
116:35 - time and through this neighbor we would
116:36 - go to this neighbor and we would also go
116:38 - to this neighbor and we found out value
116:40 - number B so we can say that okay this is
116:42 - the connection between a to B and let's
116:44 - just say for this example the value of
116:47 - this neighbor is node number c so we can
116:49 - say that there exist a path from a to c
116:51 - and from C to B where it is connected
116:54 - now this would be the strategy for
116:57 - breath first search uh and I hope that
117:00 - my explanation was clear enough so that
117:03 - you get the idea now let's see that what
117:05 - would happen in the depth for search
117:07 - scenario so in the depth for search
117:09 - scenario we will pick one neighbor and
117:11 - we will keep going deeper and deeper
117:13 - into that neighbor so let's try to
117:16 - understand this with an example suppose
117:18 - we are again located at this position
117:20 - number a so from this position number a
117:22 - first we will pick a neighbor so let's
117:24 - say we pick again this neighbor now
117:26 - again for this neighbor we would pick
117:28 - one more neighbor so one more neighbor
117:30 - we ex now we uh concluded all the
117:33 - possibility that there this neighbor
117:35 - does not have any neighbor that we
117:37 - haven't visited so what we would do is
117:39 - we would backtrack to this position
117:41 - again see that are there any neighbors
117:42 - that we haven't visited so we actually
117:45 - check this neighbor okay this one we
117:46 - haven't visited so we visit that and
117:49 - that also did not yield any result so
117:51 - again we backtrack we come back to our
117:53 - main a then we pick another neighbor so
117:55 - let's say in this case we pick another
117:57 - neighbor called C from the C we again go
118:00 - to deep okay so this one did not yield
118:03 - it result so in this case again we check
118:05 - for this one and this one yielded the
118:07 - correct result and we again created a
118:10 - path from A to B to C and again we got
118:13 - the correct answer now you must know
118:16 - that under which situation you need to
118:18 - use breath for search and under with
118:20 - situation you need to use depth for
118:22 - search let's say that you have a graph
118:25 - and you expect B to be somewhat closely
118:30 - to your current a if you expect that in
118:32 - that case it would make more sense to
118:34 - use breath for search because you are
118:36 - more likely to find a result within some
118:38 - of the neighboring graphs but let's say
118:41 - that you have a graph that is much more
118:42 - complicated and B can be located
118:45 - somewhere down the road uh somewhere
118:48 - very far far far away in that case it
118:51 - would make sense to use a depth for
118:53 - search rather than breadth for search in
118:56 - either case the time and space
118:57 - complexity for both breadth for search
118:59 - and depth for search is actually going
119:01 - to be bigo of M cross n where M can be
119:04 - the number of vertices and N cross be
119:06 - the number of edges so it could it would
119:07 - be B of Vertes multiply by edges and all
119:11 - the operations we defined for the arrays
119:13 - they are also going to have or they are
119:15 - also going to follow the same time
119:17 - complexity that whenever we need to to
119:19 - find any any two values it is going to
119:21 - be the same now let's see that what are
119:23 - the use cases when you have to use
119:26 - graphs number one use case is actually
119:28 - social network so in Social Network we
119:31 - know that let's say that my name is
119:34 - person a so person a can be friends with
119:38 - many other person so I can be friends
119:40 - with B I can be friends with C I can be
119:42 - friends with d i can be friends with e
119:44 - something something something like that
119:46 - right and E can have their own separate
119:49 - friends so e can have friends F and uh
119:52 - Zed and all all all of that now this is
119:55 - how a typical social network looks like
119:58 - and that is why it is really common to
120:00 - use that let's say if I'm using a social
120:03 - network like Facebook where if I am I
120:05 - can only be friends with someone if that
120:07 - person is friends with me in that case
120:09 - there would be an undirected
120:11 - relationship but let's say if I'm using
120:13 - something like Instagram where some X
120:15 - person can follow me but I cannot follow
120:18 - that X person so in that case let's say
120:21 - that I have a relationship like this
120:23 - where X is following me but I'm not
120:25 - following back X so in this case we have
120:27 - a directed graph or a directed
120:29 - relationship but either cases it works
120:32 - perfectly fine next there would be a
120:34 - great use case for uh different internet
120:38 - and because in the internet we have a
120:41 - many different web pages that contains
120:43 - lot of information and we have the HTTP
120:47 - uh URLs that are are connected with each
120:49 - other on top of that from every single
120:52 - uh web page we can also have many
120:55 - different HTTP web pages that connects
120:57 - to some other web page and from that it
120:59 - can have many different web pages that
121:01 - connects to some other web page so in
121:03 - this case graph can be a good way to
121:05 - store all of that information plus I
121:08 - already mentioned that if you want to
121:09 - create a GPS system or any navigation
121:12 - system graphs are a wonderful approach
121:14 - and you cannot build a navigation system
121:16 - without using graphs where cities or
121:18 - places are treated as vertices and the
121:20 - roads are treated as edges and uh that
121:23 - is how you move move forward on top of
121:25 - that wherever you have to resolve any
121:28 - dependencies you can actually use graphs
121:31 - to resolve that dep dependency so let me
121:33 - give you a quick example let's say that
121:35 - you are studying in a university and in
121:37 - the University we know that we can only
121:39 - take courses that are like 204 or 205 if
121:43 - we already completed its prerequisite of
121:45 - 105 something like this so if that
121:48 - relationship is done done if unless I
121:50 - have completed this I cannot move
121:52 - forward to this particular course so in
121:54 - that scenarios treating different
121:56 - courses as vertices and connections with
121:58 - them between them or dependencies
122:00 - between them as edges would yield to
122:03 - Greater success in terms of all the
122:05 - results so these are all the operations
122:08 - and all the things where you must use
122:10 - graphs so first of all we are going to
122:13 - understand a graph with an example so
122:16 - this is a very simple problem and I
122:18 - might use some terms or some Concepts
122:21 - that you might not be familiar with but
122:23 - don't worry about it I would be guiding
122:25 - you throughout the whole journey and
122:27 - it's actually a quite simple way to
122:29 - understand what does a typical graph
122:30 - problem looks like and how does it work
122:33 - so number one thing in the graph is that
122:36 - for this problem we are actually given
122:37 - an N cross n Matrix and in this n cross
122:40 - n Matrix we are being told that this n
122:44 - represents the basically cities and if
122:47 - there is a path from one city that
122:49 - connects to another city then there
122:51 - would be a link in this n cross n m
122:54 - Matrix so it would Mark as one for that
122:57 - particular cell and if there is not a
122:59 - path then there won't be U any
123:01 - connection and it would be defined as
123:03 - value zero so let's try to see that what
123:06 - we need to check we essentially needs to
123:08 - calculate that how many number of
123:10 - provinces are there so what provinces
123:12 - are being defined as that let's say that
123:15 - if there is there are cities connected
123:17 - with each other then they would be part
123:20 - of a single Province so this would be a
123:22 - single Province P1 and even if there is
123:25 - a unique city that is not connected with
123:27 - each other still it is a province on its
123:29 - own so we would consider this as a
123:31 - province as well and uh let's try to see
123:34 - some examples of what different
123:36 - questions or what different things that
123:38 - we can refer so number one example is
123:40 - actually quite simple let's assume that
123:42 - we are given the CI a b and c in this
123:44 - case and we can see that City a and City
123:47 - B is connected with each other City C is
123:49 - not connected with each other so in this
123:51 - case this is a province and this is in
123:54 - itself another Province so we can return
123:56 - that in this case there are two
123:57 - provinces present and we can return two
123:59 - as the answer let's consider one more
124:01 - scenario suppose we are given uh four
124:04 - cities in this case and let's say that
124:06 - for the four cities all four cities are
124:09 - connected like this and you see that
124:11 - there is actually no connection over
124:13 - here but still we can conclude these
124:16 - cities to be connected how because let's
124:19 - say that this is a so a is connected
124:22 - with B and B is connected with C and C
124:24 - is connected with d so in this case you
124:25 - can still reach to D so all of this
124:28 - entire cluster would be considered as a
124:30 - single Province only let's take just one
124:32 - more example to make things more clear
124:35 - let's suppose we are given four
124:36 - different cities and all four different
124:39 - cities are not connected with each other
124:41 - in this case we can Define that four
124:43 - there are in total four separate
124:45 - provinces available in this case so
124:47 - let's see that what is going to be the
124:49 - approach to solve this
124:51 - problem okay so let's assume that this
124:53 - is the example we are given and this
124:55 - would be its Matrix that is going to
124:57 - represents the connection connection
124:59 - between any two cities now in this
125:01 - example we can clearly see that there
125:02 - are actually going to be three number of
125:04 - provinces uh this is the first Province
125:06 - this is the second Province and this is
125:08 - the third Province but let's see that
125:10 - how we are going to compute these
125:11 - results and for that we are going to uh
125:14 - first Mark or populate these Matrix
125:17 - basically this Matrix is already given
125:18 - to you in the example but I'm just
125:20 - showing you that what is the approach we
125:22 - are going to take in order to solve this
125:24 - problem so first we are going to see
125:26 - that uh since there is a single ended or
125:29 - one unidirectional connection between a
125:30 - to B which means we can also Define that
125:32 - there is a connection from B to a as
125:34 - well and this is what we are going to
125:36 - represent in this n cross n Matrix so
125:39 - first let's see okay so we have u a
125:41 - connection between a to B so we are
125:43 - going to mark this as value number one
125:45 - same way we have a connection between B
125:47 - to a so we are going to mark this as is
125:48 - one as well and B to C there is a
125:50 - connection so from B to C there is a
125:53 - connection same way from C to B there is
125:54 - a connection up again from D to e there
125:58 - is a connection so let's mark that from
126:00 - D to e there is a connection over here
126:04 - and same way from E there is a
126:06 - connection to d as well so let's quickly
126:10 - Mark that and uh that is over here okay
126:13 - and then F there is no connection so
126:15 - basically these are all the connections
126:17 - we have apart from that all the values
126:20 - are going to be filled out with values
126:22 - of zero we can actually consider this as
126:24 - a uh adjy Matrix for our our given graph
126:30 - and we can treat each of the Cities as
126:32 - the node of a graph and the connection
126:36 - or the edges between these cities are
126:38 - actually the edges between the these
126:41 - nodes so now all we need to do is we
126:43 - need to find the number of connected
126:45 - components and that's it so that is
126:48 - actually quite simple to do but how to
126:49 - do it I'll just show it to you quickly
126:51 - now I already mentioned to you that in
126:53 - the graph we have to keep keep track of
126:56 - the notes that we have visited already
126:58 - so that we don't encounter any issues
127:00 - with the visited uh we don't have any
127:02 - issues in the future so we are going to
127:05 - have uh basically a hash map that where
127:08 - we are going to store the values of all
127:10 - the visited values and plus we are also
127:13 - going to keep track of the neighbors or
127:15 - the connected cities for that particular
127:18 - node as so we can actually skip that in
127:20 - the future and the approach we are going
127:22 - to take is we are going to do a breath
127:24 - for search starting from any node and we
127:27 - would keep on doing it until we exhaust
127:30 - or we take care of all of these six
127:32 - cities so let's start our approach and
127:35 - the idea is that we are going to start
127:37 - working from the node a so let's mark
127:40 - that currently we are located at
127:42 - position number a so we are located at
127:44 - this position now from a we are going to
127:46 - see that what are the places it it is
127:48 - marked as one or it is connected to
127:50 - those cities and we are going to Mark
127:52 - those cities as visited so let's just
127:55 - say since because we started a new
127:57 - province with this new traversal a we
127:59 - are going to increase the number of
128:01 - provinces so this probe is defined as
128:04 - the variable that keeps track of how
128:06 - many number of provinces we have been
128:08 - able to find so initial value was zero
128:10 - and now we have value as one now from a
128:13 - we see what who is the neighbor of a so
128:15 - the neighbor of a is actually value
128:17 - number B which means means in our
128:19 - hashmap we already had entry a then we
128:21 - are also going to add entry B and this
128:23 - can actually be a hash set rather than
128:25 - hashmap what is the difference you would
128:27 - soon find out uh when we talk about
128:30 - hashing but right now just consider that
128:31 - we are marking these values so this
128:33 - would allow us to let us know that these
128:35 - are the cities we have already visited
128:37 - so we don't visit them again okay now we
128:41 - are at position number B from B which
128:44 - are the cities B is connected with so
128:46 - number one city B is connected with is
128:47 - City number a but a we have already
128:50 - visited so we are going to skip this for
128:52 - now then we are going to visit City
128:54 - number C and C we haven't visited so we
128:57 - will mark C over here okay so now we are
129:00 - at City number c what are the cities C
129:03 - has that we have we haven't visited so C
129:05 - is only connected with b and we have
129:08 - already visited B so which means we can
129:10 - conclude that in this case since we
129:12 - visited C does not have any more
129:14 - neighbors that we need to visit so we
129:16 - will do a backt trck we will go to B B
129:18 - again does not have any more neighbor
129:20 - that we have to take keep track of so we
129:22 - and once again we will backt track to a
129:24 - and a we already visited all of its
129:26 - neighbors so we can conclude this a b
129:29 - and c to be completed over here and so
129:32 - far we have been able to find one
129:34 - Province but now in this case we will
129:37 - jump or have to go to the next city d by
129:40 - taking a jump because we are not going
129:43 - through a connection from any particular
129:45 - node so that is why we are adding one
129:47 - more Province or we are exploring one
129:49 - more Province so we will increase the
129:50 - number of Province to two and in this
129:53 - case uh at City number D we are going to
129:56 - visit all the neighbors of D in breath
129:58 - for search manner so since D only has
130:01 - one neighbor that is City number e so we
130:03 - are going to go to City number e and we
130:05 - are going to Mark uh both d and e as
130:08 - visited in our hashmap on top of it with
130:11 - e e only has one city as its neighbor
130:14 - and that is City number D so in this
130:16 - case we have already visited D which
130:17 - means we can Al conclude both d and e to
130:19 - be visited as well and now we will have
130:22 - to still go to a city that we haven't
130:25 - visited so far that is City number have
130:27 - the moment we go to a new city we are
130:28 - going to increase the number of
130:29 - provinces so now number of provinces is
130:32 - going to be three and we are going to
130:33 - say that we are currently visiting City
130:35 - number F now F does not have any more
130:38 - Neighbors which means we can conclude
130:40 - that from F we cannot go anywhere else
130:42 - and now we have visited all the cities
130:45 - that were present because we have that
130:47 - value in our hashmap and we so far we
130:49 - have been able to find three different
130:51 - provinces connected using this manner so
130:54 - this is how typically a graph problem
130:56 - operates where in most of the cases you
130:59 - are going to have vertices you are going
131:01 - to have edges you are somehow going to
131:04 - iterate over all the vertices through
131:06 - edges and you are going to use an
131:09 - adjacency Matrix Or adjacency List uh uh
131:13 - as the way that stores the information
131:15 - of what the graph is and most like you
131:18 - are going to use either hashmap or hash
131:21 - set to keep track of the Cities you have
131:23 - already visited so you don't end up in a
131:26 - a continuous loop so let's see the Java
131:28 - solution for number of provinces problem
131:30 - basically uh we are we are given the 2x2
131:34 - or n cross n Matrix that defines that
131:37 - what are the components that are
131:38 - connected with each other so first of
131:40 - all we are going to define a number n
131:42 - that is be that is going to be the
131:43 - cities that we have and we are going to
131:45 - create a Boolean visited array to keep
131:47 - track of all the cities that we have
131:49 - visited so far initially the number of
131:51 - provinces are going to be zero and then
131:53 - we are going to run a for Loop to
131:55 - iterate over all the given number of
131:57 - provinces and initially we are going to
132:00 - check that whether that particular city
132:02 - has been visited or not if it is not
132:04 - being visited then we we will go to our
132:07 - BFS call or breath for search call and
132:10 - uh recursively try to find the solution
132:12 - and every time uh the Call Comes Back we
132:14 - are going to update the number of
132:16 - provinces now in the end we are simply
132:18 - going to return the number of provinces
132:19 - now let's see that how does our BFS
132:21 - function works now since we are doing
132:23 - breath for search breath for search can
132:26 - be done using a cube so we are going to
132:29 - first of all initialize a cube and uh we
132:31 - are going to have a link list for the
132:33 - cube you can have lot of data structures
132:35 - s Cube so first we are going to start
132:38 - with the start value then we are going
132:40 - to mark that start value as V visited
132:42 - and then through that start value we
132:45 - will keep on iterating to its neor
132:48 - neighboring cities until we have visited
132:50 - all the values inside the current q and
132:53 - the moment as Q is empty we are going to
132:55 - jump out and say that okay now we have
132:57 - visited all the connected cities and
133:00 - throughout our connection we are marking
133:02 - those cities as visited so that's how we
133:05 - are we have been able to calculate uh
133:07 - all the connected cities as visited and
133:09 - only increasing the number of provinces
133:11 - for the new cities now let's try to run
133:13 - this
133:14 - code okay seems like our solution is
133:17 - working let's submit this code code and
133:19 - our codee runs pretty efficiently
133:21 - compared to lot of other Solutions so
133:23 - you can imagine that how a combination
133:25 - of data structures are being used to
133:27 - solve a simple problem and uh KN knowing
133:32 - all of these data structures would help
133:34 - you quite significantly in order to
133:36 - break down and solve a problem and
133:38 - generate the algorithm for that
133:42 - problem okay now we will learn about
133:44 - hash based data structures now hash
133:47 - based data structure are actually quite
133:49 - unique in nature plus they have their
133:51 - own set of uh very important use cases
133:55 - that you are going to see out throughout
133:56 - your data structure and algorithm
133:58 - problems so first let's understand that
134:00 - what does a hash based data structure is
134:02 - typically when we talk about hash based
134:04 - data structure we are usually talking
134:06 - about a hash map and a hash set now both
134:11 - are quite similar in nature and both
134:13 - have very similar properties but the
134:15 - only difference is that hashmap is
134:17 - typically used used for to store a key
134:19 - value based uh mechanism where we have
134:22 - some key that we use to search through
134:25 - the given uh data structure so it will
134:28 - give us an idea that what are the things
134:30 - currently present inside our given data
134:32 - structure and what are the values
134:34 - associated with that hash set is uh
134:36 - where we only save hash based keys so
134:40 - nothing more than that so now first
134:42 - let's understand that what does a hash
134:44 - map is how to use it we will see an
134:47 - example of how it is being used uh in an
134:49 - actual interview and then we will learn
134:51 - about hash set so hashmap as I already
134:54 - mentioned that there are two properties
134:56 - associated with that first one is a key
134:59 - and second one is a value now let's try
135:01 - to understand hashmap from a real life
135:04 - point of view if you have ever seen any
135:07 - kind of dictionary well typically the
135:09 - dictionary is a very close example of a
135:12 - hashmap where in the dictionary
135:14 - typically on the first page we usually
135:16 - have an index index page and in that
135:18 - index page we are given the information
135:21 - that uh a starts from page number one uh
135:24 - something like B starts from page number
135:26 - 15 and so on and so forth and this is
135:29 - usually sorted so if we have to find any
135:31 - particular value all we need to do is go
135:34 - to the index page in the index page we
135:36 - can find the information that okay uh
135:38 - letters starting from um M are actually
135:41 - stored at page number 53 then all we
135:44 - need to do is that in our dictionary or
135:45 - in our book just go to page number 53
135:48 - and we would be able to find the meaning
135:50 - of word man or map or anything that it
135:53 - would be present over there so this is
135:55 - the actual idea being used in the inside
135:58 - the hashmap as well where we are given
136:01 - two items or we are storing two items
136:04 - first item is a key and second item is a
136:07 - value now key is going to be the hash
136:10 - function that is a some computational
136:13 - method so this is usually the hash
136:17 - function we Define where the values are
136:20 - being stored as keys and whenever we
136:22 - need to search inside our hashmap that
136:25 - whether this particular key is present
136:27 - or not we can do that in B of one time
136:29 - in constant time so let me give you an
136:31 - example of how does this actually work
136:34 - let's try to understand that we
136:36 - currently have five different values
136:39 - that we are trying to store and these
136:41 - five values are 11 12 13 14 and 15 now
136:46 - for these values I want to create a
136:49 - hashmap function where I want to retrive
136:52 - these data in the quickest manner
136:54 - possible which means I already know that
136:56 - these five are going to be my values but
136:59 - I need to create keys for them and the
137:01 - key I'm creating is that I create a
137:04 - method where I say that any particular
137:06 - value that comes in I'm just creating a
137:09 - basic hash function so you would get an
137:11 - idea that I create a method where any
137:14 - particular value that comes in I'm going
137:16 - to divide that value by five and
137:19 - whatever the remainder is so the
137:21 - remainder I'm going to treat it as a key
137:25 - and now let's see that how would this
137:27 - work so first let me draw my hashmap and
137:30 - inside the hashmap I'm going to have two
137:32 - values key and value so first value is
137:34 - 11 that I'm need I'm trying to input so
137:36 - I'm going to divide 11 by 5 so 11 by 5
137:40 - is going to yield me the remainder as
137:42 - one I'm only concerned about the
137:45 - remainder I'm not concerned that what
137:46 - does the division value comes in so
137:49 - remainder is going to be one so I'm
137:50 - going to create a value over here where
137:52 - the key is one and its Associated value
137:56 - is going to be 11 same way for Value
137:59 - number 12 the remainder is going to be
138:01 - two so once again I have an entry two
138:03 - and the value is 12 same way there is uh
138:06 - for 13 we have value number three and
138:09 - the value is three for 14 we have value
138:12 - number four and value number uh uh 14
138:15 - and the last one is the value number 15
138:19 - so what should be the key for Value
138:21 - number 15 well if you guessed five
138:24 - that's wrong actually the key should be
138:25 - zero because remainder in this case is
138:27 - actually zero when you divide uh 15
138:30 - divided 5 you actually get the remainder
138:32 - as zero so 0o is associated with value
138:35 - number 15 now I have these currently
138:39 - these values being stored now let's say
138:41 - in my program for some purpose I want to
138:44 - check that whether in our hash map do we
138:47 - all already have value number 13 or not
138:49 - so what I'm going to do in this scenario
138:51 - is that for Value number 13 I'm going to
138:54 - uh basically divide this 13 by 5 so I'm
138:57 - going to check that remainder is equal
138:58 - to 3 now this remainder is actually my
139:01 - key so then I would go to the hashmap
139:03 - and say that hey hashmap do you have any
139:06 - value where key is equal to three so
139:08 - hashmap would say that yes I have key is
139:10 - equal to three present but I don't know
139:12 - what value is so you would say okay
139:14 - bring me this value so you you fetch
139:17 - this value and this value it turns out
139:19 - to be 13 and then you would be able to
139:21 - say that okay in my hashmap I have a
139:24 - value 13 that is stored currently
139:26 - present and then I can do some
139:27 - competition with this now can you
139:31 - identify some issues with the hash
139:33 - function I have created uh let me just
139:35 - draw the hash function again and
139:38 - currently these are the values I have
139:41 - and the associated values are 11 12 13
139:44 - 14 and 15 now this is currently my my
139:47 - hash function okay so far it looks good
139:50 - but now let's say that I'm trying to see
139:53 - that does value 61 exist in in my hash
139:56 - map or not so what would my Approach is
139:58 - going to be once again I'm going to do
139:59 - 61 divid 5 and remainder is going to be
140:02 - 1 so once again as a remainder I'm going
140:04 - to go to the hashmap and see that okay
140:06 - hey for this key number one what is the
140:09 - value associated with this the value
140:11 - Associated right now is only 11 so I can
140:14 - say that 61 is currently not present in
140:16 - the hashmap once again I got this result
140:18 - in big off one time but now what if it
140:20 - happens that I want to add 61 to my hash
140:23 - map as well well in this scenario I
140:26 - since the key can only remain constant
140:29 - so which means for this key 1 I have one
140:32 - more entry that is 61 that I need to add
140:35 - over here so in the place of value I
140:37 - might I might need to create something
140:39 - like a link list because there is a
140:41 - collision over here of the keys because
140:43 - the number of values are more and keys
140:46 - are less yes so in this kind of scenario
140:49 - collisions are bound to happen and
140:51 - because there is a collision now I have
140:53 - value number 61 let's say the value is
140:55 - 71 I'm trying to add so once again I
140:57 - will add one more node in the link list
140:59 - and I would add value number 71 over
141:01 - here so so far let's assume that
141:03 - initially when we only had five values
141:06 - we actually had five keys and five
141:09 - values so the equation was almost one to
141:12 - one relation and we were able to fetch
141:14 - any particular data in big of one time
141:17 - but now let's assume that we still keep
141:19 - only five keys and now we have uh for an
141:22 - example one 1 million entries so in this
141:25 - scenario or let's say 5 million entries
141:28 - and five keys so mathematically every
141:32 - single key would have 1 million entries
141:35 - ass associated with that particular key
141:37 - and in that case all of these 1 million
141:40 - values would be stored in a link list uh
141:43 - in the value section connect where one
141:45 - node is connected with the another node
141:47 - so so once again in this kind of
141:49 - scenario if I have to fetch any value
141:52 - now now it it's going to take big of end
141:54 - time where n is going to be 1 million in
141:57 - this case so this is actually really bad
141:59 - so in the hash whenever you are building
142:01 - your own hash map you need to make sure
142:03 - that the hash function you are you are
142:05 - using to build evenly distributes the
142:08 - values which means that for any single
142:10 - value typically the hash function tends
142:12 - to be a unique set of key and that is
142:15 - one of the biggest consideration now now
142:17 - lucky for us most of the programming
142:19 - languages like Java python or whatever
142:22 - you can think of they already have this
142:24 - functionality of implementing a very
142:26 - good hash function that usually tends to
142:28 - be unique and implements the keys in the
142:31 - unique manner so we don't have to worry
142:33 - about it all we need to do is just
142:35 - declare the hashmap and uh we need to
142:37 - declare that what type of key and value
142:39 - pairs are we are going to store so we
142:41 - can store like integer as the key and
142:44 - string as the value and then we can name
142:46 - our hash map as something like my
142:48 - hashmap and then we simply need to
142:50 - initialize it and that's it so this way
142:53 - it's it becomes really powerful so
142:55 - always make sure that even during the
142:57 - interview interviewers love asking this
142:59 - question that uh how do you handle
143:01 - Collision in your hashmap so typically
143:03 - you would assign a link list for to
143:06 - store values when you predict a scenario
143:08 - where there is going to be a collision
143:10 - in terms of values now let's see that
143:12 - what are the different operations we can
143:14 - do for any given hashmap and I'm going
143:16 - to store some values so let's say one is
143:19 - associated with 11 and two is associated
143:21 - with 12 so this is our current hash map
143:23 - right now hashmap tends to be dynamic in
143:25 - nature so which means that uh all the
143:28 - values you want want to assign if you
143:30 - want to keep on adding more and more
143:32 - values in this scenario essentially you
143:34 - don't have to do anything it will
143:36 - usually takes care of it and most of the
143:37 - languages are sophisticated enough to be
143:39 - smart in that regard so that is really
143:41 - good for us now first operation we can
143:44 - do in hashmap is we can add a value so
143:46 - typically this is done by using
143:48 - something called a put variable uh and
143:51 - we can put a new value inside the
143:53 - hashmap and this is usually done in big
143:55 - off one time where we need to provide
143:57 - the value of a key and Associated value
143:59 - with that remember key cannot be a null
144:03 - value you can have a key uh that does
144:06 - not have any value associated with that
144:08 - that's fine but still key cannot be a
144:10 - null value you cannot have a value that
144:12 - does not have a key associated with that
144:14 - in the hashmap second operation we you
144:16 - can do is you can delete any value from
144:18 - the hashmap and this is also done in big
144:20 - off one time so that's great next
144:23 - operation you can do inside the hash map
144:25 - is that you can search for any element
144:27 - and searching also takes big off one
144:29 - time because we are using the property
144:31 - of key value pair and we are searching
144:33 - using the keys we are not searching
144:35 - using the values so that is an important
144:38 - distinction you have to understand
144:40 - whenever you are trying to think that
144:42 - how you're going to use hashmap to
144:44 - achieve your goal next uh operation we
144:47 - can do is we can actually sort all the
144:50 - values but that we need to do it
144:52 - sequentially so there is no inherent
144:55 - method to do that so essentially this is
144:57 - still big of n log n uh time operation
145:00 - where you need to uh call some other
145:02 - data structure and then you need to
145:04 - populate all the values uh let's see
145:06 - what are other operations we can do you
145:08 - can of course you can modify all the
145:10 - values that are currently present and
145:11 - that can be done in B of one time and
145:14 - that's it so now you can see that uh
145:17 - hashmap on paper looks pretty good
145:18 - because all the operations that you can
145:20 - think of insertion deletion addition
145:22 - modification uh searching sorting
145:24 - they're all pretty fast and pretty
145:26 - efficient uh there is one big issue with
145:29 - the hashmap and that big issue is that
145:32 - you cannot have duplicate keys so uh the
145:36 - key value has to be unique so no
145:39 - duplicate keys and also the duplicated
145:42 - values would be stored under the same
145:45 - key because key these are typically
145:47 - generated based on based on their values
145:50 - so always remember that duplicate values
145:52 - cannot reside inside the hashmap and now
145:56 - let's see that how does a hash set work
145:59 - and then we will see an example of a
146:01 - typical hashmap problem so hash set is
146:04 - very similar to hashmap but the only
146:06 - difference is that inside the hash set
146:08 - there is no concept of key value pair it
146:10 - is only just the values that are being
146:12 - stored but these values are typically
146:14 - stored using the hash function so uh
146:17 - let's say that I currently have values 1
146:19 - 5 15 uh 31 and 21 uh that I need to
146:23 - store so so far I have stored these four
146:25 - values inside my hash uh set so I can of
146:29 - course enter these values 11 15 uh 31
146:33 - and five now I want to check that
146:34 - whether 21 value is present inside the
146:36 - hash set or not so I can check this in
146:39 - big of one time why because just like a
146:42 - hash map hash set also uses the hashing
146:44 - function it just doesn't store the key
146:47 - but still it calculates based on the
146:49 - value that you are trying to input so
146:51 - there is going to be a mathematical
146:53 - function that operates and that would be
146:55 - able to immediately identify that
146:56 - whether this value has been processed
146:58 - and stored inside the headset or not and
147:00 - uh it's not stored so I we can add this
147:02 - entry now again just like hash map hash
147:06 - set also does not allow duplicates so
147:09 - there is there are no duplicated entries
147:10 - over here and uh one good property that
147:14 - since there are no duplicated entries
147:16 - allowed whenever you need to check that
147:18 - in any other data structure like a link
147:20 - list or um an array if any duplicated
147:24 - entries exist you can actually use
147:25 - hashset to solve that kind of problem
147:27 - quite easily and there are many use
147:29 - cases for that as well uh once again if
147:32 - we look at the operation operations are
147:34 - pretty much the same so uh everything
147:36 - like uh adding value takes big off one
147:39 - time once again deleting also takes big
147:41 - of one time uh searching takes big of
147:43 - one time sorting takes big of uh and log
147:47 - and time so this you can usually
147:49 - consider very similar to hashmap the
147:52 - only difference is that in the hashmap
147:54 - you can actually store the correlation
147:56 - between key and value in the hash set
147:58 - you only store the
148:00 - value now let's try to understand couple
148:02 - of examples through which we will
148:04 - understand both hash map and hash set so
148:08 - let's say for an example we are given
148:10 - suppose an array a where we are given
148:13 - five different elements and now our job
148:15 - is to check that whether
148:17 - uh the array contains any duplicate
148:19 - element or not and if it does what is
148:21 - the duplicate element so let me give you
148:24 - an example suppose the values are 5 3 1
148:26 - 2 and 3 so we can see that three is the
148:29 - duplicated element and the purpose of
148:32 - our program is to check or find that
148:34 - whether there is a duplicate element or
148:36 - not and if it if yes then which is the
148:39 - duplicated element so first let's
148:41 - understand that what would be the Brute
148:42 - Force approach in this scenario well it
148:44 - is quite simple we just take take any
148:47 - element so let's say we take element
148:49 - number five in this case and then
148:50 - iterate over the rest of the array to
148:52 - see that whether Val value five is
148:54 - present or not if it it's present we can
148:56 - return true if it's not present we can
148:58 - return false and go to the next element
149:00 - so for three we will repeat the same
149:01 - process and we would find that three is
149:03 - also present in this case so we will
149:05 - return return three as a duplicated
149:06 - element but this approach yields the big
149:08 - of n Square time complexity because for
149:11 - every n element we are essentially doing
149:13 - n minus one work so that is a
149:14 - multiplication factor and uh which is
149:17 - not too good so let's see what would be
149:19 - the better solution so better solution
149:21 - would be that uh if we try to sort this
149:24 - given array then things would become
149:26 - easier so if we sort this input we will
149:28 - get an array that looks like this that 1
149:30 - 3 uh sorry 1 2 3 3 and 5 so in this case
149:35 - uh then we only need to check the
149:37 - adjacent values and here we would be
149:39 - able to see that these two adjacent
149:40 - values are same so we would return
149:42 - return three as the answer now this
149:44 - better solution where we are sorting the
149:45 - array that is also bigo of n log n time
149:49 - solution so could there be a better
149:52 - approach and the answer is yes and that
149:54 - is by using a hash set in this scenario
149:57 - so what we would do is we would
149:58 - initialize a hash set our algorithm
150:00 - would be that we would first check that
150:02 - whether any element if that is present
150:05 - inside the hash set or not if it is
150:07 - present already and it is also in the
150:09 - array then we can consider that to be a
150:11 - duplicated element if it is not present
150:14 - then we would simply add that element to
150:15 - our ha set so let's try to run this
150:18 - method so first we would add value
150:19 - number five over here because it is not
150:21 - present already uh so then after adding
150:24 - it we would move to the next element now
150:26 - value number three is not currently
150:28 - present inside the haset so we would
150:30 - again repeat the same process then again
150:32 - we would repeat the same process for
150:33 - Value number one and again we would
150:35 - repeat the same process for Value number
150:37 - two and all of this insertion would take
150:39 - big go of one time Plus checking that
150:41 - whether the element is present or not
150:43 - that would also take big off one time so
150:45 - this is not any uh additional overhead
150:48 - now when we are at position number three
150:50 - we check that whether three is already
150:52 - present inside the hash set or not
150:54 - within big go of one time we would be
150:56 - able to find out that three is already
150:58 - present which means we would know that
151:00 - three is the duplicated element and we
151:02 - can return true in this case that yes
151:04 - this array does contain a duplicate
151:05 - element and if we are being asked to
151:07 - pass on that which value is repeated we
151:09 - can return three in the answer so either
151:12 - case this hash set works perfectly fine
151:15 - now what would be the solution in this
151:16 - case or the time complexity well time
151:19 - complexity is going to be biger of n
151:21 - because we are going to only iterate
151:23 - over the element or this array ones to
151:25 - solve this problem but in this case
151:27 - space complexity is also going to be
151:29 - bigger of one uh bigger of n because we
151:32 - need to create an additional hash Set uh
151:34 - and its size is dependent on the number
151:37 - on the given input now let's see that uh
151:40 - this would be an example where we would
151:42 - use hash set to solve the answer but now
151:44 - consider a scenario that in the same
151:46 - example uh we are being asked that
151:49 - rather than just giving out the value of
151:51 - the uh duplicated element give us the
151:54 - index value so again let's see that how
151:56 - would that scenario work suppose this is
151:58 - the uh given new array and we need to
152:01 - return the index elements of the
152:03 - duplicated element how what should be
152:05 - our approach once again we already know
152:07 - that brute force and uh sorting approach
152:09 - already works the way it does in this
152:12 - scenario as well but in this case since
152:13 - we need to return the index values hash
152:17 - set would not be the optimal choice and
152:19 - it would make sense for us to use a hash
152:21 - map where inside the hash map we would
152:24 - actually create a key value pair based
152:26 - database where in the key we are going
152:29 - to Mark these values and as their
152:32 - subsequent values we are going to Mark
152:34 - the index positions so when we need to
152:36 - fetch that which index positions are
152:38 - duplicated we can return that quite
152:40 - easily so now let's see the solution in
152:43 - this case so for first of all we would
152:45 - check whether five is is present or not
152:47 - five is currently not present inside our
152:48 - hash map so we would add an entry called
152:50 - five and we would add its index location
152:53 - zero now again one is also not present
152:55 - so we would add entry one and its index
152:57 - location is one three is also not
152:59 - present so three and index location two
153:01 - and four is not present so four and
153:03 - index location three now again this is
153:06 - key value pair so you understand what
153:07 - I'm doing now when we are at this
153:09 - position number five or position number
153:11 - four uh where the value is one we try to
153:15 - add one but we already see that one is
153:17 - already present because it is marked as
153:18 - a key and this operation can be done in
153:20 - big off one time because it's a hashmap
153:23 - so since we already found that we can
153:26 - actually return one uh is the duplicated
153:29 - entry and if we want to return the index
153:31 - positions we can return the index
153:32 - position from here that would be four
153:34 - and the value of this key one so that
153:37 - would be one and this would be the
153:39 - answer we need to return in this case so
153:41 - you can understand that how quickly we
153:43 - are able to solve problems using hash
153:46 - map or hashset and uh we are going to
153:48 - use them throughout this course for
153:51 - bunch of different problems so you
153:52 - should be able to understand them quite
153:57 - easily now after learning most of the
153:59 - basic data structures we are going to
154:01 - learn couple of advanced data structures
154:03 - and these Advanced data structures are
154:05 - actually quite popular in technical
154:07 - interviews and also a lot of
154:08 - computational problems as well so there
154:11 - are quite a lot of advanced data
154:13 - structures but we are going to shift our
154:15 - focus on two two main ones first one is
154:18 - called Heap and second one is called try
154:21 - now both are combination of various data
154:23 - structures but they have a very specific
154:25 - use cases where it is really popular and
154:28 - really powerful so first let's
154:30 - understand that what a heap is Heap is
154:33 - typically an extraction of a binary uh
154:36 - tree tree based data structure where it
154:39 - it maintains the property of a binary
154:41 - tree which means any single node has at
154:43 - most two children and it tries to
154:45 - balance out this property as quickly as
154:48 - possible and even if there is an anomaly
154:50 - it would only be at one of the positions
154:52 - where the number of children would be
154:54 - one but nothing more than that so you
154:56 - would never encounter a scenario where
154:58 - any single node has three children or
154:59 - something like that so after that there
155:02 - is also one more important property for
155:04 - a heap and that is that it is a common
155:07 - implementation for a typical priority
155:09 - Cube and we all know that in a priority
155:11 - Cube the most important thing is higher
155:13 - or lower priority depending on that so
155:16 - in the Heap usually we use it to keep
155:19 - track of uh the maximum value out of any
155:22 - given incoming data stream or the
155:24 - minimum value of uh any incoming data
155:27 - stream and both have very significant
155:30 - purposes and very significant importance
155:32 - in many of the questions so first let's
155:34 - try to understand that how does a
155:36 - typical Heap looks like how does it work
155:39 - and then we will see some examples so
155:41 - first we will try to implement a minimum
155:43 - Heap now the property of a minimum he
155:46 - Heap is that number one it is going to
155:48 - maintain the binary tree nature so one
155:50 - node is going to have at most two
155:52 - children number two is that every single
155:56 - parent is going to have less value than
155:59 - its child and number three property is
156:02 - that all the nodes that we would try to
156:04 - enter first we would enter in the root
156:06 - position if the root is already filled
156:08 - we would try to enter that node into the
156:10 - leftmost position if that is also filled
156:12 - then we would try to enter that node as
156:14 - a right child for any particular empty
156:17 - location so we would try to find the
156:18 - location first once that is done we
156:21 - would sort of heapify the given input or
156:24 - the our given Heap to maintain this
156:26 - property so let's see this in action
156:30 - suppose uh currently we have an empty
156:32 - Heap so let me draw an empty circle and
156:35 - now let's assume that the first value we
156:37 - are trying to enter is going to be value
156:39 - number five so initially we are entering
156:41 - value number five over here now the next
156:43 - value we try to enter let's assume that
156:45 - that is value number 10 so remember the
156:49 - scenario is first we will try to add it
156:51 - to the root value root we already have
156:53 - added which means we will try to add in
156:55 - the left children so let's add the
156:58 - number 10 in the left child and after
157:00 - adding that we need to check that
157:02 - whether this property has been
157:03 - maintained or not that whether the
157:05 - parents value is less than the children
157:07 - value or not and in this case since five
157:10 - is the parent it is less than 10 so this
157:13 - is currently correct so we do not need
157:15 - to do he operation for this step now
157:17 - let's see one more element so suppose we
157:20 - try to enter value number 15 now again
157:23 - 15 needs to go to uh either root place
157:26 - but root is already filled so it needs
157:28 - to go to left that is also filled so it
157:30 - will go to the right place and right
157:32 - place after adding 15 we would again
157:34 - check that whether the he5 property is
157:36 - maintained so again parents is still
157:38 - smaller than children so that is good
157:40 - now let's try to enter the value number
157:43 - 25 so once again 25 will go go to the
157:46 - left position and so far everything
157:48 - seems to be working okay no issues with
157:50 - this now let's try to enter the value
157:52 - number seven now again by this logic
157:56 - first of all seven has to enter to the
157:58 - right available position so this is not
158:01 - available this is not available but this
158:03 - position is available so let me enter
158:05 - seven over here but does there an issue
158:09 - with parents being lesser than child yes
158:12 - there is in this case seven is smaller
158:14 - than uh value number 10 so we would have
158:16 - to do the he5 operation so we would move
158:18 - seven from here and we would make it as
158:21 - parent and 10 would come to this place
158:24 - okay now everything is good so far now
158:27 - let's say that we try to enter value
158:28 - number 31 once again 31 would be entered
158:32 - over here and the property is still
158:34 - maintained now let's try to enter value
158:36 - number two so by default value number
158:38 - two is going to come over here but since
158:40 - two is smaller we will have to make a
158:42 - shift over here so let me quickly shift
158:45 - the values so now 2 is going to come and
158:49 - 15 is going to come over here once again
158:51 - two is still smaller so once again we
158:53 - will have to do a shifting operation so
158:56 - in the end two is going to come over
158:58 - here and five is going to come over here
159:00 - and now the Heap has been maintained so
159:02 - this is how typical Heap operates now in
159:05 - this case if you see always the parent
159:08 - is going to be smaller than its children
159:10 - so currently for the entire Heap we have
159:14 - the smallest value POS positioned at the
159:16 - root position so this is whenever if we
159:19 - have to identify that hey we have an
159:21 - incoming constant data stream that is
159:23 - coming in and we want to find that what
159:25 - is the minimum value at all times we can
159:27 - actually use Heap because it's a self
159:30 - adjusting uh algorithm or data structure
159:33 - that maintains its property of whether a
159:35 - Min Heap or Max Heap so in this case we
159:38 - can identify that okay the minimum value
159:39 - is going to be the value at our very
159:42 - first node and maximum value is going to
159:44 - be some value amongst the these Leaf
159:46 - node so in this case maximum is going to
159:48 - be 31 but we are not bothered about it
159:50 - right now now once again if we take any
159:53 - subtree so let's say in this case once
159:54 - again parent is still going to be
159:56 - smaller than child once again parent is
159:59 - still going to be smaller than children
160:01 - so Heap is a great algorithm whenever
160:04 - you need to keep track of that hey I
160:06 - have an continuous incoming stream of
160:09 - data coming in and I want to check the
160:11 - fifth smallest value from the beginning
160:15 - so in that that case Heap would be an
160:16 - ideal choice where you keep track of all
160:19 - the values in a Min Heap and then you
160:21 - essentially needs to go and select the
160:23 - fifth smallest value which can be done
160:25 - in log and time so that's great you will
160:28 - get the answers quite quickly now let's
160:30 - see an example for a Max Heap and Max
160:32 - Heap also works in the similar fashion
160:34 - the only difference is that now the
160:37 - value of parent has to be greater than
160:39 - the value of child so let's see that
160:41 - first we are try we have the element and
160:44 - we are trying to add value number two
160:45 - over here now the next element we are
160:47 - trying to add is value number three so
160:48 - in this case we will have to do an
160:50 - adjustment so first we will add three
160:51 - over here and then we will do our HEI so
160:54 - we would adjust the values so now three
160:56 - would be the maximum value and two would
160:58 - be the smallest value now we are trying
160:59 - to add value number 15 once again first
161:02 - we will add 15 over here but then again
161:04 - we will do the hepy principle and we
161:06 - will flip the values so 15 will become
161:08 - over here and three will come over here
161:10 - now we want to add value number five so
161:12 - by default five would be added over here
161:14 - but once again we are going to do over
161:15 - ep5 operation so according to that logic
161:18 - five will come over here and two will
161:20 - come over here and same way we can
161:22 - maintain a Max Heap as well so in this
161:25 - case whenever you would see the root
161:28 - node is going to be the maximum element
161:30 - at any given location for any particular
161:33 - subtree the parent is always going to be
161:35 - greater than child and Heap is going to
161:38 - Bubble Up and maintain its Max Heap
161:40 - property so this is how typically we use
161:43 - Heap in order to keep track of min
161:45 - minimum value or maximum value at any
161:47 - given moment on top of that we also keep
161:50 - track to for any questions like find the
161:54 - K largest value or k smallest value from
161:57 - the top so in either case the Min Heap
162:00 - and Max Heap or are going to be the
162:04 - ideal choice to solve these kind of
162:06 - problems and we would see bunch of
162:08 - operations later on in the course so now
162:11 - let's try to see that what are going to
162:13 - be the time and space complexity so
162:15 - ially the time complexity in order to
162:17 - insert any element inside the Heap is
162:19 - actually big go of logarithmic n why log
162:22 - n because it is already a sorted tree
162:25 - structure whenever we try to enter any
162:28 - value in any particular location we
162:30 - simply need to find that what would be
162:32 - the right place for it to be so at most
162:36 - all we need to do is make change to
162:38 - couple of places and then we can
162:39 - actually find its correct location so
162:42 - insert insertion is login same way
162:44 - deletion is also login same way finding
162:47 - anything is also login so this is a very
162:49 - powerful and very fast data structure uh
162:52 - from many point of you and that is why
162:54 - it has lot of use cases in the real
162:56 - world scenarios so this is the example
163:00 - of Heap now let's try to understand that
163:02 - what does a TR data structure looks like
163:05 - now try is also uh an additional
163:08 - abbreviation of a tree based data
163:10 - structure now inside the try uh we
163:14 - actually use try on a daily basis so
163:17 - whenever you see any system that uses
163:20 - autocorrect functionality so that is
163:22 - actually using a try so this covers your
163:25 - iPhone Android phone your messaging app
163:27 - anything plus wherever you see
163:28 - predictive searches so what do I mean by
163:30 - predictive search uh you can imagine
163:33 - that whenever you try to search anything
163:34 - on the Google or Amazon it automatically
163:37 - completes the statement for you and for
163:39 - that actually behind the scenes it is
163:41 - using try as a data structure so try is
163:44 - a very powerful tool since you can see
163:46 - that it has lot of practical
163:47 - applications and also remains favorite
163:49 - amongst technical interviews as well so
163:52 - that is why we are going to understand
163:54 - what a try is basically try typically
163:57 - operates on a string based characters so
164:00 - wherever you have bunch of different
164:02 - characters that you that you working
164:04 - with and you want to store them in a
164:07 - sequential manner where depending on the
164:11 - values you enter in the character You
164:13 - can predict the next element you can
164:15 - actually use a try so how does a try
164:17 - typically work is typically it has a
164:19 - root node and this root node tends to be
164:21 - an empty node but in its children we are
164:24 - going to store all the uh alphabets that
164:27 - are possible so typically in a real life
164:30 - try there would be 26 children one for
164:33 - each character from a to zed but in this
164:35 - case let's just let's just consider our
164:37 - example small and concise so we would
164:40 - try to add five different words to our
164:42 - try and we would see how they they would
164:45 - look look like so first word we are
164:46 - going to add is going to be the word rat
164:49 - second word is going to be R third word
164:51 - is going to be uh
164:54 - men and fourth word we would be uh let's
164:58 - say tree and fifth word would be uh try
165:04 - so these are the words we are trying to
165:05 - add first so let's just start with first
165:09 - one so first we will try to add R so we
165:11 - are going to create a child over here
165:13 - called r then the next word is a so
165:16 - again R is going to have a sub child
165:19 - called a and next word is t so T is
165:22 - going to going to be the child of a and
165:25 - now since this word has ended so now
165:27 - this is going to be an end node so we
165:29 - can determine this as a star or
165:31 - something okay that defines that this
165:33 - word currently ended over here now next
165:35 - word we are trying to add is R so once
165:37 - again from our root node we are not
165:39 - creating we are not going to create a
165:41 - separate child for R we are actually
165:43 - going to create a r as it as it is and
165:46 - then we are going to create a sub Branch
165:49 - so this R has already been taken care of
165:51 - now there is the word a so once again
165:54 - for a we are not going to create a new
165:56 - Branch but we are going to treat this R
165:58 - A to be of the same group so now you can
166:01 - see that how different words can be
166:03 - stored within a tree like data structure
166:06 - by their character properties because
166:08 - they are all connected with each other
166:10 - very deeply and next one is p but over
166:13 - here the next word is actually T so in
166:16 - this case we are going to create a new
166:17 - Branch over here and this new branch is
166:20 - going to have value number P and since
166:22 - the word ends over here we are going to
166:25 - have an ending node so that is denoted
166:27 - by star so now whenever I start typing r
166:31 - a uh the system would come over here and
166:34 - then system would predict that either
166:36 - I'm typing r a rep or r a rat and then
166:40 - that is how it is able to do a
166:42 - predictive search let's say that I print
166:44 - uh I type something like r a r rare but
166:48 - the system knows that rare is not a
166:50 - valid word which means system would
166:52 - predict that either the valid word has
166:54 - to be r or R so depending on the con uh
166:57 - context of the entire statement you are
166:59 - trying to make it will automatically
167:02 - adjust the word that you are writing and
167:04 - over here it would from this it might
167:07 - autoc correct it to the word rat and uh
167:09 - things would work fine so this is how
167:12 - typically autocorrect functionality
167:13 - works now let's try to add the word man
167:15 - over here now for M there is no child so
167:18 - we are going to create a new child and
167:20 - once again we are going to create a new
167:22 - child and we are going to create a new
167:23 - child and then we are going to create an
167:25 - end node so this is how men would look
167:28 - like now let's try to create the word
167:30 - tree so once again for tree uh we do not
167:33 - have any child so let's create a new
167:35 - branch and we are going to start with
167:38 - word t now next one is r and next one is
167:42 - e and next one is going to be e and then
167:45 - there is an end node but now let's try
167:49 - to add one more word try t r i e so we
167:52 - can already see for T and R it is going
167:55 - to have the same path or same Branch but
167:58 - now it is going to have a separate
167:59 - branch called I and then it is going to
168:02 - have a separate branch called e and then
168:05 - it would end the word essentially so
168:07 - this is how using just these three
168:10 - branches we can actually navigate all of
168:13 - these five uh words
168:15 - so this is the true power of the TR data
168:18 - structure and uh try is pretty popular
168:22 - in lot of technical interviews and
168:24 - wherever you see the example where you
168:26 - are given bunch of different words and
168:28 - you are trying to find some meaning and
168:30 - you are trying to find the best way on
168:32 - how to process them and how to store
168:34 - them try to consider or thinking of
168:36 - using the the data structure try and
168:39 - once again for try later in the course
168:41 - we are going to see an example so things
168:43 - would become much more more clear so I
168:46 - hope that you got the idea about
168:48 - Advanced data structures of Max Heap Min
168:51 - Heap and tribe and now let's move
168:53 - forward so first of all I would like to
168:55 - congratulate all of you for making up
168:58 - until this far uh we have cross the
169:01 - biggest hurdle in our technical
169:02 - interview preparation journey and that
169:04 - is learning about all the popular data
169:06 - structures I hope that you must have
169:08 - good enough understanding of each one of
169:10 - them and now we are going to shift our
169:12 - Focus towards algorithms which is not so
169:15 - complicated as data structures were but
169:17 - needless to say they are quite important
169:20 - so I hope you give your utmost attention
169:22 - to this portion because once you
169:24 - understand algorithms things will become
169:26 - much more easier for you to proceed for
169:28 - the subsequent
169:32 - parts now one of the most important
169:34 - thing that you have to master in order
169:36 - to master any technical interview is to
169:39 - understand that what are the different
169:40 - algorithms available to you and what are
169:42 - typical coding patterns that you need to
169:44 - to recognize but before we start diving
169:47 - deep into it first let's understand that
169:49 - what does algorithm mean algorithm is
169:51 - nothing but a simple set of procedure a
169:54 - computer or a program needs to follow in
169:56 - order to generate some solution so let's
169:59 - say that this is the problem statement
170:01 - given you need to follow a certain steps
170:03 - in a certain sequence in order to
170:05 - generate the results and there are many
170:07 - different techniques to that that we
170:08 - will tackle in this uh portion so
170:11 - following that would generate the
170:14 - unnecessary output that you looking for
170:16 - and understanding that what are the
170:18 - options available to you is going to be
170:20 - a significant key for your Tech
170:22 - preparation Journey now what is coding
170:25 - patterns let me give you an example
170:27 - suppose if I write down uh few words
170:30 - over here let's say 2 4 6 can you
170:33 - predict what is going to be the next
170:34 - alphabet or next character I'm going to
170:36 - write over here of course you can
170:37 - predict that I'm going to write eight
170:39 - why because by looking at this you
170:42 - understood that this makes the next
170:44 - logic sequential sound move and this is
170:47 - what we need to do in terms of technical
170:49 - interviews as well that depending on the
170:52 - problem statement we should get some
170:54 - idea that hey in this type of scenario
170:56 - it would make sense to use a data
170:58 - structure like an array and in the array
171:01 - we are going to apply maybe sorting and
171:04 - then with the Sorting we are maybe going
171:06 - to apply uh binary search and this would
171:08 - yield us the correct result but we need
171:11 - to understand this type of pattern and
171:13 - this can only be done if we examine many
171:17 - questions of a similar type and then
171:19 - understand or refer meaning to that so
171:22 - combination of algorithms and coding
171:24 - patterns are closely related with each
171:26 - other and you do that in tandem with
171:28 - data structures and that's it these are
171:31 - the three building blocks for any
171:33 - efficient data structure algorithm
171:35 - technical interview and uh we are going
171:37 - to take care of it so these are all the
171:40 - different techniques that we are going
171:41 - to cover so first of all we are going to
171:44 - cover the searching algorithm and
171:45 - sorting algorithm then one of my
171:48 - favorite topics that is dynamic
171:50 - programming and recursion so after that
171:53 - we are going to see bunch of different
171:54 - tree and graph algorithms and these are
171:57 - really popular because there are some
171:59 - very practical real life applications
172:02 - completely built upon the concepts of
172:04 - tree and graph algorithms then we we
172:07 - will see some greedy algorithms and
172:09 - backtracking techniques and in the end
172:11 - we would start talking about the divide
172:13 - and conquer sliding window two pointers
172:16 - and interval coding patterns so this
172:18 - would cover most of the topics that you
172:21 - can think of for any technical interview
172:24 - and once you understand this you would
172:27 - essentially able to master all the
172:28 - problems that you are facing so without
172:31 - any further Ado let's just get started
172:34 - and uh for each and every concept I will
172:37 - explain the concept first then I'll show
172:39 - you either one or two examples depending
172:42 - on how complex the problem is and we
172:44 - will solve that problem before moving
172:46 - forward to the next one so completing
172:48 - this would be one of the most important
172:51 - key factors for this uh
172:55 - course so first let's try to understand
172:57 - the searching algorithm Now searching
172:59 - algorithms are pretty common across data
173:02 - structure and algorithm related problems
173:03 - because at any given moment we need to
173:06 - find some elements from a variety of
173:09 - data structures and these data
173:10 - structures can be an array or something
173:13 - like a St or a CU and it on top of it
173:17 - there can be some other more complicated
173:19 - data structures uh maybe something like
173:21 - a hash or a tree or a graph so
173:24 - essentially for any given data structure
173:26 - you might be asked to search some data
173:29 - from that and typically we follow two
173:33 - main techniques so number one technique
173:35 - is a linear search and linear search is
173:37 - uh as the name suggest it's quite simple
173:40 - essentially you jump from one node to
173:42 - another node to another node until you
173:44 - find the element that you are looking
173:46 - for and the moment you find the element
173:48 - you simply return that search element so
173:51 - if we have to understand it with an
173:52 - example suppose we are given an array
173:55 - and inside our array the values are
173:57 - randomly jumbled up something like 4 3 1
174:00 - 7 and 8 now I ask you that hey go ahead
174:03 - and search for Value number eight the
174:05 - approach is going to be that we are
174:06 - going to jump through all of these
174:08 - values until we reach to Value number
174:10 - eight and the moment we reach we can say
174:12 - that okay this eight is located at index
174:14 - number number four or on the fifth
174:15 - position or we can simply say that yes
174:18 - eight is present currently in this array
174:20 - in either case linear search would work
174:23 - just fine and if we see time complexity
174:25 - for a linear search it's typically going
174:27 - to be biger of n usually whenever you
174:30 - are dealing with data structures like
174:32 - link list or even Q or stack typically
174:35 - you are going to deal on the linear
174:37 - search basis because that is the only
174:39 - way you can access data uh and if there
174:42 - are some additional versions of maybe Q
174:45 - something like a Min Heap or Max Heap in
174:48 - that case you can actually find the
174:50 - value you are looking for in little bit
174:52 - simpler manner but still essentially
174:54 - linear search you are always going to
174:56 - encounter uh in whatever you are trying
174:58 - to do next example uh for a searching is
175:01 - actually a binary search and binary
175:04 - search is quite powerful but it has some
175:06 - predefined condition associated with
175:08 - that and that condition is that whenever
175:11 - you are trying to use a binary search
175:13 - the condition is that the data set has
175:15 - to be sorted so it needs to be either a
175:18 - sorted array or let's say a binary
175:22 - search tree something like that where
175:24 - you can actually apply the concept or
175:26 - the principle of binary search and
175:28 - principle is actually quite simple say
175:30 - for an example we are given bunch of
175:32 - different elements over here uh and they
175:34 - are all sorted in a particular fashion
175:36 - so 1 3 11 15 19 and 27 these are the
175:42 - values we are currently present let me
175:44 - just add one more element somewhere so
175:46 - value number four okay so currently we
175:48 - are given Seven Elements inside this
175:50 - array now I ask you that for this array
175:53 - can you go ahead and find me value
175:55 - number 15 what would be your approach
175:57 - well of course you always have the
175:59 - option to go linearly and search for
176:01 - each and every value individually till
176:03 - you find the value you are looking for
176:05 - but since this is already a sorted
176:07 - property it makes sense to use the
176:09 - binary search approach where first we
176:12 - are going to find the middle element the
176:14 - middle element in this case is going to
176:15 - be value number 11 now we know that
176:18 - since this array is sorted we are
176:20 - guaranteed that if 15 exist it has to
176:23 - exist within this portion and there it
176:26 - it is not possible that it lies within
176:29 - these values so we can essentially get
176:31 - rid of all of these inputs and only
176:34 - focus our effort for this remaining
176:36 - portion now once again for this
176:37 - remaining portion again we will try to
176:39 - find the middle pointer and middle
176:41 - pointer in this case is going to be 19
176:43 - which means once again again we can
176:44 - eliminate these two values because all
176:47 - the values are going to be either 19 or
176:49 - greater than 19 and in either case it is
176:52 - not going to be 15 so we are only left
176:54 - with one element in this case and that
176:56 - is value number 15 we which we can
176:58 - return so only in three itations we were
177:00 - able to find the our answer we are
177:03 - looking for in an array of uh seven
177:06 - total elements basically the binary
177:08 - search actually operates in bigo of log
177:11 - n time and this logarithmic time
177:14 - complexity is what makes it viable so
177:18 - this is what how you can understand
177:20 - searching algorithm and you are going to
177:22 - see them quite a lot in lot of different
177:25 - problems you are trying to
177:28 - solve now before we start understanding
177:31 - the example for searching algorithm
177:33 - let's try to understand sorting first
177:36 - and then combination of searching and
177:38 - sorting would would be what we would use
177:40 - to understand one of the actual data
177:42 - structure and algorithm Rel related
177:44 - examples so let's try to understand
177:46 - sorting first now sorting as the name
177:49 - suggest uh it is the procedure to sort
177:52 - all the given data in some particular
177:54 - fashion it could be whether all the data
177:57 - you are trying to sort in an increasing
177:58 - order or reverse could be true that you
178:01 - are trying to sort everything in the
178:02 - decreasing order or you are trying to
178:05 - sort everything based on the colors that
178:07 - you are provided or the names or
178:08 - alphabets in either case you are trying
178:11 - to bring an ordered list and sorting can
178:15 - apply to most of the data uh most of the
178:18 - data structures like arrays and uh link
178:20 - list and trees and graphs but mostly you
178:22 - are going to typically use it on the
178:25 - arrays that's what I have observed by
178:27 - solving bunch of different problems so
178:29 - even to understand the Sorting let's try
178:32 - to see some examples from array suppose
178:34 - we are given an unsorted array and the
178:37 - values currently are 2 3 1 7 and 8 okay
178:42 - now in this unsorted array if we trying
178:44 - to sort it how can we do it well
178:47 - actually sort there are multiple
178:49 - techniques we can use in order to sort
178:51 - the data and one of the in inefficient
178:54 - approach is actually something called
178:56 - bubble sort now bubble sort is typically
178:59 - where you compare any two elements and
179:02 - try to see that whether those two
179:04 - elements are in correct order or not and
179:06 - if they're not you swap those two
179:08 - elements and then go to the next element
179:10 - and you keep on repeating this process
179:11 - until all the elements are sorted so so
179:14 - if we have to see that in example we can
179:16 - see something like this where we okay we
179:18 - check two and three they are already in
179:19 - the correct order so we will leave them
179:21 - for now then we will compare 3 to 1 So
179:24 - currently 3: 1 is not in correct order
179:26 - so we will bring one over here and three
179:28 - over here and leave 7 and 8 as it is now
179:31 - once again we would compare these two
179:33 - elements So currently one and two are
179:35 - not in correct order so we will add one
179:37 - over here two over here three over here
179:39 - and then seven and 8 once again we would
179:41 - repeat the same procedure so one and two
179:42 - are correct order two and three are
179:44 - correct order and three and seven are
179:45 - Cor in correct order and same same goes
179:48 - for seven and 8 so in this case all the
179:50 - elements are now in correct order which
179:52 - means we can return this as sorted array
179:55 - and uh we use the bubble sort method but
179:58 - the issue with the bubble sort method is
180:00 - that it takes big of n Square time
180:02 - because it could be possible that for
180:04 - every single element you need to keep on
180:06 - uh Shifting the places and that could be
180:09 - pretty bad so one better approach is
180:12 - actually something called uh M sort or
180:15 - there is also a quick sort so let me
180:17 - give you the better faster sorting
180:19 - approach once again let's assume that we
180:21 - are given some random array and we are
180:24 - trying to sort this now we only have
180:26 - four elements so a better approach is
180:29 - that we actually create an entirely new
180:31 - array and currently this new array is
180:34 - blank so what we would do is we would
180:36 - add all the values in the sorted Manner
180:39 - and whenever we have to identify that
180:41 - where any new value should go we would
180:43 - use binary search in order to find the
180:46 - correct location for that place to be
180:48 - entered and we all know that binary
180:50 - search operates in log and time so
180:52 - essentially our code should run in N log
180:55 - and time why because we will have to do
180:58 - the log and operation for every single
181:01 - element that is currently present inside
181:03 - our given input array So currently let's
181:05 - try to see for Value number one so
181:06 - currently this is empty so we will add
181:08 - one just anywhere now five for five we
181:12 - can we need to check that where five
181:13 - needs to added and five is greater than
181:15 - one so it has to be added on the right
181:17 - side of one so we will add five over
181:20 - here once again for Value number two uh
181:23 - let's see where it needs to be added now
181:24 - since 2 is greater than 1 it needs to be
181:27 - added on the right side of one but it
181:28 - needs to be added on the left side of
181:30 - five and this we can calculate quite
181:33 - easily using binary search that which
181:35 - should be the correct position for two
181:36 - to be entered so in this case we can
181:38 - enter two over here and then five we can
181:40 - shift on one position to the right and
181:43 - this whole operation would take
181:44 - logarithmic of end time once again for
181:47 - Value number eight we will repeat the
181:48 - same procedure and we can find that uh
181:51 - the ideal place for eight is going to be
181:53 - here on the very end and in the end we
181:55 - would get our sorted array now this
181:57 - sorted portion looks quite good and we
182:01 - were able to achieve this whole thing in
182:03 - N log n time which is quite nice so
182:07 - whenever you are trying to deal with uh
182:09 - any operations try to see that can you
182:12 - use searching and sorting to solve this
182:15 - problem and combination of these two
182:17 - would ultimately yield you better
182:19 - results because if you can do any
182:22 - operation on an unsorted array for bigo
182:25 - of n Square time then same operation can
182:28 - be done using n log and time uh if you
182:31 - just simply sort this that given input
182:33 - array so that is a huge Advantage now
182:36 - let's try to see one real example from a
182:39 - problems uh with from the lead
182:42 - code
182:44 - okay so now let's try to understand this
182:46 - problem that is how many numbers are
182:48 - smaller than the current number the
182:50 - problem is really easy to understand uh
182:52 - we are given an input array and we need
182:54 - to create another array where for every
182:57 - single position inside the original
182:59 - array we need to determine that how many
183:01 - number of elements are smaller than that
183:04 - particular value so in this case for
183:06 - four we can see that there are actually
183:08 - two elements that are smaller than four
183:10 - so in the answer we are going to mark
183:12 - two same way for three there is only one
183:15 - element that is smaller than three so we
183:16 - are going to mark one for five there are
183:18 - actually three elements smaller than
183:20 - five so we are going to mark three as
183:22 - the answer and zero is the smallest
183:24 - element so in this case we can Mark
183:26 - there are zero elements that are smaller
183:28 - than zero and this would be the answer
183:30 - we need to return now this is actually
183:33 - quite simple to understand let's see
183:34 - that what would be the Brute Force
183:36 - approach to solve this problem well in
183:38 - The Brute Force approach the most
183:40 - simplest thing we can do is that rather
183:42 - than uh doing anything else we can
183:44 - simply start checking one element one by
183:47 - one so we first make a pair from four to
183:49 - three and we check okay that this is
183:51 - smaller so we increment the value by one
183:54 - once again we make a pair of four to
183:56 - five We compare these two value since
183:57 - five is bigger we don't do anything then
183:59 - we check one more time and then since 0
184:01 - is less than four so once again we add
184:04 - one more increment and the answer we
184:06 - store in the answer that for zero there
184:08 - are two elements that are smaller than
184:10 - that and we keep on repeating the same
184:12 - process so this Pro Force approach would
184:14 - yield as the solution in bigo of n
184:16 - Square time because for every single n
184:18 - element we are doing n minus one work so
184:22 - this is not really good so let's try to
184:24 - see that what should be the better
184:26 - approach and one of a very easy
184:29 - approaches that actually if we take the
184:32 - same input as it is but we if we sort
184:35 - that input then the answer is going to
184:37 - become quite easy so the answer is 4 3 5
184:40 - and 0 now in this case we need to return
184:42 - that how many many number are smaller
184:44 - than that so first let's see that what
184:47 - does a sorted array looks like and in
184:50 - this case it's going to be0 3 4 and 5
184:53 - now at any given position in the sorted
184:56 - array defines that how many values are
184:59 - actually smaller than that so in the
185:01 - case of zero there are actually zero
185:02 - values smaller than that same way for
185:05 - the case of three there is one value
185:07 - smaller than that and that value is zero
185:09 - for four there are two values smaller
185:11 - than that and that is two and for five
185:12 - all three values are zero so we can use
185:16 - this property to calculate that uh or to
185:19 - generate this array but how we need to
185:22 - do that uh we actually need to know the
185:24 - index location for all of these and then
185:27 - Mark appropriate value so for four we
185:30 - need to enter answer two but we there is
185:34 - one simple way to do it that is that uh
185:36 - for four we first iterate over this
185:38 - given sorted are and find the value and
185:40 - then again repeat the same work but that
185:42 - would be an additional overhead a better
185:44 - approach is to use a hashmap here so
185:47 - after we generate the sorted array we
185:49 - can put all of its values as keys and
185:53 - all the index positions as values inside
185:56 - the hashmap and then uh we can use that
186:00 - property to to populate our answer quite
186:03 - easily so in this case 0 is going to
186:05 - have zero value three as key is going to
186:07 - have value number one four S key is
186:10 - going to have value number two and five
186:12 - s key is going to value number three now
186:15 - all we need to do is from our example
186:17 - array let me get rid of this for now and
186:20 - now all we need to do is from our
186:22 - example array we will first iterate over
186:24 - this value number four try to see that
186:27 - which is the value associated with this
186:29 - value number four create an answer array
186:31 - and in the answer array just Mark that
186:33 - value same way for Value number three
186:36 - again check in the hash map and the
186:37 - associated value is value number one
186:40 - again for five Associated value is value
186:42 - number three and for 0 Associated value
186:44 - is zero and this would give us the
186:46 - correct answer we are looking for in the
186:48 - simplest manner so now let's see that
186:50 - what is going to be the time and space
186:52 - complexity in this case the time
186:54 - complexity is going to be big of n log n
186:57 - in order to generate the sorted
186:59 - algorithm or sorted array plus we have
187:01 - to do big of n work in order to generate
187:04 - this answer from this example by
187:05 - comparing this hashmap so that is pretty
187:08 - good so overall time complexity is going
187:10 - to be big of n log n now let's see that
187:13 - what is going to be the space complexity
187:15 - well of course since we are using an
187:17 - additional hashmap the space complexity
187:19 - is going to be bigger of n but that is
187:21 - still reasonable because we are saving
187:23 - uh quite some computation in the time
187:26 - complexity so now you must understand
187:28 - that how we are actually using sorting
187:31 - and then we are using searching plus we
187:34 - are using the capabilities of hashmap
187:36 - and everything is connected with arrays
187:39 - in order to generate one answer and this
187:42 - is is how typically data structure and
187:45 - algorithm related videos or uh problems
187:48 - are done so now let's see the coding
187:51 - solution okay so let's see that what is
187:53 - going to be the Java solution for this
187:55 - problem basically we are given an
187:57 - integer array called nums so first thing
188:00 - we are going to do is we are going to
188:01 - create another array and we are going to
188:03 - uh sort it so this is the sorted array
188:07 - and now we are going to create a hash
188:09 - map uh where inside this hash map we are
188:13 - going to Mark the indexes values for all
188:16 - the elements that we have in the sorted
188:18 - array so it becomes really easy for us
188:20 - to navigate and generate the results for
188:23 - our original array then all we need to
188:25 - do is initialize another array where we
188:27 - are going to store the results plus we
188:29 - are going to run a for loop on the
188:31 - original input array and we are going to
188:34 - uh check that what is the result from
188:37 - the hashmap for that particular uh key
188:39 - value and uh we populate the values
188:42 - inside our result array and we get the
188:44 - answer let's try to run this
188:46 - code and our code runs pretty
188:49 - efficiently so let's submit this
188:51 - code and our code runs actually very
188:54 - fast compared to lot of other Solutions
188:56 - so this how you can understand what are
188:59 - the powers of sorting storing and
189:01 - hashing and combine combining lot of
189:03 - data structures and to generate a
189:10 - solution now we will try to understand a
189:12 - very important topic that is called
189:14 - recursion recursion is highly used in
189:17 - many of the data structure and algorithm
189:19 - related problems plus there are many
189:22 - algorithms and many programming
189:23 - techniques that are heavily dependent on
189:26 - recursion to solve the problem so
189:29 - recursion is actually a method that we
189:31 - can typically use uh in order to
189:33 - complete any set of task where we
189:36 - usually see some sort of repeative work
189:39 - that needs to be done for a various set
189:42 - of uh different inputs and essentially
189:44 - we need to collect the results of the
189:46 - them to generate an answer now let me
189:49 - explain you recursion by a real life
189:51 - scenario first and then we will talk
189:53 - about what it is it and how do we
189:55 - actually use it in our typical technical
189:57 - interviews say for an example you are
189:59 - currently standing on a line and you
190:02 - don't know that how many number of
190:03 - people are currently in front of you so
190:06 - all you can see is that there are bunch
190:07 - of different people ahead of you but you
190:09 - have no idea and currently this is the
190:12 - person who is the very first person in
190:14 - the line now you decide that you want to
190:16 - check that what is your position inside
190:19 - the current line so the one approach is
190:22 - that you get out of the line and then
190:25 - you start counting all the people that
190:27 - are in between and then you try to come
190:29 - back to the line but there are more
190:31 - people behind you so if you get out you
190:33 - will essentially lose your place so
190:35 - there is one more way when you can
190:37 - identify that what is your current
190:39 - position that is that first you ask the
190:42 - person ahead of you that hey what is
190:45 - your position now again the person ahead
190:47 - of you also has no idea so he repeats
190:50 - the same position that hey what is your
190:52 - position and this question keeps going
190:55 - on and on and on until we reach to the
190:57 - very first person and because this very
191:00 - first person already knows what is his
191:03 - or her position is this person would say
191:06 - that hey my position is one which means
191:09 - this person would understand that his
191:11 - position has to be second second
191:13 - position so then he would respond back
191:15 - to the person behind him and this person
191:18 - would understand that his position is
191:19 - now the third position same with this
191:21 - person will conclude that his position
191:23 - must be fourth position because this
191:25 - person is at third position and same
191:27 - with this person is at fifth position
191:29 - and he tells you that hey I am on the
191:32 - fifth position which means you can
191:34 - conclude that your position has to be
191:36 - the sixth position in the current line
191:38 - now what you essentially did is you made
191:41 - a recursive call and you get the desired
191:44 - answer you were looking for and you ask
191:47 - the same question to a different set of
191:49 - input results until you f reached to a
191:52 - place who knew the answer and depending
191:54 - on that answer you started building all
191:57 - the other answers and that's it that's
192:00 - the recursion now I know at first it
192:03 - seems complicated to comprehend but if
192:05 - you try to understand with real life
192:07 - examples things would become much more
192:10 - easier let me give you one analogy
192:13 - that how it typically appears have you
192:15 - ever seen those Russian dolls that uh
192:19 - whenever you open one doll and then uh
192:22 - inside that doll there is another doll
192:24 - hanging and inside that there is another
192:26 - doll and it keeps on happening over and
192:28 - over for all the different shapes of
192:30 - dolls so the same concept applies for
192:33 - the recursion as well that behind any
192:36 - big problem or behind solution of any
192:39 - big problem lies the solution of a
192:41 - smaller problem plus plus some
192:43 - computation same way for even for that
192:45 - smaller problem there lies some other
192:47 - computation and same goes on and on
192:50 - until we reach to a base case where in
192:53 - the base case we directly know that what
192:55 - is going to be the solution for that
192:56 - particular case and apart from that from
192:59 - that we would build this solution and
193:01 - then we would build the other solution
193:03 - and we would keep on repeating the
193:04 - process again and again and again let's
193:07 - try to see that what are the things or
193:09 - areas of concern for us in any
193:11 - particular recurs
193:13 - so every single recursion has two items
193:16 - first item is that uh recursive function
193:19 - and this recursive the purpose of this
193:21 - recursive function is to call the next
193:24 - sequence or next input in line in order
193:27 - to get the answer so first one is a
193:30 - recursive function and second one is a
193:33 - base case so base case is a scenario
193:36 - where we know that this has to be the
193:38 - answer or this has to be the minimum
193:40 - answer now uh again going back to to our
193:43 - uh people standing in a q position the
193:46 - person standing very at the very first
193:48 - po position in the line knew that he was
193:52 - the first person in the line and this
193:54 - was basically our base case now our what
193:58 - was our recursive function in this case
193:59 - in our recursive function the case was
194:02 - to ask the next person that hey what is
194:05 - your position and keep on asking that to
194:08 - the next person and the moment we get an
194:10 - answer from the base case we need to
194:12 - return to the previous person that hey
194:15 - whatever the answer we get from the next
194:17 - element or the base case we need to add
194:20 - one to that so here base case would say
194:23 - that hey I'm first person so this person
194:25 - would say back to the back to his
194:27 - previous person so person who called
194:29 - originally this person he would respond
194:31 - back saying that hey I second I'm in
194:33 - second position same way this person
194:35 - would say I'm third position and so on
194:38 - and so forth the recursive call would
194:40 - keep on coming back until we reached to
194:42 - a point who originally called or
194:45 - initiated that recursive call recursions
194:47 - are very powerful and they are used in
194:49 - bunch of different data structures in
194:51 - many programming techniques data
194:53 - structures such as uh typical tree or
194:57 - graphs plus programming techniques like
194:59 - dynamic programming and also many of the
195:02 - Matrix manipulation all of this are
195:05 - heavily using recursion to solve their
195:08 - uh problem because typically in all of
195:10 - these problems we need to do the same
195:13 - computation again and again for
195:16 - different set of inputs and whenever we
195:18 - see things like that we have to try to
195:20 - see that can we solve this problem using
195:22 - recursion now there is also one more
195:24 - thing that you need to understand that
195:26 - any problem you can solve recursively
195:29 - you can also say solve the same problem
195:31 - iterative iteratively but the question
195:33 - is recursive solution is going to be
195:35 - typically very simple to implement so
195:38 - you can think of it like a simple manner
195:40 - just like asking a question again going
195:42 - back to our people standing in the line
195:44 - scenario you could have gone out of the
195:46 - line and calculated all of these values
195:49 - one by one by yourself but why did you
195:52 - decide it not to do and you just decided
195:53 - to ask to the next person because
195:55 - repetitively you can ask this question
195:57 - again and again and you can expect to
195:59 - get an answer coming back in return so
196:03 - that is how if you would have gone out
196:05 - and calculated all of this by yourself
196:07 - it would have been an iterative approach
196:09 - and if you would have stood in the line
196:10 - and waited for the result come back to
196:12 - you it would be recursive approach but
196:14 - there is a key difference between
196:16 - iterative and recursive that in the
196:18 - iterative approach memory is not being
196:21 - used that much why because in this case
196:23 - you are the only person calculating that
196:25 - how many number of people are there
196:27 - currently present in the line and then
196:29 - they can you can infer the result that
196:31 - you're looking for but in our recursive
196:33 - approach we are dependent on every
196:35 - single person to know that what is the
196:38 - position of other person and then adding
196:41 - one line to it and sending back the
196:43 - results which means we are actually
196:45 - creating a memory stack where we are
196:47 - keeping track of all the memories that
196:50 - actually called us back so all the
196:53 - places where we called we are placing
196:56 - their uh line in the stack and when we
196:59 - get the result we fetch these values out
197:01 - one by one because remember the property
197:03 - of a stack is last and first out so we
197:05 - get these values out and then we in the
197:08 - end conclude the answer so whenever
197:10 - you're dealing with recursion make sure
197:12 - that uh memory usage is not so
197:15 - significant that you actually end up in
197:18 - uh stack Overflow issue now let's try to
197:22 - understand a program programming uh
197:25 - example for recursion and that is
197:27 - something called a Fibonacci series now
197:29 - we all know what a Fibonacci series is
197:32 - Fibonacci series is basically the sum of
197:34 - two numbers now let me give an example
197:37 - initially so let's say that first value
197:40 - of Fibonacci series is Fibonacci of zero
197:42 - so that is going to be the value number
197:44 - zero second is Fibonacci of 1 Fibonacci
197:47 - of one is going to be value number one
197:49 - now if we have to calculate Fibonacci of
197:51 - 2 we will actually have to do the sum of
197:53 - these two values and that will give us
197:55 - the answer of fibon 2 so Fibonacci of 2
197:58 - is actually Fibonacci of 0 plus
198:00 - Fibonacci of 1 so the answer is going to
198:02 - be 1 once again Fibonacci of 3 is
198:05 - actually the sum of previous two
198:07 - elements so Fibonacci of 2 plus fibon
198:09 - Fibonacci of 1 so the answer answer is
198:12 - once again going to be value number two
198:14 - same way Fibonacci of 4 is sum of
198:16 - previous two elements so Fibonacci of 3
198:18 - plus Fibonacci of 2 and the answer is
198:21 - going to be value number three and this
198:23 - keeps on going on and on until whatever
198:25 - the value we are trying to find we get
198:27 - the answer so now in this case this is a
198:30 - very good candidate if you want to
198:32 - implement the solution recursively and
198:34 - how would the recursive function would
198:36 - work well we know that for recursion we
198:39 - need two things we need our base case
198:41 - and base case is lying right in front of
198:43 - our eyes that is that uh the Fibonacci
198:47 - of 0o is zero and Fibonacci of 1 is 1
198:50 - now we need a recursive function and
198:52 - recursive function is also in place that
198:55 - fibon of any number is actually
198:58 - Fibonacci of number minus one plus
199:01 - Fibonacci of number minus 2 and you can
199:03 - apply it to anywhere so Fibonacci of 2
199:06 - is going to be Fibonacci of Z or
199:07 - Fibonacci of 1 same way Fibonacci of 3
199:10 - is going to be sum of Fibonacci of 2 and
199:12 - ion of 1 so this function applies which
199:14 - means we got our recursive function and
199:17 - we also got our base case so now to
199:19 - calculate any result is going to be very
199:21 - easy for us okay so let's say that I'm
199:23 - trying to find the Fibonacci numbers and
199:25 - I try to find the Fibonacci number of
199:28 - Fibonacci value number four so first
199:30 - let's see that what is going to be the
199:31 - recursive approach well first of all in
199:33 - the recursive approach we know that what
199:34 - is the recursive function for Fibonacci
199:36 - of 4 recursive function is Fibonacci of
199:39 - 3 plus Fibonacci of 2 now we all know
199:43 - that what is the answer for Fibonacci of
199:46 - 3 that is Fibonacci of 2 plus Fibonacci
199:50 - of 1 now we know the value of Fibonacci
199:52 - of 1 but we do not know the value of
199:54 - Fibonacci of 2 so once again even in
199:57 - order to get this value we are going to
199:58 - do Fibonacci of 1 plus Fibonacci of 0
200:02 - and we know these two values so sum of
200:05 - these two values is going to be 1 + 0 so
200:08 - the value is going to be 1 so this is
200:10 - going to return us the answer
200:12 - as one so we get the value of one so in
200:16 - this case currently the Fibonacci of 2
200:18 - is going to be of value number one and
200:20 - Fibonacci of 1 is already value number
200:22 - one so 1 + 1 is going to yield us the
200:24 - result of three now we got the answer
200:27 - three in this case now for Fibonacci of
200:29 - two we again need to do the same
200:31 - computation and that is Fibonacci of 1
200:34 - plus Fibonacci of 0o now we don't know
200:37 - we already know the values of fibon 1
200:39 - and Fibonacci of zero and that is going
200:41 - to be some is equal to 1 so this is also
200:43 - going to be one so in this case
200:45 - currently the value of Fibonacci of
200:47 - three is going to be okay this is not
200:49 - going to be three this is going to be
200:50 - two I think I Mis wrote this this is
200:53 - going to be two so Fibonacci of three is
200:55 - going to be two and Fibonacci of 2 is
200:56 - going to be 1 so the answer for
200:58 - Fibonacci of 4 is going to be three okay
201:02 - so we got the recursive answer now you
201:04 - see what you did what we did in this
201:06 - case we took the larger case and then we
201:09 - started breaking down into the smaller
201:10 - pieces and even for those smaller pieces
201:13 - we started breaking down into sub
201:15 - smaller pieces until we reach to a point
201:18 - where we are at the base case and
201:20 - through the base case we found the
201:21 - solution we return those solution to our
201:24 - previous calls and then we kept on
201:26 - repeating the process until we find to
201:28 - the main value we were looking for now
201:30 - what are the things we had to take care
201:31 - of we had to take care of base case we
201:34 - had to take care of the recursive
201:35 - function and we had to take care of the
201:37 - memory call back because this function
201:40 - is calling back to Fibonacci of 2 this
201:42 - function is calling back to Fibonacci of
201:43 - 3 same way this function is calling back
201:45 - to Fibonacci of 2 and we are getting the
201:47 - answer but at least as long as we are
201:49 - getting the answer now for the same
201:51 - problem let's try to do it iteratively
201:53 - so in the iteratively we are trying to
201:55 - find Fibonacci of 4 so obviously The
201:57 - Logical approaches that we are going to
201:59 - start with Fibonacci of 0 and Fibonacci
202:01 - of 0 is already Zer Fibonacci of 1 is
202:03 - already 1 now we are going to calculate
202:05 - Fibonacci of 2 that is going to be sum
202:07 - of 0 + 1 so that is going to be 1 okay
202:09 - so this Fibonacci of 3 is going to be
202:11 - value two and then we can calculate
202:14 - Fibonacci of four that is going to be
202:16 - value three and we will also get the
202:17 - same answer now in this case in the
202:19 - iterative approach we started from the
202:21 - bottom and reach all the way to the
202:23 - value we were looking for in the
202:25 - recursive approach we started from the
202:26 - value we were looking for started asking
202:29 - and went to the base case and then came
202:31 - back again for the previous case so this
202:33 - is one common way to implement recursion
202:36 - now you are going to see quite a lot of
202:38 - examples whenever you are trying to
202:40 - prepare for any technical interviews
202:42 - because recursion are one of the most
202:44 - commonly widely used programming
202:49 - techniques now we are going to learn the
202:51 - most important topic inside the Entire
202:54 - Computer Science in my opinion and
202:55 - specifically for the technical
202:57 - interviews because if you are applying
202:59 - for any Tech interview for sure you are
203:02 - going to be asked some questions related
203:04 - to dynamic programming so let's first
203:07 - understand that what dynamic programming
203:08 - is what are the different variations
203:11 - associated with that and then we are
203:13 - going to explore bunch of different
203:14 - examples so you can get the complete
203:16 - idea on how dynamic programming Works
203:19 - basically dynamic programming is nothing
203:22 - but the art of saving the data that we
203:25 - have already computed and then reuse
203:28 - that data for some future computation
203:30 - that's it uh now let's try to understand
203:33 - this with an example suppose we have a
203:36 - map like this where we are given bunch
203:39 - of different places or points and we we
203:41 - we are trying to go from one city to
203:43 - another city now in this case currently
203:46 - we have all of these variations and we
203:49 - are trying to get to a city number F now
203:53 - uh each of this path we can assume that
203:56 - they are let's say 1 km long on top of
203:59 - this from a we have some path directly
204:01 - leading to seat that is also 1 km long
204:04 - and from C we have one path that that is
204:06 - directly leading to e and that is also 1
204:08 - km long and now the aim is to get to
204:10 - City number f
204:12 - Now The Logical conclusion is that most
204:15 - common bro Force approach would be that
204:17 - we start from City number a and we
204:19 - explore every single path and for each
204:21 - of the path we calculated that how much
204:24 - kilometers or how many kilometers did it
204:26 - took so we would first calculate a
204:28 - result for a path like this then we
204:30 - would calculate a result for a path like
204:32 - this this this and this and then in the
204:34 - end we would calculate the result for a
204:36 - path like this and we would find the
204:38 - answer but the question is uh is this
204:40 - the most approp rate approach to reach
204:43 - over here because we are repeating so
204:45 - many competitions here we already
204:47 - calculated for this portion and this
204:49 - portion and we are actually calculating
204:50 - it two times uh in order to generate the
204:52 - result one better approach is that we
204:55 - actually use dynamic programming to
204:57 - store the already calculated path and
205:00 - how we are going to do it typically in
205:02 - dynamic programming there are two
205:04 - approaches first approach is a bottom up
205:06 - approach where you start from the base
205:09 - case or the very first case and try to
205:11 - build a solution that would eventually
205:13 - lead us to the final result we are
205:15 - trying to get to so that is one way
205:17 - second approach is a top down approach
205:19 - where in the top down approach you start
205:22 - at the very end or at the very top and
205:25 - then you build smaller and smaller
205:28 - Solutions and try to come up or try to
205:30 - reach to the first point and then try to
205:32 - build a path in this manner now of
205:34 - course both of this are going to look
205:36 - quite similar uh compared in regards to
205:40 - the previous example we C for recursion
205:43 - because the top down approach is
205:46 - actually used by done by doing recurs
205:49 - recursive calculation and bottom up
205:51 - approach is typically done by using an
205:54 - iterative solution where we are storing
205:56 - the data of all the things calculated
205:58 - and that is a common factor we are going
206:00 - to store the result of already
206:03 - calculating calculated the data and we
206:05 - are going to use it for our next
206:07 - computation so let's try to see an
206:09 - example in this case the approach I am
206:12 - suggesting is that we start from F in
206:15 - this case and we try to go in the
206:18 - reverse order to find the best path
206:21 - suited path so the question is in order
206:24 - to get to the F what is the nearest
206:26 - point that leads us to Value number F
206:29 - and that is going to be value number e
206:31 - that say somehow if we get to Value
206:34 - number e we can reach to F in just 1 km
206:38 - so we can say that distance from E to F
206:40 - is going to be 1 one okay that's good
206:43 - now uh in order to get to e what are
206:46 - different options we have so first let's
206:47 - explore all of them so let's say that we
206:49 - are currently at position number D if we
206:51 - are at D we if we need to get to F we
206:55 - have this path where we are going to go
206:58 - from D to e and then e to F so in this
207:01 - case if you are if we are at D do we
207:04 - need to calculate this whole path from
207:06 - going to e and then again going from E
207:08 - to F no why because we already know that
207:11 - that once we get to e we can directly go
207:14 - to F with this effort so we are going to
207:17 - save our computation and we are only
207:19 - going to calculate that okay from D if I
207:22 - get to e using one e using one step then
207:26 - from E to F distance is already one so I
207:29 - can say that from d i if I take two
207:32 - jumps or if I go travel 2 kilm I can go
207:35 - to the value F that's awesome now once
207:38 - again let's repeat the same computation
207:40 - now we are at position position number c
207:42 - so from C how many options we have one
207:45 - option we have is that from C if we go
207:48 - to D we already know that from D to F is
207:51 - already 2 km so and from C to D it takes
207:54 - us 1 km so if we were to take this path
207:57 - from C to D then we don't care how many
207:59 - number of hops it has to take all we
208:01 - consider is that from C to D if we go
208:03 - there then within 3 km we would be able
208:06 - to reach to our final destination F so
208:08 - in this scenario we are not even going
208:10 - to bother checking for this path from E
208:12 - to F we are only consider the path
208:14 - between C to D and which is the true
208:17 - power of dynamic programming so now in
208:19 - this case we are actually we can say
208:22 - that from C if we take 3 km we would be
208:25 - able to get to D but at C we have one
208:28 - more option and that option is that if
208:30 - somehow we can go from C to e then at
208:33 - location e we can only travel 1 km and
208:36 - get to F so in this case now at C we
208:40 - have a path from C to D that takes us uh
208:43 - 3 km time and we have a path from C to e
208:47 - that takes us 2 km time and we are
208:49 - trying to find the minimum uh time it
208:51 - takes or minimum travel it takes to get
208:53 - to e so we can see that at C if we
208:57 - somehow end up at position number c then
209:00 - we can actually reach to F within 2 km
209:03 - so we are going to Mark the value of C
209:05 - S2 and then we are going to repeat the
209:07 - same process so now from B if we somehow
209:10 - end up at C
209:11 - we would be able to get to F within 2 km
209:13 - and from B to C it takes 1 km to get
209:16 - there so we can see that at B it takes 3
209:18 - km to get to F same way from a if we go
209:22 - to B it takes us 3 km plus 1 km so 4 km
209:25 - to get there but if we from a go to C
209:30 - then it only takes 3 km so we can say
209:33 - that the minimum amount of time it takes
209:35 - from us to go from a to F would be 3 km
209:39 - and this is how we build the solution by
209:42 - already calculating the previously
209:45 - computed results and in this case we
209:47 - actually use a top down approach where
209:50 - we started from the top and we kept
209:52 - going in the reverse order and we can
209:54 - actually have a recursive function call
209:56 - to find the solution in the recursive
209:58 - function the base case is going to be
210:00 - that if we are located at position
210:02 - number e it only takes us 1 km to get
210:05 - there and then uh the solution would be
210:07 - that we need to check that how can we
210:09 - get to that next location in the minimum
210:11 - amount of hop so that's pretty awesome
210:14 - actually now let's see some other
210:16 - examples on how would a dynamic
210:19 - programming would work now previous
210:21 - example we saw that how does a recursive
210:23 - function work for a Fibonacci numbers
210:26 - now once again we are going to use the
210:28 - same Fibonacci numbers but this time we
210:30 - are going to use dynamic programming to
210:33 - solve the problem so let's see that in
210:35 - action in the previously recursive
210:37 - operation we had the example that if we
210:40 - wanted to calculate the the result of
210:41 - Fibonacci number five then what we would
210:43 - do first we would calculate the number
210:45 - of four plus uh Fibonacci number three
210:49 - same way for four we would calculate the
210:51 - number phys Fibonacci of 3 plus
210:54 - Fibonacci of 2 and plus over here we
210:56 - would do Fibonacci of 2 plus Fibonacci
210:59 - of 1 same way over here we would do
211:01 - Fibonacci of 1 plus Fibonacci of 2 and
211:06 - here we would do Fibonacci of 1 plus
211:10 - Fibonacci of 0 in order to calculate
211:12 - this value and in this case we will do
211:16 - Fibonacci of 1 plus Fibonacci of 0 in
211:20 - order to calculate this Fibonacci of 2
211:22 - and Fibonacci of 1 we already know the
211:24 - value as 1 because this is a base case
211:27 - now see how many times we are repeating
211:30 - the same computation over here we are
211:33 - calculating the value of Fibonacci of 1
211:35 - plus fibon of 2 in order to generate the
211:37 - answer same computation we are doing
211:39 - here as well Plus here we are
211:41 - calculating Fibonacci of 1 plus
211:43 - Fibonacci of 0 same way we are doing it
211:45 - for Fibonacci of 1 and Fibonacci of 0 so
211:48 - in both the cases rather than doing all
211:50 - of this computation what we can do is we
211:52 - can actually create an array and inside
211:55 - the array we are going to store the
211:57 - results that we have already calculated
211:59 - now we know that for our base case it's
212:01 - fibon of Z so let me mark down the value
212:03 - 0 1 2 3 and four for all of this and let
212:07 - me make one node for five as well okay
212:10 - now we all know that the values for 0 is
212:12 - actually going to be 0er and 1 is going
212:14 - to be one these two values are already
212:16 - calculated now let's start Cal start
212:19 - let's start our recursive function so
212:21 - first we start with four four and three
212:24 - now in order to do that we need to
212:25 - calculate these two values now we need
212:28 - to calculate this two value so this
212:29 - would be the first case we would be able
212:31 - to calculate where we need to calculate
212:33 - the value for Fibonacci of 2 so we
212:35 - already know what is Fibonacci of 1 and
212:37 - Fibonacci of 0o and this is going to be
212:39 - value number one so we can do that that
212:42 - we can put Fibonacci of 2 as value
212:43 - number one okay now for Fibonacci of 2
212:46 - we need to do Fibonacci of 2 plus
212:47 - Fibonacci of 1 that is going to give us
212:50 - the result for Fibonacci of 3 and that
212:52 - would be value number two okay now we
212:54 - are done with this portion and this
212:56 - whole computation now let's do
212:58 - computation for Fibonacci of 4 so in
213:01 - order to calculate Fibonacci of 4 we
213:03 - actually had to do all of these three
213:05 - calculations but in this case we don't
213:07 - have to do it why because at Fibonacci
213:10 - of 4 we need to get the answer of
213:11 - Fibonacci of 3 which we have already
213:13 - computed and Fibonacci of 2 which we
213:16 - have already computed as well so we can
213:18 - just say that this value is going to be
213:19 - three and based on that the value of
213:21 - Fibonacci of five is going to be some of
213:23 - these two values and we can just mark it
213:25 - as five so see how storing all of these
213:29 - values actually saved us lot of time and
213:32 - imagine that if we were not using
213:34 - dynamic programming so if we are not
213:37 - using dynamic programming then the time
213:38 - complexity would be big go of 2 to the
213:41 - power n because at every single position
213:44 - we are doing two more computation and
213:46 - same way for every single computation we
213:48 - are doing two more another computation
213:51 - so that is a very bad time complexity
213:53 - meanwhile in this approach we can
213:55 - actually complete this whole transaction
213:57 - and B go of uh and time only that we are
214:01 - only traversing and we are only doing
214:03 - the all the entire transformation just
214:05 - once and generating the result so that
214:07 - is pretty quick and pretty efficient
214:10 - approach and this I showed you the
214:12 - example of top down approach now let me
214:14 - show you the same for the same example
214:16 - bottom up approach now in the bottom up
214:18 - approach once again let me just draw an
214:21 - array with all the values I have
214:22 - currently calculated so 0 1 2 3 and 4
214:26 - okay and uh the values are going to be 0
214:29 - and 1 these are my base cases now I'm
214:31 - trying to calculate the value for
214:32 - Fibonacci of 2 so Fibonacci of 2 I can
214:35 - easy easily calculate using these two
214:36 - values as value number one and in the
214:39 - bottom up we are actually using the
214:40 - iterative solution so we are doing it
214:42 - iteratively okay now same way for the
214:45 - third value we can do some of these two
214:47 - value get the answer fourth value once
214:49 - again do the sum of these two values get
214:51 - the answer and same way for Fibonacci of
214:53 - five do the sum of these two values and
214:55 - get the answer as five and return this
214:57 - in the answer once again pretty
214:59 - awesomely and pretty simply we were able
215:02 - to solve the entire computation now you
215:05 - must be thinking that this is a very
215:06 - simple scenario for dynamic programming
215:08 - and yes this is a very simple scenario
215:10 - so let me give you a more complex task
215:14 - and that is actually uh that we need to
215:16 - calculate the number of coins problem
215:19 - okay so what does number of coins
215:21 - problem suggest is that we are given a
215:23 - value and let's say that this value is
215:26 - uh currently value number eight okay and
215:28 - we are given some coins so in this case
215:31 - let's assume that the coins we are
215:33 - currently given are 1 and two now we are
215:36 - told that we can use as many number of
215:38 - coins as we want in order to reach or
215:41 - build value number eight but the catch
215:44 - is that we need to use the minimum
215:46 - number of coins so in this case the
215:48 - answer is going to be if we use 4 * 2
215:50 - Coins we would get the value eight so
215:53 - the minimum number of coins we need to
215:54 - use in this case is going to be four but
215:56 - how do we actually calculate this so for
215:58 - this let me show you a bottom up
216:00 - approach and same would be true for the
216:03 - top down approach as well so I'm just
216:04 - showing it to you from the bottom of
216:06 - approach let me just quickly draw an
216:09 - array where we are going going to store
216:11 - the value for all the items we are
216:13 - calculating and initially our case is
216:15 - going to be zero that if we want to
216:17 - generate zero value how do we do that so
216:20 - let's say and for at each position we
216:24 - are going to calculate the possibility
216:25 - that what if we use coin with value one
216:29 - uh what how many number of coins would
216:30 - we use if we have to use coin number two
216:32 - how many number of coins would we use
216:34 - okay so both scenarios we are using and
216:37 - uh let's mark all of these values so 0 1
216:40 - 2 2 3 4 5 6 uh 7 and 8 okay now for zero
216:47 - we know that we need to use zero coins
216:49 - so let's just mark this as zero now if
216:51 - we have to generate value number one uh
216:53 - how many number of coins do we need
216:55 - currently previous results we can't get
216:57 - much information from because it is uh
216:59 - for the zero value now we have two coins
217:02 - available to us the coin if we use coin
217:05 - number one we can create one within just
217:07 - one coin okay so that is one option and
217:10 - and second option is if we use coin
217:12 - number two but that we cannot use to
217:13 - generate value one so we have to use one
217:16 - coin in order to generate value one and
217:18 - that one coin is going to be the simple
217:21 - coin one that we use I'm just marking
217:23 - white color as the the coin we use now
217:26 - same way in order to generate two what
217:28 - are the options we have we already know
217:30 - that currently let's say this coin is
217:32 - one coin number one so now our aim is to
217:35 - generate value number two but if we use
217:37 - one coin number one then we can already
217:41 - know that if we do 2 - 1 so whatever
217:45 - value we have stored on top of that if
217:47 - we just add one more coin over here that
217:50 - is this coin number one we would be able
217:52 - to generate this value too you will
217:55 - understand what I'm trying to say but
217:56 - let me just write it down for now so in
217:58 - this case if I use two coins with value
218:01 - number one then I can generate the value
218:04 - two so two would be minimum number of
218:06 - coins we have calculated so far but we
218:09 - also have the option for coin number two
218:11 - so if we take for check for coin number
218:14 - two two is actually the exact value so
218:16 - if we just use one single coin of value
218:20 - two we can generate the amount two so in
218:23 - this case the minimum number of coins we
218:25 - need to generate is going to be value
218:26 - number one and the coin we are using is
218:28 - going to be value number two okay now
218:31 - let's say that we need to generate value
218:32 - number three now once again the number
218:34 - of option we have for the coins is going
218:36 - to be 1 and two so let's redo the same
218:39 - calculation again now if we use coin
218:43 - number one which means if we are let's
218:46 - say somehow we are at this previous
218:48 - position two and then we use coin number
218:50 - one we would be able to generate value
218:52 - number three quite easily that's a given
218:54 - fact and we already know that in order
218:56 - to generate value number two we only
218:58 - need to use one coin and that is the
219:01 - true power of dynamic programming that
219:03 - we are using the value we have already
219:05 - calculated over here so in this case if
219:07 - we use coin number one
219:10 - plus the dynamic programming value of
219:13 - coin number two and how did we arrive at
219:16 - this coin number two we did a
219:17 - subtraction from the current coin we are
219:20 - trying to calculate that is this coin
219:22 - number three minus the coin value we are
219:25 - currently using that is value number one
219:27 - so we can make a dynamic programming
219:29 - function that would be that dynamic
219:31 - programming of let's say this one is
219:33 - currently value number three is equal to
219:36 - going to be the so first condition we
219:39 - have is that we can actually use dynamic
219:42 - programming of three minus coin that
219:45 - currently we are using and in this case
219:47 - coin is 1 so we can say dynamic
219:49 - programming of 3 minus 1 and if we use
219:52 - that then we will also have to use the
219:54 - current coin we have and that coin only
219:57 - takes one value one coin only adds one
219:59 - coin to the previous coins so this would
220:02 - be one consideration and second
220:04 - consideration would be the next option
220:07 - with value number two but currently in
220:09 - both the cases the number of coins are
220:11 - going to be two so I'm just marking
220:13 - coins to be two and you have two options
220:15 - over here you can either pick coin as
220:17 - one and two or you can pick coins as two
220:19 - and one in either case you will be
220:21 - picking two coins in order to generate
220:23 - value number three and we don't care
220:25 - about what coins we pick we only care
220:27 - that what are the minimum number of
220:29 - coins we need to generate that value now
220:31 - we are at position number four okay now
220:34 - let's again apply the same logic to our
220:36 - dynamic programming function and let's
220:38 - see that what are the options we have so
220:40 - So currently we are considering value to
220:42 - be one so coin we are choosing is one
220:44 - okay if we and we are trying to
220:46 - calculate for dynamic programming for
220:47 - Value number 4 so first option is that
220:50 - we do 4 Min - 1 so 4 - 1 is going to be
220:53 - dynamic programming of three dynamic
220:55 - programming of three is already know
220:56 - that the minimum value is 2 so that is
220:58 - going to be 2 + 1 so we have the option
221:02 - of choosing three coins in order to
221:05 - generate value number four but we have
221:06 - another option where we can use coin
221:08 - number two as well so let's try to do
221:10 - that so again the second option is that
221:13 - we do dynamic programming of 4 - 2 + 1
221:17 - because we are using the the coin with
221:19 - value two so in this case uh we know
221:22 - that we need to generate dynamic
221:24 - programming of two so dynamic
221:26 - programming of two's result we have
221:28 - already stored and that is one so second
221:30 - comparison is that 2 + 1 so these are
221:34 - the two comparisons we have and we need
221:36 - to find the minimum value amongst both
221:37 - of this so this would lead us the value
221:39 - of d dynamic programming of four or the
221:43 - number of coins needed to generate value
221:45 - four so first option is three and second
221:48 - option is actually uh three as
221:52 - well sorry second option is actually two
221:55 - because the value of dynamic programming
221:56 - of two is actually one so in this case
222:00 - we are going to mark this as two so
222:02 - among these two of course two is smaller
222:04 - so we are going to mark two over here
222:07 - and the coins we took to generate is
222:08 - going to be 2 and two same way for for
222:11 - Value number five what are the options
222:13 - we have we can if we subtract one value
222:16 - so then uh if we use coin number one
222:18 - then we can generate this in three coins
222:20 - if we subtract or if we use coin number
222:22 - two then 5 - 3 is going to be 2 so 2 + 1
222:25 - is also going to be three so we this
222:27 - three is going to remain constant here
222:29 - same way in order to generate value
222:31 - number six if we use coin number one
222:34 - then we can use 3 + 1 so one option we
222:36 - have is four second option is that we
222:39 - can come up up to Value number four and
222:41 - then use one coin to reach to six and
222:43 - the value over here is two so we have
222:45 - two options to choose from that is four
222:47 - and three so we can actually choose the
222:48 - value number uh three in this case okay
222:51 - cool now after calculating this at 7 we
222:55 - again have two options we can either use
222:57 - coin number one or coin number two in
222:59 - either case the answer is going to be
223:01 - four so we can mark four over here now
223:03 - at this position number eight we
223:05 - actually we can actually check that if
223:07 - we use one coin like coin with value 1
223:10 - then we need to do dynamic programming
223:12 - of 7 + 1 so that gives us the result of
223:15 - five second option is if we use coin
223:18 - number two then we need to do dynamic
223:19 - programming of 2 + 1 so uh sorry not
223:23 - dynamic programming of two dynamic
223:24 - programming of 6+ 1 so in this case that
223:28 - is going to give us the result of four
223:29 - since we we are picking the minimum
223:31 - value we only need to pick the value S4
223:35 - and that's it we got the answer that it
223:39 - takes 4 minutes minimum coins to
223:41 - generate value number eight if the given
223:43 - coins are uh 1 and two so you see how
223:47 - beautifully we we were able to solve
223:49 - this problem in just one single go
223:52 - because we were calculating all the
223:53 - results we have calculated so far and
223:56 - that is the true power of dynamic
223:57 - programming in my
223:59 - opinion so now let's try to do a really
224:02 - popular lead code problem that has been
224:04 - asked in tons tons of interviews many
224:06 - times and you can see how popular It Is
224:08 - by number of people who have liked this
224:09 - video
224:10 - so basically uh you are you are being
224:13 - asked to climb a staircase now you it
224:16 - takes end steps to reach to the top you
224:18 - are given the value of n now we have the
224:20 - option of either climbing one step at a
224:22 - time or climbing two steps at a time now
224:25 - in either case we need to calculate that
224:27 - how many distinct ways can we climb to
224:29 - the top now for this problem I'm going
224:32 - to show you both top down approach and
224:34 - also bottom of approach and in the code
224:36 - we will see the solution for the bottom
224:38 - of approach okay that Mak makes sense so
224:40 - first let's try to understand the
224:42 - problem with a few simple statements so
224:44 - let's say that if you are currently
224:45 - standing at stair number zero how many
224:48 - steps does it takes of course zero
224:50 - that's a given fact let's say now you
224:52 - currently have one steps available and
224:55 - you are currently standing at position
224:57 - zero and you need to get to step number
224:58 - one how many distinct ways can you get
225:00 - there of course one distinct way because
225:02 - you can only take one step let's take
225:05 - one more example uh currently the number
225:08 - of steps given are two and you are
225:10 - standing at step number zero now how
225:12 - many distinct ways can you get to to
225:14 - Value number two once again you have the
225:16 - option to taking one step over here and
225:18 - then one step over here so that is one
225:20 - way and second way is you can take two
225:22 - steps directly to get to Value number
225:23 - two so there are two distinct ways you
225:25 - can get to Top Just One Last example
225:29 - that is for Value number three okay that
225:32 - let's say that you want to get to the
225:34 - step number three you are at zero and
225:36 - you have the option of 1 2 and three so
225:38 - now how many distinct ways can you go
225:40 - first distinct way is just taking one
225:42 - step each time so this would be way
225:44 - number one second distinct way is that
225:47 - we take two steps directly and then take
225:49 - one step so this would be second step
225:51 - and third step is that we take one step
225:54 - and then we take two steps directly so
225:57 - there are three distinct ways to climb
225:58 - to the top uh for Value number three but
226:01 - now if you notice some interesting
226:04 - property the interesting property is we
226:06 - already know that if we have just one
226:08 - step we need to climb there are only one
226:10 - ways we can do it if we want to climb
226:12 - two steps there are at Max Two Steps we
226:14 - can do it the moment we wanted to
226:17 - calculate that how many times what are
226:19 - the distinct ways we can climb to the
226:21 - top we don't even have to calculate all
226:24 - the values why because in order to reach
226:26 - to three there are only two
226:28 - possibilities first possibility is that
226:30 - we start from value number two and then
226:32 - take one step so that would be one way
226:35 - and second POS possibility would be that
226:37 - we start from value number one and then
226:40 - take two steps basically this would be
226:42 - second possibility now you must be
226:44 - asking that hey what if we take one step
226:46 - to get here still it is still going to
226:48 - be counted towards this distinct step so
226:51 - all we care about is that how many
226:54 - different ways can we get to this value
226:56 - and how many different ways can we get
226:58 - to this value some of these two would
227:00 - allow us to find the next value in our
227:03 - path and this is the important property
227:06 - for dynamic programming that we need so
227:08 - let's try to understand this with an
227:10 - example that in this case for in order
227:12 - to climb to step number three we have
227:14 - two options that we can climb from one
227:16 - is from Step number two and one is from
227:18 - Step number one so if we do sum of these
227:20 - two we can get the value 1 + 2 is equal
227:22 - to 3 now let's try to understand the
227:24 - same logic for five steps okay and now
227:28 - for five steps I'm actually drawing it
227:30 - on an array uh and starting from value
227:33 - zero we will go to all the way to five
227:35 - and see that how each iteration how many
227:37 - changes it takes for us to to get to the
227:40 - value number five okay now in this case
227:43 - uh currently we are using the bottom up
227:46 - approach we are starting from the bottom
227:47 - and then we are going up so initially
227:50 - this takes zero steps this takes one
227:52 - step and this takes two step that's a
227:53 - that's a given fact now in order to
227:55 - climb to step number three we can either
227:57 - take one jump from here or we can take
228:00 - one jump directly from here so we are
228:02 - going to do some of these two so the
228:03 - answer is going to be three once again
228:06 - from 3 to 4 it only has two
228:07 - possibilities one step from here or two
228:10 - steps directly from here so once again
228:12 - we are going to do some of these two the
228:14 - answer is going to be five now in order
228:16 - to reach to step number five we only
228:18 - need to do the sum of these two values
228:20 - and that is eight and eight are the
228:22 - distinct ways we can reach to Value
228:24 - number five see how easy it became in if
228:28 - we if you were to do this in the Brute
228:30 - Force manner you would actually have to
228:32 - first create all the different decision
228:34 - trees you can make starting from
228:36 - position number zero so zero now you
228:38 - have uh two options you can either take
228:40 - one jump and go to position number one
228:42 - or you can take two jumps and go to
228:44 - position number two once again you have
228:45 - two more possibilities you can go to
228:48 - position number two or position number
228:49 - three you can once again have two more
228:52 - possibilities you can go to position
228:54 - number three or position number four and
228:55 - once again you have two more
228:57 - possibilities you can go to position
228:58 - number five or position number four or
229:01 - five and here position number five and
229:03 - the moment you reach to the five you can
229:05 - consider that to be an end of the path
229:07 - and just over here you see that these
229:11 - are this is just one path you can take
229:14 - in order to reach to Val number five
229:15 - then this would be a second path this
229:17 - would be third path and so on and so
229:19 - forth if you keep on going on you would
229:20 - be able to find eight distinct paths and
229:23 - if you were to do it in the Brute Force
229:25 - manner without using the dynamic
229:27 - programming the time complexity would
229:29 - have been 2 to the power of n because at
229:31 - every single position we have two
229:33 - different options to choose from and
229:36 - this is a disastrous result so that is
229:38 - why you using dynamic programming was
229:40 - great now you understood that how we use
229:43 - bottom of approach let me show you the
229:44 - result for the top down approach as well
229:47 - where we are going to start from the
229:48 - very top element and we are going to
229:50 - come our way down to the very last
229:52 - element okay so currently the values are
229:54 - 5 4 3 2 1 and zero now we know that if
229:58 - we are at step number five how many
230:00 - distinct ways to get there of course
230:01 - zero because we are already at set step
230:04 - number five we don't have to calculate
230:05 - anything if we are at step number four
230:07 - there is only one distinct way to get to
230:09 - step number five so we are going to mark
230:11 - this as one if we are at step number
230:13 - three there are actually two ways to get
230:15 - to step number five we can take one step
230:18 - over here and then one step over here or
230:20 - we can take one step directly over here
230:22 - so in this case there are two options
230:24 - from now on we can apply the same logic
230:26 - in the reverse order because from Step
230:29 - number two we only have two options that
230:31 - we can choose from we can either go
230:33 - directly to step number three that would
230:35 - be one distinct way and second distinct
230:37 - way would be we can directly go to step
230:38 - number four from there on we already
230:40 - know that how many different ways it
230:42 - takes to get to step number five so we
230:44 - can just use that property so basically
230:46 - from Step number two we can go to three
230:49 - distinct ways and that came from some of
230:51 - these two values same way from value
230:54 - number one we can actually go to five
230:56 - distin distinct Ways by taking the sum
230:59 - of these two values because these are
231:01 - the only two possible jumps we can make
231:03 - and from value number zero we again have
231:06 - eight different ways that we can make
231:07 - this jump and this is our top down
231:10 - approach so see in both the sessions we
231:13 - got the correct answer we used dynamic
231:16 - programming to calculate the already
231:18 - calculated result and then we were able
231:20 - to come up with the appropriate and
231:22 - successful result in the end so now
231:24 - let's see the code for this and I hope
231:27 - you understood what dynamic Pro dynamic
231:29 - programming is and what are its key
231:31 - fundamental reasons so this is the
231:34 - problem statement and here is the Java
231:36 - code for that uh basically we are using
231:38 - bottom up op approach so first we are
231:40 - checking for the edge case that if the
231:41 - given n is equal to 1 we can simply
231:43 - return one if that is not the case we
231:45 - are going to initialize our dynamic
231:47 - programming array and we are going to
231:49 - check out or put down the base case
231:52 - values for uh number of stairs as one
231:54 - and number of stairs as two after that
231:56 - we are going to run a for Loop starting
231:58 - from the step number three all the way
232:00 - to the end and we are going to apply our
232:02 - dynamic programming logic which is quite
232:04 - simple to understand in the end we are
232:06 - simply going to return the dynamic
232:08 - programming value be found at the very
232:10 - end value now let's try to run this code
232:12 - okay seems like our solution is working
232:14 - let's submit this code and our code runs
232:17 - 100% faster than all the other Solutions
232:19 - which is pretty good to see and uh now
232:22 - you can understand that how simple it is
232:24 - to code the dynamic programming
232:28 - solution okay so now let's learn the
232:31 - sliding window technique this is a
232:33 - really popular coding technique and
232:35 - typically works really well with many of
232:37 - the array and string kind of problems
232:40 - now first let's try to understand that
232:42 - what does a sliding window technique
232:43 - means let me give you an example suppose
232:46 - I tell you that you have this rope and
232:49 - currently this rope the entire rope is
232:51 - actually in the color blue now I ask you
232:55 - that I want to change this color from
232:57 - Blue to Pink so how would you do that
232:59 - well you actually have a couple of
233:01 - options to do it number one and most
233:04 - naive approaches that you actually put
233:06 - down a table now on top of this table
233:09 - table you lay down your blue colored uh
233:12 - uh rope and then you start pouring on
233:16 - the pink color all across the table and
233:18 - then eventually entire table is now
233:20 - dripping up with p pink color and some
233:23 - of that paint has already stuck onto the
233:25 - Rope as well and now our rope is
233:27 - actually pink colored so this approach
233:29 - will give you the correct rope color
233:31 - that you want but in this process you
233:33 - would have wasted lot of paint as well
233:35 - so that is not a very good approach a
233:38 - better solution might be that suppose
233:40 - you are given this rope uh I ask you
233:43 - that hey paint this uh in the pink color
233:45 - you take a paint brush and now in this
233:48 - paint brush you apply the color pink for
233:51 - this portion and after applying whatever
233:53 - the current width of the paint brushes
233:56 - you take that width and try to paint
233:59 - that much area pink for now and once
234:02 - that is done you again take your
234:04 - paintbrush replenish it with the pink
234:06 - color and again repeat the same process
234:08 - for for the next set of uh remaining uh
234:12 - rope as well and eventually you would
234:14 - cover all the ground and eventually the
234:16 - whole rope would have been painted blue
234:18 - or sorry pink and that is the most
234:21 - simple example of what a sliding window
234:24 - is where in the longest input we had
234:28 - which was our rope we actually created a
234:31 - small subset of window that we applied
234:36 - on one particular portion of given in
234:38 - input once it achieved our con
234:41 - conclusion or the thing we wanted to
234:43 - compute then we took the same thing to
234:46 - the next area and then we took the same
234:48 - thing to the next area until we reach to
234:50 - the very end and we find the appropriate
234:53 - answer that we were looking for so this
234:56 - can be a very powerful tool in many
234:58 - examples and let's try to understand
235:01 - that with a simple example suppose we
235:02 - are given an input array a where we are
235:05 - given some arbitrary random values okay
235:07 - let's just Mark these values is 1 3 7 uh
235:11 - 2 5 8 and 9 okay these are the values we
235:14 - are currently given now I ask you that
235:17 - find me the maximum sum of three
235:21 - consecutive elements so what you what
235:24 - would be your approach in this case well
235:27 - one approach is that you actually start
235:30 - doing or making every single pair and
235:33 - try to come up with the solution so in
235:35 - that case you first take these three
235:37 - values do it sum then you take these
235:39 - three values do it sum then you take
235:41 - these three values do it sum and so on
235:43 - and so forth and eventually you will
235:44 - find the result or the second option is
235:47 - that you actually create a window of
235:50 - three characters and then keep on
235:52 - incrementing the sum uh and try to find
235:55 - that which has the maximum sum so let's
235:57 - try to use the sliding window technique
236:00 - in this one so suppose I create an
236:03 - element called Max sum that is to keep
236:05 - track of the maximum sum I'm also
236:07 - creating another variable called current
236:09 - sum and this is going to be our window
236:12 - of three elements that we are dealing
236:13 - with so first let's say that we take
236:15 - these three elements so now the sum is
236:18 - current sum is 11 and so far the maximum
236:20 - sum we have been able to find is also 11
236:23 - okay now we need to check or move our
236:25 - window on the on the side but the window
236:29 - size will remain same so once again we
236:32 - are creating a new window and that new
236:35 - window is going to be starting with
236:38 - value value three okay so let's create
236:41 - another window now the moment we we
236:44 - created new window do we need to
236:46 - calculate the sum of all of these three
236:49 - values well actually no we have a better
236:52 - approach and that better approach is
236:54 - that we can actually take the previous
236:56 - sum we already had that had current
236:59 - value what we did essentially in this
237:01 - one we subtracted one from this window
237:05 - that we got rid of this value and we
237:07 - added two in this case so we can simply
237:10 - do this computation now you must be
237:12 - wondering that this is only three
237:14 - elements so why are we even bothering
237:16 - doing this imagine if this was like 500
237:19 - elements and this was a very large area
237:21 - of million characters in that case this
237:24 - computation would save you so much time
237:26 - because every time you only have to
237:28 - subtract one element and add another
237:30 - element and that's it you will get the
237:33 - sum of all the consecutive values of
237:36 - those 500 values you don't have to to do
237:39 - much work and iterate over all 500
237:41 - values to find the result so in this
237:42 - case now this sum is going to be uh 12
237:45 - so 12 is definitely greater than 11 so
237:47 - we would update our Max variable that
237:50 - currently the maximum sum we have found
237:52 - is going to be 12 okay and we are also
237:54 - going to update our current sum as well
237:56 - to Value number 12 once again we got rid
237:58 - of three and we add value number five in
238:00 - this case so - 3 + 5 the answer is going
238:04 - to be 14 once again we update our
238:06 - maximum variable to Value number 14 and
238:09 - same way we update our current variable
238:11 - as well so 14 and 14 and currently we
238:13 - were looking at this uh pair now let's
238:16 - subtract seven and add value number
238:18 - eight so in this case the current sum is
238:21 - going to be 15 which is also the maximum
238:23 - sum we have found so far so we would
238:24 - update that once again let's get rid of
238:27 - value number two and add value number N9
238:29 - so in this case the sum is going to be
238:31 - 22 and that is the maximum sum and we
238:33 - can update that see how easy it became
238:36 - once we created a simple window and then
238:39 - we iterated or moved all the way over
238:41 - there so this is everything you need to
238:44 - understand about sliding window
238:46 - technique well sliding window is not
238:48 - very TP very difficult to comprehend and
238:50 - let me give you another example okay now
238:54 - this is one of the most popular problem
238:56 - on lead code and has been asked in tons
238:58 - of companies uh basically we are given a
239:01 - simple string s and we need to find the
239:03 - longest substring that does not have any
239:06 - repeating characters so if we see an
239:08 - example example over here in this case
239:10 - we have we are given a bunch of long
239:12 - string but we can see that first a b c
239:15 - is the longest string that does not have
239:16 - any repeating characters and its length
239:19 - is three so we are going to return three
239:20 - as the answer because apart from that
239:22 - all the other places actually has
239:24 - repeating character so the window is not
239:26 - large enough okay so now let's try to
239:28 - see that how would we solve this problem
239:30 - suppose we are given a problem like this
239:32 - that uh a b a c d a something like this
239:38 - this okay we are given this as the input
239:40 - and we are trying to find the longest
239:41 - substring without repeating characters
239:43 - so of course we are going to use sliding
239:45 - window in this on top of that we will
239:47 - also have to use some additional data
239:49 - structure to keep track of all the
239:51 - values we currently have in our existing
239:53 - window so for that uh hash map or hash
239:56 - set is actually great so we will use
239:58 - hash set because we don't need to have
240:00 - indexing in this place but we only need
240:02 - to know that what are the elements
240:04 - currently present inside our existing
240:06 - window okay so let me just quickly draw
240:09 - our hash set and now the approach is
240:11 - that we are going to have two pointers
240:13 - so first pointer is going to be left
240:15 - pointer second pointer is going to be
240:16 - right pointer initially we are going to
240:19 - keep moving right pointer until the
240:21 - point where we do not encounter any uh
240:25 - repeated characters and we would Mark
240:28 - its length uh as the maximum length we
240:31 - have been able to find so far the moment
240:33 - we encounter a repeated character we are
240:35 - going to take left pointer to move one
240:37 - step to the right right and then keep on
240:39 - repeating the same process and meanwhile
240:41 - we would only move right if the value is
240:43 - not currently present inside the hash
240:45 - set if it is present then we would move
240:47 - the left pointer and uh let's try to see
240:51 - the solution in action okay so first we
240:53 - are both are at the same position and we
240:56 - have our maximum uh substring length
240:59 - that is currently zero and hash set is
241:01 - empty okay so now let's see currently a
241:05 - is not in the hash set so we will add
241:06 - entry a over here and then move right
241:08 - pointer to the next element uh now after
241:12 - doing that now let's see a b are still
241:15 - distinct B is not added so we would add
241:17 - B over here as well and move on to the
241:19 - next element so next element currently
241:21 - is uh a again so because this is a once
241:25 - again okay what is the maximum window we
241:26 - have been able to find so far that was
241:28 - only two characters so we will Mark two
241:30 - two over here as the answer now because
241:33 - we find an identical value we are going
241:36 - to move our left pointer to the right
241:38 - the moment we move left pointer to the
241:40 - right whatever the value we had in the
241:42 - left pointer we are going to delete this
241:44 - so first let me get rid of this value
241:47 - okay now after getting rid of this value
241:50 - uh we we have our R located over here so
241:52 - we will have to add an entry a over here
241:55 - and now currently the window size is
241:57 - still two now let this R go to next
242:00 - element so it will go to next element c
242:02 - c is also unique now let this R go to
242:05 - next element d d is also unique so it
242:07 - can still still stay over here now the
242:10 - next element is once again a a we
242:13 - already have inside the existing hash
242:15 - set which means okay so far the maximum
242:17 - window we have been able to find is of
242:19 - size four so let's mark four over here
242:22 - and once again let's try to update the
242:24 - value so now we are going to move move
242:26 - our left pointer one step to the right
242:28 - okay after moving it one step to the
242:30 - right again remember we haven't added
242:32 - this a yet because it was a duplicated
242:34 - entry okay so we added we removed B from
242:37 - here so we got rid of B from our hash
242:40 - set once again this value is a and once
242:43 - again our right pointer is still stuck
242:44 - over here now this left pointer we got
242:46 - rid of a okay after getting rid of a now
242:51 - we can check that whether right pointer
242:52 - can be added over here or not yes now it
242:54 - can so we will add a over here and now
242:58 - uh we will try to move our right pointer
243:00 - but now it is the end of our list so
243:02 - this is only of size three this uh
243:06 - substring without repeated characters
243:08 - and maximum we have been able to find is
243:10 - four so four is going to be our answer
243:11 - and this is what we are going to return
243:12 - return so now you imagine how we had
243:15 - like a dynamically changing sliding
243:17 - window in this example to solve this
243:20 - problem and we actually use hash set and
243:22 - tandem to solve this problem now U this
243:25 - is quite a simple problem so I'm not
243:28 - going to show the coded solution but I
243:30 - do have the coded solution available on
243:32 - the GitHub link and I'm going to post it
243:35 - in the description so you would be able
243:36 - to check it out from there if you are
243:37 - curious ious now let's move on to the
243:39 - next topic that is called two
243:44 - pointers okay now let's try to
243:46 - understand one of the interesting uh
243:48 - coding pattern that is very similar to
243:50 - sliding window and that is called two
243:52 - pointers now this two pointers is
243:54 - actually really popular with data
243:56 - structures like array and strings and
243:59 - the idea is that just like a sliding
244:01 - window we are going to have two pointers
244:04 - but these two pointers are typically
244:06 - going to be located at the edges of Any
244:09 - Given array and depending on certain
244:11 - scenarios the pointers would come
244:13 - towards each other based on the various
244:16 - scenarios that we have available okay so
244:18 - this is the whole premise now if you
244:20 - want to understand this uh with a real
244:23 - life example you can think about that
244:25 - let's say that you are currently located
244:27 - on a Long Beach and inside this Beach uh
244:31 - you maybe lost something or uh some some
244:35 - of your maybe cousin or child or someone
244:38 - so the idea you are going to use is that
244:41 - you and your wife you both are going to
244:43 - go to different ends of the beach and
244:46 - you would try to come towards each other
244:48 - trying to find the child that whether
244:50 - that child is maybe located somewhere
244:52 - and try to consider that beach is just
244:54 - like a simple line so you are not moving
244:57 - in any other direction So eventually you
244:59 - would be able to find the child who is
245:01 - going to be located somewhere but
245:03 - essentially you and your wife you are
245:05 - going to be coming towards each other
245:07 - and the this is the whole concept of
245:09 - two- pointer solution so let's try to
245:11 - understand this with an example okay so
245:14 - let's try to solve this problem squares
245:16 - of a sorted array now this is a very
245:18 - popular problem and also a very simple
245:21 - explanation yet it explains that how we
245:24 - can use two pointers to our maximum
245:26 - Advantage uh basically we are given a
245:28 - nums array and we are told that this
245:29 - array is already sorted in an increasing
245:32 - order now we need to return a new array
245:36 - that contains square of every single
245:38 - element but we need to make sure that
245:40 - this is also in non decreasing or
245:42 - increasing order so assume that suppose
245:46 - we are given an input array like this 1
245:48 - 2 and four this array is currently in
245:50 - increasing order so in the answer we
245:52 - need to return the square that is also
245:54 - going to be 1 4 and 16 and this is the
245:57 - answer we need to return now looking at
245:59 - this example you must be thinking that
246:01 - hey this is quite simple all we need to
246:03 - do is just square of two elements and
246:05 - then we can simply return it as it is
246:08 - but it's not as as simple as it is
246:10 - because we could have an input that
246:12 - looks like this where the values could
246:14 - be Min - 8 - 1 0 and then 1 and then two
246:18 - suppose if this is the array given in
246:21 - this case the answer has to look
246:23 - something like this where the first
246:25 - value is going to be 0o because 0 square
246:27 - is 0 then 1 square is going to be 1 then
246:31 - once again - 1 square is also going to
246:33 - be 1 then 2 square is going to be 4 and
246:35 - then - 8 square is going to be 16 64 so
246:38 - see this value came over here this value
246:41 - came over here this value came over here
246:43 - so everything got jumbled up because we
246:46 - had some negative values and yet this
246:48 - satisfied the property of being in
246:50 - increasing order and this also became an
246:53 - increasing order so now how do we deal
246:55 - with negative numbers in this scenario
246:58 - so one root force or naive approaches
247:01 - that whatever input we are given suppose
247:03 - the values are -4 -2 1 and 3 suppose
247:07 - this is the input value we are given uh
247:09 - one simple approach is that we simply do
247:12 - a square as it is so values like 16 4 1
247:16 - and 9 and then we do the sort operation
247:19 - on this array so if we do that we will
247:21 - again get the correct answer that is 1 4
247:24 - 9 and 16 but this is going to be done in
247:27 - N log n time so we will try to see that
247:31 - can we do it faster in just log and uh B
247:35 - of end time rather than using log andun
247:37 - function and yes the answer is we can do
247:40 - it plus you already know because we are
247:42 - explaining two pointers for sure we are
247:44 - going to do it using two pointers the
247:46 - idea is we will have our left pointer
247:48 - located on the last location we will
247:50 - have a right pointer located on the
247:52 - rightmost position and then we are going
247:54 - to have our answer Square okay now what
247:58 - we are going to do is it is only
248:01 - possible that if this value is too
248:03 - negative it could either end up
248:06 - somewhere over here here or it could e
248:09 - if it is positive value then it has to
248:11 - end up over here there are only two
248:13 - possibilities so what we are going to do
248:15 - is at every single location we are going
248:17 - to compare the value of this with its
248:20 - right counterart and whichever value is
248:23 - going to be higher we are going to put
248:24 - that in the end and whichever value we
248:27 - put that pointer we would move to the
248:29 - next element and again repeat the same
248:31 - procedure so let's see the solution I'm
248:33 - proposing in ation action so first we'll
248:36 - compare this left with right and we are
248:38 - going to do square of both of them so
248:40 - square of left is going to be 16 and
248:43 - right square is going to be 9 so again
248:45 - left is greater because left is greater
248:48 - first we are going to add value number
248:49 - 16 over here and then we will move our
248:51 - left pointer and once again repeat the
248:53 - same exercise so now this time uh left
248:57 - pointer is located over here okay so now
248:59 - square of two is going to be four and
249:01 - square of three is going to be 9 so
249:03 - because 9 is greater now we are going to
249:05 - put 9 over here once again we are going
249:07 - to move left pointer in this case
249:09 - because we added nine here now this is 1
249:11 - and this is min -2 so square is going to
249:14 - be four and this is going to be 1 so
249:15 - once again next value we have to enter
249:17 - is going to be four and then we are
249:18 - going to move our left Point pointer on
249:20 - the right and then since because left
249:22 - and right now both are at the same
249:24 - position we are going to add the one as
249:26 - the last element over here and return
249:28 - this as the answer so see how we were
249:31 - able to generate the entire solution in
249:33 - just one single pass and this is the
249:36 - beauty of two pointer approach that
249:38 - whenever you see solution where you need
249:41 - to compare both sides of given input
249:43 - array or string try to think that can
249:46 - you solve this problem using two
249:47 - pointers and most likely this could be
249:50 - one of the possible solution so now let
249:53 - me give you a quick trick after we have
249:55 - understood lot of things about array
249:57 - first thing is whenever you are given an
249:59 - array try to think that can you sort
250:02 - this given array to generate some result
250:04 - second try to think can you use some
250:06 - some of the hashing function like hash
250:08 - map or hash set then if not try to S
250:12 - think can you use a sliding window
250:13 - technique otherwise try to think can you
250:16 - use two pointer technique typically
250:18 - amongst all of these most likely you
250:21 - would be able to find the answer you are
250:23 - looking for and this is the key trick
250:26 - for to solve any array based question in
250:29 - any of the technical interviews okay so
250:31 - now we are going to see the solution for
250:33 - squares of sorted array uh so let's see
250:36 - first of all we are going to create a
250:38 - variable called n and that is going to
250:40 - be the length of given input array then
250:42 - we are going to create a new array to
250:44 - store the result we are also going to
250:46 - initialize two pointers first is going
250:47 - to be the left pointer second is going
250:49 - to be the right pointer left pointer is
250:51 - located on the leftmost position
250:53 - rightmost right pointer is located on
250:55 - the rightmost position then we are
250:58 - running a for Loop in the reverse order
251:00 - and we are we are going to have a
251:02 - function that basically takes care of
251:05 - the Square value and then we are going
251:07 - to compare the square of the left
251:10 - element with the right element so
251:12 - basically what we are doing is uh we are
251:14 - simply comparing the absolute values of
251:18 - left element with the absolute values of
251:20 - right element so we are ignoring the
251:22 - minus sign and whichever value is
251:24 - greater we are putting that in the
251:26 - square and in the end in the result of
251:29 - that particular I value we are just
251:32 - storing whatever the square variable we
251:34 - were able to find either left or right
251:36 - and then uh in the end we simply return
251:38 - the result array that we have created
251:41 - now let's try to run this code okay
251:43 - seems like our solution is working let's
251:45 - submit this code and our code runs 100%
251:48 - faster than all the other Solutions
251:50 - which is quite awesome so now you got
251:52 - the idea of how two pointer Solutions
251:57 - work okay so first let's try to
252:00 - understand a really interesting coding
252:02 - pattern that is called fast and slow
252:04 - pointer now this is most prevalent and
252:06 - very heavily used in link list kind of
252:09 - problem so you might think whenever you
252:12 - are trying to solve some linkless
252:13 - problem try to think that can you use
252:15 - this technique in this scenario and
252:17 - first let's understand that what does a
252:19 - fast and slow pointer technique is it is
252:21 - very similar to a two-p pointer
252:23 - technique but uh in the two pointers
252:25 - where we have two pointers left and
252:27 - right coming towards each other in this
252:29 - scenario we actually have a fast pointer
252:32 - and a slow pointer both typically starts
252:34 - from the same position but fast pointer
252:37 - would would make double jumps so fast
252:39 - pointer would go to the next to the next
252:42 - value meanwhile slow pointer would only
252:44 - make a single jump like a normal uh
252:47 - typical traversal we do and doing this
252:50 - would yield us uh some good results in
252:52 - couple of specific positions so first
252:55 - let's try to see that how does a typical
252:57 - concept looks like let me draw a random
253:00 - uh link list now we are assuming that
253:02 - this one is a single link list but same
253:04 - thing would apply for a dou link list as
253:06 - well and this is the head of the link
253:08 - list and this is the last element so
253:10 - this value points to the null value now
253:13 - in this case the overall idea for the
253:16 - pattern is that we are going to have two
253:18 - variables so first one is a fast and
253:20 - second one is a slow variable okay so
253:22 - currently let's imagine that both fast
253:25 - and slow pointers are based at the head
253:27 - position okay now fast pointer is move
253:30 - in the Direction Where We are going to
253:31 - choose the next element for fast is
253:33 - going to be node do next do next so next
253:39 - to the next element for any given node
253:41 - would be the next node for the fast
253:43 - pointer meanwhile for slow pointer it is
253:45 - only going to be node do next that is
253:47 - the regular traversal so during the
253:50 - first iteration fast node is going to do
253:52 - node do next do next so fast pointer
253:54 - would end up over here meanwhile slow
253:57 - pointer would have end up over here in
253:58 - the second iteration fast pointer would
254:01 - end up over here meanwhile slow pointer
254:03 - would have ended up over here and doing
254:05 - this now fast pointer is is at the very
254:07 - last element inside the link list so now
254:10 - we can use some properties so the
254:12 - question comes that where does this
254:14 - technique is actually used so I can give
254:16 - you two examples right now first example
254:18 - is that I already showed you previously
254:20 - in the course where you need to find the
254:22 - middle of the link list in that case uh
254:25 - fast and slow pointer is very good use
254:28 - case to follow that if we want to find
254:30 - the middle of the link list typically we
254:32 - can do that and try to consider the same
254:35 - scenario in this example we are seeing
254:37 - that right now the fast pointer actually
254:40 - reached to the end position because fast
254:42 - do next is equal to null which means
254:44 - this is the last position around that
254:46 - time slow pointer is exactly located at
254:48 - the middle element and which we can see
254:51 - right over here so whenever we are being
254:52 - asked that hey go ahead and find the
254:54 - middle of the link list always try to
254:56 - use fast and slow pointer because that
254:58 - would be the quickest method to find the
255:01 - solution another one solution is that
255:04 - when you need to detect a cycle inside a
255:06 - link list and now the question comes
255:08 - that how can we actually detect a cycle
255:10 - inside the link list using the fast and
255:12 - slow pointer so let me give you an
255:13 - example for that as well now suppose uh
255:16 - let's assume that we currently have a
255:18 - bunch of different nodes lying around
255:21 - and we will try to see that how would a
255:24 - cycle inside the link list would look
255:26 - like okay now let's assume that all of
255:29 - these nodes are connected and in this
255:32 - case there is a cycle present like this
255:35 - okay now we don't know initially because
255:37 - this is a singly link list and we we
255:39 - have no idea that what are the next
255:41 - elements so let's assume that if you had
255:43 - to detect that find that if there is a
255:46 - cycle in this case or not how would you
255:47 - detect it uh one basic and naive
255:50 - approaches that let's say that these are
255:52 - all the values for this given uh link
255:55 - list what we can do is we can actually
255:57 - start iterating the given link list and
255:59 - we can have another data structure like
256:01 - a hash set and we can keep checking that
256:04 - whether this node has been previously
256:06 - visited or not and if we reach to the
256:08 - null value we can say that there are no
256:10 - Cycles in the link list like the next
256:12 - node is the null node then there are no
256:14 - Cycles in the link list if the next node
256:16 - is not null and we encounter some node
256:18 - that is already present in the hashset
256:20 - we can say that this node has been
256:21 - repeated so let's try to run this
256:23 - example first we will add all of these
256:25 - values so 1 2 3 4 5 6 7 and 8 all the
256:29 - values we would iterate but before that
256:31 - we would check whether it is present
256:33 - inside the hash set or not because it's
256:35 - not present we would add all of this 1
256:37 - to eight values over here now the moment
256:39 - we would try to iterate to this value we
256:41 - would realize that this three has
256:43 - already been added to to the hash set
256:45 - which means we encountered a value that
256:47 - has been added so that's why we can say
256:49 - that yes there exist a cycle in this
256:51 - case but now issue with this approach is
256:53 - that we actually have to use an
256:55 - additional has set so the space
256:57 - complexity in this case would be big go
256:59 - of n which we don't want we want to do
257:02 - this problem without using the space
257:04 - complexity so the another approach is to
257:06 - use fast and slow pointer and let me
257:09 - show you that how would that look like
257:11 - the whole solution okay so let's get rid
257:13 - of this hash set and let's have our fast
257:16 - and slow pointer ready so initially our
257:18 - fast pointer would be located over here
257:20 - and slow pointer would be located over
257:22 - here now let's make two jumps for the
257:24 - fast pointer and one jump for the slow
257:26 - pointer so after which fast pointer is
257:28 - going to end it up end it up over here
257:31 - and same way slow pointer is going to
257:33 - end up over here okay now once again
257:35 - fast pointer is going to end up over
257:36 - over here and slow pointer in this
257:39 - position has ended up over here okay now
257:43 - let's repeat the same process now fast
257:45 - pointer would come over here same way
257:48 - slow pointer would come over here and
257:50 - let's get rid of the previous two
257:52 - elements once again fast pointer is
257:55 - going to make two jumps so fast pointer
257:56 - would end up over here and in this time
258:00 - slow pointer would have made one jump so
258:02 - slow pointer would be here now when fast
258:04 - pointer makes two jumps it is guarantee
258:07 - that it is going to encounter slow
258:08 - pointer in this scenario and the moment
258:11 - we find out that fast pointer actually
258:12 - came back to the slow pointer or the
258:15 - position where slow pointer is we can
258:17 - say that there is a cycle in this
258:18 - scenario and we can return true that yes
258:21 - there exists a cycle so basically this
258:24 - is the whole concept of fast and slow
258:26 - pointers so whenever you are trying to
258:27 - solve some problem related to link list
258:30 - try to think that hey can I use two
258:32 - pointers where one pointer is faster
258:34 - than the other and try to come up with
258:36 - the solution more than likely you will
258:39 - be able to find some good answers in
258:44 - that now let's learn an awesome
258:46 - technique called backtracking
258:48 - backtracking is highly popular in lot of
258:50 - different scenarios and you can
258:52 - typically use backtracking to solve
258:54 - problems like dynamic programming
258:57 - recursion uh tree problems and graph
259:00 - traversal problems so for all of these
259:03 - things backtracking is heavily useful so
259:05 - you can imagine that how popular it is
259:07 - going to be if you ever wants to
259:10 - implement these data structures and try
259:12 - to come up with a solution so first
259:14 - let's do this we will try to understand
259:16 - that what backtracking is then we will
259:19 - try to see that what is some real life
259:21 - example so I'll probably give you a
259:23 - couple of real life examples and then we
259:25 - will try to see how we can navigate
259:28 - using backtracking in the depth for
259:31 - search manner so that is how and we are
259:34 - we will try to navigate it within trees
259:36 - and graph and on top of that we will see
259:38 - one of the lead code examples as well
259:40 - okay so first let's understand that what
259:42 - does a backtracking is backtracking is
259:45 - nothing but an ability to go back to the
259:49 - previous place we were at essentially
259:51 - let's say that we are following some
259:53 - certain path and at any given position
259:57 - we have the option to choose uh some
259:59 - different paths as well depending on the
260:01 - CH choices we make so let's assume that
260:03 - in this scenario we decide to take down
260:06 - uh and go we initially started with this
260:09 - and we go down this path this path and
260:11 - from this moment we decide to go to next
260:14 - PATH over here and from this we decide
260:16 - to go to the next PATH over here but we
260:19 - did not find the answer we were looking
260:20 - for so what we would do we would come
260:23 - back again to this node and try to check
260:26 - a different path once again since we did
260:28 - not get the answer we would once again
260:30 - try to get back to this path where we
260:32 - originally branched out come back to the
260:34 - same PL same path and then choose a
260:37 - different option and keep a track that
260:40 - which path that we have already taken so
260:43 - that would help us determine or backrack
260:46 - our actions that's it this is the whole
260:49 - concept of backtracking if you have to
260:51 - understand this let's say that you are
260:53 - currently located inside a garden and
260:56 - this is like a maze Garden so you don't
260:59 - know where you are going okay so
261:01 - typically all the roads are crossed in
261:05 - weird manner
261:06 - where some roads don't lead to any other
261:09 - place and then there are some roads that
261:11 - leads to different positions in the
261:13 - garden so what would be the approach you
261:15 - would take let's say that you typically
261:16 - started from here what is going to be
261:18 - the approach you are going to take well
261:20 - essentially the idea is let's say from
261:22 - this place you started traversing this
261:25 - path you would keep on going and realize
261:27 - that hey there is no path in this case
261:28 - so of course you are going to backtrack
261:30 - you are going to come back to the
261:32 - position where you originally started
261:33 - once again try to take a different path
261:36 - and again make some different decisions
261:38 - so if you go down this path once again
261:40 - it does not work so you will backtrack
261:41 - to a previous position where you made
261:43 - the choice and once again take this New
261:46 - Path and eventually this New Path might
261:48 - end up might lead you to the Final
261:50 - Destination you are trying to get so
261:52 - this is one example of backtracking so
261:54 - now let's try to see that how does
261:55 - backtracking would typically work in a
261:57 - tree like scenario okay so currently let
262:00 - me just draw a very simple binary tree
262:03 - where I have bunch of different uh nodes
262:05 - and each node had has some children
262:08 - associated with them and for each one of
262:11 - them I'm trying to see that what is
262:13 - going to be the most optimal path or
262:16 - let's say I'm trying to find this value
262:18 - x uh this node X so first I go down this
262:22 - path then once again I go down this path
262:24 - and by the way I'm using DFS in this
262:26 - case depth for search which means I'm
262:28 - going in the depth rather than going in
262:30 - the breath so I go over here I don't
262:32 - find anything so I will backtrack once
262:35 - again from this I know that there is one
262:37 - option left that I haven't checked once
262:39 - again in this case I haven't checked the
262:42 - I didn't find anything so I'll backtrack
262:45 - once I know that I have exhausted all of
262:46 - this possibilities I can also go back to
262:49 - the original root node and once again
262:51 - repeat the same process and in this case
262:53 - since I don't find anything I will again
262:54 - backtrack and okay here I find the X I
262:57 - was looking for and I can say that yeah
262:59 - this is the correct path and I can
263:00 - return that as the answer so this this
263:02 - would be an example of how uh
263:05 - backtracking would work in a tree like
263:07 - data structure and same concept applies
263:09 - to the graph as well because trees and
263:11 - graphs are very similar the only
263:13 - difference is graphs can have Cycles
263:14 - trees typically don't have cycle so even
263:17 - in terms of backtracking the same logic
263:19 - would apply that let's say that you
263:20 - decide to go to this path and then this
263:22 - path first but this part does not yield
263:23 - the result you are looking for once
263:25 - again you would backtrack and you would
263:27 - go to a different path and through which
263:29 - you find the result you are looking for
263:30 - and you get the correct answer so
263:33 - backtracking is nothing but the ability
263:35 - to go back now let's try to understand
263:37 - backtracking with one of the lead code
263:41 - examples okay now let's assume that this
263:44 - is the problem we are trying to solve
263:45 - binary tree paths now we can see that
263:48 - this has been relatively popular problem
263:50 - and the problem statement is actually
263:52 - quite simple to understand we are simply
263:53 - given the root of a binary tree and we
263:56 - need to return all root to leaf paths in
263:59 - on any order so let's try to understand
264:01 - this with an example suppose we
264:03 - currently have a binary tree that looks
264:06 - like this now in this case let's give
264:09 - some arbitary values as well uh so the
264:11 - values are going to be 1 2 3 4 five and
264:15 - six okay these are the values for each
264:16 - node so in this case how many different
264:19 - paths we have from root to node so first
264:21 - path is that we can go down this this
264:23 - scenario and this scenario so 1 to 2 to
264:27 - 3 this is a path to leave okay once we
264:29 - identify and let's create our answer
264:31 - list where we are going to store all the
264:33 - results that we are we have been able to
264:35 - find so far Okay so we found one path
264:37 - after finding this we will backtrack to
264:39 - the previous element once again repeat
264:41 - the same procedure to the remaining path
264:44 - okay we completed the remaining path and
264:46 - now this path is 1 2 and four okay once
264:49 - again back track okay now we exhausted
264:51 - all the possibilities over here so once
264:53 - again we are going to backtrack to the
264:55 - previous element from one we still have
264:57 - unexplored paths so we will start
265:00 - exploring and we will keep on going
265:02 - until we find the leaf node that we are
265:04 - looking for so in this case okay we find
265:06 - the leaf node as six and now we will add
265:08 - one more path that is 1 5 and six and
265:11 - now we explored all the paths so this
265:13 - answer list we can return as the answer
265:16 - and basically that's it okay so this is
265:19 - the problem statement binary tree paths
265:21 - and here is the solution basically the
265:24 - first thing we are going to do is uh we
265:25 - are going to check for the edge cases
265:27 - that if the given root element is equal
265:29 - to null we can simply return the paths
265:31 - we have if not we have already created a
265:33 - new link list that contains the list of
265:35 - all the parts we are going to create now
265:38 - in order to implement the backtracking
265:40 - we will have to use stacks and in the
265:42 - stack we are going to add the current
265:45 - root node and then we will keep on going
265:47 - it to iterate all the possibilities
265:50 - until we find our stack is empty or not
265:52 - and when we learn more about DFS you
265:54 - would be able to understand this
265:56 - technique that how this technique
265:58 - actually really works and how it is
265:59 - pretty efficient way to implement the uh
266:02 - backtracking method for the depth first
266:04 - search scenario so so now we have our
266:07 - link lists initialized now first we are
266:09 - going to add the root element to our
266:11 - link list and then we are also going to
266:13 - add a new path to store the integer
266:16 - value and then we are going to run a
266:18 - while loop that while the given stack is
266:20 - not empty we will keep on repeating the
266:23 - same process and basically this piece of
266:25 - code does nothing but it only Travers
266:28 - through the left side of the node or the
266:31 - right side of the node until we reach to
266:33 - a point where there no longer exist any
266:36 - more children for any particular value
266:38 - and once we get that we would add those
266:40 - values to the subsequent paths and in
266:43 - the end we are simply returning the path
266:45 - so if you didn't understood what I
266:47 - mentioned I'm going to post the solution
266:49 - in the GitHub link as well so you can
266:50 - check it out from there and you should
266:52 - be able to understand let's try to run
266:54 - this
266:55 - code and seems like the solution is
266:57 - working as expected let's submit this
266:59 - code and our code runs pretty
267:02 - efficiently compared to a lot of other
267:03 - Solutions Plus this is this gives you an
267:06 - idea that how does a typical uh depth
267:09 - for search or backtracking works for any
267:13 - tree or graph related
267:18 - problems okay now we are going to
267:20 - understand another interesting pattern
267:22 - that is called intervals intervals are
267:25 - nothing but the spaces of time or
267:28 - sequence in between and we need to do
267:31 - some work with that or some computation
267:32 - with that typically in the intervals
267:35 - type of problem you would always be
267:37 - given some specific set of time based
267:41 - connections or intervals like something
267:43 - like a starting time and ending time
267:45 - starting time and ending time and then
267:47 - through this you would try to make some
267:49 - meaningful information so let's say that
267:51 - this is the starting and ending time
267:53 - chunks of the entire day uh between 9:
267:57 - to 5: and let's say that these are the
267:58 - meetings that this meeting starts at 10:
268:00 - and ends at 11: this one starts at 1 and
268:03 - ends at 2 and this one starts at 4 and
268:05 - ends at 5 so if this is the information
268:08 - given if I'm trying to create or
268:11 - schedule a meeting how would I be able
268:13 - to do it so what are the empty time
268:15 - slots available to me so this is an
268:17 - empty time slot available this is an
268:18 - empty time slot available so if I want
268:20 - to schedule a new meeting I can actually
268:22 - schedule in that and that is the whole
268:24 - point of intervals typically most of the
268:27 - times intervals are actually being used
268:29 - for various set of uh time management or
268:33 - calendar management type of activities
268:35 - and trust me this is important because I
268:38 - personally got asked interval questions
268:40 - in two of the very big company
268:43 - interviews I I I actually give so that
268:46 - is why interviews are intervals are
268:48 - really simple to understand on top of it
268:51 - once you know the technique it's
268:52 - actually quite easy to take care of it
268:54 - so let's see that what are the different
268:56 - possible scenarios we can have inside
268:58 - the interval number one possible
269:00 - scenario is that we are given the time
269:02 - schedule for A and B to two different
269:05 - people now we are being told that uh
269:07 - this is the time sequence now these are
269:10 - the times that a currently has a meeting
269:13 - and for B we are being told that these
269:16 - are the times B currently has a meeting
269:19 - so now if I if we want to arrange a
269:21 - common meeting between them to take
269:23 - place how can we do that and the idea in
269:27 - this case would be to create or merge a
269:31 - new interval common interval this is
269:33 - just for the example sake I'm telling
269:35 - you and in this case what we would do is
269:37 - we would take whichever the starting
269:39 - point is smaller at first and whichever
269:43 - the ending point is larger at second so
269:45 - if there is a conflict between any two
269:47 - entities that can be resolved quite
269:49 - easily and we would start creating new
269:52 - intervals that are combination of both
269:54 - of them so that would give us the idea
269:56 - that which are the empty times available
269:59 - so another interval like is like this
270:02 - and this one ends with the schedule so
270:06 - now this is the
270:08 - common time schedule for A and B which
270:12 - means we can say that there is only one
270:14 - empty space available where we can
270:16 - schedule a new meeting if you want to so
270:19 - this this would be one of the use cases
270:21 - second use case would be that let's say
270:23 - that for a we are actually being told
270:27 - that a is overbooked with multiple
270:29 - meetings on many places so which means a
270:32 - has overlapping meetings throughout his
270:34 - day and we wants to simplify this
270:36 - process so what we want to do is uh
270:39 - whichever meeting is smaller in the
270:42 - value we want to get rid of it so we
270:45 - want to get rid of the interval that is
270:47 - actually causing a conflict between the
270:49 - existing meetings so in this scenario we
270:52 - can check that okay currently this
270:53 - meeting is 2 hour long let's I'm giving
270:56 - you for an example and this meeting is
270:58 - only 1 hour long but we do see that
271:00 - there is a conflict in this case so
271:02 - because there is a conflict if we want
271:04 - we can get rid of this meeting entirely
271:06 - and say that uh now a does not have any
271:09 - conflicts same way in this case there is
271:11 - a conflict between this time and of
271:13 - course this meeting is smaller so we can
271:14 - also get rid of this one so this would
271:16 - be a remov of removal of interval kind
271:19 - of scenario another way to treat this is
271:22 - that we can actually move this meeting
271:24 - to the side so let's say if meeting is
271:26 - like this rather than canceling the
271:28 - whole meeting what we can do is we can
271:30 - just get rid of the conflicted part and
271:32 - we can create another new meeting that
271:34 - looks like this that okay now a has two
271:37 - separate meetings even though they are
271:39 - back to back with each other still they
271:41 - are not conflicting so this would be
271:43 - another type of scenario for inter
271:44 - interval questions and the third type of
271:47 - scenario would be where we are actually
271:49 - being told to merge
271:52 - intervals okay now let's assume that
271:54 - this is the problem statement given to
271:55 - us that we need to merge the intervals
271:57 - and you can see that this is a very well
271:59 - like problem on lead code basically we
272:01 - are given an array of intervals where at
272:04 - any particular position position defines
272:06 - the starting and ending point for that
272:08 - particular interval now we need to merge
272:10 - all the overlapping intervals and return
272:12 - return an array of nonoverlapping
272:14 - intervals that cover all the intervals
272:17 - so here we are given an example if you
272:19 - want you can take a look at this example
272:20 - but I actually plotted this example on a
272:23 - very nice like graph so you you should
272:26 - be able to see the idea now in this case
272:28 - we can clearly see that there are four
272:31 - different intervals given to us but
272:33 - among these four intervals we see that
272:35 - these two intervals are non overlapping
272:37 - they are just as it is now how do we
272:40 - know that on our side we can just see
272:42 - them and realize that they are not
272:43 - overlapping but if you wanted to check
272:46 - that if any two o intervals overlap or
272:48 - not all you need to check is the ending
272:51 - point of the previous element and the
272:53 - starting point of the next element and
272:56 - if there is a difference between them
272:58 - let's say that because this ending point
273:00 - is smaller than the starting point of
273:02 - the next one which means we can Define
273:04 - that there is no overlap between these
273:06 - two so because there is no overlap we
273:07 - can keep them as it is we don't need to
273:10 - do anything now in this case if we see
273:11 - this is the starting point this is the
273:13 - ending point same way this is the
273:14 - starting point and this is the ending
273:15 - point so starting point of this is one
273:18 - and ending point of this is three same
273:21 - way starting point of this new element
273:23 - is actually two and this uh this
273:26 - interval is actually six so in this case
273:29 - we can see that for this interval we do
273:33 - have another interval Who start starting
273:35 - point comes before the starting before
273:38 - the ending point of this previous uh
273:40 - interval so that is why we detect that
273:42 - there is an overlap because there is an
273:44 - overlap what we can simply do in this
273:46 - scenario is that we would take the
273:49 - starting point whichever is smaller so
273:52 - in this case the smaller starting point
273:54 - is one and then we would take the ending
273:56 - point whichever is greater so ending
273:59 - point greater is six so we would create
274:01 - a new interval called 1 to 6 and then we
274:03 - would take keep this 8 to 9 interval as
274:05 - it is and same with this 15 to 18
274:07 - interval as it is so the new answer
274:10 - array is going to be this 8 to 10 and
274:12 - then 15 to 18 and this is the answer we
274:15 - need to return so basically this becomes
274:18 - a very simple problem to understand I
274:20 - don't know why lead code mentions this
274:22 - as a medium problem in my opinion this
274:23 - should have been easy all you are doing
274:25 - is comparing the values between starting
274:27 - and ending point between any two
274:28 - subsequent variables and remember in
274:31 - many scenario to trick you the intervals
274:35 - that we are originally given in the
274:37 - original input might not be sorted so if
274:40 - they are not sorted then in this case
274:42 - first thing you will have to do is sort
274:44 - them in the basis of starting time and
274:47 - once you have the sorted values then
274:50 - things becomes quite easy and then you
274:51 - should be able to solve any of the
274:53 - interval problem so let's quickly see
274:55 - the Java code for this problem so here
274:57 - is the problem statement merge intervals
274:59 - and let's see the Java code for that so
275:01 - first thing we are doing is we are
275:03 - actually sorting the given input based
275:06 - on the starting times and once we have
275:08 - that things becomes quite easy now we
275:10 - are just initializing a new link list uh
275:12 - named answer and then we are iterating
275:14 - over the original intervals array that
275:17 - we are given where we are given two
275:18 - values one for starting point and one is
275:20 - for ending point where we have all of
275:23 - these conditions that if the answer is
275:26 - empty or if it is the last element or
275:28 - whatnot we are going to add element to
275:30 - the interval if that is not the case we
275:33 - will have to do the merge operation
275:35 - where we are simply going to add the
275:37 - value of the last element or the maximum
275:40 - value of the last element compared to
275:42 - both the intervals and minimum value of
275:44 - the first interval that comes in the
275:45 - normal sequence and let's try to run
275:48 - this
275:49 - code okay seems like our solution is
275:51 - working as expected let's submit this
275:54 - code and our code runs decently
275:56 - efficiently so this is a very simple
275:58 - problem to solve once you know that you
276:00 - have to sort the given intervals based
276:02 - on the starting
276:04 - time
276:06 - now we are going to start with a very
276:07 - important topic called BFS now if you
276:10 - don't know what BFS means uh it is short
276:13 - for breath for search and it is a very
276:16 - popular tree and graph traversing
276:19 - traversal
276:20 - service
276:22 - so typically whenever we are going to
276:24 - see any data structure such as tree or a
276:28 - graph and we need to iterate over either
276:30 - tree or graph for traversal one of the
276:33 - very popular technique is is a breath
276:35 - for search technique and we spoke about
276:38 - this little bit uh in the previous
276:39 - sections but now we are going to go into
276:42 - much more deeper on how what are the
276:45 - considerations how it works and how to
276:47 - implement this plus we are going to see
276:49 - an example of uh an actual live lead
276:52 - code problem for this problem as well so
276:55 - we all know that in the breath for
276:57 - search essenti essentially you are
277:00 - traversing outwards towards your
277:02 - subsequent neighbors first before going
277:04 - out out to their neighbors so at any
277:07 - given position first you will encounter
277:09 - all the neighbors of that value then you
277:12 - will start encountering its neighbors
277:15 - and until you have done for all the
277:17 - cases you will not Branch out to the
277:20 - deeper levels so essentially you are
277:23 - traversing level by level for all of the
277:26 - nodes that are currently present inside
277:28 - your graph so if this is let's say that
277:30 - this is a graph that you are given now
277:32 - in this graph first of all you are going
277:34 - to start at the root position and this
277:36 - is the root position so first you are
277:38 - going to visit all four neighbors once
277:41 - visiting all four neighbors then for
277:44 - each neighbor you would start visiting
277:46 - their subsequent neighbors and one only
277:49 - after you have visited all the
277:50 - subsequent neighbors then only you would
277:52 - go to further higher or deeper levels so
277:55 - let's see some examples of this in both
277:58 - tree and graph like structures suppose
278:00 - this is the tree we are given I'm just
278:02 - drawing a very simple binary tree and
278:05 - and I'm going to associate some values
278:07 - to it so let's say that the values are 1
278:09 - 2 3 and 4 5 6 7 these are the values so
278:13 - if we if we have to apply breath first
278:15 - search in this scenario basically we are
278:18 - going to first visit for any root node
278:21 - we are going to first visit its
278:22 - neighbors so first of all we are going
278:24 - to visit node number two and node number
278:26 - three uh and then we are going to visit
278:29 - its subsequent nodes that are 4 5 6 and
278:31 - 7 so where this type of solution can be
278:35 - useful well let's say that at any given
278:38 - position you want to print out that what
278:39 - are all the numbers available at any
278:41 - given level of a tree then you can use
278:43 - this uh BFS approach or if you are
278:46 - trying to find some elements and you
278:48 - expect that element would generally be
278:50 - closer to the root element also in that
278:53 - case it would make more sense to use the
278:55 - BFS approach plus now let's see that how
278:57 - this would work in a graph like data
278:59 - structure typically in a graph we have
279:01 - bunch of different various data
279:03 - connected with each other
279:05 - and there are there can be some or many
279:07 - cycles associated with each one of them
279:10 - now assume that in this graph this is
279:12 - currently the root node so in this case
279:15 - for the BFS basically we will visit all
279:19 - the neighbors so this is the neighbor
279:20 - this is the neighbor and this is the
279:22 - neighbor and also this is the neighbor
279:24 - and only after visiting all these four
279:26 - neighbors we would start going to the
279:28 - deeper levels and that would be visiting
279:31 - neighbors of these neighbors uh so where
279:34 - is typically BFS useful for the graph
279:37 - likee structure is that let's say that
279:39 - for any particular node you want to know
279:41 - that how distant it is connected with
279:44 - some other node so in this scenario we
279:46 - can consider these two nodes to be
279:48 - Distance by two because this is directly
279:52 - connected with this so there is a
279:53 - distance of one and this is the distance
279:55 - of two this can easily calculated using
279:57 - BFS and there are some very real life
280:00 - practical use cases like uh websites
280:02 - like LinkedIn or even Facebook you can
280:06 - actually see that how what is your
280:08 - common connection between any two people
280:10 - and for that uh it's quite easy to
280:13 - implement the graph based bread for
280:15 - search method to calculate those values
280:17 - so you can calculate the degree of
280:19 - distance between each each other
280:21 - neighbor on top of that even for graph
280:24 - basically uh BFS is used to search any
280:28 - element plus Traverse over the entire
280:31 - graph and if you want to find any
280:34 - connection between between two end
280:35 - points you can do that if you have to
280:36 - visit all the neighbors of any
280:38 - particular element for any of your
280:40 - problem solving requirement you can also
280:42 - use BFS in that scenario and again
280:44 - remember any problem that you can solve
280:47 - with BFS you can also solve that with
280:50 - DFS as well the only difference is
280:52 - depending on the problem statement
280:54 - sometimes it would make sense to use the
280:56 - BFS and many times it would make sense
280:58 - to use DFS so always make sure that you
281:00 - are aware that which data structure
281:03 - approach you are going to choose now
281:05 - let's see that how BFS gets typically
281:07 - implemented and usually in order to
281:10 - implement a BFS we usually use a cube
281:13 - where we put one value inside the cube
281:16 - and then we add its children to that
281:18 - Cube and then we keep on repeating the
281:20 - process so the output of that CU would
281:23 - be the breath for search manner
281:25 - traversal for any given tree or graph
281:27 - and let me show you an example of a tree
281:29 - so suppose I'm given a simple tree and
281:32 - I'm just drawing uh five noes over here
281:35 - and let me Mark the values as 1 2 3 and
281:37 - four and 5 so initially we are at this
281:39 - first position now we are trying to do
281:41 - the BFS so let me also initialize my Q
281:44 - as well and in my Q uh we all know the
281:47 - principle first in first out okay so
281:49 - first the value I have currently is
281:51 - value number one so I'm adding one over
281:53 - here now before processing one I'm going
281:57 - to add all the children of one I repeat
282:00 - before processing one I'm going to add
282:02 - all the children of one so there are two
282:04 - two childrens's of 1 2 and three so I'm
282:06 - going to Mark values 2 and three over
282:08 - here after that and only after adding
282:11 - all the children I'm going to process
282:13 - one so let me print out the value one
282:15 - over here that this node has already
282:16 - been processed and also let me get rid
282:19 - of this now the immediate value or the
282:22 - very first element inside the Q is value
282:23 - number two so once again before
282:25 - processing two we are going to add all
282:27 - of its children so the values are four
282:30 - and five and then after that we can
282:32 - process value number two so once again
282:34 - let me get two out and uh second element
282:37 - over here would be two now in this case
282:40 - the next element I have is three now
282:42 - since we already process all the
282:43 - children of three or three does not have
282:45 - any children so we can take three out
282:48 - then same way after taking three out
282:50 - four and five also does not have any
282:52 - children so we will take four out and
282:53 - then we will take five out and in the
282:55 - end our que would be entirely empty
282:58 - because we process all the nodes so we
283:00 - are going to keep on processing until Q
283:02 - is not empty and using this approach we
283:04 - can actually solve the BFS for any given
283:07 - tree problem same logic applies for the
283:10 - graph problem as well so you would be
283:11 - able to understand what I mean now let's
283:14 - try to consider one example uh and then
283:17 - we will see the code for that the
283:19 - example is that we want to find the
283:21 - average at the uh level for any given
283:25 - binary tree so the problem statement is
283:28 - quite simple to understand we are simply
283:29 - given a binary tree and all the values
283:32 - we need to find the average at the its
283:36 - own level now let's give some arbitrary
283:40 - values so 1 2 3 and 4 5 6 7 and then 8
283:45 - and 9 so these are the values now what
283:47 - is the answer going to be currently on
283:50 - the very first level there is only one
283:52 - element and its value is one so the
283:54 - average for this is also going to be one
283:57 - now for the second element we have two
284:00 - values 2 + 3 so the average is going to
284:02 - be uh 5 / 2 so 2.5 so this answer is
284:06 - going to be 2.5 next over here the
284:08 - average is going to be uh 4 + 5 is 9 and
284:13 - 9 + 13 so 22 22 divided 4 so I think
284:17 - it's something like 7 uh sorry
284:20 - 5.5 yeah I think it should be 5.5 so
284:24 - this average is also going to be
284:27 - 5.5 and now for this one the average is
284:29 - going to be 8.5 and this is what we need
284:32 - to calculate so you must must have
284:34 - understood by the logic of it that we
284:36 - are going to do the traversal based on
284:39 - the levels that we are
284:41 - performing and we are going to have our
284:43 - Cube and in the cube we are going to
284:45 - first insert the value number one we are
284:47 - also going to have a method to calculate
284:49 - the average and in order to do that we
284:51 - will need to know that how many children
284:53 - are currently Pro or how many elements
284:55 - are there because this is a root element
284:57 - currently we only have one element so
284:59 - I'm going to encounter a value called
285:01 - count and initially the count is only
285:03 - one for this one I'm going to add its
285:05 - children so I added children 2 and three
285:08 - over here because I added two values I
285:11 - know that for next time when I need to
285:13 - calculate the average the count is going
285:15 - to be two okay so now this one this time
285:18 - using this I can calculate the average
285:20 - one and I can print one over here same
285:22 - way uh before processing two and three
285:24 - I'm going to process its children and
285:26 - even for the children I'm going to keep
285:28 - track that how many what was the count
285:30 - and eventually I should be able to make
285:32 - all of this continuous a average
285:34 - calculation because it's a very simple
285:36 - problem and this is how we can actually
285:38 - Traverse in the level order for the
285:40 - given tree and solve this problem quite
285:42 - easily so now let's see the lead code
285:44 - solution for this as well this is the
285:46 - problem we are trying to solve average
285:48 - levels in the binary tree and here is
285:50 - the Java code for that first of all we
285:52 - are given the definition of the tree and
285:54 - then in the main solution first of all
285:56 - we create a new list where we are going
285:58 - to store the result values plus we are
286:01 - also going to initialize a q where we
286:03 - are going to store our tree nodes and on
286:05 - top of that we first add the root
286:07 - element to our Q now we run our while
286:10 - loop that while Q is not empty we are
286:12 - going to keep track of what has been the
286:13 - long sum plus what has been the count
286:16 - for every single children we added we
286:18 - are going to add a temporary node to for
286:20 - our Cube and we once again for that we
286:23 - are going to keep track of or add all
286:25 - the children of it and increase the
286:27 - value of the count and we are going to
286:29 - keep on incrementing until the left node
286:31 - is not equal to null or right node is
286:33 - not equal to null and uh after
286:35 - calculating that we are simply going to
286:38 - run the average function that is Su
286:41 - multiply by one divided by count and um
286:44 - uh that's it so we will add those
286:47 - results into the result list we created
286:49 - earlier and this is the whole solution
286:51 - now let's try to run the
286:53 - code okay seems like our solution is
286:55 - working as expected let's submit this
286:56 - code and our code runs pretty fast
286:59 - pretty efficiently which is awesome so I
287:02 - hope you understood uh that how things
287:05 - get easier whenever you need to Traverse
287:08 - in level order for any graph or any uh
287:11 - tree you can use BFS quite
287:15 - easily okay so just like BFS now we are
287:18 - going to shift our focus on the DFS and
287:21 - DFS is also a graph and tree traversal
287:24 - method and in this scenario we are
287:26 - actually going down into the depth
287:29 - before going into the breadth so we are
287:31 - going to pick a path keep on going on
287:34 - and on in the depth until we reach to
287:36 - the very last Leaf node on that path and
287:39 - then only we are going to backtrack our
287:41 - way to a different possibility and then
287:43 - keep on repeating the same process so
287:45 - let's try to see an example suppose this
287:48 - is a tree that we are given now in the
287:50 - same example rather than traversing in
287:53 - into the sequence of breath we are
287:55 - actually going to go down into the deep
287:57 - so first we are going to Traverse down
287:59 - this path then after traversing this we
288:02 - still have one node that we haven't
288:04 - process in the reverse order so we will
288:05 - go and do a backtrack after backtracking
288:08 - go back over here once again solving
288:10 - this we would again backtrack and
288:12 - through here we would complete the
288:13 - remaining uh path that we haven't taken
288:16 - and in the end we will return this
288:18 - solution of all the paths that has been
288:20 - traveled so this was an a depth for
288:22 - search for a tree same logic will apply
288:25 - for a graph based depth for search as
288:27 - well that let's assume that we have some
288:30 - complicated graph based algorithm or
288:33 - many different nodes that are connected
288:35 - with each other in all sorts of manner
288:37 - and once again we would try to generate
288:40 - some graph based solution for this one
288:42 - as well so let's assume that if this is
288:44 - our root node initially so we decided to
288:47 - go in in the depth for each one of them
288:50 - so first let's say that we pick this
288:52 - node now this node also has other
288:54 - neighboring connection node so we are
288:56 - going to go to its neighbors again this
288:59 - also has neighbor so again we are going
289:00 - to go to its neighbors and again this
289:02 - also has neighbors so we we are going to
289:04 - go to its neighbors after completing all
289:06 - of this we are going to do a back trck
289:07 - to see if we missed any other branches
289:09 - in the depth this one has no branches
289:12 - this one also has no branches this one
289:14 - also has no branches so we come back to
289:16 - our root node but root node we still
289:17 - have other nodes that we haven't
289:18 - traveled so we will go to that node
289:20 - first before traveling to the other
289:22 - nodes and every time we are going to do
289:24 - the backtrack function now we know that
289:27 - in the breath first search we were using
289:28 - Cube but actually in the depth for
289:30 - search we are going to use a stack T to
289:33 - keep track of of all the nodes that
289:35 - would help us with the backtrack
289:37 - function so how would this work I will
289:40 - just give you an example but first let
289:41 - me talk about that if you have to do a
289:44 - tree traversal using DFS you actually
289:47 - have three different ways to do it now I
289:49 - already showed you what those ways are
289:51 - but I'm just giving you the name that is
289:52 - in order
289:54 - traversal pre-order traversal and post
289:57 - order traversal and all of these would
290:00 - be part of or would be considered a
290:02 - depth for search traversing
290:04 - methodology now the question is that
290:07 - what are some of the benefits of using
290:09 - the depth first search so first number
290:11 - one use is that if you are trying to
290:13 - find the full path between any two
290:15 - entities so in that case DFS tend to be
290:18 - more useful second thing is if you're
290:20 - trying to find some element so again in
290:23 - that regard as well that you are able to
290:25 - generate it very easily using DFS uh
290:29 - same same way let's say that if you are
290:31 - trying to make some dependency graph and
290:33 - and this is heavily useful in lot of
290:35 - scenarios let's say if you are trying to
290:37 - build a compiler or if you're trying to
290:40 - build like a schedule prerequisite
290:43 - dependency course kind of a module for
290:45 - our University so in all of these
290:47 - scenarios graph based DFS is going to be
290:50 - very useful so these are some of the
290:52 - most critical scenarios wherever you can
290:54 - think of that from one node in the graph
290:56 - you need to go to far away to some other
290:59 - node try try of thinking to use
291:02 - DFS okay now let's assume that we would
291:05 - try to do a DFS stack run example for
291:08 - any given note now initially we are
291:10 - going to have an empty stack and inside
291:12 - our empty stack just like BFS method in
291:15 - the DFS we are going to add the root
291:17 - node now remember stack has a different
291:20 - property that is last in first out okay
291:23 - and we are going to follow some
291:24 - principles so first okay let me add one
291:26 - value number one over here now the
291:28 - principle we are going to follow is the
291:30 - moment we take one value out from the
291:32 - stack we would see that how many
291:34 - children that value has and both of
291:36 - these children we are going to add to
291:37 - the stack after that and we are going to
291:39 - keep on repeating the same process okay
291:41 - so now currently we have element number
291:43 - one so we are going to take one out so
291:46 - if we take one out let me just node
291:49 - create a method where we are going to
291:51 - keep track of process node So currently
291:53 - we have process node number one okay now
291:56 - we are going to add its children 2 and
291:58 - three into the stack as well so let me
292:00 - add this value now once again just like
292:02 - the same logic we are going to pop value
292:04 - number two first so let me pop value
292:06 - number two so we process node number two
292:09 - but because we process node number two
292:10 - we are going to add its children into
292:12 - the node as well so let me add values
292:14 - five and four over here as well now once
292:17 - again same logic we are going to pop
292:19 - value number four first so after popping
292:21 - value number four we are also going to
292:23 - add children of four as well that is
292:26 - value 8 and N so once again even for 8
292:29 - and 9 we are going to pop them now since
292:31 - 8 and N does not have a children of
292:33 - Their Own so even if we pop value number
292:35 - eight and value number nine they are
292:36 - going to remain as it is because they
292:38 - don't have any children that we can add
292:40 - so now we can get rid of 8 and N from
292:42 - here now next value we have is element
292:44 - number five again element number five
292:46 - also does not have any children so we
292:48 - are going to mark value number five over
292:50 - here and then we can remove that okay
292:53 - after that we are only left with value
292:55 - number three so we will try to pop value
292:57 - number three out the moment we pop value
292:59 - number three in this case we will have
293:01 - to add its children over here so first
293:04 - let me delete this okay so now currently
293:07 - we are going to add value number six and
293:09 - seven here and then we are going to mark
293:11 - three as presented and then we are going
293:14 - to pop value number seven out and then
293:16 - we are going to pop value number six out
293:18 - so this is going to be the whole flow of
293:20 - the sequence in which we Traverse
293:23 - through all the nodes inside the given
293:25 - tree using the depth first search method
293:28 - and uh we can see that all the
293:30 - iterations leads us in the in the graph
293:32 - sequence so here here first we visit
293:34 - node number one then we visit node
293:36 - number two then we visit node number
293:38 - four then we visit node number 8 so we
293:40 - go down in depth after visiting eight we
293:44 - do a back track and we go to the four
293:46 - and visit the remaining child that is
293:48 - nine so like this and after visiting
293:50 - nine we do another backtrack and two we
293:53 - visit value number five so this is how
293:55 - the sequencing of death depth for search
293:58 - is being followed and you can find
294:00 - plenty of examples of depth for search
294:03 - in all across places so I hope uh the
294:05 - concept of BFS and DFS is quite clear to
294:08 - you now so we can move on to our next
294:14 - topic okay now we are going to see a
294:17 - really important algorithm that is
294:18 - called greedy approach now as the name
294:21 - suggest in the greedy approach we try to
294:24 - be greedy in order to generate the
294:26 - answer and we try to find the solution
294:28 - on every substep as well in the given uh
294:32 - algorithm or given problem now before we
294:35 - start understanding the technical
294:36 - details of greedy approach let's first
294:38 - try to understand the local detail of
294:40 - the how greedy approach typically Works
294:43 - let's say that you currently have an
294:45 - empty truck and you are trying to fill
294:48 - this empty truck with bunch of different
294:49 - boxes uh that you currently have now in
294:52 - terms of boxes you have three different
294:55 - types of boxes first boxes that uh and
294:59 - remember all three box boxes are
295:00 - identical in size but they contents are
295:03 - different so let's assume that the first
295:05 - box we have this contains all the ion
295:09 - now second box we have this contains all
295:11 - the aluminum and the third box we have
295:14 - this contains all the
295:16 - feathers now in this case what should be
295:19 - our approach to fill in the all of these
295:22 - boxes into the trucks so that we can get
295:25 - the maximum return out of weight we are
295:27 - trying to put in of course the approach
295:30 - is going to be quite simple we are at
295:32 - every given position or every particular
295:35 - item we are trying to fill we will try
295:37 - to maximize the value of these pink
295:40 - boxes and we will try to see as many
295:42 - number of uh these boxes we would try to
295:44 - fit inside the given uh truck before we
295:48 - run out of them and once let's assume
295:51 - that we fit all of the iron boxes what
295:53 - would be our strategy in next case next
295:56 - case strategy is to fill out the
295:58 - remaining of remaining portion of the
296:00 - truck with all the aluminum boxes uh so
296:03 - doing this method would grant us the
296:06 - best weight ratio amongst uh inside our
296:09 - truck and in the end if we have space
296:12 - then we will try to put the boxes with
296:14 - feathers in them if not then we would
296:17 - essentially fill out our entire uh truck
296:19 - with these two type of boxes so the load
296:22 - we would be handling the heaviest load
296:25 - so what we did in this scenario that
296:27 - let's assume that we consider that
296:29 - filling one box inside the truck as one
296:32 - sub problem for the given algorithm or
296:35 - given step so in every sub problem
296:38 - amongst all the options we always choose
296:41 - the best fit option in order to solve
296:44 - our problem that we are trying to solve
296:46 - and this is the classical example of a
296:48 - greedy approach where even during the
296:51 - each and every suboptimal level we try
296:53 - to choose the most optimized and best
296:57 - available option in order to go to the
296:59 - next next step so now let's see that
297:01 - what are some of the important
297:02 - characteristics of a greedy algorithm so
297:05 - greedy algorithm as I mentioned it is
297:07 - built on piece by piece by piece and
297:10 - every single time we are always choosing
297:12 - the most available and best uh
297:16 - suited particular option for our graph
297:20 - in order to build the solution so no
297:22 - matter if there are how many number of
297:24 - choices available we are always going to
297:26 - pick the choice that is the most suited
297:28 - in order to F fulfill our need now
297:32 - greedy algorithm also suggest that the
297:36 - global Optimum or the best results we
297:39 - can achieve by every single time at
297:41 - every single sub problem selecting the
297:43 - best available option so that is one of
297:46 - the characteristics of the greedy
297:47 - approach and uh there is also one more
297:51 - choice or one more uh thing that we have
297:53 - to understand that is that in order to
297:56 - optimize or find the optimal solution
297:58 - for all we need to consider that what
298:01 - are the overall constraints available to
298:03 - us because many times the greedy
298:06 - approach might look okay at the
298:08 - beginning but it might not be the
298:11 - correct Choice uh because let me give
298:13 - you an example for that do you remember
298:15 - the scenario we were trying to solve
298:17 - where we had bunch of different coins
298:19 - and we were trying to make uh any
298:21 - particular number so let's just say that
298:23 - we were trying to make value number 11
298:25 - uh to see that which are the smallest
298:27 - number of coins we can make or we can
298:29 - use to to build this property and let's
298:32 - assume that the available coins to us
298:34 - are going to be value number one uh then
298:37 - value number five and then value number
298:39 - s and we are trying to see that how many
298:41 - number of coins would it take for us to
298:42 - generate this value number 11 if we were
298:45 - to use greedy approach our approach is
298:48 - going to be that for first sub problem
298:50 - we are going to choose the coin with the
298:51 - maximum value So currently the maximum
298:53 - value is seven okay so after choosing
298:56 - the 7 once again now the remaining value
298:59 - we have to create is going to be value
299:02 - number five because sorry value number
299:04 - four because 17 minus uh sorry 11 - 77
299:08 - 11 - 7 so 11 - 7 is give us the result
299:12 - four so now we will have to create value
299:14 - number four for that we still have three
299:17 - options but we cannot choose value
299:18 - number seven because it is too high we
299:21 - cannot also choose value number five
299:23 - because that is also too high so the
299:24 - next option is to choose four different
299:27 - $1 coin so in this case we are going to
299:29 - choose 1 + 1 + 1 + 1 so in this case if
299:33 - you see in total it took us five coins
299:36 - to build this value number 11 uh and we
299:40 - use the greedy approach but do you think
299:42 - this was the most optimal way to solve
299:44 - this problem no why because we already
299:46 - have a sub option where we could have
299:48 - choose coins like 5 + 5 + 1 and this
299:51 - would have also given us the value
299:52 - number 11 and even though at every
299:55 - suboptimal level we did not choose the
299:58 - most appropriate or most greedy approach
300:00 - we still found the optimal result in
300:02 - terms or three coins so you always have
300:05 - to consider that whenever you are trying
300:06 - to solve a problem think about it that
300:09 - will greedy would be the best solution
300:12 - or could there be a scenario where
300:14 - rather than using a greedy approach you
300:16 - can try to think of using a dynamic
300:18 - programming approach which is what we
300:19 - did in this scenario so greedy problem
300:22 - and dynamic programs they go hand in
300:24 - hand they're very closely correlated
300:27 - with each other but you will have to
300:28 - make that decision and you can only
300:30 - understand that decision after correct
300:32 - directly figuring out the given input so
300:35 - this is really important now let's move
300:38 - on to the next property and let's try to
300:40 - understand this with an example now the
300:42 - example is that suppose uh we are given
300:46 - an we are given a text okay and this
300:50 - text contains lot of different
300:51 - characters now we are trying to build an
300:54 - editor where inside the editor we are
300:57 - trying to put the encryption of some of
301:00 - these values so now we need to identify
301:03 - that which character should be encrypt
301:06 - so that the that those encrypted values
301:09 - would be easy to travel over the given
301:12 - Network and that would consume less
301:13 - space so let's say that if there is a
301:15 - character like um
301:20 - chloroform and there is another
301:22 - character called the so which character
301:24 - should I pick in order to uh compress or
301:28 - in order to encrypt of course at first
301:31 - glance we would think that chloroform is
301:32 - is a bigger word so we should put the
301:34 - chloroform in the encryption but the
301:36 - idea the better choice would be the why
301:38 - because the is more likely to appear at
301:41 - multiple places throughout the document
301:43 - so if we choose to encrypt this
301:45 - character it would give us more value so
301:48 - what should be the greedy approach in
301:50 - this case to decide that which
301:51 - characters should be good candidates in
301:53 - order to uh have
301:55 - them have them available for the
301:57 - encryption and one of the best
301:59 - approaches that what we we can still use
302:02 - the greedy approach in this case we can
302:04 - actually create a heap for all the
302:07 - characters by their
302:09 - frequencies and frequ frequencies means
302:12 - I can see that how many times they
302:14 - appear now we can have the condition
302:16 - that if any two characters A and B if
302:19 - they have the same amount of frequency
302:21 - then we would choose the character with
302:25 - bigger length so this is our greedy
302:28 - approach that if the if there are like
302:31 - let's say that there are 10 10 times
302:33 - character a appears and 10 times
302:35 - character the appears in the same
302:37 - document so the would be our first
302:39 - choice rather than the character a
302:41 - because the contains three different
302:43 - characters so if we encrypt that there
302:45 - is more value behind it and in the end
302:47 - we would be able to written uh using the
302:50 - Heap whatever the top five answers are
302:53 - those five would be the characters that
302:55 - are most repeated bigger in size and
302:58 - also give us the best value for encrypt
303:00 - encrypting our result so this would be
303:04 - one of the good example for greedy
303:05 - approach and basically this sums up most
303:09 - of the questions we had regarding our
303:12 - different
303:15 - algorithms so first of all I would like
303:17 - to congratulate all of you for making up
303:19 - until this far I know it was lot of
303:21 - information to take in but you took it
303:23 - like like a champ so congratulations on
303:26 - that now let me give you some of the
303:27 - popular rule of thumbs and some tips and
303:30 - tricks that will help you
303:33 - come to the conclusion faster in an
303:35 - actual technical interview manner so
303:37 - first one is whenever you identify any
303:40 - question that deals with uh hey give me
303:43 - top closest minimum maximum of K numbers
303:47 - out of the given total n numbers in that
303:49 - case of scenario always try to think
303:51 - that hey can I use a heap in this
303:53 - scenario because Heap will allow you to
303:55 - store the values based on their
303:57 - properties either like maximum values or
303:59 - minimum values and let's say that I I
304:02 - ask you that hey out of the given input
304:04 - data stream give me the fourth maximum
304:06 - or fourth largest number the approach
304:08 - would be to generate a heap to store all
304:11 - of those values and then start popping
304:13 - out values one by one by one until you
304:15 - reach to the fourth character and that
304:17 - would be the answer you are looking for
304:18 - so always think about that can I use
304:20 - Heap in these kinds of scenarios and
304:22 - most likely the answer is going to be
304:24 - correct with that approach now second
304:26 - thing is whenever you are given a binary
304:29 - a sorted array always try to do a b
304:32 - binary search in that that type of input
304:34 - because binary search is going to save
304:36 - you lot of time because binary search
304:39 - operates on log and time meanwhile the
304:41 - regular search operates in bigo of end
304:43 - time so it makes huge difference in
304:44 - terms of performance now next step is
304:47 - let's say that whenever you are given or
304:49 - you are being asked to compute the all
304:51 - the combinations and permutations of
304:53 - given various path choices always think
304:56 - that can I use backtracking or breath
304:58 - first search in such scenarios uh why
305:01 - I'm telling you this because
305:03 - most of the time there would be
305:04 - possibilities where you need you are
305:06 - given bunch of different input paths and
305:08 - you need to pick one correct path and
305:11 - many times you need to try out different
305:13 - paths and then come back to some
305:14 - previous point and then again try
305:16 - another path so for such kind of
305:19 - problems backtracking and breath for
305:20 - search are perfect uh also one more
305:23 - thing whenever you see any question
305:25 - related to trees or graphs try to think
305:28 - about solving them using either breadth
305:29 - first search or depth first search we
305:31 - already talked talked in quite detail
305:33 - that what are the difference between
305:35 - each one of them and what are under what
305:37 - circumstances which one to choose but
305:39 - either ways you would be able to come up
305:41 - with the solution by using either breath
305:43 - for search or depth for search because
305:44 - most likely you are going to Traverse
305:46 - over the entire tree or entire graph to
305:48 - find the optimal solution you are
305:50 - looking for so always trees and graphs
305:52 - equals to BFS and DFS that's a golden
305:55 - rule next thing is whatever solution you
305:58 - try to make if you make a recursive
306:00 - solution you can all also make the same
306:03 - solution using iterative approach using
306:05 - Stacks so many times it would happen
306:08 - that during an interview you are
306:09 - discussing you are uh brainstorming you
306:11 - are coming up with the solution that is
306:13 - a Rec recursive approach your
306:15 - interviewer is for sure going to ask you
306:16 - that hey instead of recursive approach
306:18 - can I do something else and you you can
306:21 - say that yeah instead of recursion if
306:23 - you use uh an iterative approach you can
306:26 - come up to the solution using Stacks so
306:29 - that is a very powerful tool and
306:30 - basically they both achieve same kinds
306:32 - of uh results on top of it many times if
306:36 - the recursion is long enough there you
306:38 - could encounter issues such as like
306:40 - memory overflow or stack Overflow and
306:42 - things like that so that can be avoided
306:44 - if you are going to use the iterative
306:46 - approach next thing is if any problem
306:50 - related to array that you can solve
306:52 - using bigo of n Square time I repeat if
306:56 - there is any problem using an array that
306:58 - you can solve in bigo of n Square time
307:01 - you can solve the same problem using n
307:04 - log end time if you decide to go with
307:07 - the Sorting approach and you can solve
307:09 - the same problem in big off end time if
307:11 - you decide to go with either hash map or
307:13 - hash set approach and we already saw
307:16 - examples of that using two some problem
307:19 - um and many other array problems so
307:21 - always arrays and be go of n sare time
307:24 - complexity try thinking about sorting
307:26 - the array or try thinking about using a
307:28 - hash map or hash set in such kind of
307:30 - scenarios next one is is whenever you
307:33 - see that you are being asked to optimize
307:36 - or do the find the minimum or maximum
307:40 - value amongst all of the given path and
307:42 - you need to do some sort of optimization
307:44 - most of the cases you would be able to
307:46 - come up with a dynamic programming
307:48 - approach that would be able to do things
307:50 - in much faster Manner and we saw that
307:53 - using coin change example where we were
307:55 - given bunch of different coins and we
307:57 - were trying to make a particular value
307:58 - so in that case dynamic programming
308:00 - allowed us to come up with a much better
308:03 - approach and much faster approach now
308:06 - next uh Golden Rule has to deal with uh
308:09 - searching or manipulating bunch of
308:11 - different strings now we all know that
308:13 - try is a data structure very closely
308:16 - associated with strings and whenever you
308:18 - are given this kind of scenario try to
308:20 - think that if there are multiple strings
308:22 - and I wanted to do many manipulations
308:24 - can I use a try and more than likely
308:27 - that would be the correct solution uh so
308:30 - these are the nine golden rules let me
308:32 - me give you the 10th one and the 10th
308:34 - one is actually that whenever you are
308:36 - given a link list and you are explicitly
308:38 - told that you should not use any
308:41 - additional space so IE you should not
308:43 - use any additional hashmap or hash set
308:45 - or something like that to store any
308:47 - extra computation in such scenario try
308:50 - to think that in the existing link list
308:52 - can I use a fast and slow pointer method
308:55 - because that would yield us the correct
308:57 - result and we I already showed you two
308:59 - examples of that first example is
309:01 - finding the middle of the link list
309:02 - second example was that finding that
309:04 - whether a link list has a cycle or not
309:06 - and both are pretty popular and widely
309:08 - known problems amongst tech tech
309:10 - interviews so these are the most common
309:15 - approaches and rule of thumb that should
309:17 - be in the behind the back of your mind
309:19 - so always make sure that you are
309:20 - following upon
309:24 - them now let's talk about what are the
309:27 - common pitfalls to avoid because many
309:29 - times you can do everything right and
309:31 - still get it wrong during the actual
309:33 - technical interview and for that it's
309:35 - not only about your technical knowledge
309:38 - but it is you need to have a combination
309:40 - of smart communication skills uh
309:42 - optimized thinking and also being able
309:46 - to come up with the solution in the
309:48 - given limited time management so there
309:50 - are lot of things so let me tell you
309:52 - that what are some of the common
309:54 - pitfalls that you should also avoid
309:56 - during any of your interviews so number
309:58 - one is always make sure that you are
310:00 - well prepared if you're not well
310:02 - prepared you cannot blame anything on
310:04 - anyone else because if you are not
310:07 - prepared and you go to a battle you are
310:09 - for sure going to lose and missing out
310:12 - any opportunity for a technical
310:14 - interview could be a career changing
310:16 - opport opportunity that you might be
310:17 - missing out you might be uh saying
310:20 - goodbye to your favorite job or your
310:22 - favorite company so please don't do that
310:24 - always make sure that even if you are an
310:26 - experienced individual you have like 10
310:28 - years of experience still go through all
310:31 - the data structures once go through all
310:32 - the coding patterns once maybe try to
310:34 - solve two or three questions amongst
310:37 - each one of them on the lead lead code
310:39 - or hacker rank or there are a lot of
310:41 - resources available because preparation
310:43 - is half half the battle one so that is
310:45 - the number one thing I would advise
310:47 - number two
310:48 - is always try to listen to your
310:51 - interviewer first because many times
310:53 - interviewers are intentionally giving
310:55 - you a very small and very a complete
310:59 - subset of the original larger problem St
311:02 - because they wanted to check that can
311:04 - you come up with the thinking that hey
311:06 - what should we do in this kind of
311:07 - scenario or what should we do in this
311:08 - other kind of scenario are you asking
311:10 - the clarifying questions so always try
311:13 - to understand the problem fully first
311:15 - before diving deep into start going on
311:16 - and solving the problem uh because I
311:19 - have seen and I have personally
311:20 - experienced this many times that
311:22 - whenever I hear a question I would get
311:24 - too excited if I know the answer and I
311:25 - would try to start building and start
311:27 - coding and after 5 minutes the
311:29 - interviewer would be like hey did you
311:31 - think about this scenario and in those
311:33 - cases interviewers were actually
311:34 - expecting me to ask that clarifying
311:36 - question so always make sure that you do
311:39 - that number three suggestion would be
311:42 - always manage your time accordingly
311:45 - because you are only going to be given
311:47 - 45 to 60 Minutes to complete an
311:49 - interview and during this 45 to 60
311:51 - Minutes you need to maybe uh introduce
311:54 - yourself so 5 minutes go there there
311:56 - would be 5 minutes in the end uh to ask
311:59 - any questions you have so you are
312:00 - essentially your interview time breaks
312:03 - down to only 50 minutes amongst these 50
312:05 - minutes you need to understand two
312:07 - problems you need to come up with the
312:08 - solution you need to explain the
312:10 - solution you need to walk through all
312:11 - the edge cases you need to code the
312:13 - solution check whether your code has any
312:15 - errors or not run through run through it
312:17 - and uh explain the time and space
312:19 - complexity maybe explain different
312:21 - approaches and also say that why did you
312:24 - choose this or why did you choose that
312:25 - data structure answer those kinds of
312:27 - questions so there are lot of things
312:29 - that needs to happen amongst those 50
312:31 - minutes so make sure that you are not
312:33 - you are managing your time correctly and
312:35 - you know that what are the cases you
312:37 - need to do and you are you need to
312:39 - prepare for on top of that that brings
312:41 - us to our next point do not Overlook the
312:44 - edge cases try to think that what if the
312:46 - given input does not have any value what
312:48 - would be the result then what if there
312:50 - happens to be like a million values for
312:52 - this particular uh use case or this
312:54 - particular input how would your solution
312:56 - approach that is your solution scalable
312:58 - enough or not are you considering all
313:00 - the edge cases so so think about those
313:02 - things and always make sure that you are
313:04 - taking care of all the happy path plus
313:07 - edge cases and my next step is do not
313:10 - write any messy code because many times
313:13 - you would be solving these problems
313:14 - either on a page like Google Docs or
313:17 - maybe if you are in person you would be
313:19 - solving it on a on an actual physical
313:21 - whiteboard where your all your thoughts
313:24 - and your code is all over the place and
313:28 - you get lost of track and you don't
313:31 - realize that where where you have
313:32 - written what and which method or which
313:34 - class is pointing back towards which
313:36 - instance or Which object and then it
313:38 - gets confusing so you that would cost
313:40 - you your time and also it doesn't look
313:42 - good on your uh on your personality as a
313:44 - coder as
313:45 - well next step is always say what you
313:49 - are thinking because the interviewer
313:51 - doesn't like awkward silences it's okay
313:53 - that you you first ask the permission
313:55 - that hey uh can I take maybe 30 seconds
313:57 - or 1 minute to think over this problem
313:59 - that is uh fine that is acceptable but
314:03 - if you are just sitting quiet for long
314:05 - periods of quiet time then those
314:07 - uncomfortable silences doesn't look good
314:10 - on your interview and also it sometimes
314:12 - the interviewer gets the impression that
314:14 - maybe you don't know the answer or you
314:15 - are getting confused always say what you
314:18 - are thinking on top of it always reach
314:20 - out to interviewer if you are stuck at
314:22 - anywhere I have seen at lot of places uh
314:25 - where people don't raise their concerns
314:27 - and if even if they are stuck they don't
314:30 - voice that uh where they are stuck and
314:32 - what are they thinking most of the cases
314:34 - it is acceptable uh and interviewer also
314:36 - predicts that that you might get stuck
314:38 - at some place and they are there to help
314:40 - you they are it's in their interest that
314:42 - you get a job because an interviewer has
314:45 - so many things to do throughout the week
314:47 - and if they are spending 5 hours just
314:50 - speaking with five different candidates
314:51 - it is a major wastage of their time so
314:54 - they want uh they want to have a good
314:56 - candidate who have solid understanding
314:58 - and they would be more than happy to
314:59 - help you out to reach to that end goal
315:01 - but in order to do that the precursor is
315:04 - that you should be able to speak out
315:06 - loud and always mention that what is
315:08 - your thought process how are you
315:11 - processing the problem and what are you
315:12 - currently thinking what are the
315:13 - different options are coming that are
315:15 - coming to your mind so always make sure
315:17 - that you are voicing your thoughts next
315:20 - thing is at least be familiar with one
315:23 - of the programming language it could be
315:24 - Java python go JavaScript whichever you
315:27 - choose make sure that you at least have
315:29 - good command over at least one program
315:31 - programming language because you at the
315:33 - end of the day you would still have to
315:35 - write the code in any language so make
315:37 - sure that you have good understanding of
315:40 - different programming languages also
315:43 - don't become flustered or don't become
315:46 - frustrated if you make any mistakes
315:49 - let's say that I ask you a question and
315:51 - then you started solving and then you
315:53 - went on the wrong path and you went keep
315:55 - on going for five minutes before
315:56 - interviewer corrected you and then now
315:59 - you just you just feel burdened that I
316:01 - wasted 5 minutes on top of it I was not
316:05 - able to come up with the solution and
316:06 - interviewer had to point me back don't
316:08 - think about these thoughts have these
316:10 - thoughts after you done with the
316:11 - interview during the interview just stay
316:13 - focused that okay now at least you have
316:15 - the correct course now let's uh think
316:17 - about moving forward and reaching to the
316:19 - end line and finding that correct
316:22 - optimal solution so that would be the
316:24 - number one thing that your that should
316:26 - be your focus and coming up with that is
316:30 - don't give up even if you don't know the
316:32 - solution at least try to come up with a
316:34 - Brute Force approach see that what would
316:36 - be the most trivial most preliminary
316:39 - approach you can take and once you have
316:41 - the Brute Force approach then you can
316:42 - start building on top of that for that
316:45 - next block or try to see that why brute
316:48 - force is not optimal what are the things
316:51 - it is lacking are we doing a lot of
316:52 - repeated work can we use something else
316:55 - um maybe it's an array and we have to
316:56 - search it all the time in order to find
316:58 - a value can we use a hash map so things
317:01 - like this will pop up if you at least
317:02 - have the basic Brute Force solution so
317:06 - if you can't find any of the Optimal
317:08 - Solutions at least start with the brute
317:10 - force and interviewer would help you
317:12 - navigate through your thought process as
317:14 - well so that would look at at least in
317:17 - better condition that even if you did
317:19 - not knew the answer you still attempted
317:22 - and at least went as far as you got so
317:25 - that that will that can also work in
317:26 - your
317:27 - favor next thing is that do not fail to
317:32 - optimize your solution because many
317:34 - times you would think you would be
317:35 - thinking that hey my solution is the
317:36 - optimal solution and this is the best I
317:38 - can do but try to think about scenarios
317:41 - that okay can can I do better in terms
317:43 - of time complexity U maybe I'm using an
317:45 - additional space can I reduce that
317:47 - additional space and improve upon the
317:48 - space complexity ask these questions to
317:51 - yourself and also voice their answers in
317:54 - the interview towards the interviewer
317:56 - because many times let's say that you
317:58 - are building a great solution or you are
318:00 - using Dynamic program pramming and in
318:02 - order to do that you are actually using
318:04 - an additional hashmap to store all the
318:06 - results but as it turns out that you
318:08 - don't need to store all the results
318:10 - maybe you just need to store couple of
318:11 - results so rather than spending
318:14 - resources on creating an entirely new
318:16 - hashmap you can actually just have two
318:18 - variables and those variables can go
318:20 - through and solve the problem that you
318:22 - that was needed so these are the
318:24 - optimizations is what interviewer is
318:26 - looking for and if you can do that you
318:28 - would be a great candidate in everyone's
318:31 - eyes
318:31 - and the last note I would like to give
318:33 - you is after our interview is done make
318:36 - sure that within 24 to 48 hours at least
318:39 - you are sending a thank you note and
318:41 - after 3 to 5 days you are at least
318:44 - asking that hey what is the status on my
318:46 - application uh maybe they are
318:48 - interviewing other candidates and they
318:49 - haven't made the decision but still you
318:51 - do not want yourself to be uh hiding
318:54 - behind the scenes and not appear at
318:56 - least uh connect with them write a nice
318:59 - thank you email saying that hey thanks
319:00 - for the giving me the time I really like
319:03 - the interview process I learned a couple
319:04 - of new things and whatnot and it it's
319:06 - always going to look good imagine if you
319:08 - are an interviewer how would you feel if
319:10 - the candidate actually sends you a
319:11 - message and saying that thank you for
319:13 - giving me your time I find it productive
319:15 - of course it's going to bring a smile to
319:16 - your face so think about these things
319:20 - and uh I wish you best of luck in your
319:23 - Tech preparation
319:27 - Journey so now we are at the last piece
319:30 - of our our entire course and it has been
319:32 - an incredible journey for me I hope it
319:34 - has been productive for you as well now
319:36 - let me give you some of the important
319:38 - resources that would become quite handy
319:41 - whenever you are trying to prepare for
319:42 - your interviews so first resources at
319:46 - least get a lead code account I'm not
319:48 - saying that get a lead code premium
319:49 - account if you have the financial means
319:51 - for sure if you cannot still at least
319:54 - get your lead code account in line uh
319:56 - and there are some other websites like
319:58 - code Chef hacker rank geek for geeks
320:01 - they are also quite good so if you want
320:02 - you can check those out as well but in
320:04 - either case build the practice of
320:06 - solving the questions and the tech
320:08 - interview questions now first confusion
320:11 - comes in whenever you are you start
320:13 - grinding lead code is that lead code
320:15 - actually has more than 2,000 questions
320:17 - and you are not going to do all of them
320:19 - so the question comes that where can I
320:21 - find the curated list of important
320:23 - questions so I have actually created one
320:26 - list where I have listed down 125 most
320:29 - Tas most uh popular and most like
320:33 - problems from the lead code on top of
320:36 - that I have also curated the data
320:39 - associated with that which means that
320:41 - for any particular question how many
320:43 - companies have asked this that question
320:45 - and how popular that is uh also what is
320:48 - the difficulty level so I'm going to
320:50 - link that uh Google doc in the
320:53 - description as well and that is open to
320:55 - public so anyone can use it that can be
320:58 - a good starting point if you want there
321:00 - are other list available as well like
321:02 - blind 75 or need code 150 they are also
321:05 - pretty good so if you can you you can
321:08 - use that resource second resource I
321:10 - would recommend if you like to read
321:12 - stuff this is a great book that cracking
321:15 - the coding interview this has been the
321:16 - Bible for all the tech interview
321:18 - preparation so if you can buy the book
321:21 - if you cannot there are online copies
321:23 - available as well so you can read those
321:25 - uh and one last thing is don't stop
321:28 - practicing and if you can find a
321:31 - mock interview buddy or group of buddies
321:34 - or some friends or anyone there are some
321:36 - online forums available who also
321:38 - conducts mock interviews because by
321:40 - doing a mock interview number one you
321:43 - would alleviate the pressure of actually
321:44 - being in the interview this would be
321:46 - like a net practice for your actual
321:48 - technical interview preparation Journey
321:50 - uh and if you are playing the role of an
321:53 - interviewer during the mock interview
321:55 - with any of your friend you can also
321:56 - imagine that when your friend responds
321:59 - how as an interviewer you you are also
322:01 - considering or you are also thinking
322:03 - that this is what he's doing right and
322:05 - this is what he's doing wrong and you
322:07 - can build a sort of an expectation that
322:09 - how should I approach any question from
322:11 - interviewer's point of view and that
322:13 - would become that would become greatly
322:15 - advantageous um whenever you are
322:17 - actually appearing for your interviews
322:19 - also if you cannot find Solutions there
322:22 - are very good YouTube channels available
322:24 - so if you want you can go to my channel
322:26 - destination Fang or otherwise if you
322:28 - want you can also go to a channel called
322:30 - need code he is pretty good uh and there
322:32 - are channels by hacker rank that is also
322:35 - pretty good so there are lot of
322:37 - resources available there is no shortage
322:39 - of it uh the only thing is you need to
322:41 - keep on grinding and keep on preparing
322:44 - yourself now at the very last moment I
322:46 - just want to take this time and say
322:48 - thank you thank you to all of you
322:50 - because of your constant motivation I
322:53 - was able to build and make this entire
322:55 - course this is something I never thought
322:57 - I would be able to do but it has been an
322:59 - incredible experience so good luck with
323:02 - your journey and take care

Cleaned transcript:

Master technical interviews this course breaks down complex topics like data structures algorithms and interview strategies into easily digestible content par teaches this course he is an experienced engineer and he will teach you both the fundamentals and help you understand Advanced coding patterns and common pitfalls to avoid Hello friends hope you are having a fantastic day today I want to welcome you to a journey that will transform the way you approach technical interviews and my aim is to help you become significantly better at technical interviews I'm here to be your guide as someone who has walked through this path and knows the twist and turns every step of the way together we will unlock the secrets of technical interviews from the basics of bigo notation to the integrities of data structure and algorithms so before we move forward let me introduce myself my name is par and I'm based in Canada I have been in the tech industry for close to 10 years and I have worked at companies like Microsoft NOK Kia and Royal Bank of Canada I'm a big believer in technology and love Building Solutions and softwares last year I became dad of twin daughters and on the side I also run my own YouTube channel called destination Fang where I teach about data structure and algorithm related problems so now let's just get started with this course so first let's try to understand that what is going to be the format at any typical interview for any tech company usually during the interview process you can expect somewhere between 3 to six rounds of interviews and they are usually broken down into three main categories first category is the behavioral interview and the purpose of the behavioral interview is to check what kind of person you are are you a good culture fit do you work well with different people do you work well under pressure can you raise your concerns if you have any conflict between two people how can you handle that and these are the things companies wants to know before they hire you second type of interviews are system design design interviews and they are usually more emphasized for more senior level folks and if you are someone with like 10 years or 20 years of experience that would be one of the most significant chunk of importance for any job that you are applying to but that doesn't mean that uh they are not going to be there for junior level folks there would still be some emphasis but not as great and usually those interviews tend to be openended where they ask you questions like if you have to build your own Twitter or your own Google how would you do that what are the things you would consider and then the conversation Dives deep into the vast sea of software Solutions and the third category is technical interviews which is going to be our main point of focus for now from now on T typically a technical interview lasts for somewhere between 45 to 60 Minutes during this time interviewer usually ask one to two questions and once you have the solution in place they would judge the solution if solution seems to be good enough or fine they will ask you to write a preliminary code for that in any language of your choice but the thing is it's not quite as simple as it sounds there are lot of moving Parts in any technical interview usually a technical interview has a problem statement and that problem statement usually refers to some real life scenario and that problem statement needs to be solved using a computer program that we we are trying to build for that you would need two things for sure number one is data structures and data structure is nothing but a way to store the data inside the memory of the computer there are lot of different methods available uh so you will need to take care of data structure second thing is algorithm and algorithm is nothing but a set of instructions that a computer needs to follow in order to come up with a solution trust me there are lot of data structures and lot of algorithms and lot of different techniques that you have to understand but when you combine these two you get somewhat a solution but how would you know that whether your solution is a good solution or a bad one for that we actually need some way to measure that how effective our solution is and in order to do that in computer system we use something called Big O So Big O is a notion where we compute what is going to be the worst case scenario time and space complexity and depending on those results we make the decision that whether the solution or the option of solutions we have which one is the best and most optimal one and which one are suboptimal options so before we start going deeper into the realm of data structure and algorithm let's first understand that what are the measurement units how do we actually understand that this is a good solution okay so let's talk about big O big O is typically defined by a big O and in the bracket we are going to Mark the complexity of Any Given algorithm now usually when when we talk about Big O we are usually talking about two items and those two items are time complexity and space complexity and remember the purpose of Big O is to identify the efficiency of Any Given algorithm now uh there are couple of ways to measure the efficiency of Any Given algorithm but the most important consideration that we are always going to have is that we are going to consider the worst case scenario that in the worst case how efficiently our algorithm is going to perform on top of that we are also going to check that for any given algorithm let's say that currently we are dealing with five number of inputs uh so in with five number of inputs what is the efficiency now let's say that the number of inputs grow to 5 million in this case what is going to be the efficiency and that becomes the true measure of Any Given algorithm and there is also one more condition consideration while calculating big hope is that we don't care about Hardware or software abilities for any given particular solution so we are assuming that our algorithm is currently running on the best hardware or software available so that's why we eliminate those outside of our control entities and only we focus on the efficiency part of our algorithm so first uh and foremost time or space complexity is Big O of one now currently I'm only going to talk about time complexity because that is sort of like more important of course space complexity is also important but time complexity is usually where you will have to improve whenever you are building your solution now in terms of that uh I'm going to currently show you five different examples of different Big O's uh for all I'm explaining it using the time complexity but throughout this course we are going to be solving bunch of different technical interview problems and where I'm also going to explain you the what space and time complexity we are using and how do we calculate that so don't worry about anything we are we are going to cover all the topics uh for that is for sure now first and foremost the Big O notation is a constant time Big O notation that is usually defined by like like this where in the middle there is a big one present this simply means that the current operation does not depend on the given input size and uh one clear example if you want to put it in the real world is that let's say that you are currently shopping in some uh Plaza some shopping cart or some somewhere like that and you can see in front of you that uh you have the option to pick any item from the five available items so since you have the option to see these items and you are being asked that hey uh in the bracket number three there is a banana that you need to pick you can just directly walk in and pick that banana up and in this case you don't have to think anything you just B there fetch that data and you completed your operation so same way instead of five items let's say if there are 500 items and we are assuming that your eye vision is the best you are able to see everything so in that case uh even if the value is located at 499 place and I tell you that go and grab that you can still be able to go and grab that within the constant time so timing would not be impacted based on the growth of number of input size so in this kind of scenario we can consider that operation to have a constant time now next operation is bigo of end time now what does bigo of end time means is that the number of inputs as the number of input size grows the more time it takes for us to complete that task and the progression is essentially linear so let's say that uh this is the graph where we can see that the number of input size and the time it takes to complete the line is going to be a straight line that they are in proportion to each other and if we have to consider an example for uh this kind of scenario let's assume that currently uh you have 10 items that that are already placed in 10 different pots and now these pots they are covered with different lids and you have no way for know that what is currently present in each of the pot so if I ask you that uh from these 10 pots I want you to find a banana so in this case what would be your approach well you will definitely go to the first place and in the first place you will try to check that uh if the banana is present uh currently banana is not present here so you will check the next spot you will check the the next part again you will check the next Sport and eventually you would find a place where has a banana and you would return that in that scenario let's say that instead of 10 values if I put like 1 million pots then essentially you will have to open 1 million pots in order to find the banana so there is a direct correlation between the given input and the size so that's why this would be a good example for bigo of n time complexity where our solution is direct ly in correlation with the given number of input size next one is actually big of log n and this is a logarithmic time operation this is quite un interesting to understand what it happens in this type of operation is that with every step you make you essentially eliminate 50% of given input and same thing happens when you make the next step and same thing happens when you make the ne Next Step so say initially uh uh this is your entire input size when you make the first change the change is going to enable you to essentially get rid of this entire part so now you are only dealing with these number of input sizes with the next step you took again you eliminated half of them so you get rid of this part and then now you're only dealing with this much portion of the given input and same way if you keep on going and going and going eventually you would be able to find the solution you are looking for if we have to consider a practical example for this type of logarithmic time I told you that hey this is the phone book now in this phone book I want you to find the number of Patrick the plumber now for this in order to find the number of Patrick the plumber what will you do is you will open the book somewhere from the middle and let's say that you open uh at where character or alphabet m in the middle portion so essentially you can eliminate that from a to M this Patrick the plumber is not going to be present so you will essentially get rid of all of these pages so let's say that uh it's a 500 page phone book you essentially eliminated 250 pages in just one go and in the next iteration you only have to check for n to Z and again you try to open some middle page and then you would be end up with this a smaller subset size so with every increment of step you take you get almost 50% closer to your uh given answer and you are eliminating 50% of input sizes in that so that is defined as bigo of log n or logarithmic n time complexity well usually the constant time complexity is the fastest and second fastest is the logarithmic time complexity now the next sequence is going to be the combination of two items and that is going to be bigo of n log n so bigo of n log n is an operation where essentially let's say that this is the current input you are given initially first of all you are you will have to itate over all of these places in the input but once you do that then for the next set of instructions you only need to do it in the logarithmic time so for the next operation you are essentially again eliminating half of the given inputs with every single change you are trying to make and this is quite an interesting approach one of the good examples for this one could be that let's say that you are playing a card game with your friends now initially in your card game in your hand you receive five random cards but you are are a person who wants who likes to do things in more of like a sorted array or sorted way so your approach is that hey uh since the these are random values let me put them in a correct sequence so for that what would be your approach your approach would be that first you are going to put down the value number two and you will treat that two is the minimum number and this is the new sort of sequence that you are trying to make now in this case currently since this is empty you can put two anywhere so you will put two in the first place now you need to put value number 7 now again you know that 7 is greater than two so you put 7 on the right side of two now you need to put value number three you already know that all the values that are currently present in this array they are already going to be sorted because one by one you are sorting them now in order to put this value number three you will have to find the location where it should be the ideal location and ideal location would be between two and 7 the three should fall between two and 7 so what would you do you would first try to find the middle Point Middle Point is currently let's say uh 2 and 7 so you pick seven so which means you know that three needs to be on the left side of seven so again there is only one element so you know that three needs to be in the middle so once again you adjust the values and you are going to put three over here and then seven over here again you have value number one so once again you will have to make adjustments or you will have to identify that one needs to go in the beginning and again you are going to use the binary search approach the same approach we were using in the previous uh application or previous phone book example that we saw so let me just redraw all of this and this would be the sequence and now you have value number five you need to put so once again you will try to find the middle value and you find that the correct location for five is going to be this place and you will again going to put it over here so now after this after completing this example if you see the solution you currently have is actually now sorted so let's calculate the the complex for this well you had to go through each and every input in order to receive or complete the steps so definitely you did n work but even for every single element once you did or process that you also had to do some work in order to put it in the sorted place so for that you are not doing the N work you are actually doing the log n work so in this case the Big O is actually going to be Big O of n log n so these are typically the four four most popular Big O's um in terms of like any architect any technical interviews that you have to consider but apart from that we also have to worry about bigo of N squ and bigo of n cub and bigo of uh 2 to the power n and then there is the worst one and that is bigo of n factorial so let me just quickly explain these four of four of you for this so suppose in this case uh big of n Square you already you can already guess that for every every single element we will have to work with all the other elements so let's say that currently I have this value number X now I want to check that in the remaining portion does X is present or not so one by one I will have to check all of these values and since it is not present so then I can say that okay for in order to process one element I had to process all the other elements so essentially I did B of n Square work so or B of n cross n work and same would apply for all the subsequent examples as well and uh that is how we reach big of n Square time complexity this is also uh referred to as quadratic time complexity then for big of n Cube again you are adding one more n over here so let's say that you this step needs to be done as part of one of your algorithm and then once you get the process of this you again have to do n work or compare with all of these values and once again repeat the same exercise in this case case uh the time complexity is going to be big of n Cub now this one big of 2 to the^ N is a Time complexity where at every single location you have the option to process two values and among these two options depending on which option you took your complete computation path would change so in these kinds of scenario the typical uh calculation is going to be big of 2 to the power n uh and the last one is the factorial time complexity so factorial time complexity is where the input sizes grow exponentially with the increase in the number of input size and this is actually a huge restriction because these two time complexities are so bad that they can't even function and one of the very good example for this big of 2 to the power nend time complexity is actually traveling salesman problem um if you want go ahead and search about that it's a quite an interesting problem to study that gives you quite lot of idea on how computational how there are limitations to computations as well uh for the N factorial one of the very good example is to find permutations and combination for all the given input sizes that we are trying to deal with so this is what you need to understand regarding the time and space complexity and uh now let's try to start understanding that what are the data structures now we are going to talk about data structures the most important topic that you have to understand for any technical interview or computer science in general now when we talk about data structures data structure is nothing but a way for us to store the data inside the computer's memory so let's assume that these are all the memory blocks of Any Given computer so we have the option to store the data in like an entirely common box like this or we have the option to save the data where one node is present over here the connecting node is present somewhere over here its next connecting node is present some somewhere over here and so on and so forth we also have the option where we know the option of that this is one node and then this node can only be accessed through these two nodes or something like that and then there are also quite connected nodes as well plus there are some structures data structures like q and stack so data structures in itself is a huge and complex topic now let's try to break this down into categories so it helps us understand what type of data structures are and how they operate so if we have to create the categorization data structures are typically two types of data structures mainly first one is a primitive data structure and second one is a nonprimitive data structure now these primitive data structures are the smallest unit of data that we can store inside the computer and this is your integer value or your character value or Boolean value typically all the values that we usually use in any compiler language so to store store the raw bits of data in the computer and lucky for us or that this is too preliminary that it is not considered for any technical interview but you must have encountered this if you are a programming person so now the next category is the nonprimitive types of data structure and that two has further subcategorization so in the nonprimitive type of data structure the first of characterization is the linear data structure and second one is the nonlinear data structure now for the linear as the name suggest linear data structure defines as the data that are typically stored in a sequence or in a linear fashion so this includes array then uh link list stack and Q so these are the major categorization of the linear data structure now when we talk about nonlinear data structure this is essentially the data structure that that is in a weird shape uh where the connection or the hierarchy between any two nodes is quite deep and quite significant and this has some of the most interesting properties actually so that is uh trees and graphs now for the apart from trees and graphs uh there are many subtypes in each one of them and when we get to those topics we will discuss it in the in more detail but for now understand that these are the to generic subcategories now the there is also third unofficial category which is really important for us to learn and that is Hash based data structure so hash based data structure typically includes uh hash map and hash set and these will these are very powerful tools at our disposal that we can actually achieve quite an interesting uh output with these data structure so without any further Ado let's just get started with the linear data structure now arrays are a not only they are a linear data structure but arrays tend to be fixed in the size and there are some properties associated with arrays so first let's understand that typically uh let's assume that if this is the whole memory of the computer then if whenever we Define an array we have to give it a sum size uh and the size of an array usually tends to stay within a fixed Contin ous memory space inside any given computer as well so let's say that we create an array with the size five then there would be a memory space like this with five consecutive memory spaces are going to be located next to each other and this is how it would be represented in the memory now since we already know that there are going to be five continuous bits of memory uh one good thing about array is that if you want to access any element even from anywhere in the middle you can access it quite quickly and very fast so uh let me give you an example for that suppose uh this uh this is currently the whole chunk of memory for the given array now how would the fast access work is that we already know that what would be the initial location of this position in the array inside our memory I'm giving you like a detailed explanation to help you understand how does arrays work so let's say that the computer memory address like this portion is referred to as 100 and for the Simplicity we are expecting that all of these nodes they are 100 in the size which means that this if this memory location is 100 then this location is at 200 then this location is at 300 and so on and so forth so let's say that uh I currently wanted to access the fourth element that is this element present inside the given array so do I have to do any additional research or any additional extra effort no why why because I can quickly come over here I can see that okay this starts at Value number 100 I want to access the fourth element which means fourth element has to be present at Lo value memory value number 400 and that we can access quite quickly so just because we learn about the bigo time complexity the retrival bigo time complexity for array is actually going to be bigo of one or constant and how typically we access the elements inside the array uh we use something called indexing so arrays let's say that this is an array of size five because we can store five elements in this usually it is going to be indexed starting with value number 0o so 0 1 2 3 and 4 this is going to this is how array is going to be represented and you can store any item in the array you can store either character or you can store integer you can store Boolean you can store even some some of your separate classes you created all the things you can store inside the array but uh in order order to access that you will have to use these index values so let's say that I put down the values as uh 5 15 3 1 and two now if I want to access that what is located on index number two or position number three why position number three because this is the first element this is second and this is third element and we have an index starting from zero so why am I pointing you out this because this tends to be a tricky thing and many times you would encounter in technical interviews that they would say that hey I have an array that starts with index one so that this is like a common trap that you sometimes can find yourself into so that's why make sure that what type of index you are using 99% of cases you are going to be using an array starting with index number zero now let's just go back uh again so in this case uh let's say that the name of this array is a so if I want to access this third element all I need to do is try to fetch the value that is located and on the second index position and this would give us the answer as value number three so retrival inside the array is quite quickly now let's see that what are the different operations we we have the ability to perform inside an array let's say that currently we have a blank array present and what are the things we can do so let's mark down the index values now first operation we can do is we have the ability to insert element inside inside any given array now inserting an element is actually quite quick uh because if you know know which index location you are inserting element into you can actually do it in within constant time so B go of one time you can insert element you can insert element to the end of the array you can insert element to the beginning of the array all you need to know is the index value and that's it now second thing we can do is we can retrive the G the inserted array as well and retrival is also quite quick we we just saw so that is also a constant time next operation we can do is we can find element inside the given array so let's say that how does finding inside the given array would actually work and uh this is a question for you guys that while I explain try to think that what should be the time complexity for this one uh ready so let's say that currently the values are 5 15 3 and 1 and I ask you that inside this given array I want to find that uh value number three where it is located so how would you do it approach is going to be quite simple the logical explanation is going to be that you go to the first element if it is three that's it if it is not three go to the next element again not three go to the next element okay this is three then retri the index position and that's how you find it now in this case what was the time complexity well the answer is quite obvious because we had to jump through all the values in order to find the value we are looking for it was big of n so logically why it was big of n because this is unsorted array so in the unsorted array always if you have to find any element it's going going to take big off end time but let me show you a quick uh interesting thing over here let's assume that I currently have a sorted array so 1 2 3 4 5 these are the elements I have and now I want to find that whether four is present or not so in this case what what is going to be the approach since I already know that this is a sorted array I'm going to first check for the middle element and again I can check what element is there pretty quickly because retrival is Big go of one so that is an important property so in this case I can see that this value is three the moment I realize that this value is three I can say for certainty that four is not going to be anywhere left of three because all the valents all the elements are going to be less than three and we have we are trying to find for the value number four that is actually greater than three so we can eliminate these two or these three elements with a single check again we will try to check for the middle element and we find Value number four and we can retrive that so if the array is unsorted the finding is going to take big off end time but if the array is sorted then in that case the finding is going to take because of log log and time and why because the method we just use is actually called binary search where we are dividing the all the elements in one half or the other half and then we are essentially making judgment on which direction to choose and find the answer in the most optimal manner so finding uh takes B of end time next question is deletion so deletion is also if you know what place you wants to delete it only takes big off one time because all you need to do is just go to that index and get rid of that value so deletion is also very quick inside the array now we all find quite interesting items about array let's see that what are some of the drawbacks of an array well the number one drawback of an array is that it is actually a continuous memory size and it is also a fixed memory size so what do I mean by fixed memory size because initially when we are defining an array we actually have to Define that what is going to be the size of an array and let's say if we exceed the size of that array then the operation becomes quite expensive uh let me give you an example so in this case suppose the array is 1 2 3 4 5 these are the five values now we realize that in the same array we need to add more elements so what behind the scenes procedure is going to be that there will be a new array created of size 10 and now in this new size 10 array first it is going to shift all of these elements one by one and after that once the shifting is done then the next element that you wanted to add over here value number six would be added over here so previously when we have to insert any element inside the given array that was a bigo of one operation the moment we exceeded the size the operation became bigo of n operation uh because we had to repeat this whole process and that too when we did that what was also another fault with that is that currently all of this space is actually unused so we we are already running on a very important resource that is our computer's memory and we are leaving some values unused because they have not been filled yet so this is one of the biggest issue with the arrays now second issue with the array is that uh actually if you want to find any element then it takes bigo of end time because that you have no way for to understand that where any particular element is present so this is also another issue with an array but apart from that if we have to talk about benefits of an array well uh there are quite a few benefits actually if you believe it or not number one it's the simplest algorithm to understand or simplest data structure number two it is actually quite uh useful and and quite fast uh quite fast means that whenever you have to retrive any element from any particular index you can actually do it quite quite quickly uh allocation memory allocation is not an issue this works really well with other data structures when you are trying to solve some complex problems so when we get to the points of dynamic programming and Matrix manipulation we are going to learn quite a lot about arrays and we are going to use lot of arrays in many different scenarios now let's try to understand that how does a typical array problem work with an example and the example we are doing is actually the number one problem on the lead code and one of the most popular uh interview question that is two some problem so what problem statement suggest is that suppose we are given an unsorted array and uh in this case we have five elements so let's give some arbitrary values of these elements and in this case uh we are trying to identify that uh the we are also given a sum value so let's say that sum property is currently given as value number 17 now we are trying to find that find a pair that actually has the answer as value number 17 and then return its index position so we are know that the answer is actually going to be in this case 2 and three because these are the 10 + 7 but let's see that what is going to be the approach that we need to take so this will give us a very good Insight on how does algorithms also work and how does time and space complexity works so let's see the first approach first approach is going to be our Brute Force approach or the most preliminary basic approach the idea we are going to use is that we will take any element we will minus it with 17 so whatever the remaining element is left we will try to see that in the remaining array does that remaining element is present or not uh so if we are considering five so let's assume that five is currently part of this two some so which means if five is part of this 17 that makes 17 then there has to be a remaining value 12 present inside the remaining array and we all know if we have to find any value inside the array we can do it in B go of end time because this is an unsorted array so we are going to jump through all of these values to find Value number 12 but currently 12 is not present so because 12 is not present we can consider five not to be part of the answer then we will go back to Value number three once again 17 3 value is going to be 14 so we will try to see that whether 14 is present again 14 is also not present so we will get rate of three again for seven So currently we are considering value number seven which means for the sum we need to have value number 10 present somewhere and yes 10 is present over here so in this case we did find the answer as 2 and three because we need to return the index value and we can return it quite quickly but if I have to ask you that what is going to be the time time complexity or the Big O for this given input what would be the answer it's quite obvious for any single element we have to search all the remaining elements and if we do or consider that in the worst case scenario essentially the time complexity is going to be biger of n Square so that let's see that can there be a better approach using the array to solve this problem and the answer is actually yes there is a much better approach and first let me give you a slightly better approach right so a better approach in this case would be that what if for the given input array we decide to sort that and if we sort this given input array we will find the values to be 1 3 5 7 and 10 now once we have these values stored all we need to do is uh we need to check that uh whether for Value number one if the subsequent pair the value number 10 n is present or not and in this case since originally we need to find the index value when we create the Sorting we have to create actually a new array so this is an important piece of information so just Im Just a thing so now if we have value number one which means we are trying to find the sum to be 17 so then uh 17 minus 1 is going to be 16 so 16 needs to be present so since this is a sorted array we can actually find in log n time that whether 16 is present or not and all we need to do is we need to apply the binary search where we first check the middle value So currently this value number five so we make sure that 16 has to be somewhere on the right side but since it is not present over here we are not going to bother checking same thing we are going to check with for the value number three that again for Value number three if that is has to be part of the answer we can actually try to find the answer in log and time so to check whether value number 14 is present or not again that is also not present for five value number 12 is also not present but when we get to Value number seven actually the value number 10 is present and we can find this in log n time so what do what did we did we found out that the correct values we need are 7 and 10 so once we have the solution we again need to go back to our original array because we need to return the index values so now once again we would search all of these values one more time to see where what are the index location and then return the values now let's try to calculate the time and space complexity in this case so for the time complexity what are the operations we did number one operation is that for the given input array we actually sorted this so once we sorted this given input array uh it took us bigo of n log n time to sort because based on the example I showed you earlier plus after sorting it we had to iterate over all of these elements to find that what is is the subsequent or remaining element that is present or not and this so iterating over all of these elements took us B go of end time and uh in order to find that for each one of them the subsequent element is present or not again it took us beo of log n time so again we did B of n log n so in total we did two times B go of 2 * n log n but the interesting thing about Big O is that all the constant values are not considered so we are not going to consider big two in this case and we will only consider this to be big off and login on top of it once we find the correct pair we again had to go back to our original array to find the uh appropriate index values so for that we also did Big O of n work but when we are generalizing the Big O we only care so whenever there is a plus operation or the additional task essentially our main main component is still heavily going to be dependent on big of n login because that is greater than big of n so we can also ignore this one and the time complexity is going to be big go of n log n in order to generate this now in this case space complexity is also an issue why because we had to create an additional new array for the sorted property and because the new arrays size would be dependent on the original size and the original size we are considering the value to be n because of that in this case the space complexity is also going to be bigger of n so I wanted to show you this approach to show you that how to calculate time and space complexity and what are the considerations we need to make so I hope you find that uh very useful and you find the idea now of course this solution is much better than our previous Pro Force solution which gave us the result of big of n square but still this is not the most optimal approach there are still optimal approaches available and the optimal approach uh let's see that how we are going to deal with it well actually I should not be showing it to you but I'll just show it to you for the optimal approach we are actually going to use another data structure called hashmap and when we get to that point we will I'll explain you in much higher detail that what an hashmap is but for now consider that hashmap is a key value pair uh data structure that looks like like this where you have a key and you have a value and if you know the key you can find the value associated in constant time we go off one time so it's very quick now let's just draw back our uh original array so I think the values were 5 1 7 10 and 3 and we are trying to find the sum for Value number 17 now again the approach is going to be that if let's assume that five needs to be the part of the answer so if five has to be part of the answer sir we need to make sure that value number 12 is present somewhere in the remaining array now currently we don't want to check the whole remaining array because if 12 is present eventually we would also encounter 12 somewhere down the road as well by the time we would have already processed value number five so what we are going to do is we are first check that whether 12 is present inside the hashmap or not currently it's not present in the hashmap if it is not present in the hashmap we are going to add an entry of key value pair over here where we we will add value number five as the key so this value and its subsequent index value as its value because we need to return this in the answer now again going back currently value number one if one has to be part of the answer then value number 16 has to be present but currently in the hashmap we don't have value number 16 so again we are going to add one more entry that is value number one and oh sorry for this five the initial entry is going to be zero because its index location is zero so for this one the index location is one 1 once again for this 7 we need to find the value number 10 but 10 is not currently present inside the hashmap and we are able to check all of these in big off one time so that's a great benefit now we are not able to check this one so what we will do is we will actually add entry number seven over here with the index value of two now let's add one more room and now we are at Value number 10 so if 10 has to be part of the answer then 7 needs to be present somewhere in the array and 7 is already present in the Dash map because we have already processed that value the moment we realize that all we need to do is grab the index element of 10 that is value number three and grab the index element of value number seven that we can find it from the hashmap over here and we can return return uh 3 and two as the answer that this is the index pair that makes us the two sum possible inside the given array and now let's break down the time and space complexity for this solution so of course time comp complexity actually is very fast in this case because we only have to iterate over the given input array just once and we would be able to find the array so the time complexity is actually going to be dependent on big of n the given number of input sizes which is much better compared to both our Brute Force approach and our sorting approach now in terms of space complexity uh we actually have to create an additional hash map and the size of the hash map is actually going to be the size of the array maximum in the worst case scenario so again the space complexity is also going to be bigger of N and this is how you actually solve this problem so now let's quickly try to understand the problem statement for two some problem that is I just explained it to you and the coding solution so we have a Java code over here and first of all we have the two some method where we need to return the index values for both the positions and in the input we are given the num nums array and the target value or our two sum now first of all we are initializing our hash map where we are going to store the values of the subsequent values we processed inside the given array and also their indices then we are simply going to run a for Loop to iterate over our given array first of all we will try to see that what is the complement value that we need to check and then we will we can do that by subtracting the current array position minus the target value once that happens we check that if the hashmap already contains that complement value or not if it it contains the compliment value we can return the index positions quickly if it does not contain then we are going to add that value in our hashmap and in the end I'm just adding uh an illegal argument exception that there is no toome solution but this is never going to be the case because we are explicitly told that there is always going to be exactly one solution so let's try to run this code and this code runs pretty quickly let's submit this code and our code runs quite efficiently compared to a lot of other Solutions now let's learn about the next data structure that is link list Now link list is quite an interesting data structure because it's not what array was at all uh in the array we actually had all the memories being stored in a continuous block and the size used to be fixed link list is actually complete opposite of this let's say that this is currently the memory then we would have a link list that would look look somewhere something like this it would be sprad out all across computer and the nodes would be connected with each other where one node would know the address of the other node and that is how we actually Traverse over any given link list so typically link list is a dynamic structure well of course it is a linear data structure but it is also dynamic in nature and uh typically a link list looks like this where we only have the information of the first element that is present inside the link list nothing more than that that but if we have to go and reach to any particular element we can actually do it by going sequentially to from that original first element to the last element and we would be able to find that value somewhere in between so typically a link list would look something like this where you have these memory blocks or these nodes and the first node is referred as the root of the link list and in every single node there is going to be a partition and what this partition defines is that this would have the memory location of the next element inside the link list so let's assume that currently we have this value number five and this is located at memory location 100 now this particular block is going to have the memory location of this block so let's say that this block is currently located somewhere randomly at Value number 600 so that 600 would be stored over here once again let's give some arbitrary value over here so let's say that value number three is the value for this node next element it has is it could be anything it could be 300 and now at 300 memory location we have another node that is present with value number seven um and same way it has the address for this next element so basically the structure of a link list looks something like this where we have the first element that points to the next that points to the next and that points to the next and the last element actually points to the null value and when we see an element pointing to the null value that defines that whether the given link list uh where it ended basically now for the link list it's actually uh there are three different types of Link list now what I just showed you this is called a singly link list and why singly link list because one element knows that what is going to be the element after that but any particular element has no idea that what is the element before me because it does not have that address so that is why this is referred as a singly link list where you have the idea of what the single next node is going to be in the iteration but there is also a dou link list and W link list as the name suggest it has the idea that who is the previous caller and who is going to be the next caller so the structure is usually like this where you have additional memory slots uh where we store the information so something that looks like this and uh once again so let's assume that this is currently the root node so even for the root node now in this case since root node is not being pointed by any other node this address is going to be null value and then we will have some value being associated with this so let's say 10 so 10 11 3 1 these are the values associated with the link list but now this 10 this portion is actually going to to contain the address of this element so it has the address 300 let's assume and we can also assume that this address is 50 so this value number 50 would actually be stored over here that this second node would know that who is the first node that is calling them so when this node needs to go back or Traverse in the reverse order it can also do that so when traversing in the reverse order uh it will look something like this that this would actually point to this address and uh same way this has the address over here this has this address and this has this address and this is this address and in the end we have this last element that actually points to a null value and when we see last element pointing to the null value which means that the link list has ended or W link list has ended and when we see first element pointing to the null value which means that the W link list actually started there is one more link list that is called a circular link list and in the circular link list as the name suggest essentially there is a cycle that keeps on happening and uh how it operates is that usually if we consider it's an additional extended version of The W link list so let's say that currently we have a w link list where uh in the normal case scenario this W link list would be pointing to the null value in the first place but let's assume that that is not the case and currently let's just give some arbitary values 1 2 4 7 these are the values right now we know that that one is pointing towards two and two is pointing towards one same way this is relation is already stable now previously in the normal link list the last element its next node would be a null value but in this case the next node is actually going to point back to the very first value and same way this very first node is actually going to point back to the last element so that is why there is a circle circular nature happening inside the link list now understanding this let's see that what are the different operations we can perform on any given link list and for reference I'm just drawing a simple singly link list but same would be true for all the W link list and circular link list as well and uh let's define some arbitary values and currently this one is pointing towards null and uh currently this is going to be the root of our link list so we have the option to add values to the link list now if we have to add values to the link list the time complexity depends on where you are trying to add so let's say that if you are trying to add the link list to the root element and sometimes this is also referred as the head of the link list as well so let's say that you are trying to add elements to the root or the head element of the link list it's actually quite simple all you need to do is that you will first try to go to the root element you would see that what is the current memory address for this root element and then you would actually create another node and let's mark the value as nine you would point point this nine back to this root Two element and that's it now you have essentially created a new head element or the new first element where this is this becomes the root and this is being pointed by this value number nine or root so in this case uh you only have access to the next element so you give the next element of the previous head to the new head and this can be done in big of one time constant time operation same goes that if if you want to add an element somewhere in the middle well this the whole procedure is actually quite simple let me first show you the procedure and then we will talk about the time complexity well the procedure would be that let's say that I want to add a node number seven over here so what I would do is that currently this four is pointing to the one rather than doing that I'm going to Mark 4 do next or the next element that four is pointing to to 7 and then 7 do next to the previous element that four was pointing to so the value number one so we would have a temporary variable in between but essentially you get the idea what I'm trying to say and now this process only took big off one time but now the tricky part in this case is that in order to reach to the four we actually have to first go to Value number nine and then through nine we would do sequential jumps until we reach to Value number four and then we would be able to make this changes so if we have to make the change somewhere in the middle uh the time complexity is actually big of N and same goes for the end as well because if you have to add it into the end you will also have to update and go to the end and then that would also yield the time complexity of big of n but now there is there are some slight variation difference where if you have a w link list and you wanted to add to the last element maybe you can do it faster if you already have that information stored or you can go in the reverse order or in the circular link list you can do it quickly in the end but that these are rare anomalies that you are rarely going to encounter now let's see that if you have to delete an element how does it would work once again deletion process is quite simple that all you need to do is that let's say I want to delete this value number seven so what I would do is currently the next node that seven is pointing to I would ask four to point to that node and that's it seven has been deleted because now there is no way for us to reach to seven and so this the process in itself is quite easy but again the same question remains that in order to get to the value number four we will have to do all of these Hops and get there so if we have to do some deletion in the start it takes big off one time but in the middle it takes big off end time now let's see that what is the next operation we can do and that is finding an element inside the link list once again you get the idea you can find the element but once again in order to find the element you will have to Traverse through all of those these Hoopes in order ultimately till you reach that element so that two is going to be big go of end time and once again uh the last one is that you can also modify any existing element but in order to do that that also takes big off end time so essentially all the operations in the link list if they are done somewhere in the middle or the end of the link list it takes big off end time so now the question comes that why do we even care about link list why should we use it well one of the most important benefit is that it it's dynamic in nature so it keeps on growing and growing you don't have to worry about memory allocation size allocation because it can find sizes anywhere so anywhere there is an empty block of memory present link list can acquire that put it in the memory and do it on top of it swapping any two elements so if this pointing over here we can actually start pointing or add couple of new link list and then bring them back and then get rid of this uh list this is actually quite simple and quite easy so in many of the branching strategies this is actually quite helpful that uh you can actually create all sorts of like get a branch and repos and stuff like that using link list on top of it uh many times we are going to use just like arrays link list in tandem with other data structures so we will see that when we get to that point now let's talk about uh some of the examples of how typically we solve any problem inside a link list so one of the popular very popular problem is that we need to find the middle of the link list or middle element of the link list so how do we actually do that so let's assume that we are currently given a singly link list and we don't know that what is the size of this link list so how do we encounter that what would be the middle point for this one so one approach is that uh it's the simplest approach we actually start at the root value or at the head of the link list we keep on going to the next element until we reach to a point where the next element points to a null and the moment we reach that we would know the size of the link list so in this case we found out that the size of Link list is five so middle element is going to be the third element then once again we start once again from the root and let me use another color and then you we hop back and we reach to the middle element and then we say that okay this is the middle pointer of the link list so this this can be one of the examples so what is going to be the time complexity well time complexity is going to be big of n because we have to go through essenti all the inputs but there is also another better approach where once again time complexity is going to be biger of n but in practice it is going to be faster and that is that rather than making one hop you actually make two hops and how to do that well you can actually have two pointers so one pointer is a fast pointer and the second one is a slow pointer both start at the same time but slow pointer makes one jump and fast pointer makes two jumps so the moment Fast Point pointer reaches to the end of the link list the middle pointer or the slow pointer has to be in the middle and that you can return as the answer so in this case the time complexity would be big of n divided by 2 so overall since 2 is the constant value we would still write it as big of n but in practice this is going to be much faster compared to the other approaches so now let's try to understand the middle of the linkless problem and as the problem statement states that we are given the head of a singly link list and we need to return the middle node of the link list now this is the Java code for that and typically for the link list we are initializing two pointers for that first one is known as slow and second one is known as fast and currently both are located at the very first be uh beginning position of the link list now we run a v Loop that while fast is not equal to null and fast. next is not equal to null we are going to keep on moving the slow pointer to one jump so slow will go to the slow. next or the next element inside the link list and fast would go to fast do next do next so it would make two jumps at a time and in the end the moment this Loop ends we would be at a position where fast is at the last position or the next element to the fast is actually the null value in either case so slow has to be the middle pointer of the link list and we can actually return that so let's try to run this code and our solution works perfectly fine so let's submit this and our code runs with 100% efficiency so this is pretty good and uh all the code that I'm showing you would be posted in a gith up public repo so the link is going to be in the description so you would be able to check it out from there now let's see another data structure that is a stack now stack is once again very similar to an array or link list it's a linear data structure but uh the stack has a very specific property and that specific property is actually that stack is something like this uh you can consider it as like a test tube um in any lab or any sort of thing or a stack of plates this would be like a good example to understand what stack is where the value where you first store sto gets stored at the very bottom once that value is filled then the next value when you have to put in that would become at like the bottom to the uh second place and it will keep on going now when you have to take things out you will always take things out that are currently at the very top because you cannot reach to the bottom element because they are already Behind These memory lines so in order to reach to the bottom elements you will actually have to go through one by one for all the values so let's see this an example let's say that currently our stack is empty we are trying to fill in some values so let's say that we put down value number one first so one has to go at the very bottom now the we have we are putting value number two then three then four then five and then six So currently we have six elements inside our stack now when we start taking the values out actually the only value we can take out at this moment is value number six because that is the only value we have access to because this is like a test tube or a a stack of plates kind of a structure so that is why when we decide to take things out we are going to take value number six out first after taking value number six out then we we can start taking value number five out after five we will get to the value number four and so on and so forth so essentially the last element that was encountered or entered inside the stack would be the first element that is going to come out so this is this works on the Leo principle last in first out okay so and that's it this is what the whole stack is uh now if you have to see what are the operations you can do inside a stack uh you actually have some limited operations but they have very specific use cases so let's say that currently we have a stack like this 321 there are three elements so number first thing we can do is we can push value inside the stack because we already pushed these three values uh inside the stack so pushing element inside the stack is actually quite simple all you need to do is just push it and whichever is like sequentially available memory block so let's say that this is a stack like this so this would be the element that gets filled so this takes big off one time now you also have the option to pop a element out so when you pop an element out you only have access to just pop out the element that is currently located at the first pace so in this case you can only pop out this element and after that is done you will pop out this element so this also takes big off one time now the next option we have is that many times rather than popping one element out we can just check that what is the current element at the very top and that for that we usually do like a peak operation and this also takes big off one time so you would you must be thinking that hey this is super fast uh data structure so let's use this up to the fullest extent but uh this is very limited in memory size and also like the way data is being stored so if we when we start talking about additional operations if we have to find an element inside a stack that takes big off end time for obvious reasons because at one point we are only accessing one element out and let's say that the element we are trying to get out is actually located at the very bottom we won't be able to reach it until we reach all the elements if we have to once again delete any element once again it will take big of end time because we will have to first find that element so that also adds an additional layer of complexity and same goes for modify as well that that this also takes B go off end time so all of these things they are closed L correlated with each other now let's see that what are the operations we can do or what are the use cases of a stack so number one use case of a stack is that wherever you need to maintain a sequence in one order and the reverse order sequence has to be match in that case uh stack would be a great example and this is one of the very popular scenario for that where we are we want to check that the number of parentheses we have are they in the correct order or not and that can very easily be determined using a stack where all the parentheses that are coming in they also get out in the same manner and U if you want we can also try to do a quick example so let's say that currently we are trying to build a compiler and in our compiler we wants to check that all the parentheses that were opened they are closed in the same sequence so what we can do is okay the moment we open a parenthesis we are going to push an value inside the stack So currently stack is empty and let's say that these are the sequence of operation we are going to do right that first we are going to open a curly bracket then we are going to open a square bracket then a circular bracket and then we are going to close in the correct manner as well so the idea would be that first we open the bracket so we are going to add a value over here then once again open so add open so add now when we are closing the bracket we will remove the value and try to see that whether the bracket is of same kind or not so the first value we removed is a curly is a circular bracket and the value we are trying to close is also a circular bracket which means awesome so this sequencing was correct now uh the very first element currently is the square bracket open square bracket and now the bracket we are trying to close is also an open type of bracket so once again this is also a match so we can consider this and the last element is a curly bracket and a curly bracket so once again this is also a match so the whole solution work and now we are at the end of our parenthesis at that time we also check inside our stack and currently our stack is also empty which means all the brackets that were opened they got closed in the same manner let's assume that uh there is one more additional bracket over here in the beginning that this was the case so then after these three has been done we would still have one entry over here which would dictate that the parentheses were not opened and closed in the same manner and uh that would throw an error so this is actually the use case being used in many of the compilers as well so that's actually quite cool to understand that a simple data structure can give birth to such a wide variety or such a huge functionality now here is the problem statement for the valid parenthesis problem where we are given the string of opening and and closing brackets and we need to determine that whether it is a valid sequence or not so for that we are actually going to use a hashmap in this case where we are going to create the mapping of opening and closing brackets where all the closing brackets are going to be placed as the keys in the hashmap and their subsequent values would be their counterpart now let's move on to our is valid method where as an input we are given a string so first of all we will initialize our stack uh we are going to run a for Loop across the given string and we will see that whether this is a closing bracket or not if that is the closing bracket we would get the top element of the stack and if the stack is empty we can return false if it is not empty we will pop the element and we will compare it with the closing element so if they match that's fine if they don't match we can return false and if that is not the case if it is an opening bracket we will simply push the value inside the stack now in the end after this whole Loop has ended essentially a our stack should be empty if the stack is empty we can return true that the sequence is valid if it is not empty we can return false so let's try to run this code and seems like our solution is working as expected let's submit this code and our code runs pretty efficiently and you can imagine that how Stacks are actually serving a very critical functionality now let's try to think about another example of what a stack can do and that is a redo functionality so we all know that what a redo or undo functionality is basically if you are going through your Google web browser whenever you need to go back to the previous website you were at uh essentially a stack is being used and how it does is that let's say that initially you opened your Google So currently your stack is empty now you first go to the Facebook page so it will Mark the value as Facebook from Facebook you decided to go to the Instagram page from Instagram you go to the YouTube page and and from YouTube you go back to the Twitter page now at the Twitter you decide to hit that uh Arrow back button or the undo button the moment you hit back it is actually going to pop the value out so currently okay uh you are at the Twitter so previous element like the YouTube would be there okay now currently you are the Twitter you hit the element back so it is going to pop the first value out so first value popped out would be YouTube so it will take you to the YouTube page now from the YouTube you once again hit the arrow back so once again the Instagram page is going to come out now currently you are at the Instagram page and you have this value now from the Instagram page you decide to go to the let's say Uber page so now because you went to a new page there will be an entry for Uber being added over here now once again when you hit the undo button actually from The Uber page you would actually go back to the Facebook page so that's how these things would work and uh this is actually quite useful data structure in my opinion the last linear data structure that is a Q and Q is also very popular as the name suggest Q is actually quite simple where unlike stack we actually have both ends open but all the values are coming in from one end and going out from the other end so let's say that currently you have the cube and you have value number five come in so five would be the first candidate to get out then we have value number six coming so six would be the second candidate to get out same way all the subsequent elements that keeps on coming in they all would be stored in the same sequence of the sequence they came in so we have a value where we can NQ or where we can add values to the cube and where we have a position where we can DQ where the values go out of the cube and uh we all know the functionality of cube uh there are lot of real life systems where we need to have cues uh if we want to generate like some Network packet manufacturing or uh Network packet submission type of system definitely we are going to use because we want uh our let's say that we have a system a and we have a system B and we are sending some Network packets so we want Network B to receive the network packets in the same manner they were sent from Network a so for that on the B side we are actually going to create a cube and this cube is going to have the sequence IAL flow of the networks so now let's see that for the Q we already know the use case but first understand that what are the types of cues available so the number one type of que is actually the just a regular quebe then there is also priority Cube now what priority Q means is that this represents some real life scenario so let's assume that you are currently waiting at the DMV Center to make your driving license and currently the officer sitting there is asking for everyone in a sequential manner so currently all the people are standing in the line and of course the person who came the first would be the person reaching out to the DMV officer in the first manner but during this time DMV officer identify a pregnant lady or some person who had some disability so in that case this person would be the first person to go and meet to the officer and complete the task and this is the real example of how a priority looks like where it mostly operates as a normal queue unless you have some event that you can Define that would dictate that it has a higher priority so process that first and this is quite useful in many real life scenarios as well where let's say that in your phone you wants most of the stuff to happening in the sequential manner but what if there is something related to like payment fraud happening so you want to put first first priority for that and for that usually a priority queue gets implemented now let's see that what are the different operations you can do or you can perform on a given Cube so I'm drawing a preliminary basic q and uh we are going to have the values coming in from one end and going out of the other end so essentially the first value would be five that came in so the first value would be five that would be going out so Q operates on fif principle first in first out unlike stack that was working on Leo principle last in first out so that is that is a difference between them and you have to understand now uh in the Q we first have the option for NQ which means we are adding an value to the back and this process takes big off one time because it's a constant time operation we already know where we are heading same way for the DQ uh it also takes big off one time because again once again the operation is quite similar now on top of that in the Q we have the option to Peak that who is going to be the first value coming out so that does not actually comes out but we would know that this is the value then there is also another option to search inside the queue but searching like other data structure takes big off end time and by the way for peing would take big off one time now on top of that we can actually delete an element from the queue but we would rarely do that because we want to process those elements this also takes meig go off end time and that essentially that's it now I I think I already give you sufficient examples of how does a queue operate or how it looks like so you can actually imagine that uh how things work with the cube and one of the most popular data structures out there is actually trees so trees is not your everyday looking array or link list it's actually completely different uh first thing it is a hierarchical data structure second thing for the trees you actually have to consider some terminologies so typically a tree looks like this where it has a node in this node you can store some information so that information can be anything you can store an integer value you can store uh a character value or if you want you can store some class values as well so let's say that you created a class called person and in that class you have that first name last name and date of birth you can fill out all of the those information in this node but apart from that on top of storing all of this information let's say that you store that information in the majority part of the given tree node in the rest of the part you actually create the connections that it is connected to with other nodes and this is really important so one single tree you only have access to the root node but from this root node you can actually connect to multiple places inside the given tree so you can actually be connected with two more nodes that are below that under one of nodes you can be connected with three more or four more or any more number of nodes this node maybe only have one node then and this node has another node and this is how typically a tree progresses so when we are talking about trees we will have to first Define few important things so I already told you the number one thing that what a node is that node is basically the portion of tree that contains data that contains important information now next important information for that a tree needs is an edge and what does an edge represents so if we see or take a look at this picture Edge is essentially the o that connects any two node and there needs to be some relationship between them so typically in a tree you would always see a relationship like this where a tree is always under some other parent tree so in this case this root node is actually a parent node for these two subsequent nodes but also at the same time let's say that you have four more nodes over here then in this case for these nodes this becomes a grandparent and uh this becomes uh these two nodes becomes parents for these subsequent nodes so there is always a parent child relationship and that relationship is typically defined through an edge next we need to discuss that what a root means so root means the node that is that supersedes all the nodes so essentially the great great great great greatest grandparent essentially the very first node that becomes your entry point into the tree and this is defined as the root node now let's talk about that what does a leaf node means so Leaf node means that the node that does not have any children so let's say we have a tree that looks like this in this case we currently have a node this node is by default the root node and this tree is connected with these two edges to these two children but these two children does not have any subsequent children of their own so in this case uh these two nodes actually becomes the leaf node that we are trying to explain now let's talk about the concept of depth now what does a depth means inside a tree essentially for any given tree uh it is always placed in the layers that one root node has some children then these children have subsequent children of themselves as well there can be n number of Childrens and for the Simplicity sake I'm drawing two children for every single parent but there can be n number of children and in this case we can see that currently this root node is actually located at depth one or you can also consider it depth zero depending on what type of situation you're tackling they are just numbers but they would be the initial depth and then with every level you go down the number of depth increases by one so in this case this is located at depth one this is located at depth two so essentially depth can also be considered as level of parents or children uh that each one of them has and very close and very similar similar concept is of height so height basically defines that how deep a tree goes so in this case from the root node we actually go two levels down so we can consider the height of this tree to be two uh same way uh from any single separate node you can also calculate the height from that position as well and in this case the height would be one if we consider this smaller sub tree of a tree so these are the different terminology that you have to understand before we proceed with uh what a tree is now let's try to see that what are the different types of trees that are available and trust me there are lot of types of trees so first let's just start with the simplest trees and that is binary tree now what does binary tree defines well we all know the meaning of binary binary means either zero or one which means it means two so binary tree means that every single root node has exactly two children so in this case this would have two children same way these subsequent nodes would have two children of their each and so on and so forth and until we run out of the level so in this case let's say that this has two children and that's it so this is a binary tree why because by definition every single parent has exactly two children or no children at all so and that property is followed across all the nodes uh so binary tree is what you're are going to encounter mostly in your typical interviews and very closely and a a subset of this binary tree is actually binary search tree so what does binary search tree means that it follows all the properties that a binary tree has that every single node has exactly two children or no children at all but on top of that the binary search tree has an additional property where the values that are being represented in that those binary trees they are actually sorted with the condition that everything on the left is actually less than everything on the right uh and this property is followed throughout the entire tree so let me give you an example let's say that we currently have a tree that looks like this and currently the value of this root node is s then it it can only have children where the scenario is that everything on this left sub tree has to be less than seven if it is everything on this left sub tree is less than seven and everything on the right sub tree is greater than seven in that case we can Define this as a binary tree or sorry binary sear tree so let's say that we add two more nodes over here and these two nodes Define the values as that this one is value number five and this one is value number eight so far this follows the property of a binary search tree that is good for us now let's just take it one step forward as well so we have two more child over here in this case so in this case let's say that the value of this child is three and again value of this child is six is it still a binary tree yes why because let's follow the same property currently if we consider this parent node then this becomes the left sub Tree in left subtree all the values are less than value s so that is good now let's consider this node so this node is five its left is three and Its Right is six and that is also followed because left sub tree is less than five and right sub tree is greater than five so both properties match same way the right sub tree is currently greater than seven so this property also matches so in this case this would be a binary search tree and binary search tree has lot of potential and lot of application you can actually use it for sorting or you can use it for to store data or to go hierarchically down so we we will talk more about this when we go when we start talking about uh various uh scenarios where you can actually use the uh tree data structure now there is one more data structure that is called a AVL trees so what AVL trees is that AVL tree is actually a special kind of tree where not only it is a binary tree but apart from that it is also binary search tree and on top of that it is a balance tree so what does the balance tree means so let me give you first an example of a balance tree balance tree is any tree where all the nodes on the left side of sub tree and all the nodes on the right side of subtree are even so in this case let's say if I have a tree like this this is a balance tree if I have a tree like this where left node has two sub nodes and right node also has two sub nodes this is also balance tree so any symmetric tree is basically balance tree and AVL trees contains all of these three properties yeah so that is about AVL tree then there are all more specialized trees that is red black tree and there is also B trees but these are just too higher of the concepts but I'm just going to give you an example that red red black tree is actually a tree that has separate colors so some nodes are defined in a certain color and the other nodes are defined in the certain colors and depending on their positioning the colors are maintained so whenever you try to add new value uh it automatically maintains the colors and it automatically generates that what should be the next subsequent value based on those coloring groupings so the red black trees are great at sorting various items and various operations depending on the color property and B trees are multilevel balance and sorted uh tree data structure that can have more than two uh more than two children so it is actually much more complex topic and in its own uh it has actually lot of uh things that we can think about but we are not going to go deeper because that would be much that would be a topic for much higher level I just wanted to give you a brief overview for that now let's let's see that what are the operations we can do on a tree so the operations are quite simple we can do like searching we can also do sorting we can also do uh deletion and in insertion all of those things right but in order to do that uh we actually have to Traverse over the tree all the time and the most important operation that you will have to learn about is that how how the traversal Works inside a given tree so actually for trees there are typically three different ways you can Traverse over inside the given tree and that that are that in order traversal preorder traversal and postorder traversal so how each each and every one of them is going to work well I actually have a separate video on that but if you want you can just check what I'm trying to explain right now what in order traversal means is that first we are going to visit the node then we are going to visit the left child and then we are going to visit the right right child child preorder means that first we are going to visit the left child then we are going to visit the node and then we are going to visit the right child and post order means that first we visit left then we visit right and then we visit node so let's see this in action suppose we uh we are given a simple tree so I'm currently drawing a simple most basic tree and we will go through its values right so let's say the values are one then on the left is two and then Its Right is three and also on the right is four and on the left is five and on the right is six let's say that this is the type of tree that we are trying to generate now let's see that what would be the in order traversal would be for this part this type of tree well of course first we are going to visit the node so node in this case is going to be the root node and that is going to be one so the very first value we are going to go through is going to be value number one then we are going to see all the left sub tree So currently for the left subtree it only has node number two but again at node number two we are also going to visit this and then after visiting now currently for this node number two it does not have any left sub tree that we can visit so we are going to go into the right side and on the right sub tree we have value number three that we haven't visited so we are going to visit node number three after that again we are going to repeat the same process now in this case we already took care of this value this value and this value so now even for node number one we are going to go to the right sub Tre but for right sub tree again we are going to apply the same logic of node left and right so once again we we are first of all going to visit node number four and after that we are going to visit node number five and then we are going to visit node number six so we took care of all the nodes so this is how uh the traversal works for in order traversal now let's do the preorder traversal and inside the preorder traversal it's clearly see that we need to go to the left as much possible as we can so from the initial note do we have a left sub tree yes uh in the left sub tree we are going to go to this node now does this node has any left sub tree that we haven't checked no because this does not have a left sub tree then we can visit the node so while visiting the node the first node we are going to visit for the preorder traversal let me just write it over here so the first node would be node number two now the next node we are going to visit is going to be the right subt tree of this node now for this three it does not have any children which means we will have to visit this node so we are going to visit node number three first after visiting these two now for this node number one we took care of the entire left sub tree so we can actually visit node number one now after visiting node number one we need to take care of the entire right subtree but again with the same logic of left node and right so again we are at this position now this does have a left node so we are going to visit five first then we are going to visit the node and then we are going to visit node number six so this would be the preorder traversal for the given tree now let's see that what would be the postorder traversal for the given tree so in terms of post order traversal it is going to be actually quite simple uh again using the same logic we need to First go through every single left node then we need to go through every single right node and then only we will visit the existing node So currently for this one it does have a left node for this two it does not have a left node but it does have a right node so we are going to visit node number three first so in the post order traversal the first node we are going to visit is going to be node number three then the next node we are going to visit is going to be node number two and then we are going to visit node number uh one no we are not going to visit node number one right now because because node needs to be visited in the end and it still has right subt tree that we haven't checked so now we are going to visit the right subtree and this this portion now becomes the node and for this it also has a left node so now we are going to visit five then we are going to visit six then we are going to visit node number four and after completing both of these portion we are going to visit node number one in the end so this would be the full traversal for the given tree uh the in order preorder and post order traval uh this is the most trickiest thing to understand for any single tree and I hope you find you find it useful now let's see that what is going to be the searching sorting deletion and insertion for the given tree so let's say that searching if we are given a normal tree then the searching is for sure going to take big of end time but if we are given a binary search tree in that case searching would be bigo of log n only because every single iteration we would be uh moving half of the element on one side and we we can focus steadily on the target so that is why binary search trees are so popular now let's talk about sorting uh so for sorting actually if we are given a binary search tree then sorting is actually constant uh sorry because of log and time because it's quite easy to do uh we only need to Traverse over over the given tree and uh many for many sorting algorithm binary search trees are being used deletion if if we know which node we have to delete then it's a constant time deletion operation but if we don't know the node and we have to search first then it becomes big go of n or log n depending on what type of tree we are given and same goes with the insertion that if we know that we we can insert any randomly then it's B go of one but if we cannot do it and we have to insert it at specific location then it's B of n or big of log n depending on where we are trying to insert and what type of tree we are given so this is everything you need to understand about trees but now let's see that what are the uses on how on and where we can actually use trees so number one use case for a tree is typically a database management system uh why database management system because number one binary search trees then AVL trees then red black trees then B trees all of these are huge and very powerful in separating all the elements so that's why they are quite popular whenever you are trying to build a data stru database on top of that they are really po really powerful when you are trying to index all the values and indexing and enabling fast data retrival can only be possible using the trees if you have to use uh anything for file systems or file management uh so because tree they are already in hierarchical nature and whenever you see your windows path or your something something you will always see something like C drive it has a file called programs it has a file called uh Java it has a file called bin something like that so this is a parent child relation where every single node is connected with the other node and uh you can actually go over that plus if you want to create like a syntax trees you can also do that using the trees why syntax trees because let's say that if you're trying to build a scenario or a compile or something where you want to show that what class is connected with what other class and you are trying to avoid any infinite Loop scenarios so in that case tree data structure would be a huge help and on top of that you can actually use trees to build priority cues as well so this is also a very good benefit to use you can actually do that using Heap and uh I won't be explaining the whole concept but just know that this can be done okay so now let's try to see uh some examples for the tree based questions so one of the very common example is that typically we are being asked to validate a binary search tree now we all know by definition that what a binary search tree is that essentially every single node that is on the left side of the tree is actually less than uh the node value and every single node on the right side of the sub tree is actually greater than the node value and this property has to be followed throughout the entir of tree so let me give you a couple of examples where we will try to see that which are some of the valid trees which are not valid trees and how we can solve this problem in an actual interview or for our practice so assume we are given a tree like this where the values are 1 2 3 4 and 5 and uh these are the connection of the nodes so in this case we can clearly see that this is a valid binary search tree why because this is the middle node node number three now if we see the left sub tree for this node is actually the values are 2 and 1 and both are small than value number three same way in the right side of the sub tree the values are four and five and again both are greater than that particular value now we have couple of more sub trees as well that we need to check and that is this one so first sub tree is that this value of two and the value of one so again since the one is less than two and it is on the left side of the two uh it is a valid path same goes for this four and five as well and in this case we can Define this to be a valid binary search tree but now let's consider a scenario that if we are given a tree like this suppose the values are 5 4 3 and then this one is 6 and then this one is 2 and uh these are the nodes that are currently connected now let's break them down sube by sub tree so let's consider first this value number three and value number two they are just uh simple or Leaf nodes so they don't mean anything now let's consider this sub tree is this a valid sub tree yes why because three is less than four and it is currently on the left child of four so that is true now let's consider this entire sub tree so this is also valid because both four and five three are smaller than value number five now let's consider this sub tree this is also valid scenario where six is actually uh higher and in the greater value so 2 is smaller than six so that is why it is on the left side but when we consider this whole portion then it fails and why it fails because the value number for Value number five the expectation is that everything that is on the right side of value number five which means this portion has to be greater than value number five but since this two is actually less than five so because of this we can Define this to be a wrong wrongly placed uh value so this is not a valid binary search Tre now the question is how can we actually find the solution for this type of problem uh for trees so one simple approach is that if we do an in order traversal for any binary search tree if the tree is valid we should get a sorted array or sorted values in return and let me give you an example for this let me for a moment make this a valid binary search Tre so the method for in order traversal is first we visit the left sub child then we visit the node we want to check and then we visit Its Right sub child or right child and we keep on repeating for all the sub trees so so essentially first of all we will start our journey at this root position so at the root position first we need to check that whether a left child exist or not and yes because left sh exist once again this becomes our current root node or current node we are working with again this also has a left sh so three would be the first value we would visit so let's mark three would be the first value we visited then we would go back to the root now this node has no other left Sub sub trial uh that has not been visited so we would visit value number four and then it does not have a right child so we will again go back and now for this five we took care of the entire left sub tree so we can mark five as visited as well and then we will go to the right side of the sub tree now in the right side of the sub tree for seven we still have a left node available which means we would first have to Traverse that so we would Traverse value number six and then we would go back and since this seven we took care of the left sub tree so now we will take care of value number seven and this is where we would end and now if you see this sequence this actually came out as a sorted uh values so this is all we need to do that whenever we need to uh run for a tree we simply need to do an in order traversal if all the values are in correct sorted manner then we can Define this to be a valid binary search tree if that is not the case we can Define it invalid and let's try to understand this with a very small example suppose we are given the values as uh 5 3 and 2 suppose this is the sequence of values now if we do order traversal in this one first for five we are going to visit the left child so we are going to visit value number three that is good then we would visit value number five and in the end we would visit the right side right sub tree that is value number two now up until this portion this was a valid binary search Tre but the moment two entered over here this this is no longer a sorted uh sequence so that's why we can Define that this is not a valid binary search tree and let's see the code for this one right now so this is the validate binary search tree problem and now let's see the Java solution for this approach we already know that we need to do an in order traversal in order to validate that whether given tree is valid or not and for that we are creating a helper method where first of all we are checking that if the given root is equal to null then we can return true if that is not the case we need to do the in order for the left sub tree of the given root and the right sub Tre of the given roote so we do this that we call our uh recursive method once again where we call the left subtree uh as an input and we try to see that what is going to be its answer so let's say that if this yields the answer as false uh then we can simply return false if that is not the case then we can move forward and we will check that if whether the previous element was null not equal to null and if the value of the root is less than the previous element then also we can return false which means in this scenario we identified an anomaly where there has been a mismatch between any two values and they are not currently sorted if that is not the case then we are going to Mark the previous node as the root of the value of the root we identified and then we are going to call the in order function once again on the right side of the sub tree so this is a very simple piece of code but it's actually very powerful and help us Traverse the tree in the correct manner recursively plus we are learning that uh what type of uh tree it is now let's submit this code and our code runs pretty fast compared to a lot of other Solutions so that's pretty good where graph is a very similar data structure to a tree uh and if we just talk about the terminology that we are going to use in the graph even in the graph we are going to have a node but in the graph we can also Define node as a vertex and that essentially represents the same circular dot that I just mentioned where you can store all sorts of information like integer or character Boolean or class value or whatever he wants to store you can store that inside but on top of that apart from that nodes node having that important data information it also has the information of other nodes that is that it is connected to in the current system and those other nodes can be n number of nodes on top of that those other nodes can also be connected inter internally as well and there are some scenarios where one node is connected with another node but another node is not connected with that node and that node might be connected with some other node and that some other node might be connected with that node as well so there are lot of different uh ways uh graphs can work now one key difference between a tree and a graph is that graphs are graphs can be cyclic in nature and what do I mean by cyclic that let's say that you have a node that is connected with another node it could be possible that is also connected with another node and that is also connected with the previous note and this type of configuration would not be present inside a tree this this can only be present or prevalent inside the graph and that is the the biggest difference between trees and graphs and that's why they have their own entire set of different con considerations and connections so now let's just go back to the basic terminology that we need to understand first we understood that what a node or Vex is or vertices is next thing uh that we have to consider is The Edge and Edge is the it means the same thing that that is the connection point between any two values uh that are next to each that are connected with each other so Edge means the connecting points now there is also the concept of adjacent uh adjacency or adjacent vertices what do I mean by adjacent vertices let's say I have a graph that looks like this and in this case uh currently let me Mark the values as a b c and d so in this case if I consider this node number c I can say that node D node B and let's mark this node as node e so B D and E are actually adjacent nodes to this node C because they're directly connected with that with an edge but if the this node is not actually connected with vertices then in this case this node C and A are they are not adjacent nodes to each other so this is what what do we mean by adjacent nodes now there is also a concept ccept of degree inside for any single vertex and what does a degree means that degree means that how many number of vertexes uh or connections that every single node has so let's say if I have a graph that looks like this in this case I have node a b and c so I can Define that this node only has one Edge so I can consider the degree of this node to be one in this case for this B it has the degree of two and in this case this C it has degree of one now there is also another concept of the total degree depending on the incoming and out outcoming edges as well and where does incoming and outcoming edges comes to place well we we will talk more about that when we discuss the type of graphs but remember that graphs can have a functionality where two one graph is connected with another graph but another graph is not connected so in this case if we Mark if we have a graph like this where a has an edge leading to the B but B does not have an edge leading to an a which means from a we can actually go to B but from B we cannot go back to a so in this case a would have an degree of one but B would have degree of zero in this case so that is that is the difference between these two uh this concept of degree for the graphs now let's see that what are the types of graphs that we we can deal with so number one type of graph is a directed graph and what does a directed graph means that I just showed it to you you that this is actually a directed graph where one node is actually connected with another node but it is not the vice versa is not true and the directed graphs can get really complicated as well it is not always going to be this simple or this similar and it could also be possible that there can be hundreds or even millions of nodes that are connected with each other in this fashion as well uh where we would have various degrees and various directions happening amongst different vertices there could be undirected graphs as as well and undirected graphs are actually a graph where two nodes share a common Edge so in this case rather than treating is as a single edge typically this is used to be like this where node a has an edge leading to node B and B has an edge leading to node a which means from B you can also come back to a and from a you can also go back to B but in this case typically we only show them using a single edge then whenever there is an edge without an arrow it defines that both nodes are connected with each other in the simplest Manner and there are there is a bidirected connection or an undirected connection now there is also consider uh also a concept of weighted graph and what does a weighted graph means that let's say that you have different nodes and different nodes had different connections and different connections have edges so edges carry weight as well let's say if I'm trying to plot a graph of a city now in this city uh this node represents the Young Street and this node represents the main street now these two streets are being represented and there is let's say there is also third street called Queen Street now there is a graph that looks like this but in this case it could be possible that this is this graph I'm defining this is defined as a road so it could be possible that from Young to main though there is a road there is some construction going on so because of that this Edge is actually weights five which means it takes 5 minutes from Young to go to main but it could be possible that from Young if we need to go to Queen it only takes 1 minute because there is no construction and from Queen there is only uh there is an edge going to main that also only takes 1 minute because there's no uh traffic so in this case because this Edge contains higher weight if we have to choose the shortest path between young and Main Street it it has to go through the queen Street and uh this would be the concept of a weighted graph this is really powerful especially for GPS system and the shortest path that we have to create uh between any two edges like Google Maps use this like crazy uh now there is also another concept of unweighted uh Edge and unweighted Edge is basically an edge that does not have any parameter uh so let's say that I'm creating a graph of just friends so currently a is friends with B and B is friends with c and C is also friends with a so in this casee I don't need to have any weight on the edge um they are all just friends and none of them are best friends so that's why it's a common relationship and U we can do whatever he wants to do then there is also concept of Click graphs and a cyclic graphs so cyclic and ayylic both means the same thing essentially this is a cyclic graph and let's say that if I did not had this Edge in this case then this would have been an ayylic graph where cylic graph has means that there exist a cycle between the nodes and a CLI graph means that there are no no Cycles happening so usually in ayli graphs there is a very popular concept of dag which is which means directed ayylic graph and directed asly graph means that every single node has an directed Edge so let's say that there this is node a node a is connected with node B and node B is connected with node C and C is connected with node D so this is an example of directed A basically graph where we see bunch of different edges but there are there are no issues with the graph now because graphs are a little bit trickier uh we have to take care of two things we have to take care of vertices and we also have to take care of edges to represent that what graph is connected with which so that is why uh even in order to represent a graph we need to have some different set of data structure so one possible data structure is an adjacency Matrix and another data possible data structure is an adjacency list so I'll I'll give you give you an explanation of both of them let's just have a demo graph uh that is a simple enough so let's just say we have a graph that a is connected with B and B is connected with C and C is connected with d and this is a graph right uh that we are trying to represent so if we have to create an adjacency Matrix what adjacency Matrix means is that we are actually going to have a 2X two or sorry M cross n Matrix where for every single vertices and edges we are going to have uh a matrix looking like this so we are going to have rows a b c d same way we are going to have columns marked as a b c d now currently uh all of the these four values will always be zero because node cannot be connected or cannot be its own neighbor now now let's say that currently a has a connection with B so we are talking about node a and its neighboring Edge to be B so in this case we would mark this value as one now B has a connection with C so node B has a connection with C so we would also Mark this value as one C has a connection with d so C to D we would mark it as one and D to uh and D does not have any connection which means this is going to be zero and all the other values they are going to be marked as zeros because they don't represent anything which means currently we have a graph that contains four nodes a b c d amongst these four nodes we only have connection between from A to B so that is why this is one but we do not have a connection from B to a so that is why this is defined as zero let's say that rather than this being a directed graph If This Were to be an undirected graph and we only have edges like these in this case in our adjacency Matrix we are going to represent values differently where uh even from B to a we are also going to Mark as an edge same way from C to B we are also going to mark an edge and same way uh D to C we are also going to mark an edge over here so all of these values would also be one in this case so this is the way on how we can represent graph in The adjacency Matrix Now adjacency list is a little bit different where adjacency list we actually have a hash map and I I know I haven't talk talk about hashing yet but inside a typical hash we have two values we have a key and we have some value associated with those that key so as a key we are actually going to have the four vertices that we are given so in this case it's a b c and d now for this we are going to mark that what are all the neighbors that a is connected with in this case currently a is only connected with B so we are going to have a value like B Associated for a same way currently B is actually connected with A and C both so for B we will have a value of a and C both and this is actually going to be a link list that where which represents that there can be n number of children associated with a sing or n number of neighbors associated with a single node same goes for C that from C it is connected with b and d and d is only connected with c and this is how it would be represented in adjacency list now the question is which one is better and which one is worse well in my opinion both does the job well but if you're dealing with a low number of edges then in that case it makes sense to use an adjacency list because it SP it uses less space uh meanwhile over here you see that there are more zeros than the number of ones but let's say that we have bunch of different edges that we are trying to work with something like this in this case it would make more sense to use an adjacency Matrix rather than using adjacency list so so these are the two ways on which we can actually use uh to represent graphs now what are the operations we can do on the graphs uh speaking of operations well the common operations are always going to be there that in terms of operations we would be able to insert we would be able to delete we would be able to modify we would be able to search there is no there is very little concept of sorting in this case because it is not very optimal for sorting but apart from that these these are all the things that we can do but in order to do that we can only do it by traversing over the given graph because we would not know that where we are traversing so we must have to Traverse and for Traverse we actually have two options we have the breath first search and we have the depth first search so I'm going to talk about both of them in a simplest manner uh if you want to know more about this uh I have created an entire separate videos on these two topics so that's why let me give you the basic idea that BFS represents breath first search what does breath first search means that we are actually going to search our neighbors first and before going to their neighbors and DFS means that depth first search what does depth for search means that we will pick a neighbor then we will pick one more neighbor for that neighbor then we will pick one more neighbor for that neighbor and we would keep on moving forward in that direction so let's try to see that in let's say that we have a graph that looks like this where we have bunch of different nodes that are closely connected with each other and we are trying to find some particular value right uh let me draw out bunch of different edges and with every single edge uh we would be able to reach to a certain conclusion about the given graph now let's say that this is the graph currently we have and we also have a cycle in in it now we are currently located at this node number a and we are trying to find this node number B and all of these nodes they can have their own subsequent separate values so if we are going in the BFS manner breath for search manner what we what we will start to do is let's say that this a is also the root node because even just like trees graphs also have the concept of root node so let's say that this a is the root node so from this a we know that what are the neighbors of a through either adjacency list or adjacency Matrix so we are going to use that in information and we will start traversing to all the neighbors so first we will go to this neighbor okay this is not value number B then we will go to this neighbor this is not value number B then we will go to this neighbor this is not value number B then we will go to this neighbor then we will go to this number we ex ex uh excluded all the possibilities for all the neighbors none of these neighbors were actually value number B so then we will pick one neighbor at R random and we would keep on moving forward so let's say we pick pick this neighbor again we go to its neighbor and again we go to its neighbor none of these yielded any good any particular good result so what we do we backtrack in that case and again from this a we would pick another neighbor so let's say we pick this neighbor this time and through this neighbor we would go to this neighbor and we would also go to this neighbor and we found out value number B so we can say that okay this is the connection between a to B and let's just say for this example the value of this neighbor is node number c so we can say that there exist a path from a to c and from C to B where it is connected now this would be the strategy for breath first search uh and I hope that my explanation was clear enough so that you get the idea now let's see that what would happen in the depth for search scenario so in the depth for search scenario we will pick one neighbor and we will keep going deeper and deeper into that neighbor so let's try to understand this with an example suppose we are again located at this position number a so from this position number a first we will pick a neighbor so let's say we pick again this neighbor now again for this neighbor we would pick one more neighbor so one more neighbor we ex now we uh concluded all the possibility that there this neighbor does not have any neighbor that we haven't visited so what we would do is we would backtrack to this position again see that are there any neighbors that we haven't visited so we actually check this neighbor okay this one we haven't visited so we visit that and that also did not yield any result so again we backtrack we come back to our main a then we pick another neighbor so let's say in this case we pick another neighbor called C from the C we again go to deep okay so this one did not yield it result so in this case again we check for this one and this one yielded the correct result and we again created a path from A to B to C and again we got the correct answer now you must know that under which situation you need to use breath for search and under with situation you need to use depth for search let's say that you have a graph and you expect B to be somewhat closely to your current a if you expect that in that case it would make more sense to use breath for search because you are more likely to find a result within some of the neighboring graphs but let's say that you have a graph that is much more complicated and B can be located somewhere down the road uh somewhere very far far far away in that case it would make sense to use a depth for search rather than breadth for search in either case the time and space complexity for both breadth for search and depth for search is actually going to be bigo of M cross n where M can be the number of vertices and N cross be the number of edges so it could it would be B of Vertes multiply by edges and all the operations we defined for the arrays they are also going to have or they are also going to follow the same time complexity that whenever we need to to find any any two values it is going to be the same now let's see that what are the use cases when you have to use graphs number one use case is actually social network so in Social Network we know that let's say that my name is person a so person a can be friends with many other person so I can be friends with B I can be friends with C I can be friends with d i can be friends with e something something something like that right and E can have their own separate friends so e can have friends F and uh Zed and all all all of that now this is how a typical social network looks like and that is why it is really common to use that let's say if I'm using a social network like Facebook where if I am I can only be friends with someone if that person is friends with me in that case there would be an undirected relationship but let's say if I'm using something like Instagram where some X person can follow me but I cannot follow that X person so in that case let's say that I have a relationship like this where X is following me but I'm not following back X so in this case we have a directed graph or a directed relationship but either cases it works perfectly fine next there would be a great use case for uh different internet and because in the internet we have a many different web pages that contains lot of information and we have the HTTP uh URLs that are are connected with each other on top of that from every single uh web page we can also have many different HTTP web pages that connects to some other web page and from that it can have many different web pages that connects to some other web page so in this case graph can be a good way to store all of that information plus I already mentioned that if you want to create a GPS system or any navigation system graphs are a wonderful approach and you cannot build a navigation system without using graphs where cities or places are treated as vertices and the roads are treated as edges and uh that is how you move move forward on top of that wherever you have to resolve any dependencies you can actually use graphs to resolve that dep dependency so let me give you a quick example let's say that you are studying in a university and in the University we know that we can only take courses that are like 204 or 205 if we already completed its prerequisite of 105 something like this so if that relationship is done done if unless I have completed this I cannot move forward to this particular course so in that scenarios treating different courses as vertices and connections with them between them or dependencies between them as edges would yield to Greater success in terms of all the results so these are all the operations and all the things where you must use graphs so first of all we are going to understand a graph with an example so this is a very simple problem and I might use some terms or some Concepts that you might not be familiar with but don't worry about it I would be guiding you throughout the whole journey and it's actually a quite simple way to understand what does a typical graph problem looks like and how does it work so number one thing in the graph is that for this problem we are actually given an N cross n Matrix and in this n cross n Matrix we are being told that this n represents the basically cities and if there is a path from one city that connects to another city then there would be a link in this n cross n m Matrix so it would Mark as one for that particular cell and if there is not a path then there won't be U any connection and it would be defined as value zero so let's try to see that what we need to check we essentially needs to calculate that how many number of provinces are there so what provinces are being defined as that let's say that if there is there are cities connected with each other then they would be part of a single Province so this would be a single Province P1 and even if there is a unique city that is not connected with each other still it is a province on its own so we would consider this as a province as well and uh let's try to see some examples of what different questions or what different things that we can refer so number one example is actually quite simple let's assume that we are given the CI a b and c in this case and we can see that City a and City B is connected with each other City C is not connected with each other so in this case this is a province and this is in itself another Province so we can return that in this case there are two provinces present and we can return two as the answer let's consider one more scenario suppose we are given uh four cities in this case and let's say that for the four cities all four cities are connected like this and you see that there is actually no connection over here but still we can conclude these cities to be connected how because let's say that this is a so a is connected with B and B is connected with C and C is connected with d so in this case you can still reach to D so all of this entire cluster would be considered as a single Province only let's take just one more example to make things more clear let's suppose we are given four different cities and all four different cities are not connected with each other in this case we can Define that four there are in total four separate provinces available in this case so let's see that what is going to be the approach to solve this problem okay so let's assume that this is the example we are given and this would be its Matrix that is going to represents the connection connection between any two cities now in this example we can clearly see that there are actually going to be three number of provinces uh this is the first Province this is the second Province and this is the third Province but let's see that how we are going to compute these results and for that we are going to uh first Mark or populate these Matrix basically this Matrix is already given to you in the example but I'm just showing you that what is the approach we are going to take in order to solve this problem so first we are going to see that uh since there is a single ended or one unidirectional connection between a to B which means we can also Define that there is a connection from B to a as well and this is what we are going to represent in this n cross n Matrix so first let's see okay so we have u a connection between a to B so we are going to mark this as value number one same way we have a connection between B to a so we are going to mark this as is one as well and B to C there is a connection so from B to C there is a connection same way from C to B there is a connection up again from D to e there is a connection so let's mark that from D to e there is a connection over here and same way from E there is a connection to d as well so let's quickly Mark that and uh that is over here okay and then F there is no connection so basically these are all the connections we have apart from that all the values are going to be filled out with values of zero we can actually consider this as a uh adjy Matrix for our our given graph and we can treat each of the Cities as the node of a graph and the connection or the edges between these cities are actually the edges between the these nodes so now all we need to do is we need to find the number of connected components and that's it so that is actually quite simple to do but how to do it I'll just show it to you quickly now I already mentioned to you that in the graph we have to keep keep track of the notes that we have visited already so that we don't encounter any issues with the visited uh we don't have any issues in the future so we are going to have uh basically a hash map that where we are going to store the values of all the visited values and plus we are also going to keep track of the neighbors or the connected cities for that particular node as so we can actually skip that in the future and the approach we are going to take is we are going to do a breath for search starting from any node and we would keep on doing it until we exhaust or we take care of all of these six cities so let's start our approach and the idea is that we are going to start working from the node a so let's mark that currently we are located at position number a so we are located at this position now from a we are going to see that what are the places it it is marked as one or it is connected to those cities and we are going to Mark those cities as visited so let's just say since because we started a new province with this new traversal a we are going to increase the number of provinces so this probe is defined as the variable that keeps track of how many number of provinces we have been able to find so initial value was zero and now we have value as one now from a we see what who is the neighbor of a so the neighbor of a is actually value number B which means means in our hashmap we already had entry a then we are also going to add entry B and this can actually be a hash set rather than hashmap what is the difference you would soon find out uh when we talk about hashing but right now just consider that we are marking these values so this would allow us to let us know that these are the cities we have already visited so we don't visit them again okay now we are at position number B from B which are the cities B is connected with so number one city B is connected with is City number a but a we have already visited so we are going to skip this for now then we are going to visit City number C and C we haven't visited so we will mark C over here okay so now we are at City number c what are the cities C has that we have we haven't visited so C is only connected with b and we have already visited B so which means we can conclude that in this case since we visited C does not have any more neighbors that we need to visit so we will do a backt trck we will go to B B again does not have any more neighbor that we have to take keep track of so we and once again we will backt track to a and a we already visited all of its neighbors so we can conclude this a b and c to be completed over here and so far we have been able to find one Province but now in this case we will jump or have to go to the next city d by taking a jump because we are not going through a connection from any particular node so that is why we are adding one more Province or we are exploring one more Province so we will increase the number of Province to two and in this case uh at City number D we are going to visit all the neighbors of D in breath for search manner so since D only has one neighbor that is City number e so we are going to go to City number e and we are going to Mark uh both d and e as visited in our hashmap on top of it with e e only has one city as its neighbor and that is City number D so in this case we have already visited D which means we can Al conclude both d and e to be visited as well and now we will have to still go to a city that we haven't visited so far that is City number have the moment we go to a new city we are going to increase the number of provinces so now number of provinces is going to be three and we are going to say that we are currently visiting City number F now F does not have any more Neighbors which means we can conclude that from F we cannot go anywhere else and now we have visited all the cities that were present because we have that value in our hashmap and we so far we have been able to find three different provinces connected using this manner so this is how typically a graph problem operates where in most of the cases you are going to have vertices you are going to have edges you are somehow going to iterate over all the vertices through edges and you are going to use an adjacency Matrix Or adjacency List uh uh as the way that stores the information of what the graph is and most like you are going to use either hashmap or hash set to keep track of the Cities you have already visited so you don't end up in a a continuous loop so let's see the Java solution for number of provinces problem basically uh we are we are given the 2x2 or n cross n Matrix that defines that what are the components that are connected with each other so first of all we are going to define a number n that is be that is going to be the cities that we have and we are going to create a Boolean visited array to keep track of all the cities that we have visited so far initially the number of provinces are going to be zero and then we are going to run a for Loop to iterate over all the given number of provinces and initially we are going to check that whether that particular city has been visited or not if it is not being visited then we we will go to our BFS call or breath for search call and uh recursively try to find the solution and every time uh the Call Comes Back we are going to update the number of provinces now in the end we are simply going to return the number of provinces now let's see that how does our BFS function works now since we are doing breath for search breath for search can be done using a cube so we are going to first of all initialize a cube and uh we are going to have a link list for the cube you can have lot of data structures s Cube so first we are going to start with the start value then we are going to mark that start value as V visited and then through that start value we will keep on iterating to its neor neighboring cities until we have visited all the values inside the current q and the moment as Q is empty we are going to jump out and say that okay now we have visited all the connected cities and throughout our connection we are marking those cities as visited so that's how we are we have been able to calculate uh all the connected cities as visited and only increasing the number of provinces for the new cities now let's try to run this code okay seems like our solution is working let's submit this code code and our codee runs pretty efficiently compared to lot of other Solutions so you can imagine that how a combination of data structures are being used to solve a simple problem and uh KN knowing all of these data structures would help you quite significantly in order to break down and solve a problem and generate the algorithm for that problem okay now we will learn about hash based data structures now hash based data structure are actually quite unique in nature plus they have their own set of uh very important use cases that you are going to see out throughout your data structure and algorithm problems so first let's understand that what does a hash based data structure is typically when we talk about hash based data structure we are usually talking about a hash map and a hash set now both are quite similar in nature and both have very similar properties but the only difference is that hashmap is typically used used for to store a key value based uh mechanism where we have some key that we use to search through the given uh data structure so it will give us an idea that what are the things currently present inside our given data structure and what are the values associated with that hash set is uh where we only save hash based keys so nothing more than that so now first let's understand that what does a hash map is how to use it we will see an example of how it is being used uh in an actual interview and then we will learn about hash set so hashmap as I already mentioned that there are two properties associated with that first one is a key and second one is a value now let's try to understand hashmap from a real life point of view if you have ever seen any kind of dictionary well typically the dictionary is a very close example of a hashmap where in the dictionary typically on the first page we usually have an index index page and in that index page we are given the information that uh a starts from page number one uh something like B starts from page number 15 and so on and so forth and this is usually sorted so if we have to find any particular value all we need to do is go to the index page in the index page we can find the information that okay uh letters starting from um M are actually stored at page number 53 then all we need to do is that in our dictionary or in our book just go to page number 53 and we would be able to find the meaning of word man or map or anything that it would be present over there so this is the actual idea being used in the inside the hashmap as well where we are given two items or we are storing two items first item is a key and second item is a value now key is going to be the hash function that is a some computational method so this is usually the hash function we Define where the values are being stored as keys and whenever we need to search inside our hashmap that whether this particular key is present or not we can do that in B of one time in constant time so let me give you an example of how does this actually work let's try to understand that we currently have five different values that we are trying to store and these five values are 11 12 13 14 and 15 now for these values I want to create a hashmap function where I want to retrive these data in the quickest manner possible which means I already know that these five are going to be my values but I need to create keys for them and the key I'm creating is that I create a method where I say that any particular value that comes in I'm just creating a basic hash function so you would get an idea that I create a method where any particular value that comes in I'm going to divide that value by five and whatever the remainder is so the remainder I'm going to treat it as a key and now let's see that how would this work so first let me draw my hashmap and inside the hashmap I'm going to have two values key and value so first value is 11 that I'm need I'm trying to input so I'm going to divide 11 by 5 so 11 by 5 is going to yield me the remainder as one I'm only concerned about the remainder I'm not concerned that what does the division value comes in so remainder is going to be one so I'm going to create a value over here where the key is one and its Associated value is going to be 11 same way for Value number 12 the remainder is going to be two so once again I have an entry two and the value is 12 same way there is uh for 13 we have value number three and the value is three for 14 we have value number four and value number uh uh 14 and the last one is the value number 15 so what should be the key for Value number 15 well if you guessed five that's wrong actually the key should be zero because remainder in this case is actually zero when you divide uh 15 divided 5 you actually get the remainder as zero so 0o is associated with value number 15 now I have these currently these values being stored now let's say in my program for some purpose I want to check that whether in our hash map do we all already have value number 13 or not so what I'm going to do in this scenario is that for Value number 13 I'm going to uh basically divide this 13 by 5 so I'm going to check that remainder is equal to 3 now this remainder is actually my key so then I would go to the hashmap and say that hey hashmap do you have any value where key is equal to three so hashmap would say that yes I have key is equal to three present but I don't know what value is so you would say okay bring me this value so you you fetch this value and this value it turns out to be 13 and then you would be able to say that okay in my hashmap I have a value 13 that is stored currently present and then I can do some competition with this now can you identify some issues with the hash function I have created uh let me just draw the hash function again and currently these are the values I have and the associated values are 11 12 13 14 and 15 now this is currently my my hash function okay so far it looks good but now let's say that I'm trying to see that does value 61 exist in in my hash map or not so what would my Approach is going to be once again I'm going to do 61 divid 5 and remainder is going to be 1 so once again as a remainder I'm going to go to the hashmap and see that okay hey for this key number one what is the value associated with this the value Associated right now is only 11 so I can say that 61 is currently not present in the hashmap once again I got this result in big off one time but now what if it happens that I want to add 61 to my hash map as well well in this scenario I since the key can only remain constant so which means for this key 1 I have one more entry that is 61 that I need to add over here so in the place of value I might I might need to create something like a link list because there is a collision over here of the keys because the number of values are more and keys are less yes so in this kind of scenario collisions are bound to happen and because there is a collision now I have value number 61 let's say the value is 71 I'm trying to add so once again I will add one more node in the link list and I would add value number 71 over here so so far let's assume that initially when we only had five values we actually had five keys and five values so the equation was almost one to one relation and we were able to fetch any particular data in big of one time but now let's assume that we still keep only five keys and now we have uh for an example one 1 million entries so in this scenario or let's say 5 million entries and five keys so mathematically every single key would have 1 million entries ass associated with that particular key and in that case all of these 1 million values would be stored in a link list uh in the value section connect where one node is connected with the another node so so once again in this kind of scenario if I have to fetch any value now now it it's going to take big of end time where n is going to be 1 million in this case so this is actually really bad so in the hash whenever you are building your own hash map you need to make sure that the hash function you are you are using to build evenly distributes the values which means that for any single value typically the hash function tends to be a unique set of key and that is one of the biggest consideration now now lucky for us most of the programming languages like Java python or whatever you can think of they already have this functionality of implementing a very good hash function that usually tends to be unique and implements the keys in the unique manner so we don't have to worry about it all we need to do is just declare the hashmap and uh we need to declare that what type of key and value pairs are we are going to store so we can store like integer as the key and string as the value and then we can name our hash map as something like my hashmap and then we simply need to initialize it and that's it so this way it's it becomes really powerful so always make sure that even during the interview interviewers love asking this question that uh how do you handle Collision in your hashmap so typically you would assign a link list for to store values when you predict a scenario where there is going to be a collision in terms of values now let's see that what are the different operations we can do for any given hashmap and I'm going to store some values so let's say one is associated with 11 and two is associated with 12 so this is our current hash map right now hashmap tends to be dynamic in nature so which means that uh all the values you want want to assign if you want to keep on adding more and more values in this scenario essentially you don't have to do anything it will usually takes care of it and most of the languages are sophisticated enough to be smart in that regard so that is really good for us now first operation we can do in hashmap is we can add a value so typically this is done by using something called a put variable uh and we can put a new value inside the hashmap and this is usually done in big off one time where we need to provide the value of a key and Associated value with that remember key cannot be a null value you can have a key uh that does not have any value associated with that that's fine but still key cannot be a null value you cannot have a value that does not have a key associated with that in the hashmap second operation we you can do is you can delete any value from the hashmap and this is also done in big off one time so that's great next operation you can do inside the hash map is that you can search for any element and searching also takes big off one time because we are using the property of key value pair and we are searching using the keys we are not searching using the values so that is an important distinction you have to understand whenever you are trying to think that how you're going to use hashmap to achieve your goal next uh operation we can do is we can actually sort all the values but that we need to do it sequentially so there is no inherent method to do that so essentially this is still big of n log n uh time operation where you need to uh call some other data structure and then you need to populate all the values uh let's see what are other operations we can do you can of course you can modify all the values that are currently present and that can be done in B of one time and that's it so now you can see that uh hashmap on paper looks pretty good because all the operations that you can think of insertion deletion addition modification uh searching sorting they're all pretty fast and pretty efficient uh there is one big issue with the hashmap and that big issue is that you cannot have duplicate keys so uh the key value has to be unique so no duplicate keys and also the duplicated values would be stored under the same key because key these are typically generated based on based on their values so always remember that duplicate values cannot reside inside the hashmap and now let's see that how does a hash set work and then we will see an example of a typical hashmap problem so hash set is very similar to hashmap but the only difference is that inside the hash set there is no concept of key value pair it is only just the values that are being stored but these values are typically stored using the hash function so uh let's say that I currently have values 1 5 15 uh 31 and 21 uh that I need to store so so far I have stored these four values inside my hash uh set so I can of course enter these values 11 15 uh 31 and five now I want to check that whether 21 value is present inside the hash set or not so I can check this in big of one time why because just like a hash map hash set also uses the hashing function it just doesn't store the key but still it calculates based on the value that you are trying to input so there is going to be a mathematical function that operates and that would be able to immediately identify that whether this value has been processed and stored inside the headset or not and uh it's not stored so I we can add this entry now again just like hash map hash set also does not allow duplicates so there is there are no duplicated entries over here and uh one good property that since there are no duplicated entries allowed whenever you need to check that in any other data structure like a link list or um an array if any duplicated entries exist you can actually use hashset to solve that kind of problem quite easily and there are many use cases for that as well uh once again if we look at the operation operations are pretty much the same so uh everything like uh adding value takes big off one time once again deleting also takes big of one time uh searching takes big of one time sorting takes big of uh and log and time so this you can usually consider very similar to hashmap the only difference is that in the hashmap you can actually store the correlation between key and value in the hash set you only store the value now let's try to understand couple of examples through which we will understand both hash map and hash set so let's say for an example we are given suppose an array a where we are given five different elements and now our job is to check that whether uh the array contains any duplicate element or not and if it does what is the duplicate element so let me give you an example suppose the values are 5 3 1 2 and 3 so we can see that three is the duplicated element and the purpose of our program is to check or find that whether there is a duplicate element or not and if it if yes then which is the duplicated element so first let's understand that what would be the Brute Force approach in this scenario well it is quite simple we just take take any element so let's say we take element number five in this case and then iterate over the rest of the array to see that whether Val value five is present or not if it it's present we can return true if it's not present we can return false and go to the next element so for three we will repeat the same process and we would find that three is also present in this case so we will return return three as a duplicated element but this approach yields the big of n Square time complexity because for every n element we are essentially doing n minus one work so that is a multiplication factor and uh which is not too good so let's see what would be the better solution so better solution would be that uh if we try to sort this given array then things would become easier so if we sort this input we will get an array that looks like this that 1 3 uh sorry 1 2 3 3 and 5 so in this case uh then we only need to check the adjacent values and here we would be able to see that these two adjacent values are same so we would return return three as the answer now this better solution where we are sorting the array that is also bigo of n log n time solution so could there be a better approach and the answer is yes and that is by using a hash set in this scenario so what we would do is we would initialize a hash set our algorithm would be that we would first check that whether any element if that is present inside the hash set or not if it is present already and it is also in the array then we can consider that to be a duplicated element if it is not present then we would simply add that element to our ha set so let's try to run this method so first we would add value number five over here because it is not present already uh so then after adding it we would move to the next element now value number three is not currently present inside the haset so we would again repeat the same process then again we would repeat the same process for Value number one and again we would repeat the same process for Value number two and all of this insertion would take big go of one time Plus checking that whether the element is present or not that would also take big off one time so this is not any uh additional overhead now when we are at position number three we check that whether three is already present inside the hash set or not within big go of one time we would be able to find out that three is already present which means we would know that three is the duplicated element and we can return true in this case that yes this array does contain a duplicate element and if we are being asked to pass on that which value is repeated we can return three in the answer so either case this hash set works perfectly fine now what would be the solution in this case or the time complexity well time complexity is going to be biger of n because we are going to only iterate over the element or this array ones to solve this problem but in this case space complexity is also going to be bigger of one uh bigger of n because we need to create an additional hash Set uh and its size is dependent on the number on the given input now let's see that uh this would be an example where we would use hash set to solve the answer but now consider a scenario that in the same example uh we are being asked that rather than just giving out the value of the uh duplicated element give us the index value so again let's see that how would that scenario work suppose this is the uh given new array and we need to return the index elements of the duplicated element how what should be our approach once again we already know that brute force and uh sorting approach already works the way it does in this scenario as well but in this case since we need to return the index values hash set would not be the optimal choice and it would make sense for us to use a hash map where inside the hash map we would actually create a key value pair based database where in the key we are going to Mark these values and as their subsequent values we are going to Mark the index positions so when we need to fetch that which index positions are duplicated we can return that quite easily so now let's see the solution in this case so for first of all we would check whether five is is present or not five is currently not present inside our hash map so we would add an entry called five and we would add its index location zero now again one is also not present so we would add entry one and its index location is one three is also not present so three and index location two and four is not present so four and index location three now again this is key value pair so you understand what I'm doing now when we are at this position number five or position number four uh where the value is one we try to add one but we already see that one is already present because it is marked as a key and this operation can be done in big off one time because it's a hashmap so since we already found that we can actually return one uh is the duplicated entry and if we want to return the index positions we can return the index position from here that would be four and the value of this key one so that would be one and this would be the answer we need to return in this case so you can understand that how quickly we are able to solve problems using hash map or hashset and uh we are going to use them throughout this course for bunch of different problems so you should be able to understand them quite easily now after learning most of the basic data structures we are going to learn couple of advanced data structures and these Advanced data structures are actually quite popular in technical interviews and also a lot of computational problems as well so there are quite a lot of advanced data structures but we are going to shift our focus on two two main ones first one is called Heap and second one is called try now both are combination of various data structures but they have a very specific use cases where it is really popular and really powerful so first let's understand that what a heap is Heap is typically an extraction of a binary uh tree tree based data structure where it it maintains the property of a binary tree which means any single node has at most two children and it tries to balance out this property as quickly as possible and even if there is an anomaly it would only be at one of the positions where the number of children would be one but nothing more than that so you would never encounter a scenario where any single node has three children or something like that so after that there is also one more important property for a heap and that is that it is a common implementation for a typical priority Cube and we all know that in a priority Cube the most important thing is higher or lower priority depending on that so in the Heap usually we use it to keep track of uh the maximum value out of any given incoming data stream or the minimum value of uh any incoming data stream and both have very significant purposes and very significant importance in many of the questions so first let's try to understand that how does a typical Heap looks like how does it work and then we will see some examples so first we will try to implement a minimum Heap now the property of a minimum he Heap is that number one it is going to maintain the binary tree nature so one node is going to have at most two children number two is that every single parent is going to have less value than its child and number three property is that all the nodes that we would try to enter first we would enter in the root position if the root is already filled we would try to enter that node into the leftmost position if that is also filled then we would try to enter that node as a right child for any particular empty location so we would try to find the location first once that is done we would sort of heapify the given input or the our given Heap to maintain this property so let's see this in action suppose uh currently we have an empty Heap so let me draw an empty circle and now let's assume that the first value we are trying to enter is going to be value number five so initially we are entering value number five over here now the next value we try to enter let's assume that that is value number 10 so remember the scenario is first we will try to add it to the root value root we already have added which means we will try to add in the left children so let's add the number 10 in the left child and after adding that we need to check that whether this property has been maintained or not that whether the parents value is less than the children value or not and in this case since five is the parent it is less than 10 so this is currently correct so we do not need to do he operation for this step now let's see one more element so suppose we try to enter value number 15 now again 15 needs to go to uh either root place but root is already filled so it needs to go to left that is also filled so it will go to the right place and right place after adding 15 we would again check that whether the he5 property is maintained so again parents is still smaller than children so that is good now let's try to enter the value number 25 so once again 25 will go go to the left position and so far everything seems to be working okay no issues with this now let's try to enter the value number seven now again by this logic first of all seven has to enter to the right available position so this is not available this is not available but this position is available so let me enter seven over here but does there an issue with parents being lesser than child yes there is in this case seven is smaller than uh value number 10 so we would have to do the he5 operation so we would move seven from here and we would make it as parent and 10 would come to this place okay now everything is good so far now let's say that we try to enter value number 31 once again 31 would be entered over here and the property is still maintained now let's try to enter value number two so by default value number two is going to come over here but since two is smaller we will have to make a shift over here so let me quickly shift the values so now 2 is going to come and 15 is going to come over here once again two is still smaller so once again we will have to do a shifting operation so in the end two is going to come over here and five is going to come over here and now the Heap has been maintained so this is how typical Heap operates now in this case if you see always the parent is going to be smaller than its children so currently for the entire Heap we have the smallest value POS positioned at the root position so this is whenever if we have to identify that hey we have an incoming constant data stream that is coming in and we want to find that what is the minimum value at all times we can actually use Heap because it's a self adjusting uh algorithm or data structure that maintains its property of whether a Min Heap or Max Heap so in this case we can identify that okay the minimum value is going to be the value at our very first node and maximum value is going to be some value amongst the these Leaf node so in this case maximum is going to be 31 but we are not bothered about it right now now once again if we take any subtree so let's say in this case once again parent is still going to be smaller than child once again parent is still going to be smaller than children so Heap is a great algorithm whenever you need to keep track of that hey I have an continuous incoming stream of data coming in and I want to check the fifth smallest value from the beginning so in that that case Heap would be an ideal choice where you keep track of all the values in a Min Heap and then you essentially needs to go and select the fifth smallest value which can be done in log and time so that's great you will get the answers quite quickly now let's see an example for a Max Heap and Max Heap also works in the similar fashion the only difference is that now the value of parent has to be greater than the value of child so let's see that first we are try we have the element and we are trying to add value number two over here now the next element we are trying to add is value number three so in this case we will have to do an adjustment so first we will add three over here and then we will do our HEI so we would adjust the values so now three would be the maximum value and two would be the smallest value now we are trying to add value number 15 once again first we will add 15 over here but then again we will do the hepy principle and we will flip the values so 15 will become over here and three will come over here now we want to add value number five so by default five would be added over here but once again we are going to do over ep5 operation so according to that logic five will come over here and two will come over here and same way we can maintain a Max Heap as well so in this case whenever you would see the root node is going to be the maximum element at any given location for any particular subtree the parent is always going to be greater than child and Heap is going to Bubble Up and maintain its Max Heap property so this is how typically we use Heap in order to keep track of min minimum value or maximum value at any given moment on top of that we also keep track to for any questions like find the K largest value or k smallest value from the top so in either case the Min Heap and Max Heap or are going to be the ideal choice to solve these kind of problems and we would see bunch of operations later on in the course so now let's try to see that what are going to be the time and space complexity so ially the time complexity in order to insert any element inside the Heap is actually big go of logarithmic n why log n because it is already a sorted tree structure whenever we try to enter any value in any particular location we simply need to find that what would be the right place for it to be so at most all we need to do is make change to couple of places and then we can actually find its correct location so insert insertion is login same way deletion is also login same way finding anything is also login so this is a very powerful and very fast data structure uh from many point of you and that is why it has lot of use cases in the real world scenarios so this is the example of Heap now let's try to understand that what does a TR data structure looks like now try is also uh an additional abbreviation of a tree based data structure now inside the try uh we actually use try on a daily basis so whenever you see any system that uses autocorrect functionality so that is actually using a try so this covers your iPhone Android phone your messaging app anything plus wherever you see predictive searches so what do I mean by predictive search uh you can imagine that whenever you try to search anything on the Google or Amazon it automatically completes the statement for you and for that actually behind the scenes it is using try as a data structure so try is a very powerful tool since you can see that it has lot of practical applications and also remains favorite amongst technical interviews as well so that is why we are going to understand what a try is basically try typically operates on a string based characters so wherever you have bunch of different characters that you that you working with and you want to store them in a sequential manner where depending on the values you enter in the character You can predict the next element you can actually use a try so how does a try typically work is typically it has a root node and this root node tends to be an empty node but in its children we are going to store all the uh alphabets that are possible so typically in a real life try there would be 26 children one for each character from a to zed but in this case let's just let's just consider our example small and concise so we would try to add five different words to our try and we would see how they they would look look like so first word we are going to add is going to be the word rat second word is going to be R third word is going to be uh men and fourth word we would be uh let's say tree and fifth word would be uh try so these are the words we are trying to add first so let's just start with first one so first we will try to add R so we are going to create a child over here called r then the next word is a so again R is going to have a sub child called a and next word is t so T is going to going to be the child of a and now since this word has ended so now this is going to be an end node so we can determine this as a star or something okay that defines that this word currently ended over here now next word we are trying to add is R so once again from our root node we are not creating we are not going to create a separate child for R we are actually going to create a r as it as it is and then we are going to create a sub Branch so this R has already been taken care of now there is the word a so once again for a we are not going to create a new Branch but we are going to treat this R A to be of the same group so now you can see that how different words can be stored within a tree like data structure by their character properties because they are all connected with each other very deeply and next one is p but over here the next word is actually T so in this case we are going to create a new Branch over here and this new branch is going to have value number P and since the word ends over here we are going to have an ending node so that is denoted by star so now whenever I start typing r a uh the system would come over here and then system would predict that either I'm typing r a rep or r a rat and then that is how it is able to do a predictive search let's say that I print uh I type something like r a r rare but the system knows that rare is not a valid word which means system would predict that either the valid word has to be r or R so depending on the con uh context of the entire statement you are trying to make it will automatically adjust the word that you are writing and over here it would from this it might autoc correct it to the word rat and uh things would work fine so this is how typically autocorrect functionality works now let's try to add the word man over here now for M there is no child so we are going to create a new child and once again we are going to create a new child and we are going to create a new child and then we are going to create an end node so this is how men would look like now let's try to create the word tree so once again for tree uh we do not have any child so let's create a new branch and we are going to start with word t now next one is r and next one is e and next one is going to be e and then there is an end node but now let's try to add one more word try t r i e so we can already see for T and R it is going to have the same path or same Branch but now it is going to have a separate branch called I and then it is going to have a separate branch called e and then it would end the word essentially so this is how using just these three branches we can actually navigate all of these five uh words so this is the true power of the TR data structure and uh try is pretty popular in lot of technical interviews and wherever you see the example where you are given bunch of different words and you are trying to find some meaning and you are trying to find the best way on how to process them and how to store them try to consider or thinking of using the the data structure try and once again for try later in the course we are going to see an example so things would become much more more clear so I hope that you got the idea about Advanced data structures of Max Heap Min Heap and tribe and now let's move forward so first of all I would like to congratulate all of you for making up until this far uh we have cross the biggest hurdle in our technical interview preparation journey and that is learning about all the popular data structures I hope that you must have good enough understanding of each one of them and now we are going to shift our Focus towards algorithms which is not so complicated as data structures were but needless to say they are quite important so I hope you give your utmost attention to this portion because once you understand algorithms things will become much more easier for you to proceed for the subsequent parts now one of the most important thing that you have to master in order to master any technical interview is to understand that what are the different algorithms available to you and what are typical coding patterns that you need to to recognize but before we start diving deep into it first let's understand that what does algorithm mean algorithm is nothing but a simple set of procedure a computer or a program needs to follow in order to generate some solution so let's say that this is the problem statement given you need to follow a certain steps in a certain sequence in order to generate the results and there are many different techniques to that that we will tackle in this uh portion so following that would generate the unnecessary output that you looking for and understanding that what are the options available to you is going to be a significant key for your Tech preparation Journey now what is coding patterns let me give you an example suppose if I write down uh few words over here let's say 2 4 6 can you predict what is going to be the next alphabet or next character I'm going to write over here of course you can predict that I'm going to write eight why because by looking at this you understood that this makes the next logic sequential sound move and this is what we need to do in terms of technical interviews as well that depending on the problem statement we should get some idea that hey in this type of scenario it would make sense to use a data structure like an array and in the array we are going to apply maybe sorting and then with the Sorting we are maybe going to apply uh binary search and this would yield us the correct result but we need to understand this type of pattern and this can only be done if we examine many questions of a similar type and then understand or refer meaning to that so combination of algorithms and coding patterns are closely related with each other and you do that in tandem with data structures and that's it these are the three building blocks for any efficient data structure algorithm technical interview and uh we are going to take care of it so these are all the different techniques that we are going to cover so first of all we are going to cover the searching algorithm and sorting algorithm then one of my favorite topics that is dynamic programming and recursion so after that we are going to see bunch of different tree and graph algorithms and these are really popular because there are some very practical real life applications completely built upon the concepts of tree and graph algorithms then we we will see some greedy algorithms and backtracking techniques and in the end we would start talking about the divide and conquer sliding window two pointers and interval coding patterns so this would cover most of the topics that you can think of for any technical interview and once you understand this you would essentially able to master all the problems that you are facing so without any further Ado let's just get started and uh for each and every concept I will explain the concept first then I'll show you either one or two examples depending on how complex the problem is and we will solve that problem before moving forward to the next one so completing this would be one of the most important key factors for this uh course so first let's try to understand the searching algorithm Now searching algorithms are pretty common across data structure and algorithm related problems because at any given moment we need to find some elements from a variety of data structures and these data structures can be an array or something like a St or a CU and it on top of it there can be some other more complicated data structures uh maybe something like a hash or a tree or a graph so essentially for any given data structure you might be asked to search some data from that and typically we follow two main techniques so number one technique is a linear search and linear search is uh as the name suggest it's quite simple essentially you jump from one node to another node to another node until you find the element that you are looking for and the moment you find the element you simply return that search element so if we have to understand it with an example suppose we are given an array and inside our array the values are randomly jumbled up something like 4 3 1 7 and 8 now I ask you that hey go ahead and search for Value number eight the approach is going to be that we are going to jump through all of these values until we reach to Value number eight and the moment we reach we can say that okay this eight is located at index number number four or on the fifth position or we can simply say that yes eight is present currently in this array in either case linear search would work just fine and if we see time complexity for a linear search it's typically going to be biger of n usually whenever you are dealing with data structures like link list or even Q or stack typically you are going to deal on the linear search basis because that is the only way you can access data uh and if there are some additional versions of maybe Q something like a Min Heap or Max Heap in that case you can actually find the value you are looking for in little bit simpler manner but still essentially linear search you are always going to encounter uh in whatever you are trying to do next example uh for a searching is actually a binary search and binary search is quite powerful but it has some predefined condition associated with that and that condition is that whenever you are trying to use a binary search the condition is that the data set has to be sorted so it needs to be either a sorted array or let's say a binary search tree something like that where you can actually apply the concept or the principle of binary search and principle is actually quite simple say for an example we are given bunch of different elements over here uh and they are all sorted in a particular fashion so 1 3 11 15 19 and 27 these are the values we are currently present let me just add one more element somewhere so value number four okay so currently we are given Seven Elements inside this array now I ask you that for this array can you go ahead and find me value number 15 what would be your approach well of course you always have the option to go linearly and search for each and every value individually till you find the value you are looking for but since this is already a sorted property it makes sense to use the binary search approach where first we are going to find the middle element the middle element in this case is going to be value number 11 now we know that since this array is sorted we are guaranteed that if 15 exist it has to exist within this portion and there it it is not possible that it lies within these values so we can essentially get rid of all of these inputs and only focus our effort for this remaining portion now once again for this remaining portion again we will try to find the middle pointer and middle pointer in this case is going to be 19 which means once again again we can eliminate these two values because all the values are going to be either 19 or greater than 19 and in either case it is not going to be 15 so we are only left with one element in this case and that is value number 15 we which we can return so only in three itations we were able to find the our answer we are looking for in an array of uh seven total elements basically the binary search actually operates in bigo of log n time and this logarithmic time complexity is what makes it viable so this is what how you can understand searching algorithm and you are going to see them quite a lot in lot of different problems you are trying to solve now before we start understanding the example for searching algorithm let's try to understand sorting first and then combination of searching and sorting would would be what we would use to understand one of the actual data structure and algorithm Rel related examples so let's try to understand sorting first now sorting as the name suggest uh it is the procedure to sort all the given data in some particular fashion it could be whether all the data you are trying to sort in an increasing order or reverse could be true that you are trying to sort everything in the decreasing order or you are trying to sort everything based on the colors that you are provided or the names or alphabets in either case you are trying to bring an ordered list and sorting can apply to most of the data uh most of the data structures like arrays and uh link list and trees and graphs but mostly you are going to typically use it on the arrays that's what I have observed by solving bunch of different problems so even to understand the Sorting let's try to see some examples from array suppose we are given an unsorted array and the values currently are 2 3 1 7 and 8 okay now in this unsorted array if we trying to sort it how can we do it well actually sort there are multiple techniques we can use in order to sort the data and one of the in inefficient approach is actually something called bubble sort now bubble sort is typically where you compare any two elements and try to see that whether those two elements are in correct order or not and if they're not you swap those two elements and then go to the next element and you keep on repeating this process until all the elements are sorted so so if we have to see that in example we can see something like this where we okay we check two and three they are already in the correct order so we will leave them for now then we will compare 3 to 1 So currently 3 1 is not in correct order so we will bring one over here and three over here and leave 7 and 8 as it is now once again we would compare these two elements So currently one and two are not in correct order so we will add one over here two over here three over here and then seven and 8 once again we would repeat the same procedure so one and two are correct order two and three are correct order and three and seven are Cor in correct order and same same goes for seven and 8 so in this case all the elements are now in correct order which means we can return this as sorted array and uh we use the bubble sort method but the issue with the bubble sort method is that it takes big of n Square time because it could be possible that for every single element you need to keep on uh Shifting the places and that could be pretty bad so one better approach is actually something called uh M sort or there is also a quick sort so let me give you the better faster sorting approach once again let's assume that we are given some random array and we are trying to sort this now we only have four elements so a better approach is that we actually create an entirely new array and currently this new array is blank so what we would do is we would add all the values in the sorted Manner and whenever we have to identify that where any new value should go we would use binary search in order to find the correct location for that place to be entered and we all know that binary search operates in log and time so essentially our code should run in N log and time why because we will have to do the log and operation for every single element that is currently present inside our given input array So currently let's try to see for Value number one so currently this is empty so we will add one just anywhere now five for five we can we need to check that where five needs to added and five is greater than one so it has to be added on the right side of one so we will add five over here once again for Value number two uh let's see where it needs to be added now since 2 is greater than 1 it needs to be added on the right side of one but it needs to be added on the left side of five and this we can calculate quite easily using binary search that which should be the correct position for two to be entered so in this case we can enter two over here and then five we can shift on one position to the right and this whole operation would take logarithmic of end time once again for Value number eight we will repeat the same procedure and we can find that uh the ideal place for eight is going to be here on the very end and in the end we would get our sorted array now this sorted portion looks quite good and we were able to achieve this whole thing in N log n time which is quite nice so whenever you are trying to deal with uh any operations try to see that can you use searching and sorting to solve this problem and combination of these two would ultimately yield you better results because if you can do any operation on an unsorted array for bigo of n Square time then same operation can be done using n log and time uh if you just simply sort this that given input array so that is a huge Advantage now let's try to see one real example from a problems uh with from the lead code okay so now let's try to understand this problem that is how many numbers are smaller than the current number the problem is really easy to understand uh we are given an input array and we need to create another array where for every single position inside the original array we need to determine that how many number of elements are smaller than that particular value so in this case for four we can see that there are actually two elements that are smaller than four so in the answer we are going to mark two same way for three there is only one element that is smaller than three so we are going to mark one for five there are actually three elements smaller than five so we are going to mark three as the answer and zero is the smallest element so in this case we can Mark there are zero elements that are smaller than zero and this would be the answer we need to return now this is actually quite simple to understand let's see that what would be the Brute Force approach to solve this problem well in The Brute Force approach the most simplest thing we can do is that rather than uh doing anything else we can simply start checking one element one by one so we first make a pair from four to three and we check okay that this is smaller so we increment the value by one once again we make a pair of four to five We compare these two value since five is bigger we don't do anything then we check one more time and then since 0 is less than four so once again we add one more increment and the answer we store in the answer that for zero there are two elements that are smaller than that and we keep on repeating the same process so this Pro Force approach would yield as the solution in bigo of n Square time because for every single n element we are doing n minus one work so this is not really good so let's try to see that what should be the better approach and one of a very easy approaches that actually if we take the same input as it is but we if we sort that input then the answer is going to become quite easy so the answer is 4 3 5 and 0 now in this case we need to return that how many many number are smaller than that so first let's see that what does a sorted array looks like and in this case it's going to be0 3 4 and 5 now at any given position in the sorted array defines that how many values are actually smaller than that so in the case of zero there are actually zero values smaller than that same way for the case of three there is one value smaller than that and that value is zero for four there are two values smaller than that and that is two and for five all three values are zero so we can use this property to calculate that uh or to generate this array but how we need to do that uh we actually need to know the index location for all of these and then Mark appropriate value so for four we need to enter answer two but we there is one simple way to do it that is that uh for four we first iterate over this given sorted are and find the value and then again repeat the same work but that would be an additional overhead a better approach is to use a hashmap here so after we generate the sorted array we can put all of its values as keys and all the index positions as values inside the hashmap and then uh we can use that property to to populate our answer quite easily so in this case 0 is going to have zero value three as key is going to have value number one four S key is going to have value number two and five s key is going to value number three now all we need to do is from our example array let me get rid of this for now and now all we need to do is from our example array we will first iterate over this value number four try to see that which is the value associated with this value number four create an answer array and in the answer array just Mark that value same way for Value number three again check in the hash map and the associated value is value number one again for five Associated value is value number three and for 0 Associated value is zero and this would give us the correct answer we are looking for in the simplest manner so now let's see that what is going to be the time and space complexity in this case the time complexity is going to be big of n log n in order to generate the sorted algorithm or sorted array plus we have to do big of n work in order to generate this answer from this example by comparing this hashmap so that is pretty good so overall time complexity is going to be big of n log n now let's see that what is going to be the space complexity well of course since we are using an additional hashmap the space complexity is going to be bigger of n but that is still reasonable because we are saving uh quite some computation in the time complexity so now you must understand that how we are actually using sorting and then we are using searching plus we are using the capabilities of hashmap and everything is connected with arrays in order to generate one answer and this is is how typically data structure and algorithm related videos or uh problems are done so now let's see the coding solution okay so let's see that what is going to be the Java solution for this problem basically we are given an integer array called nums so first thing we are going to do is we are going to create another array and we are going to uh sort it so this is the sorted array and now we are going to create a hash map uh where inside this hash map we are going to Mark the indexes values for all the elements that we have in the sorted array so it becomes really easy for us to navigate and generate the results for our original array then all we need to do is initialize another array where we are going to store the results plus we are going to run a for loop on the original input array and we are going to uh check that what is the result from the hashmap for that particular uh key value and uh we populate the values inside our result array and we get the answer let's try to run this code and our code runs pretty efficiently so let's submit this code and our code runs actually very fast compared to lot of other Solutions so this how you can understand what are the powers of sorting storing and hashing and combine combining lot of data structures and to generate a solution now we will try to understand a very important topic that is called recursion recursion is highly used in many of the data structure and algorithm related problems plus there are many algorithms and many programming techniques that are heavily dependent on recursion to solve the problem so recursion is actually a method that we can typically use uh in order to complete any set of task where we usually see some sort of repeative work that needs to be done for a various set of uh different inputs and essentially we need to collect the results of the them to generate an answer now let me explain you recursion by a real life scenario first and then we will talk about what it is it and how do we actually use it in our typical technical interviews say for an example you are currently standing on a line and you don't know that how many number of people are currently in front of you so all you can see is that there are bunch of different people ahead of you but you have no idea and currently this is the person who is the very first person in the line now you decide that you want to check that what is your position inside the current line so the one approach is that you get out of the line and then you start counting all the people that are in between and then you try to come back to the line but there are more people behind you so if you get out you will essentially lose your place so there is one more way when you can identify that what is your current position that is that first you ask the person ahead of you that hey what is your position now again the person ahead of you also has no idea so he repeats the same position that hey what is your position and this question keeps going on and on and on until we reach to the very first person and because this very first person already knows what is his or her position is this person would say that hey my position is one which means this person would understand that his position has to be second second position so then he would respond back to the person behind him and this person would understand that his position is now the third position same with this person will conclude that his position must be fourth position because this person is at third position and same with this person is at fifth position and he tells you that hey I am on the fifth position which means you can conclude that your position has to be the sixth position in the current line now what you essentially did is you made a recursive call and you get the desired answer you were looking for and you ask the same question to a different set of input results until you f reached to a place who knew the answer and depending on that answer you started building all the other answers and that's it that's the recursion now I know at first it seems complicated to comprehend but if you try to understand with real life examples things would become much more easier let me give you one analogy that how it typically appears have you ever seen those Russian dolls that uh whenever you open one doll and then uh inside that doll there is another doll hanging and inside that there is another doll and it keeps on happening over and over for all the different shapes of dolls so the same concept applies for the recursion as well that behind any big problem or behind solution of any big problem lies the solution of a smaller problem plus plus some computation same way for even for that smaller problem there lies some other computation and same goes on and on until we reach to a base case where in the base case we directly know that what is going to be the solution for that particular case and apart from that from that we would build this solution and then we would build the other solution and we would keep on repeating the process again and again and again let's try to see that what are the things or areas of concern for us in any particular recurs so every single recursion has two items first item is that uh recursive function and this recursive the purpose of this recursive function is to call the next sequence or next input in line in order to get the answer so first one is a recursive function and second one is a base case so base case is a scenario where we know that this has to be the answer or this has to be the minimum answer now uh again going back to to our uh people standing in a q position the person standing very at the very first po position in the line knew that he was the first person in the line and this was basically our base case now our what was our recursive function in this case in our recursive function the case was to ask the next person that hey what is your position and keep on asking that to the next person and the moment we get an answer from the base case we need to return to the previous person that hey whatever the answer we get from the next element or the base case we need to add one to that so here base case would say that hey I'm first person so this person would say back to the back to his previous person so person who called originally this person he would respond back saying that hey I second I'm in second position same way this person would say I'm third position and so on and so forth the recursive call would keep on coming back until we reached to a point who originally called or initiated that recursive call recursions are very powerful and they are used in bunch of different data structures in many programming techniques data structures such as uh typical tree or graphs plus programming techniques like dynamic programming and also many of the Matrix manipulation all of this are heavily using recursion to solve their uh problem because typically in all of these problems we need to do the same computation again and again for different set of inputs and whenever we see things like that we have to try to see that can we solve this problem using recursion now there is also one more thing that you need to understand that any problem you can solve recursively you can also say solve the same problem iterative iteratively but the question is recursive solution is going to be typically very simple to implement so you can think of it like a simple manner just like asking a question again going back to our people standing in the line scenario you could have gone out of the line and calculated all of these values one by one by yourself but why did you decide it not to do and you just decided to ask to the next person because repetitively you can ask this question again and again and you can expect to get an answer coming back in return so that is how if you would have gone out and calculated all of this by yourself it would have been an iterative approach and if you would have stood in the line and waited for the result come back to you it would be recursive approach but there is a key difference between iterative and recursive that in the iterative approach memory is not being used that much why because in this case you are the only person calculating that how many number of people are there currently present in the line and then they can you can infer the result that you're looking for but in our recursive approach we are dependent on every single person to know that what is the position of other person and then adding one line to it and sending back the results which means we are actually creating a memory stack where we are keeping track of all the memories that actually called us back so all the places where we called we are placing their uh line in the stack and when we get the result we fetch these values out one by one because remember the property of a stack is last and first out so we get these values out and then we in the end conclude the answer so whenever you're dealing with recursion make sure that uh memory usage is not so significant that you actually end up in uh stack Overflow issue now let's try to understand a program programming uh example for recursion and that is something called a Fibonacci series now we all know what a Fibonacci series is Fibonacci series is basically the sum of two numbers now let me give an example initially so let's say that first value of Fibonacci series is Fibonacci of zero so that is going to be the value number zero second is Fibonacci of 1 Fibonacci of one is going to be value number one now if we have to calculate Fibonacci of 2 we will actually have to do the sum of these two values and that will give us the answer of fibon 2 so Fibonacci of 2 is actually Fibonacci of 0 plus Fibonacci of 1 so the answer is going to be 1 once again Fibonacci of 3 is actually the sum of previous two elements so Fibonacci of 2 plus fibon Fibonacci of 1 so the answer answer is once again going to be value number two same way Fibonacci of 4 is sum of previous two elements so Fibonacci of 3 plus Fibonacci of 2 and the answer is going to be value number three and this keeps on going on and on until whatever the value we are trying to find we get the answer so now in this case this is a very good candidate if you want to implement the solution recursively and how would the recursive function would work well we know that for recursion we need two things we need our base case and base case is lying right in front of our eyes that is that uh the Fibonacci of 0o is zero and Fibonacci of 1 is 1 now we need a recursive function and recursive function is also in place that fibon of any number is actually Fibonacci of number minus one plus Fibonacci of number minus 2 and you can apply it to anywhere so Fibonacci of 2 is going to be Fibonacci of Z or Fibonacci of 1 same way Fibonacci of 3 is going to be sum of Fibonacci of 2 and ion of 1 so this function applies which means we got our recursive function and we also got our base case so now to calculate any result is going to be very easy for us okay so let's say that I'm trying to find the Fibonacci numbers and I try to find the Fibonacci number of Fibonacci value number four so first let's see that what is going to be the recursive approach well first of all in the recursive approach we know that what is the recursive function for Fibonacci of 4 recursive function is Fibonacci of 3 plus Fibonacci of 2 now we all know that what is the answer for Fibonacci of 3 that is Fibonacci of 2 plus Fibonacci of 1 now we know the value of Fibonacci of 1 but we do not know the value of Fibonacci of 2 so once again even in order to get this value we are going to do Fibonacci of 1 plus Fibonacci of 0 and we know these two values so sum of these two values is going to be 1 + 0 so the value is going to be 1 so this is going to return us the answer as one so we get the value of one so in this case currently the Fibonacci of 2 is going to be of value number one and Fibonacci of 1 is already value number one so 1 + 1 is going to yield us the result of three now we got the answer three in this case now for Fibonacci of two we again need to do the same computation and that is Fibonacci of 1 plus Fibonacci of 0o now we don't know we already know the values of fibon 1 and Fibonacci of zero and that is going to be some is equal to 1 so this is also going to be one so in this case currently the value of Fibonacci of three is going to be okay this is not going to be three this is going to be two I think I Mis wrote this this is going to be two so Fibonacci of three is going to be two and Fibonacci of 2 is going to be 1 so the answer for Fibonacci of 4 is going to be three okay so we got the recursive answer now you see what you did what we did in this case we took the larger case and then we started breaking down into the smaller pieces and even for those smaller pieces we started breaking down into sub smaller pieces until we reach to a point where we are at the base case and through the base case we found the solution we return those solution to our previous calls and then we kept on repeating the process until we find to the main value we were looking for now what are the things we had to take care of we had to take care of base case we had to take care of the recursive function and we had to take care of the memory call back because this function is calling back to Fibonacci of 2 this function is calling back to Fibonacci of 3 same way this function is calling back to Fibonacci of 2 and we are getting the answer but at least as long as we are getting the answer now for the same problem let's try to do it iteratively so in the iteratively we are trying to find Fibonacci of 4 so obviously The Logical approaches that we are going to start with Fibonacci of 0 and Fibonacci of 0 is already Zer Fibonacci of 1 is already 1 now we are going to calculate Fibonacci of 2 that is going to be sum of 0 + 1 so that is going to be 1 okay so this Fibonacci of 3 is going to be value two and then we can calculate Fibonacci of four that is going to be value three and we will also get the same answer now in this case in the iterative approach we started from the bottom and reach all the way to the value we were looking for in the recursive approach we started from the value we were looking for started asking and went to the base case and then came back again for the previous case so this is one common way to implement recursion now you are going to see quite a lot of examples whenever you are trying to prepare for any technical interviews because recursion are one of the most commonly widely used programming techniques now we are going to learn the most important topic inside the Entire Computer Science in my opinion and specifically for the technical interviews because if you are applying for any Tech interview for sure you are going to be asked some questions related to dynamic programming so let's first understand that what dynamic programming is what are the different variations associated with that and then we are going to explore bunch of different examples so you can get the complete idea on how dynamic programming Works basically dynamic programming is nothing but the art of saving the data that we have already computed and then reuse that data for some future computation that's it uh now let's try to understand this with an example suppose we have a map like this where we are given bunch of different places or points and we we we are trying to go from one city to another city now in this case currently we have all of these variations and we are trying to get to a city number F now uh each of this path we can assume that they are let's say 1 km long on top of this from a we have some path directly leading to seat that is also 1 km long and from C we have one path that that is directly leading to e and that is also 1 km long and now the aim is to get to City number f Now The Logical conclusion is that most common bro Force approach would be that we start from City number a and we explore every single path and for each of the path we calculated that how much kilometers or how many kilometers did it took so we would first calculate a result for a path like this then we would calculate a result for a path like this this this and this and then in the end we would calculate the result for a path like this and we would find the answer but the question is uh is this the most approp rate approach to reach over here because we are repeating so many competitions here we already calculated for this portion and this portion and we are actually calculating it two times uh in order to generate the result one better approach is that we actually use dynamic programming to store the already calculated path and how we are going to do it typically in dynamic programming there are two approaches first approach is a bottom up approach where you start from the base case or the very first case and try to build a solution that would eventually lead us to the final result we are trying to get to so that is one way second approach is a top down approach where in the top down approach you start at the very end or at the very top and then you build smaller and smaller Solutions and try to come up or try to reach to the first point and then try to build a path in this manner now of course both of this are going to look quite similar uh compared in regards to the previous example we C for recursion because the top down approach is actually used by done by doing recurs recursive calculation and bottom up approach is typically done by using an iterative solution where we are storing the data of all the things calculated and that is a common factor we are going to store the result of already calculating calculated the data and we are going to use it for our next computation so let's try to see an example in this case the approach I am suggesting is that we start from F in this case and we try to go in the reverse order to find the best path suited path so the question is in order to get to the F what is the nearest point that leads us to Value number F and that is going to be value number e that say somehow if we get to Value number e we can reach to F in just 1 km so we can say that distance from E to F is going to be 1 one okay that's good now uh in order to get to e what are different options we have so first let's explore all of them so let's say that we are currently at position number D if we are at D we if we need to get to F we have this path where we are going to go from D to e and then e to F so in this case if you are if we are at D do we need to calculate this whole path from going to e and then again going from E to F no why because we already know that that once we get to e we can directly go to F with this effort so we are going to save our computation and we are only going to calculate that okay from D if I get to e using one e using one step then from E to F distance is already one so I can say that from d i if I take two jumps or if I go travel 2 kilm I can go to the value F that's awesome now once again let's repeat the same computation now we are at position position number c so from C how many options we have one option we have is that from C if we go to D we already know that from D to F is already 2 km so and from C to D it takes us 1 km so if we were to take this path from C to D then we don't care how many number of hops it has to take all we consider is that from C to D if we go there then within 3 km we would be able to reach to our final destination F so in this scenario we are not even going to bother checking for this path from E to F we are only consider the path between C to D and which is the true power of dynamic programming so now in this case we are actually we can say that from C if we take 3 km we would be able to get to D but at C we have one more option and that option is that if somehow we can go from C to e then at location e we can only travel 1 km and get to F so in this case now at C we have a path from C to D that takes us uh 3 km time and we have a path from C to e that takes us 2 km time and we are trying to find the minimum uh time it takes or minimum travel it takes to get to e so we can see that at C if we somehow end up at position number c then we can actually reach to F within 2 km so we are going to Mark the value of C S2 and then we are going to repeat the same process so now from B if we somehow end up at C we would be able to get to F within 2 km and from B to C it takes 1 km to get there so we can see that at B it takes 3 km to get to F same way from a if we go to B it takes us 3 km plus 1 km so 4 km to get there but if we from a go to C then it only takes 3 km so we can say that the minimum amount of time it takes from us to go from a to F would be 3 km and this is how we build the solution by already calculating the previously computed results and in this case we actually use a top down approach where we started from the top and we kept going in the reverse order and we can actually have a recursive function call to find the solution in the recursive function the base case is going to be that if we are located at position number e it only takes us 1 km to get there and then uh the solution would be that we need to check that how can we get to that next location in the minimum amount of hop so that's pretty awesome actually now let's see some other examples on how would a dynamic programming would work now previous example we saw that how does a recursive function work for a Fibonacci numbers now once again we are going to use the same Fibonacci numbers but this time we are going to use dynamic programming to solve the problem so let's see that in action in the previously recursive operation we had the example that if we wanted to calculate the the result of Fibonacci number five then what we would do first we would calculate the number of four plus uh Fibonacci number three same way for four we would calculate the number phys Fibonacci of 3 plus Fibonacci of 2 and plus over here we would do Fibonacci of 2 plus Fibonacci of 1 same way over here we would do Fibonacci of 1 plus Fibonacci of 2 and here we would do Fibonacci of 1 plus Fibonacci of 0 in order to calculate this value and in this case we will do Fibonacci of 1 plus Fibonacci of 0 in order to calculate this Fibonacci of 2 and Fibonacci of 1 we already know the value as 1 because this is a base case now see how many times we are repeating the same computation over here we are calculating the value of Fibonacci of 1 plus fibon of 2 in order to generate the answer same computation we are doing here as well Plus here we are calculating Fibonacci of 1 plus Fibonacci of 0 same way we are doing it for Fibonacci of 1 and Fibonacci of 0 so in both the cases rather than doing all of this computation what we can do is we can actually create an array and inside the array we are going to store the results that we have already calculated now we know that for our base case it's fibon of Z so let me mark down the value 0 1 2 3 and four for all of this and let me make one node for five as well okay now we all know that the values for 0 is actually going to be 0er and 1 is going to be one these two values are already calculated now let's start Cal start let's start our recursive function so first we start with four four and three now in order to do that we need to calculate these two values now we need to calculate this two value so this would be the first case we would be able to calculate where we need to calculate the value for Fibonacci of 2 so we already know what is Fibonacci of 1 and Fibonacci of 0o and this is going to be value number one so we can do that that we can put Fibonacci of 2 as value number one okay now for Fibonacci of 2 we need to do Fibonacci of 2 plus Fibonacci of 1 that is going to give us the result for Fibonacci of 3 and that would be value number two okay now we are done with this portion and this whole computation now let's do computation for Fibonacci of 4 so in order to calculate Fibonacci of 4 we actually had to do all of these three calculations but in this case we don't have to do it why because at Fibonacci of 4 we need to get the answer of Fibonacci of 3 which we have already computed and Fibonacci of 2 which we have already computed as well so we can just say that this value is going to be three and based on that the value of Fibonacci of five is going to be some of these two values and we can just mark it as five so see how storing all of these values actually saved us lot of time and imagine that if we were not using dynamic programming so if we are not using dynamic programming then the time complexity would be big go of 2 to the power n because at every single position we are doing two more computation and same way for every single computation we are doing two more another computation so that is a very bad time complexity meanwhile in this approach we can actually complete this whole transaction and B go of uh and time only that we are only traversing and we are only doing the all the entire transformation just once and generating the result so that is pretty quick and pretty efficient approach and this I showed you the example of top down approach now let me show you the same for the same example bottom up approach now in the bottom up approach once again let me just draw an array with all the values I have currently calculated so 0 1 2 3 and 4 okay and uh the values are going to be 0 and 1 these are my base cases now I'm trying to calculate the value for Fibonacci of 2 so Fibonacci of 2 I can easy easily calculate using these two values as value number one and in the bottom up we are actually using the iterative solution so we are doing it iteratively okay now same way for the third value we can do some of these two value get the answer fourth value once again do the sum of these two values get the answer and same way for Fibonacci of five do the sum of these two values and get the answer as five and return this in the answer once again pretty awesomely and pretty simply we were able to solve the entire computation now you must be thinking that this is a very simple scenario for dynamic programming and yes this is a very simple scenario so let me give you a more complex task and that is actually uh that we need to calculate the number of coins problem okay so what does number of coins problem suggest is that we are given a value and let's say that this value is uh currently value number eight okay and we are given some coins so in this case let's assume that the coins we are currently given are 1 and two now we are told that we can use as many number of coins as we want in order to reach or build value number eight but the catch is that we need to use the minimum number of coins so in this case the answer is going to be if we use 4 * 2 Coins we would get the value eight so the minimum number of coins we need to use in this case is going to be four but how do we actually calculate this so for this let me show you a bottom up approach and same would be true for the top down approach as well so I'm just showing it to you from the bottom of approach let me just quickly draw an array where we are going going to store the value for all the items we are calculating and initially our case is going to be zero that if we want to generate zero value how do we do that so let's say and for at each position we are going to calculate the possibility that what if we use coin with value one uh what how many number of coins would we use if we have to use coin number two how many number of coins would we use okay so both scenarios we are using and uh let's mark all of these values so 0 1 2 2 3 4 5 6 uh 7 and 8 okay now for zero we know that we need to use zero coins so let's just mark this as zero now if we have to generate value number one uh how many number of coins do we need currently previous results we can't get much information from because it is uh for the zero value now we have two coins available to us the coin if we use coin number one we can create one within just one coin okay so that is one option and and second option is if we use coin number two but that we cannot use to generate value one so we have to use one coin in order to generate value one and that one coin is going to be the simple coin one that we use I'm just marking white color as the the coin we use now same way in order to generate two what are the options we have we already know that currently let's say this coin is one coin number one so now our aim is to generate value number two but if we use one coin number one then we can already know that if we do 2 1 so whatever value we have stored on top of that if we just add one more coin over here that is this coin number one we would be able to generate this value too you will understand what I'm trying to say but let me just write it down for now so in this case if I use two coins with value number one then I can generate the value two so two would be minimum number of coins we have calculated so far but we also have the option for coin number two so if we take for check for coin number two two is actually the exact value so if we just use one single coin of value two we can generate the amount two so in this case the minimum number of coins we need to generate is going to be value number one and the coin we are using is going to be value number two okay now let's say that we need to generate value number three now once again the number of option we have for the coins is going to be 1 and two so let's redo the same calculation again now if we use coin number one which means if we are let's say somehow we are at this previous position two and then we use coin number one we would be able to generate value number three quite easily that's a given fact and we already know that in order to generate value number two we only need to use one coin and that is the true power of dynamic programming that we are using the value we have already calculated over here so in this case if we use coin number one plus the dynamic programming value of coin number two and how did we arrive at this coin number two we did a subtraction from the current coin we are trying to calculate that is this coin number three minus the coin value we are currently using that is value number one so we can make a dynamic programming function that would be that dynamic programming of let's say this one is currently value number three is equal to going to be the so first condition we have is that we can actually use dynamic programming of three minus coin that currently we are using and in this case coin is 1 so we can say dynamic programming of 3 minus 1 and if we use that then we will also have to use the current coin we have and that coin only takes one value one coin only adds one coin to the previous coins so this would be one consideration and second consideration would be the next option with value number two but currently in both the cases the number of coins are going to be two so I'm just marking coins to be two and you have two options over here you can either pick coin as one and two or you can pick coins as two and one in either case you will be picking two coins in order to generate value number three and we don't care about what coins we pick we only care that what are the minimum number of coins we need to generate that value now we are at position number four okay now let's again apply the same logic to our dynamic programming function and let's see that what are the options we have so So currently we are considering value to be one so coin we are choosing is one okay if we and we are trying to calculate for dynamic programming for Value number 4 so first option is that we do 4 Min 1 so 4 1 is going to be dynamic programming of three dynamic programming of three is already know that the minimum value is 2 so that is going to be 2 + 1 so we have the option of choosing three coins in order to generate value number four but we have another option where we can use coin number two as well so let's try to do that so again the second option is that we do dynamic programming of 4 2 + 1 because we are using the the coin with value two so in this case uh we know that we need to generate dynamic programming of two so dynamic programming of two's result we have already stored and that is one so second comparison is that 2 + 1 so these are the two comparisons we have and we need to find the minimum value amongst both of this so this would lead us the value of d dynamic programming of four or the number of coins needed to generate value four so first option is three and second option is actually uh three as well sorry second option is actually two because the value of dynamic programming of two is actually one so in this case we are going to mark this as two so among these two of course two is smaller so we are going to mark two over here and the coins we took to generate is going to be 2 and two same way for for Value number five what are the options we have we can if we subtract one value so then uh if we use coin number one then we can generate this in three coins if we subtract or if we use coin number two then 5 3 is going to be 2 so 2 + 1 is also going to be three so we this three is going to remain constant here same way in order to generate value number six if we use coin number one then we can use 3 + 1 so one option we have is four second option is that we can come up up to Value number four and then use one coin to reach to six and the value over here is two so we have two options to choose from that is four and three so we can actually choose the value number uh three in this case okay cool now after calculating this at 7 we again have two options we can either use coin number one or coin number two in either case the answer is going to be four so we can mark four over here now at this position number eight we actually we can actually check that if we use one coin like coin with value 1 then we need to do dynamic programming of 7 + 1 so that gives us the result of five second option is if we use coin number two then we need to do dynamic programming of 2 + 1 so uh sorry not dynamic programming of two dynamic programming of 6+ 1 so in this case that is going to give us the result of four since we we are picking the minimum value we only need to pick the value S4 and that's it we got the answer that it takes 4 minutes minimum coins to generate value number eight if the given coins are uh 1 and two so you see how beautifully we we were able to solve this problem in just one single go because we were calculating all the results we have calculated so far and that is the true power of dynamic programming in my opinion so now let's try to do a really popular lead code problem that has been asked in tons tons of interviews many times and you can see how popular It Is by number of people who have liked this video so basically uh you are you are being asked to climb a staircase now you it takes end steps to reach to the top you are given the value of n now we have the option of either climbing one step at a time or climbing two steps at a time now in either case we need to calculate that how many distinct ways can we climb to the top now for this problem I'm going to show you both top down approach and also bottom of approach and in the code we will see the solution for the bottom of approach okay that Mak makes sense so first let's try to understand the problem with a few simple statements so let's say that if you are currently standing at stair number zero how many steps does it takes of course zero that's a given fact let's say now you currently have one steps available and you are currently standing at position zero and you need to get to step number one how many distinct ways can you get there of course one distinct way because you can only take one step let's take one more example uh currently the number of steps given are two and you are standing at step number zero now how many distinct ways can you get to to Value number two once again you have the option to taking one step over here and then one step over here so that is one way and second way is you can take two steps directly to get to Value number two so there are two distinct ways you can get to Top Just One Last example that is for Value number three okay that let's say that you want to get to the step number three you are at zero and you have the option of 1 2 and three so now how many distinct ways can you go first distinct way is just taking one step each time so this would be way number one second distinct way is that we take two steps directly and then take one step so this would be second step and third step is that we take one step and then we take two steps directly so there are three distinct ways to climb to the top uh for Value number three but now if you notice some interesting property the interesting property is we already know that if we have just one step we need to climb there are only one ways we can do it if we want to climb two steps there are at Max Two Steps we can do it the moment we wanted to calculate that how many times what are the distinct ways we can climb to the top we don't even have to calculate all the values why because in order to reach to three there are only two possibilities first possibility is that we start from value number two and then take one step so that would be one way and second POS possibility would be that we start from value number one and then take two steps basically this would be second possibility now you must be asking that hey what if we take one step to get here still it is still going to be counted towards this distinct step so all we care about is that how many different ways can we get to this value and how many different ways can we get to this value some of these two would allow us to find the next value in our path and this is the important property for dynamic programming that we need so let's try to understand this with an example that in this case for in order to climb to step number three we have two options that we can climb from one is from Step number two and one is from Step number one so if we do sum of these two we can get the value 1 + 2 is equal to 3 now let's try to understand the same logic for five steps okay and now for five steps I'm actually drawing it on an array uh and starting from value zero we will go to all the way to five and see that how each iteration how many changes it takes for us to to get to the value number five okay now in this case uh currently we are using the bottom up approach we are starting from the bottom and then we are going up so initially this takes zero steps this takes one step and this takes two step that's a that's a given fact now in order to climb to step number three we can either take one jump from here or we can take one jump directly from here so we are going to do some of these two so the answer is going to be three once again from 3 to 4 it only has two possibilities one step from here or two steps directly from here so once again we are going to do some of these two the answer is going to be five now in order to reach to step number five we only need to do the sum of these two values and that is eight and eight are the distinct ways we can reach to Value number five see how easy it became in if we if you were to do this in the Brute Force manner you would actually have to first create all the different decision trees you can make starting from position number zero so zero now you have uh two options you can either take one jump and go to position number one or you can take two jumps and go to position number two once again you have two more possibilities you can go to position number two or position number three you can once again have two more possibilities you can go to position number three or position number four and once again you have two more possibilities you can go to position number five or position number four or five and here position number five and the moment you reach to the five you can consider that to be an end of the path and just over here you see that these are this is just one path you can take in order to reach to Val number five then this would be a second path this would be third path and so on and so forth if you keep on going on you would be able to find eight distinct paths and if you were to do it in the Brute Force manner without using the dynamic programming the time complexity would have been 2 to the power of n because at every single position we have two different options to choose from and this is a disastrous result so that is why you using dynamic programming was great now you understood that how we use bottom of approach let me show you the result for the top down approach as well where we are going to start from the very top element and we are going to come our way down to the very last element okay so currently the values are 5 4 3 2 1 and zero now we know that if we are at step number five how many distinct ways to get there of course zero because we are already at set step number five we don't have to calculate anything if we are at step number four there is only one distinct way to get to step number five so we are going to mark this as one if we are at step number three there are actually two ways to get to step number five we can take one step over here and then one step over here or we can take one step directly over here so in this case there are two options from now on we can apply the same logic in the reverse order because from Step number two we only have two options that we can choose from we can either go directly to step number three that would be one distinct way and second distinct way would be we can directly go to step number four from there on we already know that how many different ways it takes to get to step number five so we can just use that property so basically from Step number two we can go to three distinct ways and that came from some of these two values same way from value number one we can actually go to five distin distinct Ways by taking the sum of these two values because these are the only two possible jumps we can make and from value number zero we again have eight different ways that we can make this jump and this is our top down approach so see in both the sessions we got the correct answer we used dynamic programming to calculate the already calculated result and then we were able to come up with the appropriate and successful result in the end so now let's see the code for this and I hope you understood what dynamic Pro dynamic programming is and what are its key fundamental reasons so this is the problem statement and here is the Java code for that uh basically we are using bottom up op approach so first we are checking for the edge case that if the given n is equal to 1 we can simply return one if that is not the case we are going to initialize our dynamic programming array and we are going to check out or put down the base case values for uh number of stairs as one and number of stairs as two after that we are going to run a for Loop starting from the step number three all the way to the end and we are going to apply our dynamic programming logic which is quite simple to understand in the end we are simply going to return the dynamic programming value be found at the very end value now let's try to run this code okay seems like our solution is working let's submit this code and our code runs 100% faster than all the other Solutions which is pretty good to see and uh now you can understand that how simple it is to code the dynamic programming solution okay so now let's learn the sliding window technique this is a really popular coding technique and typically works really well with many of the array and string kind of problems now first let's try to understand that what does a sliding window technique means let me give you an example suppose I tell you that you have this rope and currently this rope the entire rope is actually in the color blue now I ask you that I want to change this color from Blue to Pink so how would you do that well you actually have a couple of options to do it number one and most naive approaches that you actually put down a table now on top of this table table you lay down your blue colored uh uh rope and then you start pouring on the pink color all across the table and then eventually entire table is now dripping up with p pink color and some of that paint has already stuck onto the Rope as well and now our rope is actually pink colored so this approach will give you the correct rope color that you want but in this process you would have wasted lot of paint as well so that is not a very good approach a better solution might be that suppose you are given this rope uh I ask you that hey paint this uh in the pink color you take a paint brush and now in this paint brush you apply the color pink for this portion and after applying whatever the current width of the paint brushes you take that width and try to paint that much area pink for now and once that is done you again take your paintbrush replenish it with the pink color and again repeat the same process for for the next set of uh remaining uh rope as well and eventually you would cover all the ground and eventually the whole rope would have been painted blue or sorry pink and that is the most simple example of what a sliding window is where in the longest input we had which was our rope we actually created a small subset of window that we applied on one particular portion of given in input once it achieved our con conclusion or the thing we wanted to compute then we took the same thing to the next area and then we took the same thing to the next area until we reach to the very end and we find the appropriate answer that we were looking for so this can be a very powerful tool in many examples and let's try to understand that with a simple example suppose we are given an input array a where we are given some arbitrary random values okay let's just Mark these values is 1 3 7 uh 2 5 8 and 9 okay these are the values we are currently given now I ask you that find me the maximum sum of three consecutive elements so what you what would be your approach in this case well one approach is that you actually start doing or making every single pair and try to come up with the solution so in that case you first take these three values do it sum then you take these three values do it sum then you take these three values do it sum and so on and so forth and eventually you will find the result or the second option is that you actually create a window of three characters and then keep on incrementing the sum uh and try to find that which has the maximum sum so let's try to use the sliding window technique in this one so suppose I create an element called Max sum that is to keep track of the maximum sum I'm also creating another variable called current sum and this is going to be our window of three elements that we are dealing with so first let's say that we take these three elements so now the sum is current sum is 11 and so far the maximum sum we have been able to find is also 11 okay now we need to check or move our window on the on the side but the window size will remain same so once again we are creating a new window and that new window is going to be starting with value value three okay so let's create another window now the moment we we created new window do we need to calculate the sum of all of these three values well actually no we have a better approach and that better approach is that we can actually take the previous sum we already had that had current value what we did essentially in this one we subtracted one from this window that we got rid of this value and we added two in this case so we can simply do this computation now you must be wondering that this is only three elements so why are we even bothering doing this imagine if this was like 500 elements and this was a very large area of million characters in that case this computation would save you so much time because every time you only have to subtract one element and add another element and that's it you will get the sum of all the consecutive values of those 500 values you don't have to to do much work and iterate over all 500 values to find the result so in this case now this sum is going to be uh 12 so 12 is definitely greater than 11 so we would update our Max variable that currently the maximum sum we have found is going to be 12 okay and we are also going to update our current sum as well to Value number 12 once again we got rid of three and we add value number five in this case so 3 + 5 the answer is going to be 14 once again we update our maximum variable to Value number 14 and same way we update our current variable as well so 14 and 14 and currently we were looking at this uh pair now let's subtract seven and add value number eight so in this case the current sum is going to be 15 which is also the maximum sum we have found so far so we would update that once again let's get rid of value number two and add value number N9 so in this case the sum is going to be 22 and that is the maximum sum and we can update that see how easy it became once we created a simple window and then we iterated or moved all the way over there so this is everything you need to understand about sliding window technique well sliding window is not very TP very difficult to comprehend and let me give you another example okay now this is one of the most popular problem on lead code and has been asked in tons of companies uh basically we are given a simple string s and we need to find the longest substring that does not have any repeating characters so if we see an example example over here in this case we have we are given a bunch of long string but we can see that first a b c is the longest string that does not have any repeating characters and its length is three so we are going to return three as the answer because apart from that all the other places actually has repeating character so the window is not large enough okay so now let's try to see that how would we solve this problem suppose we are given a problem like this that uh a b a c d a something like this this okay we are given this as the input and we are trying to find the longest substring without repeating characters so of course we are going to use sliding window in this on top of that we will also have to use some additional data structure to keep track of all the values we currently have in our existing window so for that uh hash map or hash set is actually great so we will use hash set because we don't need to have indexing in this place but we only need to know that what are the elements currently present inside our existing window okay so let me just quickly draw our hash set and now the approach is that we are going to have two pointers so first pointer is going to be left pointer second pointer is going to be right pointer initially we are going to keep moving right pointer until the point where we do not encounter any uh repeated characters and we would Mark its length uh as the maximum length we have been able to find so far the moment we encounter a repeated character we are going to take left pointer to move one step to the right right and then keep on repeating the same process and meanwhile we would only move right if the value is not currently present inside the hash set if it is present then we would move the left pointer and uh let's try to see the solution in action okay so first we are both are at the same position and we have our maximum uh substring length that is currently zero and hash set is empty okay so now let's see currently a is not in the hash set so we will add entry a over here and then move right pointer to the next element uh now after doing that now let's see a b are still distinct B is not added so we would add B over here as well and move on to the next element so next element currently is uh a again so because this is a once again okay what is the maximum window we have been able to find so far that was only two characters so we will Mark two two over here as the answer now because we find an identical value we are going to move our left pointer to the right the moment we move left pointer to the right whatever the value we had in the left pointer we are going to delete this so first let me get rid of this value okay now after getting rid of this value uh we we have our R located over here so we will have to add an entry a over here and now currently the window size is still two now let this R go to next element so it will go to next element c c is also unique now let this R go to next element d d is also unique so it can still still stay over here now the next element is once again a a we already have inside the existing hash set which means okay so far the maximum window we have been able to find is of size four so let's mark four over here and once again let's try to update the value so now we are going to move move our left pointer one step to the right okay after moving it one step to the right again remember we haven't added this a yet because it was a duplicated entry okay so we added we removed B from here so we got rid of B from our hash set once again this value is a and once again our right pointer is still stuck over here now this left pointer we got rid of a okay after getting rid of a now we can check that whether right pointer can be added over here or not yes now it can so we will add a over here and now uh we will try to move our right pointer but now it is the end of our list so this is only of size three this uh substring without repeated characters and maximum we have been able to find is four so four is going to be our answer and this is what we are going to return return so now you imagine how we had like a dynamically changing sliding window in this example to solve this problem and we actually use hash set and tandem to solve this problem now U this is quite a simple problem so I'm not going to show the coded solution but I do have the coded solution available on the GitHub link and I'm going to post it in the description so you would be able to check it out from there if you are curious ious now let's move on to the next topic that is called two pointers okay now let's try to understand one of the interesting uh coding pattern that is very similar to sliding window and that is called two pointers now this two pointers is actually really popular with data structures like array and strings and the idea is that just like a sliding window we are going to have two pointers but these two pointers are typically going to be located at the edges of Any Given array and depending on certain scenarios the pointers would come towards each other based on the various scenarios that we have available okay so this is the whole premise now if you want to understand this uh with a real life example you can think about that let's say that you are currently located on a Long Beach and inside this Beach uh you maybe lost something or uh some some of your maybe cousin or child or someone so the idea you are going to use is that you and your wife you both are going to go to different ends of the beach and you would try to come towards each other trying to find the child that whether that child is maybe located somewhere and try to consider that beach is just like a simple line so you are not moving in any other direction So eventually you would be able to find the child who is going to be located somewhere but essentially you and your wife you are going to be coming towards each other and the this is the whole concept of two pointer solution so let's try to understand this with an example okay so let's try to solve this problem squares of a sorted array now this is a very popular problem and also a very simple explanation yet it explains that how we can use two pointers to our maximum Advantage uh basically we are given a nums array and we are told that this array is already sorted in an increasing order now we need to return a new array that contains square of every single element but we need to make sure that this is also in non decreasing or increasing order so assume that suppose we are given an input array like this 1 2 and four this array is currently in increasing order so in the answer we need to return the square that is also going to be 1 4 and 16 and this is the answer we need to return now looking at this example you must be thinking that hey this is quite simple all we need to do is just square of two elements and then we can simply return it as it is but it's not as as simple as it is because we could have an input that looks like this where the values could be Min 8 1 0 and then 1 and then two suppose if this is the array given in this case the answer has to look something like this where the first value is going to be 0o because 0 square is 0 then 1 square is going to be 1 then once again 1 square is also going to be 1 then 2 square is going to be 4 and then 8 square is going to be 16 64 so see this value came over here this value came over here this value came over here so everything got jumbled up because we had some negative values and yet this satisfied the property of being in increasing order and this also became an increasing order so now how do we deal with negative numbers in this scenario so one root force or naive approaches that whatever input we are given suppose the values are 4 2 1 and 3 suppose this is the input value we are given uh one simple approach is that we simply do a square as it is so values like 16 4 1 and 9 and then we do the sort operation on this array so if we do that we will again get the correct answer that is 1 4 9 and 16 but this is going to be done in N log n time so we will try to see that can we do it faster in just log and uh B of end time rather than using log andun function and yes the answer is we can do it plus you already know because we are explaining two pointers for sure we are going to do it using two pointers the idea is we will have our left pointer located on the last location we will have a right pointer located on the rightmost position and then we are going to have our answer Square okay now what we are going to do is it is only possible that if this value is too negative it could either end up somewhere over here here or it could e if it is positive value then it has to end up over here there are only two possibilities so what we are going to do is at every single location we are going to compare the value of this with its right counterart and whichever value is going to be higher we are going to put that in the end and whichever value we put that pointer we would move to the next element and again repeat the same procedure so let's see the solution I'm proposing in ation action so first we'll compare this left with right and we are going to do square of both of them so square of left is going to be 16 and right square is going to be 9 so again left is greater because left is greater first we are going to add value number 16 over here and then we will move our left pointer and once again repeat the same exercise so now this time uh left pointer is located over here okay so now square of two is going to be four and square of three is going to be 9 so because 9 is greater now we are going to put 9 over here once again we are going to move left pointer in this case because we added nine here now this is 1 and this is min 2 so square is going to be four and this is going to be 1 so once again next value we have to enter is going to be four and then we are going to move our left Point pointer on the right and then since because left and right now both are at the same position we are going to add the one as the last element over here and return this as the answer so see how we were able to generate the entire solution in just one single pass and this is the beauty of two pointer approach that whenever you see solution where you need to compare both sides of given input array or string try to think that can you solve this problem using two pointers and most likely this could be one of the possible solution so now let me give you a quick trick after we have understood lot of things about array first thing is whenever you are given an array try to think that can you sort this given array to generate some result second try to think can you use some some of the hashing function like hash map or hash set then if not try to S think can you use a sliding window technique otherwise try to think can you use two pointer technique typically amongst all of these most likely you would be able to find the answer you are looking for and this is the key trick for to solve any array based question in any of the technical interviews okay so now we are going to see the solution for squares of sorted array uh so let's see first of all we are going to create a variable called n and that is going to be the length of given input array then we are going to create a new array to store the result we are also going to initialize two pointers first is going to be the left pointer second is going to be the right pointer left pointer is located on the leftmost position rightmost right pointer is located on the rightmost position then we are running a for Loop in the reverse order and we are we are going to have a function that basically takes care of the Square value and then we are going to compare the square of the left element with the right element so basically what we are doing is uh we are simply comparing the absolute values of left element with the absolute values of right element so we are ignoring the minus sign and whichever value is greater we are putting that in the square and in the end in the result of that particular I value we are just storing whatever the square variable we were able to find either left or right and then uh in the end we simply return the result array that we have created now let's try to run this code okay seems like our solution is working let's submit this code and our code runs 100% faster than all the other Solutions which is quite awesome so now you got the idea of how two pointer Solutions work okay so first let's try to understand a really interesting coding pattern that is called fast and slow pointer now this is most prevalent and very heavily used in link list kind of problem so you might think whenever you are trying to solve some linkless problem try to think that can you use this technique in this scenario and first let's understand that what does a fast and slow pointer technique is it is very similar to a twop pointer technique but uh in the two pointers where we have two pointers left and right coming towards each other in this scenario we actually have a fast pointer and a slow pointer both typically starts from the same position but fast pointer would would make double jumps so fast pointer would go to the next to the next value meanwhile slow pointer would only make a single jump like a normal uh typical traversal we do and doing this would yield us uh some good results in couple of specific positions so first let's try to see that how does a typical concept looks like let me draw a random uh link list now we are assuming that this one is a single link list but same thing would apply for a dou link list as well and this is the head of the link list and this is the last element so this value points to the null value now in this case the overall idea for the pattern is that we are going to have two variables so first one is a fast and second one is a slow variable okay so currently let's imagine that both fast and slow pointers are based at the head position okay now fast pointer is move in the Direction Where We are going to choose the next element for fast is going to be node do next do next so next to the next element for any given node would be the next node for the fast pointer meanwhile for slow pointer it is only going to be node do next that is the regular traversal so during the first iteration fast node is going to do node do next do next so fast pointer would end up over here meanwhile slow pointer would have end up over here in the second iteration fast pointer would end up over here meanwhile slow pointer would have ended up over here and doing this now fast pointer is is at the very last element inside the link list so now we can use some properties so the question comes that where does this technique is actually used so I can give you two examples right now first example is that I already showed you previously in the course where you need to find the middle of the link list in that case uh fast and slow pointer is very good use case to follow that if we want to find the middle of the link list typically we can do that and try to consider the same scenario in this example we are seeing that right now the fast pointer actually reached to the end position because fast do next is equal to null which means this is the last position around that time slow pointer is exactly located at the middle element and which we can see right over here so whenever we are being asked that hey go ahead and find the middle of the link list always try to use fast and slow pointer because that would be the quickest method to find the solution another one solution is that when you need to detect a cycle inside a link list and now the question comes that how can we actually detect a cycle inside the link list using the fast and slow pointer so let me give you an example for that as well now suppose uh let's assume that we currently have a bunch of different nodes lying around and we will try to see that how would a cycle inside the link list would look like okay now let's assume that all of these nodes are connected and in this case there is a cycle present like this okay now we don't know initially because this is a singly link list and we we have no idea that what are the next elements so let's assume that if you had to detect that find that if there is a cycle in this case or not how would you detect it uh one basic and naive approaches that let's say that these are all the values for this given uh link list what we can do is we can actually start iterating the given link list and we can have another data structure like a hash set and we can keep checking that whether this node has been previously visited or not and if we reach to the null value we can say that there are no Cycles in the link list like the next node is the null node then there are no Cycles in the link list if the next node is not null and we encounter some node that is already present in the hashset we can say that this node has been repeated so let's try to run this example first we will add all of these values so 1 2 3 4 5 6 7 and 8 all the values we would iterate but before that we would check whether it is present inside the hash set or not because it's not present we would add all of this 1 to eight values over here now the moment we would try to iterate to this value we would realize that this three has already been added to to the hash set which means we encountered a value that has been added so that's why we can say that yes there exist a cycle in this case but now issue with this approach is that we actually have to use an additional has set so the space complexity in this case would be big go of n which we don't want we want to do this problem without using the space complexity so the another approach is to use fast and slow pointer and let me show you that how would that look like the whole solution okay so let's get rid of this hash set and let's have our fast and slow pointer ready so initially our fast pointer would be located over here and slow pointer would be located over here now let's make two jumps for the fast pointer and one jump for the slow pointer so after which fast pointer is going to end it up end it up over here and same way slow pointer is going to end up over here okay now once again fast pointer is going to end up over over here and slow pointer in this position has ended up over here okay now let's repeat the same process now fast pointer would come over here same way slow pointer would come over here and let's get rid of the previous two elements once again fast pointer is going to make two jumps so fast pointer would end up over here and in this time slow pointer would have made one jump so slow pointer would be here now when fast pointer makes two jumps it is guarantee that it is going to encounter slow pointer in this scenario and the moment we find out that fast pointer actually came back to the slow pointer or the position where slow pointer is we can say that there is a cycle in this scenario and we can return true that yes there exists a cycle so basically this is the whole concept of fast and slow pointers so whenever you are trying to solve some problem related to link list try to think that hey can I use two pointers where one pointer is faster than the other and try to come up with the solution more than likely you will be able to find some good answers in that now let's learn an awesome technique called backtracking backtracking is highly popular in lot of different scenarios and you can typically use backtracking to solve problems like dynamic programming recursion uh tree problems and graph traversal problems so for all of these things backtracking is heavily useful so you can imagine that how popular it is going to be if you ever wants to implement these data structures and try to come up with a solution so first let's do this we will try to understand that what backtracking is then we will try to see that what is some real life example so I'll probably give you a couple of real life examples and then we will try to see how we can navigate using backtracking in the depth for search manner so that is how and we are we will try to navigate it within trees and graph and on top of that we will see one of the lead code examples as well okay so first let's understand that what does a backtracking is backtracking is nothing but an ability to go back to the previous place we were at essentially let's say that we are following some certain path and at any given position we have the option to choose uh some different paths as well depending on the CH choices we make so let's assume that in this scenario we decide to take down uh and go we initially started with this and we go down this path this path and from this moment we decide to go to next PATH over here and from this we decide to go to the next PATH over here but we did not find the answer we were looking for so what we would do we would come back again to this node and try to check a different path once again since we did not get the answer we would once again try to get back to this path where we originally branched out come back to the same PL same path and then choose a different option and keep a track that which path that we have already taken so that would help us determine or backrack our actions that's it this is the whole concept of backtracking if you have to understand this let's say that you are currently located inside a garden and this is like a maze Garden so you don't know where you are going okay so typically all the roads are crossed in weird manner where some roads don't lead to any other place and then there are some roads that leads to different positions in the garden so what would be the approach you would take let's say that you typically started from here what is going to be the approach you are going to take well essentially the idea is let's say from this place you started traversing this path you would keep on going and realize that hey there is no path in this case so of course you are going to backtrack you are going to come back to the position where you originally started once again try to take a different path and again make some different decisions so if you go down this path once again it does not work so you will backtrack to a previous position where you made the choice and once again take this New Path and eventually this New Path might end up might lead you to the Final Destination you are trying to get so this is one example of backtracking so now let's try to see that how does backtracking would typically work in a tree like scenario okay so currently let me just draw a very simple binary tree where I have bunch of different uh nodes and each node had has some children associated with them and for each one of them I'm trying to see that what is going to be the most optimal path or let's say I'm trying to find this value x uh this node X so first I go down this path then once again I go down this path and by the way I'm using DFS in this case depth for search which means I'm going in the depth rather than going in the breath so I go over here I don't find anything so I will backtrack once again from this I know that there is one option left that I haven't checked once again in this case I haven't checked the I didn't find anything so I'll backtrack once I know that I have exhausted all of this possibilities I can also go back to the original root node and once again repeat the same process and in this case since I don't find anything I will again backtrack and okay here I find the X I was looking for and I can say that yeah this is the correct path and I can return that as the answer so this this would be an example of how uh backtracking would work in a tree like data structure and same concept applies to the graph as well because trees and graphs are very similar the only difference is graphs can have Cycles trees typically don't have cycle so even in terms of backtracking the same logic would apply that let's say that you decide to go to this path and then this path first but this part does not yield the result you are looking for once again you would backtrack and you would go to a different path and through which you find the result you are looking for and you get the correct answer so backtracking is nothing but the ability to go back now let's try to understand backtracking with one of the lead code examples okay now let's assume that this is the problem we are trying to solve binary tree paths now we can see that this has been relatively popular problem and the problem statement is actually quite simple to understand we are simply given the root of a binary tree and we need to return all root to leaf paths in on any order so let's try to understand this with an example suppose we currently have a binary tree that looks like this now in this case let's give some arbitary values as well uh so the values are going to be 1 2 3 4 five and six okay these are the values for each node so in this case how many different paths we have from root to node so first path is that we can go down this this scenario and this scenario so 1 to 2 to 3 this is a path to leave okay once we identify and let's create our answer list where we are going to store all the results that we are we have been able to find so far Okay so we found one path after finding this we will backtrack to the previous element once again repeat the same procedure to the remaining path okay we completed the remaining path and now this path is 1 2 and four okay once again back track okay now we exhausted all the possibilities over here so once again we are going to backtrack to the previous element from one we still have unexplored paths so we will start exploring and we will keep on going until we find the leaf node that we are looking for so in this case okay we find the leaf node as six and now we will add one more path that is 1 5 and six and now we explored all the paths so this answer list we can return as the answer and basically that's it okay so this is the problem statement binary tree paths and here is the solution basically the first thing we are going to do is uh we are going to check for the edge cases that if the given root element is equal to null we can simply return the paths we have if not we have already created a new link list that contains the list of all the parts we are going to create now in order to implement the backtracking we will have to use stacks and in the stack we are going to add the current root node and then we will keep on going it to iterate all the possibilities until we find our stack is empty or not and when we learn more about DFS you would be able to understand this technique that how this technique actually really works and how it is pretty efficient way to implement the uh backtracking method for the depth first search scenario so so now we have our link lists initialized now first we are going to add the root element to our link list and then we are also going to add a new path to store the integer value and then we are going to run a while loop that while the given stack is not empty we will keep on repeating the same process and basically this piece of code does nothing but it only Travers through the left side of the node or the right side of the node until we reach to a point where there no longer exist any more children for any particular value and once we get that we would add those values to the subsequent paths and in the end we are simply returning the path so if you didn't understood what I mentioned I'm going to post the solution in the GitHub link as well so you can check it out from there and you should be able to understand let's try to run this code and seems like the solution is working as expected let's submit this code and our code runs pretty efficiently compared to a lot of other Solutions Plus this is this gives you an idea that how does a typical uh depth for search or backtracking works for any tree or graph related problems okay now we are going to understand another interesting pattern that is called intervals intervals are nothing but the spaces of time or sequence in between and we need to do some work with that or some computation with that typically in the intervals type of problem you would always be given some specific set of time based connections or intervals like something like a starting time and ending time starting time and ending time and then through this you would try to make some meaningful information so let's say that this is the starting and ending time chunks of the entire day uh between 9 to 5 and let's say that these are the meetings that this meeting starts at 10 and ends at 11 this one starts at 1 and ends at 2 and this one starts at 4 and ends at 5 so if this is the information given if I'm trying to create or schedule a meeting how would I be able to do it so what are the empty time slots available to me so this is an empty time slot available this is an empty time slot available so if I want to schedule a new meeting I can actually schedule in that and that is the whole point of intervals typically most of the times intervals are actually being used for various set of uh time management or calendar management type of activities and trust me this is important because I personally got asked interval questions in two of the very big company interviews I I I actually give so that is why interviews are intervals are really simple to understand on top of it once you know the technique it's actually quite easy to take care of it so let's see that what are the different possible scenarios we can have inside the interval number one possible scenario is that we are given the time schedule for A and B to two different people now we are being told that uh this is the time sequence now these are the times that a currently has a meeting and for B we are being told that these are the times B currently has a meeting so now if I if we want to arrange a common meeting between them to take place how can we do that and the idea in this case would be to create or merge a new interval common interval this is just for the example sake I'm telling you and in this case what we would do is we would take whichever the starting point is smaller at first and whichever the ending point is larger at second so if there is a conflict between any two entities that can be resolved quite easily and we would start creating new intervals that are combination of both of them so that would give us the idea that which are the empty times available so another interval like is like this and this one ends with the schedule so now this is the common time schedule for A and B which means we can say that there is only one empty space available where we can schedule a new meeting if you want to so this this would be one of the use cases second use case would be that let's say that for a we are actually being told that a is overbooked with multiple meetings on many places so which means a has overlapping meetings throughout his day and we wants to simplify this process so what we want to do is uh whichever meeting is smaller in the value we want to get rid of it so we want to get rid of the interval that is actually causing a conflict between the existing meetings so in this scenario we can check that okay currently this meeting is 2 hour long let's I'm giving you for an example and this meeting is only 1 hour long but we do see that there is a conflict in this case so because there is a conflict if we want we can get rid of this meeting entirely and say that uh now a does not have any conflicts same way in this case there is a conflict between this time and of course this meeting is smaller so we can also get rid of this one so this would be a remov of removal of interval kind of scenario another way to treat this is that we can actually move this meeting to the side so let's say if meeting is like this rather than canceling the whole meeting what we can do is we can just get rid of the conflicted part and we can create another new meeting that looks like this that okay now a has two separate meetings even though they are back to back with each other still they are not conflicting so this would be another type of scenario for inter interval questions and the third type of scenario would be where we are actually being told to merge intervals okay now let's assume that this is the problem statement given to us that we need to merge the intervals and you can see that this is a very well like problem on lead code basically we are given an array of intervals where at any particular position position defines the starting and ending point for that particular interval now we need to merge all the overlapping intervals and return return an array of nonoverlapping intervals that cover all the intervals so here we are given an example if you want you can take a look at this example but I actually plotted this example on a very nice like graph so you you should be able to see the idea now in this case we can clearly see that there are four different intervals given to us but among these four intervals we see that these two intervals are non overlapping they are just as it is now how do we know that on our side we can just see them and realize that they are not overlapping but if you wanted to check that if any two o intervals overlap or not all you need to check is the ending point of the previous element and the starting point of the next element and if there is a difference between them let's say that because this ending point is smaller than the starting point of the next one which means we can Define that there is no overlap between these two so because there is no overlap we can keep them as it is we don't need to do anything now in this case if we see this is the starting point this is the ending point same way this is the starting point and this is the ending point so starting point of this is one and ending point of this is three same way starting point of this new element is actually two and this uh this interval is actually six so in this case we can see that for this interval we do have another interval Who start starting point comes before the starting before the ending point of this previous uh interval so that is why we detect that there is an overlap because there is an overlap what we can simply do in this scenario is that we would take the starting point whichever is smaller so in this case the smaller starting point is one and then we would take the ending point whichever is greater so ending point greater is six so we would create a new interval called 1 to 6 and then we would take keep this 8 to 9 interval as it is and same with this 15 to 18 interval as it is so the new answer array is going to be this 8 to 10 and then 15 to 18 and this is the answer we need to return so basically this becomes a very simple problem to understand I don't know why lead code mentions this as a medium problem in my opinion this should have been easy all you are doing is comparing the values between starting and ending point between any two subsequent variables and remember in many scenario to trick you the intervals that we are originally given in the original input might not be sorted so if they are not sorted then in this case first thing you will have to do is sort them in the basis of starting time and once you have the sorted values then things becomes quite easy and then you should be able to solve any of the interval problem so let's quickly see the Java code for this problem so here is the problem statement merge intervals and let's see the Java code for that so first thing we are doing is we are actually sorting the given input based on the starting times and once we have that things becomes quite easy now we are just initializing a new link list uh named answer and then we are iterating over the original intervals array that we are given where we are given two values one for starting point and one is for ending point where we have all of these conditions that if the answer is empty or if it is the last element or whatnot we are going to add element to the interval if that is not the case we will have to do the merge operation where we are simply going to add the value of the last element or the maximum value of the last element compared to both the intervals and minimum value of the first interval that comes in the normal sequence and let's try to run this code okay seems like our solution is working as expected let's submit this code and our code runs decently efficiently so this is a very simple problem to solve once you know that you have to sort the given intervals based on the starting time now we are going to start with a very important topic called BFS now if you don't know what BFS means uh it is short for breath for search and it is a very popular tree and graph traversing traversal service so typically whenever we are going to see any data structure such as tree or a graph and we need to iterate over either tree or graph for traversal one of the very popular technique is is a breath for search technique and we spoke about this little bit uh in the previous sections but now we are going to go into much more deeper on how what are the considerations how it works and how to implement this plus we are going to see an example of uh an actual live lead code problem for this problem as well so we all know that in the breath for search essenti essentially you are traversing outwards towards your subsequent neighbors first before going out out to their neighbors so at any given position first you will encounter all the neighbors of that value then you will start encountering its neighbors and until you have done for all the cases you will not Branch out to the deeper levels so essentially you are traversing level by level for all of the nodes that are currently present inside your graph so if this is let's say that this is a graph that you are given now in this graph first of all you are going to start at the root position and this is the root position so first you are going to visit all four neighbors once visiting all four neighbors then for each neighbor you would start visiting their subsequent neighbors and one only after you have visited all the subsequent neighbors then only you would go to further higher or deeper levels so let's see some examples of this in both tree and graph like structures suppose this is the tree we are given I'm just drawing a very simple binary tree and and I'm going to associate some values to it so let's say that the values are 1 2 3 and 4 5 6 7 these are the values so if we if we have to apply breath first search in this scenario basically we are going to first visit for any root node we are going to first visit its neighbors so first of all we are going to visit node number two and node number three uh and then we are going to visit its subsequent nodes that are 4 5 6 and 7 so where this type of solution can be useful well let's say that at any given position you want to print out that what are all the numbers available at any given level of a tree then you can use this uh BFS approach or if you are trying to find some elements and you expect that element would generally be closer to the root element also in that case it would make more sense to use the BFS approach plus now let's see that how this would work in a graph like data structure typically in a graph we have bunch of different various data connected with each other and there are there can be some or many cycles associated with each one of them now assume that in this graph this is currently the root node so in this case for the BFS basically we will visit all the neighbors so this is the neighbor this is the neighbor and this is the neighbor and also this is the neighbor and only after visiting all these four neighbors we would start going to the deeper levels and that would be visiting neighbors of these neighbors uh so where is typically BFS useful for the graph likee structure is that let's say that for any particular node you want to know that how distant it is connected with some other node so in this scenario we can consider these two nodes to be Distance by two because this is directly connected with this so there is a distance of one and this is the distance of two this can easily calculated using BFS and there are some very real life practical use cases like uh websites like LinkedIn or even Facebook you can actually see that how what is your common connection between any two people and for that uh it's quite easy to implement the graph based bread for search method to calculate those values so you can calculate the degree of distance between each each other neighbor on top of that even for graph basically uh BFS is used to search any element plus Traverse over the entire graph and if you want to find any connection between between two end points you can do that if you have to visit all the neighbors of any particular element for any of your problem solving requirement you can also use BFS in that scenario and again remember any problem that you can solve with BFS you can also solve that with DFS as well the only difference is depending on the problem statement sometimes it would make sense to use the BFS and many times it would make sense to use DFS so always make sure that you are aware that which data structure approach you are going to choose now let's see that how BFS gets typically implemented and usually in order to implement a BFS we usually use a cube where we put one value inside the cube and then we add its children to that Cube and then we keep on repeating the process so the output of that CU would be the breath for search manner traversal for any given tree or graph and let me show you an example of a tree so suppose I'm given a simple tree and I'm just drawing uh five noes over here and let me Mark the values as 1 2 3 and four and 5 so initially we are at this first position now we are trying to do the BFS so let me also initialize my Q as well and in my Q uh we all know the principle first in first out okay so first the value I have currently is value number one so I'm adding one over here now before processing one I'm going to add all the children of one I repeat before processing one I'm going to add all the children of one so there are two two childrens's of 1 2 and three so I'm going to Mark values 2 and three over here after that and only after adding all the children I'm going to process one so let me print out the value one over here that this node has already been processed and also let me get rid of this now the immediate value or the very first element inside the Q is value number two so once again before processing two we are going to add all of its children so the values are four and five and then after that we can process value number two so once again let me get two out and uh second element over here would be two now in this case the next element I have is three now since we already process all the children of three or three does not have any children so we can take three out then same way after taking three out four and five also does not have any children so we will take four out and then we will take five out and in the end our que would be entirely empty because we process all the nodes so we are going to keep on processing until Q is not empty and using this approach we can actually solve the BFS for any given tree problem same logic applies for the graph problem as well so you would be able to understand what I mean now let's try to consider one example uh and then we will see the code for that the example is that we want to find the average at the uh level for any given binary tree so the problem statement is quite simple to understand we are simply given a binary tree and all the values we need to find the average at the its own level now let's give some arbitrary values so 1 2 3 and 4 5 6 7 and then 8 and 9 so these are the values now what is the answer going to be currently on the very first level there is only one element and its value is one so the average for this is also going to be one now for the second element we have two values 2 + 3 so the average is going to be uh 5 / 2 so 2.5 so this answer is going to be 2.5 next over here the average is going to be uh 4 + 5 is 9 and 9 + 13 so 22 22 divided 4 so I think it's something like 7 uh sorry 5.5 yeah I think it should be 5.5 so this average is also going to be 5.5 and now for this one the average is going to be 8.5 and this is what we need to calculate so you must must have understood by the logic of it that we are going to do the traversal based on the levels that we are performing and we are going to have our Cube and in the cube we are going to first insert the value number one we are also going to have a method to calculate the average and in order to do that we will need to know that how many children are currently Pro or how many elements are there because this is a root element currently we only have one element so I'm going to encounter a value called count and initially the count is only one for this one I'm going to add its children so I added children 2 and three over here because I added two values I know that for next time when I need to calculate the average the count is going to be two okay so now this one this time using this I can calculate the average one and I can print one over here same way uh before processing two and three I'm going to process its children and even for the children I'm going to keep track that how many what was the count and eventually I should be able to make all of this continuous a average calculation because it's a very simple problem and this is how we can actually Traverse in the level order for the given tree and solve this problem quite easily so now let's see the lead code solution for this as well this is the problem we are trying to solve average levels in the binary tree and here is the Java code for that first of all we are given the definition of the tree and then in the main solution first of all we create a new list where we are going to store the result values plus we are also going to initialize a q where we are going to store our tree nodes and on top of that we first add the root element to our Q now we run our while loop that while Q is not empty we are going to keep track of what has been the long sum plus what has been the count for every single children we added we are going to add a temporary node to for our Cube and we once again for that we are going to keep track of or add all the children of it and increase the value of the count and we are going to keep on incrementing until the left node is not equal to null or right node is not equal to null and uh after calculating that we are simply going to run the average function that is Su multiply by one divided by count and um uh that's it so we will add those results into the result list we created earlier and this is the whole solution now let's try to run the code okay seems like our solution is working as expected let's submit this code and our code runs pretty fast pretty efficiently which is awesome so I hope you understood uh that how things get easier whenever you need to Traverse in level order for any graph or any uh tree you can use BFS quite easily okay so just like BFS now we are going to shift our focus on the DFS and DFS is also a graph and tree traversal method and in this scenario we are actually going down into the depth before going into the breadth so we are going to pick a path keep on going on and on in the depth until we reach to the very last Leaf node on that path and then only we are going to backtrack our way to a different possibility and then keep on repeating the same process so let's try to see an example suppose this is a tree that we are given now in the same example rather than traversing in into the sequence of breath we are actually going to go down into the deep so first we are going to Traverse down this path then after traversing this we still have one node that we haven't process in the reverse order so we will go and do a backtrack after backtracking go back over here once again solving this we would again backtrack and through here we would complete the remaining uh path that we haven't taken and in the end we will return this solution of all the paths that has been traveled so this was an a depth for search for a tree same logic will apply for a graph based depth for search as well that let's assume that we have some complicated graph based algorithm or many different nodes that are connected with each other in all sorts of manner and once again we would try to generate some graph based solution for this one as well so let's assume that if this is our root node initially so we decided to go in in the depth for each one of them so first let's say that we pick this node now this node also has other neighboring connection node so we are going to go to its neighbors again this also has neighbor so again we are going to go to its neighbors and again this also has neighbors so we we are going to go to its neighbors after completing all of this we are going to do a back trck to see if we missed any other branches in the depth this one has no branches this one also has no branches this one also has no branches so we come back to our root node but root node we still have other nodes that we haven't traveled so we will go to that node first before traveling to the other nodes and every time we are going to do the backtrack function now we know that in the breath first search we were using Cube but actually in the depth for search we are going to use a stack T to keep track of of all the nodes that would help us with the backtrack function so how would this work I will just give you an example but first let me talk about that if you have to do a tree traversal using DFS you actually have three different ways to do it now I already showed you what those ways are but I'm just giving you the name that is in order traversal preorder traversal and post order traversal and all of these would be part of or would be considered a depth for search traversing methodology now the question is that what are some of the benefits of using the depth first search so first number one use is that if you are trying to find the full path between any two entities so in that case DFS tend to be more useful second thing is if you're trying to find some element so again in that regard as well that you are able to generate it very easily using DFS uh same same way let's say that if you are trying to make some dependency graph and and this is heavily useful in lot of scenarios let's say if you are trying to build a compiler or if you're trying to build like a schedule prerequisite dependency course kind of a module for our University so in all of these scenarios graph based DFS is going to be very useful so these are some of the most critical scenarios wherever you can think of that from one node in the graph you need to go to far away to some other node try try of thinking to use DFS okay now let's assume that we would try to do a DFS stack run example for any given note now initially we are going to have an empty stack and inside our empty stack just like BFS method in the DFS we are going to add the root node now remember stack has a different property that is last in first out okay and we are going to follow some principles so first okay let me add one value number one over here now the principle we are going to follow is the moment we take one value out from the stack we would see that how many children that value has and both of these children we are going to add to the stack after that and we are going to keep on repeating the same process okay so now currently we have element number one so we are going to take one out so if we take one out let me just node create a method where we are going to keep track of process node So currently we have process node number one okay now we are going to add its children 2 and three into the stack as well so let me add this value now once again just like the same logic we are going to pop value number two first so let me pop value number two so we process node number two but because we process node number two we are going to add its children into the node as well so let me add values five and four over here as well now once again same logic we are going to pop value number four first so after popping value number four we are also going to add children of four as well that is value 8 and N so once again even for 8 and 9 we are going to pop them now since 8 and N does not have a children of Their Own so even if we pop value number eight and value number nine they are going to remain as it is because they don't have any children that we can add so now we can get rid of 8 and N from here now next value we have is element number five again element number five also does not have any children so we are going to mark value number five over here and then we can remove that okay after that we are only left with value number three so we will try to pop value number three out the moment we pop value number three in this case we will have to add its children over here so first let me delete this okay so now currently we are going to add value number six and seven here and then we are going to mark three as presented and then we are going to pop value number seven out and then we are going to pop value number six out so this is going to be the whole flow of the sequence in which we Traverse through all the nodes inside the given tree using the depth first search method and uh we can see that all the iterations leads us in the in the graph sequence so here here first we visit node number one then we visit node number two then we visit node number four then we visit node number 8 so we go down in depth after visiting eight we do a back track and we go to the four and visit the remaining child that is nine so like this and after visiting nine we do another backtrack and two we visit value number five so this is how the sequencing of death depth for search is being followed and you can find plenty of examples of depth for search in all across places so I hope uh the concept of BFS and DFS is quite clear to you now so we can move on to our next topic okay now we are going to see a really important algorithm that is called greedy approach now as the name suggest in the greedy approach we try to be greedy in order to generate the answer and we try to find the solution on every substep as well in the given uh algorithm or given problem now before we start understanding the technical details of greedy approach let's first try to understand the local detail of the how greedy approach typically Works let's say that you currently have an empty truck and you are trying to fill this empty truck with bunch of different boxes uh that you currently have now in terms of boxes you have three different types of boxes first boxes that uh and remember all three box boxes are identical in size but they contents are different so let's assume that the first box we have this contains all the ion now second box we have this contains all the aluminum and the third box we have this contains all the feathers now in this case what should be our approach to fill in the all of these boxes into the trucks so that we can get the maximum return out of weight we are trying to put in of course the approach is going to be quite simple we are at every given position or every particular item we are trying to fill we will try to maximize the value of these pink boxes and we will try to see as many number of uh these boxes we would try to fit inside the given uh truck before we run out of them and once let's assume that we fit all of the iron boxes what would be our strategy in next case next case strategy is to fill out the remaining of remaining portion of the truck with all the aluminum boxes uh so doing this method would grant us the best weight ratio amongst uh inside our truck and in the end if we have space then we will try to put the boxes with feathers in them if not then we would essentially fill out our entire uh truck with these two type of boxes so the load we would be handling the heaviest load so what we did in this scenario that let's assume that we consider that filling one box inside the truck as one sub problem for the given algorithm or given step so in every sub problem amongst all the options we always choose the best fit option in order to solve our problem that we are trying to solve and this is the classical example of a greedy approach where even during the each and every suboptimal level we try to choose the most optimized and best available option in order to go to the next next step so now let's see that what are some of the important characteristics of a greedy algorithm so greedy algorithm as I mentioned it is built on piece by piece by piece and every single time we are always choosing the most available and best uh suited particular option for our graph in order to build the solution so no matter if there are how many number of choices available we are always going to pick the choice that is the most suited in order to F fulfill our need now greedy algorithm also suggest that the global Optimum or the best results we can achieve by every single time at every single sub problem selecting the best available option so that is one of the characteristics of the greedy approach and uh there is also one more choice or one more uh thing that we have to understand that is that in order to optimize or find the optimal solution for all we need to consider that what are the overall constraints available to us because many times the greedy approach might look okay at the beginning but it might not be the correct Choice uh because let me give you an example for that do you remember the scenario we were trying to solve where we had bunch of different coins and we were trying to make uh any particular number so let's just say that we were trying to make value number 11 uh to see that which are the smallest number of coins we can make or we can use to to build this property and let's assume that the available coins to us are going to be value number one uh then value number five and then value number s and we are trying to see that how many number of coins would it take for us to generate this value number 11 if we were to use greedy approach our approach is going to be that for first sub problem we are going to choose the coin with the maximum value So currently the maximum value is seven okay so after choosing the 7 once again now the remaining value we have to create is going to be value number five because sorry value number four because 17 minus uh sorry 11 77 11 7 so 11 7 is give us the result four so now we will have to create value number four for that we still have three options but we cannot choose value number seven because it is too high we cannot also choose value number five because that is also too high so the next option is to choose four different $1 coin so in this case we are going to choose 1 + 1 + 1 + 1 so in this case if you see in total it took us five coins to build this value number 11 uh and we use the greedy approach but do you think this was the most optimal way to solve this problem no why because we already have a sub option where we could have choose coins like 5 + 5 + 1 and this would have also given us the value number 11 and even though at every suboptimal level we did not choose the most appropriate or most greedy approach we still found the optimal result in terms or three coins so you always have to consider that whenever you are trying to solve a problem think about it that will greedy would be the best solution or could there be a scenario where rather than using a greedy approach you can try to think of using a dynamic programming approach which is what we did in this scenario so greedy problem and dynamic programs they go hand in hand they're very closely correlated with each other but you will have to make that decision and you can only understand that decision after correct directly figuring out the given input so this is really important now let's move on to the next property and let's try to understand this with an example now the example is that suppose uh we are given an we are given a text okay and this text contains lot of different characters now we are trying to build an editor where inside the editor we are trying to put the encryption of some of these values so now we need to identify that which character should be encrypt so that the that those encrypted values would be easy to travel over the given Network and that would consume less space so let's say that if there is a character like um chloroform and there is another character called the so which character should I pick in order to uh compress or in order to encrypt of course at first glance we would think that chloroform is is a bigger word so we should put the chloroform in the encryption but the idea the better choice would be the why because the is more likely to appear at multiple places throughout the document so if we choose to encrypt this character it would give us more value so what should be the greedy approach in this case to decide that which characters should be good candidates in order to uh have them have them available for the encryption and one of the best approaches that what we we can still use the greedy approach in this case we can actually create a heap for all the characters by their frequencies and frequ frequencies means I can see that how many times they appear now we can have the condition that if any two characters A and B if they have the same amount of frequency then we would choose the character with bigger length so this is our greedy approach that if the if there are like let's say that there are 10 10 times character a appears and 10 times character the appears in the same document so the would be our first choice rather than the character a because the contains three different characters so if we encrypt that there is more value behind it and in the end we would be able to written uh using the Heap whatever the top five answers are those five would be the characters that are most repeated bigger in size and also give us the best value for encrypt encrypting our result so this would be one of the good example for greedy approach and basically this sums up most of the questions we had regarding our different algorithms so first of all I would like to congratulate all of you for making up until this far I know it was lot of information to take in but you took it like like a champ so congratulations on that now let me give you some of the popular rule of thumbs and some tips and tricks that will help you come to the conclusion faster in an actual technical interview manner so first one is whenever you identify any question that deals with uh hey give me top closest minimum maximum of K numbers out of the given total n numbers in that case of scenario always try to think that hey can I use a heap in this scenario because Heap will allow you to store the values based on their properties either like maximum values or minimum values and let's say that I I ask you that hey out of the given input data stream give me the fourth maximum or fourth largest number the approach would be to generate a heap to store all of those values and then start popping out values one by one by one until you reach to the fourth character and that would be the answer you are looking for so always think about that can I use Heap in these kinds of scenarios and most likely the answer is going to be correct with that approach now second thing is whenever you are given a binary a sorted array always try to do a b binary search in that that type of input because binary search is going to save you lot of time because binary search operates on log and time meanwhile the regular search operates in bigo of end time so it makes huge difference in terms of performance now next step is let's say that whenever you are given or you are being asked to compute the all the combinations and permutations of given various path choices always think that can I use backtracking or breath first search in such scenarios uh why I'm telling you this because most of the time there would be possibilities where you need you are given bunch of different input paths and you need to pick one correct path and many times you need to try out different paths and then come back to some previous point and then again try another path so for such kind of problems backtracking and breath for search are perfect uh also one more thing whenever you see any question related to trees or graphs try to think about solving them using either breadth first search or depth first search we already talked talked in quite detail that what are the difference between each one of them and what are under what circumstances which one to choose but either ways you would be able to come up with the solution by using either breath for search or depth for search because most likely you are going to Traverse over the entire tree or entire graph to find the optimal solution you are looking for so always trees and graphs equals to BFS and DFS that's a golden rule next thing is whatever solution you try to make if you make a recursive solution you can all also make the same solution using iterative approach using Stacks so many times it would happen that during an interview you are discussing you are uh brainstorming you are coming up with the solution that is a Rec recursive approach your interviewer is for sure going to ask you that hey instead of recursive approach can I do something else and you you can say that yeah instead of recursion if you use uh an iterative approach you can come up to the solution using Stacks so that is a very powerful tool and basically they both achieve same kinds of uh results on top of it many times if the recursion is long enough there you could encounter issues such as like memory overflow or stack Overflow and things like that so that can be avoided if you are going to use the iterative approach next thing is if any problem related to array that you can solve using bigo of n Square time I repeat if there is any problem using an array that you can solve in bigo of n Square time you can solve the same problem using n log end time if you decide to go with the Sorting approach and you can solve the same problem in big off end time if you decide to go with either hash map or hash set approach and we already saw examples of that using two some problem um and many other array problems so always arrays and be go of n sare time complexity try thinking about sorting the array or try thinking about using a hash map or hash set in such kind of scenarios next one is is whenever you see that you are being asked to optimize or do the find the minimum or maximum value amongst all of the given path and you need to do some sort of optimization most of the cases you would be able to come up with a dynamic programming approach that would be able to do things in much faster Manner and we saw that using coin change example where we were given bunch of different coins and we were trying to make a particular value so in that case dynamic programming allowed us to come up with a much better approach and much faster approach now next uh Golden Rule has to deal with uh searching or manipulating bunch of different strings now we all know that try is a data structure very closely associated with strings and whenever you are given this kind of scenario try to think that if there are multiple strings and I wanted to do many manipulations can I use a try and more than likely that would be the correct solution uh so these are the nine golden rules let me me give you the 10th one and the 10th one is actually that whenever you are given a link list and you are explicitly told that you should not use any additional space so IE you should not use any additional hashmap or hash set or something like that to store any extra computation in such scenario try to think that in the existing link list can I use a fast and slow pointer method because that would yield us the correct result and we I already showed you two examples of that first example is finding the middle of the link list second example was that finding that whether a link list has a cycle or not and both are pretty popular and widely known problems amongst tech tech interviews so these are the most common approaches and rule of thumb that should be in the behind the back of your mind so always make sure that you are following upon them now let's talk about what are the common pitfalls to avoid because many times you can do everything right and still get it wrong during the actual technical interview and for that it's not only about your technical knowledge but it is you need to have a combination of smart communication skills uh optimized thinking and also being able to come up with the solution in the given limited time management so there are lot of things so let me tell you that what are some of the common pitfalls that you should also avoid during any of your interviews so number one is always make sure that you are well prepared if you're not well prepared you cannot blame anything on anyone else because if you are not prepared and you go to a battle you are for sure going to lose and missing out any opportunity for a technical interview could be a career changing opport opportunity that you might be missing out you might be uh saying goodbye to your favorite job or your favorite company so please don't do that always make sure that even if you are an experienced individual you have like 10 years of experience still go through all the data structures once go through all the coding patterns once maybe try to solve two or three questions amongst each one of them on the lead lead code or hacker rank or there are a lot of resources available because preparation is half half the battle one so that is the number one thing I would advise number two is always try to listen to your interviewer first because many times interviewers are intentionally giving you a very small and very a complete subset of the original larger problem St because they wanted to check that can you come up with the thinking that hey what should we do in this kind of scenario or what should we do in this other kind of scenario are you asking the clarifying questions so always try to understand the problem fully first before diving deep into start going on and solving the problem uh because I have seen and I have personally experienced this many times that whenever I hear a question I would get too excited if I know the answer and I would try to start building and start coding and after 5 minutes the interviewer would be like hey did you think about this scenario and in those cases interviewers were actually expecting me to ask that clarifying question so always make sure that you do that number three suggestion would be always manage your time accordingly because you are only going to be given 45 to 60 Minutes to complete an interview and during this 45 to 60 Minutes you need to maybe uh introduce yourself so 5 minutes go there there would be 5 minutes in the end uh to ask any questions you have so you are essentially your interview time breaks down to only 50 minutes amongst these 50 minutes you need to understand two problems you need to come up with the solution you need to explain the solution you need to walk through all the edge cases you need to code the solution check whether your code has any errors or not run through run through it and uh explain the time and space complexity maybe explain different approaches and also say that why did you choose this or why did you choose that data structure answer those kinds of questions so there are lot of things that needs to happen amongst those 50 minutes so make sure that you are not you are managing your time correctly and you know that what are the cases you need to do and you are you need to prepare for on top of that that brings us to our next point do not Overlook the edge cases try to think that what if the given input does not have any value what would be the result then what if there happens to be like a million values for this particular uh use case or this particular input how would your solution approach that is your solution scalable enough or not are you considering all the edge cases so so think about those things and always make sure that you are taking care of all the happy path plus edge cases and my next step is do not write any messy code because many times you would be solving these problems either on a page like Google Docs or maybe if you are in person you would be solving it on a on an actual physical whiteboard where your all your thoughts and your code is all over the place and you get lost of track and you don't realize that where where you have written what and which method or which class is pointing back towards which instance or Which object and then it gets confusing so you that would cost you your time and also it doesn't look good on your uh on your personality as a coder as well next step is always say what you are thinking because the interviewer doesn't like awkward silences it's okay that you you first ask the permission that hey uh can I take maybe 30 seconds or 1 minute to think over this problem that is uh fine that is acceptable but if you are just sitting quiet for long periods of quiet time then those uncomfortable silences doesn't look good on your interview and also it sometimes the interviewer gets the impression that maybe you don't know the answer or you are getting confused always say what you are thinking on top of it always reach out to interviewer if you are stuck at anywhere I have seen at lot of places uh where people don't raise their concerns and if even if they are stuck they don't voice that uh where they are stuck and what are they thinking most of the cases it is acceptable uh and interviewer also predicts that that you might get stuck at some place and they are there to help you they are it's in their interest that you get a job because an interviewer has so many things to do throughout the week and if they are spending 5 hours just speaking with five different candidates it is a major wastage of their time so they want uh they want to have a good candidate who have solid understanding and they would be more than happy to help you out to reach to that end goal but in order to do that the precursor is that you should be able to speak out loud and always mention that what is your thought process how are you processing the problem and what are you currently thinking what are the different options are coming that are coming to your mind so always make sure that you are voicing your thoughts next thing is at least be familiar with one of the programming language it could be Java python go JavaScript whichever you choose make sure that you at least have good command over at least one program programming language because you at the end of the day you would still have to write the code in any language so make sure that you have good understanding of different programming languages also don't become flustered or don't become frustrated if you make any mistakes let's say that I ask you a question and then you started solving and then you went on the wrong path and you went keep on going for five minutes before interviewer corrected you and then now you just you just feel burdened that I wasted 5 minutes on top of it I was not able to come up with the solution and interviewer had to point me back don't think about these thoughts have these thoughts after you done with the interview during the interview just stay focused that okay now at least you have the correct course now let's uh think about moving forward and reaching to the end line and finding that correct optimal solution so that would be the number one thing that your that should be your focus and coming up with that is don't give up even if you don't know the solution at least try to come up with a Brute Force approach see that what would be the most trivial most preliminary approach you can take and once you have the Brute Force approach then you can start building on top of that for that next block or try to see that why brute force is not optimal what are the things it is lacking are we doing a lot of repeated work can we use something else um maybe it's an array and we have to search it all the time in order to find a value can we use a hash map so things like this will pop up if you at least have the basic Brute Force solution so if you can't find any of the Optimal Solutions at least start with the brute force and interviewer would help you navigate through your thought process as well so that would look at at least in better condition that even if you did not knew the answer you still attempted and at least went as far as you got so that that will that can also work in your favor next thing is that do not fail to optimize your solution because many times you would think you would be thinking that hey my solution is the optimal solution and this is the best I can do but try to think about scenarios that okay can can I do better in terms of time complexity U maybe I'm using an additional space can I reduce that additional space and improve upon the space complexity ask these questions to yourself and also voice their answers in the interview towards the interviewer because many times let's say that you are building a great solution or you are using Dynamic program pramming and in order to do that you are actually using an additional hashmap to store all the results but as it turns out that you don't need to store all the results maybe you just need to store couple of results so rather than spending resources on creating an entirely new hashmap you can actually just have two variables and those variables can go through and solve the problem that you that was needed so these are the optimizations is what interviewer is looking for and if you can do that you would be a great candidate in everyone's eyes and the last note I would like to give you is after our interview is done make sure that within 24 to 48 hours at least you are sending a thank you note and after 3 to 5 days you are at least asking that hey what is the status on my application uh maybe they are interviewing other candidates and they haven't made the decision but still you do not want yourself to be uh hiding behind the scenes and not appear at least uh connect with them write a nice thank you email saying that hey thanks for the giving me the time I really like the interview process I learned a couple of new things and whatnot and it it's always going to look good imagine if you are an interviewer how would you feel if the candidate actually sends you a message and saying that thank you for giving me your time I find it productive of course it's going to bring a smile to your face so think about these things and uh I wish you best of luck in your Tech preparation Journey so now we are at the last piece of our our entire course and it has been an incredible journey for me I hope it has been productive for you as well now let me give you some of the important resources that would become quite handy whenever you are trying to prepare for your interviews so first resources at least get a lead code account I'm not saying that get a lead code premium account if you have the financial means for sure if you cannot still at least get your lead code account in line uh and there are some other websites like code Chef hacker rank geek for geeks they are also quite good so if you want you can check those out as well but in either case build the practice of solving the questions and the tech interview questions now first confusion comes in whenever you are you start grinding lead code is that lead code actually has more than 2,000 questions and you are not going to do all of them so the question comes that where can I find the curated list of important questions so I have actually created one list where I have listed down 125 most Tas most uh popular and most like problems from the lead code on top of that I have also curated the data associated with that which means that for any particular question how many companies have asked this that question and how popular that is uh also what is the difficulty level so I'm going to link that uh Google doc in the description as well and that is open to public so anyone can use it that can be a good starting point if you want there are other list available as well like blind 75 or need code 150 they are also pretty good so if you can you you can use that resource second resource I would recommend if you like to read stuff this is a great book that cracking the coding interview this has been the Bible for all the tech interview preparation so if you can buy the book if you cannot there are online copies available as well so you can read those uh and one last thing is don't stop practicing and if you can find a mock interview buddy or group of buddies or some friends or anyone there are some online forums available who also conducts mock interviews because by doing a mock interview number one you would alleviate the pressure of actually being in the interview this would be like a net practice for your actual technical interview preparation Journey uh and if you are playing the role of an interviewer during the mock interview with any of your friend you can also imagine that when your friend responds how as an interviewer you you are also considering or you are also thinking that this is what he's doing right and this is what he's doing wrong and you can build a sort of an expectation that how should I approach any question from interviewer's point of view and that would become that would become greatly advantageous um whenever you are actually appearing for your interviews also if you cannot find Solutions there are very good YouTube channels available so if you want you can go to my channel destination Fang or otherwise if you want you can also go to a channel called need code he is pretty good uh and there are channels by hacker rank that is also pretty good so there are lot of resources available there is no shortage of it uh the only thing is you need to keep on grinding and keep on preparing yourself now at the very last moment I just want to take this time and say thank you thank you to all of you because of your constant motivation I was able to build and make this entire course this is something I never thought I would be able to do but it has been an incredible experience so good luck with your journey and take care
