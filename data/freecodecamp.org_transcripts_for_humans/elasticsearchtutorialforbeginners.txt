With timestamps:

00:00 - Hello everybody today what we want to discuss really interesting topic of web development so for today is going to be elastic search
00:08 - We're going to discuss some basics
00:10 - And specific sorts work and how to integrate properly with knowledge and some other things. So let's start
00:19 - And actually we'll the first question what I believe we need to resolve before we start in section-ally
00:25 - Why do we need is technology at all? There are lots of technologies. Why do we need exactly this one?
00:30 - So what main reason here is?
00:33 - users of her assertion
00:35 - starting from with the simplest
00:38 - landing page and ending with
00:41 - complicated CRM system
00:44 - They want to search because nobody wants to waste their time just searching for content manually. Actually, that's why we have Google
00:52 - So, what does this mean for us common web developers
00:55 - It means well actually storage functionalities, one of the most important things in the entire application
01:02 - So if your search is not responsive enough or a user will tell you for sure I don't want to use your system
01:10 - I'll just go to some other one whereas search will be responsive and fast
01:14 - So we need to think carefully about search we need to optimize it and we need to be sure that it's fast enough
01:21 - for comfort usage
01:24 - Actually here you can tell me okay
01:27 - I can just do select from my favorite sql database and that's it
01:32 - Of course, of course you can do it
01:34 - you can do something like this using like a crater do some conditions between all the parameters that you want to have your
01:41 - result data set
01:43 - But there is one big problem
01:47 - first of all many just I believe almost every
01:52 - SQL databases have small disclaimer inside very documentation about such operations
01:58 - Which will tell you
02:00 - attention this can be
02:02 - Heavy up creation try to avoid usage of this one even know sequel databases like MongoDB have such disclaimers
02:11 - Everything what you should take into account join of data
02:14 - so when you want to do some joint operations, it can make your query even heavier and
02:21 - If you just plan schools two things you'll see immediately if I still have a problem with performance
02:27 - Especially when your data size is large or you need to query many parameters like we have here in test client entry
02:36 - Actually, both two problems are not new ones and
02:42 - Developers of sequel databases try to resolve it by themself how they could do it
02:47 - So some of databases like PostgreSQL that are going to use for today
02:52 - It provides like footage search native
02:58 - You can try to use this one but you'll understand immediately, but but it's like just
03:03 - operators so you can do substitute search for example, and
03:08 - Actually, that's not already
03:10 - Serious enough. I mean nobody wants to search starting from exactly start of string
03:15 - You just want to type something see results and that's it. And
03:19 - Actually, it pushes us and not only ask because many other developers try to resolve those three problems
03:26 - Well first first and second
03:29 - I believe in the first place and with third one is kind of a problem for developers because if you want to use again
03:35 - native in society SQL database you'll see problems immediately and
03:40 - Actually trying to resolve those problems. We created something that is called search engine
03:45 - Actually elastic search is search engine
03:49 - Main purpose of the screen is formatting storing and retrieving of data
03:53 - So yeah, but simple but with one small exception
03:59 - When search engine creates something that is called search index but set of formatted data
04:04 - It uses some smart algorithms to optimize
04:08 - querying for this data
04:11 - just
04:12 - Speeding up your queries for some data a changes order. It can store it in different format
04:18 - And that saturates that right and want to go to events with such algorithms. You can just google one if you're interested in
04:23 - but the main thing here
04:27 - Actually shaped perfectly for assertion in your data
04:32 - And it can do much faster assertion when you will ever do with native sequel
04:39 - simple and instrument tray
04:42 - But actually the solution it seems to be perfect but to use it properly in the first place
04:48 - You need to know your data and of a second one. You need to know your queries
04:52 - So what I'm trying to say here it is not required
04:56 - Really even forbidden just work everything that you'd have inside sushi index
05:01 - So for example even here you can see the difference
05:03 - I have this set
05:05 - of data inside
05:06 - but I query only for some subset from one entry like four six progresses instead of instead of eight and
05:14 - in reality of this subset of a query word
05:17 - It can be even smaller like two three properties from my entire entry to search for
05:23 - And you need to know where well needs of your new user
05:26 - You need to plan it before you start to create search index of rice will fail because again, no magic
05:33 - of course, you have smart algorithms based big things up, but we can speed things up just were like
05:41 - Entry were twenty properties and be efficient. Now you need to plan everything accordingly as for any our technical solutions
05:48 - You need to know your data need to know your queries plan everything accordingly before you start
05:55 - So again before
05:57 - We're before we start with some live example. I want to underline our step for today
06:03 - So it's going to be no jazz was SQL elasticsearch a search engine, and I'm we're on front and side
06:12 - So and
06:13 - actually our
06:15 - Components what we're going to using how they interact with each public
06:19 - So everything starts with front ends request to our API?
06:24 - Like the user wants to search for customers actually
06:28 - customers will have the same data schema as we used for explanation for
06:35 - And actually let's see what happens. So real data. So here I have data grid over both centuries actually
06:43 - designed in minimalistic manner, but anyways, I have around 200 pages so I have
06:50 - 10,000 entries here 50 for each page. So as you can see we have pretty large data set notice or
06:57 - For example, I want to search for some specific country like 1 2 3 4
07:03 - Actually, I should have it somewhere inside account names because I trade it exactly this one
07:08 - So and as you can see data comes immediately just immediately
07:13 - so request is super fast and
07:16 - If you open developer console and check request, you'll find exactly the same
07:24 - Same schema that we used in our chart. So what happened here? I send a request with our search criteria
07:33 - That's how is going to work on your client side. So only thing that you need to provide for the server or relevant
07:41 - Press the cayenne point and some search query version and that's it
07:48 - So let's go back to our chart what happens on API side Beverly?
07:52 - so on the first place API request elasticsearch server, I would your query and
07:59 - The last user server returns you various IDs like unique identifier were all the way interested it found
08:06 - And after you can use it just for query the data from progress. We also know search actions. No substring
08:14 - Nothing is required from your actual database so
08:18 - responsibility for certian fully goes to the elastic search server
08:22 - Your database is just responsible for data storage and getting them back to you. And that's it
08:29 - If you know what I want to underline here as well as you can see word here
08:34 - There's a bit exotic like 9 to 0 0 actually, what's a standard word for elastic search?
08:39 - So if you just install it your server will be up immediately and you can start to use it for indexing
08:49 - So, um, let's tell tell about our workflow actually
08:55 - It's related to data processing
08:58 - So what happens with data processing normally client wants to do a few things of the data music obviously. No so it can request for
09:06 - Create update or delete a country actually read operation already discuss tips or crud is not full here, but nevertheless
09:15 - and what happens here as you can see we want to
09:20 - Operations with data two times
09:22 - I want to underline it two times not one because first of all you want to store something inside your
09:29 - database like paas or SQL
09:31 - kind of straightforward
09:33 - but in other hand you want to store your search index to search for data and
09:40 - Actually one more time. I want to underline it you have data duplication. And actually that's the only way how
09:48 - Search Indexing kind of work you provided some data it stores it separately
09:53 - It optimizes version four B's data chunks and after you retrieve the data from the database
09:59 - That's how it works. And actually it can sound a bit
10:03 - frustrating and complicated because
10:05 - approaches with relational databases
10:08 - Hopefully tell us directly duplication of data is bad
10:11 - well, not really nowadays because well disk space is not so expensive as it used to be and
10:18 - It's not bad when you store some duplicates to increase performance of your application
10:24 - It's kind of widely used practice. So
10:29 - For us that's the only way here used to duplicate of this data here
10:33 - but main question now how to make this approach be easy enough and extendable enough and
10:39 - Not lose a like connection between both two type of data
10:45 - Well at least because if you have data inconsistency, you can have some problems like use port index and elasticsearch
10:52 - but there is no related ID inside progress for this data and in
10:56 - Opposite way it works the same so it can break logic of application
11:01 - and actually
11:04 - We can just provide some middleware so what I'm trying to say here
11:07 - In the common way API just tells your database server Postgres in our case
11:13 - Create update or delete entry with sequel query and with it
11:17 - but in our case
11:19 - We're really good approach would be usage of forum. So
11:24 - object model for our tables not usage sequel immediately from your endpoint
11:29 - Of course, you can of course, if you go to the code and find our and point inside rules
11:37 - So you can see just here. I have only get requests because I don't create anything in application
11:43 - But you can have just post requests next to it and in the first place send sequel query to database for
11:51 - entry creation after you can just send an hour query to
11:55 - Search engine and create index there. Of course you can but we're talking about extendable code which can be
12:03 - Actually extended with extra properties or extra date easily. We've also write in many things
12:10 - that's why I
12:11 - would like to recommend you usage of OM or PostgreSQL ver is a great Orem school supplies so we can try with this one and
12:19 - basically
12:20 - What does this mean for us and the match of the code?
12:23 - Let's look into the model actually model small tutorial for guys who are not familiar with Orem
12:29 - Model is just an object representation of a table. So so so easy basically it represents
12:36 - entry inside of a table and it provides you many mijos to interact with
12:41 - Your data like creation of entries deletion of entries update
12:47 - And some other functionality, but we know what we want to do here. We want to expand functionality but Orem provides to us
12:54 - So in the first place, we want to store some config for our model. For example, we have model customers and
13:02 - I'm going to index only few of our purposes in the data like account name city and country
13:09 - We don't want to store everything. Actually. That's a golden rule of
13:13 - Let's innovate. Hmm actually told you before
13:16 - So you don't want to store everything you want to store only the things what you are going to search for
13:22 - So in the first place we want to extend this
13:26 - Moderate presentation for our data with some configuration for elastic search I believe that's quite understandable
13:35 - The second thing
13:37 - Telev in the trick
13:39 - before
13:40 - We tell our main code part like to API that operation is done
13:47 - Before we do it actually we need to do one extra action kind extension
13:53 - So how it's going to work user requests an update from API or create or delete?
14:00 - you tell - ORM because it's now an interface for our
14:05 - sequel database
14:07 - It's in the first place
14:09 - sends a comment to sequel database with appropriate query to create something or update something or delete or october and
14:18 - Somewhere between and this operation and before we tell API what everything is done even modify user but everything is ok
14:27 - We need to inject one more action. What will go inside elastic search and
14:33 - Create appropriate index for us
14:35 - And actually that's the truth for any operational to want to do like whenever we want to create update or delete
14:42 - entry we will just
14:44 - Do this extra operation?
14:47 - So let's look into the code example how it can be done
14:51 - Actually some of the databases we already have such functionality
14:55 - I'm gonna worms for databases like Mongoose or M. It has special plugin
15:01 - It's Mongoose elastic, and actually it provides setup decorators for models, and they do exactly based thing
15:09 - So what's going to happen here?
15:12 - here we just take
15:15 - Options for our indexing I said you before why do we need them?
15:20 - After ways we are going to say original operation. So original movement
15:25 - already tails and the soul of a magical for sequel database and
15:30 - After we're going to overwrite our original create method
15:37 - with extra action
15:38 - so I
15:39 - What's going to happen here in the first place with a common action original create create entry after your entry is created
15:47 - we're going to take all the required data from the century and
15:52 - Simply index it inside elasticsearch and send exactly the same status that our program
15:59 - To API and that's it
16:02 - And actually you can override any of factions in this manner
16:07 - And with it, so all of your models will Auto index every day that goes for them
16:12 - so what's why I call that middleware because it's it's just between
16:16 - actual requests and database and just
16:20 - mirrors illuminator and
16:23 - you can do the same with for Saoirse quest so you can extend model search functionality as well likes and search and we'll just
16:31 - sensors to your
16:33 - Master engine and absolute will filter results from the database for you. And that's it
16:41 - So
16:42 - one more time how approach this goes user request something from iti you request from om or is
16:50 - extended with
16:54 - Mironova data into the last sip server server
16:57 - first of all, you save data into common data storage up through save it here and
17:02 - It's true for any operation by changing the data
17:08 - So one last thing for today, but I want to tell for you guys is
17:13 - Well, that's basically about silver bullets
17:15 - So there are no silver bullets in development is you obviously know and if you see that massive Sergius doesn't work
17:22 - As you want it to work or you search queries just all that can be kind of primitive
17:28 - More like you search only for one parameter and only in one model and it means it's no reason to integrate 1 over technology
17:35 - If search in your case can be done like with some other way
17:39 - Is like on client only if you have just a really small set of thrush results
17:43 - Well, just get rid of last six your server into the client site. For example, it can be true for
17:49 - Landing page will have just a really small piece of content. You can just return it as
17:55 - An object and filter it there if you see that it won't hire all the traffic
18:00 - but if you have a large set of entries that you need to search through all
18:06 - Volcom elasticsearch on word and try it
18:10 - So, thanks for attention
18:12 - All blinks for code sample and some other materials can be found
18:17 - Under this video. If you have any question for me, please ask me and we can discuss it and delivery solve it
18:24 - So, thanks for attention one more time guys. See you. Bye. Bye

Cleaned transcript:

Hello everybody today what we want to discuss really interesting topic of web development so for today is going to be elastic search We're going to discuss some basics And specific sorts work and how to integrate properly with knowledge and some other things. So let's start And actually we'll the first question what I believe we need to resolve before we start in sectionally Why do we need is technology at all? There are lots of technologies. Why do we need exactly this one? So what main reason here is? users of her assertion starting from with the simplest landing page and ending with complicated CRM system They want to search because nobody wants to waste their time just searching for content manually. Actually, that's why we have Google So, what does this mean for us common web developers It means well actually storage functionalities, one of the most important things in the entire application So if your search is not responsive enough or a user will tell you for sure I don't want to use your system I'll just go to some other one whereas search will be responsive and fast So we need to think carefully about search we need to optimize it and we need to be sure that it's fast enough for comfort usage Actually here you can tell me okay I can just do select from my favorite sql database and that's it Of course, of course you can do it you can do something like this using like a crater do some conditions between all the parameters that you want to have your result data set But there is one big problem first of all many just I believe almost every SQL databases have small disclaimer inside very documentation about such operations Which will tell you attention this can be Heavy up creation try to avoid usage of this one even know sequel databases like MongoDB have such disclaimers Everything what you should take into account join of data so when you want to do some joint operations, it can make your query even heavier and If you just plan schools two things you'll see immediately if I still have a problem with performance Especially when your data size is large or you need to query many parameters like we have here in test client entry Actually, both two problems are not new ones and Developers of sequel databases try to resolve it by themself how they could do it So some of databases like PostgreSQL that are going to use for today It provides like footage search native You can try to use this one but you'll understand immediately, but but it's like just operators so you can do substitute search for example, and Actually, that's not already Serious enough. I mean nobody wants to search starting from exactly start of string You just want to type something see results and that's it. And Actually, it pushes us and not only ask because many other developers try to resolve those three problems Well first first and second I believe in the first place and with third one is kind of a problem for developers because if you want to use again native in society SQL database you'll see problems immediately and Actually trying to resolve those problems. We created something that is called search engine Actually elastic search is search engine Main purpose of the screen is formatting storing and retrieving of data So yeah, but simple but with one small exception When search engine creates something that is called search index but set of formatted data It uses some smart algorithms to optimize querying for this data just Speeding up your queries for some data a changes order. It can store it in different format And that saturates that right and want to go to events with such algorithms. You can just google one if you're interested in but the main thing here Actually shaped perfectly for assertion in your data And it can do much faster assertion when you will ever do with native sequel simple and instrument tray But actually the solution it seems to be perfect but to use it properly in the first place You need to know your data and of a second one. You need to know your queries So what I'm trying to say here it is not required Really even forbidden just work everything that you'd have inside sushi index So for example even here you can see the difference I have this set of data inside but I query only for some subset from one entry like four six progresses instead of instead of eight and in reality of this subset of a query word It can be even smaller like two three properties from my entire entry to search for And you need to know where well needs of your new user You need to plan it before you start to create search index of rice will fail because again, no magic of course, you have smart algorithms based big things up, but we can speed things up just were like Entry were twenty properties and be efficient. Now you need to plan everything accordingly as for any our technical solutions You need to know your data need to know your queries plan everything accordingly before you start So again before We're before we start with some live example. I want to underline our step for today So it's going to be no jazz was SQL elasticsearch a search engine, and I'm we're on front and side So and actually our Components what we're going to using how they interact with each public So everything starts with front ends request to our API? Like the user wants to search for customers actually customers will have the same data schema as we used for explanation for And actually let's see what happens. So real data. So here I have data grid over both centuries actually designed in minimalistic manner, but anyways, I have around 200 pages so I have 10,000 entries here 50 for each page. So as you can see we have pretty large data set notice or For example, I want to search for some specific country like 1 2 3 4 Actually, I should have it somewhere inside account names because I trade it exactly this one So and as you can see data comes immediately just immediately so request is super fast and If you open developer console and check request, you'll find exactly the same Same schema that we used in our chart. So what happened here? I send a request with our search criteria That's how is going to work on your client side. So only thing that you need to provide for the server or relevant Press the cayenne point and some search query version and that's it So let's go back to our chart what happens on API side Beverly? so on the first place API request elasticsearch server, I would your query and The last user server returns you various IDs like unique identifier were all the way interested it found And after you can use it just for query the data from progress. We also know search actions. No substring Nothing is required from your actual database so responsibility for certian fully goes to the elastic search server Your database is just responsible for data storage and getting them back to you. And that's it If you know what I want to underline here as well as you can see word here There's a bit exotic like 9 to 0 0 actually, what's a standard word for elastic search? So if you just install it your server will be up immediately and you can start to use it for indexing So, um, let's tell tell about our workflow actually It's related to data processing So what happens with data processing normally client wants to do a few things of the data music obviously. No so it can request for Create update or delete a country actually read operation already discuss tips or crud is not full here, but nevertheless and what happens here as you can see we want to Operations with data two times I want to underline it two times not one because first of all you want to store something inside your database like paas or SQL kind of straightforward but in other hand you want to store your search index to search for data and Actually one more time. I want to underline it you have data duplication. And actually that's the only way how Search Indexing kind of work you provided some data it stores it separately It optimizes version four B's data chunks and after you retrieve the data from the database That's how it works. And actually it can sound a bit frustrating and complicated because approaches with relational databases Hopefully tell us directly duplication of data is bad well, not really nowadays because well disk space is not so expensive as it used to be and It's not bad when you store some duplicates to increase performance of your application It's kind of widely used practice. So For us that's the only way here used to duplicate of this data here but main question now how to make this approach be easy enough and extendable enough and Not lose a like connection between both two type of data Well at least because if you have data inconsistency, you can have some problems like use port index and elasticsearch but there is no related ID inside progress for this data and in Opposite way it works the same so it can break logic of application and actually We can just provide some middleware so what I'm trying to say here In the common way API just tells your database server Postgres in our case Create update or delete entry with sequel query and with it but in our case We're really good approach would be usage of forum. So object model for our tables not usage sequel immediately from your endpoint Of course, you can of course, if you go to the code and find our and point inside rules So you can see just here. I have only get requests because I don't create anything in application But you can have just post requests next to it and in the first place send sequel query to database for entry creation after you can just send an hour query to Search engine and create index there. Of course you can but we're talking about extendable code which can be Actually extended with extra properties or extra date easily. We've also write in many things that's why I would like to recommend you usage of OM or PostgreSQL ver is a great Orem school supplies so we can try with this one and basically What does this mean for us and the match of the code? Let's look into the model actually model small tutorial for guys who are not familiar with Orem Model is just an object representation of a table. So so so easy basically it represents entry inside of a table and it provides you many mijos to interact with Your data like creation of entries deletion of entries update And some other functionality, but we know what we want to do here. We want to expand functionality but Orem provides to us So in the first place, we want to store some config for our model. For example, we have model customers and I'm going to index only few of our purposes in the data like account name city and country We don't want to store everything. Actually. That's a golden rule of Let's innovate. Hmm actually told you before So you don't want to store everything you want to store only the things what you are going to search for So in the first place we want to extend this Moderate presentation for our data with some configuration for elastic search I believe that's quite understandable The second thing Telev in the trick before We tell our main code part like to API that operation is done Before we do it actually we need to do one extra action kind extension So how it's going to work user requests an update from API or create or delete? you tell ORM because it's now an interface for our sequel database It's in the first place sends a comment to sequel database with appropriate query to create something or update something or delete or october and Somewhere between and this operation and before we tell API what everything is done even modify user but everything is ok We need to inject one more action. What will go inside elastic search and Create appropriate index for us And actually that's the truth for any operational to want to do like whenever we want to create update or delete entry we will just Do this extra operation? So let's look into the code example how it can be done Actually some of the databases we already have such functionality I'm gonna worms for databases like Mongoose or M. It has special plugin It's Mongoose elastic, and actually it provides setup decorators for models, and they do exactly based thing So what's going to happen here? here we just take Options for our indexing I said you before why do we need them? After ways we are going to say original operation. So original movement already tails and the soul of a magical for sequel database and After we're going to overwrite our original create method with extra action so I What's going to happen here in the first place with a common action original create create entry after your entry is created we're going to take all the required data from the century and Simply index it inside elasticsearch and send exactly the same status that our program To API and that's it And actually you can override any of factions in this manner And with it, so all of your models will Auto index every day that goes for them so what's why I call that middleware because it's it's just between actual requests and database and just mirrors illuminator and you can do the same with for Saoirse quest so you can extend model search functionality as well likes and search and we'll just sensors to your Master engine and absolute will filter results from the database for you. And that's it So one more time how approach this goes user request something from iti you request from om or is extended with Mironova data into the last sip server server first of all, you save data into common data storage up through save it here and It's true for any operation by changing the data So one last thing for today, but I want to tell for you guys is Well, that's basically about silver bullets So there are no silver bullets in development is you obviously know and if you see that massive Sergius doesn't work As you want it to work or you search queries just all that can be kind of primitive More like you search only for one parameter and only in one model and it means it's no reason to integrate 1 over technology If search in your case can be done like with some other way Is like on client only if you have just a really small set of thrush results Well, just get rid of last six your server into the client site. For example, it can be true for Landing page will have just a really small piece of content. You can just return it as An object and filter it there if you see that it won't hire all the traffic but if you have a large set of entries that you need to search through all Volcom elasticsearch on word and try it So, thanks for attention All blinks for code sample and some other materials can be found Under this video. If you have any question for me, please ask me and we can discuss it and delivery solve it So, thanks for attention one more time guys. See you. Bye. Bye
