With timestamps:

00:00 - AWS cloud development kit is an open source 
tool that allows developers to use their  
00:05 - favorite programming languages to write 
infrastructures code for AWS, Matt marks is  
00:10 - an AWS community builder, and he will teach you 
how to use the AWS cloud development kit. Hey,  
00:16 - I'm Matt Mart's. And I'm Brian. And I'm an 
AWS community builder. And I'm here to give  
00:23 - you a CDK Crash Course from Free Code Camp. You 
might be here because you're tired of manually  
00:31 - provisioning your resources via the console. 
Or maybe like me, you hate writing yaml.  
00:37 - But CDK has also been in the news a lot lately. In 
December, version two became generally available.  
00:43 - Version two was a massive improvement over version 
one, since there is only one stable NPM library to  
00:48 - install, instead of one for each module. Among 
other improvements, CDK was also featured fairly  
00:56 - prominently in Dr. Vogel's reinvent keynote. 
And the CDK book was released. The CDK book  
01:03 - was written by a bunch of the AWS heroes, and 
it will go into greater depth than what will  
01:07 - be covered in this crash course, there will be 
overlap, but I still strongly recommend the book.  
01:14 - So what will we cover in this course, I'm going to 
start by going over the basics of CDK definitions  
01:21 - of the app stacks, constructs and how it all 
relates to CloudFormation. Then I'm going to do a  
01:28 - 30 minute speed run of the CDK workshop, which is 
a workshop provided by AWS, and it's available at  
01:36 - CDK workshop.com. From there, we'll go into some 
advanced topics like testing and best practices.  
01:46 - This course is split up into chapters on YouTube. 
So if there are particular areas of interest,  
01:52 - feel free to jump around. I'll also provide 
timestamp links in the description with  
01:58 - supplemental information. This will include useful 
documentation, blogs, links, or anything else.  
02:06 - I'm going to go through the CDK workshop very 
quickly, but you should do it yourself. The best  
02:12 - way to learn about CDK is by using it. And since 
this is a YouTube video, feel free to speed me up,  
02:20 - slow me down, or rewatch sections if you need to.  
02:24 - If you think I've missed something in this crash 
course, or you didn't understand something, let me  
02:29 - know in the comments or follow me on Twitter and 
reach out there. I'll be happy to help. Here are  
02:36 - a few other resources I'd like to specifically 
call out. The CDK community on Slack is very  
02:42 - active. It's full of friendly, knowledgeable 
people that love to help out. The authors of the  
02:46 - CDK book are also very active there. Speaking 
of Did you hear there's a CDK book out now.  
02:54 - Aside from that, there's also CBK day which 
is an annual conference related to CDK.  
03:00 - Last year, I gave a 15 minute 
lightning talk on creating verifiable  
03:04 - jots with CDK. And I'll add a link to that below.  
03:09 - And with that out of the way, I hope you're in 
the right place. Let's move on to the basics.  
03:16 - CDK stands for cloud development kit. 
It's open source software provided by AWS  
03:23 - that enables you to write imperative code to 
generate declarative CloudFormation templates.  
03:29 - It enables you to define the how so that you can 
get the what that means you can focus more on  
03:36 - the architecture of your app instead of the nitty 
gritty details of IAM roles and policy statements.  
03:42 - CDK is available in JavaScript, TypeScript, 
Python, Java, C sharp, and it's in a developer  
03:49 - preview for go CDK itself is no GS based. 
Even if you use one of the other languages,  
03:57 - the CDK code itself will be executed 
via no GS. So no J S is a requirement.  
04:05 - Okay, so CDK generates CloudFormation. But what's 
that cloud formation is an AWS service that  
04:14 - provisions AWS resources and stacks. AWS 
resources are things like lambda functions,  
04:20 - s3, buckets, DynamoDB, tables, pretty much 
anything that AWS offers. A CloudFormation stack  
04:27 - is just a collection of AWS resources. Cloud for 
me, CloudFormation uses JSON or YAML files as a  
04:34 - template that describes the intended state of all 
the resources you need to deploy your application.  
04:40 - The stack implements and manages the group 
of resources outlined in your template  
04:45 - and it allows the state and dependencies 
of those resources to be managed together.  
04:50 - When you update a CloudFormation 
template, it creates a change set.  
04:54 - A change set is a preview of changes that 
will be executed by stack operations to create  
05:00 - Update or remove resources so 
that the template becomes in sync.  
05:07 - So CDK generates cloud formation and cloud 
formation provisions, AWS resources. What does  
05:13 - the CDK app look like and how does it relate? The 
root of CDK is the CDK app. It's a construct that  
05:22 - coordinates the lifecycle of the stacks within it. 
There is no CloudFormation equivalent for an app.  
05:28 - Within the app, you can have multiple CDK stacks, 
and CDK stacks can even have nested stacks.  
05:35 - CDK stacks are one to one equivalent 
with CloudFormation stacks,  
05:39 - and nested stacks are also one to one equilibrium 
equivalent with CloudFormation stacks. When you  
05:45 - run CDK, synth or CDK deploy the output is the 
CloudFormation template for this app structure.  
06:00 - The CDK app is a special route construct 
that orchestrates the lifecycle of the stacks  
06:05 - and the resources within it. The app lifecycle 
constructs the tree of the app in a top down  
06:11 - approach, and then it executes the methods for 
the constructs within it. You typically don't need  
06:18 - to directly interface with any of the prepare, 
validate or synthesize methods of the constructs,  
06:23 - but they can be overridden. The final stage 
of the apps lifecycle is the deploy phase,  
06:29 - where the cloud formation artifact is uploaded to 
cloud formation. The unit of deployment in CDK is  
06:37 - called a stack. All resources defined within the 
scope of a stack, either directly or indirectly,  
06:44 - are provisioned as a single unit CDK stacks have 
the same limitations as CloudFormation stacks.  
06:51 - Stacks are powerful in cloud formation. In order 
to deploy a template to multiple environments,  
06:56 - you need to use cloud formation parameters. 
But these are only resolved during deployment.  
07:02 - In cloud formation, if you want to conditionally 
include a resource based on a parameter,  
07:07 - you have to use the CloudFormation condition. 
But in CDK, you don't have to use either, you  
07:13 - can simply use an if statement to check a value 
whether the resource should be defined or not,  
07:18 - it ends up being much simpler. You can use cloud 
formation parameters and conditions in CDK. But  
07:26 - they're discouraged since they only resolve during 
deployment, which is well after CDK synthesis.  
07:36 - We've heard a lot about 
constructs. But what are they?  
07:39 - There are four levels of constructs. Level 
zero constructs are just basic resources.  
07:45 - All of the higher levels inherit from level 
zero, there's no specific type tied to it.  
07:51 - Level one constructs are one to one 
representations of CloudFormation resources.  
07:56 - They are all prefixed in the CDK API with 
the letters C F n, we which is a short form  
08:03 - of CloudFormation. The way I remember this is 
level one is one to one with CloudFormation.  
08:11 - Level two constructs aren't improved 
or extended level one constructs.  
08:16 - They're provided by the CDK team and offer 
helper methods and sensible defaults.  
08:21 - Level three constructs are 
combinations of constructs,  
08:26 - which could be an intermingling of level 
one, two and three constructs together.  
08:31 - More often than not, you'll be interacting 
with level two or three constructs.  
08:36 - Some modules in CDK don't have level two 
constructs yet. But pretty much all of the  
08:41 - level one constructs exist for the corresponding 
CloudFormation API. The CDK team is very fast at  
08:47 - implementing changes to level one constructs 
and more frequently used level two constructs.  
08:54 - for level one construct, let's look at the access 
analyzer module. In this case, the module doesn't  
09:01 - have any level two constructs available, so 
there's only the level one CFN analyzer construct.  
09:09 - As you can see, this is a one to one 
representation with the CloudFormation API.  
09:16 - The CFN analyzer construct has the same properties 
defined as the CloudFormation API for the same.  
09:24 - There are also new helper utility 
methods on the CFN analyzer construct.  
09:31 - For level two construct, let's look 
at the DynamoDB table construct.  
09:36 - It doesn't have a CFN prefix and 
includes many sensible defaults.  
09:40 - For example, the billing mode defaults to pay per 
request, unless you specify replication regions.  
09:48 - If you specify replication regions, it becomes 
provisioned and if it becomes provisioned,  
09:54 - the default Read and Write capacities get 
set and defaulted to five The default removal  
10:00 - policy of the table is retained. And the 
table has helper methods to create global  
10:07 - or local secondary indexes, and to create varying 
levels of access to the table and it streams.  
10:16 - For level three constructs, the CDK doesn't offer 
anything specific out of the box. These tend to  
10:23 - be created at the individual organization or 
community level, and provided as libraries.  
10:30 - An example level three construct would be 
to create a notifying bucket. This construct  
10:35 - creates an s3 bucket along with an SNS topic. 
It then adds an object created notification  
10:42 - coming from the s3 bucket to target the SNS 
topic. All you have to do to use this is add  
10:49 - a new notifying bucket to your app. And it will 
provision all of these resources automatically.  
10:55 - There are several great resources in the 
community that I'd also like to call out. CDK  
11:03 - patterns.com is a resource that enables you 
to search by community provided examples,  
11:08 - and it's cross referenced by the different 
components used within it. AWS also offers another  
11:17 - open source extension of the CDK with their AWS 
solutions constructs. These provide multi service  
11:24 - well architected patterns for quickly defining 
solutions in code for frequently used patterns.  
11:31 - This is available as an NPM library that you 
can install and use right out of the box.  
11:40 - There's also the construct hub. The construct 
hub is a central destination for discovering  
11:45 - and sharing cloud application design patterns 
and reference architectures designed for CDK  
11:51 - CDK for Kubernetes, and CDK. For TerraForm, and 
other construct based tools, construct hub pulls  
12:00 - from the NPM registry, all CDK constructs that 
support multiple languages and are correctly  
12:06 - annotated. Great. So I think we have a handle 
on constructs. Now, let's go a little deeper.  
12:15 - How do we generate the CloudFormation template. In 
order to do that the app needs to be synthesized.  
12:24 - To do this, we can run CDK. Since this 
traverses the app tree and invokes synthesize  
12:30 - on all of the constructs, this ends up generating 
unique IDs for the CloudFormation resources  
12:36 - and generates the respective EML 
along with any assets that are needed.  
12:44 - Okay, so what are assets? Assets 
are the files bundled into CDK apps.  
12:51 - They include things like the lambda handler 
code, Docker images, layer versions, files,  
12:57 - going into an s3, bucket, etc. They can 
represent any artifact that the app needs.  
13:05 - When you run CDK synth or deploy, these get output 
to a CDK dot out folder on your local machine.  
13:14 - Okay, so what does CDK do with these assets? How 
do they get put into CloudFormation? Well, that's  
13:22 - where bootstrapping comes into play. Bootstrapping 
creates a CDK toolkit cloud formation stack  
13:28 - deployed to your account. This account includes 
an s3 bucket and various permissions that are  
13:34 - needed for CDK to do the deployments and upload 
the assets. bootstrapping is required when your  
13:40 - app has assets or your CloudFormation templates 
become larger than 50 kilobytes. So it's pretty  
13:46 - much always required, you're almost always 
going to have some sort of asset in your stack.  
13:52 - For CDK version to administrator access is needed 
to create the roles that CDK toolkit stack needs  
13:59 - in order to do deployments. You won't need 
administrator access after CDK is bootstrapped.  
14:08 - With the bootstrapping done, 
we can move on to deploying.  
14:12 - When you run CDK deploy, the app is 
initialized or constructed into an app tree.  
14:19 - Once the construction is done, the app goes 
through preparation, validation and synthesize  
14:24 - steps. So each construct calls its prepare method, 
then each construct calls its validate method. And  
14:31 - then each construct calls its synthesized method. 
Up to this point, this is what CDK sent us.  
14:39 - From there, the app uploads the template and any 
other artifacts to cloud formation, and cloud  
14:45 - formation deployment begins. Once this handoff 
is done, it's all in the hands of CloudFormation.  
14:54 - Now that we've defined some of the basic 
pieces of CDK let's move on to the workshop.  
14:59 - The word stops at CDK workshop calm. You 
should do this first and then come back.  
15:08 - Perfect. Once you come back, we'll do the 
30 Minute speed round through the workshop.  
15:12 - We're gonna get started with this workshop 
by creating a cloud nine environment.  
15:16 - To do that, I'm going to steal some instructions 
from the CDK pipelines workshop, it's going to  
15:20 - have a screen and I enroll for Cloud Nine that 
has full access. This is going to be used in  
15:24 - bootstrapping the account for CDK. Version two 
links for the CDK pipelines workshop will be in  
15:29 - the description below. It's a great workshop and 
you should work through it if you have the time.  
15:35 - First, we're going to go to the cloud 
nine console and create an environment.  
15:40 - I'm just going to name it CDK workshop, 
and we don't need a description.  
15:45 - Then we select an instance type, I did this 
workshop with a T three small instance. But the  
15:49 - M five large would probably be better. All 
the other options can use the defaults.  
15:55 - While CLOUD NINE spins up, I want to note 
that both the T three small and N five large  
15:58 - instances are not free tier eligible. So it might 
cost you some money. I was getting some memory  
16:04 - errors towards the end with the T three small 
instance. But it still worked. To create the  
16:09 - I am role. The CDK pipelines workshop has a deep 
link that will take you to the role creation page.  
16:16 - From there, we confirm that it's AWS service 
entity and for easy to and then go to permissions.  
16:23 - Make sure that administrator access is selected. 
We don't need new tags, so we can skip that.  
16:31 - And then we're going to give it a name, we're 
going to name this CDK admin and create the role.  
16:42 - With the role created, we can go back to the CDK 
pipeline workshop and see that we need to actually  
16:48 - go in and attach the roll to the EC two instance. 
There is a deep link. But since we had named  
16:54 - the EC two instance, something else we actually 
need to go to the EC to console, go to instances.  
17:02 - And then select the instance that with 
our cloud nine instance that's running.  
17:08 - Go to actions, security and modify Iam role.  
17:16 - From here we're going to select the IAM roles 
that we just created CDK admin and save it.  
17:23 - Now if we go to the CDK workshop, Cloud Nine 
and refresh, it will automatically have the role  
17:30 - that we need. Next, we need to do some cloud nine 
housekeeping and setup, we're going to remove the  
17:37 - AWS manage temporary credentials. These prevent 
us from using the role that we attached to the  
17:42 - Cloud Nine easy to instance, in the upper 
right corner of cloud nine, go to settings  
17:49 - and then scroll down to AWS settings and 
turn off AWS manage temporary credentials.  
17:56 - To make doubly sure that the credentials are gone, 
we're going to remove the credentials folder.  
18:09 - Next, we're going to do some environment 
config, we need to install JQ using yum.  
18:23 - And then we're going to export some environment 
variables with AWS account information.  
18:37 - To check to make sure that the AWS region was set 
correctly, we're going to do this test command.  
18:50 - And finally, we're going to export the account  
18:53 - ID and region and make sure 
AWS is configured correctly.  
19:02 - Now we need to make sure that Cloud Nine 
is easy to instances using the right a  
19:06 - Iam role. To do that, we're going to use this STS 
get color identity command. It's gonna fail here  
19:13 - because we actually named the role CDK admin. So 
if we update the command to check for CDK admin,  
19:20 - we'll get the that the im role is valid like this.  
19:32 - At this point, we can switch back to the actual 
CDK intro workshop. We're going to go to the  
19:39 - prerequisites tab and start checking things to 
make sure that everything is like it should be.  
19:50 - The AWS CLI is already installed and we've 
already set up the AWS account and user.  
19:57 - Next we want to make sure that we have a 
good node version installed In Cloud Nine,  
20:02 - CLOUD NINE comes with Node installed. 
So let's just check the version.  
20:08 - And here version 16 is fine. We're 
also gonna want to check CDK.  
20:13 - Now, this is a CDK to workshop. So we want 
to make sure that we actually bumped up  
20:19 - the version of CDK. So if we 
do NPM i for install AWS CDK.  
20:26 - Globally, we're gonna get this error because he's 
the Cloud Nine instance of easytouse weird, so you  
20:31 - actually have to force it. In this case, the CDK 
pipeline tutorial also goes through this as well.  
20:39 - Now that we've forced installed it, we 
can see that version 2.3 is installed.  
20:49 - We're already using AWS cloud nine, we 
just checked the CDK version. And that  
20:56 - concludes the prerequisites. Next, 
we can begin the actual workshop.  
21:07 - So let's get started, we'll go to the 
CDK. And next step, the first thing we  
21:12 - need to do is create a directory to work in. 
So we're gonna make the CDK workshop directory  
21:20 - and change into it. Now we need 
to actually admit the project. So  
21:27 - we're gonna run CDK and it sample 
app with the language TypeScript.  
21:36 - This creates a Git repo, and NPM installs all 
the dependencies for a basic CDK two project  
21:46 - CDK two is a massive improvement over CDK 
version one because it bakes in all of the  
21:51 - stable modules into one NPM dependency CDK version 
one had individual NPM libraries for each module  
21:58 - like DynamoDB, lambda SNS, etc. In version two, 
you just have one, and that avoids a lot of the  
22:04 - dependency management hell. Now that the thug 
project is initialized to CDK workshop is going to  
22:10 - want us to run the watch command in the background 
to compile the TypeScript into JavaScript.  
22:22 - So we're going to create a new terminal, 
change directories into the project folder,  
22:28 - and then run the NPM run watch 
command in the background.  
22:42 - With that done, we can move on to 
the next step and actually check  
22:47 - out the project structure of what 
was what's been initialized so far.  
22:52 - So let's go back to the Cloud Nine environment, 
we'll open up the project folder, and let's start  
22:58 - looking at some files. Let's start where 
CDK starts with the bin slash CDK workshop  
23:05 - TypeScript file. This file instantiates the 
CDK app by creating stacks. That is to say,  
23:11 - when you run CDK center CD kit, boy, it starts 
here to generate the CloudFormation templates.  
23:18 - CDK stacks are one to one equivalent with 
CloudFormation stacks. An app can have multiple  
23:24 - stacks, and each stack would end up creating 
a new stack in cloud formation. In the case  
23:28 - of our sample app, there's only one stack, the 
CDK workshop stack. So let's look at that next.  
23:35 - The sample stack is pretty simple. It uses 
two level two constructs. One to create an  
23:41 - SQ SQ and one to create an SNS topic, then 
subscribes the queue to the topic. That's  
23:48 - it. The workshop goes into similar detail with 
these. But let's move on to our first CDK synth.  
23:56 - As described before, when CDK apps are executed, 
they produce an AWS CloudFormation template for  
24:02 - each stack defined in the app. Switching back 
to cloud nine, let's run CDK Seth, I'm going to  
24:07 - output to a template dot Yamo file to make it 
a little easier to read. Now, there are two  
24:13 - important concepts I want to call out here. CDK is 
both imperative it describes the how the app will  
24:19 - be built. But it's also item potent, given the 
same inputs, it will produce the same outputs.  
24:29 - See here, we use the same code between the 
CDK workshop in my cloud nine instance.  
24:34 - And the cloud formation that was generated as 
the same. For example, the resource hash hashes  
24:39 - match between the two. This is because we used 
all the same inputs that the CDK workshop did.  
24:45 - If I went and change the topic or cue ID, the 
hash would change and we'd have something else.  
24:50 - This is going to be important 
in unit testing later.  
24:54 - Now that we've sent, let's deploy. In order 
to do that we need to bootstrap the account  
25:05 - Let's open up a new console window and 
go to cloud formation. And this account,  
25:08 - the only one running right now should 
be the one that's used for cloud nine.  
25:15 - Right here. So let's go back to the Cloud 
Nine terminal and run the Bootstrap.  
25:25 - This is why we needed to create an im role 
with administrator access. And it's actually  
25:29 - the only time you need admin access when you're 
bootstrapping the account. In order for CDK,  
25:35 - to deploy apps, it needs to store 
the assets somewhere. The Bootstrap  
25:39 - creates its own cloud formation template that 
we'll see when we go back to cloud formation.  
25:45 - And that includes a number of roles and policies 
that enable it to store assets for deployment.  
26:35 - As you can see here, the CDK toolkit stack 
was just created from the bootstrap process.  
26:44 - Now, if we switch back to cloud nine, 
we can actually run the deploy command.  
26:53 - The deploy command resynthesize is the 
app. And if there's any IAM policy changes  
27:02 - in the census, it will display them and ask 
to make sure that you want to continue. Here,  
27:10 - since we're subscribing the queue to the 
topic, a IAM policy needs to be in place  
27:18 - in order to make that happen. So yeah, we 
do want that to happen. So let's deploy it.  
27:27 - While CloudFormation is spinning up, if we 
refresh CloudFormation, we'll see the CDK  
27:31 - workshop stack create is in progress. And we can 
actually view the resources as they're created.  
27:37 - So here we can see that there's a metadata 
entry along with the queue and topic,  
27:41 - but there's no actual subscription 
yet or policies related to it.  
27:52 - Now that the crate is complete, we 
can go back to the resources and see  
27:56 - that yes, there is a queue 
policy and a subscription.  
28:08 - Well, that was fun. But now 
let's get her hands dirty.  
28:12 - The CDK workshop is going to take you through a 
couple steps at this point. We're going to clean  
28:16 - up the stack by removing the SNS topic and the SQ 
sq. And then we're going to create a simple API  
28:23 - gateway backed by lambda. So let's get started. 
We're going to delete the sample code from our  
28:28 - stack. And then we're going to do a diff to 
see what it shows. Go back to the stack file.  
28:39 - And delete the queue topic and the topic 
that adds description along with the imports.  
28:54 - That are on the CDK diff command.  
29:03 - What CDK diff does is it re synthesizes the  
29:06 - CloudFormation app and compares the yam all 
from one to the other. And we can see here  
29:13 - that it's destroying the queue queue 
policy subscription and the topic.  
29:20 - Next we can CDK deploy as it's deploying,  
29:28 - the only thing that the CloudFormation stack 
should be left with is the CDK metadata entry.  
29:38 - Till we go back to cloud formation, we can check  
29:41 - the progress of this by refreshing 
the resources as it is progressing.  
29:58 - They're done Now let's go back to cloud nine 
and create the lambda. We'll create a folder  
30:06 - called lambda, and put a hello.js file in it.  
30:18 - Inside of that, we'll put some basic lambda code. 
Next, we need to create the lambda in the stack,  
30:24 - we'll add the lambda import from CDK to 
then create the actual lambda function.  
30:32 - One of the biggest benefits of creating AWS 
resources using CDK is the IntelliSense.  
30:37 - Having imported from AWS lambda, I can create 
a new function using new lambda dot function,  
30:44 - pass the stack and ID of the lambda 
in and give it some properties.  
30:54 - In this case, we needed to find the runtime using  
31:02 - lambda.runtime.no, Gs 14 where the code 
lives, which we use code dot from asset  
31:16 - and then lambda, which uploads the 
lambda folder as an asset to s3.  
31:23 - And then they were the handlers. In 
this case, our handlers and Hello,  
31:28 - the Hello file, and it's named handler. Now 
we can run the diff. And this will show us  
31:35 - that it's going to create a im role for 
the lambda and the lambda function itself.  
31:48 - Which this looks good to me. So let's just deploy 
it. I'm going to speed this part up a little bit.  
32:13 - And we can see the function and the role in cloud 
formation. So let's test out the lambda itself. In  
32:25 - the code source area of the lambda console, we can 
create a test event by clicking the test button.  
32:36 - We'll select API gateway AWS proxy, because 
ultimately, we'll be connecting this to an  
32:41 - API gateway. Don't forget to give 
it a name. And doesn't like spaces.  
32:52 - And hit create. What do we get test 
again, it'll invoke the lambda.  
32:57 - And now we can see the status of 200. And 
that the body has the correct response.  
33:04 - So let's add an API gateway. First, we'll 
import the API gateway module from CDK.  
33:16 - And then we'll create a lambda REST 
API. Lambda rest API's are just rest  
33:24 - API's with a greedy proxy that sends 
everything to the defined lambda.  
33:30 - We'll pass in the stack construct 
and give the REST API an ID.  
33:36 - And then we'll tell it our hello 
function as the API handler.  
33:48 - Now we can run a diff. And I'll also show that 
there's actually no API gateway already defined  
33:57 - by going to the API gateway 
console. And here, there's no API's.  
34:13 - So let's deploy it. I'm going to speed 
this up again. But what it's doing is  
34:23 - it's creating a bunch of resources 
automatically. There's the API gateway  
34:28 - itself permissions for the gateway, and 
for it to invoke the lambda, etc, etc.  
34:45 - Now that it's done, we can see we went from 
three resources to 15 in CloudFormation. And  
34:52 - this was all handled with a couple lines of 
code. And if I go and refresh the lambda page  
35:04 - We can see that the API gateway is added 
to the lambda console as a trigger.  
35:11 - Similar, we can see the API is 
defined on the API gateway console.  
35:18 - So let's test it. We'll grab the API URL that 
was automatically output as part of the deploy,  
35:29 - and send it a curl request. 
Nice. And let's try another one.  
35:41 - Very nice.  
35:48 - All we've done so far is use a few level two 
constructs. Let's make our own level three  
35:53 - construct. We'll make an interceptor lambda that 
writes to the DynamoDB table, and then invokes any  
35:59 - targeted downstream lambda. Let's get started. 
We'll create a new hit counter type script file  
36:10 - in the lib folder, and put 
some boilerplate construct code  
36:17 - in here. All this does is extend 
the construct and to find the props.  
36:23 - Next, let's create our interceptor lambda 
and the lambda folder, we'll create  
36:28 - hit counter dot j, s. And we'll copy 
the code over from the workshop.  
36:35 - what this code does is it uses two modules from 
the AWS SDK to interact with both Dynamo DB and  
36:41 - lambda will use Update Item from Dynamo DB to 
increment a hit counter for a path. And we'll use  
36:48 - the lamda client to invoke the downstream lambda, 
and then return the response from that lambda  
36:54 - with the table and lambda will be passed into 
this interceptor lambda via environment variables.  
37:04 - Now that that's done, we need to 
create both the table and the lambda,  
37:08 - we'll add the DynamoDB module from 
CDK. And then create the table  
37:18 - using new DynamoDB dot table, we'll pass in 
the stack construct and give the table an ID.  
37:27 - And DynamoDB also needs to define a partition 
key. So we'll go ahead and do that as well.  
37:37 - Next, we'll create the lambda, this 
follows the same pattern as before  
37:46 - do lambda dot function, pass in this give it 
a ID and set the runtime which is no Jess.  
38:11 - The handler, which in this 
case is hit counter dot handler  
38:21 - and then the code coming from 
code dot from asset lambda  
38:30 - we need to pass in the environment variables.  
38:34 - And I'll make a tweak to the lambda Id 
just to be consistent with the workshop.  
38:41 - Now we're going to want to expose the lamda 
as a read only property of the construct.  
38:46 - So add this Public Read Only line to the class. 
And we'll assign the lambda to the property.  
38:55 - Now this construct is great as is, 
but it's not being used anywhere.  
38:59 - So let's fix that. We'll go 
back to the main workshop stack.  
39:08 - And use the construct. It's the same 
pattern as a level two construct.  
39:14 - So we can do a new hit counter 
pass in the stack, give it an ID.  
39:23 - And in our case, the properties here is the 
downstream lambda that we want to invoke. So we'll  
39:28 - set downstream to Hello. And I will do a trick 
to import the hit counter from the local file.  
39:40 - But now we need to make the API use this 
lambda instead. So we will move the API  
39:47 - below and change the handler of the 
API from hello to hello with counter  
39:58 - and this is why we expose The Read 
Only property for the handler,  
40:01 - it's so that the API actually has access to the 
lambda within the construct. So let's deploy it.  
40:15 - With some editing magic, we'll skip ahead again.  
40:28 - Now that we're deployed, we can test it. The 
CDK workshop builds in snares to expose some  
40:32 - nice things about LTU constructs. As we can 
see, the request here failed. In order to see  
40:39 - why we'll need to look at the logs. So let's 
switch to the lambda console in the console.  
40:45 - Click the Monitor tab, and 
click view logs in cloud watch.  
40:56 - If we go to the latest log stream,  
41:02 - we can see that there's an invoke error, and 
it's because of an Access Denied exception.  
41:07 - And if you read a little further, it says 
basically that the lambda is not authorized  
41:12 - to perform Dynamo DB Update Item on the 
resource. We never gave it permission.  
41:20 - So let's go back to the hit counter file. We're 
going to use the tables L to construct helper  
41:28 - method of grant readwrite data to apply 
the correct policy statements to lamda.  
41:39 - The workshop also forgot to add the 
permission for the lambda to be able  
41:43 - to invoke the downstream lambda. So we're 
just going to go ahead and add that now.  
41:52 - Now if we deploy again, and skip 
forward and we test the function  
42:03 - we'll get a successful response because 
everything has the correct permissions.  
42:19 - From here, if we go to Dynamo DB, and refresh 
the items in the table, we can see that the  
42:23 - right endpoints are being tracked. From the CDK 
workshop, we're going to npm install the CDK  
42:37 - Dynamo table viewer library into our project. 
With it installed, we can switch to our stack  
42:51 - and import the table viewer from 
the library. Then we're going to go  
42:58 - and create a new instance of it. This table viewer 
library is an L three construct because it groups  
43:04 - multiple L two constructs together, just like we 
did with the hit counter L three construct that we  
43:08 - made in the previous section. The table viewer 
construct expects us to pass in the DynamoDB  
43:14 - table from our other construct, but we didn't 
expose that. So let's go back to our construct  
43:23 - add the table property and assign 
the table to that property.  
43:43 - With that, we can pass the hello with counter dot 
table property into our third party construct.  
43:55 - Now if we deploy and skip ahead, we'll see 
that the table viewer construct created a  
44:01 - separate API gateway and its own 
endpoint defined in the outputs.  
44:06 - If we go there, it will end up 
displaying what's in the DynamoDB table.  
44:20 - Testing constructs is one of the 
most powerful things about CDK.  
44:24 - The CDK workshop walks you through two types 
of tests, assertion tests and validation tests.  
44:31 - For the first assertion test, 
we're going to create a stack  
44:34 - and use our hit counter construct and then 
verify that one DynamoDB table was created.  
44:41 - So let's go back to the code. Create 
the test and remove the old ones  
45:02 - Now we can run it.  
45:26 - And one DynamoDB table was created.  
45:30 - Next we'll move on to checking the lambda. The 
CDK assertions library has some useful features  
45:35 - like capture, which can intercept different 
properties as part of the template synthesis.  
45:40 - In this case, we use CAPTCHA to verify 
that the correct downstream function and  
45:44 - table names are being passed into the hit 
counter lambda. When we run this test,  
45:50 - we expect it to fail because I didn't copy 
the references from the synthesized output.  
45:54 - But making it fail actually makes it easier 
to find them. So we'll grab the correct names  
46:07 - and update the test with the right ones.  
46:18 - Now when we run it, it'll pass. Next, let's switch 
to a test driven development mindset. And say we  
46:29 - want to make sure our table is using server 
side encryption, we can assert that DynamoDB  
46:33 - table resource has server side encryption 
enabled. So when we run the test, it'll fail.  
46:48 - From a development perspective, that 
means we need to go back to the construct  
46:54 - and make sure that server 
side encryption is enabled.  
47:08 - Now if we run the test again, it'll 
pass. Since we don't actually want that,  
47:15 - I'm going to remove it from the 
construct and remove the test.  
47:23 - Next, let's talk about validation testing. 
Let's say as part of your construct, you want  
47:28 - to make sure a sane number of read capacity 
units are being used in the DynamoDB table.  
47:35 - We can add a read capacity property that gets 
passed into the construct. Use it in the table.  
47:47 - And then in the constructor, we can 
validate that the value passed in  
47:51 - is reasonable, say between five and 
20. If it's not, we'll throw an error.  
47:59 - Now let's add a test that passes in a value out 
of range to a three and verify that the error  
48:07 - is thrown. When we run the test, it'll 
pass because the error is being thrown.  
48:17 - This error would be thrown as part 
of stack synthesis. So let's see that  
48:22 - we'll go back to our workshop stack.  
48:26 - Add an out of bounds read capacity 
value and run the stack synthesis.  
48:38 - As you can see there is validation 
testing is super useful. At my work,  
48:43 - I use it to help enforce some naming conventions,  
48:46 - and also to log or throw deprecation warnings 
when property inputs or defaults change.  
48:53 - Great job with the workshop. 
Now that the workshops done,  
48:57 - we can move on to some advanced topics 
like aspects and best practices.  
49:03 - In the workshop, we went over fine grained 
assertions by checking for things like  
49:08 - number of tables created and ensuring encryption 
was turned on. We're checking to make sure the  
49:13 - lamda environment variables being passed in or 
the right one. But you could also use snapshot  
49:20 - testing to check the entire template if you want 
to do and use gests match snapshot functionality.  
49:28 - We also went over validation testing as part of 
the workshop. We checked the properties being  
49:32 - passed into the construct to make sure read 
capacity units were within a specific range.  
49:39 - In my organization, we also use this 
to help enforce some naming conventions  
49:44 - as well as throw some deprecation warnings in 
the event we have to significantly change the  
49:48 - construct. In this case, the warnings won't 
block deployment, but it will show up in the  
49:53 - console when doing synthetic deploy, where 
developers can pick them up and fix them.  
49:59 - You are aren't limited to just 
logging errors to the console though,  
50:03 - when you sent you're executing the actual 
code. So you could also log to an external  
50:08 - service like a platform service that tracks 
deployments, or logs to cloud watch itself.  
50:15 - The last form of testing is integration testing. 
With CDK, you can use AWS custom resources to test  
50:22 - that the resources are working together correctly 
as part of the CloudFormation deployment. If  
50:27 - something breaks, it will automatically 
roll back the CloudFormation deployment.  
50:34 - CDK has a provider framework for interfacing 
with CloudFormation custom resources.  
50:40 - These custom resources enable you to write 
custom provisioning logic and templates that  
50:44 - CloudFormation runs anytime you create, 
update or delete stacks. We can make use  
50:50 - of this to do integration testing across 
our stack. Let's say you have an event bus,  
50:54 - a lamda. And a DynamoDB table that you want 
to make sure are interacting with each other.  
50:59 - You could use the provider framework to spin up 
a lambda to emit a test event on an Event Bus,  
51:05 - all part of the CloudFormation deployment. And 
then the custom resource can query DynamoDB  
51:11 - waiting for the change. If the change 
doesn't happen in a set amount of time,  
51:16 - the build will fail and CloudFormation 
will automatically roll back the changes.  
51:22 - Matt Morgan has an excellent blog post about 
this called testing the async cloud with AWS CDK.  
51:29 - The CDK book also has a section on this.  
51:35 - Another advanced topic for the CDK are aspects 
aspects are a very powerful tool in CDK.  
51:43 - There are a way to apply an operation 
to all constructs in a given scope.  
51:48 - The aspect could modify the constructs such as by 
adding tags, or it could verify something or about  
51:53 - the state of the constructs such as 
ensuring that all the buckets are encrypted.  
51:59 - During the Prepare phase CDK calls the visit 
method of the object for the construct and each of  
52:05 - its children in a top down order. The visit method 
is free to change anything in the construct.  
52:14 - In this example, the bucket version checking 
class implements a visit method that checks  
52:19 - if s3 bucket versioning is enabled. Here it 
throws an error, but you could just as easily  
52:25 - modify the construct to enable versioning. 
Everything that the stack is applied to  
52:31 - that is every construct within the stack 
is evaluated by this visit method. Which  
52:37 - is why we need to check the instance of the node 
being evaluated to make sure it's the CFN bucket.  
52:44 - The nodes will all end up being the level 
one construct of the resource in question.  
52:49 - Even if you use a level two bucket 
construct within your stack code.  
52:56 - For best practices, AWS breaks up their 
best practice recommendations into four  
53:01 - different areas. Organization 
coding construct an application.  
53:10 - For organization best practices, 
AWS recommends having a team of  
53:14 - CDK experts help set standards and train 
or mentor developers in the use of CDK.  
53:20 - This doesn't have to be a large team. It 
could be as small as one or two people  
53:24 - or it could be a center of excellence 
if you have a large organization.  
53:30 - AWS also recommends the practice of deploying 
to multiple AWS accounts. For example,  
53:35 - having separate production, QA and development 
accounts. You should use continuous integration  
53:42 - and continuous deployment tools like CDK pipelines 
for deploying beyond development accounts.  
53:50 - For coding best practices, AWS recommends to 
only add complexity where you actually need it.  
53:56 - Don't architect for all possible scenarios up 
front. So the keep it simple, stupid principle.  
54:04 - It also recommends to use the 
well architected framework  
54:10 - AWS CDK apps are a mechanism to codify and 
deliver well architected best practices.  
54:16 - As you follow these principles, you can create 
and share components that implement them. Earlier  
54:24 - I stated it's possible to have multiple apps in a 
project, which is true, but it's not recommended.  
54:30 - Best practice is to not do that and to only have a 
single app per repo. In a CI CD world changes the  
54:39 - one app could unnecessarily trigger the deployment 
of another app, even if it didn't change.  
54:46 - Finally, your CDK code and the code 
that implements your runtime logic  
54:50 - should be in the same package. They don't need 
to live in separate repositories or packages.  
55:00 - For construct best practices, you should be 
building constructs of your logical units of code.  
55:06 - If you consistently build websites with 
s3, buckets, API gateways and lambdas,  
55:11 - make that a construct and then 
use the construct in your stack.  
55:16 - It's a bad practice to use environment 
variable lookups within your constructs.  
55:21 - environment variable lookups should 
happen at the top level of a CDK app,  
55:25 - and then be passed to the stacks and constructs as 
properties. By using environment variable lookups,  
55:33 - and constructs you lose portability and 
make your constructs harder to reuse.  
55:39 - If you avoid network lookups during synthesis 
and model all your production stages in code,  
55:45 - you can run a full suite of unit tests at 
build time consistently in all environments.  
55:52 - Be careful how you fact refactor your code 
that may result in changes to the logical ID.  
55:58 - The logical ID is derived from the ID you 
specify when you instantiate a construct,  
56:04 - and the constructs position in the app tree. 
Changing the logical idea of a resource results  
56:11 - in the resource being replaced with a new one at 
the next deployment, which you almost never want.  
56:18 - constructs are great, but they're 
not built to enforce compliance.  
56:23 - Compliance is better suited to using Service 
control policies and permission boundaries.  
56:34 - For application best practices, make your 
decisions at synthesis time. Don't use cloud  
56:39 - formation conditions and parameters. For 
example, a common CDK practice of iterating  
56:44 - over a list and instantiating a construct for each 
isn't possible using CloudFormation expressions.  
56:53 - Treat CloudFormation as an implementation 
detail and not a language target.  
56:58 - You're not writing CloudFormation templates, 
you're writing code that happens to generate them.  
57:04 - If you leave out resource names, CDK will generate 
them for you. And it will do so in a way that  
57:08 - won't cause problems when you end up refactoring 
your code later. CDK does its best to keep you  
57:14 - from losing data by defaulting to policies that 
retain everything you create. But Cloud watch is  
57:19 - expensive. Go through and set your own retention 
policies. CDK also has helper methods that will  
57:26 - empty an s3 bucket using a custom resource prior 
to destroying a stack which is very useful.  
57:35 - Consider keeping stateful resources like databases 
in a separate stack from stateless resources. You  
57:42 - can turn on termination protection for stateful 
stacks, while keeping it off for stateless once.  
57:49 - Stateful resources are more sensitive to 
construct renaming, which is another reason  
57:53 - to keep them in a separate stack. It reduces 
risk when reorganizing your app later. Determine  
58:01 - determinism is key to successful 
CDK deployments. CDK context is a  
58:07 - mechanism for recording a snapshot of the non 
deterministic values coming from synthesis.  
58:14 - This allows future synthesis operation 
to produce the same exact template. non  
58:20 - deterministic values results in using things like 
a constructs from lookup where you're looking  
58:26 - up an external resource. These from LOOKUP 
values are cached in CDK context dot JSON.  
58:36 - The grant convenience methods allow you 
to greatly simplify the IAM process.  
58:42 - Manually defining roles or using 
predefined roles in your AWS account  
58:46 - causes a big loss and flexibility 
in how you design your applications.  
58:52 - Service control policies and permission boundaries 
are better alternatives to predefined roles.  
59:00 - Another CDK best practice is to 
create a stack for each environment.  
59:05 - When you synthesize your application, the cloud 
assembly created in the CDK dot out folder  
59:10 - contains a separate template for each 
environment. Your entire build is deterministic.  
59:19 - Most of the level two constructs in CDK have 
convenience methods to help in the creation of  
59:24 - metrics, which you can easily use to generate 
CloudWatch dashboards and alarms use them.  
59:34 - Finally, there are a few more resources that 
I'd like to call out. Free Code Camp has a  
59:39 - great blog post about how to use CDK version two 
to create a three tier serverless application.  
59:47 - I have several posts on my blog related to 
CDK but one in particular shows how much  
59:52 - using a general purpose programming language 
enables you to extend the CDK even further.  
59:58 - In my open API specs from CDK. Without deploying 
first article, I show how you can traverse an API  
60:06 - gateways endpoint structure during synthesis to 
output an open API spec first without deploying.  
60:14 - Lastly, serverless stack framework is pretty 
neat. It extends the CDK and enables local  
60:20 - lamda development. It has a pretty neat console 
for observability when doing development too.  
60:26 - Definitely worth checking out  
60:32 - if you made it this far through 
the lesson, thanks for watching.  
60:35 - Thanks. You can follow me on Twitter at marks 
codes. And my other socials and my blog posts  
60:42 - are located at marks dot codes. This was a 
Free Code Camp CDK Crash Course. Thanks bye bye

Cleaned transcript:

AWS cloud development kit is an open source tool that allows developers to use their favorite programming languages to write infrastructures code for AWS, Matt marks is an AWS community builder, and he will teach you how to use the AWS cloud development kit. Hey, I'm Matt Mart's. And I'm Brian. And I'm an AWS community builder. And I'm here to give you a CDK Crash Course from Free Code Camp. You might be here because you're tired of manually provisioning your resources via the console. Or maybe like me, you hate writing yaml. But CDK has also been in the news a lot lately. In December, version two became generally available. Version two was a massive improvement over version one, since there is only one stable NPM library to install, instead of one for each module. Among other improvements, CDK was also featured fairly prominently in Dr. Vogel's reinvent keynote. And the CDK book was released. The CDK book was written by a bunch of the AWS heroes, and it will go into greater depth than what will be covered in this crash course, there will be overlap, but I still strongly recommend the book. So what will we cover in this course, I'm going to start by going over the basics of CDK definitions of the app stacks, constructs and how it all relates to CloudFormation. Then I'm going to do a 30 minute speed run of the CDK workshop, which is a workshop provided by AWS, and it's available at CDK workshop.com. From there, we'll go into some advanced topics like testing and best practices. This course is split up into chapters on YouTube. So if there are particular areas of interest, feel free to jump around. I'll also provide timestamp links in the description with supplemental information. This will include useful documentation, blogs, links, or anything else. I'm going to go through the CDK workshop very quickly, but you should do it yourself. The best way to learn about CDK is by using it. And since this is a YouTube video, feel free to speed me up, slow me down, or rewatch sections if you need to. If you think I've missed something in this crash course, or you didn't understand something, let me know in the comments or follow me on Twitter and reach out there. I'll be happy to help. Here are a few other resources I'd like to specifically call out. The CDK community on Slack is very active. It's full of friendly, knowledgeable people that love to help out. The authors of the CDK book are also very active there. Speaking of Did you hear there's a CDK book out now. Aside from that, there's also CBK day which is an annual conference related to CDK. Last year, I gave a 15 minute lightning talk on creating verifiable jots with CDK. And I'll add a link to that below. And with that out of the way, I hope you're in the right place. Let's move on to the basics. CDK stands for cloud development kit. It's open source software provided by AWS that enables you to write imperative code to generate declarative CloudFormation templates. It enables you to define the how so that you can get the what that means you can focus more on the architecture of your app instead of the nitty gritty details of IAM roles and policy statements. CDK is available in JavaScript, TypeScript, Python, Java, C sharp, and it's in a developer preview for go CDK itself is no GS based. Even if you use one of the other languages, the CDK code itself will be executed via no GS. So no J S is a requirement. Okay, so CDK generates CloudFormation. But what's that cloud formation is an AWS service that provisions AWS resources and stacks. AWS resources are things like lambda functions, s3, buckets, DynamoDB, tables, pretty much anything that AWS offers. A CloudFormation stack is just a collection of AWS resources. Cloud for me, CloudFormation uses JSON or YAML files as a template that describes the intended state of all the resources you need to deploy your application. The stack implements and manages the group of resources outlined in your template and it allows the state and dependencies of those resources to be managed together. When you update a CloudFormation template, it creates a change set. A change set is a preview of changes that will be executed by stack operations to create Update or remove resources so that the template becomes in sync. So CDK generates cloud formation and cloud formation provisions, AWS resources. What does the CDK app look like and how does it relate? The root of CDK is the CDK app. It's a construct that coordinates the lifecycle of the stacks within it. There is no CloudFormation equivalent for an app. Within the app, you can have multiple CDK stacks, and CDK stacks can even have nested stacks. CDK stacks are one to one equivalent with CloudFormation stacks, and nested stacks are also one to one equilibrium equivalent with CloudFormation stacks. When you run CDK, synth or CDK deploy the output is the CloudFormation template for this app structure. The CDK app is a special route construct that orchestrates the lifecycle of the stacks and the resources within it. The app lifecycle constructs the tree of the app in a top down approach, and then it executes the methods for the constructs within it. You typically don't need to directly interface with any of the prepare, validate or synthesize methods of the constructs, but they can be overridden. The final stage of the apps lifecycle is the deploy phase, where the cloud formation artifact is uploaded to cloud formation. The unit of deployment in CDK is called a stack. All resources defined within the scope of a stack, either directly or indirectly, are provisioned as a single unit CDK stacks have the same limitations as CloudFormation stacks. Stacks are powerful in cloud formation. In order to deploy a template to multiple environments, you need to use cloud formation parameters. But these are only resolved during deployment. In cloud formation, if you want to conditionally include a resource based on a parameter, you have to use the CloudFormation condition. But in CDK, you don't have to use either, you can simply use an if statement to check a value whether the resource should be defined or not, it ends up being much simpler. You can use cloud formation parameters and conditions in CDK. But they're discouraged since they only resolve during deployment, which is well after CDK synthesis. We've heard a lot about constructs. But what are they? There are four levels of constructs. Level zero constructs are just basic resources. All of the higher levels inherit from level zero, there's no specific type tied to it. Level one constructs are one to one representations of CloudFormation resources. They are all prefixed in the CDK API with the letters C F n, we which is a short form of CloudFormation. The way I remember this is level one is one to one with CloudFormation. Level two constructs aren't improved or extended level one constructs. They're provided by the CDK team and offer helper methods and sensible defaults. Level three constructs are combinations of constructs, which could be an intermingling of level one, two and three constructs together. More often than not, you'll be interacting with level two or three constructs. Some modules in CDK don't have level two constructs yet. But pretty much all of the level one constructs exist for the corresponding CloudFormation API. The CDK team is very fast at implementing changes to level one constructs and more frequently used level two constructs. for level one construct, let's look at the access analyzer module. In this case, the module doesn't have any level two constructs available, so there's only the level one CFN analyzer construct. As you can see, this is a one to one representation with the CloudFormation API. The CFN analyzer construct has the same properties defined as the CloudFormation API for the same. There are also new helper utility methods on the CFN analyzer construct. For level two construct, let's look at the DynamoDB table construct. It doesn't have a CFN prefix and includes many sensible defaults. For example, the billing mode defaults to pay per request, unless you specify replication regions. If you specify replication regions, it becomes provisioned and if it becomes provisioned, the default Read and Write capacities get set and defaulted to five The default removal policy of the table is retained. And the table has helper methods to create global or local secondary indexes, and to create varying levels of access to the table and it streams. For level three constructs, the CDK doesn't offer anything specific out of the box. These tend to be created at the individual organization or community level, and provided as libraries. An example level three construct would be to create a notifying bucket. This construct creates an s3 bucket along with an SNS topic. It then adds an object created notification coming from the s3 bucket to target the SNS topic. All you have to do to use this is add a new notifying bucket to your app. And it will provision all of these resources automatically. There are several great resources in the community that I'd also like to call out. CDK patterns.com is a resource that enables you to search by community provided examples, and it's cross referenced by the different components used within it. AWS also offers another open source extension of the CDK with their AWS solutions constructs. These provide multi service well architected patterns for quickly defining solutions in code for frequently used patterns. This is available as an NPM library that you can install and use right out of the box. There's also the construct hub. The construct hub is a central destination for discovering and sharing cloud application design patterns and reference architectures designed for CDK CDK for Kubernetes, and CDK. For TerraForm, and other construct based tools, construct hub pulls from the NPM registry, all CDK constructs that support multiple languages and are correctly annotated. Great. So I think we have a handle on constructs. Now, let's go a little deeper. How do we generate the CloudFormation template. In order to do that the app needs to be synthesized. To do this, we can run CDK. Since this traverses the app tree and invokes synthesize on all of the constructs, this ends up generating unique IDs for the CloudFormation resources and generates the respective EML along with any assets that are needed. Okay, so what are assets? Assets are the files bundled into CDK apps. They include things like the lambda handler code, Docker images, layer versions, files, going into an s3, bucket, etc. They can represent any artifact that the app needs. When you run CDK synth or deploy, these get output to a CDK dot out folder on your local machine. Okay, so what does CDK do with these assets? How do they get put into CloudFormation? Well, that's where bootstrapping comes into play. Bootstrapping creates a CDK toolkit cloud formation stack deployed to your account. This account includes an s3 bucket and various permissions that are needed for CDK to do the deployments and upload the assets. bootstrapping is required when your app has assets or your CloudFormation templates become larger than 50 kilobytes. So it's pretty much always required, you're almost always going to have some sort of asset in your stack. For CDK version to administrator access is needed to create the roles that CDK toolkit stack needs in order to do deployments. You won't need administrator access after CDK is bootstrapped. With the bootstrapping done, we can move on to deploying. When you run CDK deploy, the app is initialized or constructed into an app tree. Once the construction is done, the app goes through preparation, validation and synthesize steps. So each construct calls its prepare method, then each construct calls its validate method. And then each construct calls its synthesized method. Up to this point, this is what CDK sent us. From there, the app uploads the template and any other artifacts to cloud formation, and cloud formation deployment begins. Once this handoff is done, it's all in the hands of CloudFormation. Now that we've defined some of the basic pieces of CDK let's move on to the workshop. The word stops at CDK workshop calm. You should do this first and then come back. Perfect. Once you come back, we'll do the 30 Minute speed round through the workshop. We're gonna get started with this workshop by creating a cloud nine environment. To do that, I'm going to steal some instructions from the CDK pipelines workshop, it's going to have a screen and I enroll for Cloud Nine that has full access. This is going to be used in bootstrapping the account for CDK. Version two links for the CDK pipelines workshop will be in the description below. It's a great workshop and you should work through it if you have the time. First, we're going to go to the cloud nine console and create an environment. I'm just going to name it CDK workshop, and we don't need a description. Then we select an instance type, I did this workshop with a T three small instance. But the M five large would probably be better. All the other options can use the defaults. While CLOUD NINE spins up, I want to note that both the T three small and N five large instances are not free tier eligible. So it might cost you some money. I was getting some memory errors towards the end with the T three small instance. But it still worked. To create the I am role. The CDK pipelines workshop has a deep link that will take you to the role creation page. From there, we confirm that it's AWS service entity and for easy to and then go to permissions. Make sure that administrator access is selected. We don't need new tags, so we can skip that. And then we're going to give it a name, we're going to name this CDK admin and create the role. With the role created, we can go back to the CDK pipeline workshop and see that we need to actually go in and attach the roll to the EC two instance. There is a deep link. But since we had named the EC two instance, something else we actually need to go to the EC to console, go to instances. And then select the instance that with our cloud nine instance that's running. Go to actions, security and modify Iam role. From here we're going to select the IAM roles that we just created CDK admin and save it. Now if we go to the CDK workshop, Cloud Nine and refresh, it will automatically have the role that we need. Next, we need to do some cloud nine housekeeping and setup, we're going to remove the AWS manage temporary credentials. These prevent us from using the role that we attached to the Cloud Nine easy to instance, in the upper right corner of cloud nine, go to settings and then scroll down to AWS settings and turn off AWS manage temporary credentials. To make doubly sure that the credentials are gone, we're going to remove the credentials folder. Next, we're going to do some environment config, we need to install JQ using yum. And then we're going to export some environment variables with AWS account information. To check to make sure that the AWS region was set correctly, we're going to do this test command. And finally, we're going to export the account ID and region and make sure AWS is configured correctly. Now we need to make sure that Cloud Nine is easy to instances using the right a Iam role. To do that, we're going to use this STS get color identity command. It's gonna fail here because we actually named the role CDK admin. So if we update the command to check for CDK admin, we'll get the that the im role is valid like this. At this point, we can switch back to the actual CDK intro workshop. We're going to go to the prerequisites tab and start checking things to make sure that everything is like it should be. The AWS CLI is already installed and we've already set up the AWS account and user. Next we want to make sure that we have a good node version installed In Cloud Nine, CLOUD NINE comes with Node installed. So let's just check the version. And here version 16 is fine. We're also gonna want to check CDK. Now, this is a CDK to workshop. So we want to make sure that we actually bumped up the version of CDK. So if we do NPM i for install AWS CDK. Globally, we're gonna get this error because he's the Cloud Nine instance of easytouse weird, so you actually have to force it. In this case, the CDK pipeline tutorial also goes through this as well. Now that we've forced installed it, we can see that version 2.3 is installed. We're already using AWS cloud nine, we just checked the CDK version. And that concludes the prerequisites. Next, we can begin the actual workshop. So let's get started, we'll go to the CDK. And next step, the first thing we need to do is create a directory to work in. So we're gonna make the CDK workshop directory and change into it. Now we need to actually admit the project. So we're gonna run CDK and it sample app with the language TypeScript. This creates a Git repo, and NPM installs all the dependencies for a basic CDK two project CDK two is a massive improvement over CDK version one because it bakes in all of the stable modules into one NPM dependency CDK version one had individual NPM libraries for each module like DynamoDB, lambda SNS, etc. In version two, you just have one, and that avoids a lot of the dependency management hell. Now that the thug project is initialized to CDK workshop is going to want us to run the watch command in the background to compile the TypeScript into JavaScript. So we're going to create a new terminal, change directories into the project folder, and then run the NPM run watch command in the background. With that done, we can move on to the next step and actually check out the project structure of what was what's been initialized so far. So let's go back to the Cloud Nine environment, we'll open up the project folder, and let's start looking at some files. Let's start where CDK starts with the bin slash CDK workshop TypeScript file. This file instantiates the CDK app by creating stacks. That is to say, when you run CDK center CD kit, boy, it starts here to generate the CloudFormation templates. CDK stacks are one to one equivalent with CloudFormation stacks. An app can have multiple stacks, and each stack would end up creating a new stack in cloud formation. In the case of our sample app, there's only one stack, the CDK workshop stack. So let's look at that next. The sample stack is pretty simple. It uses two level two constructs. One to create an SQ SQ and one to create an SNS topic, then subscribes the queue to the topic. That's it. The workshop goes into similar detail with these. But let's move on to our first CDK synth. As described before, when CDK apps are executed, they produce an AWS CloudFormation template for each stack defined in the app. Switching back to cloud nine, let's run CDK Seth, I'm going to output to a template dot Yamo file to make it a little easier to read. Now, there are two important concepts I want to call out here. CDK is both imperative it describes the how the app will be built. But it's also item potent, given the same inputs, it will produce the same outputs. See here, we use the same code between the CDK workshop in my cloud nine instance. And the cloud formation that was generated as the same. For example, the resource hash hashes match between the two. This is because we used all the same inputs that the CDK workshop did. If I went and change the topic or cue ID, the hash would change and we'd have something else. This is going to be important in unit testing later. Now that we've sent, let's deploy. In order to do that we need to bootstrap the account Let's open up a new console window and go to cloud formation. And this account, the only one running right now should be the one that's used for cloud nine. Right here. So let's go back to the Cloud Nine terminal and run the Bootstrap. This is why we needed to create an im role with administrator access. And it's actually the only time you need admin access when you're bootstrapping the account. In order for CDK, to deploy apps, it needs to store the assets somewhere. The Bootstrap creates its own cloud formation template that we'll see when we go back to cloud formation. And that includes a number of roles and policies that enable it to store assets for deployment. As you can see here, the CDK toolkit stack was just created from the bootstrap process. Now, if we switch back to cloud nine, we can actually run the deploy command. The deploy command resynthesize is the app. And if there's any IAM policy changes in the census, it will display them and ask to make sure that you want to continue. Here, since we're subscribing the queue to the topic, a IAM policy needs to be in place in order to make that happen. So yeah, we do want that to happen. So let's deploy it. While CloudFormation is spinning up, if we refresh CloudFormation, we'll see the CDK workshop stack create is in progress. And we can actually view the resources as they're created. So here we can see that there's a metadata entry along with the queue and topic, but there's no actual subscription yet or policies related to it. Now that the crate is complete, we can go back to the resources and see that yes, there is a queue policy and a subscription. Well, that was fun. But now let's get her hands dirty. The CDK workshop is going to take you through a couple steps at this point. We're going to clean up the stack by removing the SNS topic and the SQ sq. And then we're going to create a simple API gateway backed by lambda. So let's get started. We're going to delete the sample code from our stack. And then we're going to do a diff to see what it shows. Go back to the stack file. And delete the queue topic and the topic that adds description along with the imports. That are on the CDK diff command. What CDK diff does is it re synthesizes the CloudFormation app and compares the yam all from one to the other. And we can see here that it's destroying the queue queue policy subscription and the topic. Next we can CDK deploy as it's deploying, the only thing that the CloudFormation stack should be left with is the CDK metadata entry. Till we go back to cloud formation, we can check the progress of this by refreshing the resources as it is progressing. They're done Now let's go back to cloud nine and create the lambda. We'll create a folder called lambda, and put a hello.js file in it. Inside of that, we'll put some basic lambda code. Next, we need to create the lambda in the stack, we'll add the lambda import from CDK to then create the actual lambda function. One of the biggest benefits of creating AWS resources using CDK is the IntelliSense. Having imported from AWS lambda, I can create a new function using new lambda dot function, pass the stack and ID of the lambda in and give it some properties. In this case, we needed to find the runtime using lambda.runtime.no, Gs 14 where the code lives, which we use code dot from asset and then lambda, which uploads the lambda folder as an asset to s3. And then they were the handlers. In this case, our handlers and Hello, the Hello file, and it's named handler. Now we can run the diff. And this will show us that it's going to create a im role for the lambda and the lambda function itself. Which this looks good to me. So let's just deploy it. I'm going to speed this part up a little bit. And we can see the function and the role in cloud formation. So let's test out the lambda itself. In the code source area of the lambda console, we can create a test event by clicking the test button. We'll select API gateway AWS proxy, because ultimately, we'll be connecting this to an API gateway. Don't forget to give it a name. And doesn't like spaces. And hit create. What do we get test again, it'll invoke the lambda. And now we can see the status of 200. And that the body has the correct response. So let's add an API gateway. First, we'll import the API gateway module from CDK. And then we'll create a lambda REST API. Lambda rest API's are just rest API's with a greedy proxy that sends everything to the defined lambda. We'll pass in the stack construct and give the REST API an ID. And then we'll tell it our hello function as the API handler. Now we can run a diff. And I'll also show that there's actually no API gateway already defined by going to the API gateway console. And here, there's no API's. So let's deploy it. I'm going to speed this up again. But what it's doing is it's creating a bunch of resources automatically. There's the API gateway itself permissions for the gateway, and for it to invoke the lambda, etc, etc. Now that it's done, we can see we went from three resources to 15 in CloudFormation. And this was all handled with a couple lines of code. And if I go and refresh the lambda page We can see that the API gateway is added to the lambda console as a trigger. Similar, we can see the API is defined on the API gateway console. So let's test it. We'll grab the API URL that was automatically output as part of the deploy, and send it a curl request. Nice. And let's try another one. Very nice. All we've done so far is use a few level two constructs. Let's make our own level three construct. We'll make an interceptor lambda that writes to the DynamoDB table, and then invokes any targeted downstream lambda. Let's get started. We'll create a new hit counter type script file in the lib folder, and put some boilerplate construct code in here. All this does is extend the construct and to find the props. Next, let's create our interceptor lambda and the lambda folder, we'll create hit counter dot j, s. And we'll copy the code over from the workshop. what this code does is it uses two modules from the AWS SDK to interact with both Dynamo DB and lambda will use Update Item from Dynamo DB to increment a hit counter for a path. And we'll use the lamda client to invoke the downstream lambda, and then return the response from that lambda with the table and lambda will be passed into this interceptor lambda via environment variables. Now that that's done, we need to create both the table and the lambda, we'll add the DynamoDB module from CDK. And then create the table using new DynamoDB dot table, we'll pass in the stack construct and give the table an ID. And DynamoDB also needs to define a partition key. So we'll go ahead and do that as well. Next, we'll create the lambda, this follows the same pattern as before do lambda dot function, pass in this give it a ID and set the runtime which is no Jess. The handler, which in this case is hit counter dot handler and then the code coming from code dot from asset lambda we need to pass in the environment variables. And I'll make a tweak to the lambda Id just to be consistent with the workshop. Now we're going to want to expose the lamda as a read only property of the construct. So add this Public Read Only line to the class. And we'll assign the lambda to the property. Now this construct is great as is, but it's not being used anywhere. So let's fix that. We'll go back to the main workshop stack. And use the construct. It's the same pattern as a level two construct. So we can do a new hit counter pass in the stack, give it an ID. And in our case, the properties here is the downstream lambda that we want to invoke. So we'll set downstream to Hello. And I will do a trick to import the hit counter from the local file. But now we need to make the API use this lambda instead. So we will move the API below and change the handler of the API from hello to hello with counter and this is why we expose The Read Only property for the handler, it's so that the API actually has access to the lambda within the construct. So let's deploy it. With some editing magic, we'll skip ahead again. Now that we're deployed, we can test it. The CDK workshop builds in snares to expose some nice things about LTU constructs. As we can see, the request here failed. In order to see why we'll need to look at the logs. So let's switch to the lambda console in the console. Click the Monitor tab, and click view logs in cloud watch. If we go to the latest log stream, we can see that there's an invoke error, and it's because of an Access Denied exception. And if you read a little further, it says basically that the lambda is not authorized to perform Dynamo DB Update Item on the resource. We never gave it permission. So let's go back to the hit counter file. We're going to use the tables L to construct helper method of grant readwrite data to apply the correct policy statements to lamda. The workshop also forgot to add the permission for the lambda to be able to invoke the downstream lambda. So we're just going to go ahead and add that now. Now if we deploy again, and skip forward and we test the function we'll get a successful response because everything has the correct permissions. From here, if we go to Dynamo DB, and refresh the items in the table, we can see that the right endpoints are being tracked. From the CDK workshop, we're going to npm install the CDK Dynamo table viewer library into our project. With it installed, we can switch to our stack and import the table viewer from the library. Then we're going to go and create a new instance of it. This table viewer library is an L three construct because it groups multiple L two constructs together, just like we did with the hit counter L three construct that we made in the previous section. The table viewer construct expects us to pass in the DynamoDB table from our other construct, but we didn't expose that. So let's go back to our construct add the table property and assign the table to that property. With that, we can pass the hello with counter dot table property into our third party construct. Now if we deploy and skip ahead, we'll see that the table viewer construct created a separate API gateway and its own endpoint defined in the outputs. If we go there, it will end up displaying what's in the DynamoDB table. Testing constructs is one of the most powerful things about CDK. The CDK workshop walks you through two types of tests, assertion tests and validation tests. For the first assertion test, we're going to create a stack and use our hit counter construct and then verify that one DynamoDB table was created. So let's go back to the code. Create the test and remove the old ones Now we can run it. And one DynamoDB table was created. Next we'll move on to checking the lambda. The CDK assertions library has some useful features like capture, which can intercept different properties as part of the template synthesis. In this case, we use CAPTCHA to verify that the correct downstream function and table names are being passed into the hit counter lambda. When we run this test, we expect it to fail because I didn't copy the references from the synthesized output. But making it fail actually makes it easier to find them. So we'll grab the correct names and update the test with the right ones. Now when we run it, it'll pass. Next, let's switch to a test driven development mindset. And say we want to make sure our table is using server side encryption, we can assert that DynamoDB table resource has server side encryption enabled. So when we run the test, it'll fail. From a development perspective, that means we need to go back to the construct and make sure that server side encryption is enabled. Now if we run the test again, it'll pass. Since we don't actually want that, I'm going to remove it from the construct and remove the test. Next, let's talk about validation testing. Let's say as part of your construct, you want to make sure a sane number of read capacity units are being used in the DynamoDB table. We can add a read capacity property that gets passed into the construct. Use it in the table. And then in the constructor, we can validate that the value passed in is reasonable, say between five and 20. If it's not, we'll throw an error. Now let's add a test that passes in a value out of range to a three and verify that the error is thrown. When we run the test, it'll pass because the error is being thrown. This error would be thrown as part of stack synthesis. So let's see that we'll go back to our workshop stack. Add an out of bounds read capacity value and run the stack synthesis. As you can see there is validation testing is super useful. At my work, I use it to help enforce some naming conventions, and also to log or throw deprecation warnings when property inputs or defaults change. Great job with the workshop. Now that the workshops done, we can move on to some advanced topics like aspects and best practices. In the workshop, we went over fine grained assertions by checking for things like number of tables created and ensuring encryption was turned on. We're checking to make sure the lamda environment variables being passed in or the right one. But you could also use snapshot testing to check the entire template if you want to do and use gests match snapshot functionality. We also went over validation testing as part of the workshop. We checked the properties being passed into the construct to make sure read capacity units were within a specific range. In my organization, we also use this to help enforce some naming conventions as well as throw some deprecation warnings in the event we have to significantly change the construct. In this case, the warnings won't block deployment, but it will show up in the console when doing synthetic deploy, where developers can pick them up and fix them. You are aren't limited to just logging errors to the console though, when you sent you're executing the actual code. So you could also log to an external service like a platform service that tracks deployments, or logs to cloud watch itself. The last form of testing is integration testing. With CDK, you can use AWS custom resources to test that the resources are working together correctly as part of the CloudFormation deployment. If something breaks, it will automatically roll back the CloudFormation deployment. CDK has a provider framework for interfacing with CloudFormation custom resources. These custom resources enable you to write custom provisioning logic and templates that CloudFormation runs anytime you create, update or delete stacks. We can make use of this to do integration testing across our stack. Let's say you have an event bus, a lamda. And a DynamoDB table that you want to make sure are interacting with each other. You could use the provider framework to spin up a lambda to emit a test event on an Event Bus, all part of the CloudFormation deployment. And then the custom resource can query DynamoDB waiting for the change. If the change doesn't happen in a set amount of time, the build will fail and CloudFormation will automatically roll back the changes. Matt Morgan has an excellent blog post about this called testing the async cloud with AWS CDK. The CDK book also has a section on this. Another advanced topic for the CDK are aspects aspects are a very powerful tool in CDK. There are a way to apply an operation to all constructs in a given scope. The aspect could modify the constructs such as by adding tags, or it could verify something or about the state of the constructs such as ensuring that all the buckets are encrypted. During the Prepare phase CDK calls the visit method of the object for the construct and each of its children in a top down order. The visit method is free to change anything in the construct. In this example, the bucket version checking class implements a visit method that checks if s3 bucket versioning is enabled. Here it throws an error, but you could just as easily modify the construct to enable versioning. Everything that the stack is applied to that is every construct within the stack is evaluated by this visit method. Which is why we need to check the instance of the node being evaluated to make sure it's the CFN bucket. The nodes will all end up being the level one construct of the resource in question. Even if you use a level two bucket construct within your stack code. For best practices, AWS breaks up their best practice recommendations into four different areas. Organization coding construct an application. For organization best practices, AWS recommends having a team of CDK experts help set standards and train or mentor developers in the use of CDK. This doesn't have to be a large team. It could be as small as one or two people or it could be a center of excellence if you have a large organization. AWS also recommends the practice of deploying to multiple AWS accounts. For example, having separate production, QA and development accounts. You should use continuous integration and continuous deployment tools like CDK pipelines for deploying beyond development accounts. For coding best practices, AWS recommends to only add complexity where you actually need it. Don't architect for all possible scenarios up front. So the keep it simple, stupid principle. It also recommends to use the well architected framework AWS CDK apps are a mechanism to codify and deliver well architected best practices. As you follow these principles, you can create and share components that implement them. Earlier I stated it's possible to have multiple apps in a project, which is true, but it's not recommended. Best practice is to not do that and to only have a single app per repo. In a CI CD world changes the one app could unnecessarily trigger the deployment of another app, even if it didn't change. Finally, your CDK code and the code that implements your runtime logic should be in the same package. They don't need to live in separate repositories or packages. For construct best practices, you should be building constructs of your logical units of code. If you consistently build websites with s3, buckets, API gateways and lambdas, make that a construct and then use the construct in your stack. It's a bad practice to use environment variable lookups within your constructs. environment variable lookups should happen at the top level of a CDK app, and then be passed to the stacks and constructs as properties. By using environment variable lookups, and constructs you lose portability and make your constructs harder to reuse. If you avoid network lookups during synthesis and model all your production stages in code, you can run a full suite of unit tests at build time consistently in all environments. Be careful how you fact refactor your code that may result in changes to the logical ID. The logical ID is derived from the ID you specify when you instantiate a construct, and the constructs position in the app tree. Changing the logical idea of a resource results in the resource being replaced with a new one at the next deployment, which you almost never want. constructs are great, but they're not built to enforce compliance. Compliance is better suited to using Service control policies and permission boundaries. For application best practices, make your decisions at synthesis time. Don't use cloud formation conditions and parameters. For example, a common CDK practice of iterating over a list and instantiating a construct for each isn't possible using CloudFormation expressions. Treat CloudFormation as an implementation detail and not a language target. You're not writing CloudFormation templates, you're writing code that happens to generate them. If you leave out resource names, CDK will generate them for you. And it will do so in a way that won't cause problems when you end up refactoring your code later. CDK does its best to keep you from losing data by defaulting to policies that retain everything you create. But Cloud watch is expensive. Go through and set your own retention policies. CDK also has helper methods that will empty an s3 bucket using a custom resource prior to destroying a stack which is very useful. Consider keeping stateful resources like databases in a separate stack from stateless resources. You can turn on termination protection for stateful stacks, while keeping it off for stateless once. Stateful resources are more sensitive to construct renaming, which is another reason to keep them in a separate stack. It reduces risk when reorganizing your app later. Determine determinism is key to successful CDK deployments. CDK context is a mechanism for recording a snapshot of the non deterministic values coming from synthesis. This allows future synthesis operation to produce the same exact template. non deterministic values results in using things like a constructs from lookup where you're looking up an external resource. These from LOOKUP values are cached in CDK context dot JSON. The grant convenience methods allow you to greatly simplify the IAM process. Manually defining roles or using predefined roles in your AWS account causes a big loss and flexibility in how you design your applications. Service control policies and permission boundaries are better alternatives to predefined roles. Another CDK best practice is to create a stack for each environment. When you synthesize your application, the cloud assembly created in the CDK dot out folder contains a separate template for each environment. Your entire build is deterministic. Most of the level two constructs in CDK have convenience methods to help in the creation of metrics, which you can easily use to generate CloudWatch dashboards and alarms use them. Finally, there are a few more resources that I'd like to call out. Free Code Camp has a great blog post about how to use CDK version two to create a three tier serverless application. I have several posts on my blog related to CDK but one in particular shows how much using a general purpose programming language enables you to extend the CDK even further. In my open API specs from CDK. Without deploying first article, I show how you can traverse an API gateways endpoint structure during synthesis to output an open API spec first without deploying. Lastly, serverless stack framework is pretty neat. It extends the CDK and enables local lamda development. It has a pretty neat console for observability when doing development too. Definitely worth checking out if you made it this far through the lesson, thanks for watching. Thanks. You can follow me on Twitter at marks codes. And my other socials and my blog posts are located at marks dot codes. This was a Free Code Camp CDK Crash Course. Thanks bye bye
