With timestamps:

00:00 - learn data analytics using only free
00:02 - Google services this course teaches key
00:05 - data analytics Concepts using Google big
00:07 - query Google Sheets Google looker studio
00:10 - and Google collab Vias will teach you
00:13 - data analytics using the Google stack
00:16 - hello guys welcome to this end to end
00:18 - free data analytics projects course I'm
00:21 - vas adya currently working as an
00:23 - analytics instructor near Berlin Germany
00:26 - in this course I will be covering all
00:28 - the important data analytics topics like
00:30 - Excel SQL Python and data visualization
00:34 - and use it to solve interesting
00:36 - questions on varied projects we will be
00:38 - using the Google stack here because to
00:41 - use these tools with Google stack we do
00:44 - not need any additional software
00:46 - installation all we need is a Gmail ID
00:49 - before we get started I would like to
00:51 - thank free code camp for the massive
00:53 - impact they creating and I'm happy to
00:55 - contribute to this cost and reach a
00:57 - larger audience so that a lot of people
00:59 - can learn these data analytics topics
01:01 - for free I also run a YouTube channel
01:04 - named analyst Aditya the link is given
01:06 - in the description here I have posted
01:08 - End to End videos on SQL python web
01:11 - scraping projects tblo power Bay and
01:13 - also tips on how you can build your
01:15 - resume how you can leverage LinkedIn to
01:17 - get a job and also some tips around
01:20 - interviews and building your GitHub
01:21 - profile so let's get started with the
01:24 - project series first up we will start
01:26 - with spreadsheets spreadsheets are one
01:29 - of the most common tools tools you're
01:30 - going to use in your data analyst job in
01:32 - this coming project we are going to use
01:34 - Google Sheets to analyze my own travel
01:36 - expenses data of my trip to varied
01:39 - countries we are going to use Simple
01:41 - intermediate and also Advanced functions
01:43 - using Google Sheets and drive insights
01:45 - and find interesting stats from my data
01:49 - so this is the data set we are going to
01:50 - work with it's in fact my original data
01:53 - I always want to showcase original data
01:55 - and we can do some analysis on it that's
01:57 - always interesting so this is like the
01:59 - date
02:00 - this is the country where I've been to
02:02 - this is the city then I have something
02:05 - called as cost let's say this is in
02:07 - Euros there's a column called category
02:09 - ID right it has 1 2 3 4 5 6 7 10 9 all
02:13 - these numbers what this is for this sake
02:16 - we have a second table called category
02:19 - so as you see category ID each of them
02:22 - signifies a specific area where I have
02:24 - spent money right one is break first for
02:27 - instance s is some entrance ticket to
02:29 - some place or some Museum or whatever 10
02:32 - is like something that has been done
02:34 - with shopping and so on right so we have
02:36 - two simple data
02:38 - sets and uh now we are going to solve
02:41 - some questions using Google Sheets right
02:43 - like plenty of questions plenty of
02:45 - Concepts and topics we're going to do so
02:48 - let me directly jump into the question
02:49 - list we'll try to crack them one by one
02:52 - right this will be great practice for
02:53 - you we going to cover a wide array and
02:55 - range of functions as well so first of
02:58 - all find the unique values for each of
03:00 - the columns and show us how to count the
03:03 - unique values
03:04 - right so unique values for each of the
03:07 - columns what is the formula you can use
03:09 - I'll just show you for one specific uh
03:12 - column let us say I want to find the
03:14 - unique countries that I've been to right
03:16 - I've been to number of countries so how
03:19 - I can do that is using the unique
03:21 - function itself so you can say unique
03:24 - and just select the full range right B2
03:26 - is to b128 so now I get the unique names
03:30 - of countries that I've been to right
03:32 - around eight countries so suppose I want
03:35 - to count the unique countries what we
03:38 - can do the only difference in the
03:40 - formula is you say count unique and you
03:44 - will select the same range okay so now
03:47 - I'll get eight why because I've been to
03:50 - eight unique countries right so if you
03:52 - put unique you'll get the actual values
03:55 - if you say count unique you'll get the
03:57 - number of unique values right same way
04:00 - if we have to do the same thing for
04:01 - another example let us say City I can
04:04 - simply say
04:06 - unique Open brackets and select the
04:09 - different column right so I can select
04:11 - this and you see I've been to so many
04:14 - different cities right basically I've
04:15 - been to 12 different cities across eight
04:18 - different countries right so unique is a
04:20 - powerful use case uh so do remember that
04:23 - and when you want to count unique values
04:26 - use count unique function right very
04:28 - very relevant so so we have done first
04:31 - question now next question comes how can
04:33 - you combine the category table with the
04:36 - original data so I have category table
04:39 - here where I have the actual name of the
04:41 - category how can I combine it with the
04:43 - original data right maybe I'll just
04:45 - insert one more column here just to kind
04:48 - of create some uh
04:50 - space so how can we combine these two so
04:53 - I have category ID here and I have
04:56 - category ID here right they are the same
04:58 - common column now we can join these two
05:00 - data sets using the V lookup formula
05:03 - because we have a common matching column
05:05 - right how can we do that so I can add a
05:07 - new column and I will call it category
05:09 - itself so I will simply say we look
05:13 - up I want to look for this category ID
05:16 - value where do I want to look for it
05:18 - I'll go to this table I'll select this
05:21 - range right this is the range where I
05:23 - want to find in this which column do I
05:25 - want to look for I want to look for the
05:27 - second column right because second
05:29 - column has the ual value of the category
05:31 - and I want an exact match so I'll put
05:33 - false okay and also remember for the
05:36 - whole formula range I want this to be
05:39 - fixed right always I'm going to refer to
05:41 - the same A2 to b14 range so I will just
05:43 - lock it with the
05:45 - dollar and now I get okay category ID
05:47 - one means break first and now let us say
05:50 - I can just go here and double click the
05:52 - plus I will get the formula copied
05:55 - accordingly right so for example five
05:57 - category five means for travel right
06:00 - basically for flights let us just double
06:02 - check so five is travel okay now we have
06:04 - the column category also in our original
06:07 - data we managed to integrate it with a
06:09 - simple vlookup function very very
06:11 - powerful
06:12 - function next question what is the total
06:15 - cost spent on breakfast overall there
06:18 - are multiple ways to do it I'm going to
06:21 - teach you a simple way using Su if okay
06:24 - so let me go here and like only for B
06:28 - break first I want to count the cost
06:30 - right so what I can do for example I can
06:34 - write break first okay and I can say sum
06:38 - if
06:39 - right what is the range right where I
06:42 - want to check for the criteria I want to
06:43 - check this column so I'll select this
06:45 - complete thing okay the second thing is
06:48 - the actual criteria right what is the
06:50 - criteria I want it to match with break
06:53 - first so I will select this and in the
06:55 - case it matches I want to sum I want to
06:58 - sum the values in this column right so I
07:01 - just select that and leave it okay so I
07:04 - noticed that for breakfast alone overall
07:07 - spent around 400 right simple use of
07:11 - some if right so if we want to verify
07:15 - this for example we can simply put a
07:18 - filter right let us just filter out
07:20 - break first this is just to cross check
07:24 - so I'll filter out breakfast and I can
07:25 - see the total cost as you see the sum is
07:28 - coming to 400 so overall across all
07:29 - these tips for breakfast I have spent 00
07:32 - so I'm going to just remove the filter
07:34 - this is a powerful use case of su very
07:36 - good function to know
07:39 - okay next uh total cost spent on travel
07:43 - for Spain okay there's an extra twist
07:45 - here there are two conditions okay so
07:48 - travel is one column and also
07:50 - specifically for Country Spain right so
07:53 - in this case what we can do we can use a
07:55 - su ifs function we want to give multiple
07:57 - conditions right so for instance I will
08:00 - uh just write these two words here right
08:03 - for example I can write Spain and travel
08:06 - and now I will use a su use function
08:07 - right so I will say sum
08:10 - ifs here the first thing is the sum
08:13 - range so I want to sum this
08:15 - range okay and now criteria range number
08:18 - one right criteria range number one is
08:20 - basically country so I'm going to select
08:23 - uh B2 to B1 128 what is the first
08:26 - criteria what is the first criteria I'm
08:28 - going to select if that ever matches the
08:31 - value here which is pain and then
08:34 - criteria range two criteria range two is
08:36 - basically the last column right
08:38 - basically our category column and what
08:40 - is actual criteria 2
08:42 - here criteria 2 is actually if it
08:45 - matches travel okay and I'm going to
08:49 - close and I get the value as 768 right
08:53 - so 768 is the amount I spent on travel
08:55 - to Spain if you see here it's a 280 here
08:58 - on a trip to mayor
09:00 - and there's one more Spain Madrid where
09:02 - travel was 488 if you add them up you'll
09:03 - get that number so that is the answer so
09:06 - some so some a column here in the case
09:09 - cost column but based on multiple
09:11 - conditions Country Must Be Spain at the
09:13 - same time the category must be travel
09:16 - okay another useful use case I would
09:19 - say then how many rows are there in the
09:22 - data that have category as travel okay
09:25 - so we want to count the number of rows
09:27 - here so this is a simple use case of a
09:30 - count if function okay so I'm simply
09:33 - going to say count
09:35 - if uh so this is the range again I want
09:37 - to check in this range right I'll select
09:40 - them all and I want to make sure how
09:42 - many of them equate to travel right so I
09:45 - have the word set up here already so
09:47 - I'll just click that sell and as you see
09:49 - there are 11 times in 11 rows there is
09:52 - some cost associated with travel right
09:54 - simple use case of the county function
09:57 - okay moving on to the next next one find
10:00 - the month of the date using a
10:02 - calculation in a new column so in this
10:04 - data we are given month right how can we
10:08 - find the uh I mean we given the date how
10:10 - can we find the month right I'm just
10:12 - going to show a dummy formula here how
10:14 - you can do it that's actually month
10:16 - function itself directly and you just
10:18 - select month of date okay and you close
10:20 - it you get 12 right so this is December
10:22 - 24 2022 so month is 12 so it gives an
10:26 - auto suggestion if you want you can rock
10:27 - the formula just go to remove it for now
10:29 - but you can use the month function as
10:31 - you see for that
10:33 - question next question use an if formula
10:36 - to show wherever cost greater than 100
10:38 - are expensive the other value should be
10:40 - shown as cheap okay so I'm going to go
10:43 - back here right so let's call this
10:47 - column like
10:48 - price or something like that so if it is
10:51 - greater than 100 so I will say if this
10:54 - value is greater than 100 right then it
10:57 - is expensive very simple
11:00 - otherwise I'll call it cheap right as
11:01 - simple as that and close the bracket
11:04 - okay so 20 is obviously less than 100 so
11:06 - it's cheap going to drag the formula so
11:08 - this is 230 obviously it's expensive and
11:10 - so on okay easy use case of a simple IF
11:13 - function many of times you might use
11:14 - this in your job as well
11:17 - okay moving on to the next one show
11:20 - pivot table for average cost per country
11:23 - right so what can we do I'm going to
11:26 - just select the whole range right all
11:28 - the rows and columns and now I'm going
11:32 - to just say insert pivot
11:34 - table and I'm going to put it in a new
11:36 - sheet going back to the question average
11:38 - cost per country right so in the rows I
11:41 - can add country right here it is and
11:44 - then in the values I can add the cost
11:47 - right I don't want to show the sum I
11:48 - want to show the average I will select
11:50 - the average so then I get the values
11:52 - right so as you see average cost per
11:55 - country um Colombia it's yeah around
11:59 - 164 uh other countries are like slightly
12:02 - lesser right what could be the reason
12:04 - right if we were asked to investigate
12:06 - one step further why this number is high
12:09 - if we go back into the data and deep
12:10 - dive a little bit you see mostly cost is
12:13 - like like this travel is maybe 200 300
12:16 - and so on but if you notice specifically
12:19 - for Colombia travel itself cost 2,600
12:22 - right this is the flight ticket going
12:24 - from Europe to you know South America is
12:26 - quite costly and this is the anomaly
12:28 - right this is the Reon why the average
12:30 - for Colombia is high right you you
12:32 - notice this is very high this is the
12:34 - reason you need to be able to
12:35 - investigate and find reasons like that
12:38 - because there is a abnormal value you
12:39 - should be able to find out what is the
12:41 - root cause of that abnormal value right
12:43 - this is an additional thing you could do
12:45 - for this
12:46 - question then uh simple uh calculation
12:50 - how would you display the first two
12:52 - letters for each country right so I have
12:56 - uh the country as a column here how can
12:58 - I display the first two letters for each
13:00 - country for example for austri I want to
13:02 - show Au we can use a simple text
13:04 - function called left so I would say left
13:07 - I select the string which is this and
13:09 - just say two right that will just show
13:11 - the first two letters so if I copy the
13:14 - same formula for instance for here for
13:16 - Slovakia you see you'll getl right very
13:19 - simple use case of LIF function very
13:21 - powerful function text
13:24 - function moving on write a function to
13:27 - find or check if a city name contains
13:29 - the letter V okay what can we do for
13:32 - this case so I'm just going to copy this
13:36 - data up to
13:39 - price and I'm going to go to a new sheet
13:42 - and just paste special like basically
13:45 - the values so now we want to check if
13:48 - the letter V is there in the word or not
13:50 - we can simply use a find function okay
13:53 - I'll write find so I want to search for
13:55 - the letter V and where do I want to
13:57 - search for I want to search for in the
14:00 - um I think it was city or country let's
14:03 - let's just go back here yeah it is for
14:05 - the
14:07 - city right so if it shows value
14:09 - obviously it's it's an
14:11 - error um because yeah it is not able to
14:15 - find it right so if I drag this formula
14:17 - down you can
14:18 - see bratis laava has the letter V none
14:21 - of these have anything plit has the
14:24 - letter V so the interesting thing to
14:26 - note here is VNA has the letter V but it
14:28 - has a cap capital V right that is the
14:30 - reason it is still showing a value error
14:32 - which means it cannot find V so let us
14:34 - convert this into a capital V and C then
14:36 - we get the value one because it is able
14:38 - to find a capital V in VN right so
14:40 - remember there's a differentiation
14:42 - between the small letter V and the
14:44 - capital letter V if we want a
14:47 - showcase next one formula to show the
14:49 - second third and fourth letters of the
14:51 - column category right I'll go to this
14:54 - new sheet second third and fourth
14:56 - letters right of column category which
14:58 - is here here so what we can do is we can
15:01 - try to use the mid function so I'll say
15:03 - mid of this particular string then I
15:06 - want to start from the second letter and
15:08 - then show the next three letters so I
15:10 - will put three so in break first I'll
15:12 - get second letter third letter fourth
15:14 - letter which is re now I can drag the
15:16 - formula down for lunch you will get UNC
15:18 - for dinner you'll get i n travel you'll
15:21 - get second third and fourth is r and so
15:23 - on okay another useful function to know
15:26 - uh mid right very relevant moving to the
15:29 - next question which country cost the
15:31 - most money overall according to the data
15:34 - right which had the highest
15:36 - cost so for this again we can just
15:40 - select everything right you can go to
15:43 - the pivote
15:45 - table and say create a pivot table so
15:48 - again I'm just going to select
15:50 - country and then I'm going to select in
15:53 - values cost right the total cost right
15:57 - as you notice here and then after that
16:00 - what can we do just think about it so if
16:03 - you notice here we want to arrange it by
16:06 - some of cost but descending right so
16:08 - what can we do we can go here and select
16:10 - sum of cost okay this should work and
16:13 - then we notice of course total cost RS
16:15 - Colombia and Peru are on on the top
16:17 - right overall cost RS these two are the
16:19 - most expensive right let me move to the
16:22 - next
16:23 - question so we are done with question
16:26 - this one right so conditional format
16:29 - rows which have country as Spain with
16:31 - red color date before 12th July 2023
16:35 - right any date that is before 12th July
16:36 - 2023 with blue color okay so let us try
16:39 - this I'll go to the original data so
16:41 - country as Spain right how can we
16:43 - conditional format let me go here format
16:46 - I'll say conditional formatting so for
16:48 - this whole set I want to apply a rule uh
16:51 - let us say text is
16:54 - exactly and then I will write
16:57 - Spain and I want to do red color right
17:00 - so I'll select red
17:01 - color and you know the rule is written
17:04 - and it's done okay so that means Spain
17:08 - is quoted red right let's see if there
17:11 - is some more Spain later yes it's also
17:13 - given red color right that's perfect
17:16 - okay let us move on to the next one
17:17 - which is for the date right so what they
17:19 - are asking us is anything before 12th
17:21 - July should be blue color so for example
17:25 - let me select one date I go to format
17:27 - conditional formatting and I I say for
17:30 - example this cell and I can say custom
17:34 - formula right this is cell uh A2 so I'll
17:38 - say if this
17:39 - is less than I will use the date
17:43 - function okay so date
17:44 - 2023 July is the 7th month 12 right
17:47 - anything before that please quote it
17:49 - with blue color okay and I will say done
17:53 - so by doing that yes this is before 12th
17:55 - July 2023 it is blue color and what I
17:58 - can do I can format paint and just drag
18:01 - it along all the way down to the end of
18:04 - the data right like this and I stopped
18:08 - here and now let's say which all got
18:09 - blue color so as you see all this date
18:11 - is 13th December so up to any date
18:13 - before 12th July which is like up to
18:15 - 10th July got coded with blue color okay
18:18 - this is how you can do conditional
18:19 - formatting for a particular column in
18:21 - Google
18:22 - Sheets so that question is done what was
18:25 - the highest value of cost in the given
18:27 - data this is a simple on line formula so
18:32 - you can say maximum of the value of cost
18:35 - in this column right which is the full e
18:38 - so I presume it will be 2600 which I
18:41 - already showed you right I think it's
18:42 - the travel that happened with if I
18:45 - remember right it'll be in bota like
18:48 - Colombia this is what it
18:51 - is okay moving on to the next question
18:54 - which category cost the most money in
18:56 - pero here instead of calculating I'm
18:58 - just going to go through the data right
19:00 - because there's not a lot of rows for
19:03 - per if we scroll down we see um you know
19:06 - plenty of uh combinations here so what
19:09 - can we probably do we can try to maybe
19:12 - do the P table again so I'm just going
19:15 - to select everything right these columns
19:19 - and I'm going to say insert P table okay
19:22 - the first thing I want to add is I want
19:24 - to add a filter for country that's the
19:27 - first thing um here we can select what
19:30 - we want to show want to clear everything
19:32 - and just show Peru right so it's data
19:35 - only for Peru now coming to row what can
19:37 - we add here we can add the category and
19:40 - then in the values I can add total cost
19:43 - okay so I have these values now order by
19:45 - I can see descending sum of cost okay so
19:49 - now I notice again with respect to Peru
19:52 - to an extent we can see that um travel
19:54 - is probably uh the costliest right and
19:57 - how do I know this is only Peru because
19:59 - here I selected only for Peru okay so
20:02 - travel is costing around uh 960 right
20:06 - that's probably one of the most
20:09 - expensive now let me move
20:11 - back now they're asking can you create a
20:14 - drop- down list of cities and show the
20:17 - total cost of a particular City
20:19 - depending on the city selected right so
20:21 - for this what we can do I'm going to
20:24 - copy um all this I'm going to go to a
20:27 - new sheet right I'm going to pay
20:29 - special I will say values only right now
20:33 - they want a drop down of cities how can
20:35 - we do a drop down for that we can go to
20:39 - data data validation right we can add
20:43 - rules but before that we want to find
20:45 - the unique values of cities right that
20:47 - will make our calculation easier so I
20:49 - will write
20:50 - unique and I will select the full list
20:53 - of cities right as a first step so I
20:55 - have the list of cities from this I can
20:57 - generate the drop now I can go back to
21:00 - data validation and say add rule uh and
21:04 - then from here I'm just going to say uh
21:08 - drop down from a range okay so it's
21:11 - going to apply to basically uh this cell
21:14 - over here right which is
21:16 - I3 which is written Here and Now drop
21:19 - down from a range I'm selecting and what
21:21 - are the values so I want to select all
21:23 - these values okay want to click okay and
21:26 - say done now now let's close okay so now
21:30 - I have the CT and now it's a simple
21:32 - matter of writing a sum IF function okay
21:36 - I'm going to say Su
21:38 - if then I'm going to say for instance
21:42 - City
21:43 - range so I'm going to select everything
21:46 - right and what is the criteria if it is
21:48 - equivalent to the one we have in the
21:50 - drop down which is
21:52 - I3 then please show the total cost so
21:56 - the sum range of this column which is
21:58 - column e
21:59 - okay so it's 143 for bratis laava now if
22:02 - I change it to Berlin it's 144 banal
22:05 - Luca is 281 and so on right if I change
22:07 - it to split was it's 252 and so on right
22:09 - the total
22:11 - cost uh depending on the city selected
22:13 - right we did data validation created a
22:15 - drop down how many unique months are
22:17 - there in the data how can we find this
22:21 - so uh to find this what we can do I mean
22:24 - we have so many months here right so we
22:26 - can first try to find the month so I'll
22:29 - insert one column to the left again
22:32 - right let me say
22:33 - month and then as you all know we can
22:36 - put a simple formula month of date A2
22:40 - that's
22:41 - done I'm just going to track this okay
22:45 - and now from this column I can simply
22:48 - write count unique right to count the
22:50 - number of unique months write the
22:52 - formula with the right spelling and I
22:55 - want to do it for H2 to H1 128 and then
22:59 - that's it so we have like we have only
23:02 - four unique months it's a little bit
23:05 - weird let's check we have
23:07 - 12167 and again 12 right more or less
23:11 - yeah so you have December if you notice
23:14 - then you have July
23:16 - June then yeah January there's there and
23:23 - then again December right so the count
23:27 - unique values
23:29 - says that it's only four so 12 1 6 and
23:34 - 7
23:35 - okay then moving on to the next one so
23:38 - this is a bit more complicated I think
23:40 - they want us to create a grid with
23:42 - countries on the one side categories on
23:44 - the other use the index match to
23:46 - Showcase formulas to display the total
23:49 - cost depending on a combination this
23:51 - question seems very very clumsy but
23:54 - let's break it down and see what it
23:55 - actually means right so for this
23:57 - question what I'm going to do is so
24:00 - they're asking based on countries and
24:03 - then
24:04 - categories and the total cost okay so
24:07 - easiest option I can think about is
24:09 - first I'll create a pivot table as usual
24:11 - I will say insert pivot table in a new
24:15 - sheet
24:16 - okay now step number one I will bring
24:20 - country to
24:21 - row then I'll bring uh category to
24:25 - columns and then for the values I want
24:27 - I'll click and say sum of cost okay so
24:30 - this is done now we have for all the
24:33 - different categories the thing so now
24:36 - they want us to create a drop down right
24:38 - so this is going to be a bit tricky so
24:41 - let us say I will have Austria here for
24:44 - example right just to show you a simple
24:47 - example then let us say I write dinner
24:50 - here okay so now for Austria for dinner
24:52 - what was the total cost right if we see
24:54 - the grid we see the value 12 how can we
24:56 - use index match to show this
24:58 - automatically right so what we can do we
25:02 - will have to use formulas right first I
25:05 - will try to
25:06 - match okay the value of Austria and see
25:10 - over in this crit which row does it
25:13 - match to I'm going to select all this
25:16 - and now I will get it matches the first
25:17 - row right because Austria comes in the
25:19 - first row so if I have to change this to
25:22 - Bosnia then it will show second row
25:24 - because in this list of values Bosnia
25:26 - comes in the second row right
25:28 - so this is one value the same match I
25:31 - will use to see where does dinner come
25:33 - in this full list of categories so I can
25:35 - say match of dinner right and now I want
25:39 - to compare it with this list of
25:41 - categories so I'm going to select all
25:43 - these values all the way up to travel
25:45 - okay and I put a zero because I want an
25:48 - exact match so it shows that dinner is
25:51 - the second column right if I were to
25:53 - let's say select game then it would be
25:55 - the fourth column right because break
25:57 - first dinner entrance game right so let
25:59 - me move it back to
26:01 - dinner so now I have where it comes in
26:05 - the country like which row and where it
26:07 - comes in the category like where where
26:09 - is the column basically now what we can
26:12 - do right once we do these two steps we
26:14 - can use a index
26:16 - function right and now what we need to
26:19 - do is we have to select the whole range
26:21 - right just select the range of the 13
26:24 - columns and the countries right no need
26:27 - to select the grand totals selecting the
26:28 - whole range and in this we need to put 2
26:32 - comma 2 right that was the value we had
26:34 - we get 40 right so instead of 2 comma 2
26:37 - I can make so I can substitute it with
26:39 - this cell values which is b19 and c19
26:43 - right so I'll make it
26:45 - b19 I'll make this
26:48 - c19 now I get 40 so for Bosnia for
26:51 - dinner it cost 40 right let us say now I
26:54 - change it to Peru so for Peru so this
26:57 - value has changed so Peru for dinner for
26:59 - Peru for dinner it cost $189 right so
27:02 - now the grid changes automatically if I
27:04 - change dinner to
27:07 - entrance for Peru for entrance right for
27:10 - Peru for entrance it cost 200 and we get
27:12 - that value now our value is dynamic so
27:14 - you need to match the column and the row
27:16 - and then put it into an index function
27:18 - for the whole array and then accordingly
27:20 - based on the row and the column your
27:22 - value will automatically change right
27:24 - cool use case of index and
27:27 - match moving to the next question 21st
27:30 - question can you use a filter function
27:32 - to Showcase only data when country equal
27:35 - to Colombia right so what I'm going to
27:37 - do again I'm going to copy this right
27:39 - the whole data I'm going to put it in a
27:42 - new sheet okay I'm going to pay special
27:46 - so filter function to show only the
27:48 - information when country is Colombia
27:50 - right so for this we can use a filter
27:52 - function which is directly there in
27:54 - Google Sheets I'm going to say filter
27:56 - right so let us say I want to filter the
27:59 - whole range of data so I'll select
28:01 - everything right and what is the
28:03 - condition that I want to
28:04 - apply I want to apply it for this column
28:07 - right basically country column and say
28:11 - whenever this is equal to columia we can
28:13 - write like
28:15 - this right so filter what is the range
28:18 - you want to show then which column you
28:20 - want to filter and what is the criteria
28:22 - here it has to be equal to Colombia so
28:24 - I'm going to write like that now you
28:25 - notice I got like with just one formula
28:28 - an array formula I got all the rows just
28:30 - for Colombia right basically Colombia
28:32 - and in that there was only one city
28:34 - which is bota right super powerful
28:36 - function filter so definitely learn it
28:38 - very good to
28:39 - know moving back to the questions
28:42 - they're saying use text join function
28:44 - maybe this is new for us to show cities
28:47 - separated by a hyphen depending on the
28:50 - name of the country right for one
28:52 - particular date of your choice right
28:54 - this seems very very confusing you know
28:57 - so so let us maybe go back to the data
29:02 - right over
29:04 - here so they are to select one
29:07 - particular date right so for example let
29:11 - us select just 24th December right
29:15 - there's only Austria in here but I will
29:18 - still copy this to a new
29:22 - sheet okay so for this date for the
29:26 - particular country right showcase all
29:29 - the cities separated by a hyphen right
29:32 - so in this case host has only one city
29:35 - right how can we apply this function how
29:38 - can we apply this so you'll have to say
29:40 - text
29:41 - join okay and then you want to separate
29:44 - them by hyphen you put that first then
29:47 - if you want if there is empty values if
29:49 - you want to ignore you can leave it
29:50 - blank so I'm going to leave it blank and
29:52 - then what do you want to showcase so I
29:54 - will basically put a filter formula here
29:57 - you say so here I want to basically
29:59 - showcase the
30:02 - city
30:03 - okay and the criteria is this thing
30:07 - should be equal to a particular country
30:09 - right Austria for
30:13 - example let's see what we
30:15 - get so I get VN VN V separated by hyphen
30:19 - right just like that hypothetically if I
30:22 - had something else like salsburg or
30:26 - something then as you see I'll get
30:28 - Vienna VNA salsburg Vienna right so
30:31 - essentially this is what it is if we
30:33 - want to test this formula on a better
30:36 - data I can also go back to my previous
30:40 - sheet right and grab some of the data
30:42 - where I have multiple countries right
30:46 - multiple
30:47 - cities like Peru has Lima on the
30:51 - different days kusco on a different day
30:54 - Machu picu on a different day right so
30:56 - maybe I can just grab
30:58 - some of this to just show you so I just
31:02 - copy all this come back to sheet
31:05 - seven right let me just uh paste it
31:09 - again here like this right so the
31:12 - columns are not sorted let me just
31:14 - delete them for now and also remove this
31:19 - column now what I can do here if I have
31:22 - to do text join I could do the same
31:23 - thing right text join D limiter here is
31:27 - the hyphen
31:28 - then I'm going to ignore the empty and
31:30 - the text so I can as usual put a
31:33 - filter want a filter for
31:35 - this and then I'm going to say based on
31:39 - the criteria that is this is equal to
31:43 - B okay now we get Lima Li basically all
31:46 - the city names they're coming in an
31:49 - order and hyphen is there to separate
31:52 - each of them right that is the whole
31:53 - purpose of this question so good
31:55 - function to not text join is not so
31:58 - complicated but not commonly used also
32:00 - but it's good to know it's like an
32:01 - add-on
32:02 - question which country cost the highest
32:05 - money for travel right so I think we did
32:07 - a kind of similar question somewhere
32:11 - so uh let's go back to one of the P
32:14 - table so here I have uh sum of cost
32:17 - right so like let me go back to edit
32:19 - which country cost the highest for
32:21 - travel right so here I'm going not going
32:23 - to show only one item I'm going to
32:25 - select
32:26 - everything
32:28 - okay and then let me just remove country
32:32 - from here right here I will add category
32:35 - right so I want to see only for travel
32:38 - right so I'm going to clear and select
32:40 - only travel that is Step number one okay
32:43 - and actually here in the row I'm going
32:46 - to remove category and I'm going to add
32:48 - country right and now the filter is only
32:51 - applying for travel as you notice which
32:54 - country cost highest for travel again
32:57 - it's Columbia 2600 as we can see we can
32:59 - also sort and see but yeah it cost the
33:01 - most for travel I think we did a similar
33:03 - question
33:04 - before insert a pie chart to show cost
33:07 - breakdown per
33:09 - category right so I can go back to pivot
33:13 - table 7 uh cost breakdown per category
33:16 - so what can we do um I'm just going to
33:19 - remove the filter here and uh instead of
33:23 - country I can add uh cost break down by
33:27 - category so I have this so I can now
33:30 - simply
33:31 - select this full thing right and I can
33:35 - say the
33:38 - chart and we get pie chart right so we
33:40 - get the percentages stay cost 19.7%
33:43 - travel was the most expensive 57%
33:45 - breakfast 4.8% DIN 4.6% and so on right
33:49 - simple pie chart can showcase okay which
33:52 - cost the most in a very visually
33:53 - appealing
33:55 - format then translate the word travel
33:58 - into Spanish right so here we can use a
34:01 - Google translate function itself so I'm
34:04 - going to say Google
34:06 - Translate what is the text right the
34:08 - text is travel I'm going to put that
34:11 - Source language right I want to
34:12 - translate it from English obviously this
34:14 - is English to Spanish Spanish will be es
34:17 - so if I translate this I get vaha like J
34:21 - sounds like a h sound so that means
34:24 - travel right so you can do that
34:28 - cool so we have done that let's move to
34:30 - the next question display total cost
34:32 - spent per month right Remember December
34:34 - was there in 2 years but they are
34:36 - looking at month level so we can use the
34:39 - same month although it was different
34:41 - years and let us see right so what can
34:45 - we do we can maybe go to the original
34:48 - data again right so I'm going to Simply
34:53 - sa
34:55 - insert first let me copy this to a new
34:58 - sheet
34:59 - right because I want to do uh the month
35:02 - calculation as well um let me just say
35:07 - paste special right I just want to paste
35:09 - the values so I'm going to do month and
35:11 - say month of um this date okay and then
35:15 - drag the formula so step number one step
35:20 - number two select them insert P table
35:24 - create
35:26 - so row will have
35:28 - month then values will have sum of
35:32 - cost and then percentage of total right
35:36 - so for that here you can see uh values
35:39 - is shows as you can select percentage of
35:42 - column then that will show okay 80% of
35:45 - the cost came from December right this
35:47 - is an easy way to do
35:50 - it okay let's move to the next question
35:53 - how many days were spent in Spanish
35:55 - speaking countries right how do we know
35:58 - which is Spanish speaking this like
36:00 - needs some basic knowledge so here I
36:01 - know for example Spain Colombia and Peru
36:04 - are the Spanish speaking countries right
36:07 - so what can we do I can again copy this
36:12 - data and put it into a new sheet I will
36:15 - pay
36:17 - special okay then I can put a filter and
36:20 - only select Spanish speaking countries
36:22 - right what is those Peru Spain and
36:26 - Colombia right so these are the dates
36:29 - now count the unique days right so I'll
36:31 - simply say count
36:33 - unique of this right so now now I have
36:36 - the filter data let's say I can copy
36:39 - this and put it into another new sheet
36:42 - right so now here I have only Spain
36:45 - Peru and Colombia right now I can find
36:49 - the unique number of days so I can say
36:51 - count
36:53 - unique of this column
36:56 - basically so there are about 22 unique
36:59 - days I have spent in these Spanish
37:00 - speaking
37:01 - countries right that is there then
37:04 - concatenate country and city separated
37:07 - by a hyphen right this seems a simple
37:10 - question how can we uh concatenate
37:12 - country and
37:13 - city so let
37:16 - us go to the original data again or this
37:20 - column for example I'm going to remove
37:22 - the filter again right concatenate
37:24 - country and city so we can do it two
37:27 - ways is you can use
37:31 - concate this one which is country then
37:34 - put a hyphen and then select the city
37:37 - right this is option number one Austria
37:40 - hyphen Vienna option number two is you
37:43 - can select this put an Amper sand then
37:45 - hyphen Amper sand and then the city C2
37:49 - right so either use Amper sand or you
37:51 - can use concatenate function both are
37:53 - going to work to do
37:56 - this then how do you remove duplicates
37:58 - from the country column so this is also
38:01 - very straightforward we go back to the
38:04 - original data let us copy the country
38:06 - column into a new sheet so I'm going to
38:09 - Space special values so now if I want to
38:11 - remove duplicates I can get to data data
38:14 - cleanup remove
38:16 - duplicates and now I get the only the
38:18 - original countries the unique countries
38:20 - which is eight Austria Slovakia Germany
38:21 - Spain Bosnia Croatia Colombia and Peru
38:24 - okay so I hope you enjoyed the video we
38:27 - have managed to solve all the questions
38:28 - I'll post the sheet also in our
38:30 - description have a look at it just to
38:32 - finish off suppose some of the formulas
38:35 - you're not aware of right you can
38:36 - obviously use chat GPT so I'm going to
38:39 - show you
38:40 - some interesting examples where even if
38:44 - you don't know the formula how you could
38:45 - leverage CH GPD let us take simple
38:47 - example of that Google translate
38:49 - question for travel so you can write
38:51 - write me a Google translate function in
38:55 - Google
38:56 - Sheets to convert the word travel from
39:01 - English to Spanish okay simple example
39:05 - chat jpt will probably give you uh the
39:07 - formula Google translate
39:09 - function says travel and Es right is
39:12 - English es the target language is
39:14 - Spanish right so simple level it can
39:17 - easily teach you things like this right
39:21 - if we are to just give it one more
39:23 - scenario for example here I have like
39:25 - the data right let's say is in column B
39:28 - cost is in column B I want to find only
39:31 - the total cost for Country Spain right
39:36 - we want to do some if but let's see if
39:38 - we can generate that using chat gbt
39:40 - right I have column b as
39:44 - country column e as
39:47 - cost write me a sumi formula to
39:53 - show only the cost when the
39:58 - column has value let's say Spain
40:05 - right and it's going to give a simple
40:07 - sum if formula it's assuming that a head
40:09 - us so it simply says sum if B is to be
40:12 - Spain and
40:13 - then do the cost of that column right so
40:17 - if I can copy this code come
40:20 - here and
40:24 - paste that's a double equal to let me
40:26 - just remove that you see we get 1747
40:29 - which is kind of the cost for Spain okay
40:32 - so if you're not aware of the formula
40:34 - also you can use chat GPD please
40:36 - remember that give the right prompts and
40:38 - you will learn the formulas okay I hope
40:40 - you enjoyed the video I'll see you again
40:42 - in another project if you like the video
40:44 - subscribe to the channel follow us for
40:46 - more videos there are more topic related
40:48 - videos like this with projects on SQL
40:50 - python coming up stay tuned spreadsheets
40:53 - are a great tool to start with however
40:56 - not always you get data in spreadsheets
40:58 - especially if the data is very large it
41:01 - becomes prudent to understand how to
41:03 - write queries and get data from
41:05 - databases in this coming project we are
41:07 - going to use Google be query to write
41:09 - SQL queries and analyze information on
41:13 - my own expenses data from 2023 this
41:15 - expenses data has detailed breakdown of
41:18 - expenses across various categories we
41:20 - are going to write simple and also
41:23 - intermediate and advanced SQL queries
41:25 - using Google B query to drive in
41:27 - sites so once again welcome to this
41:30 - practical project we going to use real
41:32 - data to understand and learn SQL write
41:34 - queries and make insights and we're
41:37 - going to use Google B query okay so I
41:39 - have some data here for example there's
41:41 - the date uh the company basically where
41:45 - this expense was done uh there is
41:47 - something called category ID we'll learn
41:49 - about this further and what was the cost
41:51 - rate like what was the amount spent so
41:54 - there's a separate table called category
41:56 - ID and C category so you have category
41:59 - ID and the category so for example one
42:02 - is rent five is recharge eight is
42:04 - shopping and so
42:05 - on now we're going to try and answer
42:08 - questions by uploading this data to
42:10 - Google bigquery we are going to answer a
42:12 - lot of questions okay so what is the
42:14 - first step we can go and put this URL
42:17 - I'll put it in our description as well
42:20 - and you'll land
42:22 - in a place like Google bigquery okay now
42:25 - you can say create project
42:28 - as a first step give it a name big query
42:32 - analysis right you can give whatever
42:34 - name you want I'm going to say create
42:37 - okay that's the step number
42:39 - one it will take some time to create a
42:42 - project okay and this is where we can
42:44 - actually upload our data and start
42:46 - writing
42:48 - queries so now it's loaded so over here
42:51 - I can go and say create data set so data
42:55 - set let me say uh
42:57 - expenses okay I can give it any name I
42:59 - want rest you can leave it as such and
43:02 - just say create data
43:03 - set okay so now I have a data set called
43:06 - expense in this I can upload tables okay
43:09 - so how are we going to upload tables so
43:11 - I'm going to go and download
43:13 - this as a CSV file okay so downloaded
43:19 - that same way we will download category
43:21 - also as a CSV
43:23 - file now I have downloaded both so I can
43:26 - go go here and say first of all create
43:30 - table so I want to upload a table so
43:32 - I'll select upload so as a first step
43:35 - I'll select uh the data
43:37 - table okay and I can give it a name data
43:40 - over here I will say Auto detect and
43:43 - create
43:44 - table right so first I'm uploading the
43:46 - data
43:50 - table so now we have the data table
43:54 - loaded you can go to 3D buttons and
43:57 - click on query and you can select
43:59 - everything from the table right I will
44:01 - just remove this uh limit so if you
44:04 - select everything from the table you get
44:06 - the data now okay so basically here what
44:10 - you have is bigquery analysis 41260
44:13 - that's the name of the project expenses
44:15 - is the name of your data set and data is
44:17 - the name of your table okay you can also
44:19 - go here and click on open to understand
44:21 - the data types like there's date column
44:23 - which is date company is a string
44:26 - category ID is an integer cost is an
44:28 - integer okay same way I want to upload
44:31 - the other table which is category so I
44:33 - will again say create table I'll say
44:36 - upload and I want to browse my computer
44:38 - to upload so I'm going to come and say
44:41 - uh
44:42 - category and give it a name category
44:44 - itself right so it's easy to understand
44:47 - Auto detect and
44:48 - create okay again it might take a few
44:51 - seconds and it will finish loading so
44:53 - now I also have the category table so if
44:55 - I say query nice select
44:57 - star I'll be able to see the category
45:00 - table right so as you notice category
45:02 - table as category ID uh the data table
45:06 - also has category this is the common
45:07 - column between the two okay now we have
45:10 - both the data sets ready and the tables
45:13 - ready so let's start U writing our
45:16 - queries and answering
45:17 - questions first question find the unique
45:20 - categories in the data table okay so I'm
45:22 - going to go here so how do you do unique
45:25 - categories
45:28 - I can say
45:30 - distinct category ID right as simple as
45:35 - that and then I just run the
45:39 - query so of course there is 1 2 3 4 5 6
45:42 - 7 8 9 in the data
45:44 - table okay so I'm going to copy the
45:46 - query and I'm going to save it here okay
45:48 - that's the query so next one show the
45:51 - purchase which had the highest cost okay
45:54 - so let me go back to this table and
45:57 - select
45:58 - everything so the purchase which had the
46:00 - highest cost so basically we want to
46:02 - find the maximum right so I can simply
46:05 - say maximum of cost right this is a very
46:07 - simple formula to get started these are
46:10 - more like warm-up questions so we get
46:12 - 630 right so that is the answer so I'm
46:16 - just going to copy this and come here
46:18 - and paste the query okay write a query
46:21 - to show only first 20 rows of data so
46:25 - what is the logic we need to use so if
46:27 - you say select everything you'll
46:29 - obviously get all the rows right so if
46:32 - you have to select only the first 20
46:35 - rows of data what can we do we can
46:37 - simply write U the statement called
46:40 - limit okay so you can say limit
46:42 - 20 uh when you write that it's going to
46:44 - show only 20 rows as you see here now we
46:47 - are only able to see 20 rows okay so I'm
46:51 - going to save this query as well so
46:53 - these are all pretty
46:55 - quick um
46:58 - yeah like if it's multiple lines it's
46:59 - coming here so maybe I'll remove it from
47:03 - here and yeah I can paste it here okay
47:08 - so this is question uh number three
47:15 - okay maybe I'll just create question
47:20 - numbers okay so 1 2 3 and so on then you
47:24 - know you can just do like this
47:27 - so this was question number
47:29 - three
47:31 - right now let's move to the next
47:33 - question show the unique company names
47:36 - where money has been
47:39 - spent so I go back here and I say select
47:46 - everything so unique company names where
47:49 - money has been spent so I can simply say
47:50 - distin company right it's very similar
47:52 - to one of the previous questions we just
47:55 - solved so so you see you see the company
47:59 - names like there are like a lot like
48:01 - close to 21 company names these are the
48:04 - unique names where money has been spent
48:09 - okay so I'm going to come back here and
48:12 - I'm going to say question four and paste
48:14 - my query
48:18 - okay let me go back to the questions
48:21 - next question how many unique days has
48:23 - money been spent in each month so in
48:26 - each month how many unique days right so
48:28 - for that first we need to also find the
48:30 - month so how can we do this question so
48:33 - let me say select everything from the
48:37 - table right so now I have a lot of days
48:40 - like Jan Feb March April and so on uh
48:43 - 2023 there I think even May and June so
48:47 - what can we do for month we can try to
48:50 - use a formula called extract of month
48:55 - from date okay
48:57 - so if I run this query let's see what we
48:59 - get we're able to get the months right 1
49:02 - 2 3 4 5 6 the question here is Unit t
49:07 - money has been spent in each month okay
49:10 - so I can select the month and unique
49:13 - days what can we do for Unique days you
49:15 - can do a count of distinct date
49:18 - right um and then you can do that and
49:22 - then uh Group by this uh extract of
49:26 - month from date itself right so that
49:28 - will give for each month the unique
49:30 - number of
49:31 - days let us now run the query
49:36 - right so as you notice in uh one month
49:40 - one which is January 13 unique days some
49:42 - kind of purchase was done in month
49:45 - through February it was 18 and so on
49:47 - okay so the highest seems to be in March
49:49 - when there was something spent on 21
49:52 - unique days right that's why we are
49:53 - doing count of distinct date so this is
49:56 - going to
49:57 - be question number
50:00 - five so I'm going to paste the
50:04 - query okay let's move to question number
50:07 - six for the above question do the same
50:09 - just show it in descending order right
50:12 - so what is the difference here the same
50:14 - thing I want to show in descending order
50:15 - of this count distinct date so I can
50:18 - simply say order by count of distinct
50:23 - date and then say descending Okay so now
50:27 - we will see the month of March which are
50:29 - the highest number of unique days on top
50:31 - right now this is in descending order so
50:33 - I'm going to copy this and uh this is
50:36 - going to be question number six right
50:39 - almost same we are just also doing some
50:41 - kind of sorting okay that's question
50:44 - number six and anyways I'll put this in
50:46 - our description the solution also so you
50:48 - can use it later let's move to the next
50:51 - question show only data of category ID
50:54 - 3A 4 okay this is question number seven
50:58 - so again I'm going to just delete all
51:00 - this and I'm going to say select
51:02 - star
51:06 - okay uh category ID 3 comma 4 only that
51:09 - so what we can do it's a very simple
51:11 - thing so you can say where category ID
51:14 - in 3A 4 right you need to use the inst
51:16 - statement so this will only show all the
51:19 - data all the expenses of these three
51:21 - Cate I mean these two categories three
51:23 - and four as you see right if you see a
51:25 - lot of four
51:27 - uh Category 3 is very minimal I think
51:29 - just once so that's the
51:32 - answer okay this is question number 7 so
51:35 - I'm going to paste the query
51:39 - here okay let's move to the next
51:42 - question question number eight what is
51:44 - the highest category ID of expense in
51:46 - March right so we also want to filter
51:49 - for the month
51:50 - year let's go here highest category ID
51:53 - of expense in March okay so first of all
51:57 - what we can do we can say where extract
51:59 - of month from date is equal to three
52:03 - okay because we want for March category
52:05 - ID with the highest expense so what we
52:07 - can do we can write category ID can do
52:10 - the sum of cost right the total
52:12 - cost and then we want to group by
52:15 - category
52:17 - ID right and not only that they want the
52:20 - highest right so I can also do order by
52:25 - sum of cost descending right very
52:28 - similar to the previous question so what
52:30 - I'm doing here is I'm just filtering for
52:32 - month number three which is March for
52:34 - each category ID the total cost and then
52:37 - grouping by category ID obviously and
52:39 - then also ordering by sum of cost
52:41 - descending so that we can see the
52:42 - highest on top okay so now let me run
52:46 - this
52:47 - query and we can see category ID 1 had
52:50 - the highest expense it was 630 we don't
52:52 - know what this is we'll see it later but
52:54 - category id1 had 630 EUR worth expenses
52:58 - so I'm going to copy this query so this
53:00 - is question number
53:03 - eight okay so we're done with question
53:05 - eight let's move to the next question
53:07 - question n which store I think by store
53:10 - they mean the company had the highest
53:12 - expense in
53:13 - May okay so now it's May so I'm just
53:18 - going to change this uh some of cost is
53:21 - the same so when they mean store it
53:23 - means company so I'm going to select
53:25 - company and and then Group by company
53:28 - right and order by sum of cost
53:30 - descending because I want to see the
53:31 - highest and this is for the month of May
53:34 - so let me run this I notice okay Prima
53:37 - again right like this is the rent that I
53:38 - spend usually every month so Prima has
53:41 - the highest the next one is re which is
53:43 - a kind of
53:44 - Supermarket okay so this is how you can
53:47 - do this question month number five me uh
53:50 - which company or store had the highest
53:52 - expense so I'm going to copy this again
53:55 - this is question number n
53:59 - right so we'll keep
54:01 - moving next is question number 10 uh
54:04 - question number 10 which category had
54:07 - the
54:08 - lowest total number in February
54:12 - right lowest total number I think they
54:15 - mean lowest total cost for February
54:18 - which category okay so now there is a
54:20 - small twist so here right in the data
54:25 - table if you noce
54:28 - I say select
54:32 - everything just going to close
54:36 - this and say
54:40 - start so if you notice here I have only
54:43 - category ID I don't have the name of the
54:44 - category category comes from this table
54:47 - right so if I click on this table there
54:49 - is category ID and category right so we
54:51 - can try to join on category ID between
54:53 - the two
54:54 - tables uh and we need to find for uh
54:57 - February okay so what can we do here so
55:00 - I will take from this table data
55:06 - table I will call it as a and I want to
55:09 - join this with basically um the other
55:13 - table so the other table name is also
55:16 - the same almost so I can copy like this
55:18 - and instead of data the table's name is
55:21 - category right I'm going to substitute
55:23 - it like that and say as B right so we
55:26 - going to try and do a join and what is
55:28 - the common connection both have category
55:31 - ID right so I'm going to say a do
55:33 - category ID equal to P do category ID
55:36 - right and now from the second table I
55:40 - can select the category and from the
55:42 - first table I can select the total cost
55:46 - okay I can do this and then I group
55:50 - by B do
55:53 - category and what else uh for f February
55:57 - right so I need to also do One V
56:00 - condition so where extract of month from
56:04 - date right that filter is equal to two
56:06 - right two means
56:08 - February so let's run this and
56:12 - see It'll be again rent only rent is
56:15 - highest usually but then next one we see
56:17 - it is grocery right 276 which makes
56:19 - sense to rent grossery is usually my
56:21 - highest expense so some restaurant and
56:24 - other things we can see as well okay so
56:26 - this is how you can join on a common
56:27 - column put a filter and also Group by to
56:30 - see the cost
56:33 - right all right so I'm going to just
56:35 - copy
56:38 - this this is question number 10 right so
56:41 - I'm going to paste it here and let's
56:44 - continue question number
56:46 - 11 show the data only where shop name I
56:49 - guess this means company name contains
56:51 - the letter W
56:53 - okay so this is just one table
56:57 - again so I will say select everything
57:00 - from this
57:02 - table shop name right so we where we can
57:04 - say company like percentage W percentage
57:09 - so this means that using the like we can
57:11 - find whichever contain the letter of the
57:14 - world W so you have for instance re
57:18 - right majorly and WW Worth right capital
57:20 - W it starts with that letter so these
57:22 - are the
57:24 - shops right so I'm going to copy this
57:28 - and paste it here this is question
57:29 - number 11 moving on to question number
57:34 - 12 find a way to get the category based
57:36 - on category ID this is what I showed you
57:39 - just a while back so let us say from
57:41 - this table I select everything I'll say
57:43 - a. star I will call it as a how can we
57:47 - join with the other table can simply do
57:50 - a
57:52 - join and yeah just copy this table name
57:56 - and then just replace the last part
57:58 - instead of data it is category table so
58:01 - I can do
58:03 - that as
58:06 - B and then you can say on a. category ID
58:11 - equal to b. category ID
58:17 - right and I can say b. Star as well
58:20 - right so I'm joining both the tables let
58:23 - me see whatever is possible so now I can
58:26 - see okay company Prima category ID 1
58:29 - second table also has a category ID so
58:31 - since it's a duplicate column name it's
58:33 - giving underscore one and what is the
58:35 - actual name of category so one is rent
58:37 - two is
58:38 - Crosser and so on right so we'll if I
58:41 - move
58:42 - forward uh I see six is ticket seven is
58:44 - cosmetics and so on right this is how
58:46 - you can join both the
58:48 - tables I will just copy this okay this
58:51 - is question number
58:53 - 12 okay let's move to next question
58:56 - question number
58:58 - 13 is there any category ID not present
59:01 - in the data table okay how can we do
59:04 - this so first of all let us sect this
59:09 - table right category table the original
59:11 - table and let's see what is
59:15 - there so over here I see 1 2 3 4 5 6 7 8
59:19 - 9 10 right so 10 unique category IDs but
59:23 - if I were to see the original table the
59:26 - other one data table and say from that
59:29 - table distinct category
59:35 - ID so I see 1 2 3 4 5 6 7 8 9 right so
59:40 - that means category ID 10 is actually
59:41 - missing from data table but how can we
59:44 - show this right is there a way to show
59:46 - this by comparing the two tables right
59:50 - so what we can do here so we can
59:53 - select disting category ID this is
59:55 - obviously an option and then manually
59:57 - compare but other than that what we can
60:00 - do we can make our category
60:04 - table like primary like
60:08 - this as a this
60:12 - time okay and then I'm going to join
60:17 - this with data
60:21 - table as
60:23 - B okay so for so good on a. category ID
60:29 - equal to b. category ID right this is
60:32 - very simple so again I can select
60:34 - everything from both tables for sake of
60:37 - Simplicity and
60:41 - then here you have to write a join but
60:43 - I'm going to do a left join right so
60:45 - what left join will do is it will show
60:47 - all the category IDs from the category
60:50 - table if there's a match in data table
60:52 - it will show the match otherwise it will
60:54 - show null Okay so do like
60:58 - this let's see what happens we get 115
61:02 - rows okay so you can scroll down can
61:04 - even make this 200 so I see all the
61:07 - results in one page if you notice I will
61:09 - see everything right all the data but at
61:12 - the bottom right category Ed 10 is not
61:14 - there in the data table so you get
61:16 - everything is null right so how can we
61:19 - now spot only the ones which are null
61:21 - you can say where uh B do let's say d
61:25 - date is null right any column which is
61:27 - null you can just pick that because when
61:30 - there is a match obviously there'll be a
61:32 - date and data table then we see this
61:34 - right then we see this category ID this
61:36 - is the one that is there in the category
61:38 - table but it is not there in the data
61:40 - table right so there is no not been any
61:42 - expense related to this category
61:45 - others so I'm going to copy this this is
61:48 - I think question number 13 okay again a
61:51 - simple use of left
61:52 - join now let's move to question number
61:55 - 14 show categories with expense more
61:57 - than 150 for the month of April
62:01 - right so again uh let
62:05 - us delete this so this time I I will
62:09 - make our data table as primary as usual
62:12 - I will make
62:13 - our category table as
62:17 - secondary okay and I just want to do a
62:19 - normal join right wherever there are
62:20 - matches so that is all fine on will
62:23 - still remain the same now from the first
62:26 - table again I want to know the
62:28 - category right and what do we want uh
62:31 - expenses so I'll
62:33 - say uh category actually comes from the
62:35 - second table right B table so I'll do B
62:38 - do category and from the first table I
62:40 - want to do cost so I will say sum of a
62:42 - do cost is there any other filter month
62:45 - of April right note that down so where
62:48 - extract
62:49 - of month from date right so April is the
62:52 - fourth month so we can say is equal to 4
62:56 - then Group by B do category right this
62:59 - is Step number one now let us see what
63:01 - we get so we get a lot of expense okay
63:05 - and now they want to show only those
63:06 - with more than 150 okay so what can we
63:09 - do here we can simply say having right
63:12 - on an aggregated calculated column we
63:15 - can put a filter like using having
63:17 - having sum of a do cost greater than 15
63:20 - now we'll see only those categories it's
63:22 - going to be rent and grossery the rest
63:24 - are below 150 right nice use of the
63:27 - having
63:28 - Clause this is question number
63:32 - 14 okay so let us move to question
63:35 - number 15 they're asking any patterns in
63:38 - ticket expenses over time right so what
63:41 - do they mean let us uh combine both
63:45 - these tables together right and I'm
63:47 - going to say a. star comma B Star right
63:52 - so let's see what we
63:54 - get so there is a category um let's see
63:59 - if there's a category like ticket so
64:00 - I'll say where category equal to ticket
64:04 - okay not sure if there is something like
64:06 - that but let's
64:09 - see okay so there is no data Maybe it's
64:12 - capital T let's try like
64:16 - that and you see DB is do bond company
64:20 - where I spend for tickets yes there are
64:22 - ticket columns they're asking any
64:24 - patterns Okay so so maybe what we can do
64:26 - now we can try and do it like per month
64:30 - right so I'll say as
64:33 - usual uh maybe I'll extract the month
64:36 - right so I'll say extract of month from
64:39 - date which we usually do and uh patterns
64:43 - so I'll try to put some
64:46 - of cost
64:48 - itself
64:50 - right and here it should be b. category
64:53 - equal to ticket and uh now group
64:56 - by basically this extract of month from
64:59 - date so I'm going to copy that I'm going
65:01 - to paste it here okay if you notice here
65:04 - just by looking at it there's a lot of
65:06 - 33s but then there's a 98 as well so
65:09 - let's see what has
65:12 - happened okay so January was 33 Fe Fe
65:16 - was
65:17 - 33 uh for some reason in March there's
65:20 - been a lot of expenses it's become 99
65:22 - April is 66 then from May B basically
65:26 - this uh Dand ticket started so me and my
65:28 - wife each took for 49 so it became
65:31 - standardized okay so for some reason
65:33 - March there have been lot of trips so it
65:35 - has increased right so that is the trend
65:37 - in terms of tickets so I'm going to copy
65:40 - this this is question number
65:43 - 15 okay I'm saving all the queries so
65:46 - you'll have
65:47 - access next which restaurant has
65:50 - received the maximum
65:51 - orders based on
65:54 - days right right so that means like
65:57 - which restaurant has received the orders
65:59 - on the unique number of days right
66:01 - that's what it means actually so
66:04 - restaurant obviously is a category so
66:08 - I'll put
66:10 - restaurant okay and here the company
66:14 - right company is where the name of the
66:16 - restaurant or the name of the shop is
66:19 - there so I will say company and the
66:22 - question is maximum orders based on
66:25 - number of of days so we want to count
66:27 - the unique days which we kind of did
66:29 - little bit earlier so count of
66:33 - distinct date right for the restaurant
66:37 - category so first let's run that and
66:40 - see so so many restaurants are there
66:42 - right sound is there Kebab shop is there
66:45 - so Panda seems to be the highest we
66:48 - could also simply say order by count of
66:52 - distinct dat descending right so pandas
66:54 - is a restaurant where we buy
66:56 - MOS that has been the most prominent in
66:59 - the six months being there nine times
67:02 - right that's the highest so another
67:04 - interesting use case of count distinct
67:05 - order by alongside group bu okay so this
67:09 - was question number 16 so I'm going to
67:12 - paste the
67:13 - query let's move
67:15 - further 17th question calculate average
67:18 - spend per day for restaurants okay
67:22 - average spend per day that means you
67:24 - have to find the total cost and divide
67:26 - it by the number of unique days you been
67:28 - to the restaurant right this is one way
67:32 - of doing it so the cost is what sum of
67:37 - cost divided by count of unique days
67:40 - right this will kind of you could also
67:41 - do count of date uh this is also another
67:44 - option right assume that maybe on the
67:47 - same day you been to two restaurants
67:50 - then this number can change so anyways
67:52 - let us do both the calculations and see
67:55 - what is coming so basically average
67:57 - spend per day for restaurants so I'm
67:59 - going to do with unique
68:02 - days so it shows on average when we go
68:04 - to a restaurant we spend around 15 right
68:07 - based on unique days if I change this to
68:09 - days right let's see what
68:13 - happens yeah slightly lesser 14.5 but
68:16 - still it's 14 to 15 Euro on every visit
68:19 - on average to a restaurant okay so
68:21 - that's what
68:23 - happens so I'm going to save this
68:25 - question number 17 right that's
68:26 - basically that 14 to 15 is the amount we
68:29 - spend on average when we go to a
68:31 - restaurant right some may be lower some
68:33 - may be
68:33 - higher we we are not sure about that but
68:37 - basically that is the overall
68:40 - average which day of week saw the
68:43 - highest spend in me right so we need to
68:48 - know the function for day of week is it
68:50 - there maybe we can also check with chat
68:52 - gbd highest spend for the month of May
68:55 - so remember it's for the month of
68:57 - May so this is question number
69:01 - 18 right which day of week so here we
69:04 - don't even need the category table so
69:06 - I'm going to remove that so I have date
69:10 - right so we have this function called
69:13 - format date and you can say like
69:17 - percentage W so if you're not sure we
69:20 - can go and ask chat GPT as well right so
69:22 - always chat GPT is there to
69:24 - help
69:26 - so Group
69:30 - by week day or day of
69:33 - week in Google big
69:36 - query and find total
69:38 - cost please tell me formula something
69:42 - like that you know you can type
69:43 - something like this should
69:46 - give and it's going
69:49 - to give you a general
69:52 - example it's giving sales date
69:56 - and it's saying format date okay
69:59 - percentage a right that seems to be
70:02 - useful so we will just copy that so as
70:06 - you see Sunday is
70:08 - 1 um Saturday is 7 right so let's go and
70:12 - try
70:14 - that here we have
70:17 - date the question is highest spending me
70:20 - okay so we still need to keep that in
70:22 - mind so I'll say sum of cost okay that
70:25 - is is obviously there and then Group by
70:30 - this so This step is covered but before
70:34 - that it is May so I have to say where
70:37 - extract of month from date is like it's
70:41 - month number five so I have to put five
70:44 - right let's run this and
70:47 - see so as you see we already get the day
70:50 - so we
70:51 - get different ones so it looks like
70:54 - Tuesday is the
70:56 - highest
70:59 - right and this is all categories put
71:02 - together it looks like Tuesday is
71:04 - highest obviously this is 7:34 that is
71:07 - because maybe on that day I paid the
71:09 - rent right rent itself is 6:30 that is
71:11 - the reason right that becomes a big
71:14 - number but other than that you see
71:16 - wedness day is also quite high right for
71:18 - the month of May so I'm going to copy
71:21 - this this is question number 18
71:26 - okay I'm going to leave it here let's
71:29 - move to the next question question
71:31 - number 19 calculate total cost for
71:34 - grocery per month and show month in year
71:37 - and month format right separated by
71:40 - hyphen so total cost for grocery per
71:43 - month so let's go back here and let's do
71:48 - the join again right because we need to
71:50 - identify uh this particular uh category
71:54 - called as grocery so for that we need to
71:57 - join back with the category
72:02 - table so I'm going to again write
72:04 - category that is Step number one and
72:07 - what is the common column on a. category
72:10 - ID so we just going to repeat the same
72:11 - thing
72:14 - again this is done now where Clause we
72:17 - have to put where this B do category
72:21 - should be equal to grocery right it's g
72:23 - with the capital
72:27 - and I think the spelling here is wrong
72:29 - okay and now we want to find total cost
72:34 - per month and show the month in year and
72:36 - month format so for that what we can do
72:40 - like percentage a you also have
72:43 - percentage y percentage M right this
72:45 - will show in year month format total
72:48 - cost okay I think that is pretty much it
72:52 - and I can also do a group by right and
72:54 - what do I want to group by I want to
72:56 - group by this year
72:57 - month so I guess this should be
73:00 - it let's
73:02 - run the question is total cost of
73:04 - grocery per month so for example January
73:07 - is 210 May is 183 Feb is
73:11 - 276 March is 178 April is 174 and so on
73:15 - right June is also pretty
73:18 - less and what else have they asked they
73:20 - just asked to calculate that so I'm just
73:22 - going to copy this right I'm going to
73:24 - put it here as question number
73:28 - 19 okay let's move
73:31 - further question number 20 calculate
73:33 - total spent for shops starting with
73:36 - capital letter r okay I think they want
73:39 - like for example stuff like
73:42 - R so I'm going to just say sum of
73:46 - cost from the original table I don't
73:48 - want to
73:50 - join and uh the column name is company
73:53 - so I'll say where company like
73:56 - R percentage right so that starts with
73:58 - the letter
74:00 - A so just give us the value 859 so if I
74:04 - want to see what are the companies you
74:06 - can also do a group by so you can just
74:08 - do like this and then say Group by
74:11 - company not sure if there is anything
74:13 - else anyways let's see right there's R
74:16 - and Rosman right that's pretty much it
74:18 - so I'm going to just copy this this is
74:20 - simple question number 20 right so we
74:23 - kind of getting closer to the end let's
74:27 - continue 21 how many unique companies
74:30 - exist in the shopping category right so
74:33 - again we have to go back to the join
74:38 - right so maybe I'm going to come here
74:40 - and
74:42 - uh pick this up
74:45 - right I'm going to put it back
74:48 - here so the question goes like this
74:52 - unique companies that exist in the
74:53 - shopping category okay
74:55 - so we can say where B do category right
74:59 - equal to
75:01 - shopping so I will just say select Star
75:05 - right first let's see if there's
75:07 - something like this actually for
75:08 - spelling is right for shopping yeah we
75:10 - have for instance Teddy Amazon and wwor
75:14 - I think that is pretty much it anyway I
75:16 - will say distinct company that will give
75:18 - us the distinct
75:21 - values so Teddy Amazon Worth right only
75:23 - three companies are unique that exist in
75:26 - the uh shopping category okay that was
75:29 - question number I remember
75:33 - 21 okay move to question number 22 what
75:36 - is the spending pattern at re month-wise
75:38 - and any insights okay so we can go back
75:43 - and pick
75:45 - this question up right I'm going to copy
75:50 - this so R and month-wise right so I
75:54 - don't really need the join here I think
75:57 - we just need the original table so I
76:00 - want buy month so I'll put
76:03 - company comma per month total cost and
76:07 - then Group by
76:09 - company as well and
76:13 - uh we can say where company equal to
76:18 - reev right I think this should
76:22 - work so the question again let's see
76:25 - it's question 22 spending pattern at R
76:27 - month-wise okay so R January 128
76:31 - February 128 right very very
76:33 - standardized March 104 so March and
76:36 - April 145 March has dropped a little bit
76:39 - I think right and then um yeah it's 12
76:43 - 13 it's very very stable pretty much
76:45 - around the same Mark as you see more or
76:48 - less so it's like 120 130 that kind of
76:52 - range right so there's no Trend but
76:54 - March I can see it's 104 that was the
76:56 - month like I made lesser purchases
76:58 - because my wife had gone home that also
77:00 - makes sense it's so another use case of
77:02 - this format date
77:04 - function so this is question number
77:08 - 22 so I'm going to
77:11 - paste okay so we have I think about 12
77:15 - more question any Trend with respect to
77:17 - eating at
77:18 - dominoes okay so same thing here uh the
77:23 - company name will become if we see the
77:25 - original data right it will become
77:29 - dominoes okay so
77:32 - where just remove this and say dominoes
77:38 - okay any Trends so I'll just see
77:41 - month-wise 1722 it's standardized I
77:43 - think in March I've ordered a lot more I
77:45 - didn't cook much so March it has been a
77:47 - lot 49 otherwise it's 17 14 15 right
77:50 - this is the standard if you order once a
77:52 - month uh so we can also see
77:55 - distinct dates I have Ed in each month
77:58 - as well just to see the
78:01 - patterns so if you notice yeah most
78:05 - months it's one in March alone I ordered
78:07 - three times with dominoes okay that's
78:10 - the
78:11 - pattern um that is question number 23
78:14 - I'm going to save the
78:17 - query let's move to the next question 24
78:20 - is there any month where grocery expense
78:22 - has is a bit different or as it changed
78:25 - a little bit right so I think we did
78:29 - query similar to this right so I'm going
78:33 - to copy
78:36 - this so I'm going to run this again so
78:39 - grocery
78:40 - expense yeah as you see it's kind of
78:42 - standardized right January is 210 febr
78:45 - is 276 there picked up and then yeah
78:48 - March and April as you see it's below
78:50 - 200 so like there's been a drop and may
78:53 - is again 180 right so it looks like
78:55 - February had a peak right like February
78:57 - had a lot of grocery purchases and then
79:00 - uh June again dropped June we went for a
79:02 - trip as well we were not there for a few
79:04 - days in Germany so I guess that's why
79:06 - it's dropped to 156 so I can strongly
79:08 - see February has peaked at it's a month
79:11 - where we have purchased a lot of
79:14 - grossery right that was question number
79:17 - 24 so February had a slight jump in
79:21 - terms of grocery
79:23 - expenses
79:25 - then move to 25 show the show only the
79:28 - company with highest Spen in each
79:30 - category for April right so this is
79:32 - probably a question where we might need
79:34 - to use something like Windows functions
79:37 - right only only the company with the
79:40 - highest pin in each category for April
79:44 - okay so I'm going to I probably don't
79:48 - need the category
79:50 - ID I just remove
79:52 - that the join so I we have the original
79:56 - table so I probably need to find the
79:59 - total cost
80:05 - right so what we can do we
80:09 - can do category
80:15 - ID then uh the
80:22 - company so all this is good and and then
80:25 - this is only for specifically the month
80:27 - of April right so I have to say where
80:30 - extract of month from date is equal to
80:34 - four right and then say Group
80:38 - by category ID for comma company so I
80:41 - could just copy
80:46 - this right so I get each month I mean
80:50 - each uh
80:52 - category company and then this right
80:56 - right now what if I want to show only
80:59 - the highest like for example uh Category
81:01 - 2 is grocery in that there is R there is
81:03 - interest store right so what if I want
81:06 - to show only the highest right same way
81:08 - in four which looks like a restaurant
81:11 - there is Panda jaur Domino's kebab and S
81:14 - so only the highest right s is the
81:16 - highest spending how can I pick and show
81:18 - that so this is interesting so I'll say
81:22 - sum of cost as total cost right this is
81:25 - Step number
81:26 - one now I can put this whole thing into
81:28 - a CT right so with Clause I can say
81:32 - with let us say
81:35 - uh data new or something as right so I
81:40 - can do step number one like
81:42 - this and now from this data I can
81:46 - select company comma category
81:49 - ID and then I can do a rank okay so I
81:52 - can say
81:53 - rank
81:56 - Partition
81:57 - by category ID so in each category ID
82:02 - and also do a order
82:05 - by that total cost
82:07 - column descending right to show the one
82:10 - on top and say as ranking right and then
82:14 - I say from final new right that is the
82:17 - name of the
82:19 - temporary class or table I created with
82:21 - the width so now I can run this
82:25 - table final new must be qualified with
82:28 - the data set right so there is some
82:32 - error here it's not final new it's data
82:34 - new right put the wrong
82:37 - name now it should
82:41 - work okay so now I see okay in category4
82:44 - sound is one in category labar that is
82:49 - one
82:50 - in Amazon and Teddy are category 8 which
82:53 - is shopping Amazon is one right now I
82:55 - want to show only the ones that are one
82:58 - to do that what we can do in big query
83:00 - we have a formula called qualify you can
83:03 - say qualify ranking equal to one right
83:05 - this is like a V Clause but meant for
83:07 - window functions so if we write that
83:10 - then we will see only the ones that are
83:11 - ranked one in each category right so rev
83:14 - is coming as the highest in grocery
83:17 - Rosman comes in cosmetics s in
83:20 - restaurant Amazon in shopping and I
83:22 - think DB is the only thing in tickets
83:25 - so we are getting all that right so this
83:27 - is a nice use case of the with Clause
83:30 - normal Group by and also learning to use
83:32 - the window function like Rank and
83:34 - filtering rank or window function we can
83:36 - use qualify right so great question this
83:40 - one question number 25 I'm going to
83:46 - save
83:47 - okay question 26 let's move on we have I
83:50 - think few more
83:52 - questions percentage change change in
83:54 - total cost for each month and find the
83:57 - month with the highest percentage change
83:58 - so anytime you have percentage change
84:00 - year on year it's time to use a window
84:02 - function like lag okay so for each month
84:06 - percentage change in cost they're asking
84:09 - so I'm going to start with
84:12 - select and uh we need month right so we
84:14 - can write uh format date function and
84:17 - say percentage y percentage M right that
84:21 - is Step number
84:23 - one and we want to uh find the total
84:26 - cost right so I can say sum of
84:29 - cost and then copy this and put it in
84:32 - the group I okay so there is no filter
84:35 - here so I will remove
84:37 - where and I'm just going to run
84:41 - this okay I think there are two commas I
84:44 - will remove the one of
84:46 - them format date it should be for the
84:49 - date function right I mean date column
84:51 - so I forgot to put that over here as
84:54 - well right so sometimes be careful you
84:57 - might see errors like this silly
84:59 - mistakes only right so I'm getting total
85:01 - cost all months okay so this is great so
85:04 - now what I can do I can put this in
85:07 - a with final as in a CTE right that is
85:10 - the first step now I have to calculate
85:13 - percentage change so now I can say
85:17 - select let us say this format date
85:19 - whatever is called as year month I give
85:22 - it an alas name so I can say year month
85:26 - total
85:28 - cost and also to see the previous value
85:30 - I can say lag of this column lag of
85:32 - total
85:34 - cost then over here there is just month
85:38 - and year right so we don't really need a
85:41 - partition so we can say order
85:43 - by this year month column right
85:46 - ascending order and I can call this as
85:49 - previous month cost right and say
85:55 - from
85:57 - final let's see what we
86:00 - get so we see each month so for example
86:04 - uh January 1062 is total cost previous
86:07 - month is not there it's null February
86:09 - total cost 1166 previous month value was
86:12 - 1062 we get that and you know here it's
86:15 - not in order but for example March 1071
86:18 - previous month cost is February that's
86:21 - 1166 and we are getting that here right
86:24 - so so this is like we getting them side
86:26 - by side how can we now calculate
86:28 - percentage change so for that it just
86:30 - becomes little more complicated so I
86:33 - will put this whole thing into another
86:35 - CTE so with I will say final 2 as or
86:38 - something like
86:40 - that okay close the
86:43 - brackets just drag this down and now
86:46 - from this final to I can select year
86:50 - month then I want to do this percentage
86:53 - difference so I will trite total cost
86:56 - minus previous month
86:58 - cost divided by previous month cost
87:03 - right from final two that's the second
87:09 - CT and then I want to order by year
87:12 - month
87:14 - right and if I want to do percentage I
87:17 - can also put this whole thing and
87:19 - multiply it by 100
87:23 - right
87:25 - let's see what we
87:29 - get okay so we don't really see the
87:32 - values so if I want to also see the
87:34 - values over here I can put those columns
87:37 - as well right so total
87:40 - cost previous month cost as
87:44 - well and run
87:46 - this just for you to have that appeal so
87:50 - from for January there's nothing makes
87:53 - sense February you
87:54 - see um it's basically a 99.7% increase
87:59 - right from January so from 1062 it
88:01 - became 1166 then from Feb to March it
88:04 - dropped again so minus 8% decline from
88:07 - here to April again it declined by about
88:10 - 2% then from here it increased by about
88:13 - 7% then from 1125 it dropped to 1084 so
88:17 - 3.7% drop so the highest has been from
88:20 - Jan to Feb where we saw 99.79% increase
88:23 - okay
88:24 - this is how you can use multiple CTE and
88:28 - also use lag to do this percentage
88:30 - change okay interesting and slightly
88:33 - complicated question was question number
88:36 - 26 I'm going to paste the query here
88:39 - let's move to question
88:40 - 27 okay do the same as that question but
88:45 - only for restaurant category okay so if
88:48 - if you have to do only for restaurant
88:49 - category the query is going to remain
88:52 - pretty much the same and we know we have
88:54 - to just put a filter on the restaurant
88:56 - category right so if I go here and open
89:00 - this table in a new tab I see for
89:05 - example restaurant is category ID 4 so I
89:08 - can go back to our query and over here I
89:11 - simply put where categ category ID equal
89:15 - to four right so that will filter the
89:17 - total cost but only for
89:20 - restaurant right nothing else
89:23 - changes
89:25 - so it's running let's see what we get
89:27 - now we see some start differences for
89:30 - example from FIB to March the jump is
89:32 - significant 50% jump so I told you march
89:34 - I didn't cook much I used to order
89:36 - outside that kind of makes sense right
89:39 - and then same way then it drops back
89:41 - again in April and then again drops and
89:44 - then from uh May to June again there's a
89:47 - jump right so 73% jump so it's like a
89:51 - lot of trends like going up coming down
89:54 - but this is what it is for this
89:55 - restaurant
89:58 - category
90:00 - q27 okay let's move to question 28 we're
90:04 - nearing the end find the date with
90:06 - highest number of unique categories
90:09 - where money was spent okay this is a
90:12 - fairly simple question so I'm going to
90:14 - remove everything
90:18 - else okay delete all that is there find
90:23 - the date with the
90:26 - highest number of unique categories okay
90:28 - so I say select
90:30 - date and then count of distinct category
90:33 - ID right on a particular date what were
90:36 - the unique categories and then we want
90:38 - to find which was the highest date in
90:40 - this so I'll say Group by date order by
90:44 - discount distinct uh category
90:49 - ID and say I put double remove that and
90:54 - see descending as simple as that let's
90:56 - see if there's a particular
90:58 - date okay so I think 7th June there have
91:02 - been three different categories where
91:04 - there's been some kind of purchase money
91:05 - has been spent right that is the day
91:08 - rest of it is 2 or one so 7th June is
91:11 - that
91:12 - date so I'm going to copy this this is
91:14 - question number
91:16 - 28 simple
91:19 - question 29 use Cas statement to
91:23 - category is response as Indian versus
91:25 - non-indian based on name and show total
91:27 - cost for June right so for June we need
91:30 - to use some case statement
91:33 - logic let's go back here right so first
91:36 - of all I will remove all this and I will
91:39 - say where extract of month from date
91:44 - equal to 6 okay step number one let's
91:47 - select
91:50 - everything and then for restaurant so we
91:53 - also need to
91:54 - format it by restaurant category so if I
91:57 - go
91:58 - here for example jur is restaurant so
92:01 - category ID should be four right so I
92:02 - also put that as a
92:06 - filter equal to four so let's see what
92:09 - what is been the restaurant expenses so
92:11 - you see lot right so in this we have to
92:13 - tactically separate Indian non Indian so
92:16 - the only Indian is jpur the rest are all
92:18 - non- Indian right so I will simply say
92:21 - case
92:22 - when company equal to
92:26 - jur pretty
92:29 - simple then
92:32 - Indian else non- Indian
92:36 - okay end
92:38 - as restaurant type you can give it a
92:41 - name then you sum of cost that's it
92:44 - right so I'm splitting jur versus the
92:46 - other ones the others are non Indian and
92:48 - now we can say Group by this uh
92:52 - restaurant type write the column that I
92:55 - created for month of June for restaurant
92:58 - category Indian versus non-indian
93:00 - non-indian 50 Indian 21 right that is
93:02 - the split up Indian only jur non Indian
93:05 - had Panda and other restaurants
93:10 - as question
93:12 - number I think this is 29 okay so we
93:15 - getting to the end 30 ratio of total
93:19 - spend for restaurants versus grocery for
93:22 - April okay so April so first thing I'll
93:25 - do is I'll put this is
93:28 - four
93:30 - um can remove this so let us go back to
93:34 - the category
93:36 - table and uh so restaurant is four a
93:39 - groceries is two right category ID so
93:42 - let's note that down so we want to do
93:45 - the uh total cost only right so I'll do
93:49 - this is a use case of a sum sum if so I
93:52 - can say ratio of uh restaurant versus
93:56 - grocery Right restaurant is four grocery
93:58 - is
93:59 - two that is the
94:01 - ID so sum of
94:05 - if category ID equal to 4 right if it is
94:08 - four then do the cost otherwise
94:12 - zero this will show the total for the
94:15 - restaurant and I can simply divide this
94:22 - by sum of if category ID equal to two
94:25 - whenever it is category id2 which is
94:27 - grocery please sum the cost otherwise
94:29 - zero so if I divide both these and I'm
94:32 - putting equal to four in the filter
94:33 - because it is the month of April right
94:36 - let us see what we
94:38 - get so we get 36 right what does that
94:42 - mean so if I put a comma and see the
94:44 - values right what is the restaurant spin
94:46 - what is the category spin uh I mean for
94:48 - grocery so restaurant spend is 63
94:51 - grocery is 174 the ratio is about 36
94:55 - right so you can put divided by and that
94:58 - will give you the
94:59 - answer so that is question number
95:04 - 30
95:05 - cool moving on 31 average spend per
95:10 - month at interest store interest store
95:11 - looks like some grocery
95:13 - store so I can come back
95:16 - here can say where company equal
95:22 - to
95:24 - let's see if there is something called
95:25 - interest store right so I'm going
95:28 - to just say
95:31 - star yeah interest store is there so
95:34 - average spend per month
95:39 - okay so what can we do we can say
95:43 - company
95:44 - comma let's put
95:47 - average
95:50 - cost I think it's
95:52 - AVG
95:55 - but we also want to do per month so I'm
95:58 - going to
95:59 - put per format I mean we can even put
96:02 - just the month so you can say extract of
96:04 - month from
96:06 - date we
96:08 - want and group by we can say these two
96:11 - right so instead of writing company and
96:13 - extra extract of month from date we can
96:15 - also write Group by one comma two group
96:17 - by the first and second column this is
96:20 - also
96:21 - possible then we notice okay it's
96:24 - usually 12 15 7 this is average of each
96:27 - purchase
96:29 - right so we can do that or to make it
96:32 - even more correct we can say sum of
96:35 - cost divided by count of distinct date
96:39 - so like cost per each unique date that
96:43 - we visit if I do something like this
96:46 - then you see it's around that right
96:48 - March was a bit cheap we didn't buy much
96:50 - but the rest of the months is around 12
96:51 - to 15 right
96:55 - so this is basically calculating total
96:57 - cost divided by total number of days we
96:59 - have been this will give you average
97:01 - cost for that month we are doing the
97:02 - same for all the
97:04 - months that was question
97:09 - 31 next one which company in shopping
97:11 - category had the highest total cost I
97:14 - think we did something like this already
97:17 - uh shopping category is what category ID
97:20 - is8 so I can say where category ID is 8
97:25 - that's a easy thing to do which company
97:28 - had the highest cost right so I can
97:29 - simply say company comma sum of
97:33 - cost again I can Group by one group by
97:36 - one means Group by the First Column
97:38 - which is
97:39 - company so I can run this I think there
97:42 - only two or three companies so we can
97:43 - see Amazon had the highest cost okay you
97:45 - can also do an order by if you want
97:48 - question number
97:51 - 32 okay and then use Union Clause to
97:56 - show total cost for Kebab shop and also
97:59 - Panda using two different
98:01 - queries uh so let us uh see
98:04 - the distinct names of these
98:11 - shops total cost using
98:14 - Union so that is keop shop K and Sr
98:18 - capital and what else was there Panda
98:21 - okay so we can
98:23 - easily do this we can say
98:26 - company comma sum of
98:28 - cost from
98:31 - table where
98:34 - company equal to first let me put Kebob
98:39 - shop um Group by company this is
98:43 - done and then I can use Union
98:48 - all and simply copy the same query right
98:52 - only difference is
98:54 - here I will substitute it by Panda they
98:56 - want us to write two different queries
98:58 - to do
99:00 - this give us the total cost for Kebab
99:02 - shop and Panda Kebab shop 34 Panda 66
99:05 - right simple use of Union
99:08 - all question number 33 so we are almost
99:14 - there and then finally last question is
99:18 - there any fully duplicate value in the
99:20 - data right that means every row like
99:24 - every column should be the same is there
99:25 - any kind of duplicate data like that
99:28 - this is a bit of a tricky question so I
99:31 - can say select star
99:35 - from and do this right I will run so for
99:39 - this we need to do a check of all the
99:41 - columns if there is any kind of
99:43 - duplicate okay so what we can do I will
99:46 - select
99:47 - everything and then I will
99:50 - say row
99:52 - number
99:54 - and then I can say over and here we need
99:57 - to Partition by every single column so
99:59 - by date
100:01 - company category ID and
100:06 - cost and say row number okay alas
100:12 - name let's try to run this
100:16 - query right and we see if I select all
100:19 - the 200 rows I see row number is only
100:22 - one right that kind of means means
100:23 - there's no duplicate what does this mean
100:25 - Suppose there was row number two
100:27 - somewhere that means that particular set
100:29 - of data is repeating multiple times
100:31 - right so if row number is more than one
100:33 - that means it is potentially duplicate
100:35 - data right so we don't have that so to
100:38 - check that we can put this whole thing
100:40 - in a CTE so I will say which CTE
100:43 - as um and then
100:45 - say to check for duplicates what we will
100:48 - do is we'll say select star from CT
100:51 - where row number is greater than one
100:55 - right if it shows some value then that
100:57 - is a duplicate here it is no data that
101:00 - means all our values are unique unique
101:02 - in each column right that means there's
101:04 - no two rows where all the values for all
101:07 - columns are the same right this is also
101:09 - very challenging and commonly asked
101:11 - question to find duplicates so you can
101:13 - use this
101:14 - method so I'm going to copy
101:17 - that question 34
101:20 - okay so I hope you enjoyed the video it
101:23 - was a long video you can practice all
101:25 - these question we have tested a lot of
101:27 - Concepts I'm going to put the solutions
101:29 - all the data in our description stay
101:31 - tuned for more videos I'll see you again
101:33 - in another video next week till then
101:35 - take care bye now that we have learned
101:37 - using Excel and also writing SQL queries
101:41 - you need to understand many of times in
101:43 - your data analyst job you'll be dealing
101:44 - with business stakeholders they might
101:46 - not have the relevant technical skills
101:49 - in this case it becomes important to
101:51 - tell your story and drive your analysis
101:54 - through Visual medium so in this coming
101:57 - project we are going to use Google
101:58 - looker Studio to analyze my own social
102:01 - media data from LinkedIn YouTube and
102:04 - Instagram and build basic graphs charts
102:07 - and understand how you can also join
102:09 - data in lucer studio and drive simple
102:12 - insights so here we have some social
102:14 - media data this is my actual social
102:16 - media data I post across multiple
102:19 - platforms
102:20 - Instagram YouTube and also LinkedIn I
102:23 - post regularly on all three platforms as
102:25 - you may all know so I've just taken the
102:28 - month of the post the year of the post
102:31 - and collected the actual data right
102:33 - views likes and comments for each of
102:35 - these posts right and what was the title
102:37 - what was the idea of each of these post
102:39 - then there's a column called category ID
102:42 - what does this event mean there is 1 2 3
102:44 - and so on so for this sake I have a
102:46 - second table okay so it says category ID
102:50 - and the post category right for example
102:51 - category ID one is tips two is projects
102:54 - five is like some interview four is more
102:57 - of fun post and so on right three stands
102:59 - for information now what we're going to
103:01 - try to do bring these two data into
103:04 - looker Studio this used to be called
103:06 - Google data Studio before and try to
103:08 - build some simple graphs simple analysis
103:11 - and drive insights okay what we are
103:13 - going to do is the social media data we
103:15 - going to upload it to Big query if you
103:17 - want to understand how exactly to do it
103:19 - do check out my big query video which I
103:21 - posted a couple of weeks back back where
103:23 - I've shown in to end how to upload your
103:25 - data okay step number one we need to
103:27 - download this as a CSV file okay the
103:30 - social media data I've already
103:31 - downloaded it so I'm going to go to big
103:34 - query okay I already have a project I'm
103:37 - going to create a data set okay I'm
103:38 - going to say create data set let's say
103:41 - social right I can give it a name and I
103:44 - can create the data set okay that's it
103:46 - step number one is done so I have a data
103:48 - set here now I can click and go and say
103:51 - create table I will upload it from uh
103:54 - something that I already downloaded so I
103:56 - can simply crawl down and say social
103:58 - media sheet one right I have downloaded
104:00 - this data I can call it social unor
104:03 - media okay this is simple step number
104:05 - one schema autod detect and create
104:08 - table okay it will take a few seconds to
104:10 - load let's wait for
104:13 - that and once it's done we have the
104:15 - table okay so if I go to query and I say
104:19 - select everything let me run the data
104:22 - and see
104:23 - and now I get the data itself right as
104:25 - you see uh month year views likes
104:28 - comments everything is there okay so we
104:29 - have now connected this data set to
104:31 - bigquery the second data set will stay
104:33 - as a Google sheet now we going to try to
104:35 - combine both within Lucas Studio let's
104:37 - see how to do
104:38 - it so for that you go to Lucas studio.
104:41 - google.com this used to be called uh
104:44 - data Studio Google data Studio before so
104:46 - I'm going to type that and this is how
104:48 - you land right you land in a homepage
104:50 - something like this so I'm going to
104:52 - Simply say blank report okay when you
104:55 - click on blank report basically you'll
104:57 - have multiple ways to connect right you
104:59 - might connect it to your Google
105:00 - analytics data you might connect it to
105:02 - your big query you might connect it to
105:04 - your local computer right upload some
105:07 - file you might also connect it to a
105:08 - Google sheet right and there are so many
105:10 - other options to connect to other social
105:12 - media platform so today we are going to
105:14 - start with trying to connect it to
105:15 - bigquery okay because I have that table
105:17 - in bigquery right so I go here and I
105:20 - know this is my project in this social
105:22 - is the data set I created and I click on
105:24 - social media okay so I can connect to
105:26 - the table inside big query like this so
105:30 - I can simply say
105:31 - add right it will take some time to
105:35 - load and then simply say add to
105:39 - report okay step number one as you see
105:42 - we we have all the values right so if I
105:44 - pull for example the total
105:47 - views and uh see it across three
105:49 - platforms so Instagram had 750
105:54 - 7 lakh right like 7571 0 right basically
106:01 - 757,50 7,100 right depending on the
106:04 - notation you use so we have the data
106:07 - like this okay this is a nice and easy
106:09 - step number one now let us go and see
106:12 - some questions right so step number one
106:14 - is they are saying import data from
106:16 - bigquery we have already done that right
106:19 - uh now we will try to connect the Google
106:20 - sheet right with this before that let's
106:23 - see this one right they say write a case
106:25 - statement to categorize fun and tips
106:28 - content as one category other as a
106:30 - separate category right so if I go here
106:34 - I see fun is ID number four and tips is
106:38 - ID number one right so whenever it's
106:40 - tips or fun I want to put it as one
106:42 - category how can we do this in looker
106:45 - studio so first of all before that I'll
106:47 - come and give this a name social media
106:49 - report okay I can click social media
106:51 - report give it a name like this
106:53 - then I can go to Resource manage added
106:56 - data sources right and click on edit
106:59 - right now I can add a new field okay
107:02 - calculated
107:03 - field um and then what else can I do I
107:07 - can say for example category new right I
107:10 - can give it any name I want so the idea
107:13 - here is so I can use a case statement
107:15 - very similar to SQL so case when
107:18 - category ID right that is the column
107:20 - right when this is one or four right
107:23 - that's what we said then we can call it
107:27 - uh let's
107:28 - say fun tips
107:32 - right otherwise we can call
107:35 - it other right so we're splitting like
107:38 - this and we can say end okay in SQL
107:40 - we'll say end as here we can simply say
107:42 - end right as you see the formula is
107:45 - correct I can simply go and
107:46 - save right and I can click on done right
107:49 - so we have now created a new column
107:51 - called category new
107:53 - uh which is appearing here right so if
107:55 - you want to see category new for
107:57 - instance um as you see most of it is in
108:00 - other category right so uh fun and tips
108:02 - I have not created as much content so
108:04 - the views is only half right this is
108:06 - just giving us a general idea but you
108:08 - now learned how to create a case
108:10 - statement in Luca Studio as you see it
108:12 - was very very similar to how we do it in
108:14 - SQL okay so first step is done now let
108:17 - us come back to the uh previous question
108:20 - which is like also connect to the Google
108:21 - sheet data and see how can we merge them
108:24 - or combine them together okay so to do
108:27 - this first of all I'm going to say go to
108:30 - Resource manage added data source and
108:33 - I'm going to add a new data source right
108:34 - and this time it's going to come from
108:36 - Google Sheets right and what is it
108:38 - basically this category ID post right
108:40 - that sheet so I'm going to just select
108:42 - that and that's it right you can simply
108:45 - go and add right this way now we are
108:48 - connecting it to a second data source as
108:51 - well right so we have now social media
108:53 - as well as this uh category ID post
108:57 - Google sheet data okay now we have an
108:59 - option to blend or merge or combine the
109:01 - data so now let us try and uh do that
109:04 - okay so I'm going to say blend
109:07 - data okay now what do I want to blend so
109:12 - I want to join social media table from
109:14 - here I want everything right so I will
109:16 - select category ID category new is
109:19 - already there I want to see the month of
109:22 - of course the
109:24 - platform the year and the title as well
109:26 - right I'm just going to pull all of them
109:28 - into dimensions and in metrics I want to
109:30 - see the views what else I want to see
109:32 - the likes I want to see the comments I
109:35 - guess that's pretty much it right from
109:37 - social media table I'm pulling all the
109:39 - things for this blending or smudging
109:41 - process join with another table from
109:44 - this one category ID post I want the
109:47 - category ID obviously and I also want
109:49 - the post category right that gives us
109:51 - the name
109:53 - now that I have pulled both right I
109:56 - pulled everything from here and both the
109:58 - columns from the other table uh we can
110:01 - configure the join we can say select
110:03 - inner join right as you see category ID
110:06 - table is common in both so it will join
110:07 - based on that similar to the SQL
110:09 - principles so I'm simply going to
110:12 - save right and uh it will be named as
110:14 - Blended data one name doesn't matter so
110:16 - I'm going to Simply
110:18 - Save okay so as you see Blended data
110:22 - come now uh so now I have category ID
110:25 - and category new as well right apart
110:28 - from that the name of the post category
110:29 - right so if I pull post category
110:32 - here as you see in other itself we have
110:36 - information we have projects we also
110:38 - have interview in fun tips we have fun
110:40 - and tips right now they showing
110:42 - separately so we have been able to blend
110:44 - or merge the data similar to join in SQL
110:47 - right so we have done this this is cool
110:49 - we also have all the metrics here and
110:51 - the category ID right if I I want to see
110:53 - the category ID as well I can pull that
110:54 - in so for instance uh information is
110:57 - category ID 3 tips is category ID 1 and
111:00 - so on right now we have all the
111:02 - information set up we have also done the
111:04 - merging right now let us go back to the
111:07 - questions so case statement is done so
111:10 - they're asking to observe Trends in
111:12 - platforms and also categories right now
111:14 - let us do step by step so we will make
111:16 - sure we don't overpopulate too many
111:18 - graphs too many tables in one sheet so
111:21 - this is uh the first page right so over
111:25 - here let me do something very very
111:27 - simple so I'm going to just remove this
111:30 - right I'm going to cut this out right
111:32 - and I'm going to click on Blended data
111:34 - and let us say I want to insert a simple
111:36 - scorecard scorecard will have simple
111:38 - values like this right so first of all
111:42 - what do I want to see here let us say I
111:44 - want to see the total likes right I'll
111:48 - drag that in okay so the total likes
111:51 - that I received right across all these
111:53 - platforms is
111:55 - 25,338 so I can copy and paste so I can
112:00 - get a duplicate like this as well and
112:02 - now let me just put the total views okay
112:06 - so total views is uh more than a million
112:09 - right as you see across all the
112:11 - platforms put together and then I can
112:14 - again just copy and paste right so I can
112:17 - uh replicate as well and this time let
112:20 - us say I want to put total comments okay
112:23 - honestly we don't get many comments so
112:25 - total comments is less than 500 so we
112:27 - have these three right now this is like
112:30 - just simple top level metrix that we are
112:32 - seeing right uh before that if you want
112:35 - you can also go and add a text box on
112:39 - top right I can place it wherever I want
112:42 - maybe I'll just bring this down a little
112:46 - bit I think it just got stuck so let me
112:49 - just drag this down a bit also drag this
112:52 - down little bit and I can say
112:55 - insert text right I can place a text box
112:59 - here right I can
113:04 - say
113:06 - important overall information right I
113:09 - can give whatever name I want right can
113:11 - play around with the formatting and
113:13 - stuff right so as you see you can make
113:15 - it bold right by selecting the text we
113:17 - can make it
113:19 - bold uh if you want you can underline it
113:21 - and so on right you can play around with
113:23 - all that just going to drag this make it
113:25 - a little bigger right let's make the
113:28 - size even bigger maybe I can select the
113:32 - whole thing and make it
113:35 - 20px okay so it became a little bit
113:37 - bigger uh if we want to give it a color
113:41 - for the background or filling also we
113:43 - can do stuff like that okay if I want
113:46 - some background can also do like this
113:48 - right so um yeah going to just remove
113:53 - this other one so this is like important
113:55 - overall information so I have likes I
113:58 - have views and I also have comments okay
114:00 - you can share it with whatever color you
114:02 - want but this is just giving simple
114:04 - important overall information okay now
114:07 - let's say add new page okay so I'm
114:09 - creating a new page I've created a new
114:12 - page here let us say I want to add
114:14 - something important right so I can
114:16 - simply say
114:18 - table okay I'm going to insert a table
114:21 - let's say I want to see by
114:23 - platform right so I want to bring
114:25 - platform to Dimensions the total views
114:28 - the total likes and total comments so
114:30 - I'm going to drag uh total views
114:34 - here total likes as
114:37 - well and total comments okay the three
114:40 - main metrics for all the platforms this
114:42 - is across the complete time period okay
114:45 - so as you notice Instagram is on top
114:48 - right in terms of views YouTube views
114:50 - overall is not that much same Trend with
114:53 - the likes but if you see YouTube is
114:54 - getting more comments than Instagram so
114:57 - Instagram doesn't get as many comments
114:58 - right although the views is high likes
115:00 - is side can we show this visually is it
115:02 - possible so yes we can try to do it
115:05 - let's say we want to show different
115:07 - colors for views I can go to
115:10 - style right and I can scroll
115:12 - down now we have three metrics right
115:15 - views likes and comments so for metric
115:17 - one let us say I want to show something
115:19 - different can click heat map right and I
115:22 - say heat map you see Instagram is the
115:23 - highest it will show darker blue color
115:25 - right LinkedIn is slightly lighter blue
115:28 - the YouTube with less views is very much
115:30 - very light blue right for instance for
115:33 - the second metric for lights I can show
115:36 - like a bar right it shows Instagram has
115:39 - more likes and if I click on show number
115:42 - then it will also show the values right
115:44 - you can depi like a bar same way for
115:45 - comments right you can come to metric 3
115:48 - and select whatever you want right I can
115:50 - say again heat map it will show a
115:51 - different color right you can play
115:53 - around with the color but this shows
115:54 - that LinkedIn received much more
115:55 - comments than the other two right so
115:58 - simple Trend we can see so it looks like
116:00 - Instagram performed well on the views
116:01 - and the likes but in terms of comments
116:03 - LinkedIn is the best right so this is
116:05 - what we get just at overall Picture
116:07 - level now if you want you can also add a
116:10 - filter right so you can say insert a
116:12 - drop down list and over here for example
116:15 - I can put month as a filter right I can
116:18 - bring that here now I can see per month
116:21 - right let's say I want to see only for
116:23 - no can select no and see the trend right
116:27 - so even there you see Instagram is
116:29 - dominating in views YouTube had a lot of
116:31 - comments right so I can select multiple
116:33 - months or just select one month for
116:35 - example December or I could select
116:37 - everything right so I could play around
116:40 - and see the overall trend right so I put
116:42 - month as a filter right so this uh is
116:45 - indicating me that yes Instagram is
116:48 - doing well in views and likes whereas
116:49 - LinkedIn is doing well in comments right
116:52 - this is a simple thing we can play
116:53 - around this is in terms of the platform
116:57 - right so this information is basically
116:59 - about platform now let us say I go to
117:02 - page and click on current page settings
117:04 - so we get something like this so we can
117:06 - go to style and you know you want to
117:08 - change the size and all you can play
117:10 - around as
117:12 - well
117:13 - right I can go to view mode right so if
117:16 - I go to view mode for example what will
117:18 - I get I can play around right your
117:21 - stakeholder can go select a particular
117:23 - month and they will see only that right
117:24 - for example there's no August data here
117:27 - for LinkedIn I guess in this so only
117:29 - Instagram and YouTube are showing right
117:31 - so I can select everything if I want if
117:33 - I come back to edit mode I get the
117:35 - access to edit the report right so this
117:39 - is by platform now let us move to
117:42 - something further let us say I add
117:44 - another new page right this time let us
117:47 - say I want to add some more calculations
117:49 - right so what I can do this time let me
117:53 - again add a table
117:56 - okay so this time let's say I want to
117:59 - see by category right so I have post
118:02 - category so I can select that right by
118:06 - category how things are going right so I
118:09 - I don't need the month so I can just
118:11 - again pull
118:13 - likes then
118:16 - comments and views
118:20 - right same
118:22 - so I can just reorder them so that uh
118:25 - first is views then it's likes and then
118:27 - it's comments right so now I see the
118:30 - values as you see across these five I
118:33 - can apply the same logic right I can
118:35 - simply come to uh the style section and
118:38 - for the first metrics let's say I want
118:40 - to show heat map and second metric also
118:43 - I want to show heat map okay I can
118:45 - select heat map as simply that and then
118:48 - third metric let's say I again select
118:50 - heat map okay so going to show different
118:51 - colors
118:52 - but now as you see here in terms of post
118:55 - category it looks like informative posts
118:56 - are doing really well overall right uh
118:59 - tips is also doing reasonably well the
119:02 - others there's not a lot of use maybe
119:04 - there's not a lot of content this could
119:06 - also be the case same way information
119:08 - and tips are getting a lot of likes as
119:09 - well and very good amount of comments
119:11 - right in fact projects and interview did
119:13 - not get as many comments maybe it's
119:15 - because number of project videos are
119:17 - also lesser right this is also something
119:18 - you need to look into but at least you
119:20 - can see what kind of posts getting views
119:23 - likes interactions and stuff like that
119:26 - on top of this right I can drag this
119:28 - down a little bit and I can say insert
119:31 - same way right I can insert a filter and
119:34 - what filter can I put in here right I
119:35 - can put in for instance platform itself
119:37 - right and see in each platform is there
119:39 - a different Trend right so let us say I
119:41 - want to see only Instagram in Instagram
119:44 - what is happening as you see I not
119:46 - really uh posted all types of content
119:49 - here right that's just information tips
119:51 - projects and fun there's no interview
119:54 - post here and you can see the trend
119:55 - right again information is doing pretty
119:57 - well tips is doing well as well right
119:59 - now if I go to LinkedIn let's see how
120:01 - it's different here there's little bit
120:03 - about projects but again it's
120:04 - predominantly information and tips and
120:07 - they are doing pretty well as well right
120:09 - and finally going to
120:11 - YouTube YouTube there's also projects
120:13 - but again information and tips are
120:15 - predominantly dominating right in terms
120:16 - of comments likes and views right so
120:20 - this way you can put a filter for a
120:22 - platform and see in each platform which
120:24 - post category is doing well in terms of
120:26 - overall numbers right now let me go and
120:31 - add another uh page so I'm going to
120:34 - Simply say page and add a new page okay
120:39 - now what I want to actually do I want to
120:43 - this time insert a table again right but
120:47 - this time the purpose is going to be
120:48 - little bit different right so what do I
120:51 - want to do here instead of just pulling
120:53 - likes comments views just like that I
120:55 - want to also do some calculation for
120:57 - example what is the ratio of likes to
121:00 - the Views what is the ratio of comments
121:03 - to the likes right or what is the ratio
121:05 - of comments to the overall views right
121:07 - if we get some kind of Trends here so
121:10 - for this what can we do let's say I want
121:12 - to see it by
121:14 - platform I can drag platform to
121:17 - Dimensions right that's step number one
121:19 - now I can do some calculations right so
121:21 - so I already have uh metric here if I
121:25 - want I can add a new metric okay how do
121:27 - we do that you can say add metric and
121:30 - say add field okay now let us say the
121:33 - first one I want to do is the ratio of
121:35 - likes to the Views I can type it like
121:37 - that I can come here and write a formula
121:39 - right I can say sum of likes right total
121:42 - likes divided by the total views right
121:46 - you get a formula like this and let's
121:48 - say I want it decimal with two
121:50 - percentage points can select like this
121:52 - and say
121:54 - apply okay so this is how I get the
121:58 - likes to views ratio right I can make
122:01 - this a little bit smaller if I want and
122:04 - drag this a little bigger so likes to
122:06 - views I'm getting right this is one
122:07 - calculation I doing already I can also
122:10 - add another calculation if I want right
122:12 - I can simply go here and I can say add
122:15 - field this time I want to do comments
122:19 - to likes right this is another
122:22 - interesting ratio let me again say
122:24 - percentage but two decimal points so
122:27 - this time it's going to be uh sum of
122:31 - commments right divid by the total
122:34 - number of
122:35 - likes right that's it I'm going to apply
122:38 - this right so this is a second
122:39 - calculation I'm doing this will be a
122:40 - very small number as you see uh comments
122:43 - to likes right these are all below 1
122:45 - percentage but still it's fine to show
122:47 - them right there's likes to views and
122:49 - there's also comments to likes right if
122:51 - you we want we can add a third uh trick
122:53 - as well I'm going to go here and add
122:56 - this so this is nothing but comments I'm
123:00 - getting to the overall views right this
123:03 - might be a very minuscule number but
123:06 - anyway let me just add it right I'm
123:08 - going to say percentage two let's say if
123:10 - this calculation even shows some insight
123:12 - so I'm going to say some of commments
123:14 - but this time I'm going to divid by some
123:16 - of
123:17 - use right it's a very minuscule very
123:20 - small number that we going to get as you
123:22 - see 01 0 right doesn't really make a lot
123:25 - of sense uh so for instance maybe I can
123:28 - just remove it right I was just testing
123:29 - it but it's not really making much sense
123:31 - very very small numbers so I'm just
123:33 - going to keep the other two okay I'm
123:36 - going to remove comments to
123:38 - use now with this what else can we do we
123:41 - could for example bring in uh post
123:44 - category right can bring in post
123:46 - category so we see values across the
123:48 - board right so and I can drag this to
123:51 - see everything at one place and now we
123:54 - can also do an execute our heat map
123:57 - thing right to change the colors and
123:59 - stuff like that so for example I could
124:01 - come here and for the first metric I
124:03 - want to see heat
124:05 - map right so we get a distribution and
124:07 - then for the second metric Also let's
124:09 - say I want to see eat map right you can
124:11 - play
124:12 - around so now what we notice right the
124:15 - dark blue ones right for example YouTube
124:18 - tips is having uh very solid likes use
124:22 - ratio right it's not very high but it's
124:24 - 0.05% same with Instagram tips as well
124:27 - right looks like tips is doing fine
124:29 - whereas LinkedIn tips is not working
124:31 - right it's
124:32 - 0.01% same way YouTube information is
124:35 - having
124:36 - 0.05 YouTube fund content is also having
124:39 - 0.04 right and if you notice here
124:41 - generally uh in LinkedIn right the likes
124:44 - to view ratio is very low right whether
124:46 - it's tips projects or information so
124:48 - that is one thing we are observing then
124:51 - if you go to Instagram if there is an
124:53 - information or projects content that is
124:55 - also not doing that well so in Instagram
124:57 - what is primarily doing well is uh to
125:00 - give tips right so it looks like
125:02 - executing tips gives a good likes to
125:04 - views ratio right so out of people who
125:06 - view the video good number of people
125:08 - click on the like button and in YouTube
125:10 - generally tips projects and information
125:13 - all are working even fun videos are
125:14 - working right even interview is doing
125:16 - quite well 0.03% is not bad so it looks
125:19 - like the likes to views ratio is pretty
125:21 - good in YouTube right as a starting
125:23 - point now looking at the other metric
125:25 - which was basically the one we
125:27 - calculated that is comments to likes you
125:30 - see um whenever there's a project video
125:33 - compared to likes there's a lot of
125:34 - comments right and same with the
125:36 - interview right when I interviewed
125:38 - someone about their data analyst journey
125:40 - and so on uh these two are working and
125:42 - information video is also working fine
125:44 - in terms of comments to likes13 but you
125:47 - see Instagram and all this is
125:48 - non-existent right what is the reason
125:51 - like overall all comments only is very
125:52 - low in Instagram right if I go back to
125:55 - our first page we see it's only 490 not
125:58 - only that if you see here right you see
126:00 - the comments are very very low in
126:02 - Instagram right compared to the Views
126:04 - and the likes that is the reason why you
126:06 - see um this value is very very low for
126:08 - Instagram at least LinkedIn is fine 05%
126:12 - 04 but it's not still high right YouTube
126:14 - is still doing well even in comments to
126:16 - likes right so that is an interesting
126:19 - Trend to note so if I come back to this
126:21 - page you notice that YouTube has lower
126:23 - views and likes lower comments as well
126:25 - but the likes to views ratios and the
126:28 - comments to likes ratios are good right
126:30 - so although overall numbers are not that
126:31 - high but still there is reasonably good
126:34 - engagement compared to the Views
126:35 - happening in YouTube and if we want to
126:38 - pick up specific things it looks like uh
126:41 - information videos are doing well in
126:42 - terms of likes and when I post a project
126:44 - video or an interview video the comments
126:46 - I get compared to the likes is really
126:48 - solid right so this is some idea I can
126:50 - take to further develop my content in
126:52 - the future right very very simple
126:54 - insights so that is there now if I want
126:57 - to uh go and add a new page I can again
126:59 - say page and insert another page this
127:03 - time let's say I want to add some simple
127:05 - uh charts so for example I could select
127:08 - column chart right column chart I could
127:11 - for example uh put uh post category
127:14 - right as a simple example and see okay
127:17 - what is the trend in terms of
127:19 - likes and also in terms of use okay so
127:23 - we could do simple things like
127:26 - this right so I make it bigger as you
127:30 - see fun and interview is very small
127:32 - numbers right they kind of non-existent
127:34 - and one other thing if you notice is
127:37 - there's already two sets of graphs right
127:39 - because views is in millions right that
127:41 - is the light blue color and this dark
127:43 - blue is the lik one so as you notice
127:46 - information has like lot of likes and
127:48 - then tips and these two also get the
127:50 - maximum number views right fun and
127:52 - interview there were not many videos I
127:54 - guess so they're kind of non-existent so
127:56 - I can move this down right as a simple
127:59 - graph and uh I can again insert a drop
128:02 - down filter right pretty simple here I
128:04 - can bring in platform as the filter so I
128:08 - can select by platform and see for
128:10 - example only
128:12 - LinkedIn what are the values and so on
128:14 - LinkedIn there's only three types of
128:15 - content I put and yeah you can play
128:18 - around right so it's good to give
128:20 - interactive filters now I'm selecting
128:21 - all the platforms can select by platform
128:23 - and see any sort of insight simple bar
128:25 - graph with multiple metrics that can
128:28 - indicate some kind of trend right so
128:30 - this is how you can create a bar graph
128:32 - on top of this you can also add some
128:34 - insights right like if you notice
128:36 - information and tips is working you can
128:38 - add this as a bullet point as well right
128:40 - so this way you can play around little
128:43 - bit with uh you know your filters as
128:45 - well right so let's say I have this one
128:49 - uh graph uh can I can I do a second
128:52 - graph yes we can right so there are many
128:54 - other options as you see you could like
128:57 - I mean we already saw what's the Heap
128:58 - map uh I also showed you what is a
129:00 - scorecard so you could also create a pie
129:02 - chart for example right simple pie chart
129:05 - uh would be to understand in terms of
129:08 - platforms right which has the highest
129:09 - share in terms of views right so I can
129:12 - say insert pie chart right I can place a
129:16 - second chart here very very simple and
129:20 - in this pie chart what I'm going to do I
129:22 - want to see by platform the trend for
129:25 - the overall views
129:28 - okay so I'm pting views in
129:33 - here and uh here I want platform right I
129:36 - don't want the post
129:39 - category let me just uh drag platform
129:45 - here now you see right so Instagram has
129:49 - the line share in terms of the total
129:51 - views almost 60% then LinkedIn YouTube
129:54 - is a minus cule just 1.5% in terms of
129:56 - views right that's hardly 20K views
129:58 - right this is a simple Trend right so on
130:00 - top of this you can also insert a simple
130:03 - heading if you want right so you can say
130:05 - insert can come here you can add a text
130:08 - if you want right simple text box right
130:11 - and you can move this around and say for
130:14 - example view share by platform right of
130:18 - course you can do the formatting and all
130:19 - right I'm just uh
130:22 - building out the graphs and the
130:23 - calculations right you can of course
130:25 - format it the way you want uh you know
130:27 - you can select the text make it bigger
130:29 - as I have shown you in the beginning as
130:30 - well right so this is all there right
130:33 - you can give like a color as well you
130:35 - can come here select a random color
130:38 - right let's say select this one so you
130:39 - can share it and so on right you can
130:41 - give headings for each of these right
130:43 - you can play around with all this
130:45 - right so this is also possible so keep
130:48 - this in mind right on top of that what
130:51 - else can we do so if I go here like we
130:53 - have already done this color coding for
130:55 - most of it let's see what other features
130:58 - are possible right so if I come back
131:00 - here into this I have views likes
131:03 - already right if I come back into this
131:05 - graph let us say I want to add another
131:07 - metric let's say I just want to see the
131:09 - overall views also as a third metric I
131:11 - will just drag that in right so this way
131:13 - I can see the sum of views as a extra
131:15 - column here right for this column we can
131:18 - also do a few things right so if you go
131:20 - to St
131:23 - right there's a way to add conditional
131:25 - formatting similar to excel right you
131:26 - can play around with this so I can say
131:28 - for example add right let's say I want
131:30 - to add a color and what is the condition
131:33 - let's say if views
131:35 - is um greater than let's say 5,000 I
131:40 - want to give it a specific color right
131:41 - for the entire row I'm going to come and
131:43 - select the color let's say I'm going to
131:45 - select the color yellow and save right I
131:48 - did a simple conditional formatting so
131:50 - wherever as you see it views is more
131:52 - than 5,000 it will share the whole thing
131:54 - in yellow right so this is also
131:56 - something you can play around and do
131:58 - right if you want you can do it you can
131:59 - go back and also uh go to the rule and
132:02 - like simply delete it right this is just
132:04 - to play around this is also
132:07 - possible apart from that as you notice
132:10 - if I come to another uh chart like for
132:13 - example
132:14 - here I can also go to um the setup right
132:18 - there's also a way to do sorting right
132:20 - you can sort by descending and ascending
132:22 - you can play around you can also add a
132:24 - filter to the table right I'm just going
132:27 - to click and what can you do for example
132:29 - you can say include or exclude right and
132:32 - over here you can like select what kind
132:34 - of filter you want to you know impose
132:37 - right is it for the platform title so
132:39 - title for example only for certain type
132:42 - of title right if I come back into the
132:44 - data only for resum or something like
132:46 - that you can also put and play around
132:48 - right that is another possible option
132:52 - so yeah that is that now let's go back
132:54 - to the questions so we have done
132:56 - calculations for total views comments we
132:58 - did some
132:59 - calculation uh they are asking to
133:01 - observe trend-wise for months and drive
133:05 - key insights right so we found a few
133:07 - things already so one thing that we have
133:09 - still not done maybe I will add this as
133:11 - an extra page right is to see by month
133:15 - is there any kind of trend right so for
133:18 - this let me again go and insert a simple
133:20 - table
133:22 - right and I'm just going to do it by
133:24 - month right I think I have the column
133:26 - month already ready so I can just select
133:31 - this um and yeah go to
133:37 - properties right and then I can drag the
133:42 - month okay and month I want to see the
133:45 - total
133:46 - views total likes and total comments
133:50 - right I'm just going to drag these
133:52 - three to see if there is a trend right
133:55 - there's like multiple months so again we
133:58 - can simply go and do heat map or bar
134:00 - chart right that's up to us this time
134:02 - just to do something different I can go
134:03 - here and select bar chart and also show
134:05 - the value I'm going to do the same with
134:08 - the other metrics as well right I want
134:10 - to do a bar chart and show the value
134:12 - comments I'm just going to leave them as
134:14 - such so now if you notice again November
134:16 - seem to be the strongest month right and
134:19 - then um of course October was also
134:21 - strong right you see the buildup right
134:23 - August was only 16k views overall across
134:25 - platforms September 80k then 275,000 or
134:29 - 275 1,572 and then so on right November
134:33 - peaked right so we see a steady increase
134:35 - in Trend in terms of views over months
134:37 - so on top of this I can also add a
134:39 - filter I want
134:41 - for uh in terms of platform right so
134:44 - again I'm going to I'm not going to
134:46 - insert text I'm just going to insert a
134:48 - drop- down list so I can come here right
134:52 - and here I can give platform as a filter
134:55 - right as simple as
134:57 - that so month I don't want as a filter
135:00 - so let me just cut this and just
135:03 - platform right so I can select each
135:04 - platform let's see if there was specific
135:06 - Trends in LinkedIn LinkedIn there's only
135:08 - data for 3 months uh in LinkedIn October
135:12 - seems to be the strongest month right in
135:15 - YouTube let's see YouTube actually
135:18 - August seems to be the strongest month
135:19 - right but but in
135:22 - Instagram as you see from August
135:24 - September October November I mean
135:26 - December November in that November seems
135:29 - to be the strongest right so there's a
135:31 - steady uptrend up till November but when
135:33 - we select um overall all the months
135:36 - together then we saw see that there's a
135:38 - steady increase right there's August
135:40 - September October November December
135:43 - actually dropped a little bit right so I
135:45 - think that is something to keep in mind
135:48 - um but there's been a steady increase
135:50 - right with the drop in December August
135:52 - September October November showed an
135:53 - overall uptrend right so you can drive
135:55 - insights like this and then find which
135:57 - platform contributed to that increase
135:59 - right so this is how you can create a
136:01 - report and basically if you see here you
136:04 - can also go and download it as a PDF if
136:06 - you want you can also share it with
136:08 - people right you can share uh uh click
136:10 - the share option and then you can create
136:13 - uh for example a link right instead of
136:15 - restricted you can say public so I'm
136:17 - going to share the link of the dashboard
136:19 - right uh and then then I can copy the
136:21 - link and you know anyone can view it
136:23 - right on the internet right so we can do
136:25 - all these kind of things as well right
136:27 - play around so now if I go into View
136:30 - mode I mean all the pages don't have a
136:32 - title yet but as you see we have uh
136:35 - shown a few things right each page has
136:37 - their own unique story so make sure each
136:39 - page doesn't have one table or maximum
136:41 - one or two charts right keep that in
136:44 - mind now one last thing to do how can we
136:47 - actually uh give the pages some kind of
136:50 - names right this will be very
136:52 - relevant so for example I can go to
136:54 - manage pages right so I if I go to first
136:58 - page this is overall information so I
137:00 - can give it a
137:01 - rename overall info right I have not put
137:04 - a lot in this page just overall numbers
137:06 - right second page this is I think a
137:09 - platform wise metrics so I can click
137:11 - here and rename it platform wise metrix
137:18 - okay so I can give it a name like this
137:21 - so names are getting saved next page
137:24 - this is I think uh post category wise
137:27 - overall metrics again right so
137:29 - rename post
137:32 - category wise metrix right you can give
137:34 - some legible name right that should be
137:36 - enough then here it's I think this uh
137:40 - specific KPS that we are calculating by
137:43 - platform so like let's say specific
137:47 - kpas per
137:49 - platform and category right I can give a
137:52 - name like
137:53 - this this is overall likes and view
137:56 - share right so I can rename this as
137:59 - likes and view
138:02 - share and I'm mostly I'm considering by
138:05 - platform and category so I'll say
138:07 - platform and category right simple names
138:11 - and then the last one I think was by
138:13 - month
138:14 - right month-wise
138:18 - performance right so we can easily give
138:20 - names like this right I'm saving now if
138:23 - I go into View mode I also can jump
138:25 - across pages right I can go to this page
138:27 - this page CH change and play around with
138:29 - the filter and so on okay so I hope you
138:32 - enjoyed the video right we didn't do a
138:34 - lot but we we learned basics of Lucas
138:36 - Studio how to use it how to blend the
138:38 - data bring data from Google sheet from
138:40 - Big query how to create calculations
138:43 - right for example in these sheets as you
138:45 - see I've done some calculated field
138:47 - right like comments to likes I showed
138:49 - you how to do that how to do heat map
138:52 - coloring say a story keep this in mind I
138:56 - hope you enjoy the video see you again
138:57 - in another video till then take care
139:00 - bye now that we have learned Excel SQL
139:03 - and data visualization it becomes
139:06 - important to learn one more tool that
139:08 - can help you differentiate yourself in
139:10 - this job market in this era of AI it is
139:13 - very important to learn python in this
139:15 - coming project we are going to use
139:17 - Google collab and write python code to
139:20 - to analyze my own food intake and
139:22 - calorie data and drive insights we're
139:25 - going to use some simple functions from
139:27 - packages such as pandas matplot lib and
139:30 - num pipe additionally at the end we will
139:32 - solve a few general purpose python
139:34 - questions using Loops if statement and
139:37 - so on so here we have a data set it's
139:41 - basically the item I had there is a
139:44 - column called time ID I'll explain what
139:45 - that means then the amount of calories
139:47 - of that particular food and also the
139:49 - date right this is some sample data from
139:52 - Jan 2024 of the food I actually had like
139:54 - I eat dosa Corn Flakes C rice potato fry
139:58 - and so on okay what is time ID here so
140:00 - for time ID we have a second table so
140:03 - time ID one means breakfast two is lunch
140:05 - three is a snack evening snack and four
140:07 - is dinner okay it's like the time when I
140:09 - have that food so that is also marked
140:11 - and we have date of I think up to 15th
140:13 - of January right 1st to 15 January 2024
140:16 - we're going to answer some questions
140:18 - based on this using python right this is
140:21 - going to be there plus we'll have some
140:22 - additional python questions to solve
140:24 - other general concepts as well so here
140:27 - we given list of questions so basically
140:31 - we will start doing them one by one but
140:33 - before that uh we also have this small
140:36 - clue to start with this right what does
140:38 - this mean what to do how to do uh how to
140:41 - use Python right this is what we're
140:42 - going to see first so for that step
140:44 - number one you simply type cab.
140:46 - research. google.com I will put this
140:48 - link in our description as well
140:51 - this will take you to place like this so
140:53 - over here you can click on new notebook
140:55 - right this is a place where you could
140:57 - actually write python code and execute
140:58 - it right it will set up like this so to
141:01 - begin uh they just asked us to put these
141:03 - two lines of command I'm just going to
141:05 - copy right uh let me just copy
141:11 - this okay this one and then the second
141:15 - one okay what does this mean is we want
141:19 - to be able to connect to Google Drive
141:22 - Right from this because the files right
141:25 - are in Google Drive right so basically
141:27 - these are the two data sets right if I
141:30 - go to my Google
141:32 - Drive I've already downloaded them and
141:34 - uploaded them as csvs okay calories. CSV
141:38 - and time day. CSV they basically contain
141:40 - the same data so you can upload it to
141:42 - your Google Drive and then over here we
141:45 - are trying to connect to Google Drive so
141:47 - for that we write this set of command as
141:49 - step number one let's see what happens
141:51 - right it will take a little bit to
141:53 - connect little bit of
141:56 - time let's just wait
141:59 - patiently and it will pop up like this
142:02 - give a permission to Google right so we
142:04 - can just click on that and say continue
142:06 - right that will enable us to connect to
142:08 - the
142:09 - dve and I think that's it right a few
142:11 - steps to start out if it is done it will
142:13 - give a green tick that is how we know
142:16 - that it's working
142:19 - okay
142:22 - is still taking time it says mounted so
142:24 - that means this is worked so we could
142:25 - add this plus code to keep adding more
142:28 - and more lines of code right first of
142:30 - all we are going to import some packages
142:32 - right to actually perform some
142:34 - operations one package is called as
142:36 - pandas so we will say import pandas as
142:38 - PD that will be step number
142:41 - one now I want to read one of the data
142:44 - set right as I told you there is
142:46 - calories and then there is time day CSV
142:49 - two files so to the calories file let me
142:52 - give it a name data so I could use this
142:54 - command from pandas pd. read
142:57 - CSV right and then all I need to uh do
143:01 - is I have to copy
143:03 - this
143:05 - okay and then I have to write my drive
143:08 - right because it's coming from my drive
143:11 - and then the name of the file right this
143:13 - is just a syntax so I'll say calories.
143:16 - CSV okay and now if I want to see what
143:18 - is there inside data then I am able to
143:21 - read the file so from our Google Drive
143:24 - we have been able to bring the data into
143:26 - Google collab which is able to let us
143:28 - execute python code right this is that
143:31 - the same way I can just copy the same
143:34 - thing for time data I would just give it
143:36 - a different name right time
143:38 - data I'm going to change this to time
143:41 - data
143:43 - okay and the name of the file was
143:46 - timecore off day. CSV okay
143:52 - it's showing some error let me go and
143:54 - check oh it's time day not time of day
143:57 - so I'll remove the
143:59 - off okay just make sure you put the
144:02 - correct file name and we have that data
144:04 - also right so we are nicely set up so
144:06 - data is there which is about my food and
144:09 - the calories time data is about uh the
144:12 - you know the time of the day basically
144:14 - was it breakfast lunch and so on right
144:16 - and time ID is the common column between
144:18 - these two data set now let us uh jump
144:21 - right into the questions and start start
144:23 - solving them one by one read data from
144:25 - the folder this is already done we have
144:27 - finished first question write a command
144:29 - to see what type of columns are present
144:31 - in the data how can we do that so for
144:34 - that we could simply say so like I'll
144:37 - say command to see what columns are
144:40 - present right so this is a way to write
144:42 - commments to make it more readable so I
144:44 - will say data.
144:47 - info right so in in the data table we
144:50 - have item time ID calories and the date
144:53 - right so this is how we can see by
144:55 - putting info we can see what is present
144:57 - in the data notice one thing date new is
145:00 - still an object object or like more like
145:02 - a string it's not yet date right keep
145:04 - that in mind we will need to address
145:06 - this at some point okay I'm just going
145:09 - to keep adding more lines of code show
145:11 - only the first 15 rows of the data how
145:14 - can we do that so first 15
145:17 - rows so for that we can simply write
145:19 - data head of 15 okay this is like limit
145:22 - 15 in SQL if you say head of 15 you'll
145:25 - get the first 15 rows right starting
145:26 - from zero all the way to 14 this is how
145:29 - we can see the first 15 rows of data so
145:32 - that question is done convert the date
145:34 - new column to date or date time data
145:37 - type right why are they asking us to
145:39 - convert it as you notice here it's
145:41 - object right so how can we
145:43 - convert so I can come here convert date
145:47 - new I'll just give it a heading so I can
145:49 - say date of data of date new right this
145:53 - the column and say data of date
145:58 - new right and I want to convert it so I
146:01 - can say do apply and pandas has this
146:04 - function called to date time right so I
146:07 - want to convert it into date time so I
146:09 - will do this as a first step okay now
146:12 - that is done if I now write data. info
146:15 - let's see what we get now you notice
146:18 - date new has converted to date type type
146:20 - because I did the conversion here right
146:22 - so now it is no more an object we have
146:23 - been able to convert it to daytime this
146:25 - is simple operation commonly asked
146:27 - question sometimes now let's move to the
146:30 - next question combine the calories and
146:32 - time date table right the two tables
146:34 - with the common link right they want us
146:36 - to join or merge the two tables how can
146:38 - we do that so if you notice this is data
146:42 - the other one is called as time data
146:45 - time ID is the common column okay so we
146:48 - need to join on that so so I will say
146:50 - combined data right so I'm joining both
146:53 - how can we do that I will write data.
146:55 - merge of the other table time data right
146:59 - this is how you'll do now what is the
147:01 - common column on which we want to join
147:03 - here we have to notice one thing for the
147:05 - data column data table the column name
147:08 - is time ID t with the
147:10 - Cs whereas for the time data it's time
147:14 - ID but T small letter right so we have
147:16 - to mention both so the first table or
147:20 - the the left table is actually the data
147:22 - table so I will say left underscore
147:25 - on right what is the left column that is
147:28 - common on which we want to join it is
147:29 - this one right time ID but T SCS this is
147:34 - one and from the right table which is
147:36 - the time data table what is the column
147:38 - is one I copied now right so it's time
147:41 - ID but T is small right this is how we
147:43 - can combine the two tables now let's
147:46 - just quickly see how the new table will
147:47 - look like yeah we have time ID So based
147:51 - on time ID We join now we are able to
147:52 - get the time also in the same data right
147:54 - we have breakfast or dinner or lunch
147:56 - whatever we know that this is a
147:58 - duplicate column right it is same as
148:00 - this so we want we can remove this how
148:02 - to do that can say combine data. drop
148:06 - right you can write like this and let us
148:09 - say I I write the small T time ID then
148:13 - you can say a is equal to one right this
148:15 - basically means drop the column and then
148:17 - if I want to drop it in this existing
148:20 - data set itself I can write in place
148:22 - equal to True right when I do that this
148:24 - combined data table will lose that
148:25 - particular column as we are dropping it
148:27 - so now once I write that if I write
148:30 - combined data
148:31 - again now you notice that other time ID
148:34 - column is gone right now we have only
148:36 - five columns because they were duplicate
148:38 - I removed the other column right that is
148:40 - how you can drop a
148:41 - column so now we've been able to uh
148:44 - combine them and also drop the duplicate
148:46 - time ID column right both these are done
148:48 - now show the data filter the data only
148:50 - for break first right how can we do that
148:53 - so before that I'm just going to give a
148:56 - heading to this so what did we do here
148:58 - is merging the two data sets and also
149:03 - dropping duplicate column of time ID
149:07 - right this is what we did here so now
149:09 - let's move to the next one right so I'll
149:11 - keep adding more and more
149:16 - code so I'm just saving it again
149:26 - okay
149:27 - so so I'm just saving it something got
149:31 - stuck there it's okay so we'll
149:34 - continue so only data for
149:37 - breakfast data for breakfast how can we
149:39 - filter only for breakfast if you notice
149:41 - here breakfast is there in the time
149:43 - column right so if I want to show only
149:45 - data for breakfast can write data
149:48 - breakfast as a new data frame
149:51 - it's basically combine data right but
149:53 - within this combine data I want to
149:56 - filter for this column time right and it
149:59 - should be equal to only break first so
150:02 - whenever this combined data of time
150:04 - double equal to break first This Is How
150:05 - We compare and put a filter in Python
150:08 - please show or pick up the data right
150:11 - that is going to be stored into Data
150:12 - breakfast now if I read data break first
150:14 - I will see now I get only the data where
150:18 - the time is breakast this is only purely
150:20 - breakfast data right that is how you can
150:22 - do this question show only data where it
150:25 - is lunch and also calories total
150:27 - calories more than 250 two conditions
150:30 - right so time has to be lunch calories
150:33 - must be greater than
150:34 - 250 so let me put the condition lunch
150:37 - and calories above 250 how to put this
150:40 - condition so let me say data
150:44 - lunch and 250 above right I can give any
150:48 - name so I will say combine data that is
150:51 - the data set again within that combine
150:53 - data I have to introduce a filter so
150:56 - what is the filter the first filter is
150:58 - time has to be equal to lunch right
151:00 - that's the first
151:02 - rule and also you can put an Amper hand
151:05 - and
151:06 - say the other column is about calories
151:09 - so I'm going to copy
151:11 - this right uh column name is calories
151:15 - with the
151:18 - c and this has to be greater than 250
151:21 - that is the condition okay and remember
151:24 - when we give multiple conditions we have
151:26 - to put each of them within a separate
151:28 - bracket right so this
151:30 - condition in this bracket then an Amper
151:32 - or an end and then the other condition
151:35 - again within this uh normal brackets
151:38 - okay so once I do this now let me run
151:40 - and see data
151:42 - lunch 250 and above what data we get now
151:45 - we only get data as you see off lunch
151:47 - and only above 250 right so basically
151:49 - there's only card rice which I eat
151:52 - during lunch it's more than 380 calories
151:54 - and then pizza right pretty much it and
151:56 - then once fried rice which was 350 right
151:58 - these are the only three items that I
152:00 - eat during lunch that have more than 250
152:03 - calories right so that is how you could
152:05 - solve that question next one is Group by
152:07 - time ID time ID is like by breakfast
152:09 - lunch dinner whatever see which had the
152:11 - overall highest calories intake right so
152:14 - how do we solve this question let me
152:16 - just keep adding some more code so
152:20 - calories by time ID
152:22 - right so time ID column is there but I
152:25 - could also do by time because time
152:27 - contains lunch breakfast and all for
152:30 - this what we can do we can simply say
152:32 - combine data. Group by here we have to
152:34 - do group by similar to SQL so I want to
152:37 - group by time right and what I want to
152:39 - do is I want to do for calories right
152:42 - the total sum right so to see which is
152:44 - the time when I eat the most amount of
152:46 - food so I can see like this I run it and
152:49 - as you see breakfast 6650 dinner is 6175
152:52 - little bit less snack is not everyday so
152:55 - it's less lunch is where I eat the most
152:57 - right more than 9,000 calories in this
152:59 - 15-day time period so lunch seems to be
153:01 - the highest amount of calories the time
153:03 - when I eat a
153:05 - lot next one sort the data of the given
153:10 - uh you know information by calories in
153:12 - descending order right so how can we do
153:15 - that so this is sort by calories this is
153:19 - also very straightforward question okay
153:21 - so I can say combine data dot there a
153:25 - like order by in SQL we have sort values
153:27 - a command right and then I can say by
153:31 - what do I want to sort by I want to sort
153:33 - by calories right just put that column
153:35 - name and what is the rule I want to sort
153:38 - it in descending so there is a function
153:40 - called ascending here I mean not a
153:42 - function an argument you can say
153:44 - ascending equal to false that means you
153:45 - want to sort in descending order now let
153:48 - me run this
153:50 - now you see Dosa is come on the top
153:53 - because that's the highest 400 banana is
153:55 - at the bottom because that has the
153:56 - lowest calories right so it is getting
153:57 - sorted in descending order of calories
154:00 - the highest calories is coming on Top
154:02 - This is how you could do a simple
154:04 - sort here just let me save it one more
154:08 - time and yeah I'm going to come back
154:11 - here next two seem very straightforward
154:14 - so show the unique values for the item
154:15 - column how many unique dates does the
154:18 - data have right
154:20 - so let's see here unique items right
154:24 - this is very straightforward so I can
154:27 - say combine data of
154:28 - items I think it's item right not items
154:32 - so item what are the unique values I
154:34 - could simply say do
154:36 - unique so you see Dosa cornflakes bread
154:38 - smoothie POA carrot cheese beans Tamar
154:41 - and R chips piz all this right all these
154:43 - are the unique values of items that I
154:45 - have eaten in these two weeks time frame
154:48 - if I want to find unique dates but also
154:52 - do a count right what is that so I can
154:56 - simply copy the similar formula right so
155:00 - here I the column name is date new
155:02 - that's the only difference but I want to
155:04 - count right so unique is similar to
155:07 - distinct in SQL right if you want to
155:10 - count distinct we can write Y unique
155:13 - okay Y unique is another function that
155:15 - will count the number of unique values
155:16 - so it says 14 values okay there 14
155:20 - unique dates in the given data set that
155:22 - is what they wanted us to count how many
155:23 - unique data set is dates is there in the
155:26 - data
155:27 - set next one they say rename the
155:30 - calories column to intake right the
155:32 - calories column name should change to
155:33 - intake and the time column which is this
155:35 - breakfast lunch dinner thing to time of
155:37 - day how can we
155:39 - rename okay this is an interesting
155:42 - question rename is a function that's
155:44 - also sometimes asked in interviews so
155:46 - first of all what is the rename I can
155:48 - like create a new map in a dictionary
155:52 - okay first of all what I will do I write
155:55 - okay calories is there please rename it
155:57 - to intake okay that is what they want us
155:59 - to do and the other one is there's a
156:02 - column called time so you write this
156:05 - colon symbol and write I want to rename
156:07 - that to time of day okay this is what
156:10 - they're asking step number one now in
156:12 - the original data right combine data you
156:16 - can simply say combine data do rename
156:19 - okay okay and what is the renaming that
156:21 - should happen so the columns should be
156:24 - changed to what is given in the map okay
156:26 - you can say columns equal to map what
156:28 - does this mean so calories will change
156:30 - to intake time will change to time of
156:32 - day now can we cross check our combined
156:35 - data let's see now if you notice instead
156:39 - of calories we got intake instead of
156:40 - time we got time of day right so you
156:42 - create a normal map using a dictionary
156:44 - and then use the rename function to
156:46 - rename the columns right pretty
156:47 - interesting question
156:50 - then coming to next one from 12th
156:53 - January to 13th January can you show the
156:55 - percentage increase in total calories
156:57 - okay now remember calories column has
156:59 - been renamed to intake so we want to
157:01 - find percentage increase in intake from
157:03 - 12th to 13th January how can we
157:05 - accomplish this right so I'm going to
157:08 - keep adding more and more
157:10 - rows so 12 to 13 gen percentage change
157:15 - in calories right whether it was
157:16 - increase or decrease first of all let us
157:18 - see the data right we have combined
157:21 - data like this right now for each day
157:25 - right we want to First do the total sum
157:27 - of calories right how can we do that so
157:30 - first of all I will say Group
157:31 - by date new right I want to do for the
157:34 - overall day right not buy breakfast
157:36 - dinner and all for the overall day so
157:38 - I'll do that and then I want to do total
157:41 - calories so intake is the column and do
157:43 - some okay so if I do like this you will
157:46 - get for each day for 1 Jan 2024 20 150
157:49 - is the overall calories second gen is
157:51 - 2,130 and so on right but here if you
157:54 - notice we don't have the column name
157:56 - here so if I write reset Index right if
158:00 - I use
158:01 - this now you'll notice we have date new
158:03 - and intake okay this will be step number
158:06 - one now step number two what can we
158:11 - do I want to compare it with the
158:14 - previous value right this is similar to
158:15 - lack function in SQL so what can we do I
158:19 - can write combine data of previous value
158:22 - right I can create a new column how can
158:25 - we do this I can say combine data of
158:27 - intake right and simply say do shift of
158:31 - one right this will basically pick up
158:33 - the previous value right and put it in a
158:37 - new column called combine data previous
158:41 - value maybe I shouldn't do it on the
158:43 - combine data I will do it on this
158:45 - calculated group right so what is this
158:48 - let us say
158:50 - aggregated data I write AG data equal to
158:53 - this okay so so I'm going to run this
158:56 - code and now I want to do it on the AG
158:59 - data not on the original data so I will
159:02 - also convert this and change it to AG
159:05 - data okay just observe what happens
159:09 - now what is this shift doing okay so for
159:13 - example first gen intake was 2150 there
159:15 - is no previous day value so obviously it
159:17 - is null right na is like n 2 January
159:21 - 21130 previous value is 2150 we are
159:23 - getting that here 4th January for
159:26 - example
159:27 - 2055 previous day or previous value is
159:30 - 1750 we are getting that here okay if
159:32 - you notice for 11th it's 1225 but
159:36 - previous day is 1,600 that is coming
159:38 - here which is good but previous day is
159:40 - 9th okay so that is missing we will
159:42 - still not be able to address that just
159:44 - go to pick up the immediate previous
159:46 - value of date okay for us we are just
159:49 - focused on 12 to 13 so basically from 13
159:53 - and 12 how did it have change right so
159:55 - 12 was 1475 it increased to 2100 but we
159:59 - want to do this calculation right so
160:01 - what can we do I can just come here and
160:04 - add aggregate data and create a new
160:07 - column okay percent change right I can
160:10 - give it a name so this is going to be
160:12 - nothing but aggregate like want to put a
160:16 - bracket so aggregate data
160:18 - of
160:20 - intake value
160:22 - right minus aggregate data of the
160:26 - previous
160:27 - value right percentage changes the
160:30 - current value intake minus previous
160:32 - value this overall thing divided
160:35 - by aggregate dat of the current I mean
160:40 - the previous value so that will show how
160:42 - much it has increased from the previous
160:44 - day or how much it has decreased right
160:46 - so something like this
160:49 - I think there's an
160:51 - extra symbol here this should be good
160:54 - okay let's now see aggregate data what
160:56 - value we get okay so we getting for
161:00 - example on 13th right from 12th if you
161:03 - compare 1475 became 2100 so that's
161:06 - almost a 42.3 7% increase from 12 to 13
161:09 - gen I increased my calorie intake by
161:11 - 42.3 7% okay this is how you can do this
161:17 - question so this is nice use of use case
161:19 - of the shift function right it's very
161:21 - similar to
161:24 - lag so I'm just going to add more and
161:26 - more lines let's go back to the
161:28 - questions use some function in NPI nump
161:31 - is another package to create a new
161:33 - column which which says small meal if
161:36 - that you know the time of the day is
161:37 - snack otherwise it has to say main meal
161:40 - right this is a very simple use case
161:42 - right similar to the IF function in like
161:45 - Excel so I'm going to go back
161:47 - here what I can do so this is numpy
161:52 - function so I can first import the
161:54 - package numpy and call it as NP now for
161:57 - this new function I can say combine data
162:00 - of let me say meals right new column so
162:04 - what should it says it the function is
162:06 - npw
162:08 - n.w so basically
162:11 - when the time of day right that is the
162:14 - column right whenever the time of the
162:16 - day is dou equal to snack
162:20 - right I have to call it small
162:23 - mean otherwise call it Big mean okay
162:26 - this is what they want us to do simple
162:28 - calculation like if now if I see comine
162:31 - data I'll have the new column okay so
162:34 - break first is a big meal dinner is a
162:35 - big meal when wherever there is snack
162:39 - right so if I want to quickly verify
162:41 - this data for snack it should show small
162:43 - meal right so wherever this time of day
162:49 - is equal to
162:53 - snack make sure you put the spelling
162:58 - right let's
163:00 - see so wherever is snack you see it's
163:03 - small meal so our logic is working right
163:04 - dinner breakfast and lunch will be big
163:06 - meal snacks is small so that is how we
163:09 - can do use np. whereare it comes from
163:11 - the nump package okay moving on to the
163:15 - next one rank the food so we need to do
163:18 - ranking
163:20 - which had the highest overall intake for
163:22 - breakfast dinner and so on right what
163:24 - does this question actually mean is in
163:26 - breakfast which was the food which had
163:27 - the highest total number of calories was
163:29 - it Dosa was it bread same way for lunch
163:31 - was it C rice was it Tamarind rice
163:33 - whatever same way for dinner was it
163:35 - pasta or was it something else for each
163:37 - time of the day right breakfast lunch
163:39 - dinner which food had the highest total
163:41 - calories how can we do this this is
163:43 - another interesting
163:45 - question so like rank food for each time
163:49 - of day right this there is a rank
163:52 - function similar to SQL in Python we
163:54 - will try to explore that right so I'm
163:56 - going to first load the data combine
163:58 - data and what I want to do first is I
164:02 - will say combine dat let us say this is
164:05 - ranking right so I'll give it a name
164:07 - rank data so I want to do combine
164:11 - data do group by
164:14 - right and I want to group two things
164:17 - right so based on time of
164:21 - and
164:23 - also the food right basically the item
164:26 - because I can eat the same item on
164:28 - multiple days and for this I want to do
164:31 - the total sum of intake
164:35 - right let let me do this let's see what
164:38 - I get okay so now let me see rank data
164:42 - what is
164:43 - there okay I'm getting like this so if I
164:47 - do reset
164:49 - Index right I will rerun this let's see
164:53 - what we get now now we get three columns
164:55 - so break first totally bread I have
164:59 - taken th000 calories right so for
165:01 - instance if I come to the data here
165:03 - bread is 250 per day so maybe I've taken
165:05 - bread four times right in this two week
165:07 - time period and same with so on right
165:09 - poha total calorie intake is 400 and
165:12 - poha was part of breakfast right so in
165:14 - breakfast Dosa is
165:17 - 1,600 but in dinner also some days I
165:19 - have taken those are that is 700 right
165:21 - this is how we are splitting the data
165:23 - now we want to give a rank right within
165:25 - breakfast which is the topper right so
165:27 - if we look at the data here can quickly
165:29 - see I think looks like conflix is the
165:31 - highest in breakast in terms of intake
165:33 - how do we give a ranking for that can
165:37 - create a column called Rank and see how
165:40 - this logic works so I can say rank dot
165:43 - Group by okay and I want to group by
165:47 - time of day okay so this group by is
165:50 - very similar to the Partition by we use
165:52 - in rank in
165:54 - SQL time of
165:57 - day and what do I want to rank I want to
166:00 - rank the
166:01 - intake so I'll say do rank off and here
166:04 - you have multiple methods okay method
166:07 - you see within that you have average
166:09 - minan Max first and dense dense is
166:11 - similar to dense and then we have first
166:13 - mean Max you can play around for now I'm
166:15 - going to just put first right this is
166:18 - one of the methods and then ascending or
166:20 - descending right this is like order by
166:22 - ascending is false right because I want
166:24 - to do it descending order of calories
166:27 - now let us see what rank data is showing
166:29 - right so Group by time of day is like
166:31 - partition each time of day separately
166:34 - then total the intake intake value is
166:36 - already total and find the rank right so
166:38 - within breakfast which is the highest
166:39 - within lunch which is the highest we
166:41 - will be able to find this out now let's
166:43 - start the query and see so notice we got
166:45 - the rank right so within breakfast rank
166:48 - one goes to F 2,000 and I think the
166:51 - least is seven rank seven which is vermi
166:54 - which is just 200 if I come to dinner
166:57 - for example the topper is milk like
166:59 - every day I have milk for sure so that
167:01 - is the highest then when I come to lunch
167:04 - C race is leading the way right more
167:05 - than 4,000 calories right and in snack
167:08 - category also there is milk so I drink
167:10 - milk a lot both for evening and night so
167:12 - milk is the Topper Again rank one right
167:15 - so this is how you could Partition by
167:17 - time of day and based on intake do the
167:19 - rank there's also dense rank like method
167:22 - equal to dense just play around with it
167:24 - but this is one way to Showcase okay in
167:26 - each time of day what was the food that
167:28 - had the highest amount of intake overall
167:30 - across this two we time
167:32 - period okay next one uh simple plotting
167:35 - question plot the time of day category
167:38 - and the overall calories using uh
167:41 - plotting function okay so for this we
167:45 - can just go to chat GPT and ask uh plot
167:49 - package M plot Li how to import suppose
167:52 - you don't even know the function for
167:56 - example it should ideally give you some
167:59 - sort of an answer import M plot Li as py
168:01 - plot right I could come here and copy
168:03 - that so this is
168:05 - plotting I'm going give the name okay
168:09 - now what do I want to do each time of
168:13 - day total calories so we have done this
168:14 - multiple times I'll simply say plot data
168:17 - this is nothing but combine data do
168:21 - group by right I want to group by time
168:23 - of dat step number one calories is now
168:27 - called as intake do sum
168:31 - right so if I see plot
168:35 - data it'll be like this okay now if I
168:38 - want to actually plot this what I can
168:40 - do can see pl. bar if I want to show a
168:44 - bar graph I can say plot data. index
168:47 - index is nothing but the time of of the
168:49 - DAT and also plot data. values okay
168:51 - values is the values we
168:53 - have so if I run this I'll be able to
168:57 - plot right okay I see breakfast dinner
168:59 - lunch is where I have the most intake
169:01 - right simple way to plot you can also
169:03 - see ways like how to add xaxis y axis
169:05 - and all right try with chity but this is
169:07 - a simple way to plot right so you import
169:10 - the package do the group by and then you
169:12 - say PLT which is nothing but this
169:15 - package bar want to plot a bar graph
169:17 - plot data. index index will be the time
169:20 - of day values is the calculation right
169:22 - the sum of intake that we did this is
169:25 - how you can do simple plotting one more
169:27 - question write a code to find rows which
169:29 - contain name pasta right so I think
169:32 - there is pasta
169:34 - somewhere um if I scroll down you see so
169:37 - you want to see the row where there is
169:40 - pasta how can we do that I can create a
169:43 - new column combine data
169:45 - of let's say check pasta okay you can
169:49 - give whatever name you want so I can say
169:52 - combine data
169:54 - of this item column right it should
169:57 - contain right the string should contain
170:00 - pasta so I'm going to say string. find
170:02 - of
170:03 - pasta and now if I run
170:07 - this you'll see mostly minus one right
170:10 - wherever it is not found wherever it is
170:12 - found there will be some value right so
170:14 - how can we try and do that so I'll say
170:16 - combine data of combine
170:20 - data of check
170:23 - pasta right this
170:25 - column wherever it's greater than zero
170:29 - right wherever it's not minus one let's
170:32 - see what we
170:33 - get
170:36 - okay there's like literally no value
170:39 - like that right that's a bit weird let's
170:42 - check let's say not equal to
170:46 - minus1 okay yeah okay it's it shows zero
170:50 - here right so it's able to find it at
170:52 - the zeroth place that's why you know we
170:54 - should not put greater than zero but
170:56 - should put not equal to minus one only
170:58 - two values right I think on 2 Jan and 7
171:01 - Jan I had dinner as pasta right it was
171:03 - able to locate that that is that
171:05 - question now coming to few general
171:08 - questions beyond the data set little bit
171:11 - about loops we will see write a for Loop
171:13 - to display only multiples of five
171:15 - starting from five all the way to 45
171:17 - right I want to show 5 10 15 20 so on
171:19 - till 45 so for that let me just add a
171:23 - few more lines of code so how can we do
171:27 - multiples of five you write a simple for
171:30 - Loop so you can say for I in
171:32 - range uh you can begin it at five take
171:36 - it all the way up to 45 in steps of I
171:39 - okay and in each of these cases you want
171:41 - to just print the I right print the
171:44 - value here you will get only till 40
171:47 - right because whatever you include here
171:50 - it will check only till one number
171:51 - before that so here it will go only till
171:53 - 44 so before 44 the closest multiple of
171:56 - 5 is 40 so if you want to show till 45
171:59 - you can increase this by one number now
172:02 - we show 5 10 15 20 all the way up to 45
172:05 - right simple for Loop you can use to
172:06 - show the multiples of five all the way
172:08 - up to 45 same way for Loop to display
172:12 - squares of numbers from 1 to
172:14 - 9 so very simple I can just copy the
172:18 - similar formula squares of 1 129 okay so
172:23 - here what I have to do I have to start
172:24 - with the number one go all the way up to
172:26 - number I want to show till 9 so I will
172:28 - say 10 and in steps of one that is okay
172:32 - and print the square of the number so I
172:34 - will say print I into I that will show 1
172:37 - 4 9 16 all the way up to 81 right I into
172:40 - I means I square right so for each
172:42 - number whenever I is 1 it will show one
172:46 - y is 2 it will show 2 into two which is
172:47 - four and so on since I put 10 here it
172:50 - will go all the way up to I equal to 9
172:52 - when I equal to 9 show 9 into 9 that is
172:54 - 81 we get that right then one more
172:58 - question write a simple code to declare
173:00 - a variable a as 8 and write an if
173:02 - statement to say if the value is greater
173:03 - than eight or
173:05 - not so this is if
173:08 - statement so they say declare a as8 and
173:12 - I will write so if a is greater than it
173:16 - then I will say print
173:19 - is above it okay simple and then I can
173:23 - put else condition so else what should I
173:26 - print print a is not above it okay now
173:31 - let me execute this code and it will say
173:34 - a is not above eight as you know a
173:37 - greater than 8 condition won't work the
173:39 - else condition is working right if I put
173:41 - a is
173:42 - six again a is not greater than 8 so the
173:46 - else condition will work a is not above
173:48 - eight okay okay if I put a as 13 then if
173:50 - a greater than 8 condition is true a is
173:52 - greater than 8 so it should show a is
173:54 - above 8 right so you can play around
173:57 - this is how you can write a simple if
173:58 - and else make sure this I and E are
174:01 - aligned in the same line that is very
174:02 - very important okay one final question
174:06 - declare a simple list with B with four
174:09 - values 0 1 2 3 write a for Loop using
174:12 - try and accept for running I values from
174:15 - 0 to 6 Whenever there is no value print
174:17 - value on available what does this even
174:19 - mean right looks bit complicated let's
174:22 - see right so this is a list question so
174:25 - we they ask us to create a list B with
174:26 - four values 0 1 2 and three okay step
174:29 - number one so I'm going to execute this
174:32 - okay now within a list if I want to read
174:34 - an element if I say B of Zer it will
174:36 - read the first element that is zero if I
174:38 - say B of one it will read the second
174:40 - element what is second element it is one
174:42 - right if I say B of two it will read the
174:44 - third element that is two right that is
174:48 - how a list works right L index start
174:51 - from zero now they want to show us these
174:53 - values and run it in a for Loop for I
174:55 - ranging from 0 to 6 okay so you notice
174:59 - if I write B of three it will show the
175:01 - fourth value that is three but if I
175:03 - write B of four it will show index error
175:05 - right because B of four means the fifth
175:07 - value in B B has only four values there
175:09 - is no fifth value so it shows index
175:11 - error right so we have to be careful
175:14 - just going to change this to something
175:15 - else now if I write for right for I in
175:22 - range they want from 0 to six I'm just
175:25 - going to put like this right and they
175:28 - want us to print the value within B
175:31 - right so I'll say print B of I if you
175:34 - notice here so when I is Zer B of 0 is
175:38 - zero right I is 1 B of 1 is 1 I is 2 B
175:41 - of 2 is two i is 3 B of 3 is three but
175:44 - when I becomes Four B of four is not
175:47 - there it's an index error that that is
175:48 - what is showing up and they are saying
175:50 - use try and accept statement to remove
175:52 - the index error and say when there is no
175:54 - value present print value unavailable
175:56 - how can we do this so for this we have
175:58 - to add this in a try and accept
176:00 - statement so first you will say try
176:02 - right wherever there is no error in
176:04 - those
176:06 - cases the for Loop should work right
176:08 - make sure they are
176:10 - aligned step number one so I'm printing
176:13 - BFI right in the cases where there is a
176:16 - problem where is there is an index error
176:18 - you can say accept index error right
176:20 - wherever there's index error in those
176:22 - cases can simply print what they're
176:25 - saying value unavailable or something
176:28 - like that okay now let's see what we
176:31 - get now we we get value unavailable
176:34 - right so 0 1 2 3 is coming that is great
176:37 - but when I becomes Four B of four is not
176:40 - there since value is not there it shows
176:42 - Val unavailable this is better than
176:44 - showing an error so you can use try and
176:46 - accept for these cases where there's
176:47 - some specific type of error like index
176:50 - error okay so what I will be doing is I
176:53 - will uh share the link to this whole
176:55 - notebook right you can play around with
176:57 - the code I will also upload the data
176:59 - sets please upload them as CSV and then
177:01 - use this code to start reading them okay
177:05 - I hope you enjoyed the video I'll see
177:06 - you again in another video till then
177:08 - take care bye

Cleaned transcript:

learn data analytics using only free Google services this course teaches key data analytics Concepts using Google big query Google Sheets Google looker studio and Google collab Vias will teach you data analytics using the Google stack hello guys welcome to this end to end free data analytics projects course I'm vas adya currently working as an analytics instructor near Berlin Germany in this course I will be covering all the important data analytics topics like Excel SQL Python and data visualization and use it to solve interesting questions on varied projects we will be using the Google stack here because to use these tools with Google stack we do not need any additional software installation all we need is a Gmail ID before we get started I would like to thank free code camp for the massive impact they creating and I'm happy to contribute to this cost and reach a larger audience so that a lot of people can learn these data analytics topics for free I also run a YouTube channel named analyst Aditya the link is given in the description here I have posted End to End videos on SQL python web scraping projects tblo power Bay and also tips on how you can build your resume how you can leverage LinkedIn to get a job and also some tips around interviews and building your GitHub profile so let's get started with the project series first up we will start with spreadsheets spreadsheets are one of the most common tools tools you're going to use in your data analyst job in this coming project we are going to use Google Sheets to analyze my own travel expenses data of my trip to varied countries we are going to use Simple intermediate and also Advanced functions using Google Sheets and drive insights and find interesting stats from my data so this is the data set we are going to work with it's in fact my original data I always want to showcase original data and we can do some analysis on it that's always interesting so this is like the date this is the country where I've been to this is the city then I have something called as cost let's say this is in Euros there's a column called category ID right it has 1 2 3 4 5 6 7 10 9 all these numbers what this is for this sake we have a second table called category so as you see category ID each of them signifies a specific area where I have spent money right one is break first for instance s is some entrance ticket to some place or some Museum or whatever 10 is like something that has been done with shopping and so on right so we have two simple data sets and uh now we are going to solve some questions using Google Sheets right like plenty of questions plenty of Concepts and topics we're going to do so let me directly jump into the question list we'll try to crack them one by one right this will be great practice for you we going to cover a wide array and range of functions as well so first of all find the unique values for each of the columns and show us how to count the unique values right so unique values for each of the columns what is the formula you can use I'll just show you for one specific uh column let us say I want to find the unique countries that I've been to right I've been to number of countries so how I can do that is using the unique function itself so you can say unique and just select the full range right B2 is to b128 so now I get the unique names of countries that I've been to right around eight countries so suppose I want to count the unique countries what we can do the only difference in the formula is you say count unique and you will select the same range okay so now I'll get eight why because I've been to eight unique countries right so if you put unique you'll get the actual values if you say count unique you'll get the number of unique values right same way if we have to do the same thing for another example let us say City I can simply say unique Open brackets and select the different column right so I can select this and you see I've been to so many different cities right basically I've been to 12 different cities across eight different countries right so unique is a powerful use case uh so do remember that and when you want to count unique values use count unique function right very very relevant so so we have done first question now next question comes how can you combine the category table with the original data so I have category table here where I have the actual name of the category how can I combine it with the original data right maybe I'll just insert one more column here just to kind of create some uh space so how can we combine these two so I have category ID here and I have category ID here right they are the same common column now we can join these two data sets using the V lookup formula because we have a common matching column right how can we do that so I can add a new column and I will call it category itself so I will simply say we look up I want to look for this category ID value where do I want to look for it I'll go to this table I'll select this range right this is the range where I want to find in this which column do I want to look for I want to look for the second column right because second column has the ual value of the category and I want an exact match so I'll put false okay and also remember for the whole formula range I want this to be fixed right always I'm going to refer to the same A2 to b14 range so I will just lock it with the dollar and now I get okay category ID one means break first and now let us say I can just go here and double click the plus I will get the formula copied accordingly right so for example five category five means for travel right basically for flights let us just double check so five is travel okay now we have the column category also in our original data we managed to integrate it with a simple vlookup function very very powerful function next question what is the total cost spent on breakfast overall there are multiple ways to do it I'm going to teach you a simple way using Su if okay so let me go here and like only for B break first I want to count the cost right so what I can do for example I can write break first okay and I can say sum if right what is the range right where I want to check for the criteria I want to check this column so I'll select this complete thing okay the second thing is the actual criteria right what is the criteria I want it to match with break first so I will select this and in the case it matches I want to sum I want to sum the values in this column right so I just select that and leave it okay so I noticed that for breakfast alone overall spent around 400 right simple use of some if right so if we want to verify this for example we can simply put a filter right let us just filter out break first this is just to cross check so I'll filter out breakfast and I can see the total cost as you see the sum is coming to 400 so overall across all these tips for breakfast I have spent 00 so I'm going to just remove the filter this is a powerful use case of su very good function to know okay next uh total cost spent on travel for Spain okay there's an extra twist here there are two conditions okay so travel is one column and also specifically for Country Spain right so in this case what we can do we can use a su ifs function we want to give multiple conditions right so for instance I will uh just write these two words here right for example I can write Spain and travel and now I will use a su use function right so I will say sum ifs here the first thing is the sum range so I want to sum this range okay and now criteria range number one right criteria range number one is basically country so I'm going to select uh B2 to B1 128 what is the first criteria what is the first criteria I'm going to select if that ever matches the value here which is pain and then criteria range two criteria range two is basically the last column right basically our category column and what is actual criteria 2 here criteria 2 is actually if it matches travel okay and I'm going to close and I get the value as 768 right so 768 is the amount I spent on travel to Spain if you see here it's a 280 here on a trip to mayor and there's one more Spain Madrid where travel was 488 if you add them up you'll get that number so that is the answer so some so some a column here in the case cost column but based on multiple conditions Country Must Be Spain at the same time the category must be travel okay another useful use case I would say then how many rows are there in the data that have category as travel okay so we want to count the number of rows here so this is a simple use case of a count if function okay so I'm simply going to say count if uh so this is the range again I want to check in this range right I'll select them all and I want to make sure how many of them equate to travel right so I have the word set up here already so I'll just click that sell and as you see there are 11 times in 11 rows there is some cost associated with travel right simple use case of the county function okay moving on to the next next one find the month of the date using a calculation in a new column so in this data we are given month right how can we find the uh I mean we given the date how can we find the month right I'm just going to show a dummy formula here how you can do it that's actually month function itself directly and you just select month of date okay and you close it you get 12 right so this is December 24 2022 so month is 12 so it gives an auto suggestion if you want you can rock the formula just go to remove it for now but you can use the month function as you see for that question next question use an if formula to show wherever cost greater than 100 are expensive the other value should be shown as cheap okay so I'm going to go back here right so let's call this column like price or something like that so if it is greater than 100 so I will say if this value is greater than 100 right then it is expensive very simple otherwise I'll call it cheap right as simple as that and close the bracket okay so 20 is obviously less than 100 so it's cheap going to drag the formula so this is 230 obviously it's expensive and so on okay easy use case of a simple IF function many of times you might use this in your job as well okay moving on to the next one show pivot table for average cost per country right so what can we do I'm going to just select the whole range right all the rows and columns and now I'm going to just say insert pivot table and I'm going to put it in a new sheet going back to the question average cost per country right so in the rows I can add country right here it is and then in the values I can add the cost right I don't want to show the sum I want to show the average I will select the average so then I get the values right so as you see average cost per country um Colombia it's yeah around 164 uh other countries are like slightly lesser right what could be the reason right if we were asked to investigate one step further why this number is high if we go back into the data and deep dive a little bit you see mostly cost is like like this travel is maybe 200 300 and so on but if you notice specifically for Colombia travel itself cost 2,600 right this is the flight ticket going from Europe to you know South America is quite costly and this is the anomaly right this is the Reon why the average for Colombia is high right you you notice this is very high this is the reason you need to be able to investigate and find reasons like that because there is a abnormal value you should be able to find out what is the root cause of that abnormal value right this is an additional thing you could do for this question then uh simple uh calculation how would you display the first two letters for each country right so I have uh the country as a column here how can I display the first two letters for each country for example for austri I want to show Au we can use a simple text function called left so I would say left I select the string which is this and just say two right that will just show the first two letters so if I copy the same formula for instance for here for Slovakia you see you'll getl right very simple use case of LIF function very powerful function text function moving on write a function to find or check if a city name contains the letter V okay what can we do for this case so I'm just going to copy this data up to price and I'm going to go to a new sheet and just paste special like basically the values so now we want to check if the letter V is there in the word or not we can simply use a find function okay I'll write find so I want to search for the letter V and where do I want to search for I want to search for in the um I think it was city or country let's let's just go back here yeah it is for the city right so if it shows value obviously it's it's an error um because yeah it is not able to find it right so if I drag this formula down you can see bratis laava has the letter V none of these have anything plit has the letter V so the interesting thing to note here is VNA has the letter V but it has a cap capital V right that is the reason it is still showing a value error which means it cannot find V so let us convert this into a capital V and C then we get the value one because it is able to find a capital V in VN right so remember there's a differentiation between the small letter V and the capital letter V if we want a showcase next one formula to show the second third and fourth letters of the column category right I'll go to this new sheet second third and fourth letters right of column category which is here here so what we can do is we can try to use the mid function so I'll say mid of this particular string then I want to start from the second letter and then show the next three letters so I will put three so in break first I'll get second letter third letter fourth letter which is re now I can drag the formula down for lunch you will get UNC for dinner you'll get i n travel you'll get second third and fourth is r and so on okay another useful function to know uh mid right very relevant moving to the next question which country cost the most money overall according to the data right which had the highest cost so for this again we can just select everything right you can go to the pivote table and say create a pivot table so again I'm just going to select country and then I'm going to select in values cost right the total cost right as you notice here and then after that what can we do just think about it so if you notice here we want to arrange it by some of cost but descending right so what can we do we can go here and select sum of cost okay this should work and then we notice of course total cost RS Colombia and Peru are on on the top right overall cost RS these two are the most expensive right let me move to the next question so we are done with question this one right so conditional format rows which have country as Spain with red color date before 12th July 2023 right any date that is before 12th July 2023 with blue color okay so let us try this I'll go to the original data so country as Spain right how can we conditional format let me go here format I'll say conditional formatting so for this whole set I want to apply a rule uh let us say text is exactly and then I will write Spain and I want to do red color right so I'll select red color and you know the rule is written and it's done okay so that means Spain is quoted red right let's see if there is some more Spain later yes it's also given red color right that's perfect okay let us move on to the next one which is for the date right so what they are asking us is anything before 12th July should be blue color so for example let me select one date I go to format conditional formatting and I I say for example this cell and I can say custom formula right this is cell uh A2 so I'll say if this is less than I will use the date function okay so date 2023 July is the 7th month 12 right anything before that please quote it with blue color okay and I will say done so by doing that yes this is before 12th July 2023 it is blue color and what I can do I can format paint and just drag it along all the way down to the end of the data right like this and I stopped here and now let's say which all got blue color so as you see all this date is 13th December so up to any date before 12th July which is like up to 10th July got coded with blue color okay this is how you can do conditional formatting for a particular column in Google Sheets so that question is done what was the highest value of cost in the given data this is a simple on line formula so you can say maximum of the value of cost in this column right which is the full e so I presume it will be 2600 which I already showed you right I think it's the travel that happened with if I remember right it'll be in bota like Colombia this is what it is okay moving on to the next question which category cost the most money in pero here instead of calculating I'm just going to go through the data right because there's not a lot of rows for per if we scroll down we see um you know plenty of uh combinations here so what can we probably do we can try to maybe do the P table again so I'm just going to select everything right these columns and I'm going to say insert P table okay the first thing I want to add is I want to add a filter for country that's the first thing um here we can select what we want to show want to clear everything and just show Peru right so it's data only for Peru now coming to row what can we add here we can add the category and then in the values I can add total cost okay so I have these values now order by I can see descending sum of cost okay so now I notice again with respect to Peru to an extent we can see that um travel is probably uh the costliest right and how do I know this is only Peru because here I selected only for Peru okay so travel is costing around uh 960 right that's probably one of the most expensive now let me move back now they're asking can you create a drop down list of cities and show the total cost of a particular City depending on the city selected right so for this what we can do I'm going to copy um all this I'm going to go to a new sheet right I'm going to pay special I will say values only right now they want a drop down of cities how can we do a drop down for that we can go to data data validation right we can add rules but before that we want to find the unique values of cities right that will make our calculation easier so I will write unique and I will select the full list of cities right as a first step so I have the list of cities from this I can generate the drop now I can go back to data validation and say add rule uh and then from here I'm just going to say uh drop down from a range okay so it's going to apply to basically uh this cell over here right which is I3 which is written Here and Now drop down from a range I'm selecting and what are the values so I want to select all these values okay want to click okay and say done now now let's close okay so now I have the CT and now it's a simple matter of writing a sum IF function okay I'm going to say Su if then I'm going to say for instance City range so I'm going to select everything right and what is the criteria if it is equivalent to the one we have in the drop down which is I3 then please show the total cost so the sum range of this column which is column e okay so it's 143 for bratis laava now if I change it to Berlin it's 144 banal Luca is 281 and so on right if I change it to split was it's 252 and so on right the total cost uh depending on the city selected right we did data validation created a drop down how many unique months are there in the data how can we find this so uh to find this what we can do I mean we have so many months here right so we can first try to find the month so I'll insert one column to the left again right let me say month and then as you all know we can put a simple formula month of date A2 that's done I'm just going to track this okay and now from this column I can simply write count unique right to count the number of unique months write the formula with the right spelling and I want to do it for H2 to H1 128 and then that's it so we have like we have only four unique months it's a little bit weird let's check we have 12167 and again 12 right more or less yeah so you have December if you notice then you have July June then yeah January there's there and then again December right so the count unique values says that it's only four so 12 1 6 and 7 okay then moving on to the next one so this is a bit more complicated I think they want us to create a grid with countries on the one side categories on the other use the index match to Showcase formulas to display the total cost depending on a combination this question seems very very clumsy but let's break it down and see what it actually means right so for this question what I'm going to do is so they're asking based on countries and then categories and the total cost okay so easiest option I can think about is first I'll create a pivot table as usual I will say insert pivot table in a new sheet okay now step number one I will bring country to row then I'll bring uh category to columns and then for the values I want I'll click and say sum of cost okay so this is done now we have for all the different categories the thing so now they want us to create a drop down right so this is going to be a bit tricky so let us say I will have Austria here for example right just to show you a simple example then let us say I write dinner here okay so now for Austria for dinner what was the total cost right if we see the grid we see the value 12 how can we use index match to show this automatically right so what we can do we will have to use formulas right first I will try to match okay the value of Austria and see over in this crit which row does it match to I'm going to select all this and now I will get it matches the first row right because Austria comes in the first row so if I have to change this to Bosnia then it will show second row because in this list of values Bosnia comes in the second row right so this is one value the same match I will use to see where does dinner come in this full list of categories so I can say match of dinner right and now I want to compare it with this list of categories so I'm going to select all these values all the way up to travel okay and I put a zero because I want an exact match so it shows that dinner is the second column right if I were to let's say select game then it would be the fourth column right because break first dinner entrance game right so let me move it back to dinner so now I have where it comes in the country like which row and where it comes in the category like where where is the column basically now what we can do right once we do these two steps we can use a index function right and now what we need to do is we have to select the whole range right just select the range of the 13 columns and the countries right no need to select the grand totals selecting the whole range and in this we need to put 2 comma 2 right that was the value we had we get 40 right so instead of 2 comma 2 I can make so I can substitute it with this cell values which is b19 and c19 right so I'll make it b19 I'll make this c19 now I get 40 so for Bosnia for dinner it cost 40 right let us say now I change it to Peru so for Peru so this value has changed so Peru for dinner for Peru for dinner it cost $189 right so now the grid changes automatically if I change dinner to entrance for Peru for entrance right for Peru for entrance it cost 200 and we get that value now our value is dynamic so you need to match the column and the row and then put it into an index function for the whole array and then accordingly based on the row and the column your value will automatically change right cool use case of index and match moving to the next question 21st question can you use a filter function to Showcase only data when country equal to Colombia right so what I'm going to do again I'm going to copy this right the whole data I'm going to put it in a new sheet okay I'm going to pay special so filter function to show only the information when country is Colombia right so for this we can use a filter function which is directly there in Google Sheets I'm going to say filter right so let us say I want to filter the whole range of data so I'll select everything right and what is the condition that I want to apply I want to apply it for this column right basically country column and say whenever this is equal to columia we can write like this right so filter what is the range you want to show then which column you want to filter and what is the criteria here it has to be equal to Colombia so I'm going to write like that now you notice I got like with just one formula an array formula I got all the rows just for Colombia right basically Colombia and in that there was only one city which is bota right super powerful function filter so definitely learn it very good to know moving back to the questions they're saying use text join function maybe this is new for us to show cities separated by a hyphen depending on the name of the country right for one particular date of your choice right this seems very very confusing you know so so let us maybe go back to the data right over here so they are to select one particular date right so for example let us select just 24th December right there's only Austria in here but I will still copy this to a new sheet okay so for this date for the particular country right showcase all the cities separated by a hyphen right so in this case host has only one city right how can we apply this function how can we apply this so you'll have to say text join okay and then you want to separate them by hyphen you put that first then if you want if there is empty values if you want to ignore you can leave it blank so I'm going to leave it blank and then what do you want to showcase so I will basically put a filter formula here you say so here I want to basically showcase the city okay and the criteria is this thing should be equal to a particular country right Austria for example let's see what we get so I get VN VN V separated by hyphen right just like that hypothetically if I had something else like salsburg or something then as you see I'll get Vienna VNA salsburg Vienna right so essentially this is what it is if we want to test this formula on a better data I can also go back to my previous sheet right and grab some of the data where I have multiple countries right multiple cities like Peru has Lima on the different days kusco on a different day Machu picu on a different day right so maybe I can just grab some of this to just show you so I just copy all this come back to sheet seven right let me just uh paste it again here like this right so the columns are not sorted let me just delete them for now and also remove this column now what I can do here if I have to do text join I could do the same thing right text join D limiter here is the hyphen then I'm going to ignore the empty and the text so I can as usual put a filter want a filter for this and then I'm going to say based on the criteria that is this is equal to B okay now we get Lima Li basically all the city names they're coming in an order and hyphen is there to separate each of them right that is the whole purpose of this question so good function to not text join is not so complicated but not commonly used also but it's good to know it's like an addon question which country cost the highest money for travel right so I think we did a kind of similar question somewhere so uh let's go back to one of the P table so here I have uh sum of cost right so like let me go back to edit which country cost the highest for travel right so here I'm going not going to show only one item I'm going to select everything okay and then let me just remove country from here right here I will add category right so I want to see only for travel right so I'm going to clear and select only travel that is Step number one okay and actually here in the row I'm going to remove category and I'm going to add country right and now the filter is only applying for travel as you notice which country cost highest for travel again it's Columbia 2600 as we can see we can also sort and see but yeah it cost the most for travel I think we did a similar question before insert a pie chart to show cost breakdown per category right so I can go back to pivot table 7 uh cost breakdown per category so what can we do um I'm just going to remove the filter here and uh instead of country I can add uh cost break down by category so I have this so I can now simply select this full thing right and I can say the chart and we get pie chart right so we get the percentages stay cost 19.7% travel was the most expensive 57% breakfast 4.8% DIN 4.6% and so on right simple pie chart can showcase okay which cost the most in a very visually appealing format then translate the word travel into Spanish right so here we can use a Google translate function itself so I'm going to say Google Translate what is the text right the text is travel I'm going to put that Source language right I want to translate it from English obviously this is English to Spanish Spanish will be es so if I translate this I get vaha like J sounds like a h sound so that means travel right so you can do that cool so we have done that let's move to the next question display total cost spent per month right Remember December was there in 2 years but they are looking at month level so we can use the same month although it was different years and let us see right so what can we do we can maybe go to the original data again right so I'm going to Simply sa insert first let me copy this to a new sheet right because I want to do uh the month calculation as well um let me just say paste special right I just want to paste the values so I'm going to do month and say month of um this date okay and then drag the formula so step number one step number two select them insert P table create so row will have month then values will have sum of cost and then percentage of total right so for that here you can see uh values is shows as you can select percentage of column then that will show okay 80% of the cost came from December right this is an easy way to do it okay let's move to the next question how many days were spent in Spanish speaking countries right how do we know which is Spanish speaking this like needs some basic knowledge so here I know for example Spain Colombia and Peru are the Spanish speaking countries right so what can we do I can again copy this data and put it into a new sheet I will pay special okay then I can put a filter and only select Spanish speaking countries right what is those Peru Spain and Colombia right so these are the dates now count the unique days right so I'll simply say count unique of this right so now now I have the filter data let's say I can copy this and put it into another new sheet right so now here I have only Spain Peru and Colombia right now I can find the unique number of days so I can say count unique of this column basically so there are about 22 unique days I have spent in these Spanish speaking countries right that is there then concatenate country and city separated by a hyphen right this seems a simple question how can we uh concatenate country and city so let us go to the original data again or this column for example I'm going to remove the filter again right concatenate country and city so we can do it two ways is you can use concate this one which is country then put a hyphen and then select the city right this is option number one Austria hyphen Vienna option number two is you can select this put an Amper sand then hyphen Amper sand and then the city C2 right so either use Amper sand or you can use concatenate function both are going to work to do this then how do you remove duplicates from the country column so this is also very straightforward we go back to the original data let us copy the country column into a new sheet so I'm going to Space special values so now if I want to remove duplicates I can get to data data cleanup remove duplicates and now I get the only the original countries the unique countries which is eight Austria Slovakia Germany Spain Bosnia Croatia Colombia and Peru okay so I hope you enjoyed the video we have managed to solve all the questions I'll post the sheet also in our description have a look at it just to finish off suppose some of the formulas you're not aware of right you can obviously use chat GPT so I'm going to show you some interesting examples where even if you don't know the formula how you could leverage CH GPD let us take simple example of that Google translate question for travel so you can write write me a Google translate function in Google Sheets to convert the word travel from English to Spanish okay simple example chat jpt will probably give you uh the formula Google translate function says travel and Es right is English es the target language is Spanish right so simple level it can easily teach you things like this right if we are to just give it one more scenario for example here I have like the data right let's say is in column B cost is in column B I want to find only the total cost for Country Spain right we want to do some if but let's see if we can generate that using chat gbt right I have column b as country column e as cost write me a sumi formula to show only the cost when the column has value let's say Spain right and it's going to give a simple sum if formula it's assuming that a head us so it simply says sum if B is to be Spain and then do the cost of that column right so if I can copy this code come here and paste that's a double equal to let me just remove that you see we get 1747 which is kind of the cost for Spain okay so if you're not aware of the formula also you can use chat GPD please remember that give the right prompts and you will learn the formulas okay I hope you enjoyed the video I'll see you again in another project if you like the video subscribe to the channel follow us for more videos there are more topic related videos like this with projects on SQL python coming up stay tuned spreadsheets are a great tool to start with however not always you get data in spreadsheets especially if the data is very large it becomes prudent to understand how to write queries and get data from databases in this coming project we are going to use Google be query to write SQL queries and analyze information on my own expenses data from 2023 this expenses data has detailed breakdown of expenses across various categories we are going to write simple and also intermediate and advanced SQL queries using Google B query to drive in sites so once again welcome to this practical project we going to use real data to understand and learn SQL write queries and make insights and we're going to use Google B query okay so I have some data here for example there's the date uh the company basically where this expense was done uh there is something called category ID we'll learn about this further and what was the cost rate like what was the amount spent so there's a separate table called category ID and C category so you have category ID and the category so for example one is rent five is recharge eight is shopping and so on now we're going to try and answer questions by uploading this data to Google bigquery we are going to answer a lot of questions okay so what is the first step we can go and put this URL I'll put it in our description as well and you'll land in a place like Google bigquery okay now you can say create project as a first step give it a name big query analysis right you can give whatever name you want I'm going to say create okay that's the step number one it will take some time to create a project okay and this is where we can actually upload our data and start writing queries so now it's loaded so over here I can go and say create data set so data set let me say uh expenses okay I can give it any name I want rest you can leave it as such and just say create data set okay so now I have a data set called expense in this I can upload tables okay so how are we going to upload tables so I'm going to go and download this as a CSV file okay so downloaded that same way we will download category also as a CSV file now I have downloaded both so I can go go here and say first of all create table so I want to upload a table so I'll select upload so as a first step I'll select uh the data table okay and I can give it a name data over here I will say Auto detect and create table right so first I'm uploading the data table so now we have the data table loaded you can go to 3D buttons and click on query and you can select everything from the table right I will just remove this uh limit so if you select everything from the table you get the data now okay so basically here what you have is bigquery analysis 41260 that's the name of the project expenses is the name of your data set and data is the name of your table okay you can also go here and click on open to understand the data types like there's date column which is date company is a string category ID is an integer cost is an integer okay same way I want to upload the other table which is category so I will again say create table I'll say upload and I want to browse my computer to upload so I'm going to come and say uh category and give it a name category itself right so it's easy to understand Auto detect and create okay again it might take a few seconds and it will finish loading so now I also have the category table so if I say query nice select star I'll be able to see the category table right so as you notice category table as category ID uh the data table also has category this is the common column between the two okay now we have both the data sets ready and the tables ready so let's start U writing our queries and answering questions first question find the unique categories in the data table okay so I'm going to go here so how do you do unique categories I can say distinct category ID right as simple as that and then I just run the query so of course there is 1 2 3 4 5 6 7 8 9 in the data table okay so I'm going to copy the query and I'm going to save it here okay that's the query so next one show the purchase which had the highest cost okay so let me go back to this table and select everything so the purchase which had the highest cost so basically we want to find the maximum right so I can simply say maximum of cost right this is a very simple formula to get started these are more like warmup questions so we get 630 right so that is the answer so I'm just going to copy this and come here and paste the query okay write a query to show only first 20 rows of data so what is the logic we need to use so if you say select everything you'll obviously get all the rows right so if you have to select only the first 20 rows of data what can we do we can simply write U the statement called limit okay so you can say limit 20 uh when you write that it's going to show only 20 rows as you see here now we are only able to see 20 rows okay so I'm going to save this query as well so these are all pretty quick um yeah like if it's multiple lines it's coming here so maybe I'll remove it from here and yeah I can paste it here okay so this is question uh number three okay maybe I'll just create question numbers okay so 1 2 3 and so on then you know you can just do like this so this was question number three right now let's move to the next question show the unique company names where money has been spent so I go back here and I say select everything so unique company names where money has been spent so I can simply say distin company right it's very similar to one of the previous questions we just solved so so you see you see the company names like there are like a lot like close to 21 company names these are the unique names where money has been spent okay so I'm going to come back here and I'm going to say question four and paste my query okay let me go back to the questions next question how many unique days has money been spent in each month so in each month how many unique days right so for that first we need to also find the month so how can we do this question so let me say select everything from the table right so now I have a lot of days like Jan Feb March April and so on uh 2023 there I think even May and June so what can we do for month we can try to use a formula called extract of month from date okay so if I run this query let's see what we get we're able to get the months right 1 2 3 4 5 6 the question here is Unit t money has been spent in each month okay so I can select the month and unique days what can we do for Unique days you can do a count of distinct date right um and then you can do that and then uh Group by this uh extract of month from date itself right so that will give for each month the unique number of days let us now run the query right so as you notice in uh one month one which is January 13 unique days some kind of purchase was done in month through February it was 18 and so on okay so the highest seems to be in March when there was something spent on 21 unique days right that's why we are doing count of distinct date so this is going to be question number five so I'm going to paste the query okay let's move to question number six for the above question do the same just show it in descending order right so what is the difference here the same thing I want to show in descending order of this count distinct date so I can simply say order by count of distinct date and then say descending Okay so now we will see the month of March which are the highest number of unique days on top right now this is in descending order so I'm going to copy this and uh this is going to be question number six right almost same we are just also doing some kind of sorting okay that's question number six and anyways I'll put this in our description the solution also so you can use it later let's move to the next question show only data of category ID 3A 4 okay this is question number seven so again I'm going to just delete all this and I'm going to say select star okay uh category ID 3 comma 4 only that so what we can do it's a very simple thing so you can say where category ID in 3A 4 right you need to use the inst statement so this will only show all the data all the expenses of these three Cate I mean these two categories three and four as you see right if you see a lot of four uh Category 3 is very minimal I think just once so that's the answer okay this is question number 7 so I'm going to paste the query here okay let's move to the next question question number eight what is the highest category ID of expense in March right so we also want to filter for the month year let's go here highest category ID of expense in March okay so first of all what we can do we can say where extract of month from date is equal to three okay because we want for March category ID with the highest expense so what we can do we can write category ID can do the sum of cost right the total cost and then we want to group by category ID right and not only that they want the highest right so I can also do order by sum of cost descending right very similar to the previous question so what I'm doing here is I'm just filtering for month number three which is March for each category ID the total cost and then grouping by category ID obviously and then also ordering by sum of cost descending so that we can see the highest on top okay so now let me run this query and we can see category ID 1 had the highest expense it was 630 we don't know what this is we'll see it later but category id1 had 630 EUR worth expenses so I'm going to copy this query so this is question number eight okay so we're done with question eight let's move to the next question question n which store I think by store they mean the company had the highest expense in May okay so now it's May so I'm just going to change this uh some of cost is the same so when they mean store it means company so I'm going to select company and and then Group by company right and order by sum of cost descending because I want to see the highest and this is for the month of May so let me run this I notice okay Prima again right like this is the rent that I spend usually every month so Prima has the highest the next one is re which is a kind of Supermarket okay so this is how you can do this question month number five me uh which company or store had the highest expense so I'm going to copy this again this is question number n right so we'll keep moving next is question number 10 uh question number 10 which category had the lowest total number in February right lowest total number I think they mean lowest total cost for February which category okay so now there is a small twist so here right in the data table if you noce I say select everything just going to close this and say start so if you notice here I have only category ID I don't have the name of the category category comes from this table right so if I click on this table there is category ID and category right so we can try to join on category ID between the two tables uh and we need to find for uh February okay so what can we do here so I will take from this table data table I will call it as a and I want to join this with basically um the other table so the other table name is also the same almost so I can copy like this and instead of data the table's name is category right I'm going to substitute it like that and say as B right so we going to try and do a join and what is the common connection both have category ID right so I'm going to say a do category ID equal to P do category ID right and now from the second table I can select the category and from the first table I can select the total cost okay I can do this and then I group by B do category and what else uh for f February right so I need to also do One V condition so where extract of month from date right that filter is equal to two right two means February so let's run this and see It'll be again rent only rent is highest usually but then next one we see it is grocery right 276 which makes sense to rent grossery is usually my highest expense so some restaurant and other things we can see as well okay so this is how you can join on a common column put a filter and also Group by to see the cost right all right so I'm going to just copy this this is question number 10 right so I'm going to paste it here and let's continue question number 11 show the data only where shop name I guess this means company name contains the letter W okay so this is just one table again so I will say select everything from this table shop name right so we where we can say company like percentage W percentage so this means that using the like we can find whichever contain the letter of the world W so you have for instance re right majorly and WW Worth right capital W it starts with that letter so these are the shops right so I'm going to copy this and paste it here this is question number 11 moving on to question number 12 find a way to get the category based on category ID this is what I showed you just a while back so let us say from this table I select everything I'll say a. star I will call it as a how can we join with the other table can simply do a join and yeah just copy this table name and then just replace the last part instead of data it is category table so I can do that as B and then you can say on a. category ID equal to b. category ID right and I can say b. Star as well right so I'm joining both the tables let me see whatever is possible so now I can see okay company Prima category ID 1 second table also has a category ID so since it's a duplicate column name it's giving underscore one and what is the actual name of category so one is rent two is Crosser and so on right so we'll if I move forward uh I see six is ticket seven is cosmetics and so on right this is how you can join both the tables I will just copy this okay this is question number 12 okay let's move to next question question number 13 is there any category ID not present in the data table okay how can we do this so first of all let us sect this table right category table the original table and let's see what is there so over here I see 1 2 3 4 5 6 7 8 9 10 right so 10 unique category IDs but if I were to see the original table the other one data table and say from that table distinct category ID so I see 1 2 3 4 5 6 7 8 9 right so that means category ID 10 is actually missing from data table but how can we show this right is there a way to show this by comparing the two tables right so what we can do here so we can select disting category ID this is obviously an option and then manually compare but other than that what we can do we can make our category table like primary like this as a this time okay and then I'm going to join this with data table as B okay so for so good on a. category ID equal to b. category ID right this is very simple so again I can select everything from both tables for sake of Simplicity and then here you have to write a join but I'm going to do a left join right so what left join will do is it will show all the category IDs from the category table if there's a match in data table it will show the match otherwise it will show null Okay so do like this let's see what happens we get 115 rows okay so you can scroll down can even make this 200 so I see all the results in one page if you notice I will see everything right all the data but at the bottom right category Ed 10 is not there in the data table so you get everything is null right so how can we now spot only the ones which are null you can say where uh B do let's say d date is null right any column which is null you can just pick that because when there is a match obviously there'll be a date and data table then we see this right then we see this category ID this is the one that is there in the category table but it is not there in the data table right so there is no not been any expense related to this category others so I'm going to copy this this is I think question number 13 okay again a simple use of left join now let's move to question number 14 show categories with expense more than 150 for the month of April right so again uh let us delete this so this time I I will make our data table as primary as usual I will make our category table as secondary okay and I just want to do a normal join right wherever there are matches so that is all fine on will still remain the same now from the first table again I want to know the category right and what do we want uh expenses so I'll say uh category actually comes from the second table right B table so I'll do B do category and from the first table I want to do cost so I will say sum of a do cost is there any other filter month of April right note that down so where extract of month from date right so April is the fourth month so we can say is equal to 4 then Group by B do category right this is Step number one now let us see what we get so we get a lot of expense okay and now they want to show only those with more than 150 okay so what can we do here we can simply say having right on an aggregated calculated column we can put a filter like using having having sum of a do cost greater than 15 now we'll see only those categories it's going to be rent and grossery the rest are below 150 right nice use of the having Clause this is question number 14 okay so let us move to question number 15 they're asking any patterns in ticket expenses over time right so what do they mean let us uh combine both these tables together right and I'm going to say a. star comma B Star right so let's see what we get so there is a category um let's see if there's a category like ticket so I'll say where category equal to ticket okay not sure if there is something like that but let's see okay so there is no data Maybe it's capital T let's try like that and you see DB is do bond company where I spend for tickets yes there are ticket columns they're asking any patterns Okay so so maybe what we can do now we can try and do it like per month right so I'll say as usual uh maybe I'll extract the month right so I'll say extract of month from date which we usually do and uh patterns so I'll try to put some of cost itself right and here it should be b. category equal to ticket and uh now group by basically this extract of month from date so I'm going to copy that I'm going to paste it here okay if you notice here just by looking at it there's a lot of 33s but then there's a 98 as well so let's see what has happened okay so January was 33 Fe Fe was 33 uh for some reason in March there's been a lot of expenses it's become 99 April is 66 then from May B basically this uh Dand ticket started so me and my wife each took for 49 so it became standardized okay so for some reason March there have been lot of trips so it has increased right so that is the trend in terms of tickets so I'm going to copy this this is question number 15 okay I'm saving all the queries so you'll have access next which restaurant has received the maximum orders based on days right right so that means like which restaurant has received the orders on the unique number of days right that's what it means actually so restaurant obviously is a category so I'll put restaurant okay and here the company right company is where the name of the restaurant or the name of the shop is there so I will say company and the question is maximum orders based on number of of days so we want to count the unique days which we kind of did little bit earlier so count of distinct date right for the restaurant category so first let's run that and see so so many restaurants are there right sound is there Kebab shop is there so Panda seems to be the highest we could also simply say order by count of distinct dat descending right so pandas is a restaurant where we buy MOS that has been the most prominent in the six months being there nine times right that's the highest so another interesting use case of count distinct order by alongside group bu okay so this was question number 16 so I'm going to paste the query let's move further 17th question calculate average spend per day for restaurants okay average spend per day that means you have to find the total cost and divide it by the number of unique days you been to the restaurant right this is one way of doing it so the cost is what sum of cost divided by count of unique days right this will kind of you could also do count of date uh this is also another option right assume that maybe on the same day you been to two restaurants then this number can change so anyways let us do both the calculations and see what is coming so basically average spend per day for restaurants so I'm going to do with unique days so it shows on average when we go to a restaurant we spend around 15 right based on unique days if I change this to days right let's see what happens yeah slightly lesser 14.5 but still it's 14 to 15 Euro on every visit on average to a restaurant okay so that's what happens so I'm going to save this question number 17 right that's basically that 14 to 15 is the amount we spend on average when we go to a restaurant right some may be lower some may be higher we we are not sure about that but basically that is the overall average which day of week saw the highest spend in me right so we need to know the function for day of week is it there maybe we can also check with chat gbd highest spend for the month of May so remember it's for the month of May so this is question number 18 right which day of week so here we don't even need the category table so I'm going to remove that so I have date right so we have this function called format date and you can say like percentage W so if you're not sure we can go and ask chat GPT as well right so always chat GPT is there to help so Group by week day or day of week in Google big query and find total cost please tell me formula something like that you know you can type something like this should give and it's going to give you a general example it's giving sales date and it's saying format date okay percentage a right that seems to be useful so we will just copy that so as you see Sunday is 1 um Saturday is 7 right so let's go and try that here we have date the question is highest spending me okay so we still need to keep that in mind so I'll say sum of cost okay that is is obviously there and then Group by this so This step is covered but before that it is May so I have to say where extract of month from date is like it's month number five so I have to put five right let's run this and see so as you see we already get the day so we get different ones so it looks like Tuesday is the highest right and this is all categories put together it looks like Tuesday is highest obviously this is 734 that is because maybe on that day I paid the rent right rent itself is 630 that is the reason right that becomes a big number but other than that you see wedness day is also quite high right for the month of May so I'm going to copy this this is question number 18 okay I'm going to leave it here let's move to the next question question number 19 calculate total cost for grocery per month and show month in year and month format right separated by hyphen so total cost for grocery per month so let's go back here and let's do the join again right because we need to identify uh this particular uh category called as grocery so for that we need to join back with the category table so I'm going to again write category that is Step number one and what is the common column on a. category ID so we just going to repeat the same thing again this is done now where Clause we have to put where this B do category should be equal to grocery right it's g with the capital and I think the spelling here is wrong okay and now we want to find total cost per month and show the month in year and month format so for that what we can do like percentage a you also have percentage y percentage M right this will show in year month format total cost okay I think that is pretty much it and I can also do a group by right and what do I want to group by I want to group by this year month so I guess this should be it let's run the question is total cost of grocery per month so for example January is 210 May is 183 Feb is 276 March is 178 April is 174 and so on right June is also pretty less and what else have they asked they just asked to calculate that so I'm just going to copy this right I'm going to put it here as question number 19 okay let's move further question number 20 calculate total spent for shops starting with capital letter r okay I think they want like for example stuff like R so I'm going to just say sum of cost from the original table I don't want to join and uh the column name is company so I'll say where company like R percentage right so that starts with the letter A so just give us the value 859 so if I want to see what are the companies you can also do a group by so you can just do like this and then say Group by company not sure if there is anything else anyways let's see right there's R and Rosman right that's pretty much it so I'm going to just copy this this is simple question number 20 right so we kind of getting closer to the end let's continue 21 how many unique companies exist in the shopping category right so again we have to go back to the join right so maybe I'm going to come here and uh pick this up right I'm going to put it back here so the question goes like this unique companies that exist in the shopping category okay so we can say where B do category right equal to shopping so I will just say select Star right first let's see if there's something like this actually for spelling is right for shopping yeah we have for instance Teddy Amazon and wwor I think that is pretty much it anyway I will say distinct company that will give us the distinct values so Teddy Amazon Worth right only three companies are unique that exist in the uh shopping category okay that was question number I remember 21 okay move to question number 22 what is the spending pattern at re monthwise and any insights okay so we can go back and pick this question up right I'm going to copy this so R and monthwise right so I don't really need the join here I think we just need the original table so I want buy month so I'll put company comma per month total cost and then Group by company as well and uh we can say where company equal to reev right I think this should work so the question again let's see it's question 22 spending pattern at R monthwise okay so R January 128 February 128 right very very standardized March 104 so March and April 145 March has dropped a little bit I think right and then um yeah it's 12 13 it's very very stable pretty much around the same Mark as you see more or less so it's like 120 130 that kind of range right so there's no Trend but March I can see it's 104 that was the month like I made lesser purchases because my wife had gone home that also makes sense it's so another use case of this format date function so this is question number 22 so I'm going to paste okay so we have I think about 12 more question any Trend with respect to eating at dominoes okay so same thing here uh the company name will become if we see the original data right it will become dominoes okay so where just remove this and say dominoes okay any Trends so I'll just see monthwise 1722 it's standardized I think in March I've ordered a lot more I didn't cook much so March it has been a lot 49 otherwise it's 17 14 15 right this is the standard if you order once a month uh so we can also see distinct dates I have Ed in each month as well just to see the patterns so if you notice yeah most months it's one in March alone I ordered three times with dominoes okay that's the pattern um that is question number 23 I'm going to save the query let's move to the next question 24 is there any month where grocery expense has is a bit different or as it changed a little bit right so I think we did query similar to this right so I'm going to copy this so I'm going to run this again so grocery expense yeah as you see it's kind of standardized right January is 210 febr is 276 there picked up and then yeah March and April as you see it's below 200 so like there's been a drop and may is again 180 right so it looks like February had a peak right like February had a lot of grocery purchases and then uh June again dropped June we went for a trip as well we were not there for a few days in Germany so I guess that's why it's dropped to 156 so I can strongly see February has peaked at it's a month where we have purchased a lot of grossery right that was question number 24 so February had a slight jump in terms of grocery expenses then move to 25 show the show only the company with highest Spen in each category for April right so this is probably a question where we might need to use something like Windows functions right only only the company with the highest pin in each category for April okay so I'm going to I probably don't need the category ID I just remove that the join so I we have the original table so I probably need to find the total cost right so what we can do we can do category ID then uh the company so all this is good and and then this is only for specifically the month of April right so I have to say where extract of month from date is equal to four right and then say Group by category ID for comma company so I could just copy this right so I get each month I mean each uh category company and then this right right now what if I want to show only the highest like for example uh Category 2 is grocery in that there is R there is interest store right so what if I want to show only the highest right same way in four which looks like a restaurant there is Panda jaur Domino's kebab and S so only the highest right s is the highest spending how can I pick and show that so this is interesting so I'll say sum of cost as total cost right this is Step number one now I can put this whole thing into a CT right so with Clause I can say with let us say uh data new or something as right so I can do step number one like this and now from this data I can select company comma category ID and then I can do a rank okay so I can say rank Partition by category ID so in each category ID and also do a order by that total cost column descending right to show the one on top and say as ranking right and then I say from final new right that is the name of the temporary class or table I created with the width so now I can run this table final new must be qualified with the data set right so there is some error here it's not final new it's data new right put the wrong name now it should work okay so now I see okay in category4 sound is one in category labar that is one in Amazon and Teddy are category 8 which is shopping Amazon is one right now I want to show only the ones that are one to do that what we can do in big query we have a formula called qualify you can say qualify ranking equal to one right this is like a V Clause but meant for window functions so if we write that then we will see only the ones that are ranked one in each category right so rev is coming as the highest in grocery Rosman comes in cosmetics s in restaurant Amazon in shopping and I think DB is the only thing in tickets so we are getting all that right so this is a nice use case of the with Clause normal Group by and also learning to use the window function like Rank and filtering rank or window function we can use qualify right so great question this one question number 25 I'm going to save okay question 26 let's move on we have I think few more questions percentage change change in total cost for each month and find the month with the highest percentage change so anytime you have percentage change year on year it's time to use a window function like lag okay so for each month percentage change in cost they're asking so I'm going to start with select and uh we need month right so we can write uh format date function and say percentage y percentage M right that is Step number one and we want to uh find the total cost right so I can say sum of cost and then copy this and put it in the group I okay so there is no filter here so I will remove where and I'm just going to run this okay I think there are two commas I will remove the one of them format date it should be for the date function right I mean date column so I forgot to put that over here as well right so sometimes be careful you might see errors like this silly mistakes only right so I'm getting total cost all months okay so this is great so now what I can do I can put this in a with final as in a CTE right that is the first step now I have to calculate percentage change so now I can say select let us say this format date whatever is called as year month I give it an alas name so I can say year month total cost and also to see the previous value I can say lag of this column lag of total cost then over here there is just month and year right so we don't really need a partition so we can say order by this year month column right ascending order and I can call this as previous month cost right and say from final let's see what we get so we see each month so for example uh January 1062 is total cost previous month is not there it's null February total cost 1166 previous month value was 1062 we get that and you know here it's not in order but for example March 1071 previous month cost is February that's 1166 and we are getting that here right so so this is like we getting them side by side how can we now calculate percentage change so for that it just becomes little more complicated so I will put this whole thing into another CTE so with I will say final 2 as or something like that okay close the brackets just drag this down and now from this final to I can select year month then I want to do this percentage difference so I will trite total cost minus previous month cost divided by previous month cost right from final two that's the second CT and then I want to order by year month right and if I want to do percentage I can also put this whole thing and multiply it by 100 right let's see what we get okay so we don't really see the values so if I want to also see the values over here I can put those columns as well right so total cost previous month cost as well and run this just for you to have that appeal so from for January there's nothing makes sense February you see um it's basically a 99.7% increase right from January so from 1062 it became 1166 then from Feb to March it dropped again so minus 8% decline from here to April again it declined by about 2% then from here it increased by about 7% then from 1125 it dropped to 1084 so 3.7% drop so the highest has been from Jan to Feb where we saw 99.79% increase okay this is how you can use multiple CTE and also use lag to do this percentage change okay interesting and slightly complicated question was question number 26 I'm going to paste the query here let's move to question 27 okay do the same as that question but only for restaurant category okay so if if you have to do only for restaurant category the query is going to remain pretty much the same and we know we have to just put a filter on the restaurant category right so if I go here and open this table in a new tab I see for example restaurant is category ID 4 so I can go back to our query and over here I simply put where categ category ID equal to four right so that will filter the total cost but only for restaurant right nothing else changes so it's running let's see what we get now we see some start differences for example from FIB to March the jump is significant 50% jump so I told you march I didn't cook much I used to order outside that kind of makes sense right and then same way then it drops back again in April and then again drops and then from uh May to June again there's a jump right so 73% jump so it's like a lot of trends like going up coming down but this is what it is for this restaurant category q27 okay let's move to question 28 we're nearing the end find the date with highest number of unique categories where money was spent okay this is a fairly simple question so I'm going to remove everything else okay delete all that is there find the date with the highest number of unique categories okay so I say select date and then count of distinct category ID right on a particular date what were the unique categories and then we want to find which was the highest date in this so I'll say Group by date order by discount distinct uh category ID and say I put double remove that and see descending as simple as that let's see if there's a particular date okay so I think 7th June there have been three different categories where there's been some kind of purchase money has been spent right that is the day rest of it is 2 or one so 7th June is that date so I'm going to copy this this is question number 28 simple question 29 use Cas statement to category is response as Indian versus nonindian based on name and show total cost for June right so for June we need to use some case statement logic let's go back here right so first of all I will remove all this and I will say where extract of month from date equal to 6 okay step number one let's select everything and then for restaurant so we also need to format it by restaurant category so if I go here for example jur is restaurant so category ID should be four right so I also put that as a filter equal to four so let's see what what is been the restaurant expenses so you see lot right so in this we have to tactically separate Indian non Indian so the only Indian is jpur the rest are all non Indian right so I will simply say case when company equal to jur pretty simple then Indian else non Indian okay end as restaurant type you can give it a name then you sum of cost that's it right so I'm splitting jur versus the other ones the others are non Indian and now we can say Group by this uh restaurant type write the column that I created for month of June for restaurant category Indian versus nonindian nonindian 50 Indian 21 right that is the split up Indian only jur non Indian had Panda and other restaurants as question number I think this is 29 okay so we getting to the end 30 ratio of total spend for restaurants versus grocery for April okay so April so first thing I'll do is I'll put this is four um can remove this so let us go back to the category table and uh so restaurant is four a groceries is two right category ID so let's note that down so we want to do the uh total cost only right so I'll do this is a use case of a sum sum if so I can say ratio of uh restaurant versus grocery Right restaurant is four grocery is two that is the ID so sum of if category ID equal to 4 right if it is four then do the cost otherwise zero this will show the total for the restaurant and I can simply divide this by sum of if category ID equal to two whenever it is category id2 which is grocery please sum the cost otherwise zero so if I divide both these and I'm putting equal to four in the filter because it is the month of April right let us see what we get so we get 36 right what does that mean so if I put a comma and see the values right what is the restaurant spin what is the category spin uh I mean for grocery so restaurant spend is 63 grocery is 174 the ratio is about 36 right so you can put divided by and that will give you the answer so that is question number 30 cool moving on 31 average spend per month at interest store interest store looks like some grocery store so I can come back here can say where company equal to let's see if there is something called interest store right so I'm going to just say star yeah interest store is there so average spend per month okay so what can we do we can say company comma let's put average cost I think it's AVG but we also want to do per month so I'm going to put per format I mean we can even put just the month so you can say extract of month from date we want and group by we can say these two right so instead of writing company and extra extract of month from date we can also write Group by one comma two group by the first and second column this is also possible then we notice okay it's usually 12 15 7 this is average of each purchase right so we can do that or to make it even more correct we can say sum of cost divided by count of distinct date so like cost per each unique date that we visit if I do something like this then you see it's around that right March was a bit cheap we didn't buy much but the rest of the months is around 12 to 15 right so this is basically calculating total cost divided by total number of days we have been this will give you average cost for that month we are doing the same for all the months that was question 31 next one which company in shopping category had the highest total cost I think we did something like this already uh shopping category is what category ID is8 so I can say where category ID is 8 that's a easy thing to do which company had the highest cost right so I can simply say company comma sum of cost again I can Group by one group by one means Group by the First Column which is company so I can run this I think there only two or three companies so we can see Amazon had the highest cost okay you can also do an order by if you want question number 32 okay and then use Union Clause to show total cost for Kebab shop and also Panda using two different queries uh so let us uh see the distinct names of these shops total cost using Union so that is keop shop K and Sr capital and what else was there Panda okay so we can easily do this we can say company comma sum of cost from table where company equal to first let me put Kebob shop um Group by company this is done and then I can use Union all and simply copy the same query right only difference is here I will substitute it by Panda they want us to write two different queries to do this give us the total cost for Kebab shop and Panda Kebab shop 34 Panda 66 right simple use of Union all question number 33 so we are almost there and then finally last question is there any fully duplicate value in the data right that means every row like every column should be the same is there any kind of duplicate data like that this is a bit of a tricky question so I can say select star from and do this right I will run so for this we need to do a check of all the columns if there is any kind of duplicate okay so what we can do I will select everything and then I will say row number and then I can say over and here we need to Partition by every single column so by date company category ID and cost and say row number okay alas name let's try to run this query right and we see if I select all the 200 rows I see row number is only one right that kind of means means there's no duplicate what does this mean Suppose there was row number two somewhere that means that particular set of data is repeating multiple times right so if row number is more than one that means it is potentially duplicate data right so we don't have that so to check that we can put this whole thing in a CTE so I will say which CTE as um and then say to check for duplicates what we will do is we'll say select star from CT where row number is greater than one right if it shows some value then that is a duplicate here it is no data that means all our values are unique unique in each column right that means there's no two rows where all the values for all columns are the same right this is also very challenging and commonly asked question to find duplicates so you can use this method so I'm going to copy that question 34 okay so I hope you enjoyed the video it was a long video you can practice all these question we have tested a lot of Concepts I'm going to put the solutions all the data in our description stay tuned for more videos I'll see you again in another video next week till then take care bye now that we have learned using Excel and also writing SQL queries you need to understand many of times in your data analyst job you'll be dealing with business stakeholders they might not have the relevant technical skills in this case it becomes important to tell your story and drive your analysis through Visual medium so in this coming project we are going to use Google looker Studio to analyze my own social media data from LinkedIn YouTube and Instagram and build basic graphs charts and understand how you can also join data in lucer studio and drive simple insights so here we have some social media data this is my actual social media data I post across multiple platforms Instagram YouTube and also LinkedIn I post regularly on all three platforms as you may all know so I've just taken the month of the post the year of the post and collected the actual data right views likes and comments for each of these posts right and what was the title what was the idea of each of these post then there's a column called category ID what does this event mean there is 1 2 3 and so on so for this sake I have a second table okay so it says category ID and the post category right for example category ID one is tips two is projects five is like some interview four is more of fun post and so on right three stands for information now what we're going to try to do bring these two data into looker Studio this used to be called Google data Studio before and try to build some simple graphs simple analysis and drive insights okay what we are going to do is the social media data we going to upload it to Big query if you want to understand how exactly to do it do check out my big query video which I posted a couple of weeks back back where I've shown in to end how to upload your data okay step number one we need to download this as a CSV file okay the social media data I've already downloaded it so I'm going to go to big query okay I already have a project I'm going to create a data set okay I'm going to say create data set let's say social right I can give it a name and I can create the data set okay that's it step number one is done so I have a data set here now I can click and go and say create table I will upload it from uh something that I already downloaded so I can simply crawl down and say social media sheet one right I have downloaded this data I can call it social unor media okay this is simple step number one schema autod detect and create table okay it will take a few seconds to load let's wait for that and once it's done we have the table okay so if I go to query and I say select everything let me run the data and see and now I get the data itself right as you see uh month year views likes comments everything is there okay so we have now connected this data set to bigquery the second data set will stay as a Google sheet now we going to try to combine both within Lucas Studio let's see how to do it so for that you go to Lucas studio. google.com this used to be called uh data Studio Google data Studio before so I'm going to type that and this is how you land right you land in a homepage something like this so I'm going to Simply say blank report okay when you click on blank report basically you'll have multiple ways to connect right you might connect it to your Google analytics data you might connect it to your big query you might connect it to your local computer right upload some file you might also connect it to a Google sheet right and there are so many other options to connect to other social media platform so today we are going to start with trying to connect it to bigquery okay because I have that table in bigquery right so I go here and I know this is my project in this social is the data set I created and I click on social media okay so I can connect to the table inside big query like this so I can simply say add right it will take some time to load and then simply say add to report okay step number one as you see we we have all the values right so if I pull for example the total views and uh see it across three platforms so Instagram had 750 7 lakh right like 7571 0 right basically 757,50 7,100 right depending on the notation you use so we have the data like this okay this is a nice and easy step number one now let us go and see some questions right so step number one is they are saying import data from bigquery we have already done that right uh now we will try to connect the Google sheet right with this before that let's see this one right they say write a case statement to categorize fun and tips content as one category other as a separate category right so if I go here I see fun is ID number four and tips is ID number one right so whenever it's tips or fun I want to put it as one category how can we do this in looker studio so first of all before that I'll come and give this a name social media report okay I can click social media report give it a name like this then I can go to Resource manage added data sources right and click on edit right now I can add a new field okay calculated field um and then what else can I do I can say for example category new right I can give it any name I want so the idea here is so I can use a case statement very similar to SQL so case when category ID right that is the column right when this is one or four right that's what we said then we can call it uh let's say fun tips right otherwise we can call it other right so we're splitting like this and we can say end okay in SQL we'll say end as here we can simply say end right as you see the formula is correct I can simply go and save right and I can click on done right so we have now created a new column called category new uh which is appearing here right so if you want to see category new for instance um as you see most of it is in other category right so uh fun and tips I have not created as much content so the views is only half right this is just giving us a general idea but you now learned how to create a case statement in Luca Studio as you see it was very very similar to how we do it in SQL okay so first step is done now let us come back to the uh previous question which is like also connect to the Google sheet data and see how can we merge them or combine them together okay so to do this first of all I'm going to say go to Resource manage added data source and I'm going to add a new data source right and this time it's going to come from Google Sheets right and what is it basically this category ID post right that sheet so I'm going to just select that and that's it right you can simply go and add right this way now we are connecting it to a second data source as well right so we have now social media as well as this uh category ID post Google sheet data okay now we have an option to blend or merge or combine the data so now let us try and uh do that okay so I'm going to say blend data okay now what do I want to blend so I want to join social media table from here I want everything right so I will select category ID category new is already there I want to see the month of of course the platform the year and the title as well right I'm just going to pull all of them into dimensions and in metrics I want to see the views what else I want to see the likes I want to see the comments I guess that's pretty much it right from social media table I'm pulling all the things for this blending or smudging process join with another table from this one category ID post I want the category ID obviously and I also want the post category right that gives us the name now that I have pulled both right I pulled everything from here and both the columns from the other table uh we can configure the join we can say select inner join right as you see category ID table is common in both so it will join based on that similar to the SQL principles so I'm simply going to save right and uh it will be named as Blended data one name doesn't matter so I'm going to Simply Save okay so as you see Blended data come now uh so now I have category ID and category new as well right apart from that the name of the post category right so if I pull post category here as you see in other itself we have information we have projects we also have interview in fun tips we have fun and tips right now they showing separately so we have been able to blend or merge the data similar to join in SQL right so we have done this this is cool we also have all the metrics here and the category ID right if I I want to see the category ID as well I can pull that in so for instance uh information is category ID 3 tips is category ID 1 and so on right now we have all the information set up we have also done the merging right now let us go back to the questions so case statement is done so they're asking to observe Trends in platforms and also categories right now let us do step by step so we will make sure we don't overpopulate too many graphs too many tables in one sheet so this is uh the first page right so over here let me do something very very simple so I'm going to just remove this right I'm going to cut this out right and I'm going to click on Blended data and let us say I want to insert a simple scorecard scorecard will have simple values like this right so first of all what do I want to see here let us say I want to see the total likes right I'll drag that in okay so the total likes that I received right across all these platforms is 25,338 so I can copy and paste so I can get a duplicate like this as well and now let me just put the total views okay so total views is uh more than a million right as you see across all the platforms put together and then I can again just copy and paste right so I can uh replicate as well and this time let us say I want to put total comments okay honestly we don't get many comments so total comments is less than 500 so we have these three right now this is like just simple top level metrix that we are seeing right uh before that if you want you can also go and add a text box on top right I can place it wherever I want maybe I'll just bring this down a little bit I think it just got stuck so let me just drag this down a bit also drag this down little bit and I can say insert text right I can place a text box here right I can say important overall information right I can give whatever name I want right can play around with the formatting and stuff right so as you see you can make it bold right by selecting the text we can make it bold uh if you want you can underline it and so on right you can play around with all that just going to drag this make it a little bigger right let's make the size even bigger maybe I can select the whole thing and make it 20px okay so it became a little bit bigger uh if we want to give it a color for the background or filling also we can do stuff like that okay if I want some background can also do like this right so um yeah going to just remove this other one so this is like important overall information so I have likes I have views and I also have comments okay you can share it with whatever color you want but this is just giving simple important overall information okay now let's say add new page okay so I'm creating a new page I've created a new page here let us say I want to add something important right so I can simply say table okay I'm going to insert a table let's say I want to see by platform right so I want to bring platform to Dimensions the total views the total likes and total comments so I'm going to drag uh total views here total likes as well and total comments okay the three main metrics for all the platforms this is across the complete time period okay so as you notice Instagram is on top right in terms of views YouTube views overall is not that much same Trend with the likes but if you see YouTube is getting more comments than Instagram so Instagram doesn't get as many comments right although the views is high likes is side can we show this visually is it possible so yes we can try to do it let's say we want to show different colors for views I can go to style right and I can scroll down now we have three metrics right views likes and comments so for metric one let us say I want to show something different can click heat map right and I say heat map you see Instagram is the highest it will show darker blue color right LinkedIn is slightly lighter blue the YouTube with less views is very much very light blue right for instance for the second metric for lights I can show like a bar right it shows Instagram has more likes and if I click on show number then it will also show the values right you can depi like a bar same way for comments right you can come to metric 3 and select whatever you want right I can say again heat map it will show a different color right you can play around with the color but this shows that LinkedIn received much more comments than the other two right so simple Trend we can see so it looks like Instagram performed well on the views and the likes but in terms of comments LinkedIn is the best right so this is what we get just at overall Picture level now if you want you can also add a filter right so you can say insert a drop down list and over here for example I can put month as a filter right I can bring that here now I can see per month right let's say I want to see only for no can select no and see the trend right so even there you see Instagram is dominating in views YouTube had a lot of comments right so I can select multiple months or just select one month for example December or I could select everything right so I could play around and see the overall trend right so I put month as a filter right so this uh is indicating me that yes Instagram is doing well in views and likes whereas LinkedIn is doing well in comments right this is a simple thing we can play around this is in terms of the platform right so this information is basically about platform now let us say I go to page and click on current page settings so we get something like this so we can go to style and you know you want to change the size and all you can play around as well right I can go to view mode right so if I go to view mode for example what will I get I can play around right your stakeholder can go select a particular month and they will see only that right for example there's no August data here for LinkedIn I guess in this so only Instagram and YouTube are showing right so I can select everything if I want if I come back to edit mode I get the access to edit the report right so this is by platform now let us move to something further let us say I add another new page right this time let us say I want to add some more calculations right so what I can do this time let me again add a table okay so this time let's say I want to see by category right so I have post category so I can select that right by category how things are going right so I I don't need the month so I can just again pull likes then comments and views right same so I can just reorder them so that uh first is views then it's likes and then it's comments right so now I see the values as you see across these five I can apply the same logic right I can simply come to uh the style section and for the first metrics let's say I want to show heat map and second metric also I want to show heat map okay I can select heat map as simply that and then third metric let's say I again select heat map okay so going to show different colors but now as you see here in terms of post category it looks like informative posts are doing really well overall right uh tips is also doing reasonably well the others there's not a lot of use maybe there's not a lot of content this could also be the case same way information and tips are getting a lot of likes as well and very good amount of comments right in fact projects and interview did not get as many comments maybe it's because number of project videos are also lesser right this is also something you need to look into but at least you can see what kind of posts getting views likes interactions and stuff like that on top of this right I can drag this down a little bit and I can say insert same way right I can insert a filter and what filter can I put in here right I can put in for instance platform itself right and see in each platform is there a different Trend right so let us say I want to see only Instagram in Instagram what is happening as you see I not really uh posted all types of content here right that's just information tips projects and fun there's no interview post here and you can see the trend right again information is doing pretty well tips is doing well as well right now if I go to LinkedIn let's see how it's different here there's little bit about projects but again it's predominantly information and tips and they are doing pretty well as well right and finally going to YouTube YouTube there's also projects but again information and tips are predominantly dominating right in terms of comments likes and views right so this way you can put a filter for a platform and see in each platform which post category is doing well in terms of overall numbers right now let me go and add another uh page so I'm going to Simply say page and add a new page okay now what I want to actually do I want to this time insert a table again right but this time the purpose is going to be little bit different right so what do I want to do here instead of just pulling likes comments views just like that I want to also do some calculation for example what is the ratio of likes to the Views what is the ratio of comments to the likes right or what is the ratio of comments to the overall views right if we get some kind of Trends here so for this what can we do let's say I want to see it by platform I can drag platform to Dimensions right that's step number one now I can do some calculations right so so I already have uh metric here if I want I can add a new metric okay how do we do that you can say add metric and say add field okay now let us say the first one I want to do is the ratio of likes to the Views I can type it like that I can come here and write a formula right I can say sum of likes right total likes divided by the total views right you get a formula like this and let's say I want it decimal with two percentage points can select like this and say apply okay so this is how I get the likes to views ratio right I can make this a little bit smaller if I want and drag this a little bigger so likes to views I'm getting right this is one calculation I doing already I can also add another calculation if I want right I can simply go here and I can say add field this time I want to do comments to likes right this is another interesting ratio let me again say percentage but two decimal points so this time it's going to be uh sum of commments right divid by the total number of likes right that's it I'm going to apply this right so this is a second calculation I'm doing this will be a very small number as you see uh comments to likes right these are all below 1 percentage but still it's fine to show them right there's likes to views and there's also comments to likes right if you we want we can add a third uh trick as well I'm going to go here and add this so this is nothing but comments I'm getting to the overall views right this might be a very minuscule number but anyway let me just add it right I'm going to say percentage two let's say if this calculation even shows some insight so I'm going to say some of commments but this time I'm going to divid by some of use right it's a very minuscule very small number that we going to get as you see 01 0 right doesn't really make a lot of sense uh so for instance maybe I can just remove it right I was just testing it but it's not really making much sense very very small numbers so I'm just going to keep the other two okay I'm going to remove comments to use now with this what else can we do we could for example bring in uh post category right can bring in post category so we see values across the board right so and I can drag this to see everything at one place and now we can also do an execute our heat map thing right to change the colors and stuff like that so for example I could come here and for the first metric I want to see heat map right so we get a distribution and then for the second metric Also let's say I want to see eat map right you can play around so now what we notice right the dark blue ones right for example YouTube tips is having uh very solid likes use ratio right it's not very high but it's 0.05% same with Instagram tips as well right looks like tips is doing fine whereas LinkedIn tips is not working right it's 0.01% same way YouTube information is having 0.05 YouTube fund content is also having 0.04 right and if you notice here generally uh in LinkedIn right the likes to view ratio is very low right whether it's tips projects or information so that is one thing we are observing then if you go to Instagram if there is an information or projects content that is also not doing that well so in Instagram what is primarily doing well is uh to give tips right so it looks like executing tips gives a good likes to views ratio right so out of people who view the video good number of people click on the like button and in YouTube generally tips projects and information all are working even fun videos are working right even interview is doing quite well 0.03% is not bad so it looks like the likes to views ratio is pretty good in YouTube right as a starting point now looking at the other metric which was basically the one we calculated that is comments to likes you see um whenever there's a project video compared to likes there's a lot of comments right and same with the interview right when I interviewed someone about their data analyst journey and so on uh these two are working and information video is also working fine in terms of comments to likes13 but you see Instagram and all this is nonexistent right what is the reason like overall all comments only is very low in Instagram right if I go back to our first page we see it's only 490 not only that if you see here right you see the comments are very very low in Instagram right compared to the Views and the likes that is the reason why you see um this value is very very low for Instagram at least LinkedIn is fine 05% 04 but it's not still high right YouTube is still doing well even in comments to likes right so that is an interesting Trend to note so if I come back to this page you notice that YouTube has lower views and likes lower comments as well but the likes to views ratios and the comments to likes ratios are good right so although overall numbers are not that high but still there is reasonably good engagement compared to the Views happening in YouTube and if we want to pick up specific things it looks like uh information videos are doing well in terms of likes and when I post a project video or an interview video the comments I get compared to the likes is really solid right so this is some idea I can take to further develop my content in the future right very very simple insights so that is there now if I want to uh go and add a new page I can again say page and insert another page this time let's say I want to add some simple uh charts so for example I could select column chart right column chart I could for example uh put uh post category right as a simple example and see okay what is the trend in terms of likes and also in terms of use okay so we could do simple things like this right so I make it bigger as you see fun and interview is very small numbers right they kind of nonexistent and one other thing if you notice is there's already two sets of graphs right because views is in millions right that is the light blue color and this dark blue is the lik one so as you notice information has like lot of likes and then tips and these two also get the maximum number views right fun and interview there were not many videos I guess so they're kind of nonexistent so I can move this down right as a simple graph and uh I can again insert a drop down filter right pretty simple here I can bring in platform as the filter so I can select by platform and see for example only LinkedIn what are the values and so on LinkedIn there's only three types of content I put and yeah you can play around right so it's good to give interactive filters now I'm selecting all the platforms can select by platform and see any sort of insight simple bar graph with multiple metrics that can indicate some kind of trend right so this is how you can create a bar graph on top of this you can also add some insights right like if you notice information and tips is working you can add this as a bullet point as well right so this way you can play around little bit with uh you know your filters as well right so let's say I have this one uh graph uh can I can I do a second graph yes we can right so there are many other options as you see you could like I mean we already saw what's the Heap map uh I also showed you what is a scorecard so you could also create a pie chart for example right simple pie chart uh would be to understand in terms of platforms right which has the highest share in terms of views right so I can say insert pie chart right I can place a second chart here very very simple and in this pie chart what I'm going to do I want to see by platform the trend for the overall views okay so I'm pting views in here and uh here I want platform right I don't want the post category let me just uh drag platform here now you see right so Instagram has the line share in terms of the total views almost 60% then LinkedIn YouTube is a minus cule just 1.5% in terms of views right that's hardly 20K views right this is a simple Trend right so on top of this you can also insert a simple heading if you want right so you can say insert can come here you can add a text if you want right simple text box right and you can move this around and say for example view share by platform right of course you can do the formatting and all right I'm just uh building out the graphs and the calculations right you can of course format it the way you want uh you know you can select the text make it bigger as I have shown you in the beginning as well right so this is all there right you can give like a color as well you can come here select a random color right let's say select this one so you can share it and so on right you can give headings for each of these right you can play around with all this right so this is also possible so keep this in mind right on top of that what else can we do so if I go here like we have already done this color coding for most of it let's see what other features are possible right so if I come back here into this I have views likes already right if I come back into this graph let us say I want to add another metric let's say I just want to see the overall views also as a third metric I will just drag that in right so this way I can see the sum of views as a extra column here right for this column we can also do a few things right so if you go to St right there's a way to add conditional formatting similar to excel right you can play around with this so I can say for example add right let's say I want to add a color and what is the condition let's say if views is um greater than let's say 5,000 I want to give it a specific color right for the entire row I'm going to come and select the color let's say I'm going to select the color yellow and save right I did a simple conditional formatting so wherever as you see it views is more than 5,000 it will share the whole thing in yellow right so this is also something you can play around and do right if you want you can do it you can go back and also uh go to the rule and like simply delete it right this is just to play around this is also possible apart from that as you notice if I come to another uh chart like for example here I can also go to um the setup right there's also a way to do sorting right you can sort by descending and ascending you can play around you can also add a filter to the table right I'm just going to click and what can you do for example you can say include or exclude right and over here you can like select what kind of filter you want to you know impose right is it for the platform title so title for example only for certain type of title right if I come back into the data only for resum or something like that you can also put and play around right that is another possible option so yeah that is that now let's go back to the questions so we have done calculations for total views comments we did some calculation uh they are asking to observe trendwise for months and drive key insights right so we found a few things already so one thing that we have still not done maybe I will add this as an extra page right is to see by month is there any kind of trend right so for this let me again go and insert a simple table right and I'm just going to do it by month right I think I have the column month already ready so I can just select this um and yeah go to properties right and then I can drag the month okay and month I want to see the total views total likes and total comments right I'm just going to drag these three to see if there is a trend right there's like multiple months so again we can simply go and do heat map or bar chart right that's up to us this time just to do something different I can go here and select bar chart and also show the value I'm going to do the same with the other metrics as well right I want to do a bar chart and show the value comments I'm just going to leave them as such so now if you notice again November seem to be the strongest month right and then um of course October was also strong right you see the buildup right August was only 16k views overall across platforms September 80k then 275,000 or 275 1,572 and then so on right November peaked right so we see a steady increase in Trend in terms of views over months so on top of this I can also add a filter I want for uh in terms of platform right so again I'm going to I'm not going to insert text I'm just going to insert a drop down list so I can come here right and here I can give platform as a filter right as simple as that so month I don't want as a filter so let me just cut this and just platform right so I can select each platform let's see if there was specific Trends in LinkedIn LinkedIn there's only data for 3 months uh in LinkedIn October seems to be the strongest month right in YouTube let's see YouTube actually August seems to be the strongest month right but but in Instagram as you see from August September October November I mean December November in that November seems to be the strongest right so there's a steady uptrend up till November but when we select um overall all the months together then we saw see that there's a steady increase right there's August September October November December actually dropped a little bit right so I think that is something to keep in mind um but there's been a steady increase right with the drop in December August September October November showed an overall uptrend right so you can drive insights like this and then find which platform contributed to that increase right so this is how you can create a report and basically if you see here you can also go and download it as a PDF if you want you can also share it with people right you can share uh uh click the share option and then you can create uh for example a link right instead of restricted you can say public so I'm going to share the link of the dashboard right uh and then then I can copy the link and you know anyone can view it right on the internet right so we can do all these kind of things as well right play around so now if I go into View mode I mean all the pages don't have a title yet but as you see we have uh shown a few things right each page has their own unique story so make sure each page doesn't have one table or maximum one or two charts right keep that in mind now one last thing to do how can we actually uh give the pages some kind of names right this will be very relevant so for example I can go to manage pages right so I if I go to first page this is overall information so I can give it a rename overall info right I have not put a lot in this page just overall numbers right second page this is I think a platform wise metrics so I can click here and rename it platform wise metrix okay so I can give it a name like this so names are getting saved next page this is I think uh post category wise overall metrics again right so rename post category wise metrix right you can give some legible name right that should be enough then here it's I think this uh specific KPS that we are calculating by platform so like let's say specific kpas per platform and category right I can give a name like this this is overall likes and view share right so I can rename this as likes and view share and I'm mostly I'm considering by platform and category so I'll say platform and category right simple names and then the last one I think was by month right monthwise performance right so we can easily give names like this right I'm saving now if I go into View mode I also can jump across pages right I can go to this page this page CH change and play around with the filter and so on okay so I hope you enjoyed the video right we didn't do a lot but we we learned basics of Lucas Studio how to use it how to blend the data bring data from Google sheet from Big query how to create calculations right for example in these sheets as you see I've done some calculated field right like comments to likes I showed you how to do that how to do heat map coloring say a story keep this in mind I hope you enjoy the video see you again in another video till then take care bye now that we have learned Excel SQL and data visualization it becomes important to learn one more tool that can help you differentiate yourself in this job market in this era of AI it is very important to learn python in this coming project we are going to use Google collab and write python code to to analyze my own food intake and calorie data and drive insights we're going to use some simple functions from packages such as pandas matplot lib and num pipe additionally at the end we will solve a few general purpose python questions using Loops if statement and so on so here we have a data set it's basically the item I had there is a column called time ID I'll explain what that means then the amount of calories of that particular food and also the date right this is some sample data from Jan 2024 of the food I actually had like I eat dosa Corn Flakes C rice potato fry and so on okay what is time ID here so for time ID we have a second table so time ID one means breakfast two is lunch three is a snack evening snack and four is dinner okay it's like the time when I have that food so that is also marked and we have date of I think up to 15th of January right 1st to 15 January 2024 we're going to answer some questions based on this using python right this is going to be there plus we'll have some additional python questions to solve other general concepts as well so here we given list of questions so basically we will start doing them one by one but before that uh we also have this small clue to start with this right what does this mean what to do how to do uh how to use Python right this is what we're going to see first so for that step number one you simply type cab. research. google.com I will put this link in our description as well this will take you to place like this so over here you can click on new notebook right this is a place where you could actually write python code and execute it right it will set up like this so to begin uh they just asked us to put these two lines of command I'm just going to copy right uh let me just copy this okay this one and then the second one okay what does this mean is we want to be able to connect to Google Drive Right from this because the files right are in Google Drive right so basically these are the two data sets right if I go to my Google Drive I've already downloaded them and uploaded them as csvs okay calories. CSV and time day. CSV they basically contain the same data so you can upload it to your Google Drive and then over here we are trying to connect to Google Drive so for that we write this set of command as step number one let's see what happens right it will take a little bit to connect little bit of time let's just wait patiently and it will pop up like this give a permission to Google right so we can just click on that and say continue right that will enable us to connect to the dve and I think that's it right a few steps to start out if it is done it will give a green tick that is how we know that it's working okay is still taking time it says mounted so that means this is worked so we could add this plus code to keep adding more and more lines of code right first of all we are going to import some packages right to actually perform some operations one package is called as pandas so we will say import pandas as PD that will be step number one now I want to read one of the data set right as I told you there is calories and then there is time day CSV two files so to the calories file let me give it a name data so I could use this command from pandas pd. read CSV right and then all I need to uh do is I have to copy this okay and then I have to write my drive right because it's coming from my drive and then the name of the file right this is just a syntax so I'll say calories. CSV okay and now if I want to see what is there inside data then I am able to read the file so from our Google Drive we have been able to bring the data into Google collab which is able to let us execute python code right this is that the same way I can just copy the same thing for time data I would just give it a different name right time data I'm going to change this to time data okay and the name of the file was timecore off day. CSV okay it's showing some error let me go and check oh it's time day not time of day so I'll remove the off okay just make sure you put the correct file name and we have that data also right so we are nicely set up so data is there which is about my food and the calories time data is about uh the you know the time of the day basically was it breakfast lunch and so on right and time ID is the common column between these two data set now let us uh jump right into the questions and start start solving them one by one read data from the folder this is already done we have finished first question write a command to see what type of columns are present in the data how can we do that so for that we could simply say so like I'll say command to see what columns are present right so this is a way to write commments to make it more readable so I will say data. info right so in in the data table we have item time ID calories and the date right so this is how we can see by putting info we can see what is present in the data notice one thing date new is still an object object or like more like a string it's not yet date right keep that in mind we will need to address this at some point okay I'm just going to keep adding more lines of code show only the first 15 rows of the data how can we do that so first 15 rows so for that we can simply write data head of 15 okay this is like limit 15 in SQL if you say head of 15 you'll get the first 15 rows right starting from zero all the way to 14 this is how we can see the first 15 rows of data so that question is done convert the date new column to date or date time data type right why are they asking us to convert it as you notice here it's object right so how can we convert so I can come here convert date new I'll just give it a heading so I can say date of data of date new right this the column and say data of date new right and I want to convert it so I can say do apply and pandas has this function called to date time right so I want to convert it into date time so I will do this as a first step okay now that is done if I now write data. info let's see what we get now you notice date new has converted to date type type because I did the conversion here right so now it is no more an object we have been able to convert it to daytime this is simple operation commonly asked question sometimes now let's move to the next question combine the calories and time date table right the two tables with the common link right they want us to join or merge the two tables how can we do that so if you notice this is data the other one is called as time data time ID is the common column okay so we need to join on that so so I will say combined data right so I'm joining both how can we do that I will write data. merge of the other table time data right this is how you'll do now what is the common column on which we want to join here we have to notice one thing for the data column data table the column name is time ID t with the Cs whereas for the time data it's time ID but T small letter right so we have to mention both so the first table or the the left table is actually the data table so I will say left underscore on right what is the left column that is common on which we want to join it is this one right time ID but T SCS this is one and from the right table which is the time data table what is the column is one I copied now right so it's time ID but T is small right this is how we can combine the two tables now let's just quickly see how the new table will look like yeah we have time ID So based on time ID We join now we are able to get the time also in the same data right we have breakfast or dinner or lunch whatever we know that this is a duplicate column right it is same as this so we want we can remove this how to do that can say combine data. drop right you can write like this and let us say I I write the small T time ID then you can say a is equal to one right this basically means drop the column and then if I want to drop it in this existing data set itself I can write in place equal to True right when I do that this combined data table will lose that particular column as we are dropping it so now once I write that if I write combined data again now you notice that other time ID column is gone right now we have only five columns because they were duplicate I removed the other column right that is how you can drop a column so now we've been able to uh combine them and also drop the duplicate time ID column right both these are done now show the data filter the data only for break first right how can we do that so before that I'm just going to give a heading to this so what did we do here is merging the two data sets and also dropping duplicate column of time ID right this is what we did here so now let's move to the next one right so I'll keep adding more and more code so I'm just saving it again okay so so I'm just saving it something got stuck there it's okay so we'll continue so only data for breakfast data for breakfast how can we filter only for breakfast if you notice here breakfast is there in the time column right so if I want to show only data for breakfast can write data breakfast as a new data frame it's basically combine data right but within this combine data I want to filter for this column time right and it should be equal to only break first so whenever this combined data of time double equal to break first This Is How We compare and put a filter in Python please show or pick up the data right that is going to be stored into Data breakfast now if I read data break first I will see now I get only the data where the time is breakast this is only purely breakfast data right that is how you can do this question show only data where it is lunch and also calories total calories more than 250 two conditions right so time has to be lunch calories must be greater than 250 so let me put the condition lunch and calories above 250 how to put this condition so let me say data lunch and 250 above right I can give any name so I will say combine data that is the data set again within that combine data I have to introduce a filter so what is the filter the first filter is time has to be equal to lunch right that's the first rule and also you can put an Amper hand and say the other column is about calories so I'm going to copy this right uh column name is calories with the c and this has to be greater than 250 that is the condition okay and remember when we give multiple conditions we have to put each of them within a separate bracket right so this condition in this bracket then an Amper or an end and then the other condition again within this uh normal brackets okay so once I do this now let me run and see data lunch 250 and above what data we get now we only get data as you see off lunch and only above 250 right so basically there's only card rice which I eat during lunch it's more than 380 calories and then pizza right pretty much it and then once fried rice which was 350 right these are the only three items that I eat during lunch that have more than 250 calories right so that is how you could solve that question next one is Group by time ID time ID is like by breakfast lunch dinner whatever see which had the overall highest calories intake right so how do we solve this question let me just keep adding some more code so calories by time ID right so time ID column is there but I could also do by time because time contains lunch breakfast and all for this what we can do we can simply say combine data. Group by here we have to do group by similar to SQL so I want to group by time right and what I want to do is I want to do for calories right the total sum right so to see which is the time when I eat the most amount of food so I can see like this I run it and as you see breakfast 6650 dinner is 6175 little bit less snack is not everyday so it's less lunch is where I eat the most right more than 9,000 calories in this 15day time period so lunch seems to be the highest amount of calories the time when I eat a lot next one sort the data of the given uh you know information by calories in descending order right so how can we do that so this is sort by calories this is also very straightforward question okay so I can say combine data dot there a like order by in SQL we have sort values a command right and then I can say by what do I want to sort by I want to sort by calories right just put that column name and what is the rule I want to sort it in descending so there is a function called ascending here I mean not a function an argument you can say ascending equal to false that means you want to sort in descending order now let me run this now you see Dosa is come on the top because that's the highest 400 banana is at the bottom because that has the lowest calories right so it is getting sorted in descending order of calories the highest calories is coming on Top This is how you could do a simple sort here just let me save it one more time and yeah I'm going to come back here next two seem very straightforward so show the unique values for the item column how many unique dates does the data have right so let's see here unique items right this is very straightforward so I can say combine data of items I think it's item right not items so item what are the unique values I could simply say do unique so you see Dosa cornflakes bread smoothie POA carrot cheese beans Tamar and R chips piz all this right all these are the unique values of items that I have eaten in these two weeks time frame if I want to find unique dates but also do a count right what is that so I can simply copy the similar formula right so here I the column name is date new that's the only difference but I want to count right so unique is similar to distinct in SQL right if you want to count distinct we can write Y unique okay Y unique is another function that will count the number of unique values so it says 14 values okay there 14 unique dates in the given data set that is what they wanted us to count how many unique data set is dates is there in the data set next one they say rename the calories column to intake right the calories column name should change to intake and the time column which is this breakfast lunch dinner thing to time of day how can we rename okay this is an interesting question rename is a function that's also sometimes asked in interviews so first of all what is the rename I can like create a new map in a dictionary okay first of all what I will do I write okay calories is there please rename it to intake okay that is what they want us to do and the other one is there's a column called time so you write this colon symbol and write I want to rename that to time of day okay this is what they're asking step number one now in the original data right combine data you can simply say combine data do rename okay okay and what is the renaming that should happen so the columns should be changed to what is given in the map okay you can say columns equal to map what does this mean so calories will change to intake time will change to time of day now can we cross check our combined data let's see now if you notice instead of calories we got intake instead of time we got time of day right so you create a normal map using a dictionary and then use the rename function to rename the columns right pretty interesting question then coming to next one from 12th January to 13th January can you show the percentage increase in total calories okay now remember calories column has been renamed to intake so we want to find percentage increase in intake from 12th to 13th January how can we accomplish this right so I'm going to keep adding more and more rows so 12 to 13 gen percentage change in calories right whether it was increase or decrease first of all let us see the data right we have combined data like this right now for each day right we want to First do the total sum of calories right how can we do that so first of all I will say Group by date new right I want to do for the overall day right not buy breakfast dinner and all for the overall day so I'll do that and then I want to do total calories so intake is the column and do some okay so if I do like this you will get for each day for 1 Jan 2024 20 150 is the overall calories second gen is 2,130 and so on right but here if you notice we don't have the column name here so if I write reset Index right if I use this now you'll notice we have date new and intake okay this will be step number one now step number two what can we do I want to compare it with the previous value right this is similar to lack function in SQL so what can we do I can write combine data of previous value right I can create a new column how can we do this I can say combine data of intake right and simply say do shift of one right this will basically pick up the previous value right and put it in a new column called combine data previous value maybe I shouldn't do it on the combine data I will do it on this calculated group right so what is this let us say aggregated data I write AG data equal to this okay so so I'm going to run this code and now I want to do it on the AG data not on the original data so I will also convert this and change it to AG data okay just observe what happens now what is this shift doing okay so for example first gen intake was 2150 there is no previous day value so obviously it is null right na is like n 2 January 21130 previous value is 2150 we are getting that here 4th January for example 2055 previous day or previous value is 1750 we are getting that here okay if you notice for 11th it's 1225 but previous day is 1,600 that is coming here which is good but previous day is 9th okay so that is missing we will still not be able to address that just go to pick up the immediate previous value of date okay for us we are just focused on 12 to 13 so basically from 13 and 12 how did it have change right so 12 was 1475 it increased to 2100 but we want to do this calculation right so what can we do I can just come here and add aggregate data and create a new column okay percent change right I can give it a name so this is going to be nothing but aggregate like want to put a bracket so aggregate data of intake value right minus aggregate data of the previous value right percentage changes the current value intake minus previous value this overall thing divided by aggregate dat of the current I mean the previous value so that will show how much it has increased from the previous day or how much it has decreased right so something like this I think there's an extra symbol here this should be good okay let's now see aggregate data what value we get okay so we getting for example on 13th right from 12th if you compare 1475 became 2100 so that's almost a 42.3 7% increase from 12 to 13 gen I increased my calorie intake by 42.3 7% okay this is how you can do this question so this is nice use of use case of the shift function right it's very similar to lag so I'm just going to add more and more lines let's go back to the questions use some function in NPI nump is another package to create a new column which which says small meal if that you know the time of the day is snack otherwise it has to say main meal right this is a very simple use case right similar to the IF function in like Excel so I'm going to go back here what I can do so this is numpy function so I can first import the package numpy and call it as NP now for this new function I can say combine data of let me say meals right new column so what should it says it the function is npw n.w so basically when the time of day right that is the column right whenever the time of the day is dou equal to snack right I have to call it small mean otherwise call it Big mean okay this is what they want us to do simple calculation like if now if I see comine data I'll have the new column okay so break first is a big meal dinner is a big meal when wherever there is snack right so if I want to quickly verify this data for snack it should show small meal right so wherever this time of day is equal to snack make sure you put the spelling right let's see so wherever is snack you see it's small meal so our logic is working right dinner breakfast and lunch will be big meal snacks is small so that is how we can do use np. whereare it comes from the nump package okay moving on to the next one rank the food so we need to do ranking which had the highest overall intake for breakfast dinner and so on right what does this question actually mean is in breakfast which was the food which had the highest total number of calories was it Dosa was it bread same way for lunch was it C rice was it Tamarind rice whatever same way for dinner was it pasta or was it something else for each time of the day right breakfast lunch dinner which food had the highest total calories how can we do this this is another interesting question so like rank food for each time of day right this there is a rank function similar to SQL in Python we will try to explore that right so I'm going to first load the data combine data and what I want to do first is I will say combine dat let us say this is ranking right so I'll give it a name rank data so I want to do combine data do group by right and I want to group two things right so based on time of and also the food right basically the item because I can eat the same item on multiple days and for this I want to do the total sum of intake right let let me do this let's see what I get okay so now let me see rank data what is there okay I'm getting like this so if I do reset Index right I will rerun this let's see what we get now now we get three columns so break first totally bread I have taken th000 calories right so for instance if I come to the data here bread is 250 per day so maybe I've taken bread four times right in this two week time period and same with so on right poha total calorie intake is 400 and poha was part of breakfast right so in breakfast Dosa is 1,600 but in dinner also some days I have taken those are that is 700 right this is how we are splitting the data now we want to give a rank right within breakfast which is the topper right so if we look at the data here can quickly see I think looks like conflix is the highest in breakast in terms of intake how do we give a ranking for that can create a column called Rank and see how this logic works so I can say rank dot Group by okay and I want to group by time of day okay so this group by is very similar to the Partition by we use in rank in SQL time of day and what do I want to rank I want to rank the intake so I'll say do rank off and here you have multiple methods okay method you see within that you have average minan Max first and dense dense is similar to dense and then we have first mean Max you can play around for now I'm going to just put first right this is one of the methods and then ascending or descending right this is like order by ascending is false right because I want to do it descending order of calories now let us see what rank data is showing right so Group by time of day is like partition each time of day separately then total the intake intake value is already total and find the rank right so within breakfast which is the highest within lunch which is the highest we will be able to find this out now let's start the query and see so notice we got the rank right so within breakfast rank one goes to F 2,000 and I think the least is seven rank seven which is vermi which is just 200 if I come to dinner for example the topper is milk like every day I have milk for sure so that is the highest then when I come to lunch C race is leading the way right more than 4,000 calories right and in snack category also there is milk so I drink milk a lot both for evening and night so milk is the Topper Again rank one right so this is how you could Partition by time of day and based on intake do the rank there's also dense rank like method equal to dense just play around with it but this is one way to Showcase okay in each time of day what was the food that had the highest amount of intake overall across this two we time period okay next one uh simple plotting question plot the time of day category and the overall calories using uh plotting function okay so for this we can just go to chat GPT and ask uh plot package M plot Li how to import suppose you don't even know the function for example it should ideally give you some sort of an answer import M plot Li as py plot right I could come here and copy that so this is plotting I'm going give the name okay now what do I want to do each time of day total calories so we have done this multiple times I'll simply say plot data this is nothing but combine data do group by right I want to group by time of dat step number one calories is now called as intake do sum right so if I see plot data it'll be like this okay now if I want to actually plot this what I can do can see pl. bar if I want to show a bar graph I can say plot data. index index is nothing but the time of of the DAT and also plot data. values okay values is the values we have so if I run this I'll be able to plot right okay I see breakfast dinner lunch is where I have the most intake right simple way to plot you can also see ways like how to add xaxis y axis and all right try with chity but this is a simple way to plot right so you import the package do the group by and then you say PLT which is nothing but this package bar want to plot a bar graph plot data. index index will be the time of day values is the calculation right the sum of intake that we did this is how you can do simple plotting one more question write a code to find rows which contain name pasta right so I think there is pasta somewhere um if I scroll down you see so you want to see the row where there is pasta how can we do that I can create a new column combine data of let's say check pasta okay you can give whatever name you want so I can say combine data of this item column right it should contain right the string should contain pasta so I'm going to say string. find of pasta and now if I run this you'll see mostly minus one right wherever it is not found wherever it is found there will be some value right so how can we try and do that so I'll say combine data of combine data of check pasta right this column wherever it's greater than zero right wherever it's not minus one let's see what we get okay there's like literally no value like that right that's a bit weird let's check let's say not equal to minus1 okay yeah okay it's it shows zero here right so it's able to find it at the zeroth place that's why you know we should not put greater than zero but should put not equal to minus one only two values right I think on 2 Jan and 7 Jan I had dinner as pasta right it was able to locate that that is that question now coming to few general questions beyond the data set little bit about loops we will see write a for Loop to display only multiples of five starting from five all the way to 45 right I want to show 5 10 15 20 so on till 45 so for that let me just add a few more lines of code so how can we do multiples of five you write a simple for Loop so you can say for I in range uh you can begin it at five take it all the way up to 45 in steps of I okay and in each of these cases you want to just print the I right print the value here you will get only till 40 right because whatever you include here it will check only till one number before that so here it will go only till 44 so before 44 the closest multiple of 5 is 40 so if you want to show till 45 you can increase this by one number now we show 5 10 15 20 all the way up to 45 right simple for Loop you can use to show the multiples of five all the way up to 45 same way for Loop to display squares of numbers from 1 to 9 so very simple I can just copy the similar formula squares of 1 129 okay so here what I have to do I have to start with the number one go all the way up to number I want to show till 9 so I will say 10 and in steps of one that is okay and print the square of the number so I will say print I into I that will show 1 4 9 16 all the way up to 81 right I into I means I square right so for each number whenever I is 1 it will show one y is 2 it will show 2 into two which is four and so on since I put 10 here it will go all the way up to I equal to 9 when I equal to 9 show 9 into 9 that is 81 we get that right then one more question write a simple code to declare a variable a as 8 and write an if statement to say if the value is greater than eight or not so this is if statement so they say declare a as8 and I will write so if a is greater than it then I will say print is above it okay simple and then I can put else condition so else what should I print print a is not above it okay now let me execute this code and it will say a is not above eight as you know a greater than 8 condition won't work the else condition is working right if I put a is six again a is not greater than 8 so the else condition will work a is not above eight okay okay if I put a as 13 then if a greater than 8 condition is true a is greater than 8 so it should show a is above 8 right so you can play around this is how you can write a simple if and else make sure this I and E are aligned in the same line that is very very important okay one final question declare a simple list with B with four values 0 1 2 3 write a for Loop using try and accept for running I values from 0 to 6 Whenever there is no value print value on available what does this even mean right looks bit complicated let's see right so this is a list question so we they ask us to create a list B with four values 0 1 2 and three okay step number one so I'm going to execute this okay now within a list if I want to read an element if I say B of Zer it will read the first element that is zero if I say B of one it will read the second element what is second element it is one right if I say B of two it will read the third element that is two right that is how a list works right L index start from zero now they want to show us these values and run it in a for Loop for I ranging from 0 to 6 okay so you notice if I write B of three it will show the fourth value that is three but if I write B of four it will show index error right because B of four means the fifth value in B B has only four values there is no fifth value so it shows index error right so we have to be careful just going to change this to something else now if I write for right for I in range they want from 0 to six I'm just going to put like this right and they want us to print the value within B right so I'll say print B of I if you notice here so when I is Zer B of 0 is zero right I is 1 B of 1 is 1 I is 2 B of 2 is two i is 3 B of 3 is three but when I becomes Four B of four is not there it's an index error that that is what is showing up and they are saying use try and accept statement to remove the index error and say when there is no value present print value unavailable how can we do this so for this we have to add this in a try and accept statement so first you will say try right wherever there is no error in those cases the for Loop should work right make sure they are aligned step number one so I'm printing BFI right in the cases where there is a problem where is there is an index error you can say accept index error right wherever there's index error in those cases can simply print what they're saying value unavailable or something like that okay now let's see what we get now we we get value unavailable right so 0 1 2 3 is coming that is great but when I becomes Four B of four is not there since value is not there it shows Val unavailable this is better than showing an error so you can use try and accept for these cases where there's some specific type of error like index error okay so what I will be doing is I will uh share the link to this whole notebook right you can play around with the code I will also upload the data sets please upload them as CSV and then use this code to start reading them okay I hope you enjoyed the video I'll see you again in another video till then take care bye
