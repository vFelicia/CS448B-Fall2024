With timestamps:

00:00 - this machine learning course starts at
00:02 - the beginning and goes all the way to an
00:04 - advanced level teaching you both the
00:06 - theory and applications of machine
00:09 - learning concepts ayush who teaches this
00:12 - course is a data scientist and machine
00:14 - learning engineer hi everyone and
00:16 - welcome to this course of machine
00:18 - learning this course will teach you
00:19 - machine learning from very basics to an
00:22 - advanced level in machine learning in
00:24 - this course this and this course will be
00:26 - having both theoretical plus practical
00:29 - understanding of machine learning
00:30 - algorithms and building real world ai
00:32 - projects after this course you will be
00:35 - you will be able to build your own
00:37 - machine learning applications and
00:38 - real-world applications and many domains
00:41 - okay but wait first who am i my name is
00:45 - ayush and i'm a data scientist at
00:46 - artifact i'm in standard nine from india
00:50 - i've worked on various applications of
00:52 - artificial intelligence like machine
00:54 - learning deep learning i've worked on
00:56 - various domains from deep learning which
00:58 - is another computer vision generative
01:00 - adversarial networks and nash language
01:02 - processing i've also contributed to the
01:04 - large ai projects and routine by andana
01:08 - okay so this is this is my basic uh
01:11 - skills and also i run a small youtube
01:14 - channel which is not as near now not a
01:16 - small a big youtube channel which is
01:18 - around we have a 500 members where we
01:20 - when i where i make a content on machine
01:23 - learning deep learning and various ai
01:26 - things and i put end-to-end courses
01:29 - there currently deep learning course is
01:31 - being launched so you can start watching
01:33 - after this completing that start this
01:35 - course that deep learning course okay so
01:38 - that's that's that is from my side and
01:40 - you can connect me on linkedin if you
01:42 - want to know over more about me and i've
01:44 - also cleared some microsoft exams so you
01:46 - can get to know more about there about
01:48 - me okay i'm also a founder of android
01:51 - and ai tech platform and also product
01:54 - based platform okay so that's it from my
01:56 - side and i hope that you will get a lot
01:58 - more from this course now let's discuss
02:00 - the syllabus of this course
02:03 - we will start with the very basics of
02:05 - machine learning covering the
02:06 - fundamentals of machine learning in the
02:08 - section number one and then it will go
02:10 - further into understanding some
02:12 - algorithms like linear regression a
02:15 - logistic regression support victim
02:17 - machine principal common analysis
02:19 - learning theory and some in symbol
02:22 - learning methods like bagging boosting
02:25 - stacking cascading and then we'll talk
02:28 - about unsupervised learning and you may
02:29 - think yeah you sure you would you wanted
02:31 - to teach this much no absolutely no in
02:34 - this this is a 10 plus hours of course
02:37 - so absolutely there is a lot more
02:40 - content so this this course is divided
02:43 - into sections and each sections have a
02:46 - different sub sections so you and i have
02:49 - made a full syllabus talks what topics
02:51 - i'm going to cover in each and every
02:54 - topic or something a section divided in
02:56 - a sub section and you can assess the
02:58 - syllabus by visiting the course website
03:01 - the course website i premade with um are
03:04 - made with my friends friends of andrew
03:06 - so you can definitely go there and
03:08 - assess all the syllabus all the problem
03:11 - sets of this
03:12 - of this course and each and every
03:14 - section you will be you you'll be having
03:16 - one problem set and all of these is in
03:19 - the description down box below okay all
03:22 - of
03:23 - where the time stamps as well as the
03:25 - course world notes okay so are all
03:28 - available on the course website so you
03:30 - can go there see what's assignments are
03:32 - there complete that and join our discord
03:35 - server to just to discuss your
03:38 - assignments and you can also submit it
03:40 - through forum okay
03:42 - so this is the basic syllabus that we
03:44 - are going to follow and i really hope
03:46 - that it worked a lot in preparing the
03:48 - materials for this course teaching you
03:51 - all in the blackboard and understanding
03:53 - you're helping understand each and every
03:55 - topics of machine learning in a very
03:58 - very very easy way and this course has
04:00 - extensive syllabus a very good syllabus
04:03 - uh to um which i have which i haven't
04:06 - seen on youtube youtube okay so please
04:09 - be sure to see the syllabus what we are
04:11 - going to cover just have told you in in
04:13 - just shot the reason is i i want to just
04:16 - start with this uh video so i've given a
04:18 - shot you can see the syllabus by
04:20 - visiting our course website for
04:22 - absolutely free everything for
04:23 - absolutely free you can go to the course
04:26 - website which is the link in the
04:27 - description that box below so let's
04:29 - start with the section number one
04:32 - fundamentals of machine learning okay so
04:34 - now we'll start with machine learning in
04:36 - this section you will get an
04:38 - introduction to machine learning and
04:39 - we'll talk about introduction to machine
04:42 - learning types of machine learning and
04:44 - there are types and we'll see some cool
04:46 - applications and then we will see some
04:48 - problem of overfitting and under fitting
04:50 - and then we'll wrap up this section okay
04:52 - so let's start okay so now we'll answer
04:55 - a question
04:56 - what is machine learning and you may ask
04:59 - here you sure this is very uh can you
05:03 - tell what actually machine learning is
05:05 - yeah you will get to know more and more
05:07 - about what actually the big picture of
05:09 - machine learning means you in depth when
05:12 - when we will go through this course but
05:14 - in simple terms
05:16 - machine learning is like this computer
05:18 - programs that uses algorithms to analyze
05:21 - the data and make intelligent
05:23 - predictions based on the data without
05:26 - being explicitly programmed and you
05:28 - might think hey are you sure
05:30 - what is kind of this um it i'm getting a
05:32 - little bit confused no worries so let's
05:35 - um let's get into this and let me
05:36 - explain you what i'm saying over here in
05:38 - this blackboard so you are given a data
05:41 - you are given a data okay and then you
05:44 - give to the algorithm
05:46 - the algorithm the algorithm analyzes the
05:49 - data analyzes the data
05:52 - analyzes
05:54 - the data and
05:56 - whatever he has analyzed or learned from
05:58 - the data it makes predictions based onto
06:00 - that it makes
06:02 - predictions under that
06:04 - okay so specifically what we were the
06:08 - what what we are doing we want to make a
06:10 - function x that maps out input variable
06:14 - x to the output variable y and you may
06:17 - think here you're sure confusing me what
06:19 - is x what is y no worries
06:22 - x is the input feature x is the input
06:25 - feature means uh let's take a problem
06:28 - statement of predicting the house prices
06:30 - predicting the house prices okay so you
06:35 - want to do this so uh here on the basis
06:38 - of the size of the house so
06:41 - on the basis of size of the house
06:45 - you want to predict the price
06:48 - of the
06:50 - house okay so you give an input variable
06:54 - x and you get outward variable y okay so
06:58 - on the basis of the size of the house
07:00 - you want uh the price of the house okay
07:02 - so you wanted to make a function so you
07:04 - wanted to make a function
07:06 - f
07:07 - that takes input x and maps that to y
07:12 - and that's the definition of machine
07:14 - learning that's the beauty of machine
07:15 - learning so what we were doing we are we
07:18 - want to have we want to map our input
07:21 - variable x maybe it can be maybe the
07:23 - size of the house maybe the
07:27 - number of fans of the house maybe the
07:29 - number of our bedrooms in the house so
07:31 - i'm denoting with a subscript one
07:33 - subscript to subscript three and we want
07:35 - to make a function that maps these input
07:37 - variables to the output variable which
07:40 - which we did denote with y which is the
07:42 - price of the house and that's what and
07:46 - that we are doing
07:47 - and we will learn how to make this
07:49 - functions okay so that's the beauty of
07:51 - machine learning which you can see over
07:53 - here so let's see some of the more
07:54 - formal definitions which you will see
07:57 - you more over the internet then the
07:59 - machine learning is the field of study
08:01 - that gives computer the ability to learn
08:03 - without being explicitly programmed
08:06 - saved by author samuel but one
08:08 - definition that i said to use totally
08:10 - means if you if you if someone asks you
08:13 - hey hey whatever your name uh what is
08:16 - machine learning you just ask hey i i
08:18 - know a better way to define a machine
08:20 - learning you just make a fun geo just to
08:22 - make a function that maps your input
08:24 - variables to the output variable okay
08:27 - and that's the beauty or that that's
08:29 - called the machine learning and i hope
08:31 - that's you that you that you got it what
08:32 - i'm what i'm trying to say you hear and
08:34 - access are the input features that you
08:36 - that you wanted to on the basis of that
08:38 - these are the input input features and
08:40 - the basis of that you want to predict
08:42 - the price
08:43 - okay the another definition of machine
08:45 - learning is the computer program is say
08:48 - to the learn from the experience e with
08:51 - respect to the sum class of a task t and
08:54 - some performance measure by p if its
08:56 - performance on t as measure by p
08:59 - improves with experience e and this mean
09:02 - seems a little bit intimidating but let
09:05 - me clear this definition is very uh
09:08 - my my favorite definition although this
09:10 - this is my favorite definition that i've
09:11 - shown to you but let me tell you what
09:14 - the definition tells you the definition
09:16 - is so before that let me take one
09:18 - example which is let's take an example
09:20 - of checkers okay playing checkers
09:24 - playing
09:25 - checkers i hope that's you no no no
09:27 - let's let's take another because many
09:29 - other people do not play checkers over
09:31 - here okay so let's take a spammed email
09:34 - spam detection system email spam
09:37 - detection detection
09:40 - system which you will make in this
09:42 - course
09:43 - yeah you will make this course you will
09:44 - make this into the course okay so this
09:47 - is a problem statement and what's what's
09:49 - the let's fit that definition onto this
09:51 - problem here t
09:53 - is the detecting the emails means
09:56 - detecting whether the email is a spam or
09:58 - not so let's let's denote zero as uh
10:01 - detecting a spam or one as uh
10:05 - okay so let's say let's say ham
10:07 - and e is the experience of his
10:10 - prediction is the experience here e is
10:13 - the experience of detection and p is the
10:15 - performance how much performance
10:17 - increases upon to the experience so in
10:20 - this way higher the experience is best
10:22 - the system is but i think this is more
10:25 - formally fit to something called a
10:27 - reinforcement learning which will not
10:28 - see the advanced learning but
10:32 - again the definition which you have to
10:34 - take is you wanted to make a function of
10:36 - function f that maps your input
10:39 - variables to the output variable and
10:41 - that's machine learning and or you can
10:43 - say that's the beauty of machine
10:44 - learning
10:45 - okay so some of the applications of
10:47 - machine learning there is um i just
10:50 - listed on a few but there are a lot more
10:53 - self-driving cars real estate stock
10:56 - price prediction and medical we have or
10:59 - corbin 19 detection maybe
11:02 - using chest radiographs and then uh
11:05 - disease prediction cancer detection etc
11:08 - and then it's just a boom and i highly
11:10 - encourage people to get into this field
11:14 - and try to contribute to the world in a
11:16 - unique way okay so you can see over here
11:18 - some some of the applications of machine
11:20 - learning so how it works
11:22 - so what you do uh let me get to get back
11:24 - to my boat and how it actually works all
11:27 - this how it works
11:29 - it's kind of a very easy
11:31 - how it works uh first you study a
11:33 - problem so again let's let's take a
11:35 - problem let's take a problem of again a
11:37 - spam detection
11:39 - spam detection detection
11:42 - system okay i i think the c okay so to
11:46 - make a span detection system so first
11:48 - you study problem you have a look at the
11:50 - data how actually the data is
11:52 - okay so first you do this the second
11:55 - thing is the basic workflow the second
11:56 - thing you train the algorithm and
11:59 - algorithm is just a function it's just a
12:01 - function okay f of x which you will uh
12:04 - how it is defined which you'll see later
12:06 - on but you just
12:07 - have a function which is algorithm this
12:09 - is this is the algorithm
12:11 - algorithm and you train with this
12:14 - algorithm and then you go further into
12:16 - evaluation evaluation you evaluate it
12:19 - into uh you give a new train new emails
12:23 - and check which is correcting for
12:24 - correct or not and then if it is good
12:27 - then you launch the system then you
12:29 - launch the system
12:31 - launch the system otherwise
12:33 - otherwise you
12:35 - analyze some error you do error analysis
12:39 - you do error analysis and then you go
12:42 - further into tuning or improving your
12:44 - algorithm or evaluating your uh and then
12:46 - you evaluate then again do that do like
12:48 - this so that's what machine learning is
12:50 - called ml is very
12:52 - very iterative process iterative
12:56 - process which you will see in more and
12:58 - more loops why this term that but but if
13:00 - beginner don't worry about it okay but
13:03 - if you want to get it after this course
13:04 - you can get to my gans course or maybe
13:08 - the deep learning course
13:10 - or uh
13:11 - maybe another course which is dsa which
13:13 - which i'll talk about that is very
13:15 - important and then you can head over to
13:16 - the ml oops videos okay so this is the
13:19 - basic you can you can head over to that
13:21 - and learn something new from there
13:24 - okay so uh what are the types of machine
13:26 - learning systems since there are uh i
13:30 - think the three types of main main
13:31 - machine learning systems are three types
13:33 - supervised unsupervised reinforcement
13:36 - learning and although there is few more
13:38 - which is batch learning transfer
13:39 - learning active learning passive
13:41 - learning and etc which you which you can
13:44 - learn obviously when you go further no
13:46 - when you go further means into more into
13:48 - machine learning then you will see that
13:51 - uh how you are learning these all and
13:54 - you learn to grasp each and every
13:56 - content a few
13:57 - minutes okay so what are supervised
14:00 - learning supervised learning uh let's
14:03 - let's let's go get back to my boat again
14:05 - and let's take an example of another
14:07 - example which is my favorite uh no not
14:11 - not my favorite but yeah it's a house
14:14 - price prediction so i'm just providing
14:15 - about house
14:17 - price prediction
14:19 - prediction
14:21 - problem registry system okay so this is
14:24 - a house price prediction so you have a
14:26 - feature uh let's let's let's denote that
14:29 - on the basis of the size of the house
14:32 - size of the house
14:33 - i'm just taking example because in the
14:35 - real world the size of the house thus
14:37 - the fan number of fans in the house
14:39 - number of bedrooms in the house on the
14:40 - base of the butt just for now uh for
14:42 - predicting this from the size of the
14:44 - house you want to predict the price of
14:48 - the house
14:49 - you want to predict the price of the
14:51 - house which is which we denote as a y
14:54 - and whatever we give whatever we take as
14:56 - a feature we denote this as a x okay so
14:59 - there is uh we denote there is only one
15:01 - one feature which is x1 and only we are
15:04 - getting a one output which is y
15:06 - okay so uh we have we provide x1 means
15:09 - the size of the house and we are getting
15:10 - the price of the house as an output okay
15:13 - so uh
15:15 - you can see over here that we have uh
15:18 - size and we have a label
15:21 - means we have given the price and the
15:24 - model can learn from this house the
15:26 - trend is how the trend is on
15:29 - it can recognize patterns okay so you
15:32 - can see over here that our data is
15:34 - labeled as a y means we know what our
15:36 - output so it learned from their label
15:38 - and input that's called the supervised
15:39 - learning how you can identify the
15:41 - problem is supervised
15:43 - because you see the target variable
15:46 - which is called the target this is
15:48 - called a target variable
15:50 - and this is called the features
15:53 - features or variables okay
15:56 - and the one we want to predict is called
15:57 - the target variable so we this is the
15:59 - features or variable so you see that
16:02 - there is a relationship between your
16:04 - input value x and the output value y
16:09 - input value x and output value y well
16:11 - i'm saying it has some relationship
16:13 - because you can see over that we are
16:15 - given the size of the house and going to
16:17 - predict the price of house so you can
16:19 - see over the entirety is that they have
16:21 - some kind of relationship and we know
16:23 - what our output should look like in this
16:25 - case we know what our
16:27 - our output should look like in reduction
16:29 - it's kind of a continuous output our
16:32 - output will be in continuous value so we
16:34 - know what our output should look like
16:36 - and that's called supervised learning
16:38 - okay so i think you i i think it's going
16:41 - good means you're understanding what i'm
16:43 - saying so in simple terms you can see
16:45 - the definition of a hill we feed the
16:47 - data and this the data are labeled means
16:49 - that the output variable which we denote
16:51 - as a y are labeled and which we give
16:53 - which has some relationship between our
16:55 - input value x and the output value y
16:58 - okay so in the unsupervised learning uh
17:01 - which which i'm not going to go to dig
17:03 - dive just now and further i will i will
17:04 - be digging dive into this
17:06 - so we the data are not labeled and we
17:10 - can say that we don't know what our
17:11 - output should look like and there is not
17:13 - kind of any relationship between what
17:15 - are what will be our input variable and
17:17 - what will be the our output variable and
17:19 - we have to recognize our patterns based
17:22 - on the data for doing so we have
17:24 - different algorithm which we'll study
17:26 - later okay so i'm just not digging
17:28 - digging type but in simple terms
17:31 - but in simple terms what i what i'm
17:33 - saying that
17:35 - let me let me tell you what i'm what i'm
17:36 - saying
17:38 - okay so uh
17:40 - let's say you this these are the t-shirt
17:42 - sizing you want to you have a different
17:44 - different t-shirts and we're denoting
17:46 - this as t-shirt so we have a different
17:48 - different t-shirt and what else
17:51 - and this is our data this is our data
17:52 - and you have to
17:54 - then you have to simply classify or
17:56 - cluster it out so whatever what your
17:58 - model will do it simply make this as a l
18:02 - it simply makes this as xl and simply
18:05 - mix as an m okay so it's just uh make
18:08 - clusters it makes cluster
18:11 - xl and l and for now i don't recommend
18:14 - to brainstorming these things because we
18:16 - will first we have to understand fully
18:18 - supervised learning then it will most
18:20 - much clear uh unsupervised learning so i
18:22 - don't want to dig dive into unsupervised
18:25 - learning for now but you can see what
18:26 - the definitions are cut to cut okay so
18:28 - let's start let's keep deep diving a
18:30 - little supervised learning so what are
18:32 - supervised learning so in supervised
18:34 - learning um we know our output variable
18:37 - and input variable etc that i would just
18:39 - explain your house price prediction so
18:41 - in supervised learning we have two types
18:44 - of problems the problems of supervised
18:46 - learning can be classified into two
18:47 - types so let me write it a supervised
18:50 - learning problem supervised learning
18:53 - problem can be classified into
18:56 - regression problem
18:57 - regression problem and it can be
19:00 - classified into classification problem
19:03 - classification
19:05 - problem okay so let's keep talking about
19:07 - what is regression what is
19:08 - classification so i'm gonna take take
19:10 - one example which is a house price
19:12 - prediction which is a house price
19:15 - prediction means house price prediction
19:18 - and we can see over here that our output
19:21 - will be in continuous value because
19:23 - super supervised learning and we know
19:25 - what our output is so you can see over
19:27 - that output will be in continuous value
19:30 - continuous
19:32 - value
19:33 - okay so your output is in continuous
19:36 - value and classification and in
19:38 - classification uh let's say
19:41 - given a picture x means the often uh you
19:44 - want to classify an image of a picture
19:47 - as a cat
19:48 - or a non-cat
19:51 - or a non-cat
19:55 - okay so um you're gonna picture x um you
19:59 - wanted to uh identify this as a cat or
20:01 - non-cat okay so you can see here but
20:03 - that is a binary it has only two it is
20:05 - it is a it is called a degree value it
20:08 - is called the degree value means we can
20:10 - now classify that in regression if our
20:13 - output of the problem is in continuous
20:15 - value that's called that that's that's
20:17 - that is a regression problem if our
20:20 - output of the particular problem is in
20:21 - degree value we can classify that as a
20:23 - classification problem and you can see
20:26 - over here the definition is the same
20:28 - okay
20:29 - okay so
20:30 - why we need to divide our data so let's
20:34 - let let me talk about because i'm
20:36 - talking too much about data but what is
20:38 - data it's this question arrives a very
20:40 - good question that i want to ask by
20:42 - myself
20:43 - is data are the they how does data looks
20:46 - like in data let's say let's take an
20:49 - example of an application a system that
20:51 - is a price of the house
20:54 - house price predictor okay so
20:56 - the data will look like this
20:59 - so i'm just just making a data frame so
21:01 - you have a size of the house then you
21:03 - have a number of fans then you have a
21:05 - number of bedrooms then then is the
21:08 - target variable which is the price so
21:10 - these are your x these are your x and
21:13 - this is your y okay and what you do uh
21:17 - let's let's take nine square feet two to
21:20 - twenty two i'm just taking as a thousand
21:23 - et cetera just a thousand dollars i'm
21:24 - just taking as an example don't think
21:26 - that is a nine it's a nine square feet
21:28 - size of the house don't don't think like
21:30 - that
21:32 - okay so uh this this is kind of thing
21:34 - uh so this this is kind of thing and we
21:36 - have a size and we have a number of fans
21:39 - we have a number of bedrooms okay so uh
21:41 - what you do uh here you can see over
21:44 - here that we have a data we have your
21:46 - data
21:48 - and what you do you divide your data
21:50 - into training
21:52 - into training and testing set
21:55 - into test training and testing sets so
21:57 - let's say you have a hundred percent of
21:58 - data if you take 80 percent of your data
22:01 - for training or model and 20 of your
22:03 - data for testing the reason why you take
22:06 - this to evaluate your model because you
22:09 - from where you will get all those uh for
22:10 - testing so you just keep 20 20 for
22:13 - evaluating so check how how best your
22:15 - model is okay
22:17 - so this is the evaluation of the data
22:19 - which we'll see more later on okay so
22:21 - there are two problem that i want to
22:23 - highlight is uh
22:25 - overfitting and under fitting okay so
22:28 - what is overfilling so let's take an
22:30 - example again i just i just i just
22:32 - believe in examples
22:33 - okay so here is your x and y plane i
22:36 - hope that everyone remembers in in in
22:38 - their school days oops what is happens i
22:41 - hope that i drawn correctly okay so you
22:43 - have this uh these features let me draw
22:46 - it very
22:47 - quickly
22:50 - this is your data points and what you do
22:53 - uh you simply draw a straight line you
22:55 - simply draw a straight line to make
22:57 - predictions okay so let's this is your
23:00 - input which is x so it's a 2200 square
23:03 - feet so it will go over here and check
23:05 - what is the price so it will give here
23:07 - okay so like that it will make
23:08 - prediction which we'll see later on so
23:10 - you can see over here that
23:13 - in under fitting in underfitting and
23:15 - under fitting what happens
23:17 - if your model if your model has not
23:20 - performed well onto the training data as
23:23 - well as when testing data means in under
23:25 - fitting your model does not perform well
23:28 - under the training and the testing data
23:31 - means uh your model is performs bad
23:33 - under training and the testing data it
23:36 - means because you don't have a large
23:37 - number of in a large number for data you
23:39 - can you can simply add more data okay
23:42 - but what happens in under fitting can
23:44 - then you will tell me what happens in
23:46 - under fitting so let me highlight this
23:47 - little bit
23:48 - let me
23:51 - so in under fitting if your model has
23:53 - learned too much this is because when
23:55 - you have too much of features so let's
23:57 - say your uh it
23:58 - will try to touch each and every point
24:00 - it will try to touch each and every
24:02 - point
24:03 - and this is called and you can see if
24:05 - you if you have a if your model learned
24:07 - too much and it is generalizing very
24:10 - very well
24:11 - very very well onto the training data on
24:15 - the training data but it fails to
24:17 - generalize well
24:19 - fails to generalize well
24:21 - on testing data
24:23 - testing data then you can say that your
24:26 - model is overfitting okay so you can see
24:29 - over here that the diagram is over here
24:31 - and you can see with that under fitting
24:33 - which your does not feed a straight line
24:35 - a very good way and good fit is a good
24:37 - good good model you can just fit a
24:39 - straight line and in a bad fit over fit
24:41 - it okay so
24:43 - the solutions of this which you'll see
24:44 - later on but before that we'll touch
24:46 - some algorithms and again some notations
24:48 - which i've already taught you x means
24:50 - the input features x1 x2 all the way
24:52 - down to xn y means the output features m
24:55 - means the number of training examples
24:57 - and here let's say 600 training example
24:59 - which you will get to know
25:01 - more further which when when we will go
25:04 - more further into this course
25:06 - okay so now we are done with this uh
25:09 - introduction of machine learning and i
25:10 - really hope that you enjoyed this
25:12 - tutorial and in the next section we'll
25:14 - be talking about one of the algorithm
25:16 - which is linear regression and i hope
25:18 - that you will really enjoy that so let's
25:20 - meet at the next section
25:22 - okay so now we will briefly talk about
25:25 - supervised and unsupervised learning
25:27 - with adaptation and some cases studies
25:30 - and data sets so to fully understand
25:32 - what happens in supervised and
25:34 - unsupervised learning okay so let's
25:36 - start
25:38 - so
25:38 - uh what happens in supervised learning
25:41 - and supervised learning as the name
25:42 - suggests someone is supervising over
25:45 - here i will take an example of a data
25:47 - set to help you understand better okay
25:49 - so in supervised learning uh what i have
25:52 - told you in the in the previous session
25:54 - is about in machine learning that you uh
25:56 - in
25:57 - in supervised learning we make a
25:59 - function f of x that maps your input
26:01 - variable
26:02 - to the output variable okay so here in
26:06 - supervised learning we have the input
26:09 - data
26:10 - input data as well as the output data
26:14 - okay
26:15 - means here as an example that we have
26:18 - this data set
26:22 - we have this data set just assume that
26:24 - we have this data set
26:26 - and here we have this outlook feature
26:29 - temperature feature means x1
26:32 - x2
26:33 - then we have a humidity as x3
26:36 - windy as x4 okay and here this the red
26:40 - one play tennis so here is our problem
26:43 - statement is given on these features
26:46 - outlook temperature and humidity and
26:48 - windy we have to predict whether the
26:51 - whether that boy will play tennis or not
26:54 - okay so this is your target variable
26:56 - this is your target variable or or the
26:59 - variable that you want to predict okay
27:01 - this is the target variable or the
27:03 - variable
27:05 - that we wanted to predict
27:06 - that we want to predict so it is given
27:09 - in this case so it is given in this case
27:12 - so here uh we have our x variable as
27:17 - well as y variable as well as the y okay
27:21 - as well as the y variable okay so we're
27:24 - going to make a function f of x using
27:26 - this data that maps our input value all
27:29 - these features x1 all the way onto x4
27:32 - uh
27:32 - do a y variable okay so we'll give input
27:36 - whether there is sunny or whether you're
27:38 - hot or high or false and given on this
27:41 - feature the function will give you
27:42 - output whether it will play no or yes
27:46 - okay so here and this is a supervised
27:48 - learning problem because we have our so
27:51 - we have our labels which you can see
27:53 - over here okay so and you can also see
27:56 - that we have a some kind of relationship
27:58 - between our input value and our output
28:01 - value why as you can see that
28:04 - and these are there is there is some
28:06 - kind of relationship like a male
28:08 - stylistic example of house price
28:10 - prediction so given an input feature
28:12 - size you want to predict the price of
28:14 - the house of the house of the house so
28:17 - it is on a shame name so there is some
28:19 - kind of relationship between our input
28:21 - feature x and the output feature why
28:24 - okay another another property of
28:27 - supervised learning is that these
28:29 - features which are input features are
28:32 - our independent features our independent
28:36 - features
28:37 - are independent
28:40 - independent
28:42 - features what do i mean by independent
28:44 - features they do not have to depend on
28:46 - any and any feature they don't have to
28:49 - depend on any feature but this target
28:51 - variable y is a dependent feature
28:54 - because the target of y is depending on
28:57 - these features it's depending on these
28:58 - features to be mapped and is depending
29:00 - on these features so that's why
29:03 - x1
29:04 - x1
29:05 - x1 all the way down to the x i i equals
29:09 - to 1 all around to the k means x 1 x 2 x
29:11 - 3 x 4
29:12 - is a independent feature which you call
29:14 - usually as an indian independent
29:16 - variable or feature and y is your a
29:19 - dependent variable or feature okay so
29:22 - that's the that's that's called the
29:24 - features um the supervised learning so
29:27 - let's um so let's let me write a basic
29:30 - definition or a good definition of
29:32 - supervised learning what what is
29:34 - supervised learning a good definition
29:37 - okay
29:38 - so the good definition of supervised
29:40 - learning is here in supervised learning
29:43 - we have we have our input features x we
29:46 - have our input we have our input
29:49 - features
29:51 - x we have our input feature x large x
29:54 - and just assume that x large x this
29:57 - contains all features in a vector all
29:59 - the way under the x i okay okay so we
30:02 - have input we have our input feature x
30:04 - and also we have our output feature y we
30:08 - have our output feature y
30:10 - output feature y y and there is
30:14 - some kind of there is
30:16 - some kind of relationship some kind of
30:20 - relationship
30:21 - between the input value x and the output
30:24 - value y
30:26 - and
30:27 - and
30:27 - x is called independent feature
30:31 - x x feature circle independent feature
30:34 - and y is the dependent feature because
30:37 - it is dependent on to the input features
30:40 - okay so we have seen here so show you an
30:42 - example that there is a y there is a y
30:46 - that is used to train uh using x okay
30:49 - this is that using x and y okay so we'll
30:52 - be able to uh predict our mod so we will
30:54 - see in the next section how we make a
30:56 - predictive model okay as a part of
30:59 - linear regression so let's see some of
31:01 - the so um but before that i want to i
31:03 - wanted to uh just to show you that there
31:06 - are two parts of supervised learning
31:09 - first one is a regression second one is
31:12 - classification classification so what do
31:14 - i mean by regression you know what your
31:17 - output will look like because here we
31:19 - know that what our output because we
31:21 - have already seen our data so you can
31:22 - see the output is in decreased value
31:25 - what do you mean by degrade value your
31:27 - output is in finite means either it will
31:29 - be yes or no so here if it is integrate
31:32 - value if you know that your output is in
31:34 - degree value then you then you then you
31:37 - consider that as a classification
31:39 - problem how you identify that is a
31:41 - classification problem when your output
31:44 - is in degree value and when your output
31:46 - is in continuous value means um
31:50 - it's not finite maybe the age of the
31:52 - person maybe the stock prices that is a
31:55 - that is continuous okay so that's why if
31:58 - your output is in continuous then it's a
32:00 - regression if your output is degree then
32:02 - it's a classification okay so let's see
32:05 - some of the applications of supervised
32:07 - learning to help you understand more
32:09 - better to get the feel of supervised
32:11 - learning so in supervised learning we
32:14 - have our favorite uh in supervised
32:17 - learning we have maybe the stock price
32:19 - prediction stock price prediction we are
32:22 - you are given closing price high closing
32:24 - high then etc maybe some volume and
32:28 - predict what is the
32:29 - stock price and on the maybe the you
32:31 - want to predict this you can consider c
32:33 - close as a target variable you want to
32:35 - predict what what with the closing price
32:37 - basis on high and volume okay so high in
32:40 - volume are your independent feature and
32:42 - c equals c will be your independent
32:44 - feature which will be the y
32:46 - next is maybe the house price prediction
32:49 - maybe you want to basis on the size like
32:52 - that you want to predict what will be
32:53 - the output why
32:55 - and maybe uh let's do example of a
32:57 - classification problem given you want to
33:00 - identify whether the person has a
33:01 - diabetes or not basis on maybe the age
33:05 - gender bmi etc
33:08 - okay so we have this output variable y
33:10 - okay so these are some of the
33:12 - applications of unsuper sorry supervised
33:14 - learning okay so now let's see so
33:17 - unsupervised learning as i'm not going
33:19 - to go deep dive into this uh
33:22 - unsupervised learning there is a next
33:24 - section that there is a particular
33:26 - section after supervised learning we
33:27 - will cover the in depth about
33:29 - unsupervised learning but the core idea
33:31 - behind unsupervised learning that in
33:33 - this case in supervised learning we are
33:35 - given x i as well as y i for uh for each
33:40 - uh for every i equals to 1
33:43 - all the way down to the m and m here is
33:45 - the number of training examples means uh
33:48 - okay so that's m here is means we have
33:50 - for we are given i okay so here yeah in
33:54 - super supervised learning in supervised
33:56 - learning we have this in unsupervised
33:58 - learning the unsupervised learning we
34:00 - have only x i's we have only x i's we
34:03 - don't have y eyes
34:05 - you have only x i we have x1
34:08 - x2 x3 all the way down to the xm
34:11 - okay we don't have the label y i there
34:14 - is no supervisor that will guide you
34:16 - okay and what you have to do let's take
34:18 - an example um you have
34:20 - you have this
34:23 - uh so uh here is your data set so here
34:26 - you have a channel reason fresh milk
34:29 - grocery frozen detergent and delicious
34:32 - so let's take an example that uh
34:34 - unfortunately is used in markets market
34:36 - segmentation segmenting your customers
34:39 - so you have these features and you don't
34:41 - have the whether the person with you
34:43 - what you do you just cluster the person
34:46 - which has similar nature you have you
34:48 - just clustered the person let's take an
34:50 - example that these person use used to
34:52 - eat milk these person used to that so
34:55 - you cluster this out you cluster this
34:58 - out okay then you can hand code it okay
35:00 - these person used to eat milk and then
35:03 - you can send promotion to these people
35:05 - or big deal another thing to these
35:07 - people so you can identify your business
35:09 - needs etc from these clusters either i'm
35:11 - not going to give deep dive into the
35:13 - application etc but i will go deep dive
35:15 - into the application everything but as
35:18 - of now i hope that you understood
35:19 - supervised learning in that okay so
35:22 - that's it for this uh
35:24 - just a small uh video on supervised
35:26 - learning and unsupervised learning and
35:27 - the next section we'll be starting with
35:29 - actually the math and then we'll leave
35:31 - dive into the machine learning the
35:32 - beauty of you will see the beauty of
35:33 - machine learning okay so let's meet at
35:36 - the next section till then do the
35:38 - problem sets
35:39 - so now we have seen an introduction to
35:41 - machine learning and i hope that you
35:43 - have really enjoyed that section now
35:45 - it's time for getting enhance your dirty
35:47 - into the maths now we will see some
35:49 - learning algorithms which is linear
35:51 - regression and then we will do one
35:53 - project which is boston hot springs
35:55 - prediction so i uh so i'm very excited
35:57 - to
35:58 - have your first learning algorithm in a
36:00 - toolkit so head over to the next section
36:03 - okay so now we will see one algorithm
36:06 - which is a linear regression which is a
36:08 - learning algorithm um as in the in our
36:10 - previous section we have seen a machine
36:12 - learning and an introduction to machine
36:14 - learning now we will see how to make
36:17 - that function f of x that maps that maps
36:20 - your input variable x to the output
36:23 - variable of i okay so before that i want
36:27 - to recall something which is in
36:29 - supervised learning in super advised
36:33 - learning we are we were having two types
36:36 - of problems
36:37 - first one is a regression problem
36:40 - the second one is classification problem
36:43 - as you might think okay so
36:46 - linear regression as you know as you can
36:49 - see from the term regression it's a
36:51 - regression algorithm so it's a
36:54 - regression algorithm that we'll study
36:56 - today okay in this section
37:00 - okay so let's recall what is regression
37:03 - it's it's a type it's it's a type of
37:05 - supervised learning and supervised
37:08 - learning algorithm and here we know our
37:11 - output will be in continuous value our
37:14 - output will be in continuous value means
37:16 - let's say let's let's take an example
37:18 - that you want to predict the price of
37:21 - the house let's say you want to predict
37:22 - the price
37:23 - of the house okay so you can see over
37:27 - here the output of this particular
37:28 - problem will be in continuous value we
37:31 - don't have any kind of decreased value
37:33 - so we can identify that this problem is
37:35 - based on to the
37:36 - uh
37:37 - regression problem okay so let's let's
37:40 - let's start see let's ski let's see how
37:43 - this algorithm works in much more detail
37:46 - so that you could get more intuition
37:48 - about and you can ace an interview on
37:51 - linear regression and also i'll be
37:52 - putting some entropy questions over you
37:55 - of what someone can ask you and what
37:56 - someone not okay
37:59 - so let's assume that we have a scattered
38:01 - data so let me make one x and y plane i
38:04 - hope that this is good pretty good
38:06 - and let me make that one okay so i'm
38:09 - just going to make the scatter data that
38:11 - looks like this
38:13 - okay so this is your data and let's take
38:16 - as a problem statement as like this
38:18 - let's take a problem statement which is
38:21 - predicting the price of the house based
38:23 - on the size of the house so let me write
38:25 - that predicting
38:26 - the price of the house predicting the
38:29 - price
38:30 - of the house
38:33 - and this is the end in rupees so
38:35 - price of the house based on the size of
38:37 - the house okay so you will give x which
38:40 - which will be the size of the house and
38:42 - you will get the y which will the price
38:44 - of the house okay
38:47 - okay
38:48 - so we have the scattered data and in x
38:51 - axis we have our size
38:53 - which is our input variable
38:55 - and in y-axis we have our price
38:58 - okay so what we do we fit a straight
39:02 - line we fit a straight in linear
39:04 - regression we fit a straight line like
39:07 - this we fit a straight line which is
39:08 - called the hypothesis which is called a
39:11 - hypothesis and uh regression term this
39:14 - is called the hypothesis which we'll see
39:15 - how we can compute the straight line so
39:17 - we make this straight line and you can
39:20 - see over here that after making the
39:22 - straight line we can make predictions so
39:24 - let's say that this is this is the size
39:26 - and based on this we are making the
39:28 - prediction like this onto the y-axis
39:30 - okay so and again let's say the prime
39:33 - let's say the size of the house is 2200
39:36 - square feet then the price will be like
39:38 - this uh 2 22 000 etc so like like like
39:41 - this we are making predictions okay and
39:44 - you can see over here this line is
39:46 - little bit far away from the actual data
39:48 - point so that's the issue that that
39:50 - we'll see later on but you just
39:52 - construct a straight line that touches
39:54 - each that that closely touches each
39:56 - point or definitely that is closely uh
39:59 - uh passes through this tray uh
40:02 - scatter data points okay so let's see
40:05 - how we can compute the straight line
40:07 - because linear regression as you know
40:09 - linear means it constructs a linear line
40:11 - that separates the data okay
40:14 - okay so let's see how it works
40:17 - so in
40:18 - for making a straight line as i've
40:21 - already told you this is called the
40:22 - hypothesis so how we construct
40:25 - hypothesis so this is called the
40:27 - hypothesis function we compute
40:28 - hypothesis function like this we have
40:31 - weight of every features so let's say
40:34 - theta 0 times x 0 plus theta 1 theta 0
40:39 - time times x 0 plus theta 1 times x 1
40:42 - plus theta 2
40:44 - times x 2 all the way down to the theta
40:47 - and times x n okay so
40:50 - you're summing it all up so what what i
40:52 - what what you can see over here
40:54 - that
40:56 - what you can see over here that
40:58 - we have the status and we have these
41:00 - features this is th this is the let's
41:03 - say the size of the house let's say this
41:05 - is the maybe the number of fans in the
41:09 - house i'm just taking the problem
41:11 - statement predicting the price of the
41:12 - house so so that's why number of a fans
41:15 - in the house and and etc okay so these
41:18 - are the features x1 x2 and x0 is the
41:22 - biased term is the biased term or the
41:25 - y-intercept or the y-intercept maybe if
41:28 - you know about inter-intercept of y
41:30 - means if x0 equals to 0 then your line
41:34 - will be crossing from the origin if x 0
41:36 - equals to 1 then it will be from 1 if x
41:39 - 0 equals to 2 then it will be from 2.
41:42 - okay so it determines the y intercept
41:44 - from where he wants to make a straight
41:46 - line okay so we have this theta zero
41:49 - times x zero theta one times x one theta
41:52 - two times x two all the way on to theta
41:54 - x times x x n and let's take a
41:57 - particular problem statement and let's
41:59 - understand that but before that you may
42:01 - think hey use what is theta here what is
42:04 - theta here
42:06 - we only have to learn machine only have
42:08 - to learn this theta machine only have to
42:11 - get the best theta now we are able to
42:13 - make prediction now let's say we we take
42:15 - theta zero let's take we take theta zero
42:18 - to be
42:19 - uh uh two okay and theta one to be
42:23 - let's say three theta two to be four
42:26 - okay so just i'm taking only uh two
42:29 - features and one bias term which is the
42:31 - this this is the bias term and these are
42:33 - the two features and x zero is obvious
42:36 - is always equals to one x zero is always
42:39 - equals to one so that's why we never
42:41 - write x zero okay so that's why we never
42:43 - write we just write uh theta zero plus
42:45 - uh theta one times x one we did not
42:47 - write but i just just have showed you so
42:50 - for a clear ratio of those things okay
42:52 - so you can see over here that uh let's
42:55 - let's take an example that this we have
42:57 - two features like the size of the house
42:59 - and the number of fans on the basis of
43:01 - that you have to predict the price so
43:04 - for each feature we learned the weight
43:07 - these these are called the feature
43:08 - weights these are called the feature
43:10 - weights so we learned this and if we get
43:13 - the best feature weight we will getting
43:15 - the best prediction if we get the bad
43:17 - feature weight we'll be
43:19 - getting bad prediction okay so let's say
43:22 - uh let's let's construct the problem so
43:25 - let's say your theta 0 to be 2 times x 0
43:28 - which is x where x 0 equals to 1 so it's
43:31 - obviously true plus theta 1 which is
43:33 - like let's say theta 1 is 3 as of the
43:36 - end times the size of the house plus the
43:40 - theta two before times the number of
43:42 - fans in the house okay so now this now
43:46 - using this you can make the prediction
43:48 - you can just plug in the size and you
43:50 - can plug in the number of fans and you
43:52 - will be getting your desired output why
43:55 - okay so
43:56 - just now you may think hey machine
43:58 - learning is not we are not it we are
44:01 - only using it as a computational power
44:04 - and you can see over here that how it
44:06 - how it learns theta will which we'll see
44:09 - because machine learning is totally
44:10 - based upon learning parameters okay so
44:13 - you will see how the theta is learned so
44:15 - let me tell you uh thetas
44:18 - we have to only learn theta we have to
44:21 - only
44:22 - learn which will see the techniques
44:24 - where we have to only learn
44:27 - theta
44:28 - we have to only learn theta and if the
44:30 - theta is bad then then you then your
44:33 - hypothesis when the function is bad so
44:35 - this is your function this this
44:36 - constructs your function like this
44:39 - theta one times x one plus theta two
44:42 - times x cubed all the way down to the
44:44 - theta n times x n and and here they
44:46 - denotes the number of features and
44:48 - features are the columns okay and the
44:50 - data okay so uh this is a function and
44:53 - you can use this function to map your
44:55 - input variable to your output variable y
44:57 - okay so that's it that's that's kind of
45:00 - our we have our kind of a
45:02 - function that maps our input variable to
45:03 - our output variable okay
45:06 - okay so now i think the twos that said
45:09 - that we've got how we construct that a
45:10 - straight line and using this function we
45:12 - can construct that a straight line and
45:14 - we have to only learn these these this
45:16 - this is called
45:17 - these are called the feature weights
45:20 - these are called the feature weights and
45:22 - these are called the feature weights and
45:24 - this is the bias term or the y intercept
45:28 - uh from where the
45:29 - the the line should originate as i've
45:32 - showed you earlier okay
45:34 - so uh now i hope that you got a
45:36 - intuition about hypothesis function
45:39 - okay so now let's keep talking about uh
45:43 - the vectorized form of this means the
45:45 - vectorized form
45:47 - is
45:48 - maybe vector vectorization means how
45:52 - here we are separately computing for
45:54 - each values we are computing theta zero
45:56 - then times x zero theta one times x 1
45:59 - means separately for each value so in
46:02 - vectorization we do at once we do at
46:05 - once so what we do we put over all the
46:08 - thetas so we put our so i'm just writing
46:10 - vectorized form
46:12 - vectorized forum so we put our all theta
46:16 - we put our all theta
46:18 - it will be in joint vector theta and uh
46:22 - let me do this theta zero theta one
46:25 - theta two all the way down to theta and
46:27 - and theta these theta this is the
46:29 - feature vector this is the feature
46:32 - vector which can which is all the
46:33 - weights you will further see that yeah
46:35 - we have to only learn this then you will
46:37 - believe me that yeah we have only have
46:39 - to learn this whether it's a neural
46:40 - network but it's a machine learning okay
46:43 - so you have this base theta into joint
46:45 - vector theta and you take a giant vector
46:47 - x and you store all your x's over there
46:50 - x 0
46:52 - x 1 x 2
46:54 - x 3 all the way down to the xn okay so
46:57 - you take this and then you take out the
46:59 - dot product okay so then you take out
47:01 - the dot product and theta
47:04 - times dot product okay so now your
47:07 - hypothesis f of x will be like this okay
47:10 - so you just give this function and
47:12 - thetas what what it will do it will uh
47:15 - theta zero times x one theta one times x
47:18 - one it will sum sum it all up theta one
47:20 - theta two like like this broadcast it
47:23 - okay and it is computing at once okay so
47:26 - you can draw and then some sum it all up
47:28 - okay so so you can write in summation
47:31 - format
47:32 - i equals to 1 all the way down to the n
47:33 - or i equals 0 all the way around to the
47:35 - n theta theta i times x uh let's say i
47:39 - okay so so you are doing it's a
47:41 - vectorized form of that and you can see
47:43 - over here
47:44 - and python is very easy just one line of
47:46 - code uh like like this you just do like
47:49 - this np
47:50 - dot dot
47:52 - theta
47:53 - and x
47:55 - done okay so it's very easy in python so
47:58 - don't worry how how we can code this all
48:01 - it's quite easy
48:02 - okay so now we have seen the hypothesis
48:06 - and and we have seen the vectorized form
48:08 - of this linear regression okay
48:12 - so
48:13 - you may think hey i use how i can get
48:15 - this theta but before that how we can
48:19 - evaluate your theta is best means your
48:21 - thetas are good your theta are good so
48:25 - for evaluating our model we have
48:27 - something called cost function we have
48:29 - something called cost
48:31 - function okay so why we evaluate a model
48:35 - to check
48:36 - how are p if our theta is good or not
48:39 - okay so we check because
48:41 - using that theta we are making
48:43 - prediction we are multiplying with the
48:44 - features and we will get feature these
48:46 - the size we will get from the user we
48:48 - will this game fan number of fans get
48:50 - the user we multiply with the weights
48:53 - and then sum it all up and then we give
48:55 - the result okay so this is the cost
48:57 - function and here uh what why why we use
49:00 - cost function to evaluate our model okay
49:03 - so
49:04 - you you will get to know how what what
49:06 - we do so let's say uh
49:08 - we have a scatter plot so let me plot on
49:11 - a scatter plot like this again the same
49:13 - i'll be doing the same
49:15 - but this time little bit more crunchy
49:18 - yeah i think so
49:20 - okay so this is this is my plot and what
49:23 - we do
49:24 - we simply draw a straight line uh this
49:27 - this is your hypothesis this is your
49:28 - hypothesis which is f of x and what this
49:31 - cost function will do this is your this
49:33 - is your actual data point these are your
49:35 - actual data point and these these are
49:38 - your actual data point it will what it
49:40 - will simply do it will simply take out
49:43 - the distance between predicted this this
49:45 - is the predictor that i'm highlighting
49:47 - and this is the actual okay so this is
49:49 - the predicted this is the sorry this is
49:52 - the predicted and this is the actual
49:54 - this is the predicted this is actual
49:56 - okay so it takes out the difference
49:57 - between or the the it takes a distance
50:01 - between like like this predicted
50:04 - minus the actual value predicted minus
50:06 - the actual value like this
50:08 - uh yeah like this and
50:11 - and then sum it all up means higher the
50:14 - this uh cost function will be better or
50:17 - more or less higher the cost function
50:19 - will be better your moral will be and
50:22 - less the cost function will be
50:24 - good your moral will be the reason why
50:27 - if your if your points are on this line
50:29 - and your cost function will be zero
50:31 - because the predicted will be zero sorry
50:34 - let's say predicted will be all the same
50:36 - and actually will be also the same so it
50:38 - will be resulting in zero so just what
50:41 - what we do we this these are called the
50:42 - residuals in terms of uh
50:45 - cost function so we just take out the
50:47 - distance between predicted and actual
50:50 - value for all data points okay so this
50:53 - is the cost function
50:55 - okay so uh let's rest forward to
50:58 - formulate this in a formula
51:00 - let's formulate this is the foreign
51:02 - formula like this
51:04 - uh let me show you how we can formulate
51:06 - that yeah so you just take out of j of
51:09 - theta i'm just denoting j of theta will
51:12 - be like the uh
51:13 - short form of cost function because we
51:16 - are checking how our theta is good or
51:18 - bad or not okay because it only
51:20 - determines whether your model is good or
51:21 - bad
51:22 - 1 over m 1 over m and m here is the
51:25 - number of data points
51:28 - plus
51:29 - i equals to 1 all the way down to the m
51:32 - and you just model predicted value less
51:35 - let's denote the model predicted value
51:37 - by y hat and how how we have we got y
51:41 - hat yeah we have got y hat like this y
51:43 - hat equals to uh f of x
51:47 - equals to theta times x means dot
51:49 - product of theta and x which is
51:52 - equivalently equals to the hypothesis
51:54 - okay so we let's let's note as a y hat
51:57 - minus y
51:58 - okay and in other words we can write
52:01 - this out like this
52:03 - in other words we can write
52:04 - write this out like this theta transpose
52:07 - x i
52:09 - minus y i and this this is just a
52:11 - hypothesis h of x okay and transpose
52:14 - like this
52:16 - are you you
52:17 - your uh
52:19 - x will be like this so you make this uh
52:21 - theta will to be like this
52:23 - okay so it will be easier like this okay
52:26 - so this so that's what this transpose is
52:28 - doing but
52:29 - if you can do or not just just we are
52:31 - doing the this uh let me write that
52:35 - theta
52:36 - times x okay the dot product between
52:39 - theta and x minus y i
52:42 - okay minus y i for each and every day at
52:45 - a point we are taking out the difference
52:47 - between predicted and actual value and
52:50 - then we're squaring we had a squaring
52:52 - here because it helped us to and further
52:54 - call something called the gradient
52:55 - descent okay for easily derivation of
52:58 - this cost function you will see why i'm
53:00 - taking derivation term over here okay so
53:03 - in other words it's this this this this
53:05 - is called the loss function which is
53:07 - known as mean square error m s e
53:10 - okay which is called the mean square
53:12 - error if you square root this if you
53:15 - make this
53:17 - let me show you what i'm telling
53:19 - if you square root over 1 over m
53:22 - plus
53:23 - i equals to 1 all the way down to the m
53:26 - theta x i
53:29 - minus y i
53:31 - squared if you square root this like
53:34 - this
53:35 - okay this this is called the root mean
53:37 - square error
53:38 - root mean
53:40 - root
53:41 - mean squared error okay and higher this
53:45 - and better your model less okay
53:48 - okay that's just just we are taking the
53:50 - square root
53:51 - okay but we'll stick with this um mmc
53:54 - but in real world a million kaggle
53:56 - competition they have given what they're
53:57 - going to use mainly i have seen rmse to
54:00 - be used very much okay so uh after we
54:03 - got our cost function it tells okay your
54:06 - model is that good or that bad now if
54:08 - your modeling that how you can optimize
54:10 - or how how you can get optimal theta
54:13 - means best theta how you can get the
54:15 - optimal theta this is the great question
54:18 - to ask
54:19 - okay so how are you how you're going to
54:21 - get this optimal theta for getting that
54:24 - we have something called gradient decent
54:27 - something called a gradient decent
54:29 - algorithm
54:31 - gradient decent algorithm which is known
54:33 - as the optimization algorithm which is
54:35 - known as the optimization algorithm
54:38 - which will help us to get the best theta
54:40 - okay optimization algorithm okay so uh
54:44 - let's let's stick dive into this uh
54:46 - algorithm and let's understand how we go
54:48 - get this kind of thing so let's say our
54:50 - the visualization of the cost function
54:52 - will be like this okay just just for the
54:54 - sake of an example i'm visualizing like
54:57 - this okay so this is this is your cost
54:59 - function i'm just writing as a z of
55:01 - theta this is your cost function and now
55:03 - your cos
55:04 - cos here use is your theta where the
55:06 - cost function is very high okay so here
55:09 - is your theta okay so what gradient
55:12 - descent does it tweaks the theta means
55:14 - let's see your theta is zero then simply
55:17 - let's say it's mismakes theta little bit
55:19 - to 0.2 okay it tweaks the theta it
55:22 - changes theta a little bit and if the
55:24 - cost function decreases then updates the
55:27 - theta to be not like this to be like
55:28 - this if the theta go down means the cost
55:31 - function little bit
55:33 - decreases then it changes again 0.3
55:36 - if the cost function decreases then it's
55:39 - do not make this then it's
55:41 - uh update this theta okay then again it
55:44 - simply tweaks checks if the j of theta
55:47 - going down if yes update the theta okay
55:50 - until and unless your cost function is
55:54 - until unless your cost function is
55:56 - approximately equal to zero
55:58 - okay so that is simply the gradient
56:01 - decent it's very very simple that i've
56:04 - just shown to you so let's let's further
56:06 - formulate this mathematically because
56:08 - it's very very simple when we formulate
56:10 - this as a mathematics so how we simply
56:13 - what what we do for tweaking these
56:15 - things for tweaking the theta we take
56:18 - out the partial derivative we take out
56:21 - the partial derivative of your cost
56:23 - function j of theta
56:25 - now you will think hey i use you have
56:28 - why why you have taken the calculus name
56:30 - i'm not a calculus student i'm not kind
56:32 - of that don't worry at all at all it's
56:35 - kind of it's i just want to give you one
56:38 - definition of a partial derivative
56:40 - partial what if what it does it simply
56:42 - tweaks your theta it simply tweaks your
56:44 - theta and checks if the cost function
56:47 - decreasing okay and it's just like the
56:49 - slope it's just like the slope but you
56:51 - don't need calculus you don't even need
56:54 - calculus yeah if you want to go on a
56:55 - research level then you obviously need
56:57 - but for now for a machine learning you
56:59 - don't need calculus for deep learning
57:01 - even you don't need calculus just um
57:04 - just you can just what what this
57:07 - equation is doing it is just it is just
57:10 - uh
57:11 - tweaking your theta tweaking your theta
57:14 - a little bit so it gives us like this
57:16 - two over m so it gives us two over m
57:19 - plus
57:20 - i equals to one all the way down to the
57:22 - m and this is a y hat minus y squared
57:25 - okay so this the after after deriving
57:28 - this partial we we get like this okay so
57:33 - now after this we do uh we do we take
57:36 - out the partial derivative for every
57:38 - theta means theta zero theta one theta
57:40 - two theta t all around the theta and we
57:42 - do for all theta we take out the partial
57:44 - derivative of all theta and then we up
57:48 - and then we update our theta so here is
57:50 - a full gradient decent algorithm so what
57:53 - what what we do
57:54 - we simply write theta z
57:58 - this is the
57:59 - update kind of assignments theta is a
58:02 - minus the learning rate alpha and the
58:05 - kind of a partial derivative of your
58:09 - okay partial derivative of your cost
58:11 - function okay so what we are doing this
58:14 - is how this this is uh this this is this
58:16 - will be our new theta that i've just
58:18 - shown to you we update the theta so this
58:20 - this is your old theta means the bad
58:22 - theta this is your learning rate and
58:24 - what rate your uh uh this is the hyper
58:27 - parameter which i will talk about in
58:28 - just one second in detail but what we
58:31 - are doing over here we are this this
58:33 - this the alpha determines the rate means
58:36 - if the alpha is too large if the alpha
58:39 - is too large it will go like this it
58:41 - will never converge it will be like
58:43 - diverging like like this if your theta
58:45 - is very small then i think that it will
58:48 - never converge at local minimum it will
58:50 - be like this it will never converge at
58:52 - local minimum so the optimal theta that
58:55 - i've used till now it's a 0.1 for larger
58:59 - data data set 0.01 for okay for a little
59:03 - bit to smaller medium data set 0.001
59:07 - a little bit more smaller and
59:10 - 0.0001 okay so these these are the
59:13 - optimal uh for me i have seen so far is
59:16 - these alpha but you can tune it you can
59:19 - tune it using um grids or cv or
59:22 - randomized search cv which we will see
59:24 - later on okay
59:26 - okay so i i just say to you why by this
59:29 - theta it just determines the weight of
59:31 - your uh tweaking the parameter okay just
59:33 - going down and this this this gives this
59:36 - is the simply the partial derivative of
59:38 - your cost function and we are updating
59:39 - this this this will be our new theta and
59:42 - this is whole
59:44 - algorithm of gradient descent okay
59:47 - okay this this just just equations tells
59:50 - us the whole algorithm for gradient
59:51 - descent okay so now again i'm going to
59:54 - talk about uh vectorized bottom how we
59:57 - can vectorize this okay because i i
60:00 - totally believe in vectorization so
60:02 - let's tell
60:03 - what what what we can do uh here we are
60:07 - in the pre previously we are taking out
60:10 - the partial derivative of theta zero and
60:13 - then we are taking the partial
60:14 - derivative of theta 1 separately what we
60:17 - can do what we can do
60:20 - and we can simply put that into uh
60:24 - like like this partial derivative into a
60:26 - joint vector theta
60:29 - into a j of theta with respect to zero
60:32 - kind of this
60:34 - and like this
60:37 - all the way down to the n okay so you
60:38 - just put into the giant vector and you
60:40 - just take out the partial derivative of
60:43 - whatever you want to take out and then
60:45 - and then you just uh write the
60:47 - vectorized form theta z
60:51 - theta z minus
60:53 - the learning rate alpha and that gives
60:55 - us like like this 2 over m
60:58 - times the x transpose
61:00 - x theta x theta
61:03 - minus y and this is your new um derived
61:06 - equation which is a vectorized form okay
61:10 - and yeah yeah you can definitely use any
61:13 - any kind of this this is totally okay
61:16 - but for vectorization you can follow or
61:18 - not it's your opponent but for
61:19 - computational powers just just have told
61:21 - to you okay so we have seen so far and
61:24 - now we are done with this we have
61:26 - developed our linear regression model we
61:28 - first have developed the model from
61:30 - making predictions and then then we have
61:32 - moved further to check how our theta is
61:34 - good then we have seen how to how to get
61:38 - optimal theta okay but you may think ask
61:42 - here you see i have to do these kind of
61:44 - things yeah you have to do these these
61:46 - kind of things for getting your and
61:49 - and if i did if i say truth uh the truth
61:52 - is in scikit learn you can implement
61:54 - this in three lines of code you can
61:56 - implement this whole algorithm into
61:58 - three lines of code in some library but
62:00 - in programming assignments you have to
62:01 - implement from scratch this algorithm so
62:03 - that you can ace any kind of interview
62:05 - okay okay so um
62:08 - you may ask there is something called
62:09 - the normal equation there is something
62:11 - called normal
62:13 - equation that that i want to highlight
62:15 - little but normal equation gives you a
62:17 - better theta in just one way means
62:20 - normally patient gives you a theta
62:22 - optimal theta in just one equation like
62:24 - this so equation is x transpose
62:27 - x
62:28 - inverse of that x transpose y and for by
62:31 - you by using this and x here is the data
62:33 - points it means the features so you can
62:35 - simply use this uh formula for getting
62:38 - the for for getting your optimal theta
62:41 - okay this is just the same as doing this
62:44 - but
62:45 - not in every algorithm it will work it
62:47 - will only for linear regression the
62:49 - normal equation is only for linear
62:51 - regression and i hope but
62:53 - having a good intuition of all those
62:54 - because in interview they usually ask
62:56 - this they don't they usually talk about
62:58 - normal equation
63:00 - okay they don't all talk about normal
63:02 - equation the usual talk about this
63:04 - gradient descent etc although there are
63:06 - too many optimization algorithm some as
63:09 - like gradient descent in gradient
63:11 - descent we have this and then we have a
63:13 - stochastic gradient descent we have a
63:15 - stochastic which is called hdd we have a
63:17 - atom optimization algorithm we have rms
63:20 - prop
63:21 - rms prop and then gradient with momentum
63:24 - which we which you will see advanced
63:25 - level in
63:26 - uh i will talk about hdd pattern atom rm
63:30 - rms prop and some more optimization
63:32 - algorithm or convex optimization
63:34 - advanced as um which you will ever see
63:37 - in deep learning okay okay or you can
63:40 - head over to the newer of it and do deep
63:42 - learning courses currently learning and
63:43 - you can learn from there okay okay so
63:46 - now we are done with this and let's
63:47 - little bit let's literally spend some
63:49 - time on to some assumptions of a linear
63:51 - regression okay because in an interview
63:54 - they usually ask why you wanted to
63:55 - choose this algorithm instead of this
63:57 - algorithm or what is the assumptions of
63:59 - this algorithm etc so the sum of
64:01 - assumptions um of a linear regression if
64:04 - the issue it should have a lean linear
64:07 - relationship linear relationship the
64:10 - data should be linear the data should be
64:12 - linear and
64:15 - no or little multi-collinearity
64:17 - the code the correlation between uh
64:19 - variables would be uh no nothing okay
64:23 - no
64:24 - or little
64:25 - multicollinearity
64:27 - multicollinearity okay you can see ac
64:30 - internet for more
64:31 - okay so now we have seen some
64:33 - assumptions but i want to just i want to
64:35 - give you the things what is independent
64:37 - and dependent feature independent means
64:40 - the size of the house
64:42 - the pro the number of fans and number of
64:44 - let's say the bedroom so these are the
64:46 - independent features because they are
64:47 - not independent
64:49 - to any feature for the kind of any value
64:51 - but the target variable y is dependent
64:54 - on all these features so that's why the
64:55 - target variable is called the
64:56 - independent sorry dependent and these
64:59 - are called
65:00 - independent okay so this is just a
65:02 - casual information to know because
65:04 - everyone talks about this
65:06 - okay so now i think that we have talked
65:09 - very very much in small amount of time
65:11 - and i hope that you really really enjoy
65:13 - this tutorial
65:15 - and i'm putting all my effort then you
65:17 - can go on to my youtube channel new era
65:20 - new era and you can subscribe that
65:22 - youtube channel if you want okay okay so
65:25 - um now we have talked that and in the
65:28 - next section i'm going to go over uh in
65:31 - theory pattern i'm going to go over
65:33 - polynomial regression but let's spend
65:36 - some more amount of if i have time let's
65:38 - spend two more minutes onto polynomial
65:40 - regression okay so there is something
65:42 - called a polynomial regression as we
65:44 - have seen the assumption that data
65:46 - should be linear but let's say our data
65:48 - is not linear then what we do okay then
65:51 - what we do so let's say your data will
65:53 - be like let's say your data is like this
65:58 - your data is like this
66:01 - your data is like this so you if you
66:04 - feel fit like this then it is obviously
66:06 - overfitting so what you do you just
66:08 - simply transform your data you simply
66:11 - transform your data to be like this into
66:14 - the quadratic form you enter the
66:16 - quadratic forum to be uh you just simply
66:19 - transform this one one degree to the two
66:23 - degrees so it will confirm
66:25 - like this
66:26 - okay so you two will be transformed as
66:28 - let's say
66:30 - four and six uh threes maybe transform
66:33 - that's a nine and whatever what whatever
66:34 - it was just so i'm taking an example
66:36 - okay so you transform your data to be
66:38 - fitting over the linear so you transform
66:40 - your data to be fitting over linear now
66:42 - your uh algorithm will be fitting like
66:45 - this okay so now i hope that you have
66:48 - gone everything about polynomial etc now
66:51 - we will talk about it we'll do some past
66:54 - and house class prediction and then
66:55 - we'll move on to the irregularized
66:57 - linear models okay so let's head over to
67:00 - the uh boston hospital prediction and
67:02 - then we'll move on to the regularized
67:05 - linear models okay so now we have seen
67:08 - linear regression and we have done one
67:10 - project now it's time for getting your
67:12 - hands dirty in the programming
67:13 - assignment you will be able to find the
67:15 - programming assignment description box
67:16 - below in the sign-in page okay so now
67:20 - we'll start with logistic regression
67:22 - after doing assignment come at the com
67:24 - come again and follow up with this
67:26 - course so now we'll talk about logistic
67:28 - regression and i hope that you will
67:30 - really enjoy this okay so now we have
67:32 - seen linear regression which is one of
67:34 - the regression algorithm now we will see
67:36 - one classification algorithm with this
67:38 - logistic regression don't worry uh don't
67:42 - think that this legislative question is
67:44 - a regression algorithm no it's a
67:46 - classification algorithm so because the
67:48 - name is logistic regression because the
67:51 - underlying working of this algorithm is
67:53 - same as
67:54 - is
67:55 - something similar to linear regression
67:58 - okay so
68:00 - you will get to know about this how it
68:01 - differs from linear regression okay so
68:05 - before that let's uh let's be clear
68:07 - about we are on the same page about
68:09 - close classification what is
68:11 - classification okay so this is a great
68:13 - question to ask to yourself what is
68:15 - classification
68:17 - so let's take an example
68:18 - given in range x you want to classify
68:20 - this image as a cat if it is cat then we
68:23 - will name it as zero if it is non cat
68:25 - then we will name it as a one okay so
68:27 - this is a tweet value our output is
68:29 - indicated value and the classification
68:32 - is a supervised learning approach so
68:35 - this algorithm is a supervised learning
68:36 - algorithm so
68:38 - here we know what our output should look
68:40 - like so here our output is in degree
68:43 - value so we can classify this as a
68:45 - classification task okay so that's the
68:48 - specification and something called the
68:51 - binary classification and we have a
68:54 - multi-class classification also called a
68:57 - multi-class classification means uh
69:00 - maybe the person has a cancer person has
69:03 - a pneumonia etc this means integrated
69:05 - value your output is in finite value
69:08 - value okay so we have this
69:10 - classification and uh this tool so now
69:13 - it's time to study about legit
69:15 - regression in detail and
69:19 - so what we do in legitimation we
69:21 - classify the data we classify the data
69:25 - so uh let's start with hypothesis in
69:28 - linear regression we have our hypothesis
69:30 - which is uh
69:32 - hfx let's stay known as h of x
69:35 - equals to the in legitimation we also do
69:38 - the same theta zero times x zero plus
69:41 - theta one times x one plus theta two
69:45 - times x two
69:46 - all the way down to the theta and times
69:48 - x n okay so in linear regression we are
69:51 - doing the same for drawing a straight
69:53 - line and here we are also doing the same
69:55 - for a function and this is and this this
69:57 - this will be uh for linear regression
70:00 - and the same for a legislation and this
70:03 - is the step this is the fourth step for
70:05 - hypothesis and the second step of
70:07 - hypothesis means the more predicted
70:09 - value equals to the sigmoid of h of x so
70:12 - let's denote this as a short form of z
70:15 - okay so this h of x is g and g here is
70:18 - simply h of x and h of x is here theta
70:20 - zero all over theta so we're gonna name
70:22 - it as a theta transverse x
70:25 - okay so you just here you just
70:28 - do the sigmoid of your head h of x which
70:31 - is which is your
70:33 - prediction function so you just
70:35 - do do the sigmoid of this z and you get
70:38 - your output and you get your output so
70:41 - let's say what the sigma does you get
70:43 - your output from legit logistic
70:45 - regression and this output makes the out
70:49 - this uh the this whatever the output
70:51 - came let's say 22
70:53 - 22 to between zero to one the sigmoid
70:57 - the if if you apply sigmoid to this you
71:00 - apply sigmoid
71:02 - to this then it then it makes your
71:04 - output between the range of zero and one
71:07 - and you then you set the threshold if
71:11 - and you set the threshold if you're the
71:13 - model particular y hat is greater than
71:16 - uh y hat is greater than 0.5 then yeah
71:20 - this picture is a cat okay otherwise if
71:23 - it's smaller than 0.5 then it is a non
71:26 - cat okay and this is what it is this is
71:29 - what we are doing in linear regression
71:31 - we are just this is this this was our
71:33 - hypothesis but in addition we add a
71:36 - sigmoid to our edge of x and the reason
71:39 - why we add sigmoid uh it's it's totally
71:42 - because
71:44 - uh that we want our output between zero
71:47 - and one in the range of zero and one so
71:49 - that we can make prediction like this so
71:51 - uh just you apply sigma and the formula
71:54 - for sigmoid is 1 over 1 plus e to the
71:58 - power minus z and z here is h of x okay
72:03 - so this this this will be your whole
72:05 - hypothesis this is your prediction
72:07 - function okay now you just put the z and
72:11 - theta you have to one learn theta you
72:14 - have to learn these thetas which is
72:16 - called the parameter it's again the same
72:17 - as a linear regression okay so what we
72:21 - are doing we are just uh
72:23 - doing the same as uh
72:24 - first the first step we are doing same
72:27 - as a linear regression and then we are
72:28 - applying a sigma at that h of x and then
72:32 - um we are getting the output which is
72:34 - the which is in the range of zero and
72:36 - one and uh we set a threshold 0.5 is a
72:40 - threshold and if the particular the
72:42 - model predicted y hat from this output
72:45 - between the range is greater than 0.5
72:47 - then it is a cat otherwise with smaller
72:49 - than uh of 0.5 then it is a non-cat if
72:52 - you want to be more uh
72:54 - strict then you can make 0.7 the
72:56 - probability is greater than 0 70 okay so
73:00 - let's say you're more output like this
73:01 - 0.
73:03 - 80 okay so it is equal to the eighty
73:06 - percent your model is saying that a
73:07 - particular uh this image is a eighty
73:10 - percent accurate that this is a cat okay
73:13 - so you just make it as a one round of
73:15 - two one means it is a cat otherwise if
73:18 - it is a 0.4 t then it's 40 that is so
73:21 - you make it as a non-count
73:23 - okay so this is the basic thing that you
73:25 - should understand is a prediction
73:26 - function that we have made and again we
73:28 - have to only learn these thetas um it
73:31 - means we have to get these tt three and
73:33 - these thetas together to get our good
73:36 - output okay so this this was a legit
73:39 - regression and then i and the hypothesis
73:42 - for legit regression okay
73:45 - okay so now in linear question we have
73:48 - seen something called the cost function
73:50 - something called as cost function and
73:52 - cost function simply what this does it
73:53 - simply
73:54 - gives you the accuracy of the model
73:57 - means if the cost function is very very
73:59 - high then then your model is very bad if
74:01 - your cost function is
74:03 - low then your uh
74:05 - then then then your model is good okay
74:07 - so it helps it help us to evaluate your
74:10 - model okay is the the loss function it
74:13 - should be all the cost budget for a good
74:16 - uh for a good
74:18 - model your j of theta means the cost
74:20 - function should be approximately equals
74:22 - to zero
74:23 - okay okay so uh in lecture expression we
74:25 - have defined little bit different this
74:27 - cost function like this uh let's do for
74:30 - one training example like this j of
74:33 - theta j of theta equals to minus 1 times
74:37 - y i
74:39 - the log
74:40 - of h of x i
74:42 - h of x sine plus
74:45 - 1 minus y i minus 1 minus y i
74:48 - log
74:49 - of 1 minus h of x i
74:52 - okay so this this is your cost function
74:55 - for for one training example
74:57 - and you can see over here that
74:59 - we have a cosplay one minus one times
75:01 - the y i times the log of h of x i and
75:04 - one minus y i uh times the log of one
75:07 - minus h of x time so what we are
75:09 - actually doing so let's break down this
75:11 - equation and let's understand step by
75:13 - step
75:14 - okay so what we are doing here we are
75:16 - doing why i
75:19 - is the grand route is the ground root
75:22 - ground with truth
75:24 - and h of x i h of x sign is your model
75:28 - predicted value which is the model
75:29 - predicted value
75:31 - and it's just taking the log of that
75:34 - your model and multiplying with the y i
75:36 - okay so let's say your y is equals to
75:41 - zero your y is equals to zero and your
75:44 - model predictor y hat is also equals to
75:46 - zero then your cost function will be
75:49 - approximately equal to zero because uh
75:52 - they both are same so your boss
75:53 - mentioned will be zero okay will be low
75:57 - if let's say your
75:59 - ground through this one and your model
76:01 - predicted is equals to the zero then
76:03 - this this is a mismatch your model done
76:06 - very bad so your cost function will be
76:08 - very very high okay so this is what the
76:11 - basic integration behind is cost
76:13 - function and this is your basic formula
76:15 - and
76:16 - again uh you can see over here that we
76:18 - do this uh kind of for
76:21 - oops what is okay so uh let let me write
76:24 - the equation for m training example we
76:25 - have done for one training example so
76:27 - let's do for m training example so let
76:29 - me write the equation for that
76:31 - so you have a j of theta you have a j of
76:34 - theta and
76:35 - 1 over m 1 over m
76:38 - i equals to 1 all the way down to the m
76:40 - y i
76:42 - log
76:44 - of h of x i
76:46 - plus 1 minus phi i
76:49 - the log
76:51 - of 1 minus h of x i
76:54 - okay so this is the log loss this is
76:56 - this some sometimes called as log
77:00 - loss in terms of machine learning so you
77:02 - just uh this this is your calls function
77:04 - that is used to uh use as a loss
77:06 - function that we have seen so far and
77:08 - i've given an example when the both the
77:10 - output is correct me on ground truth and
77:12 - your moderator is equals then your cost
77:14 - function will be zero otherwise is if it
77:17 - is different then your cost will be very
77:19 - very high okay so this is the cause
77:21 - function for your legitimacy model so
77:24 - let's recapitulate the two things the
77:26 - hypothesis and your
77:29 - fault cost function so the hypothesis is
77:31 - that
77:33 - h of x equals to the
77:35 - uh sigmoid of z and z here is theta
77:39 - transpose times x okay the dot product
77:42 - between transpose times x and you just
77:45 - uh take the it's the equation which is
77:47 - uh similarly equals to 1 over 1 plus e
77:50 - to the power minus c and z here is just
77:52 - a theta transpose x data transpose
77:55 - okay so uh the theta contains the
77:58 - parameter rates uh theta contains the
78:00 - parameter base and x contains the x one
78:02 - x x zero x one all the way to multiply
78:05 - okay and in y convention we are using x
78:07 - zero equals to one you can rewatch that
78:10 - uh linear regression section once more
78:12 - if you are getting a little bit confused
78:13 - because i have expect i've gone a little
78:15 - bit slow there okay okay so
78:19 - and the gradient isn't for getting the
78:22 - good for reducing this j of theta or for
78:25 - getting the good optimal parameter we
78:27 - use gradient decent algorithm and
78:28 - gradient reason why it does the same
78:30 - here is your theta we have the cost
78:32 - function very very high this is your
78:33 - cost function diagram so your cost
78:35 - function will be very very high when
78:36 - your theta is here when you change theta
78:38 - your a little bit decreases over here
78:40 - again you change again you change means
78:42 - you're taking out the gradient of your
78:44 - cost function and checking if it is
78:46 - going down if it is then you just update
78:50 - your parameter let's say theta 0 was
78:52 - here to be
78:53 - there i want to be here too then you
78:55 - update it out one to be little bit 2.1
78:57 - then your costs and decreases then you
78:59 - do the same for getting into the
79:02 - global optimum over here okay
79:04 - like this okay so here's an equation for
79:07 - the same so
79:09 - how's the equation
79:11 - uh you just uh
79:13 - i'm doing it here theta is a for t is
79:15 - just means of taking out a partial
79:16 - derivative
79:18 - j of theta
79:19 - equals the one over m this this equation
79:22 - after deriving from cos function the
79:24 - decision equation forms i equals to 1
79:27 - all around to the m x i minus y i
79:31 - okay
79:32 - and then you just add up some some kind
79:34 - of um x j times x j
79:37 - okay so this this is your calls function
79:39 - that's it this this is the taking of the
79:41 - partial deliberative although it might
79:44 - change a little bit because everyone has
79:45 - a different kind of uh but it's but it's
79:48 - similar to many of them okay and then
79:51 - you just take out the partial derivative
79:53 - of your cos function j of theta and then
79:56 - you uh update the theta by the by taking
79:58 - out the gradient then you update the
80:00 - data like this theta is a theta z minus
80:03 - the learning rate alpha and this is your
80:05 - uh this is your pre-previous theta and
80:08 - this is a new theta is updated theta and
80:10 - you are taking another partial
80:11 - derivative of cos punch it and it's just
80:13 - the same you just tweaks your parameter
80:15 - and checks if your cost function is
80:16 - decreasing or not okay
80:18 - okay so we are done with the legislative
80:20 - question and i really hope that you
80:22 - enjoyed so let's recap recap and then a
80:25 - little bit go further into vectorization
80:27 - of this code
80:28 - okay so what we have seen we have seen
80:30 - hypothesis and hypothesis is given by
80:32 - the
80:33 - this sigma of z and is the simple 1 over
80:36 - 1 plus e to the power minus e and z here
80:39 - theta transpose to x okay and then what
80:42 - you do you have a cost function for
80:43 - getting the
80:45 - accuracy different model uh this j of
80:47 - theta which is equal to the minus one
80:49 - times y i
80:51 - the log of this is this is that using
80:54 - phi and
80:55 - and for m training example you have that
80:57 - and the gradient descent you just update
80:59 - the this
81:01 - where you just updated theta and theta
81:03 - say minus the learning rate alpha and is
81:06 - take out the partial derivative of your
81:07 - cost bunch of j of theta okay and the
81:09 - alpha here is simple the datum is the
81:12 - rate of learning that we have seen
81:14 - linear regression okay
81:16 - okay so we have seen so far and now it's
81:18 - time for getting into more detail about
81:20 - vectorization uh what's the
81:22 - vectorization means so factorization
81:25 - means is
81:27 - uh you just you hear you are taking some
81:29 - amount of time but if you want to do at
81:31 - once if you want to do all the
81:33 - calculation at once so here is a
81:36 - vectorized code for
81:38 - uh
81:38 - gram cost function okay so i'm right
81:40 - writing for cos function which is a
81:42 - vectorized code so here it is minus 1
81:44 - over m times y transpose times the
81:48 - taking of the dot product between y
81:50 - transpose dot h
81:53 - plus 1 minus y t
81:56 - and transpose
81:58 - dot
81:59 - log
82:00 - of 1 minus h okay and h here is your
82:03 - model predicted and y here is a ground
82:05 - throughout okay and as we had just
82:08 - vectorized the code little bit
82:10 - to get your
82:11 - job done okay and a good way okay so the
82:15 - gradient descent also a little bit
82:16 - vectorized so here is a gradient descent
82:18 - theta
82:21 - this theta minus the learning uh this is
82:24 - a partial derivative uh learning rate
82:26 - alpha
82:28 - m times
82:29 - x transpose dot
82:31 - h minus y
82:33 - okay so this is then this is what you
82:35 - get after deriving your partial
82:37 - dedicative
82:38 - okay so this is the basic thing that's
82:40 - you should uh keep in mind about uh when
82:43 - performing legit regression and i really
82:45 - hope that you have enjoyed till now and
82:48 - now if you if you can see but let's
82:50 - summarize a little bit so that you can
82:51 - get a more better feel what we have seen
82:53 - so far
82:54 - okay so legislation is a classification
82:57 - algorithm that will classify our example
83:00 - um that will give the probability after
83:03 - you just apply the sigmoid to the z then
83:06 - you get the probability means in between
83:08 - zero and one you just get between zero
83:10 - and one and then what you do you simply
83:12 - uh take a threshold means if it is zero
83:15 - if it is the if your output is greater
83:17 - than 0.5 then you make it as a one
83:20 - otherwise you make it a zero okay as a
83:22 - convention we take one as a positive
83:23 - indication means that the the image as a
83:26 - as a cat is a positive indication and
83:28 - zero at the images are not cat then it's
83:31 - a negative indication okay you can take
83:33 - anything but for convention you do this
83:35 - kind of thing
83:36 - okay pretty much easy what i'm trying to
83:38 - say over here okay
83:40 - so we have the hypothesis and we have a
83:43 - cost function for a checking accuracy
83:44 - for modern we have a gradient reason for
83:46 - getting your best optimal theta and
83:47 - again we are only learning theta over
83:49 - here using the gradient descent
83:50 - algorithm okay so now i think we are
83:53 - done by the legislative regression and
83:56 - in the next section we will go over to
83:59 - uh
84:00 - project which is breast cancer detection
84:01 - system and then we'll go a little bit
84:03 - further into understanding the support
84:06 - vector machine okay and i really hope
84:09 - that you will enjoy that section also so
84:10 - let's meet at the next section okay so
84:12 - here i am on my jupyter notebook and you
84:15 - can download a jupiter notebook by
84:17 - searching online how to download the
84:19 - juba jupiter notebook and you can follow
84:21 - the tutorials to download a jupiter
84:23 - notebook okay so uh
84:26 - what we will do we will first start with
84:29 - uh
84:29 - important libraries then we will load
84:32 - the data we will understand what data we
84:34 - are working on and then we will follow
84:36 - the feature engineering then we will see
84:39 - how to select features we will do
84:41 - exploratory data analysis like data
84:43 - visualization and data analysis and will
84:46 - perform feature engineering and then
84:47 - before and then we'll see how to select
84:49 - the features on from the correlation of
84:52 - the features and you know you don't need
84:55 - to have any kind of experience with
84:57 - pandas or although
84:58 - you can have a look if you want to in
85:00 - detail but you don't have to be expert
85:02 - in all of these if you are just this is
85:04 - just a beginner project you can also
85:06 - modify it and put it on your resume and
85:09 - make make some changes and what you can
85:11 - do you can save this model and simply
85:14 - deploy it over a website okay okay so i
85:17 - will talk about deployment later on
85:20 - but before that uh let's let's walk
85:22 - through let let me make you walk through
85:23 - this project so first of all we are
85:26 - importing the libraries first we are
85:27 - importing the numpy snp and we are
85:30 - importing np as allies uh pandas as pd
85:33 - pde is also alive to short form a name
85:36 - plotly is another great visualization
85:38 - library but i really use it i don't want
85:41 - to use it for now but in future you can
85:44 - use it plotly just just wanted to show
85:45 - you i uh seaborn which i'm going to use
85:49 - here and mathplotlab is also a
85:51 - visualization library that i'm going to
85:53 - use over here and this macbook live in
85:55 - line tells you to use a matplotlib in
85:57 - the back end okay uh it's kind of a tell
86:00 - smart plot clip to choose the to plot
86:02 - the images in the backend use use the
86:04 - jupyter notebook as a backend okay so uh
86:07 - first of all uh this is the learning
86:09 - thing so we will load the data from the
86:12 - scikit-learn library scikit-learn
86:14 - library is a famous library for machine
86:16 - learning so we'll load the data sets
86:17 - from loadbuster which is a boston house
86:20 - price prediction will make boston house
86:21 - price prediction so you so we want a
86:24 - data set of that okay then we
86:26 - instantiate our
86:28 - load boston and then we take our x which
86:31 - is the data i will tell you what is x
86:33 - and y over here and y which is a load
86:35 - boston.target in our previous tutorials
86:38 - in the introduction to machine learning
86:40 - we have a talk about x and y variables x
86:43 - variables is the independent features
86:45 - which we which which we use to predict
86:47 - the model and this is the y which is the
86:50 - target variable because it's
86:51 - unsupervised so we know what our output
86:53 - is that we know what our output label y
86:55 - is okay so um we will be given this and
86:59 - x and y is the target variable which
87:01 - will be in case in this case is the
87:03 - sales price and this is the features
87:05 - okay and then i call pd.data frame and
87:07 - it con
87:09 - constructs a data frame and we give x
87:11 - which is the features and we give the
87:13 - name of the columns dot feature names
87:15 - there is a dot attribute feature names
87:17 - to get the names of the columns
87:19 - automatically okay and then we make one
87:21 - column here we are making one column
87:24 - which is a sale price we are making a
87:25 - sale price and then we are making it y
87:28 - over here okay ma why why means lord
87:31 - boston.target either you can make this
87:33 - also like this
87:34 - either you can make this also it's just
87:35 - the same okay y is just a target
87:37 - variable and if you just run this now
87:40 - you can see this is the data frame um
87:42 - here you have a crime rate per capita
87:44 - that let's see the column distribution
87:46 - so i just first see let me show you what
87:49 - we have done these are the x variable
87:51 - till s l stat these are the x variable
87:55 - and this this is the y variable that you
87:57 - use to predict and you may think yeah
87:58 - use 24.0
88:00 - means 24.0 is the dollars is just the
88:04 - price of the house no the price of the
88:06 - house is given 20.0
88:09 - thousand dollars okay so you can so just
88:11 - just just we will see the whole thing
88:13 - just a second okay so this is the data
88:15 - frame that we constructed okay so now
88:17 - let's take a look at what data we are
88:19 - working on so there are 506 rows and
88:22 - there are 30 numeric and categorical
88:24 - columns and with the median value
88:26 - attribute 14 which is our target
88:28 - variable here i'm giving given is a sale
88:30 - price name but you can give it a median
88:32 - value it's usually the target variable
88:34 - okay so here is the column name is the
88:36 - crime is the per capita rate then the
88:39 - proportion of the
88:41 - residential land proportion of a
88:43 - non-retail business which knocks age
88:46 - what's the proportion of average number
88:48 - of rooms per dwelling in stratfor you
88:50 - can wait over here and the last which is
88:52 - the
88:53 - favorite the target variable which is
88:55 - the median value of the which is the
88:57 - sales price in this case in a thousand
88:58 - dollars so 24 thousand dollars now you
89:01 - know your dream has gone out i think so
89:04 - okay so you're going to read it over
89:06 - here just just you can use dot d c e d e
89:09 - s e r because it is available in the
89:11 - cycle learn so you have this kind of
89:12 - thing to see the information about that
89:15 - data set but in real world we will work
89:16 - on real world data sets so you will see
89:18 - how uv download how we process etc okay
89:21 - so let's understand a little bit more
89:23 - about the data we look at the shape of
89:24 - the data which is 506 rows and 14
89:26 - columns means rows and then columns then
89:29 - your dot input tells us the information
89:31 - of your data which is non-null values
89:34 - means what are the data types and is
89:36 - there any null values into that null
89:38 - means missing values into that column
89:41 - okay and all the data sides are float
89:43 - what is the memory usage etc okay and
89:46 - let's uh dot describe will tell you the
89:48 - mean of that particular column the
89:50 - standard deviation the minimum 25
89:52 - percent of that 70 percent max count etc
89:56 - okay so we had seen how what data we are
89:59 - working on these are the features which
90:01 - is the x variable and this is the
90:03 - target which is why which is a
90:04 - supervised learning problem as we can
90:06 - see over here okay
90:08 - okay so let's just take a look at the no
90:10 - you can use data dot is no dot sum and
90:13 - you can see over here that we have the 0
90:15 - 0 0 all the way and then we can plot a
90:18 - pair plot sns dot pair plot which will
90:21 - plot all the things which with respect
90:23 - to every feature so you can see over
90:24 - here that we are just plotting the pair
90:26 - plot uh you can see but if you we we do
90:29 - not get a lot of information from this
90:31 - pair plot because it's very kind of
90:33 - small and we cannot see what data is it
90:35 - is it pointing on etc okay so we have to
90:38 - definitely take care of that to do to
90:40 - check more uh visual visualization that
90:43 - i made okay just wait for a few seconds
90:45 - then it will
90:46 - show up
91:41 - okay so it's plots and we are unable to
91:43 - see this kind of thing and we are unable
91:45 - to see so it's very hard to see this so
91:47 - what what we do let's let's take out and
91:49 - let's just take all the inferences from
91:51 - the sales price this is which is the
91:52 - target variable let's do some analysis
91:55 - so we plot a distribution plot and you
91:57 - can see over here this is a little bit
91:59 - skewed we want it is we are we are
92:01 - seeing over here this positive skew but
92:04 - here we can add some transformation so
92:06 - what's the seek skewness and word sum
92:09 - could notice so here we have one point
92:11 - one zero eight zero nine eight and one
92:13 - point four nine five one nine seven
92:15 - which are which this this will help us
92:17 - to find out liars and outliers are those
92:20 - who are far away let's say that you are
92:23 - working on uh
92:25 - age okay so uh age is 20 uh 20 years old
92:29 - 50 years old but let's say 150 years
92:32 - this is the outliers okay these are the
92:34 - outliers
92:35 - okay those who are exceptional those
92:38 - were exceptions of the data frame okay
92:41 - so we have to take care of this but
92:42 - before that let's see some relationship
92:43 - with each and every column one you have
92:45 - taken two columns you can try different
92:47 - different columns
92:49 - so
92:49 - where there is
92:51 - a little bit crime there is the sale
92:53 - price is very high and there is a lot
92:54 - more crime there is sale prices very
92:57 - very low okay and what's the age you can
93:00 - also see and you can see over your
93:02 - 100 years old has been sold uh in a
93:04 - smaller rate and uh 20 years old has a
93:07 - little little bit higher ray and you can
93:10 - see see the data visualization over here
93:12 - okay and you can see over here that i've
93:13 - imported sci pi which is again that like
93:15 - numpy i'm just taking out the norm and
93:17 - the skewness so you just plot a
93:19 - distribution plot for seeing this kind
93:22 - of thing means uh for a normal
93:24 - distribution if you know what normal
93:26 - distribution you are just plotting the
93:27 - normal distribution and we and this is
93:30 - your actual this black line and you have
93:32 - this blue line so you have to transform
93:34 - it a little bit so your
93:37 - new which is uh two trend
93:39 - mean is 22.53 and sigma is 9.19 okay so
93:43 - these are some if you know what python
93:45 - you should know about these kind of for
93:47 - formatting etc okay and this is the qq
93:50 - plot which will help us to see the
93:52 - coordinate quantiles which is uh order
93:55 - values you can search more on the
93:56 - internet or go on wikipedia to learn
93:58 - more about this but to our main main
94:00 - focus will be this uh sales price means
94:03 - distribution plot okay so let's run this
94:05 - let's try let's add let's add a
94:08 - log let's let's uh transform our sale
94:11 - price to a little bit more accurate so
94:14 - now you can see over here that is his
94:16 - skewness is over now we have just
94:18 - applied a transformation over here log
94:20 - one p and it's now good okay to avoid
94:23 - outliers
94:24 - okay
94:26 - and this quadrant trial is also uh
94:28 - removed okay so data correlation what a
94:31 - correlation first of all correlation is
94:33 - the is a relation between features okay
94:36 - so if the if it is one then it is uh
94:39 - positive correlated then it's minus one
94:42 - very negatively correlated you can
94:44 - search more internet about it because
94:46 - it's not a statistics class so you see
94:48 - if the diagonal is one all the features
94:49 - are perfectly correlated okay so how do
94:52 - we select the features which are highly
94:54 - correlated okay the features how we
94:56 - select if we have taken the absolute
94:58 - value of the sale price and we are
95:00 - taking the highly correlated feature
95:02 - from this uh
95:04 - statement and there is 12 feature that
95:06 - we get that is highly highly correlated
95:08 - you can choose this but i'm not going to
95:10 - choose you can either
95:12 - delete the rest of the columns except
95:14 - these two all okay and let's just start
95:17 - with model building so you just employ
95:19 - important split and train test please
95:20 - simply from divide your data into
95:22 - training and testing means um
95:25 - let's say you have 80 of the data so
95:27 - sorry hundred percent it will take
95:29 - eighty percent for training and twenty
95:30 - percent for testing and use draw because
95:32 - you don't want x to be sales price and
95:35 - why to be the sales price okay and then
95:38 - you test size then the band random state
95:41 - will tell you
95:42 - the
95:43 - uh means every time you run the data
95:46 - should not be changed
95:47 - okay so if you run this now let's take a
95:50 - look at the shape 404 and 13 columns for
95:53 - training and furniture for testing and
95:56 - for them for labels and one and two
95:57 - labels okay so let's let's start with uh
96:01 - let me make one more little little bit
96:03 - more uh so that it should be clearly
96:05 - visible okay so you just uh import uh
96:08 - from scikit-learn which is a linear
96:10 - regression and you just instantiate it
96:12 - and then you fit the model x strain and
96:14 - y train which we have used for training
96:16 - and why training extreme are the these
96:18 - are the input and this is that by a
96:20 - target variable and then if you run this
96:22 - now it's instantiated now we can now we
96:25 - can make prediction okay so you can see
96:27 - over the actual label because we know we
96:29 - we know what y test is 0 because this
96:32 - actual label and this is the prediction
96:34 - which is 3.36 is a predicted value from
96:37 - the model and three point two one
96:39 - eight eight eight eight seven five eight
96:40 - two nine is etcetera is the
96:43 - is the actual value which is little bit
96:45 - uh different from this but it's um good
96:48 - for perform very very good in terms of
96:50 - linear regression as we have seen so far
96:52 - okay now if you want to check the
96:54 - accuracy for checking the accuracy we
96:55 - have seen a cost function you can run
96:57 - this and msc mean square error and let's
97:00 - say if you want to see msc there is
97:02 - 0.035 which is good and if you want to
97:05 - take out the rmse the square root you
97:07 - just npd or square root and you are
97:09 - getting the rmse so you can just print
97:11 - it out our msc
97:13 - okay and you have seen that it's pretty
97:14 - much good okay you will learn more about
97:17 - how we can improve this by using xgboost
97:19 - tagging boosting etc later on okay now
97:22 - we have done our full prediction project
97:24 - the code will be in uh
97:27 - my github which is in the description
97:29 - down box below there is a lot more
97:30 - project which which is available in
97:32 - computer vision natural language
97:33 - processing which you can take a look if
97:34 - you want to my projects okay so now i
97:37 - think i have not quoted just now because
97:39 - it will take a lot of time so i just
97:41 - wait and have done just annotated each
97:42 - and every line of statement
97:44 - okay so if you have any kind of prop in
97:45 - a search on internet because you have to
97:47 - master google to if you if you have
97:49 - encountered any kind of problem and in
97:51 - the next tutorial we'll be talking about
97:53 - regularized linear models which we'll
97:55 - talk about lasso and which which we'll
97:57 - also use in this uh
97:59 - to check uh as a last one regression and
98:02 - a ridge regression okay so let's let's
98:04 - get into the
98:06 - next uh
98:07 - section okay so now we have talked to
98:10 - talk talked about a linear regression
98:12 - and we have made one project now it's
98:14 - time for getting into the regularized
98:17 - linear models linear models okay so uh
98:22 - if you remember that we have a pointed
98:25 - out or some problem which is uh
98:28 - overfitting which is overfitting which
98:30 - we have pointed out earlier
98:32 - okay so how does overfitting happen
98:35 - let's say if your model has learned too
98:37 - much so let me draw one uh
98:39 - x and y plane and let me draw some data
98:42 - points okay so these these are the data
98:45 - points and let's see or you have a
98:47 - complex model which is a complex
98:49 - function which maps your input variable
98:51 - to output variable so you just uh make
98:53 - the complex function like this which is
98:56 - which is touching each and every line so
98:58 - let's say a new uh example comes in and
99:01 - it's making a bad prediction so you can
99:03 - see over here it learned too much onto
99:05 - the training data which are inner
99:06 - trained and it's it is it is very going
99:10 - bad it is it is uh not generalizing well
99:13 - onto the new examples okay so that's
99:16 - that's called overfitting if your model
99:18 - working better best 100 accuracy under
99:21 - training and working worse on the
99:23 - validation accuracy then your model is
99:26 - likely to fit overfitting
99:28 - okay so how it is cost let's you have a
99:31 - lot of features and you um let's say a
99:33 - thousand features and so it will learn
99:35 - obviously the complex functions and then
99:38 - it will perform very very bad okay so uh
99:41 - for that we have some solution and the
99:43 - solution are uh
99:45 - either uh you do reduce some features
99:47 - reduce some features
99:49 - uh reduce some features this is you can
99:52 - do this another thing is what you can do
99:53 - you can uh this is the same as like this
99:56 - regularization
99:58 - in simple terms regularization is just
100:00 - uh eliminating the features that are not
100:03 - useful okay so it is just equals to this
100:06 - so we give another name which is called
100:07 - the regularization so let's see some
100:09 - other regularization techniques so the
100:12 - first one is lasso regression so let's
100:14 - see a lasso regression
100:16 - so what is last regression last
100:18 - regression is a regularized linear
100:20 - models what we do we just add a simple
100:23 - term with a simple a regularization term
100:27 - at the
100:28 - at the end of the cost function let's
100:29 - say this this term lambda 1 over 2
100:33 - i equals to 1 all the way down to the n
100:36 - theta squared i
100:38 - okay so you this is uh this is for a
100:41 - ridge regression this is for a ridge
100:43 - regression
100:45 - okay so this is for raised regression i
100:46 - will talk about lasso just just after
100:48 - this okay so just you add this at the
100:51 - end of the cost function so your now new
100:53 - cost function will become like this 1
100:56 - over m plus i equals to 1 all the way
100:59 - down to the m
101:00 - uh theta transpose x i and this this is
101:03 - the model predicted minus y i
101:06 - squared plus your regularization term
101:09 - uh this one i equals to 1 all the way
101:11 - down to the n theta squared i
101:14 - okay so you can do like this now let's
101:16 - let's understand what is doing it is
101:18 - just let's say you have some features
101:20 - which is the let's say the size of the
101:22 - house let's say the price uh this is the
101:24 - number of fans number of bedrooms and a
101:27 - number of uh grass okay num number for
101:30 - grass so you can see whether this this
101:32 - this seems to be a less important
101:33 - feature so it will it will simply make
101:36 - the theta means the parameter feature
101:38 - means the feature weight of this
101:41 - column to be zero
101:43 - okay so it simply penalizes or closer
101:45 - and closer to zero in rich regression it
101:48 - makes the feature weights closer and
101:51 - closer to zero okay so
101:55 - what is doing it is
101:56 - whatever the less important features are
101:58 - is just penalizing the theta of that and
102:01 - the theta is the is used to make
102:03 - prediction and let's say theta times the
102:05 - number of graphs equals to prediction so
102:06 - let's see it's a very very very very
102:08 - small okay so it just penalizes your
102:10 - theta okay so that's a ridge regression
102:12 - is doing just penalizing or eliminating
102:15 - the or
102:16 - by how how it eliminating just making
102:18 - theta to be equal to zero okay but if a
102:21 - but in ridge regression it is it is
102:23 - making closer and closer to zero but in
102:26 - case of last regression it is simply it
102:29 - is in case of last regression in case of
102:32 - lasso
102:33 - regression i'm talking about lasso
102:34 - regression it's it's whatever the less
102:37 - important feature are it simply makes it
102:39 - simply eliminate it simply make the
102:41 - theta zero so whatever let's say theta
102:43 - times the number of a graph uh so theta
102:46 - equals zero zero times the let's say
102:48 - seven which is equal to zero so this
102:50 - feature says eliminate net so that's a
102:52 - lasso is very strict okay so these two
102:55 - and just just to use l2 norm um in in
102:58 - that case in range regression you are
103:00 - using l1 norm but in lasso you're using
103:02 - l two norm okay just adding the
103:05 - regularization term which is like this
103:07 - uh
103:08 - at the end of the cost function i equals
103:10 - to 1 all the way down to the n the
103:11 - absolute value i and one yeah there's
103:14 - this one okay okay so uh but one one
103:17 - more thing that you can see over here
103:19 - that we we do not penalize our theta
103:22 - zero which is the biased term which is
103:23 - only the bias term so we don't want to
103:25 - penalize this so we start with i goes to
103:28 - 1 so we start with i equals to 1 rather
103:30 - than starting with i 0 so we do
103:32 - separately of all the things okay so
103:34 - what
103:35 - what what we do
103:36 - we just uh take um we just start with
103:40 - the
103:41 - i equals to 1
103:42 - all the way down to the j which is the
103:45 - theta we do we separately do zero okay
103:49 - uh and it's and i i think it's very
103:51 - clear let me make you clear what i'm
103:52 - saying i'm saying that you do
103:55 - let's say for theta zero j of theta zero
103:57 - you do separately this you do separately
104:00 - this without the regular regularization
104:03 - term without okay but uh for other other
104:06 - thetas one all the way around to the j
104:08 - you do you do at the regularization term
104:11 - at the end of
104:13 - the equation and then you separately
104:15 - update this also uh this theta zero and
104:17 - you separately update this theta 1 and
104:20 - you just take this as a gradient of this
104:23 - theta for theta 1 all the branches of j
104:25 - and this gradient this the gradient of
104:28 - this cos function theta 0 for updating
104:30 - your theta 0 and getting the best theta
104:32 - 0 okay so you do not want to penalize
104:34 - because only the bias term you don't
104:36 - want to penalize this
104:37 - okay so i think that is very clear to
104:39 - you and again for recap regularization
104:42 - is just penalizing or eliminating the
104:44 - less important features by making the
104:47 - parameter weights equals to zero
104:50 - okay now i hope that's pretty much clear
104:53 - now we hope that is very clear and in
104:55 - the next tutorial we'll be working on
104:57 - two uh uh
104:59 - last regression sorry uh largest
105:01 - regression which is the now we'll start
105:03 - with the specification uh which is which
105:05 - will cover logistic regression as a same
105:08 - as a linear regression but it's a
105:09 - classification not regression okay so
105:12 - let's uh
105:13 - i will be happy to see you in the next
105:15 - section
105:17 - okay so now we'll talk about a
105:19 - regularization order one other favorite
105:21 - topic that i like to talk on i will take
105:23 - around 10 to 15 minutes to complete
105:26 - something called as a regularization
105:28 - topic and i think this is one of the
105:30 - most important topic in machine learning
105:32 - or when maybe you go to deep learning
105:35 - okay so we learned about uh l1 arm l1
105:38 - and l2 regularization which is often
105:41 - called a rich and lasso regularization
105:44 - and i hope that you will understand that
105:46 - and why what is a regularization so
105:49 - first of all this is the problem that
105:51 - should come into mind and what is and
105:54 - why regularization i think these two
105:57 - questions must be your first question
105:59 - over here so but before that i'm going
106:01 - to highlight one uh something called as
106:04 - overfitting and i think overfitting um
106:07 - you all know but just as uh just to
106:09 - those who are forgetting about it let's
106:11 - uh revisit that
106:13 - so uh let's assume that you have an x
106:16 - and y plane x in x here
106:19 - and y here okay and here is here you
106:22 - have a data point okay so you have a
106:25 - data point like this
106:28 - okay and you fit it and your model
106:31 - learns a lot your model learns a lot
106:34 - means your model is performing very very
106:36 - best on the training set let's take an
106:38 - example that it performs it is it is the
106:41 - the error the cost function over to here
106:44 - means that the residual error or the
106:46 - cost function over here will be
106:48 - approximately or very very low to zero
106:51 - and accuracy or on the training set will
106:53 - very very high because this tries to
106:56 - touch each and every point over here
106:58 - okay and here your cost function means
107:01 - the difference between your predicted
107:04 - and actual value um summation of i
107:07 - equals to 1 all around the m will be
107:10 - approximately equals to zero and if it
107:12 - is if it is if you if if it is touching
107:15 - each and every point so it's obvious
107:18 - that it is very very best onto the
107:20 - training set on which it is trained so
107:22 - it is it has learned a lot but let's for
107:25 - the sake of example some example come
107:27 - over here
107:28 - and some example come over here so what
107:31 - will happen
107:32 - your model will fail to generalize well
107:35 - under the testing set okay so that's why
107:38 - i'm telling that your model will fail to
107:40 - generalize well on testing set so you
107:42 - can assume that that this this this you
107:45 - can you can say that this this model is
107:48 - one overfitting because you find out
107:50 - that your model is performing a very
107:52 - very best on a training set and then if
107:55 - you evaluate it then you will see that
107:57 - your model is performing very very bad
107:59 - okay so that's the sign of overfitting
108:02 - so we we always wanted to reduce the
108:04 - overfitting so how we how can we reduce
108:07 - our overfilling we have something called
108:09 - as a regularization and how it happens
108:12 - it can happen if you have a lot of
108:14 - features a lot of features
108:16 - a lot of features or your polynomial
108:18 - degree is very high if you're using
108:20 - polynomial regression okay so the the
108:23 - measure for the problem is lots of
108:25 - features okay
108:27 - okay so
108:29 - now let's see uh how we can remove this
108:32 - uh how how we can prevent or how we can
108:34 - make our our model less prone to
108:37 - overfitting so some we have something
108:39 - called as regularization
108:42 - regularization will help you to
108:44 - eliminate to eliminate the features to
108:48 - eliminate the features which are less
108:50 - important so again i'm saying it will
108:53 - help you it will
108:55 - help you
108:56 - it will help you
108:58 - to eliminate to eliminate
109:02 - the features to eliminate the features
109:05 - which are
109:06 - which are
109:08 - which are
109:09 - less
109:10 - which are less helpful or contains less
109:15 - less information okay so it will
109:17 - eliminate that so that's how we that's
109:19 - how that's what the regularization is
109:21 - doing it is saying that if the feature
109:24 - is less important remove that okay or
109:26 - make the make their respective and make
109:29 - their respective hyper parameter to be
109:31 - equals to zero okay make the respective
109:33 - hyper parameter to be equal to zero
109:35 - means i make make the respective not a
109:37 - hyper primer make the respective theta
109:40 - to be zero so we will see we will see
109:41 - how what what it will do just just for
109:43 - as an example let's assume that it will
109:46 - help you to eliminate the features which
109:48 - are less helpful now let's see how
109:51 - how how it will do okay so let's assume
109:54 - let's assume that you're working on uh
109:56 - some problem which is house price
109:59 - prediction okay so so you're working on
110:01 - house price prediction and there you
110:03 - have some features so here you have x1
110:06 - so maybe
110:07 - the size of the house my favorite size
110:10 - of the house okay then x2 is maybe your
110:14 - favorite the number of fans in a house
110:16 - number of fans in a house okay number of
110:20 - x3 maybe the number of bedrooms number
110:23 - of bedrooms maybe another feature maybe
110:26 - another feature number of
110:29 - uh
110:30 - maybe some fan no no fancies or well
110:33 - maybe acs okay air conditioners so here
110:36 - we have four features okay
110:38 - and let's uh now what we'll do so we so
110:41 - for each for each feature for each
110:44 - feature for each feature x1 x2 x3 x4
110:47 - we'll be having some parameter weights
110:49 - we'll be having some parameter which
110:50 - like theta theta one times x one plus
110:55 - theta two times x two plus theta three
110:58 - times x three plus theta four times x
111:01 - four and you can see over here that we
111:04 - have this this is this called the
111:05 - hypothesis function so here these two
111:08 - only the these are the weights these
111:11 - these are the weights of these features
111:13 - and we only have to learn these weights
111:15 - by just tweaking it okay by just
111:17 - tweaking it tweaking means let's take an
111:19 - example i hope that you already seen a
111:21 - linear regression just as an overview
111:23 - that your theta was this equals to zero
111:26 - to two point one theta zero equals to
111:28 - two point one previously and you just
111:30 - take out the partial derivative of your
111:32 - cost function with respect to this theta
111:35 - and then you update the theta okay why
111:38 - and just see the linear regression part
111:40 - you all all will be very clear okay
111:43 - so here if you're if you're if you are
111:46 - being confused please go to linear
111:49 - regression part um you will be not able
111:51 - to further continue so please please go
111:53 - back and lay in your regression if
111:54 - you're not able to understand why
111:56 - what is theta and why it is okay so this
111:59 - theta is a wait for the feature and we
112:02 - can simply give let's take an example
112:04 - that our theta 1 is equals to 2 theta 2
112:07 - equals to 4 theta 3 equals to 2 okay and
112:10 - theta 4 equals to 2 okay so we can
112:13 - simply multiply so these f these thetas
112:16 - to be learned okay so um our user will
112:19 - give input
112:20 - let's say the size of the house so two
112:22 - times size of the house maybe 24 square
112:25 - feet plus uh then num number of fans
112:28 - though so four times number of fans
112:30 - maybe four plus number of bedrooms two
112:33 - times because here we have theta three
112:35 - equals to two let's assume that the user
112:37 - given two plus uh two times two times uh
112:42 - maybe
112:43 - number of ac is equals to one okay and
112:45 - this the the this this is the y hat of
112:48 - your model so here you learned some
112:50 - weights you learned some weights and
112:52 - usually you do the same you have some
112:54 - parameter weights you have some
112:56 - parameter weights which you learn by by
112:59 - tweaking or by changing and taking a
113:01 - look if it is if you if your model is
113:02 - performing best and we just take out the
113:04 - partial derivative of our cost function
113:06 - with respect to this theta and then see
113:09 - if our if our cost function decreasing
113:11 - if it is then we update the new theta
113:13 - and then we update our old theta with
113:16 - the new theta okay so that's that's
113:18 - that's what we are doing over here and i
113:20 - hope that you are understanding what i'm
113:21 - trying to say over here so
113:24 - just for an um just for this intuitive
113:26 - example i hope that you understood what
113:29 - i'm trying to convey over here can i
113:30 - convey you over here okay so let's
113:33 - assume that you have this now
113:35 - uh let's assume that this number of uh
113:39 - like your model is overfilling okay so
113:42 - what you do in regularization you apply
113:45 - something called as uh rigid so let's
113:47 - see the ridge regression what it does
113:50 - rich regression rich regression okay so
113:54 - the the equation for this regression is
113:57 - just add is just add a regularization
114:00 - term at the end of the cost function
114:04 - okay at the end of the cost function so
114:07 - again here we have theta 0 also here we
114:10 - have oops what happens
114:12 - here we have theta 0 also here we have
114:14 - theta 0 times x 0 just a biased term
114:17 - because then x 0 is always equals to 1
114:20 - okay so in the range of regression in
114:22 - ridge regression we add uh a
114:25 - regularization term so here here's what
114:27 - i'm here's what i mean so j of theta j
114:31 - of theta equals to 1 over m 1 over m
114:34 - plus 1 over m plus
114:37 - i equals to 1 all the way down to the m
114:40 - theta transpose theta transpose x i
114:44 - theta transpose x i minus y i
114:48 - squared plus i'm saying plus
114:51 - and here we have something called as
114:53 - learning rate
114:54 - and this is just alpha okay so don't
114:57 - assume that is the learning this is just
114:59 - alpha
115:00 - uh or you can say that someone can write
115:02 - it as a lambda okay so it is just a
115:04 - greek letter uh just within note okay so
115:07 - don't don't compare with that uh
115:09 - learning rate alpha do not compare here
115:12 - i've i will tell you i will tell you
115:14 - what is this what is what this alpha
115:16 - does
115:17 - 1 over 1 over 2
115:19 - i equals to 1 all the way down to the m
115:22 - theta square i
115:24 - okay so here we have added a new uh a
115:28 - new regularization term a regularization
115:31 - term over here a regularization term
115:34 - over here so what is this so this is
115:38 - simply what it does it's simply it
115:40 - simply make it simply take the features
115:43 - which are
115:44 - which are less important and make that
115:46 - parameter weights closer and closer to
115:48 - zero okay so what do i mean with this so
115:51 - for an example let's let's assume let's
115:53 - assume that uh that you
115:56 - that the number of
115:57 - your model this you using the eq this
116:00 - using this equation this is the l1 norm
116:02 - the it is the l1 norm okay so let's
116:06 - assume sorry l2 norm this is l2 norm
116:08 - okay in ridge regression we have l2 norm
116:11 - and here it's simply penalizing your
116:14 - theta who is the very less important so
116:16 - let's assume that the number of ac or
116:18 - modern model find out that the number of
116:20 - ac is less important so what it will do
116:23 - so uh theta 4 our indicating the number
116:26 - of ac though theta 4 is the weight of
116:28 - our number of ac then it will make theta
116:31 - 4 to be to be closer and closer to 0
116:34 - 0.0001
116:37 - okay so it penalizes your theta it
116:40 - penalizes your theta as it found as you
116:42 - as it found that your number of ac is
116:44 - less important so it penalizes your
116:46 - theta and whenever you are multiply with
116:49 - penalize
116:50 - penalize times the number of ac then it
116:53 - will be also very uh means low okay so
116:56 - that that just helps you to less prone
116:59 - to overfitting okay so it is not doing
117:02 - anything with your with your input value
117:04 - it is doing because if you multiply
117:07 - 0.0001 with whatever the number number
117:09 - feature it will be approximately zero
117:11 - points there is a reservation okay so
117:13 - like like that okay so what it does
117:15 - simply it simply eliminates or penalizes
117:20 - your theta value by just making closer
117:23 - and closer to zero okay so this is the
117:26 - l2 norm okay
117:29 - and here we have something called as
117:31 - alpha and alpha contains alpha contains
117:34 - how harsh or how strict to be on to the
117:37 - solent feature so let's assume that we
117:39 - have set up some alpha obviously we
117:41 - don't touch alpha inside learn but here
117:44 - let's assume that your alpha controls
117:46 - the strictness okay so if your alpha is
117:49 - large i think so if your alpha is large
117:51 - or lambda is large um
117:54 - some people may write this as a lambda
117:56 - also okay so don't uh don't be confused
117:58 - so if you had a lambda is large then it
118:01 - will make it it is making close and
118:03 - closer to zero now it will make theta
118:05 - four equals to
118:07 - zero fully zero okay so it simply
118:09 - eliminates it if you it's it is very
118:11 - strict if you keep this if it is very
118:14 - strict okay so it kit controls it
118:16 - controls the strictness
118:18 - but whatever i think okay but i think
118:20 - what i like to remember is controls the
118:22 - strictness okay so
118:24 - and here you can see that you are taking
118:26 - the l one norm and you are not taking
118:29 - off theta zero you are explicitly doing
118:32 - for theta zero because theta 0 is your
118:34 - bias term and you do not want to
118:36 - penalize your theta 0 theta 0 okay so we
118:40 - are not penalizing we are going from
118:41 - theta i equals to 1 all the way on to
118:43 - the m we are not going to i equals to 0
118:45 - we are going to each and every theta
118:47 - okay so we are not so we are not uh
118:50 - going to uh theta zero so we explicitly
118:53 - do for theta zero and we it's explicitly
118:55 - between two and tweak our theta or we
118:58 - take out the derivative of our theta
119:00 - explicitly okay because we don't want to
119:02 - penalize our uh bias uh sorry
119:06 - it's uh our biased term okay so this is
119:10 - the rigid regression okay so we have
119:12 - something called as a lasso regression
119:14 - lasso regression lasso regression means
119:18 - lasso regression is very very it's it's
119:20 - it uses l1 norm instead of l2 norm it's
119:24 - just the same it's just the same it's
119:26 - also penalizes the theta value but what
119:28 - it will do i will tell you okay so theta
119:30 - 0 theta 0 equals to whatever your cost
119:33 - function will be i'm just putting 1 2 3
119:36 - plus now i'm right regularized num
119:38 - writing the regularization term i equals
119:40 - to 1 all the way down to the m you're
119:42 - not penalizing again theta zero the norm
119:45 - of
119:46 - the norm of
119:48 - theta i
119:50 - okay so this this is what you and here
119:52 - you are taking the alpha norm okay so
119:54 - taking the norm
119:56 - you're taking the norm of your theta
119:58 - okay so here what if here you are
120:01 - applying the l1 norm so what it does if
120:04 - he if if the last regression is very
120:06 - strict just assume it's very strict
120:07 - whatever feature he finds whatever i'm
120:10 - saying i'm taking the gender as a he
120:12 - okay or whatever this this last
120:14 - regression finds whatever feature that
120:16 - less important he finds he will directly
120:18 - make that theta four to zero so here we
120:21 - assume here we taken theta four equals
120:23 - closer and closer to now then it lasso
120:25 - it will take a directly to zero okay so
120:27 - it is very harsh so the both have
120:30 - specific use cases okay so these are the
120:33 - this is called the l2 l1 norm and this
120:35 - is called the alpha norm okay so here we
120:38 - have started about a regularization in
120:40 - detail and i hope that you understood
120:42 - very very clearly and
120:44 - uh we have talked a lot and there is one
120:47 - more which is elastic net which you
120:48 - don't need to worry about now it's very
120:50 - kind of a
120:51 - just combination of both of them but
120:52 - it's not used in earth industry as we
120:54 - use this l1 and l2 norm okay so thank
120:58 - you for seeing this video about
121:00 - regularization and and you can head over
121:03 - to the next section to learn more about
121:05 - more about machine learning and
121:06 - completing this course okay so thank you
121:08 - for seeing this video head over to the
121:11 - next section
121:13 - okay so now we will talk about support
121:15 - vector machine in detail so that you
121:17 - could be more powerful in machine
121:19 - learning or you or you will be having a
121:21 - powerful algorithm in your toolkit of
121:24 - machine learning so support vector
121:26 - machine is a supervised learning and
121:28 - learning algorithm which is a both for
121:31 - classification and regression we have
121:33 - seen logistic regression and legislation
121:36 - is for classification
121:38 - and linear regression is for regression
121:41 - so support vector machine is for both
121:43 - which is classification which is
121:45 - classification
121:47 - and one more which is
121:49 - a regression task okay so regression
121:53 - task
121:54 - so support vector machine can be used in
121:57 - classification either your output and
121:59 - degree value or it can be used in
122:01 - continuous value
122:03 - okay okay so uh let's i will take
122:06 - diabetes support like the machine but
122:09 - before that uh let's uh let me tell you
122:12 - what we are going to study in this
122:13 - section so we start with the
122:15 - introduction of support vector machine
122:17 - then we'll go further into what svm do
122:20 - and then we'll talk about linear heart
122:22 - margin then we will typically go further
122:24 - into non-linear specification and then
122:26 - we'll talk about empirical risk
122:28 - minimization
122:30 - and then a semi supervisor is
122:31 - transductive um
122:33 - svm and then we will talk about svr
122:36 - which is
122:37 - support vector regression okay and the
122:39 - next section we will do one project
122:40 - which is stock price prediction project
122:43 - okay
122:44 - okay so uh what is svm what actually svm
122:48 - does it's it's it's it's simply just
122:51 - what is like this so let me draw one x
122:53 - and y plane so here is my x and y plane
122:56 - i hope that's that's beautiful
122:59 - so here is my x and y plane and let let
123:02 - me make a linear data okay
123:05 - so here we have the one day data point
123:09 - and another data point is over here
123:14 - okay so we have like this
123:16 - and
123:19 - then we have this data okay so let's
123:21 - assume that that you're working on cat
123:24 - and a non-cad uh brick off recognition
123:27 - system okay so you are working on cat
123:30 - and non-cat recognition system so what
123:32 - actually svm does is
123:35 - here you can see over let's assume that
123:37 - white color
123:38 - is for
123:40 - cat images means the labels are cat and
123:42 - blue color let's take as a non-cat okay
123:46 - so these are data and what svm does it
123:49 - makes its its constructor hyper hybrid
123:52 - plane it's construct a hyperplane like
123:54 - this
123:55 - let's construct a hyperplane like this
123:59 - okay and now whatever new point come on
124:02 - or beyond any here then then this
124:05 - example will be cat otherwise if
124:08 - something
124:08 - come here then it will be non-cad okay
124:13 - so this is what svm does um but it's i
124:16 - will this is not the full procedure
124:18 - i will tell you but here what it does it
124:21 - simply construct a hybrid plane and two
124:24 - parallel hyperplane
124:25 - and uh one
124:27 - two parallel hyperplane
124:29 - two parallel hyperplane
124:32 - with this margin okay these are called
124:34 - the margin so it always tries to
124:36 - maximize that margin so it may sound a
124:38 - little bit
124:40 - kind of confusing so let's draw it again
124:42 - to
124:43 - let let let me show you once more time
124:45 - what actually it does okay
124:48 - so here is the white examples
124:51 - and here is your blue examples
124:54 - is it non-cat and not cat so what it
124:57 - does is construct a hyper plane and a
125:00 - two
125:01 - two parallel hyper plane over here
125:04 - two parallel hyperplane like this
125:07 - okay so and this is called the margin
125:09 - this is called the margin
125:12 - and svm always tries to maximize this
125:15 - margin keeping away the nearest data
125:18 - point far away from the hypomaine what
125:20 - i've said it's very uh crucial to listen
125:23 - what i'm saying i'm saying that what svm
125:26 - does it simply construct a hyperplane
125:28 - and a two parallel hyperplane that
125:30 - separates the data point and at a
125:33 - maximum margin okay
125:35 - so it always wants to as we always wants
125:38 - to maximize that margin in such a way in
125:42 - such a way in such
125:44 - a way
125:45 - so that the nearest data point so that
125:48 - the nearest data point let's say x i is
125:50 - far away from the hyperplane this
125:52 - hyperplane okay
125:54 - it's far away from the hyperplane so
125:56 - that uh so that it would be easily so
125:58 - that whatever comes here then it would
126:01 - classify as an um as a knock as a non
126:04 - cat whatever comes here or here it will
126:07 - be classified as a cat okay and then and
126:11 - and what i'm saying that the nearest
126:13 - data point and the nearest data point is
126:16 - far it should should be the far away
126:18 - from the hyper plane
126:20 - here okay so it would be here so these
126:22 - are called the support vectors who are
126:25 - the nearest data point
126:27 - from the hyperplane okay and that is
126:30 - supported by these are the
126:32 - support vectors which supports this
126:35 - parallel hyperplane to separate this
126:37 - okay again this may sound a little bit
126:39 - unconfusing so let's revisit this again
126:42 - in a more detailed way so let's say uh
126:45 - let let's take another another example
126:47 - that we are building a person has a
126:49 - cancer or a non-cancer i think malignant
126:52 - uh let's say a non-cancer okay so you
126:55 - build uh x y plane so let's build one x
126:58 - and y plane and then you put uh this
127:01 - blue examples which is which indicates
127:03 - as a cancer and this white example which
127:07 - indicates is a non-cancer okay so what
127:09 - is um does simply construct a hyper
127:12 - plane like this oops
127:14 - it simply construct a hyperplane and a
127:16 - two hybrid plane like this
127:19 - and a two hybrid plane
127:21 - and this is this is called the margin
127:23 - and it always tries to maximize this
127:25 - margin so that in such a way in such a
127:28 - way that the nearest data point is far
127:31 - away from the from the main hyperplane
127:34 - okay so you can see over here that this
127:36 - this is the nearest data point is far
127:37 - away so these are called the support
127:39 - vectors these are called the support
127:41 - vectors okay pretty much easy now i
127:44 - think that's is much clearer uh with
127:46 - that we have taken three examples now i
127:48 - think this is much clearer okay so it's
127:52 - me it may sounds you like it's just like
127:54 - a linear regression you have a linear
127:55 - data and you're just spitting a straight
127:57 - line with two hyperplanes what does this
127:59 - mean it obviously means like linear
128:01 - regression but if you come to the more
128:03 - in detail the data are not
128:05 - not linear okay the data never a linear
128:09 - so uh
128:10 - there are two kinds of svm there
128:12 - the first kind of is hard margin
128:16 - classification
128:18 - and soft margin classification okay so
128:20 - let's revis visit us a heart marching
128:23 - first and then we'll revisit uh soft
128:26 - margin okay okay so uh you here you can
128:29 - see over here all that
128:31 - uh this is just like a linear regression
128:33 - but wait for a few seconds few minutes
128:35 - then you will understand why it is not
128:37 - like cleaning your depression although
128:39 - it seems like that you could simply
128:41 - construct a straight line but equation
128:43 - and it's used for classification it's
128:45 - quite quite different okay
128:48 - okay so
128:49 - in
128:50 - it's called the linear svm the what we
128:52 - have seen is called a linear svm where
128:56 - we are constructing a simple hyperplane
128:58 - and separating two
129:00 - data points okay so what are hard
129:03 - margins hard margin means that we are
129:06 - not allowing any data point to come into
129:10 - that margin okay that's what the
129:13 - violating the hot margin so sorry
129:16 - highlighting the margin so we are not
129:18 - allowing any data point to violate that
129:20 - margin so in that way we end up being an
129:23 - overfilling or in that way we we very
129:26 - much um
129:27 - go we our our model is being started
129:30 - overfitted so let's see one of what i'm
129:32 - trying to say of here over over here
129:35 - so let's construct a hyper let's let's
129:37 - construct one x and y plane again so let
129:40 - me construct one x and y plane oops
129:44 - here is my x and y plane and let's uh
129:46 - let's just draw two data point again let
129:49 - me draw two data point like this
129:53 - okay and let's draw a white data point
129:56 - like this
129:57 - okay
129:58 - okay so and now what as we have got
130:00 - simply construct a straight line with
130:02 - two hyperplanes
130:04 - okay
130:05 - with this hyperplane
130:09 - okay so in hard margin we are not
130:12 - allowing any data point that generally
130:14 - of the it comes under in so we simply
130:17 - kind of do like this we simply kind of
130:20 - do means we simply uh minimize this
130:23 - margin like this
130:25 - so we are doing like this all it it is
130:27 - very strict hard margin is very strict
130:31 - hard margin
130:32 - is very
130:34 - strict the reason i'm saying is very
130:37 - strict because it does not allow
130:40 - any data point to come into that margin
130:43 - but in soft margin we allow some data
130:46 - points to violate that margin to avoid
130:49 - overfitting okay so that's what the soft
130:52 - margin and hard margin means hot margin
130:55 - which means we are not allowing any data
130:57 - point to come into that margin and soft
130:59 - production means we are allowing a
131:01 - little bit of data point to come in
131:02 - right between and the width is in the
131:05 - width of the margin this is the width of
131:08 - the margin is is is is uh is adjusted by
131:13 - c okay so
131:15 - if c is very very large then uh your
131:19 - fifth will be very very small like this
131:22 - okay it's let's say c equals to zero
131:24 - this is the margin my margin so this is
131:26 - my margin so let's say your c hundred c
131:29 - equals to hundred so your uh margin will
131:32 - be very very uh the width of the margin
131:34 - is
131:35 - is kind of a
131:37 - low means it's very slow kind of it's
131:39 - very small but if if if c equals to one
131:43 - then your the width of the margin will
131:45 - be very very large okay
131:47 - like like this so it's just kind of any
131:50 - it's kind of a very awkward thing that
131:52 - you can see over here but that's what
131:53 - the gun convention site okay so we have
131:56 - seen um this this kind of thing and
131:58 - maybe you will see
132:00 - sometimes c to be named as a lambda okay
132:03 - it's just it's just the same lambda and
132:05 - c are the same just as convention we
132:07 - give it a c as a name okay so let's just
132:10 - get now is you now you've got the
132:12 - overview of this hot margin and svm so
132:15 - we have seen a lot more things now it's
132:17 - time for getting into
132:19 - the little little mathematics which is
132:22 - how do we construct that
132:24 - hyperplane in linear regression we are
132:27 - just making the straight line and this
132:29 - is theta transpose x but this was our
132:33 - favorite equations like this theta zero
132:35 - times x zero and in uh logistic relation
132:38 - we are just doing the sigmoid of z so
132:39 - these are our hypothesis so this from
132:41 - this equation we are we were making our
132:44 - um straight line or maybe the sigma so
132:46 - uh what happens in case of a supported
132:49 - machine we have our hyper plane is diff
132:53 - our hyperplane
132:54 - should be is defined by w transpose x
132:58 - minus b equals to z this is the
133:00 - condition that our hyperplane should
133:01 - satisfy okay okay so what is this uh
133:05 - this w is our parameter weight is our
133:08 - parameter rate and this guy in linear
133:10 - question we have seen is theta and b is
133:14 - our
133:15 - a biased term which is in case of linear
133:18 - and logistic which is theta 0 okay so we
133:21 - have just just given our new name which
133:23 - is w and b okay and it's
133:27 - okay so we have made a w transpose x
133:29 - minus b
133:30 - and this is our hyperplane that we have
133:32 - made
133:33 - as
133:34 - w and b are the parameter weights
133:36 - okay
133:38 - so we have just just given a new name
133:39 - and transpose you all know linear
133:41 - algebra and this is w is a parameter
133:43 - vector
133:44 - okay so
133:46 - let's define some constraints in for
133:48 - heart margins so let's define some
133:50 - constraints for heart margin how hard
133:53 - margin make predictions
133:55 - okay
133:56 - so
133:58 - whatever whatever the output of your
134:00 - model minus w transpose x minus b is
134:03 - greater than or equals to one then
134:06 - anything on or above this margin will be
134:09 - regarded as one in this case it will be
134:12 - count okay why i'm seeing like this is
134:14 - let's see you have this straight line
134:16 - and you have this and you have the data
134:18 - point and one uh these two
134:21 - parallel lines and again here you have
134:24 - so whatever on this margin or above this
134:27 - margin is regarded as one means the
134:29 - positive attention so it is regarded
134:31 - it's a cap as you as you know okay and
134:33 - whatever below this is regarded as a
134:36 - zero okay as a non-cat
134:38 - okay so let's let's let's write the
134:41 - equation for that and it's quite easy
134:43 - it's quite um
134:44 - remember rememberable like double
134:47 - transpose x minus v whatever on or
134:49 - beyond this margin this margin will be
134:51 - regarded as one whatever below this
134:53 - margin will be regarded as a zero okay
134:56 - as a negative attention
134:58 - so that is the heart margin constraints
135:01 - and that's that that's how we make
135:03 - predictions onto uh support vector
135:06 - machine
135:06 - okay
135:07 - pretty much clear what i'm trying to say
135:09 - over here okay so now let's dig dive
135:12 - into some a little bit more further into
135:15 - math is
135:17 - how it truly is it it is being
135:19 - constructed like this so let's say you
135:21 - had made a straight line
135:23 - and this
135:24 - um this margin you can see over here
135:26 - this these margin
135:28 - is is written by this hyperplane this
135:31 - the main hyperplane is written by double
135:33 - transpose x minus b and this margin is
135:36 - equals this margin is equals to 2 over
135:40 - the norm of w so to maximize this margin
135:43 - we wanted to minimize this monitor the
135:46 - minimizer w okay if we want to maximize
135:50 - this margin because svm always has to
135:52 - maximize this margin to maximize this
135:54 - margin we have to minimize this norm of
135:57 - w and this margin is written by
136:01 - two over the norm of w okay and so so as
136:04 - you have said that as we have always
136:05 - tried to maximize so uh that is written
136:08 - by the uh two over uh norm of w and to
136:11 - maximize that you want to minimize some
136:13 - hormone of w so we can write an
136:15 - objective function we can write of
136:17 - objective problem object like like like
136:20 - this
136:21 - the distance between two hyperplane the
136:23 - distance
136:25 - distance between
136:27 - two hyperplane two hyperplane is written
136:30 - by two over the norm of w so to maximize
136:33 - its margin we want to minimize the norm
136:36 - of w
136:38 - with sub subject to
136:40 - subject to
136:43 - y i
136:44 - double transpose x i minus b greater
136:48 - than or equals to one so what i have
136:50 - said so let's understand this equation a
136:52 - little bit more further what i have
136:54 - written over here
136:55 - so you for maximum you this is the
136:57 - minimizing means we want to minimize to
136:59 - maximize that margin with respect to
137:03 - y i which is your ground growth means
137:05 - actual label and this is your moral
137:07 - predicted value moral predicted value
137:11 - and you can show your if it is on or
137:12 - beyond this it will be one otherwise it
137:15 - will be zero so if y i
137:17 - is equals to your border predicted value
137:20 - then your cost function will be zero
137:22 - then your loss function will be zero
137:24 - otherwise if it is not equals to y then
137:27 - then your loss function will be very
137:28 - very high so you want to minimize this
137:30 - normal w to get the good predictions
137:33 - okay
137:34 - so we have started this and i really
137:36 - hope that you had understood the concept
137:39 - that i explained to you and we can write
137:41 - our false function in a hinge loss or
137:44 - i'm talking about some soft margin so we
137:47 - can write our
137:49 - soft margin like this so we can write
137:52 - uh the the
137:53 - loss function the cost function the loss
137:56 - function
137:57 - you can write our loss function
137:59 - like this uh 1 over n plus
138:04 - i'm going to each and every training
138:05 - examples
138:07 - max
138:08 - of max of 0 comma 1 minus y
138:14 - double transpose x i minus b
138:17 - plus the regularized section plus
138:20 - lambda over was times the norm of w
138:23 - straight okay so this is quite confusing
138:25 - a little bit but let me try to explain
138:28 - you in more detail way
138:30 - so you already can see we are we are
138:32 - going to each a restraining example but
138:34 - taking on the max and this is the hinge
138:36 - loss if you can see this is this is
138:38 - called the hinge loss if i will get into
138:40 - more detail about a hinge loss you can
138:42 - have some wikipedia pages for knowing
138:44 - about hinge loss okay and this is your
138:46 - model model predicted value y a y i and
138:48 - the ground this is your ground truth y i
138:51 - and this is your predicted value and
138:53 - this is the lambda times you can write
138:56 - it c also you can write c also because
138:59 - it it it help you to adjust the width of
139:03 - that margin so that's why it is a very
139:05 - very important hyper parameter okay
139:08 - and times the non of w squared okay
139:13 - okay so we are done with a kind of a
139:16 - more
139:16 - linear uh classifier we are lame your
139:19 - svm is linear classification so we have
139:22 - made our good loss function so we have
139:25 - made a prediction function and now it's
139:27 - okay we want to minimize the this norm
139:30 - of w to get the good predictions okay
139:32 - okay so yes yes we have seen only the
139:34 - linears svm so let's let me form firm
139:38 - formulate one example which is like this
139:42 - let me make one
139:44 - again x and y plane number and making
139:46 - too much x and y plane it's best to have
139:49 - a
139:50 - this kind of things okay so let me make
139:52 - one non-linear classification like this
139:57 - okay so you have this kind of data
139:59 - and this kind of data and let me make
140:03 - the these white examples are the cat
140:05 - images and these white examples are
140:07 - non cat images so now if you can if you
140:11 - want to make the straight line you will
140:13 - be notable to do that means you're not
140:15 - able to um kind of classify it so it's
140:18 - very bad so what you have to do you have
140:20 - to make a non-linear you have to do the
140:22 - non-linear classification like this
140:25 - now it will be okay now it will be okay
140:28 - so svm also is also is very kind of
140:31 - powerful in nonlinear specification with
140:33 - something called as kernel trick it's
140:35 - something called as kernel trick so we
140:38 - will elaborate kernel trick in detail so
140:41 - let's start with kernel trick so what
140:43 - what we do in kernel tricks so let me
140:45 - write an algorithm so what you do you
140:48 - write an algorithm in terms of x you
140:50 - write the inner product
140:52 - let's say let me write you write
140:55 - an algorithm you write an algorithm
140:58 - in terms of
141:00 - the inner product of x and z and the
141:04 - these x and z are two data points are
141:07 - two data points so what you do
141:10 - let me tell you what what what we do in
141:13 - normal in a classification we take our
141:15 - data we take our data x and we transform
141:18 - our data to a some more let's say we
141:21 - have um one dimension data to a two
141:24 - dimensional data and non-linear
141:26 - specification okay so we transform our
141:28 - data to be from one-dimensional to
141:30 - two-dimensional like like this which
141:33 - okay so we write an algorithm in the
141:35 - form of x and z and x and z are the data
141:38 - points so in simply in kernel trick we
141:40 - transform our data to from one
141:42 - dimensional to
141:44 - higher dimensional space so you will get
141:46 - to know what what we are doing so let's
141:48 - uh let me write the steps
141:50 - so after uh we have written our
141:52 - algorithm in terms of the inner product
141:54 - of x and z now what's what we do we map
141:57 - our input input and this x without i
142:00 - write we map our input x to the phi of x
142:04 - okay to the phi of
142:06 - x so we are just i will tell you what
142:09 - this function is because
142:11 - okay so we write our function we map out
142:15 - x to the phi of x i will tell you what
142:18 - what we do in this case so we we find a
142:21 - way to map our this we find if we find a
142:24 - function
142:25 - [Music]
142:26 - so we map our x to the phi of x so we
142:29 - write a function or a final way
142:32 - we find our way
142:34 - so we find the x to be some
142:37 - uh phi of x and it will transform your
142:39 - one-dimensional data
142:41 - to the uh maybe and then any kind of
142:43 - your data to be the high dimensional one
142:46 - okay
142:47 - so you write up her you write the
142:48 - function at k we transform a data the
142:51 - phi of x transpose that times the
142:54 - uh phi of z okay so let's see what it
142:57 - does with that help an example and then
143:00 - what we do we replace our x
143:02 - and z with our transformed theta which
143:06 - is
143:06 - phi of x and z to be the beta phi of z
143:10 - okay so this is what we do
143:13 - so
143:14 - let's see um some how what is just and
143:17 - and what faced us so we write uh the
143:20 - kernel functions are one of the famous
143:23 - kernel is rbf kernel that will transform
143:26 - your data excels into the high
143:27 - dimensional space
143:28 - so
143:30 - the kernel function is written by the rv
143:33 - of kernel function written by k of x
143:35 - comma z exponent of
143:38 - minus
143:40 - norm of x minus z
143:41 - squared over 2 over the sigma squared
143:45 - okay and the x and z are the data points
143:48 - okay great and some more kernels are
143:51 - which is polynomial homogeneous
143:53 - polynomial inhomogeneous which you can
143:56 - search on internet but the most famous
143:58 - one is rbf kernel which is widely used
144:00 - in the end of stream okay
144:02 - okay so we have seen various kind of
144:04 - things and about kernel trick how we do
144:06 - the non-linear the transforming data
144:08 - you're able to do the non-linear
144:10 - classification so here are some we will
144:12 - discuss one two kind of one primal
144:15 - problem which will help us to state our
144:17 - optimization objective and then we will
144:19 - see the sub gradient okay
144:22 - so uh why why i'm talking about primal
144:24 - problem it will help you to form
144:26 - formalize your objective function so it
144:29 - will help you to formalize
144:31 - your objective function
144:33 - so it's just the same just as written we
144:36 - write that
144:37 - so for each i
144:39 - for each i
144:41 - be the member
144:43 - of one
144:44 - two all the round to the n we introduce
144:47 - a new variable
144:48 - zeta we introduce a new variable zeta
144:52 - where zeta i where is equal to the max
144:55 - of zero comma one minus yi
145:04 - so we introduce a new variable zeta i
145:08 - zero comma one minus y i okay and then
145:11 - in that we write w transpose x minus b
145:14 - okay so this is just a hinge loss where
145:17 - we introduce a new variable that hence
145:18 - ross is a story okay right image you see
145:21 - what i'm trying to say here okay so then
145:24 - we write our function like this you want
145:27 - to minimize
145:28 - you want to minimize
145:30 - 1 over n
145:31 - i equals to 1 all the way down to the
145:33 - end zeta i plus
145:35 - the
145:37 - the regular regularization term c the
145:39 - norm of w is great okay with respect to
145:43 - r is subject to
145:45 - subject to
145:46 - y i double transpose x minus b greater
145:50 - than or equal to 1 minus the
145:53 - zeta i
145:54 - time um
145:55 - is just a where zeta i is greater than
145:58 - or equal to b
145:59 - for all i
146:01 - okay so we have just formulated one
146:03 - problem it is just equal to the hinge
146:06 - loss that we have seen we want to
146:08 - minimize the objective function that we
146:10 - have seen so far is just equal to that
146:12 - so we have formulated in such a way that
146:15 - you can use this okay so we have a
146:17 - object objective function which is our
146:18 - cost function now we can now sum
146:20 - something called a sub gradient
146:22 - something called as sub gradient descent
146:25 - and which what we do we we make a convex
146:28 - function f of w and b we take out the
146:31 - sub gradient of our of of our function
146:34 - we sub take out the sub gradient of our
146:36 - cos function and then we update our
146:38 - parameter w and b okay and that's the
146:42 - sub as the gradient descent what what we
146:44 - are doing okay so it's little bit
146:46 - different than gradient descent here we
146:48 - are taking the sub gradient of our cos
146:50 - function okay so this is what we are
146:52 - doing this is called the primal problem
146:54 - and then we uh with this we we take out
146:56 - the sub gradient of that primal problem
146:59 - okay pretty much easy what i'm trying to
147:01 - say over here
147:02 - okay so one more thing that the that is
147:05 - very popular among beginners are
147:07 - learning theory something known as
147:09 - empirical risk minimization what do you
147:12 - mean by empirical risk minimization
147:14 - given you're given the input x1 x2 all
147:17 - the way down to the xn
147:18 - you want to and you and given y1 all the
147:22 - way down to the yn
147:25 - you want your output you want your
147:27 - output you want your output yn plus 1
147:30 - given
147:31 - xm plus 1. so it's just the same you
147:34 - give a function x and you want your
147:36 - output y okay and your and the loss and
147:39 - the getting the getting the error should
147:42 - be minimized means the risk should be
147:44 - minimized so that's the empirical risk
147:46 - minimization which we have already seen
147:48 - so we just have to know the definition
147:50 - for itself what is this okay okay so um
147:53 - ss we have talked about nonlinear and
147:56 - linear now it's time for getting into
147:57 - this
147:58 - uh support vector regression uh i'm just
148:01 - going to give you the equations okay it
148:03 - will it will all it will it is kind of a
148:06 - quite easy
148:07 - you want to minimize your one over two
148:09 - the norm of w is great you want to
148:11 - minimize this to get your output with
148:14 - respect to or subject to
148:16 - the y i the absolute value of y i minus
148:20 - the inner product of w and x i
148:24 - hence p
148:25 - times b and it should be greater than or
148:28 - equal to the sum epsilon and epsilon be
148:30 - the smallest positive in teaser okay so
148:33 - just to uh be comfortable into that so i
148:35 - hope that is quite clear and this this
148:38 - is for regression task okay and we will
148:41 - see the implementation in our next
148:42 - section so i hope that you really
148:44 - enjoyed this tutorial this section and
148:47 - we will be carrying out this more more
148:49 - into detail now we have gone too much
148:51 - into math but if you haven't understood
148:54 - any anyone please feel free to put a
148:56 - comment uh put your comment in the
148:58 - comment box i'll be very very happy to
149:00 - take your comment and
149:02 - and
149:04 - provide your answers over there i'll i
149:05 - will be uh taking taking a look at the
149:08 - questions and we will be answering soon
149:09 - at that point just put the timestamp
149:11 - where you're commenting okay so that i
149:13 - could know where you have a problem
149:16 - okay so i think that's how we have gone
149:18 - in too much detail if you haven't
149:20 - understood grammar problems or gradient
149:22 - don't worry it is not required for a
149:25 - beginner machine learning so if you have
149:27 - if you if you learn too much in machine
149:30 - learning and bonus deploying now you can
149:32 - come back to this primal problem to
149:34 - understand what i'm saying but it's
149:35 - quite easy to understand that the kernel
149:37 - trick what i said etc okay so thank you
149:40 - for seeing this video sorry thank you
149:42 - for seeing this section i'll be catching
149:44 - up here in the next section uh till then
149:47 - you can do the programming assignment
149:49 - okay i'll be catching up your next
149:51 - section will be making one project which
149:52 - is stock price predictor okay thank you
149:55 - so now we will make a stock price
149:57 - predictor which is our end-to-end
149:59 - machine learning project and here's a
150:01 - demo and you can see over here that i
150:04 - have to use you can just remove the i
150:05 - will show you where i have taken all
150:07 - those things just so i do i'm not a web
150:09 - developer but i had made a good front
150:12 - end of this and also i made a back end
150:14 - using flask okay so we will code
150:18 - as i made a stock price predictor and i
150:20 - will show you how you can uh build the
150:22 - same website like me and you can also uh
150:25 - make a beautify if you're a web
150:27 - developer okay so here is my um here's
150:31 - my jupiter notebook and here first of
150:35 - all i'm going to download the data from
150:37 - yahoo finance and you can simply pip
150:41 - install live finance i've already
150:43 - installed that you can install that so
150:45 - you just want to import first of all the
150:47 - basic libraries let me do that so first
150:50 - of all you want to import the basic
150:52 - libraries like this
150:53 - uh
150:54 - first of all i will import numpy as np
150:57 - then i will import pandas as tv and then
151:00 - i will import matplotlib and i'll
151:03 - implode import matplot left dot
151:06 - pi plot as plt
151:09 - then uh with that i'm going to import
151:12 - the c bar because i'm going to use
151:14 - seaborn now in this case as a
151:17 - visualization library so numpy is a
151:19 - scientific library pandas is they're
151:21 - working with the data the seaborn is an
151:23 - uh visualization library and matplotlib
151:26 - is also a visualization library okay oh
151:29 - and one more thing that i want to import
151:30 - is uh for my data for my data which is
151:34 - import y finance as y f okay
151:38 - as y f and y f is just allies given to
151:41 - that okay let me run this out
151:44 - and yeah i can to add this is optional
151:47 - but i can to add over here like this mat
151:49 - block level line
151:51 - matplotlib inline
151:54 - okay now it should work fine okay so we
151:57 - had done with importation of our uh all
152:00 - the libraries and now it's time for
152:02 - getting in a little bit more uh detail
152:04 - about the data how we can load our data
152:06 - so first of all i'm i'm just going to
152:09 - use um
152:11 - i just want to i'm in this project i
152:14 - will make a stock price predictor of
152:17 - natural gas okay and you can do any of
152:21 - like gold silver just go head over to
152:24 - the yahoo finance just head over to the
152:26 - ua yahoo finance
152:28 - and
152:30 - just head over to that and just to
152:31 - search whatever let's say i want to go
152:33 - for gold so if you go over gold then you
152:36 - will see over here that you have a gc
152:38 - equals to f which is the code of that
152:41 - okay so you just take take copy the code
152:43 - and here's just uh i will just show you
152:46 - how what you can do first of all i will
152:47 - take input i will take input which is
152:50 - enter the code of this talk enter the
152:52 - code of this talk to download
152:55 - enter the code of the stock to download
152:58 - okay now it will take an input now i
153:01 - will just uh make a variable
153:04 - now i'll just make a variable yf dot
153:06 - download
153:07 - and it will take off the code from the
153:10 - stocks okay and it will download from uh
153:14 - it will download from let's say 2008 it
153:17 - will download from 2008
153:19 - in january to one till
153:23 - uh it will down it
153:24 - download till two two two zero two one
153:28 - till uh zero let's say
153:32 - let's a two let's say one and tell 18.
153:36 - okay so this is the favorite thing and
153:38 - now what you can do we can simply do
153:40 - this kind of thing and let me run this
153:42 - and let's ask the code of this talk
153:47 - okay so you just give the code of the
153:49 - stock so let me give the natural gas
153:51 - equals to f this is the code so it will
153:53 - download a stock like this and then it
153:56 - will simply tell you the data how this
153:58 - looks okay now if you can see see over
154:01 - here that you have open
154:04 - high low close adjust and close and
154:06 - volume okay so one more and one more
154:09 - thing that studies that you can do you
154:10 - can write auto adjust or to adjust
154:15 - equals to true what it does is adjust
154:17 - your uh
154:19 - all of the
154:20 - kind of data frame and then you can see
154:22 - over here like this okay so that's what
154:24 - it's doing till now
154:27 - okay so we are done with this now it's
154:29 - time for getting into a little bit more
154:31 - detail about uh now we have loaded the
154:34 - data now let's take a look at the shape
154:35 - of the data like that
154:37 - so data dot shape
154:40 - and would tell us that we have a total
154:42 - of thousand two hundred fifty six uh
154:45 - training examples and five columns
154:47 - including date one two three four uh
154:50 - three two four five we have five columns
154:53 - and uh
154:54 - information about the data you can take
154:56 - a look we have a non-null values we have
154:59 - this we have that was the data type you
155:02 - can also take a look at the
155:04 - mean standard deviation maximum minimum
155:07 - of all the stuff so let me do that
155:10 - okay so you just uh see this and now you
155:13 - can see that you have a all of the count
155:15 - the minimum mean standard deviation
155:18 - minimum 25 and etc
155:21 - okay now if you wanted to take a look at
155:23 - the now we are done with data
155:25 - exploration now let's literally go
155:27 - further into how it uh because stock
155:30 - price prediction is very very non-linear
155:32 - okay but uh one thing that i want to
155:35 - mention over here they do not use it for
155:37 - personal purposes it's only for
155:39 - educational purposes okay only for uh
155:43 - educational purposes the reason why it's
155:45 - very non-linear and you can't uh and
155:48 - then you and you can't depend on your
155:50 - algorithm to to simply predict the
155:52 - output okay our other good it's it it
155:55 - may give you uh the wrong output i don't
155:57 - know about this very very non-linear so
156:00 - be sure to do not use it just for
156:02 - educational purposes not working company
156:04 - you're just making a simple project so
156:06 - that you could get a concept of how you
156:08 - implement how the process hold looks
156:11 - like okay so don't immediate by yourself
156:13 - um kind of a use in yourself and do not
156:17 - kind of
156:18 - make a website like that do not it is
156:20 - only for educational purposes okay now
156:22 - if you are done with this now we can
156:24 - analyze our data now if you followed an
156:26 - an analyzer with data you can write this
156:28 - close dot plot you can just plot it out
156:32 - and now it will look like this oops
156:37 - you can fix size
156:38 - let's say i'm just want to make it
156:41 - 10 7
156:43 - and
156:45 - we have this and here our target
156:48 - variable is close
156:50 - okay our target variable is closed
156:53 - and
156:54 - uh means we it will just tell you the
156:56 - direction of the stock let's say
156:59 - if the close is very high then your
157:01 - direction of a stock is very high means
157:03 - it will close will very high so here's
157:05 - very nonlinear so it just starts with
157:08 - 2008 in very low way and gets up up in
157:11 - 2009 then gone drastically down in 2010
157:15 - and then um kind of that so you can see
157:17 - the non-linearity like this so it's very
157:19 - very non-linear it's not uh you can you
157:22 - can depend on this algorithm or this
157:24 - predictor to predict your output in a
157:26 - good way okay so now now i think that we
157:29 - are done with everything now let me see
157:32 - what i have to do
157:33 - okay now let's take a look at that this
157:35 - how we can plot the distribution plot
157:37 - what's the distribution plot of our open
157:39 - then what's the distribution plot our
157:41 - close
157:42 - okay so it will give us a more feel how
157:44 - we are proceeding with our data or it
157:47 - will help us to choose the algorithm
157:49 - okay so
157:51 - here's the thing that i wanted to
157:53 - mention so first of all um just i'm
157:55 - going to use as
157:57 - c bar and
158:01 - just i'm going to use seaborn and then
158:04 - here i'm going to name as uh data i just
158:07 - want to name it as data and i'm going to
158:09 - put over here
158:10 - uh this open let's say close okay so we
158:13 - will see if this is normally if this is
158:16 - non-linear etc to take a little bit more
158:19 - field okay so you can see it's a little
158:21 - bit
158:22 - non uh
158:23 - it's just it's a non-normally
158:25 - distributed okay so you can apply and
158:28 - lock transformation that's called
158:29 - feature engineering but that does not
158:31 - work well in this case so we should
158:33 - leave like this and then we will take a
158:35 - look at this plot and then if you wanted
158:37 - to take a look at the open
158:39 - then you will again see it's again
158:41 - normally disputed now you can do the
158:44 - same for other other things to get the
158:47 - feel of what we are doing let's say we
158:49 - are we have done for high
158:51 - so we are done for high
158:53 - and if you take a look at the highs also
158:56 - like there's a sweet okay so we are done
158:58 - uh we are done with you can you can play
159:00 - with the data visualization and it say
159:02 - take out the inferences about the data
159:04 - and about the data inferences okay now
159:07 - we have understood the data what we have
159:10 - understood okay let's write the
159:12 - conclusion what we have understood till
159:14 - now so we have understood the first and
159:17 - first foremost
159:19 - is the shape of the data shape of the
159:22 - data
159:23 - and then we have understood the
159:25 - uh how a data is distributed how our
159:29 - data is distributed our data is
159:31 - distributed then we have understood
159:34 - that then we have understood
159:37 - how our
159:38 - uh it's it's very very non-linear it's
159:41 - very very non-linear okay so you can't
159:45 - cannot use for own purpose
159:47 - maybe you can use deep learning
159:48 - architectures like lstm to get the
159:51 - direction of your stocks and let's say
159:53 - if you uh maybe the 99 95 percent that
159:56 - works correct or remember 80 works
159:59 - correct maybe 725 works correct uh so
160:02 - you can
160:03 - just turn down do not use linear
160:04 - regression or any kind of things to make
160:07 - your own use but definitely in future
160:09 - let's see what the research
160:11 - comes with uh for stock price predictor
160:13 - because stock price prediction is also
160:15 - competitive uh project to work on
160:18 - because it's very very non-linear
160:20 - okay so we are done with this and now
160:23 - it's time for we have started how much
160:25 - algorithm you have started linear we
160:27 - have started linear then we have studied
160:30 - logistic
160:31 - then we have studied some regularized
160:33 - linear models regularized linear models
160:37 - then we have a started support vector
160:38 - machine then we have studied principle
160:40 - combat analysis which will study uh
160:42 - which we have not studied so we will
160:44 - study principle common analysis and then
160:46 - furthermore okay so we will use support
160:48 - vector machine we will use support
160:50 - vector machine uh but we will see that
160:54 - linear regression and regularized linear
160:56 - models works best in this case and we
161:00 - will go with our saving the model of
161:02 - regularized linear model okay so let's
161:05 - start with linear regression before that
161:07 - let's split our data into x and y and
161:09 - then the training and testing set so
161:12 - here i am um just i'm going to x so i
161:15 - like my convention so i'm just going to
161:16 - make it like this
161:18 - and
161:19 - our x variable will be all the except
161:22 - close so i'm just going to remove this
161:25 - and then an axis number one
161:28 - and then y equals to data and then y
161:32 - equals data dot drop
161:34 - i'm not saying we will not drop it we
161:36 - will just simply keep the close okay now
161:40 - if yeah we
161:41 - we are done with this now x and y data
161:43 - to drop close x now we are done now what
161:46 - what we can do we can simply uh
161:48 - import more uh kind of a moral selection
161:51 - uh which is trained to split we'll
161:53 - import one thing which is train to split
161:55 - which let's say you want to split your
161:57 - data let's you have 100 of data so you
162:00 - will uh split your data 80 for training
162:03 - and 20 for testing to validate your
162:05 - model okay so here i'm doing what i'm
162:08 - see you can see over here we have a x
162:10 - train x test and y train y test okay so
162:14 - this is the you can make the variable
162:16 - and all the training elements the labels
162:19 - of x train will be in y train and label
162:21 - of x test will be in y test like this
162:24 - okay now if you now you have just give x
162:27 - and y and just give the size of that uh
162:30 - test set which is let's say give the 20
162:32 - percent means you just want to use 20 20
162:34 - percent of your whole data for testing
162:37 - then you want to do this random
162:39 - state and you may think hey you schwarz
162:40 - run random stage does it simply uh let's
162:43 - say if you if you run it one more time
162:46 - then your data will not be changed to
162:48 - your shuffle because shuffles also so
162:50 - your data will be not changed
162:52 - okay so we will take a look at the
162:54 - shapes of that so that we can get a more
162:57 - feel what we are doing so you could
162:59 - understand what to whom we are working
163:01 - with
163:02 - uh let me just copy and paste one over
163:04 - here and just gonna to make it like this
163:07 - and
163:08 - then i'm just going to
163:10 - make it wide swing
163:12 - and this one by test okay and just meant
163:15 - to make it a little bit more detail okay
163:18 - when you run this you can you can see
163:20 - over here that you have a two thousand
163:22 - six hundred four and four columns and
163:24 - the fifth column is two two thousand uh
163:27 - this the labels of y okay so that's the
163:30 - thing and now what we can do we can go
163:32 - further and we have taken the close as
163:35 - our target variable which will tell us
163:36 - the direction of our stock stocks
163:39 - okay
163:40 - okay so now we are done with splitting
163:42 - now it's time for getting into a little
163:43 - bit more depth is uh modeling part means
163:46 - we are going to first of all i'm going
163:48 - to import the linear regression because
163:51 - everyone thinks linear regression is
163:53 - very bad but let me tell you it's very
163:56 - powerful algorithm when it comes to
163:58 - linearity but here we don't have a
164:00 - linearity but still it works best when
164:03 - you apply your polynomial saturated
164:04 - question okay
164:06 - but let's uh keep let's use the
164:09 - logistics or linear regression and you
164:11 - can see over here that this is a
164:12 - regression problem and so supervised
164:14 - learning problem so we cannot use
164:16 - logistic it will be very very bad for us
164:19 - okay so just i'm going to instantiate
164:21 - just i'm going to instantiate
164:23 - instantiate and i'm just going to call
164:27 - lr.fit and i'm just going to give xtrain
164:30 - and the labels y train which is the
164:32 - labels of x-ray
164:35 - okay the predict one means i'm going to
164:37 - use that
164:38 - lr which is train model to predict my x
164:42 - test okay
164:43 - now if i run this now if you see the
164:46 - predicted output you can see over here
164:48 - that the uh let's
164:50 - see the first training example
164:53 - so you can see over here oops this y
164:55 - test now
164:57 - so you can see over 2.918 and the
164:59 - predicted is 2.90 and the
165:03 - actual value is 2.918
165:05 - okay see that things that that is over
165:07 - here this
165:09 - quite uh it's quite very very good
165:11 - because you can see away that's quite
165:13 - working very very good and yeah linear
165:16 - regression works out best but it may
165:17 - happen that may overfit your data
165:20 - but let's see let's calculate a matrix
165:23 - so we are going to use some matrix which
165:25 - is m a we are going to use m a which is
165:29 - uh
165:29 - sorry mse which is a mean square adder
165:32 - which is a mean squared error which we
165:34 - have talked about the cost function for
165:36 - linear regression
165:37 - then we are going to use
165:39 - uh then we are going to use uh
165:42 - rmse and simply is it does simply the
165:46 - square root of a square root of
165:50 - mean square error
165:52 - and then what you do here and then we
165:53 - will calculate the r2 square okay and
165:56 - you can see if you want to get into
165:57 - mathematically we'll we'll talk about
165:59 - some matrices matrix later on but you
166:02 - know the best output of r2 if your model
166:05 - giving output
166:06 - r2 equals to 1.0 then you have a very
166:09 - bad sorry good model and it's a good
166:11 - model if if it's giving good okay so
166:13 - we'll see how much hour r2 etc so i will
166:16 - write one helper function like this
166:18 - we'll write one helper function
166:20 - calculate matrices
166:22 - i'll just write a matrix and then it
166:25 - simply takes the actual value which is a
166:27 - grand truth and it simply strikes the
166:29 - predicted value of your model to
166:31 - calculate and then first of all i'm
166:33 - going to calculate the mse and it's just
166:36 - uh first of all i have to import because
166:38 - you can also make your own function but
166:40 - it's better to use vectorized or cyclone
166:43 - because it's already provided to you but
166:44 - you know it's very kind of easy if you
166:46 - wanted to define msc so you just write
166:49 - and define msc and just
166:50 - take the sum of everyday data point and
166:52 - the residuals and then just
166:55 - square them up and then like that you
166:56 - can do that we have already i think your
166:58 - area have implemented programming
167:00 - assignments
167:01 - okay so you can just to make it import
167:04 - uh let's say oops i don't want to i just
167:06 - want to import the matrix and i'm going
167:08 - to import uh mse and mean square error
167:12 - obviously we do have mean absolute error
167:15 - which you can also use but for now i'm
167:17 - going to use this
167:19 - but by the way we don't have rmse we
167:21 - have to code rmse buyers by ourselves
167:24 - okay we only have r2 squared so first of
167:27 - all let's uh do this kind of thing means
167:29 - being a square giving the for our
167:31 - parameters y test and y and wipe fret
167:35 - and then
167:37 - rmstn you may think here use how how you
167:39 - can calculate the
167:40 - root mean square error just write np dot
167:43 - square root is just taking the square
167:45 - root of mse okay that's easy so r2 score
167:50 - which is r2 scores i'm just now on the
167:52 - right is doing a spelling wrong because
167:55 - maybe it will cause some error if you
167:57 - have a reserved keyword or like that's
167:59 - function okay so you have r2 squared and
168:02 - then uh score and now you just give y
168:05 - test
168:06 - and now you just give y test sorry yeah
168:09 - y test and wipe red
168:12 - okay and these are white as in white red
168:14 - are just so let me write that what is
168:16 - this
168:17 - so why test is your
168:19 - ground truth is your ground truth is
168:22 - your ground truth
168:24 - and why fret why pred is your moral
168:26 - predicted value okay moral predicted
168:30 - predicted value
168:32 - oops i'm i think that i'm doing it wrong
168:34 - uh you can see the spelling
168:37 - okay okay so we are now whatever what i
168:40 - will do i'll just print it out msc then
168:42 - i will print rmse
168:44 - then i will print rmsc then i will print
168:46 - r2 okay
168:48 - r2 is coarse
168:50 - okay and this i'm just gonna to
168:53 - msc
168:55 - uh just going to make it mse like this
168:58 - [Applause]
169:00 - and here also i'm going to make it rmsc
169:05 - okay and here also i'm going to make r2
169:08 - square
169:09 - r2
169:11 - score sorry score it's score okay now i
169:14 - think that it should work now we are
169:16 - done now if you wanted to now we are
169:18 - done with helper function now if you
169:20 - want to calculate the matrix so you
169:22 - where we will just calculate the for a
169:24 - linear regression so we would just give
169:25 - a y test which is our ground truth which
169:28 - i have made while splitting out data now
169:30 - we will make a y prediction y prediction
169:33 - and sorry it's a prediction one
169:35 - uh that that we have made in linear
169:37 - regression predicted okay so you can see
169:39 - the msc is equal equals to zero means
169:41 - approximately equal to zero is quite
169:43 - good because in cost function your cost
169:45 - function should be very very
169:47 - approximately equal to zero your root
169:49 - mean square is also and your r two is
169:51 - zero point nine nine nine this
169:54 - is approximately equals to 1.0
169:57 - okay so it's quite good linear
169:59 - regression performs quite good okay now
170:02 - let's a little bit let me go go further
170:04 - into uh some regularized linear models
170:08 - like rich and lasso so
170:12 - let's use that from sklearn
170:15 - sklearn dot model sorry linear models
170:19 - linear model i'm just going to import
170:22 - lasso
170:24 - and you if you know if your name may
170:26 - know about this lasso and rich lasso
170:30 - what it's doing simply eliminates the
170:32 - less important features simply
170:34 - eliminates the less important features
170:37 - and rich is just
170:40 - penalizes your less important features
170:43 - okay
170:44 - so now let's uh make the two of them so
170:47 - let's say la as a lasso
170:49 - so i'm just going to fit it over like
170:51 - this is a short form giving the
170:53 - x train and y train
170:56 - is a short form for doing that and then
170:58 - i will do for the same for a rich
171:01 - i'm just going to go for the ridge
171:04 - and it just fits the same thing and oops
171:06 - i should give it r a i think r i
171:10 - l a p i'll just go l a p is the lasso
171:14 - predicted value and then i'm l a
171:19 - x test okay
171:21 - and here also i'm just going to make r r
171:24 - i p
171:25 - equals to r i dot predict
171:30 - and i'm just going to give x test
171:32 - let's run this now we are done now if
171:34 - you want to take a look let's first take
171:36 - a look at the lasso what lasso performs
171:39 - l a
171:40 - first of all we are going to give the
171:41 - ground truth which is y test and then we
171:43 - will gonna give the lap now it's quite
171:46 - uh not good it's zero point it's quite
171:48 - not good because simply it's very strict
171:51 - it simply eliminates so but it's you're
171:53 - you're with lasso your modal in your
171:55 - model is less prone to overfitting but
171:58 - here you can see if i take a look at the
172:00 - rich it's quite uh for now it's quite
172:03 - good because uh it is also a
172:05 - regularization now it's quite a similar
172:08 - to linear regression but this is less
172:10 - prone to overfitting okay it's less
172:14 - prone to overfitting so we are going to
172:16 - use uh rich regression to save our model
172:19 - and build a website under this
172:21 - okay so one one more thing that i want
172:23 - to mention over here that we can use
172:25 - support vector machine i mean support
172:27 - vector regression uh for this task so
172:30 - let's see how we can make this kind of
172:33 - thing so let's let me uh
172:35 - svm so you can just and i think that the
172:38 - portable machine will not work well
172:40 - but it should work well if you have a
172:42 - lot of features like index voltage and
172:44 - then we have a different different
172:45 - features which contain different
172:47 - different uh importance okay so i'm just
172:50 - going to import and here you can
172:52 - obviously will not use it but here you
172:54 - will learn how to so how to do the fine
172:58 - tuning of any other model using grid
172:59 - source cv okay so dot model selection
173:04 - and just going to import the grid source
173:06 - cv okay first of all i'm going to
173:08 - instantiate svr and that is just going
173:11 - to um
173:12 - i'm just going to make it params and
173:14 - then and then i'm going to make it
173:16 - params and then here i'm going to make
173:18 - it c to be uh maybe and c is just a
173:22 - lambda which will tell us the width of
173:23 - your margin so i'm just going to copy it
173:25 - out this i'm just going to write it from
173:27 - my there i've already written over there
173:30 - it's just i'm going to write it to
173:31 - minimize the length of the video
173:35 - okay so it's just like this and i'm
173:36 - taking c as uh to use these values and
173:40 - check how is model performing with
173:42 - different different values and kernel
173:44 - will be obviously the rvf kernel because
173:46 - it's very kind of non-linear okay now if
173:49 - you now what we'll do we will just uh we
173:52 - will just make this and then i will call
173:54 - my greatsword cv and i'll give my params
173:57 - i just gonna to give my params and svr
174:00 - first of all svr obviously
174:02 - svr and then i'm going to give it the
174:04 - rams red
174:06 - ram grid and then
174:09 - i just want to rough it equal to true
174:11 - and just wrap it will tell you means the
174:14 - warnings you can see the documentation
174:16 - verbose equals to three
174:19 - okay messages
174:21 - done now if you wanted to run it let's
174:24 - fit now now we'll fit grid
174:26 - onto our training to check different
174:29 - different values
174:31 - y twain
174:33 - okay now let's run this it will take a
174:35 - little bit of our own time but yeah i'm
174:36 - just gonna to
174:38 - uh code it further
174:40 - it will take a little bit amount of time
174:41 - it is checking for each and every uh
174:43 - this zero point one zero point twos
174:45 - etcetera and checking the score and
174:46 - whatever works best it just will give
174:48 - out
174:49 - okay just want to make it small
174:52 - okay now let's wait for a few seconds
174:55 - and i think this will uh end up being in
174:57 - a few seconds
174:59 - uh in the meanwhile i'm just going to
175:01 - just copy it out these things because
175:03 - the parameter which we are going to get
175:04 - is like this the c equals to 10 and
175:06 - gamma equals to 0.1 and kernel equals to
175:09 - rbf and if you run this if here you will
175:11 - be left with a very good matrices but it
175:14 - means it is very bad i think so this is
175:16 - we are performing is very very bad
175:18 - because of that we have a don't have a
175:20 - lot of features over here
175:21 - and spr is not able to
175:24 - find learn in the model actually but
175:26 - regular regularized linear models are
175:28 - more powerful in here okay
175:32 - that image is what i'm trying to say you
175:34 - here okay now i'm gonna do is to see
175:37 - this how much it was still running it's
175:39 - just checking for each and every uh this
175:42 - will take 1.8 seconds more to i think
175:45 - it's 1.9 seconds it's just taking a
175:48 - little bit of one time but i'm just
175:49 - going to wait for a few seconds and you
175:51 - can see over here that is trying for
175:53 - each and every value gamma then c then
175:55 - this then that
175:57 - okay so we will just wait and then i
175:59 - will uh let's come back
176:02 - i think we are we will just code it
176:04 - further because um we will just code it
176:06 - for the import job lib
176:09 - and here we will import job left to save
176:12 - our model to save our model because we
176:14 - are going to use a regularized linear
176:17 - models okay so model job lib dot dump
176:21 - job lib dot dum
176:24 - i'll just dumps and just going to save
176:26 - this model dot pkl
176:29 - okay and then i will simply uh if i want
176:33 - to load my model equals to joblib.load
176:37 - i'm just going to if you want to load
176:38 - your model you can just write it down
176:40 - and you can just make it model.pkl
176:43 - okay
176:45 - that's what we are going to do over here
176:47 - and now i think that's done now if you
176:49 - want to like this and now if you want to
176:51 - make it like this now you're done with
176:53 - this kind of thing now if you run this
176:55 - this support victim uh regression and
176:58 - now if you run this now the dumps is not
177:01 - there particularly very good okay so we
177:03 - are done with this now let's see the in
177:05 - folder where we have the pkl file and we
177:09 - can use this model to make predictions
177:11 - okay so we can use this model to make
177:13 - predictions so let's keep making
177:15 - predictions with this so let's me let me
177:18 - go to my
177:21 - let let me go to my uh one of the mlo
177:23 - one and then stock price predictor and
177:26 - here i'm going to open with code okay i
177:28 - do have made which i will just copy if i
177:30 - want to save my time i'll just copy and
177:32 - paste over there to save my time so that
177:35 - it would be more perfect if i just copy
177:37 - the prediction.html because it's just uh
177:40 - simple html blocks
177:42 - you're just going to
177:43 - cut it down because i don't think that
177:45 - this should require further
177:48 - it's just active
177:51 - let me cut it down
177:53 - okay so now i think that we are on to
177:55 - this now what what i can do i can just
177:57 - make a app.pi
177:59 - app.pi and here first of all i'm going
178:02 - to i think that all are able to see ya
178:05 - so from flask
178:07 - i'm just going to import
178:10 - import flask
178:13 - and then i'm going to import the vendor
178:15 - template
178:16 - render template
178:19 - and if you don't know what plan don't
178:21 - worry it's quite uh easy to understand i
178:23 - will walk through each and every process
178:25 - but i don't know why it's not working
178:27 - but it's okay if it's not working it's
178:31 - uh it's my vs code box a lot
178:34 - i don't know why but yeah i will just
178:36 - keep trying it out let me again open
178:39 - with code
178:41 - it's again open with code
178:43 - and then let's see what i can do over
178:45 - here that we have just imported the
178:47 - flash till now and
178:49 - render template now we'll just
178:51 - instantiate my model like this flask
178:55 - uh name oops it's just i think name
179:01 - it's correct yeah so now i'm just to
179:03 - make a route app.route
179:08 - and it's just uh this
179:10 - simple homepage to validate our server
179:12 - is working return render template
179:17 - i just want to take a render template
179:21 - from the index.html
179:24 - index.html
179:25 - and you may think hey you should haven't
179:27 - made index.html so let's make that uh
179:30 - this i'm not made just i'm going to make
179:32 - it over here so flask looks for html
179:34 - files into the templates folder to just
179:37 - make one templates older over here
179:40 - okay just make it and then one more
179:42 - folder you have to make for your images
179:45 - which is static folder okay static and
179:48 - all your images will be here
179:50 - now you can also make from here just to
179:53 - templates like this now just make a new
179:56 - file which is index.html
179:59 - okay now after making index.html you can
180:01 - just type this down like this
180:04 - and now if you go away stock price
180:06 - predictor i just i will just copy it
180:08 - down i will tell you where i have taken
180:10 - all those stops so let me show you where
180:12 - i've taken from these all so but let's
180:15 - see before that
180:16 - how is it working or not
180:18 - like writing a hello world
180:21 - okay just save this down and now if now
180:25 - it's time for uh like this
180:28 - instantiating for setting up your server
180:32 - name
180:33 - equal equals to
180:35 - main
180:36 - and then i will just uh
180:39 - app
180:40 - dot run
180:43 - debug equals to true
180:45 - anything going wrong
180:47 - i think yeah uh no
180:50 - it's true
180:52 - okay now if i save this if i run this
180:55 - down it will take a little bit of time
180:56 - and it will run and so it's starting
180:58 - over here and this is my url address
181:01 - if i see over here now you can see over
181:03 - here that we have a
181:05 - a beautiful
181:06 - website but now you can see why it is
181:08 - running the reason why it's i have to
181:11 - stop that server to get running so let
181:13 - me stop that server because another
181:15 - server is running
181:17 - um into the ml01 projects folder over
181:21 - here which i have to stop it
181:23 - i will debug it i have to reinstall my
181:25 - visual studio code but i will show you
181:27 - where i have taken this all so the first
181:29 - thing first you have to keep in mind
181:30 - from where you have to take this it's
181:32 - from uh see a tail block so i will just
181:36 - annotate the code in my
181:38 - mlo1 projects folder this i will
181:41 - annotate from where i have taken
181:43 - it says from first of all i have
181:45 - imported the cdn first of all i've
181:47 - imported the cdn
181:48 - of bootstrap and talvin css and then
181:51 - i've gone to tailblocks.cc i will gone
181:54 - to tailblocks.cc
181:56 - and grabbed my header grabbed my header
181:59 - then this nav navigation menu then i
182:02 - have to grab my header and then i have
182:04 - this predictor and you can see
182:06 - all the code is in my github okay
182:10 - now if i show you what the
182:11 - prediction.html does it's simply uh
182:14 - first of all what i've done i i have
182:16 - written a form into that you can uh the
182:19 - code will be in the description
182:20 - description elements that get up you can
182:21 - head over to that okay so i'm just using
182:24 - the request to get the form the open the
182:27 - high which is the input variables and
182:28 - then i'm pretty preprocessing it so how
182:31 - it's how i'm preprocessing it and
182:32 - putting into the 2d array to make
182:34 - prediction then i'm loading the model
182:36 - then i'm predicting on the test data and
182:39 - then returning the prediction and then
182:40 - i'm just running the template from
182:42 - prediction.html
182:44 - and prediction equals to prediction
182:45 - which has gone through here so if i go
182:47 - to the prediction.html you can see that
182:50 - i have just extra i have made one layout
182:51 - i use flask
182:53 - flask inheritance to inherit the
182:55 - template from
182:56 - layout or html and you can see the
182:58 - layout of this similar just a chunk of
183:00 - code so prediction is just a prediction
183:03 - and the prediction is derived from here
183:05 - okay and it's just prediction is there's
183:07 - prediction status just given okay
183:10 - pretty much easy let's see if it's
183:11 - working still now or not it's still
183:14 - working so let me put some value
183:17 - so it's just and it will tell the
183:18 - closing price
183:20 - and it will tell when it sells at
183:21 - closing prices tells the direction of
183:24 - the stocks okay so the closing price is
183:27 - four point eight six five eight eight
183:28 - zero five four okay so that's the pretty
183:31 - much easy that we need uh to understand
183:33 - about uh uh making a flask of flask
183:36 - website and end-to-end machine learning
183:37 - project i really really hope that you
183:39 - enjoyed this tutorial a section in this
183:41 - project in the next section we will be
183:43 - talking about principal combat analysis
183:45 - then we'll do one of our project and
183:46 - then we have done step 10 now two
183:48 - projects which is an end-to-end machine
183:49 - learning project to get on the resume
183:52 - and you can also modify it let me tell
183:54 - you how you can modify it you can see
183:56 - over that that we have an open high low
183:58 - close volume then a research paper or
184:01 - something called the stock price
184:02 - prediction using machine learning they
184:04 - have given what the features they have
184:05 - used like index volatility like uh mean
184:08 - etc selling price of the sorry
184:11 - three three days price three days
184:13 - previous price and nine days pre selling
184:16 - previous price so you can do that kind
184:18 - of features and integrate over there to
184:20 - make it the more powerful model with the
184:22 - complex model okay but do not make it
184:25 - too complex we can see we had we had
184:27 - worked on lots of data to understand and
184:29 - how we understood that this is good for
184:31 - linear regression the reason why we have
184:33 - understood because our data is not
184:35 - multiple linear what do i mean by
184:37 - multiple linear because many of the
184:39 - interviewer asks that how you will
184:41 - perform when your data is
184:43 - multi-co-linear with linear regression
184:45 - algorithm your answer will be no we
184:47 - cannot perform when a linear regression
184:50 - when your data is multi-core linear it's
184:53 - only because
184:54 - it's only because your because the
184:57 - variables linear regression does not
184:58 - work well when your variables are highly
185:00 - intercourse correlated okay when you're
185:03 - let's say on it will be all same means
185:05 - correlated very highly into intercollect
185:08 - correlated so if they ask you what's the
185:10 - way to remove this so you can say okay
185:12 - we can use principal component analysis
185:14 - which will study in the next section so
185:16 - you can say hey we can use principal
185:18 - component analysis to remove the
185:22 - uh multi-collinearity from our data and
185:25 - then it's boom you are done with your
185:27 - interview it means kind of just one
185:28 - question as an astronaut interview as i
185:30 - was in one of my interview okay so
185:33 - that's the basic thing that we need to
185:35 - understand and i really hope that you
185:36 - enjoy this section the next section will
185:38 - head over to the pca and we've had done
185:41 - the two projects now it's good to see
185:42 - that all of you are doing projects and
185:44 - it's i hope that you're very enjoying
185:46 - okay you can leave your questions in the
185:48 - comment box i will definitely pick up
185:50 - that question
185:51 - okay thank you for seeing this section
185:53 - i'll be catching up in the next section
185:56 - okay so now we will talk about principle
185:59 - component analysis which is a
186:01 - dimensionality reduction algorithm okay
186:04 - so uh you will get to know what is
186:06 - dimensionality reduction etc but before
186:09 - that we we should have a toolkit of some
186:12 - some other concept of linear algebra
186:15 - like linear combinations or linear
186:18 - transformations and eigenvectors and
186:20 - eigenvalues okay so we will review the
186:24 - linear transformation and eigenvectors
186:26 - and eigenvalues so that we can be on the
186:29 - same page
186:31 - okay so
186:33 - if you want to get in more detail there
186:35 - is a youtube channel named three blue
186:37 - one brown like this you can head over to
186:39 - that they have it he has a very good
186:42 - playlist on linear algebra they have a
186:45 - series of section videos you can watch
186:47 - that if you want to get dick dive into
186:49 - that but for this you don't need that
186:51 - okay but
186:53 - uh what is linear transformation
186:56 - if you have linear transformation just
186:59 - like a is a function as we have seen f
187:02 - of x which is a function so it just
187:04 - transforms your function transform this
187:07 - x to maybe the squared of x so this is
187:10 - just is a function
187:12 - the transform or the transform from one
187:14 - vector space
187:16 - to another is that respects to
187:18 - underlying linear structure of each
187:20 - vector space okay
187:22 - so if you if you have seen the three
187:25 - blue one brown videos he has clearly
187:27 - mentioned that
187:29 - is a function lean linear transformation
187:32 - is a function that transforms your one
187:35 - vector space to another with linear
187:38 - structure okay are we parallel to each
187:41 - other it's a linear structure of each
187:43 - vector space if a little bit of
187:46 - nonlinear gains you will be not able to
187:48 - do the transformation of your vector
187:50 - okay so that's called the linear
187:52 - transformation so linear transformation
187:54 - can be written as t
187:56 - column we are transforming our vector r
187:58 - to that okay okay so here is here's an
188:02 - example of 1d linear uh
188:04 - transformation so here's the function t
188:06 - of x and a be the sum is scalar and
188:10 - their one dimensional linear
188:12 - transformation t of x which is our
188:14 - function that maps your
188:16 - that that maps your from from interval
188:18 - of zero to one to the interval of three
188:21 - to zero so we have a vector the zero to
188:24 - one and it's just scales okay by the
188:26 - factor of three but a factor of three to
188:29 - the three end to inter looks like this
188:31 - okay so that's the linear transformation
188:33 - if you head over to the three blue one
188:36 - brown channel for more detail
188:38 - so uh
188:39 - i know vectors are nice and values i'm
188:41 - not going to take dividend math of
188:43 - eigenvectors and eigenvalues but it's
188:46 - just like what it does let's say you
188:48 - have the new transform vector it's just
188:50 - a scaled version of the original vector
188:53 - so you have some vector let's say
188:56 - well v you have a vector we have a
188:58 - vector let's say this and it's the new
189:01 - transform it's just a scale means the uh
189:04 - the new vector is just scaled from this
189:06 - vector like this if i choose new pen
189:09 - yeah so it's
189:11 - like this
189:12 - then the original vector then the
189:14 - original vector is the eisen vector of
189:17 - the original matrix okay so you just if
189:21 - your new transform you just scale from
189:23 - the original then your original vector
189:26 - is known as to be a eigenvector and the
189:29 - factor by which it is stretched like
189:32 - this green color is known as eyes in
189:34 - values okay and vectors that have this
189:37 - characteristics are known as eyes and
189:39 - vectors okay and eisen values means the
189:42 - factor by which it is scaled or
189:44 - stretched are known as the eigenvalues
189:47 - which is denoted by this symbol which is
189:49 - lambda okay so that's the simple idea
189:52 - behind eigenvectors and eigenvalues
189:54 - again let's revise what we have studied
189:57 - uh till now
189:58 - until now we have studied about linear
190:01 - transformation and a linear
190:02 - transformation is a function that
190:04 - transforms you from one vector space to
190:07 - another with respect to lying under a
190:10 - linear structure of each vector space
190:13 - okay we can write out here because we
190:16 - can write our value linear
190:18 - transformation as a t of x
190:20 - uh for example for only one d linear
190:22 - equals to a x and a b to some a linear
190:26 - sorry scalar okay so what we are doing
190:29 - over in this example here we have this
190:31 - vector of form from the interval of zero
190:33 - to one we are transforming it to zero to
190:36 - three by scaling it by two by a factor
190:39 - of three okay
190:41 - that's the linear transformation
190:44 - okay and here an eigenvectorized value
190:48 - we have a new transform vector which is
190:50 - the linear transformation which is
190:52 - happening okay it's a linear
190:54 - transformation which is a new transform
190:55 - vector it's a scale from the original
190:58 - vector means from the original vector
191:00 - like this it has been shown you over
191:02 - here
191:03 - then it is it is the original vector is
191:06 - known as the eisen vector of the
191:08 - original matrix otherwise it's just a
191:11 - vector and the factor by which it is
191:14 - scaled here is three the factor by which
191:16 - is scale here is three then the three is
191:18 - your eigenvalue okay
191:21 - it's this is what the simple eisen
191:23 - vector analyzing values are okay
191:26 - pretty much easy what i'm trying to say
191:27 - you here okay if you want to get in more
191:30 - detail there is a video of
191:32 - give by gilbert strang gilbert i think
191:35 - i'm pronouncing correct gilbert strang
191:38 - lean new algebra videos or a book by
191:40 - introduction to lean your ass bra
191:42 - introduction to linear algebra you can
191:45 - have a look by gilbert strand or you can
191:47 - have a look for a quick look at three
191:50 - blue one brown video the blue one brand
191:53 - video on linear algebra on youtube okay
191:57 - so that's the
191:58 - uh
191:59 - kind of uh resources to learn more but
192:02 - for now if you know this then you are
192:03 - good to learn about principle covenant
192:05 - analysis
192:06 - okay
192:08 - so you may think yeah i don't want to do
192:10 - so much of math etc so you have a
192:13 - library known as numpy
192:15 - which you can have a look which i have
192:17 - given the notebook in the description
192:19 - downloads below about numpad panda so
192:21 - you can have a look so we can just
192:24 - implement we can just implement by this
192:27 - la la is allies
192:30 - l a is allies as a linear algebra we are
192:33 - taking out the eyes e i z of the input
192:37 - and input here is our vector okay
192:41 - and this is your the eigenvector and
192:43 - either value as in vector of the or this
192:46 - matrix sorry yeah this is a matrix okay
192:49 - so and this this matrix is just a 2
192:51 - comma minus 1 4
192:53 - okay so that's the matrix of 2 by 2
192:55 - matrix okay
192:58 - so we have started about um
193:00 - linear um
193:01 - algebra that is required for us for a
193:03 - principal common analysis now it's time
193:06 - for understanding why we are studying
193:09 - this all and why why we need
193:11 - dimensionality reduction
193:13 - so let's say you're working on
193:15 - kind of a large amount of dataset so
193:17 - this is 3 000 dimensions and what do you
193:20 - mean by dimensions is like the size of
193:22 - the house is one dimension then floor of
193:25 - a house is second dimension the number
193:27 - of fans is a third dimension then etc so
193:30 - unlikely that we have three thousand
193:31 - features okay so we have three thousand
193:34 - features so for that it you first of all
193:37 - it will cause storage
193:40 - second it will cost time it will even
193:42 - take months to train your model so it
193:45 - may even take months so you don't have
193:47 - too much of computer resources okay so
193:49 - that's why but in real world we have a
193:51 - millions of dimensions data available so
193:54 - what we do we simply use dimensionality
193:57 - reduction method or technique which is a
193:59 - pca to reduce your model feature with
194:02 - data features or variables okay and we
194:05 - typically see this in text data or image
194:07 - data so let's say you have some image
194:10 - let me draw one image of mine so here's
194:12 - my image so it will the eye has one
194:15 - dimension and it may be a millions of
194:17 - dimensional data sets only one image
194:19 - millions of dimensions one image i have
194:22 - worked on i have worked on to that which
194:25 - is
194:26 - which has 75 dimensions 75 dimensions so
194:30 - we have what we have to work on this
194:32 - typically will be seen on your text data
194:34 - where you will working on ash range
194:36 - processing like what embeddings or image
194:38 - data will be working on
194:40 - images okay so you need the principal
194:43 - common analysis
194:45 - okay so what is principal common
194:46 - analysis principle common analysis is a
194:49 - method for dimensionality reduction that
194:52 - is used to reduce the variables or the
194:54 - dimensions of the data by transforming
194:57 - large set of features
194:59 - large set of features into smaller ones
195:02 - that contains most of the information so
195:04 - let's see
195:06 - you have x1 then you have x2 then you
195:10 - have x3 and all the parameters let's say
195:12 - x 40 let's say 50 okay so what it will
195:16 - common analysis does it ask you a
195:19 - component let's say you have given a two
195:20 - component so it will try to put it will
195:23 - try to put
195:24 - most of the information into the first
195:26 - component x1 and it will try to put
195:28 - let's say p1 and and and in the second
195:31 - component most of the most of the
195:32 - information in these two components
195:34 - because we have say to do
195:36 - reduce from 40 dimension to two
195:39 - dimensions okay so so it will simply um
195:43 - compress that like that or put all the
195:44 - information into the first data
195:46 - variation first and second if you say it
195:48 - is one so it will try to put every with
195:51 - most of the information in the first and
195:53 - it will remove this all so obviously you
195:55 - will lose some of the information from
195:57 - the data but it's good to have uh not
196:00 - more than dimensions okay i will give a
196:02 - tip when you when you have to work on
196:03 - principle component analysis
196:07 - okay so what is the basic intuition
196:10 - basic intuition behind principal common
196:12 - analysis is that we have a principal
196:14 - components which is a new variable which
196:17 - are the new variable like let's say i
196:19 - have i given you know p1 and p2 they are
196:22 - the new principal components which are
196:25 - new variables okay that are constructed
196:28 - as a linear combinations of the initial
196:30 - variables okay so what what what we do
196:34 - uh let's say we have x1 x2
196:38 - all the way down to x40 so we just try
196:40 - to put in all the first and second so
196:43 - it's v it's a hyperbranner two is a
196:45 - complex number of accomplish the high
196:47 - parameter so let's say we have taken two
196:49 - okay so it will try to put most of the
196:51 - information into p1 and p2 and these are
196:54 - the new vectors or the unit vectors or
196:56 - the variables like this all and
197:00 - it's just a linear combination of these
197:03 - variables okay of the initial variables
197:07 - okay you will get to know the through
197:08 - visualization what i'm saying and these
197:10 - combinations are done in such a way that
197:13 - the principal components are
197:14 - uncorrelated they are uncorrelated and
197:17 - most of the information
197:19 - from these variables i mean size branch
197:21 - etc will be compressed into the first
197:24 - components and so on
197:26 - okay and we're projecting each data
197:28 - point on t1 onto only the first few
197:31 - components to obtain a lower dimensions
197:34 - of data please preserving as much as of
197:37 - the data variation as possible so what
197:40 - is this we are projecting etc if you
197:42 - have seen orthogonality concept into
197:45 - an uh linear algebra orthogonality so
197:50 - what it tells so here's an uh
197:52 - visualization of that so here we have a
197:55 - data and what we do we take out the two
197:57 - columns let's say we have two components
197:59 - like this uh first dimension and then we
198:02 - have a second dimension like this
198:05 - okay so we have a second dimension like
198:07 - this okay is these these are the
198:09 - principal components which are
198:11 - constructed which is which are
198:12 - constructed as the linear combinations
198:15 - of the initial variables so what is what
198:18 - we do we project our data point onto
198:20 - this we project our each and every data
198:22 - point onto these
198:24 - diamond uh principle components like
198:26 - this
198:28 - and now our data point will be on this
198:31 - so here's the visualization which is
198:32 - showing more about this so we are
198:34 - projecting each data point onto the two
198:37 - components here we have
198:40 - first component and here we have second
198:43 - component
198:44 - okay this is the basic contribution
198:46 - behind principal components so basically
198:49 - we have let's say this and let's say
198:51 - this one and you have a data point like
198:54 - this okay so you just project the data
198:56 - point onto here you project data point
198:59 - under here to reduce the dimension of
199:02 - the data preserving as much as
199:04 - information as you can in the first
199:05 - component okay so we will see the
199:08 - algorithm so let's start seeing the
199:10 - algorithm to understand a little bit
199:12 - more detail what what we are doing okay
199:14 - but for that let's review some other
199:16 - concept from previous uh sites
199:19 - okay so principal components are the
199:21 - unit vectors uh means they are the unit
199:24 - vectors like the new variables that come
199:27 - out as a p one and p two whatever the p
199:29 - orbital p and p c is the number of
199:31 - components as constructed because
199:33 - from the
199:34 - linear combinations of the initial
199:37 - variables
199:38 - and these combination combinations are
199:41 - done in such a way that the principal
199:43 - components are uncorrelated okay you
199:46 - will see the algorithm by this one
199:47 - correlated etc and most of your
199:49 - information within the initial variables
199:52 - are just in a compressed in the first
199:54 - and then second like this number of
199:56 - components you are given okay very much
199:58 - easy what i'm trying to say here okay
200:00 - and
200:02 - we have seen the basic intuition now
200:04 - it's time for getting into the algorithm
200:06 - so the first step and the first and
200:08 - foremost step of this principal common
200:11 - analysis is data pre-processing what do
200:14 - i mean by data pre-processing means we
200:16 - have to standardize our data so in this
200:19 - step you standardize your data it simply
200:21 - means that your data should be falling
200:24 - in the same range
200:25 - okay so let's say you are working on a
200:28 - sum system like let's say the h uh like
200:32 - the one one one where you have a one
200:34 - variable which is the age
200:36 - so
200:37 - you have eight and let's say the first
200:39 - person is twenty second person is 40
200:42 - like like this so let's say a new
200:44 - percentage is 1 200
200:46 - is far away or far different from these
200:49 - means it is it's called an outlier it's
200:52 - called an outlier which is which which
200:55 - is which is not in the range of age okay
200:59 - and it's which is not in the range of
201:00 - the common ones okay so let's say your
201:02 - data is like 20 40 it's a two three so
201:06 - let's use the five four four thousand so
201:09 - you this is this is kind of a outlier
201:12 - and principal combat analysis is
201:14 - sensitive to outliers okay so what it
201:18 - would do
201:20 - for them for so uh so that's why we do
201:23 - the standardization of the data some
201:25 - sometimes we do normalization also so we
201:28 - do the standardization of the data so
201:31 - our data falls in the same range and the
201:34 - reason why it's critical form because
201:36 - it's quite sensitive regarding the
201:39 - variances of the initial variables okay
201:42 - if you have seen the variance and mean
201:43 - if you and the formula for this is x
201:47 - scale equals to x minus the mean of
201:51 - x x i by the standard deviations okay
201:56 - standard deviation and then you will get
201:58 - the scale formula of your um
202:00 - data and don't worry how to implement
202:02 - this you can also implement this just by
202:04 - coding in python
202:06 - so let's say you have made a function
202:07 - this is standardized it takes the value
202:10 - of x then you should make a new variable
202:12 - x scale then you subtract x minus the
202:15 - mean is np dot mean of x divided by the
202:18 - np dot standard deviation of x okay you
202:21 - can do this but if more formula
202:22 - vectorized code is in scikit-learn you
202:25 - can use scikit-learn to implement it
202:26 - just three lines of code okay don't
202:28 - worry if you're if you are um not able
202:31 - to implement from scratch
202:34 - after first step after you standardize
202:36 - your data now it's time for getting into
202:39 - the computing your covariance matrix of
202:42 - your data so what do you mean by
202:45 - covariance maintenance in the cover is
202:47 - basically a p by p symmetric matrix
202:49 - where the diagonal are the variances of
202:51 - whatever the um data but if you will t
202:54 - you can have i will go to internet what
202:56 - about what is covariance matrix but here
203:00 - after taking out the covariance matrix
203:02 - it will tell you that um that that tell
203:06 - us how to feature how the features of
203:09 - the input data set is varying from the
203:11 - mean with respect to each other okay so
203:15 - here's tells the
203:16 - correlation like that that's not a
203:19 - really correlation but here we have an
203:21 - input date data set like x and it's va
203:24 - out of how much the input data set are
203:26 - varying from the mean with respect to
203:28 - each other means the x1 how it's varying
203:31 - from x2 and etc it is sometimes
203:34 - important because they are some
203:36 - variables highly uh are highly
203:38 - correlated and they contain unnecessary
203:40 - information to work on okay so you
203:43 - should you have to you can remove that
203:45 - okay so that's how we compute the
203:47 - covariance matrix
203:50 - pretty much easy one i'm trying to save
203:51 - here okay so you just denote covariance
203:54 - matrix with c and for implementing
203:56 - covariance matrix you can use the again
203:58 - numpy for the scientific numpy dot np
204:01 - dot cough and you just give the data as
204:04 - your features let's say x and you'll get
204:06 - your output as a covariance matrix
204:08 - okay pretty much just see i'm trying to
204:10 - say you here so let's um see whatever
204:13 - i've seen so far we've seen first we
204:15 - have to pre-process your data like a
204:17 - state of standardization or
204:19 - normalization then we have to compute
204:22 - the covariance matrix of your data which
204:25 - tells you how the input variables are
204:27 - varying from the mean with respect to
204:30 - each other variables okay because it's
204:32 - sometimes important because some
204:33 - variables highly correlated and they
204:35 - contain unnecessary information
204:38 - okay the next step is computing the
204:40 - eisen vectors and eigenvalues of the
204:42 - covariance matrix so let's review what
204:45 - we have seen in eigenvectors and
204:46 - eigenvalues
204:47 - so in either vectors we have seen that
204:50 - if our new transform vector
204:52 - is just a scale from the original vector
204:56 - and the factor is called the horizon
204:58 - vectors and the factored by which is
205:00 - stretched is known as eisen values okay
205:04 - and so that's the eigenvectors and
205:06 - either values
205:07 - the reason why i made this ppt is i if
205:11 - if i write in blackboard that would be
205:13 - not beneficial for you because i would
205:15 - be saying so i had megan know so you can
205:18 - have a look on the future also to see
205:20 - how it's working and it's better to have
205:23 - a text onto the screen to uh while
205:26 - you're listening
205:27 - okay okay so what we do you compute the
205:29 - eyes and vectorize a value of the
205:32 - covariance matrix means you come from
205:34 - eigenvectors are the transform vector
205:36 - from the original vector and the factor
205:39 - by which the
205:40 - is stretched is called the eigenvalues
205:43 - okay you can easily compute the
205:45 - eigenvectors and eigenvalues in python
205:47 - and then what you do you sort the
205:49 - columns of eisen vectors matrix v and
205:52 - i's in value matrix d in order of
205:55 - decreasing value what do you mean by
205:57 - step four
205:59 - let's say your computer eisen vectors
206:01 - are nice and values and those who has um
206:04 - high means high information or high
206:06 - numbers so you just sort the means the
206:10 - larger word in the first then larger one
206:12 - in the first and larger second second
206:14 - third fourth year six seven like this
206:16 - okay and then after that what you do you
206:20 - simply um you'll see oops let me do that
206:24 - you simply uh compute the cumulative
206:26 - energy content how much the content is
206:28 - each eisen vector is having okay and
206:31 - then you select a subset of eigenvectors
206:35 - as a basis vector means let's say
206:38 - you are in cyclone there is a sorry and
206:41 - any other you should choose
206:42 - how many number of components to use
206:45 - okay that's the main thing so what you
206:47 - do you simply
206:49 - sort in decrease in decreasing order and
206:51 - you come
206:52 - the content of each engine vector and
206:54 - then you select who has the high
206:56 - energy or content from the top and if it
206:59 - is your if you choose the principal
207:01 - component two then only two highest to
207:03 - highest will be choose those who have
207:05 - highest number of information okay
207:08 - and then you take this and then you take
207:10 - this two and to project onto the
207:14 - final you project data onto the new
207:16 - basis okay so you prob you have a large
207:19 - amount of again and and then what you do
207:22 - you remove this or you project this um
207:25 - pretty simple component uh this
207:28 - eigenvector onto the new vectors okay
207:31 - and this is the formula and this is
207:33 - random device and this is the feature
207:34 - vector transpose okay so we have seen so
207:37 - far and here's uh uh sap what's the
207:40 - algorithm of steps and i have not
207:42 - written last step which is uh
207:45 - projecting the data you can have a look
207:47 - but because my uh kind of was not
207:51 - fitting okay so first you cross
207:53 - pre-process your data then you compute
207:55 - the covariance matrix then you compute
207:57 - the eigenvector and either values of the
207:59 - covariance matrix then you rearrange the
208:01 - eigenvectors and either values then you
208:03 - compute the cumulative energy content of
208:05 - each engine vectors although it is not
208:07 - necessary because when you sort the
208:09 - integrating order you the top will be
208:11 - having the highest information and then
208:14 - you select a subset of the eigenvectors
208:16 - as basis vectors
208:20 - okay so i think that we have seen so far
208:23 - and i really really hope that you have
208:25 - enjoyed this tutorial and in this
208:28 - section uh previously i think you may
208:30 - find it's quite uh intimidating now i
208:32 - think that you are able to grasp that
208:35 - con
208:36 - concept of linear regression logistic
208:39 - regression support vector machine
208:41 - principal common analysis and then we
208:43 - have current projects and then you have
208:45 - coded boston health risk prediction
208:47 - stock price prediction one
208:49 - classification project you have coded
208:51 - logistic and linear from scratch now in
208:54 - the next section we'll we will cover the
208:56 - principal component analysis from
208:58 - scratch we will do by uh with ourselves
209:00 - to get the more feel of the principal
209:02 - color analysis okay
209:06 - so i really hope that you have enjoyed
209:08 - i'll be catching up your next section uh
209:10 - so let's start with the next section to
209:12 - learn something new okay so now we'll
209:15 - start with learning theory again one of
209:17 - the most important concept to learn in
209:19 - machine learning and
209:21 - i think gaining
209:23 - some something or less
209:24 - we will see the topics which will start
209:27 - in this course
209:28 - in this section is we will see why it is
209:31 - very important means maybe it might look
209:34 - a little bit more nonsense over here but
209:36 - maybe if you are going to tell advanced
209:38 - version of machine learning like deep
209:39 - learning or nlp or computer vision it
209:42 - should surely make sense type that
209:45 - learning theory actually works and in
209:48 - learning theory in this section we'll
209:49 - learn about these three topics our main
209:52 - uh
209:53 - main communication main talk on to this
209:55 - like bias and variance tradeoff and then
209:58 - we'll move on to approximation
209:59 - estimation error then we will move on
210:02 - empirical versus minimization and this
210:04 - this will be our new concept this this
210:07 - this this will be this is these are two
210:09 - just a definition just i don't just just
210:12 - just a problem framed okay just a
210:14 - definition which which is which is
210:16 - needed because in many of these research
210:18 - papers they have listed uh empirical
210:20 - risk minimization of or approximation
210:23 - estimation error the reason why they
210:25 - have maybe some in history they may
210:28 - might be have different something out of
210:30 - different choices okay so we will study
210:32 - we will just see the definition of these
210:34 - and and it will surely make sense but if
210:37 - it is not please be sure to
210:39 - ignore it for now continue with this
210:41 - course and you are free for your feel
210:44 - free to come again okay you're feel free
210:46 - to come again and then watch this do
210:48 - concept because it will surely make
210:50 - sense okay so let's start with bias and
210:54 - variance okay so in bias and variance
210:57 - here we will study about bias and
210:59 - various tradeoffs and here is your
211:01 - warning warning is is learning is is
211:04 - this is one of the easiest concept to
211:07 - learn as instructed by even uh whenever
211:10 - i heard that this easiest concept to
211:11 - learn and it seems to easiest but it's
211:14 - very hard to master very hard to master
211:17 - and i hope that you heard andrew nung
211:19 - saying this and i think this this
211:21 - actually makes sense if you're a
211:23 - beginner then it might not because you
211:25 - will understand everything but it when
211:27 - you are actually developing the product
211:29 - it's a very very important to keep track
211:31 - of bias and various trade-offs and etc
211:34 - okay so let's start with
211:36 - bias and variance but before that we are
211:38 - going to recall our two problems which
211:41 - is
211:42 - my favorite overfitting oops not my
211:44 - favorite it's an overfitting and under
211:47 - fitting okay so here is my favorite
211:49 - diagram uh from the google so here uh
211:53 - let's assume that we have a
211:55 - time and x axis and values and y-axis
211:59 - okay so maybe some kind of problem okay
212:02 - so here you have these data points here
212:06 - you have this data points and what you
212:09 - do you just flip a straight line that's
212:12 - a simple linear regression simple
212:15 - simple
212:17 - linear
212:19 - regression okay you just fitted a simple
212:22 - linear regression which is just theta
212:24 - zero times uh x0 plus theta 1 times x1
212:29 - okay so um plus theta 2 times x2 okay so
212:33 - here you just assume that we have a
212:35 - straight line using a linear regression
212:38 - okay but you can see over here that the
212:40 - tree it is not performing well on the
212:42 - training set also means
212:44 - this is my training set so it is not
212:46 - performing well uh the the residual
212:49 - error or the cost function will be very
212:51 - very high will be very very high
212:54 - okay the cost function which is j of
212:56 - theta which will be very very high in
212:58 - this case so we call it as under fill
213:01 - okay so the major problem makes a major
213:04 - major problem that make this problem
213:07 - occur is that you have a low amount of
213:09 - features
213:11 - low
213:12 - amount of features
213:14 - or you have low amount of data or you
213:17 - have a low amount or you have a low
213:20 - amount of data okay so these two causes
213:23 - the problem so your low amount of
213:25 - features low amount of data okay and
213:28 - that can be that that can be sensed
213:31 - using just by
213:32 - adding more data or adding more feature
213:34 - or if you don't have feature you can do
213:37 - feature engineering to generate more
213:38 - features okay so uh just to do not focus
213:42 - on future engineering for now because
213:43 - it's not a data science course but
213:45 - obviously you just need a simple feature
213:47 - engineering means it's just generating
213:49 - more features based on our features so
213:51 - let's what an example that you are
213:53 - building a spam detection system so
213:55 - let's assume that we are building a spam
213:57 - detection system where you have a one
213:59 - column which is of text another column
214:01 - which is the label whether the whether
214:03 - that text is a spam or ham so it is a
214:05 - label okay so you can generate more
214:07 - feature like length of the text what is
214:10 - the now how many number what is the
214:12 - number of a text in that what is the
214:13 - number of words in that text what is the
214:15 - number of characters so you can you take
214:18 - you using this this this text feature
214:20 - you generate more three features and
214:22 - that's called a feature engineering okay
214:24 - so i think we if you if you if you see
214:27 - i'll be very happy to make a video on a
214:30 - feature engineering okay it will it will
214:32 - be a full place data science course
214:34 - okay so here after this we have our
214:37 - simple linear question which is just
214:39 - like this now this is called underfitted
214:41 - and major problem that i've seen so far
214:44 - in my experience is a low amount of
214:46 - feature stack that we have okay so
214:49 - in general the underfooted me the under
214:52 - underfitting means is just that your
214:54 - model is not performing well on the
214:57 - training set and it's obvious that
214:59 - you'll not perform well onto the testing
215:02 - set so that's why we call this under
215:04 - fitting okay the next picture of here is
215:08 - good fit slash robust robust means it
215:11 - will it will be very robust which is a
215:13 - very good fit you can see you it is a
215:14 - very good fit the cost the residual
215:17 - error is low the residual error is low
215:21 - and it says we have a very good
215:22 - polynomial kind of thing um
215:26 - a
215:26 - non-linear uh or or i can see here
215:29 - against a nonlinear
215:31 - or a polynomial regression over here we
215:33 - have applied polynomial regression and
215:35 - here's what we get the as a as a as a
215:38 - hypothesis okay so here you can see that
215:41 - is a very good fit and this is this is
215:42 - the robust model okay so we can say that
215:45 - this model is performing well under the
215:48 - training set
215:49 - as well as on the testing set because
215:51 - whatever example will come here the
215:53 - residual error will be low okay so like
215:56 - like that is perfecting well under
215:58 - training and testing set another picture
216:01 - which tells you about overfitting what
216:03 - do you mean by overfitting overfitting
216:05 - simply means that your model performs
216:06 - very very well or i can say that your
216:08 - model wants very very well under
216:10 - training set where your cost function
216:12 - your cost function of j of theta is
216:15 - equals to zero okay where you you don't
216:18 - have any residual error or approximately
216:20 - equals to zero okay so your cost
216:22 - function is very very low so you can
216:24 - assume that your model learned a lot
216:26 - which is touching each and every
216:28 - examples your model learned a lot so
216:30 - that's why your cost function is very
216:31 - very low and cost function is just
216:33 - denoted by the submission over i equals
216:35 - to 1 all the way down to the m
216:37 - h of x i h of x i
216:40 - minus y i squared okay and just taking
216:43 - out the difference between the predicted
216:45 - and actual value and here the the
216:48 - predicted and actual value are on the
216:50 - same line so here you you your model
216:53 - want a very nonlinear
216:54 - hypothesis it all it happens
216:57 - that if if you have a lot of features a
217:00 - lot of features and here you have a low
217:03 - features and here if you have a lot of
217:05 - features that happens okay and maybe you
217:08 - have used too much of degree in
217:09 - polynomial regression so that's why it
217:11 - happens or maybe something kind of a
217:14 - other no a very kind of complex
217:16 - architecture or you have or you have
217:18 - made a very complex function f of x with
217:20 - the highest
217:21 - x4 etc like that like that okay so this
217:24 - is this is the this is the problem for
217:26 - overfitting and whatever new example
217:28 - come over here your model will be very
217:30 - very high whatever come here the
217:32 - residual layer will be very very high
217:34 - okay so your model will fail to
217:36 - generalize well onto the new training
217:39 - examples okay so
217:41 - in general overfitting means over
217:44 - overfitting means that your model
217:46 - perform bad or or against your model
217:49 - perform very very well under training
217:51 - setting which your cost function is low
217:54 - is is it is equal to zero which is
217:56 - actually good but but you you may think
217:59 - it is good but just just wait that your
218:01 - testing set error is very very high okay
218:04 - so that indicates the problem of
218:07 - overfitting so
218:09 - we can prevent overfilling by selecting
218:12 - some of the important features
218:14 - selecting important features or
218:17 - regularization so regularization is just
218:20 - advanced version of selection of
218:22 - features so let's see what it does
218:24 - okay so i have already told you about
218:27 - regularization now in our regularized
218:30 - linear models and i hope that you
218:31 - understood that okay so now we will uh
218:35 - see the bias and variance trade-off by
218:37 - taking a look at some scenario of your
218:39 - model okay so let's assume that you are
218:42 - building some model okay so you are
218:44 - building some model and your model gives
218:46 - one percent error one percent error on a
218:48 - training set so you have one training
218:51 - training set like this
218:52 - and you divided this training set into
218:55 - uh training
218:57 - and evaluation set so you have this
218:59 - whole data you have this whole data and
219:02 - you divided this in training and
219:03 - evaluation set okay so what you've done
219:06 - you've taken a one percent adder under
219:09 - the training set one percent adder on a
219:11 - training set which is uh if you see oh
219:14 - you one percent error one percent error
219:17 - on a training set and fifteen percent
219:20 - error on the evaluation set so you can
219:23 - assume that your model is you can see
219:25 - that your model is overfilling because
219:27 - your error is very very low end training
219:29 - set but your error in validation set is
219:31 - actually 15 which is very high okay
219:34 - according to this okay so it is
219:36 - performing a very very well on a
219:38 - training set but it's fails to
219:40 - generalize well onto the testing set so
219:43 - it is overfitting and in this case we
219:46 - say that the model is having high
219:49 - variance and we use bagging we use
219:51 - bagging to reduce high variance which
219:54 - you will see in ensembl learning methods
219:56 - or sections so don't don't worry you can
219:58 - come back again to this section to watch
220:00 - this okay so this is this is how you
220:03 - identify if your model is having high
220:05 - variance next
220:07 - next is that let's assume that your
220:09 - model is giving a 15 percent adder on a
220:12 - training set on the training set okay
220:16 - 15 percent add-on training set and
220:18 - sixteen percent adderall
220:20 - on evaluation set so it is not
220:22 - performing well under training set
220:24 - obviously to not perform well on the
220:26 - evaluation set so it seems to be
220:28 - underfitting so here it has high bias
220:32 - and we use boosting we use boosting to
220:35 - reduce bias
220:37 - okay so this is this this is what i'm
220:39 - saying and let's take let's stick for
220:42 - the sake of an example again again
220:44 - example that your model is having both
220:46 - high bias and high variance where you
220:48 - have a 15 percent error which is
220:50 - obviously high variance and 30 percent
220:53 - error on evaluation which is obviously
220:55 - high bias okay so it is both overfilling
220:57 - and unfitting and obviously it has a
220:59 - high bias and high variance okay the
221:01 - next our favor and last example of this
221:04 - bias and variance tradeoff is your model
221:06 - gives 0.5 percent model gifts 0.5
221:09 - percent or training set and one percent
221:12 - underscore testing set so it seems to be
221:14 - a perfect model or a robust model where
221:17 - it's not learned too much on training
221:18 - setting for it is a very robust and good
221:20 - model okay here it seems to be a good so
221:23 - we can say it is it has a low bias where
221:26 - it has a very small error and it has a
221:29 - low variance where it has on training
221:31 - set is a very good okay so this is this
221:33 - is what we consider for low bias and low
221:36 - variance and all of these all of these
221:39 - we take assumption do you know what
221:41 - assumption oops you don't know but
221:42 - because you're watching but uh
221:44 - when we take an assumption that base
221:47 - error or human level performance or
221:50 - human or human
221:52 - level performance human level
221:55 - performance is approximately equal to
221:58 - zero percent is approximately equal to
222:01 - zero percent so what do i mean with this
222:04 - assumption i what what do i mean with
222:06 - this assumption that we take our base
222:08 - error to be base error base error to be
222:12 - approximately zero percent in all of
222:14 - these examples in all of this example
222:16 - this example this example this example
222:19 - okay so let's see what's that human
222:20 - level of bayes error is so here you can
222:23 - see that you're you're you're going to
222:25 - build some uh classification model or
222:27 - maybe the face detection model okay so
222:29 - your build your you have built the face
222:31 - detection or face recognition or real
222:33 - time face recognition so your algorithm
222:36 - even you will fail to identify this
222:39 - person even i will fail to identify this
222:41 - person the reason why because it's very
222:44 - blurred very very very with blood okay
222:46 - so even a human even a human
222:49 - human error okay hlp you even in human
222:53 - error will be very very high very very
222:55 - high because he will be not able to he
222:56 - will be not able to uh either identify
222:59 - who's this person is okay so so so and
223:03 - you can cannot expect that your model
223:06 - should be very great over here you can
223:09 - expect that your model is very your
223:11 - model is also giving the same error as
223:13 - you are giving because you are also not
223:14 - able to identify as well as your model
223:17 - also not not able to identify and
223:18 - actually this is not this is here the
223:21 - hlp hlp is very very high or i can say
223:24 - the base error is very very high so we
223:26 - can say that here um you can
223:30 - you cannot expect your algorithm to work
223:32 - best but let's assume that that you have
223:34 - a fresh image and where the hlp is
223:37 - equals to zero means human level
223:38 - performance is equal to zero and you now
223:41 - you can expect your algorithm
223:42 - performance to be good because it is the
223:44 - human performance is equals to zero so
223:47 - that's called the base error and and i
223:49 - hope that you understood the next
223:51 - uh we we have talked about bias and
223:53 - variance trade-off you can again rebound
223:55 - this video to understand again but what
223:57 - is approximation estimation error this
223:59 - is just a definition
224:02 - so the approximation estimation error
224:05 - approximation error in some data is the
224:08 - difference between exact value and the
224:10 - approximation of it and this
224:12 - approximation indicates your f of x
224:15 - means the outputted model uh the output
224:18 - from the model so we here your f x given
224:21 - some approximation and this is the
224:23 - ground truth which is y hat okay so
224:26 - difference between these both is called
224:28 - as approximation error okay so here i've
224:31 - taken one example from wikipedia again
224:33 - it's a scale example but that's that's
224:35 - that's generally mean i i already told
224:37 - you 9 cost function you take out the
224:39 - difference between that's an
224:40 - approximation estimation error okay so
224:42 - it's just like this if the exact value
224:44 - is 50 and the approximation is 449.9
224:48 - then the error will be 0.1 and that's
224:50 - actually what you do when taking out the
224:52 - error for one training example you just
224:54 - subtract this and the regression problem
224:57 - what you do you just subtract y hat
224:59 - minus y and then and you get your answer
225:02 - okay and then you add submission for
225:04 - every i for every eye etc okay so this
225:06 - is what you do and this is just a
225:08 - definition because you will see a lot in
225:09 - your research papers okay next one is
225:12 - empirical risk minimization again we
225:14 - have seen so an algorithm receives as an
225:17 - input on a training set so i'm going to
225:19 - just i make you familiar with this what
225:21 - i'm saying that an algorithm receives as
225:24 - an input a training set as means
225:27 - we we get and we get our training set
225:30 - which is a sample from the large
225:32 - distribution d okay so we get our sample
225:36 - from the distribution d means large we
225:38 - just take out some
225:39 - sample and label by some target function
225:42 - y okay so here we have our training set
225:46 - as well as we'll be having the labels
225:47 - for it because this is a this is framed
225:49 - on supervised learning okay so here we
225:52 - will be having label as well as the
225:54 - samples for each training example okay
225:56 - and should make a predictor we should
225:58 - make a f
226:00 - the predictor that maps our input
226:02 - variable x means these features to the
226:04 - output variable y okay and the goal of
226:07 - this algorithm is to minimize the error
226:09 - outputted with the respect to the
226:11 - unknown d means now we will feed a new
226:14 - example that a model has not have
226:16 - even seen
226:17 - and your model should be very minimal or
226:20 - you or your or your model should be
226:23 - audio model errors should be very
226:24 - minimal okay so this is what the full
226:26 - definition is saying
226:28 - and it simply means that we want to come
226:31 - up with the predictor l
226:33 - subscript s h we're going to come up
226:35 - with the l of h with sub subscript s
226:38 - where s emphasis the fact that the
226:41 - output predictor depends on s okay so
226:44 - whatever the output will be it depends
226:46 - on s because we have taken we have
226:48 - learned we have learned the weights we
226:50 - have learned the w we have learned the
226:52 - theta one theta two all around n from
226:55 - these s so that's emphasizes that
226:57 - minimizes the risk or the error which is
227:00 - called the erm which is called the
227:02 - empirical risk minimization okay so i
227:05 - hope that you understood this concept
227:07 - very much clearly and i really hope that
227:10 - you had enjoyed seeing this section and
227:13 - we i have talked a lot on empirical risk
227:16 - minimization learning theory and et
227:18 - cetera so i hope that you will utilize
227:20 - this uh way and we have already talked
227:22 - about uh
227:23 - the job and now you can continue further
227:25 - if you haven't understood anything you
227:27 - can feel free to ask in the comment box
227:29 - below i'll be very happy to take your
227:30 - down and be sure to have a look at the
227:33 - course website which is already
227:34 - available in the description box below
227:36 - so meet you in the next section
227:38 - okay a very warm welcome in this section
227:41 - and
227:42 - in this section we will be talking about
227:44 - decision tree one of my favorite topic
227:46 - to talk on as i will go in depth of
227:50 - decision tree to make you understand
227:52 - everything and decision free with
227:54 - intuitive examples with solved examples
227:57 - of decision tree as i have seen on
227:59 - youtube that they are there some
228:01 - instructors are doing great job but they
228:03 - are not doing that into decision tree
228:06 - means for free so i just want to make
228:08 - you familiar with decision tree whoever
228:10 - is watching this tutorial into depth and
228:14 - i really hope that you will enjoy this
228:16 - section but before that what we are
228:18 - going to cover in this section are as
228:20 - follows first we will start with the
228:23 - introduction geometric intuition a basic
228:26 - intuition about decision tree what the
228:28 - actual the decision trees are
228:31 - and then we will go further into how we
228:34 - were building that decision tree so for
228:36 - building we will learn some sub tasks of
228:39 - concept which is like entropy
228:42 - information gain a guinea impurity okay
228:45 - then after that we will build our own
228:48 - decision trees and then i will show you
228:51 - the implementation of decision tree okay
228:54 - but before that let's uh understand the
228:56 - basic intuition of decision tree as
228:59 - there will be more topics which we'll
229:01 - cover
229:02 - as i will discuss later on okay okay so
229:04 - let's start so uh first of all what is
229:07 - decision tree decision tree is a
229:09 - supervised learning algorithm okay so it
229:12 - is a supervised learning algorithm and
229:14 - what do i mean by supervised learning is
229:16 - that we are having our uh
229:19 - x rx 1 with our label y1 all the way
229:23 - down to the x2 then we have i2 all the
229:27 - way down to the xn
229:29 - and we have y okay so we are having
229:31 - labels so it is a supervised learning
229:33 - algorithm
229:34 - and it is used for both like support
229:37 - with the machine is used for both
229:38 - regression classification so it is used
229:41 - for both uh classification and
229:43 - regression okay so uh you will see how
229:47 - we do how we construct the distant tree
229:49 - like that okay so let's start with um
229:52 - the basic intuition of decision tree so
229:54 - the definition of decision trees that
229:57 - they are nested if an else
229:59 - statements okay if you're a programmer
230:02 - then you will be relating this concept
230:04 - which is if and else and the python is a
230:06 - prerequisite or any programming language
230:08 - is a prerequisite so
230:11 - what is this entry it is just a nested
230:14 - if and l statement so it is a nested it
230:18 - is a nested if and else statement so i
230:21 - don't know why it is so bold so it is a
230:24 - nested if and else statement
230:26 - um so is what it does is just ask a
230:29 - question and it splits the data okay so
230:32 - let me write the formal definition to
230:34 - make your more uh intuitive intuition
230:36 - behind so they are
230:39 - nested
230:40 - nested
230:42 - if and else
230:45 - statements okay so he's just ask
230:48 - questions is just ask questions
230:51 - is just ask questions and splits the
230:53 - data okay so it's just ask question and
230:56 - splits the data so
230:58 - let me take one example of iris data set
231:02 - let me take one example
231:04 - of iris
231:06 - data set okay so what we do when iris
231:10 - data set so but
231:12 - what let me make you familiar with what
231:14 - is that this data set to make you more
231:17 - clear understanding of this topic okay
231:20 - so iris data is simply like this you
231:23 - have a data set which has four features
231:26 - like sepal length sepal with petal and
231:28 - parallel petalworth okay and you have
231:30 - the label which is the species of the
231:32 - flower okay so this is a task of flower
231:35 - species detection under the basis of
231:38 - four features okay so this is a
231:40 - classification data set a binary class
231:43 - classification data set so you were
231:46 - having and like this so let me change my
231:48 - color i don't know why it is so bold
231:50 - okay so you have like this uh first you
231:54 - have sepal length sepal length and then
231:57 - i i i hope that you understand what is
232:00 - sepal and what is parallel so sepal
232:02 - width then you have petal length
232:05 - and then you have a petal width okay and
232:09 - then you have a one more column which is
232:11 - the label which indicates for the
232:13 - species so let's take an example 2.2
232:16 - 4.30 that's a 3.2
232:19 - 4.6 and the label is um acetosa satosa
232:23 - okay so you have three classes in this
232:26 - data set as a label which is cetosa
232:29 - which we label as one sorry zero
232:32 - versicolor versicolor which we label as
232:37 - one and virginica virginica which is
232:41 - labeled as two okay so the output will
232:44 - be either zero means a tossa then either
232:47 - it will be one means we're cycler or
232:49 - virginica as in quotas as two okay so
232:52 - that's the iris data set that i had just
232:55 - make you familiar with okay so let's
232:58 - what what we will do we will not make
232:59 - use of any library will not be used and
233:01 - then anything we will simply what what
233:04 - we will do we will simply make a
233:07 - decision tree by yourself by making just
233:09 - if an else condition okay so we'll make
233:12 - a simple classifier obviously it is not
233:14 - so formal but we'll make a simple
233:16 - classifier that will simply classify
233:18 - your flowers okay so that's what we are
233:21 - going to do
233:23 - so let me remove this and i really hope
233:25 - that you understand what this data set
233:27 - is and more uh understand uh if you want
233:30 - to more in detail about what the data
233:32 - set is you can search online this is a
233:34 - famous data set like iris state data set
233:37 - which is just for flower species
233:39 - detection system okay so
233:42 - let's start so first uh
233:45 - here we have an um variable x's here we
233:48 - have our x's which is sepal length sepal
233:52 - width parallel length and parallel width
233:56 - okay so we are having these features and
233:58 - we have a y i which indicates either one
234:02 - or two or two or zero or two okay so
234:06 - that's the basic intuition uh means of
234:09 - the data set part we are given this data
234:11 - set now what we will do we will make
234:13 - classifier like this first if we write
234:17 - if let me choose another pen okay i i
234:20 - hope that i should choose a better pen
234:22 - like this blue okay okay so if
234:26 - the parallel length is smaller than some
234:29 - a and may a may be some number a maybe
234:32 - some number let's say let's say 2.3 a
234:36 - maybe some number if petal length is
234:39 - smaller than a then consider
234:42 - y
234:43 - to be um
234:44 - for cycler okay so let's consider y to
234:47 - be one okay
234:49 - if not if it is parallel length is
234:51 - greater than a then what do what what to
234:54 - do oops i hope that it is getting not
234:58 - clear
234:59 - what what happened
235:01 - i have to buy my new computer why do i
235:03 - don't know what to why it is so much
235:04 - lagging okay so you'd if it is smaller
235:07 - than a the parallel length then consider
235:10 - your flower is means of
235:12 - a versailles color and we have we have
235:14 - made one one and if if it is parallel
235:17 - and if your parallel length is not is is
235:19 - greater than a then what you will do you
235:21 - will write else
235:23 - if
235:24 - separate you take again one feature you
235:26 - take a game one feature and says if it
235:28 - is smaller than b if sepal length is
235:31 - smaller than b
235:32 - then you will you consider your y to be
235:36 - uh virginians too okay
235:38 - if it is not if it is not if both is
235:42 - both condition fails then say if both
235:45 - condition fails then say that your
235:48 - output is setosa okay so here is our
235:52 - simple decision tree we're using two
235:55 - features we have made the decision trees
235:59 - using two features so let me make it
236:01 - more intuitive i i i hope so that you
236:04 - are able to understand okay so that's
236:06 - why i'm speaking very slow so here let
236:08 - me tell you what i'm if petal length
236:11 - here we are we have taken two features
236:13 - which is petal length and sepal length
236:15 - okay we had not taken this uh this two
236:18 - features okay but you can make that but
236:20 - this is not a formal decision tree this
236:22 - is just for an example this is obviously
236:24 - not correct okay so
236:26 - you had to
236:28 - make a mid one if condition that if the
236:31 - parallel length is smaller than some a
236:34 - and a can be anything 2.3
236:36 - 4.3 that that is usually i'm taking
236:39 - anything but it is usually taken uh
236:41 - which will see um in one of our data set
236:45 - we will see how it is chosen and you
236:47 - will obviously see how it is selected
236:49 - okay so if it is smaller than a parallel
236:52 - length then consider that y
236:54 - to be equals to one if it is not let me
236:57 - check that this recording is on here
236:59 - okay regarding is on okay so we if the
237:02 - parallel length smaller than a then we
237:04 - consider our y to be this uh versionica
237:08 - okay if the pedal length is greater than
237:10 - a or is it this this this condition
237:13 - fails this condition fails it then goes
237:15 - to else condition and in else condition
237:18 - it this is again a nested loop nested
237:21 - sorry not if an assess control flow just
237:24 - check if your sepal length is smaller
237:26 - than b if it is then you say that y
237:30 - equals to virginica okay and otherwise
237:33 - if this condition also fails then it
237:35 - says else your y means y should be
237:38 - satosa and you have this hole into the
237:41 - this
237:42 - nested loop in this and you have this
237:43 - whole classifier and this is your whole
237:46 - classifier so that this is the decision
237:48 - tree yeah so let me make this
237:50 - diagrammatically in the terms of
237:52 - decision tree so
237:54 - in terms of decision tree we can write
237:56 - this equation this uh
237:58 - this if
237:59 - statement first we have our root node
238:02 - this uh we have first we make our root
238:04 - node like this
238:06 - let me make one root node here we have
238:09 - our root node
238:10 - with this condition if a parallel length
238:14 - parallel length is smaller than a okay
238:17 - then if it is if it is yes
238:20 - then you say your y to be
238:23 - one okay if it is no if your parallel
238:26 - length is no okay you consider you again
238:29 - make one more condition which is sepal
238:31 - length is smaller than b if it is yes
238:34 - then you what you do you classify this y
238:36 - equals to two if it is not if it is not
238:39 - then you take it as a zero and your
238:41 - whole three variable uh target variables
238:43 - are covered and this is the decision
238:46 - tree and this is whole this is the
238:49 - decision tree i have made in yellow this
238:51 - is the decision
238:53 - tree is just ask a question on the data
238:56 - set if the pedal is smaller than a if it
238:58 - is then consider y equals to one if it
239:01 - is not then again we have made another
239:03 - another decision and then we uh if it is
239:05 - yes or if it is known like this okay so
239:08 - that's the this is the decision tree
239:10 - it's damn is like this okay so here
239:13 - again i'm saying this is what you do
239:15 - just believe me yeah we had this is the
239:17 - decision tree and how it is constructed
239:19 - we will see okay so we have made this as
239:22 - a final statement yesterday if an else
239:24 - statement like this and this is what the
239:26 - decision tree is so here are certain
239:28 - terminology that we will have to see
239:31 - over here
239:32 - so here are the the details that we
239:35 - should
239:36 - know okay so the the
239:38 - the first node or head node is no is
239:41 - known as root node is known as a root
239:44 - node or parent node okay this is this is
239:47 - a root node obviously this is also a
239:49 - parent node and these are the child node
239:53 - these are the child node
239:56 - okay child node and this is the parents
239:59 - node and this is also the parent node
240:02 - and this is the terminal node this is
240:05 - the terminal or leaf node because you
240:09 - are not splitting this node into further
240:12 - nodes so this is called the terminal and
240:14 - this is also a terminal node this is
240:17 - also a terminal node okay this is also
240:20 - terminal or a leaf node this is some
240:22 - sometimes called a leaf node when you
240:24 - are not spitting further okay so this is
240:27 - a leaf node or you consider it as a leaf
240:29 - node this is the whole thing is called
240:31 - the branch this whole thing is called
240:34 - branch
240:35 - use
240:36 - this whole thing is called branch okay
240:39 - and that's the basic terminology of this
240:42 - okay and this is the splitting of your
240:44 - data okay this is the this is what you
240:46 - are doing doing which is splitting okay
240:49 - if you're removing some node let's take
240:51 - an example this then you are pruning it
240:54 - okay then you are pruning this node but
240:56 - we and we don't know we don't want right
240:58 - now okay so that's the that's what
241:01 - that's the decision free and i hope that
241:04 - you understood this example
241:08 - clearly and i really really hope that
241:10 - you will uh that you got a very good
241:12 - intuition of decision tree in much
241:14 - smaller span of time in much easy way
241:17 - okay so i hope that you remember this
241:20 - terminology either i will make you
241:22 - familiar with terminology by the time
241:24 - also if it is not required for
241:26 - remembering all those things okay but
241:28 - this is it's it's best to
241:31 - take a paper and a pen and write notes
241:33 - with me whatever i'm writing okay and
241:36 - just listen me carefully
241:38 - after listening me you can make notes
241:40 - okay so now let's see what's the
241:43 - decision boundaries will look like
241:46 - okay what's the decision boundaries will
241:49 - look like or the hyperplanes will look
241:51 - like but what do i mean with hype
241:53 - airplanes i mean with hyperplane
241:55 - decision boundary is let's take an
241:58 - example of linear regression in linear
242:01 - regression we are making a straight line
242:03 - this is called the hypothesis decision
242:05 - boundary then we have a hyperplane it's
242:07 - called the hyperplane in support victim
242:10 - machine we are also making hyperplane in
242:12 - logistic regression we are also making
242:14 - hyperplane means a decision boundary so
242:17 - in the decision decision tree we also
242:19 - have the diffusion boundaries okay or
242:21 - hydroplanes so let's see how it is
242:23 - constructed so i don't know i will be
242:26 - able to make that image or not but i
242:28 - will fully try that okay so here uh let
242:31 - let me make one x and y plane x and y
242:35 - oops i'm
242:36 - please anyone help me to make this
242:40 - okay let me do that oops i'm just
242:42 - freaking out let me do it again
242:45 - yeah okay great so i have made one and
242:48 - this is my x-axis
242:50 - this is this is my x-axis and this is my
242:52 - y-axis and we have a two features which
242:54 - is sample length and uh parallel uh
242:57 - length i think so yeah so we have
242:59 - parallel length in the x-axis and we
243:01 - have separate length in the y-axis okay
243:03 - so we i i have just made it you can
243:05 - remove this y-axis maybe it will confuse
243:07 - you in in our x's we have petal length
243:10 - and y axis pf zeppelin because we have
243:12 - taken only two features in this example
243:14 - we have we are not taking more features
243:16 - like parallel with and past apple width
243:18 - okay so what what we consider what we
243:21 - have done we have considered we have
243:24 - considered
243:25 - this full reason we have considered this
243:28 - full reason
243:30 - this full reason
243:32 - to be y equals to one okay
243:36 - this hyperplane this hyperplane list
243:38 - let's name it as a first type of plane
243:41 - so this full reason is our y equals to
243:44 - one means whatever data point will come
243:46 - is considered y equals to one and this
243:48 - is just this is just the if statement
243:50 - that we have seen if parallel length if
243:53 - parallel length is smaller than a okay
243:56 - then y equals to one so that's this is
243:58 - the full reason okay means we have not
244:00 - for this bit so it is just a full reason
244:02 - where y equals to one if that condition
244:06 - passes
244:07 - okay then another hyperplane we can
244:09 - construct let me choose another pen
244:12 - another hyperplane be construct that
244:14 - this reason
244:16 - this reason
244:17 - would consider
244:18 - y equals to
244:21 - 2 okay y equals to 2. if
244:24 - the sepal length is smaller than b if
244:27 - the points come in this
244:30 - region then it is it will consider y
244:31 - equals to 2.
244:32 - another we have hyper plane let me take
244:35 - another pen that let me take another pen
244:38 - let's take an example of blue
244:40 - okay
244:41 - another outcome we can consider that as
244:43 - a y equals to three okay if that
244:46 - if that falls in this region so here we
244:48 - are constructing hyper planes and if
244:51 - some with something come here then
244:52 - control y goes to one it's y equals to
244:54 - two or y equals to three with these two
244:57 - features obviously it will be more
244:59 - dimensionally high when you plot the
245:02 - four features okay so
245:04 - you can see that we have a hyper planes
245:06 - where we are able to make predictions
245:08 - okay and we have made a simple
245:09 - classifier okay but something to note
245:12 - over here that all your hyper planes are
245:16 - axis parallel okay our x is parallel
245:21 - means this is parallel and this is
245:23 - parallel so you can see over here that
245:26 - all the hyperplanes are x is parallel
245:29 - okay so that's the i i hope that you
245:31 - understood decision trees in that and
245:35 - um this is the basic exam intuition that
245:38 - i want to give it to you in more uh
245:40 - sophisticated way or not sophisticated
245:43 - it's just a good way okay
245:45 - okay so as i've tried it to keep it as
245:47 - simple as i can and i kept it okay so
245:50 - let's uh let's
245:53 - let's start building or let's start with
245:55 - mathematical region that's how we
245:57 - construct these kind of decision trees
246:00 - these kind of decision trees how we
246:01 - construct okay so
246:05 - but before that we have what what what
246:08 - we do we uh
246:10 - how we choose the variable or how we
246:13 - choose the feature to be the root node
246:15 - or the bran or this this how we split so
246:19 - we have attribute selection measure and
246:22 - you if you select run randomly like i
246:24 - have choose a petal land of you if you
246:26 - choose ran randomly then you will be
246:28 - ended a very bad model so we have
246:31 - different attribute selection measure we
246:33 - like entropy information gain gain
246:36 - impurity which we'll see in detail to
246:38 - understand the how we select the
246:40 - attribute to be as a root node or like
246:42 - this okay so let's take a let's take an
246:45 - example of this data set if you want to
246:47 - split this data set what feature you
246:49 - will use you
246:51 - what are you going to use outlook as
246:52 - your feature root node or temperature as
246:55 - a root nor or humidity as a root node or
246:57 - when as a root node okay and play tennis
247:00 - is our uh label so which you will use if
247:02 - you choose run randomly maybe you will
247:04 - be end up ending up with a bad model
247:07 - okay so you have to do that kind of
247:09 - thing no so we will we will uh
247:11 - scientists or researchers have done a
247:14 - very great job even you all have to do
247:16 - all this kind of thing research and
247:18 - please keep contributing to the ai
247:20 - community that maybe and i'm also doing
247:23 - research in machine learning and
247:25 - definitely will come up with something
247:27 - extra okay so um different measures
247:31 - different measures are
247:33 - different attribute selection measure
247:35 - are entropy we have entropy
247:38 - then we have the second number we have
247:41 - information gain information gain
247:44 - information gain
247:47 - which we usually write as ig
247:51 - then we have guinea impurity then we
247:53 - have
247:54 - guinea impurity
247:56 - and is simply
247:58 - uh
247:59 - i
248:00 - g okay so we denote like this okay so uh
248:03 - we will talk about all of these three
248:06 - and i and i hope that you will uh
248:09 - understand each of them okay so let's
248:11 - start with entropy okay
248:14 - so
248:15 - uh
248:16 - entropy let me write it more formally
248:19 - yeah so what first of all what is
248:21 - entropy entropy is the attribute
248:24 - selection measure it's the measure of a
248:27 - randomness okay how pure or how pure
248:30 - that attribute is to be used as some
248:33 - nodes or a root node okay so it's the
248:36 - measure of randomness so let me write
248:39 - the definition because definition is
248:40 - also important and if you want this kind
248:43 - of all my notes you can simply write me
248:45 - right with me along either you can
248:48 - comment or
248:50 - join the newer community discord
248:51 - community and ask me there i will be
248:53 - able to give okay so ask me there i will
248:56 - be able to give all this entropy etc is
248:58 - the measure is the measure
249:02 - of randomness it's the measure
249:05 - of
249:07 - randomness okay the higher the entropy
249:10 - is the higher the the higher the entropy
249:13 - is the harder to draw any information
249:16 - from them okay so it's if the higher the
249:19 - entropy is it's very hard to break your
249:22 - uh
249:24 - node okay or to choose the node so um
249:27 - our entropy should be low to to be
249:29 - considered as is uh leaf node but still
249:32 - don't don't worry i will dig dive into
249:34 - the cases to make you more understand
249:36 - what do i mean with these terms okay but
249:38 - first of all uh let's take and i will
249:41 - show you one equation and then i will
249:43 - show you um how some first of all one
249:46 - example and then i will show you
249:47 - properties of entropy okay so first of
249:50 - all uh
249:53 - let's take an example where you were
249:54 - given you have y
249:57 - to be maybe uh
249:58 - y1
250:00 - y2 all the way down to the y k and in
250:03 - this case you are naughty this is not
250:05 - examples this is a this this is like
250:08 - maybe satosa means what is the number of
250:11 - classes you have okay so um maybe you
250:14 - have binary classifier or you have a
250:16 - multi-class classifier okay so you what
250:19 - is the number of a classifier so maybe
250:21 - you have in the in the iris satosa we
250:23 - have here's uh versus
250:26 - tosa vergenic and ver cycler so we here
250:29 - we have y equals y equals to y1 to
250:32 - vctosa then we have virginica then we
250:36 - have very cycler means three wise okay
250:39 - so that's what i mean with this okay so
250:43 - let's first of all let me give you um
250:45 - let let me give you the equation okay so
250:48 - the equation is defined as like this
250:51 - h we define our entropy by h
250:54 - equals
250:55 - to let me choose white color because i
250:58 - like white much okay
251:00 - minus mini uh this is this minus is very
251:03 - important minus
251:05 - the submission
251:07 - i equals to 1 all the way around to the
251:09 - k and k here is the number of your what
251:12 - is the class what is the number of a
251:14 - class okay
251:16 - p of y probability being y i
251:21 - log
251:22 - of base and b is usually taken as 2 or e
251:28 - okay to a 2.713
251:30 - okay so b is usually taken as 2 or 3 but
251:34 - usually take b as a 2. so if you were
251:37 - taking p as a 2 then you can consider it
251:40 - as l g if you're taking b as a e then
251:43 - then you take as l and natural logarithm
251:46 - and you have a log 2 base a log 2 um
251:49 - with a log with a base 2 okay this means
251:52 - lg okay so you take log
251:55 - of
251:56 - p
251:57 - of
251:58 - y i okay and that's the full equation of
252:02 - your entropy means it's just measures
252:05 - the randomness okay so let's let's take
252:07 - one example because it is i i i i know
252:11 - that is making no sense to you and i
252:13 - know that is making no sense to you but
252:16 - i will make sure that it will make sense
252:18 - okay so
252:20 - first
252:21 - is
252:22 - you we want to measure our randomness
252:25 - for playing golf okay you want to
252:28 - measure your randomness for playing golf
252:30 - okay so let me write play
252:33 - golf
252:34 - oops uh let me write the data set first
252:37 - what's the data set we'll be using so we
252:40 - have this play golf data set play
252:43 - goal data set
252:46 - where if it is what is the number of
252:49 - yes
252:50 - which is
252:50 - 9
252:52 - and what is the number of uh no which is
252:55 - 5
252:57 - okay so this is our data set like this
253:00 - and let me make this also okay so this
253:02 - is a day-to-day data set and you want to
253:04 - take out the entropy of playing golf
253:07 - okay playing golf
253:10 - okay and here we want to take out
253:13 - entropy of being no
253:15 - being no
253:16 - and being yes
253:18 - okay so what you do first
253:21 - you take out
253:23 - the entropy entropy of 0.36
253:29 - log 2
253:30 - 0.36 minus means this is your first this
253:34 - is your first
253:36 - y i this is your first y means yes sorry
253:39 - no this is for no and minus let me make
253:43 - it
253:44 - up okay minus
253:46 - 0.64
253:48 - log
253:50 - base 2
253:51 - 0.64
253:53 - okay
253:54 - this is what we have and the answer is
253:56 - 0.94
253:58 - okay so here what we what what we are
254:01 - doing over here that first we are
254:04 - writing this this equation p of y i
254:07 - times the log of for no and then we are
254:10 - writing for a yes okay and there is
254:13 - subtracting and we have um entropy at
254:17 - 0.94 and it can be further splitted okay
254:21 - okay so this this this was the
254:24 - basic calculation of entropy but let's
254:26 - see some cases of entropy to make you
254:30 - more sense of this uh entropy um
254:35 - attribute selection measure okay so we
254:38 - will see some properties so let's uh
254:40 - consider let's consider that that we
254:42 - have y to be two class means we have a
254:45 - binary classifier we have where we have
254:46 - two class one is yes one is yes and
254:50 - other one is no okay
254:52 - any kind of yes or no whether it is
254:54 - playing tennis or etcetera that's yes or
254:58 - no okay so let's take an example of
255:01 - let's let's take one scenario let's take
255:03 - one scenario number one okay so here is
255:06 - our scenario which tells
255:08 - we here use data here is your data and
255:11 - number of a yes is a 99
255:14 - number of a yes is 99 in your data means
255:17 - these are the your y labels so we have
255:20 - two unique values in your y labels so
255:22 - here you have yes and no so in that case
255:25 - your yes is around 99
255:28 - and your no is about one percent
255:32 - is about one percent okay this is your
255:35 - case one so let's take out the entropy
255:37 - for this
255:39 - h
255:39 - of y
255:41 - minus you're taking minus 0.99
255:45 - means 99
255:47 - log means lg i'm writing log not two
255:50 - maybe i'm writing a log of
255:52 - 0.99 minus
255:55 - this this is for my
255:57 - yes means this is for my yes because we
256:00 - have added a summation for each for each
256:03 - uh y variable so we are for we are doing
256:06 - for each for each y variable okay minus
256:09 - 0.01
256:11 - the log of 0.01 and your output is
256:15 - 0.0801
256:18 - okay so that's the your entropy okay so
256:22 - let's take one more scenario let's take
256:24 - one more scenario
256:26 - scenario number two
256:28 - and here let's take an example of your
256:30 - data having the yes to be around 50
256:35 - and
256:36 - your no
256:38 - is around 50
256:40 - okay
256:41 - so um if you take out entropy of this if
256:44 - you take out entropy of this minus 0.5
256:47 - log of 0.5 minus 0.5 log of 0.5 which is
256:54 - equals to 1 which is equals to 1 and the
256:57 - maximum maximum entropy is 1 and it is
257:02 - and this is very very hard to add to
257:05 - split this to split this it's very very
257:08 - hard okay so it's maximum entropy is one
257:13 - let's take another scenario and if you
257:16 - have a binary classifier i'm taking an
257:18 - example your maximum entropy is one if
257:21 - you have a binary classifier if you have
257:23 - a multi-class then the equation changes
257:26 - okay which you can see on internet but
257:28 - most of most of the cases if you
257:30 - understand binary you will be able to
257:31 - understand multi-class okay let's take
257:34 - another scenario scenario number three
257:36 - okay scenario number three tells you so
257:39 - now your number tells you that you're a
257:41 - d
257:42 - which has
257:43 - yes to be around zero percent
257:46 - and you have
257:47 - no to be around hundred percent so
257:50 - you're in trophy over here would be
257:53 - zero okay your entropy will be zero and
257:56 - minimum entropy is zero over here okay
257:59 - so you can see some cases that is
258:03 - if you have id3 follows if you have um
258:06 - if you have a some algorithm means a
258:09 - decision tree follows that if you have
258:11 - entropy equals to zero then you consider
258:14 - that as a leaf node and what is leaf
258:16 - node
258:17 - as a your prediction if your entropy is
258:20 - zero then you consider that as a leaf
258:22 - node if your entropy is one then it
258:25 - needs further splitting or if your
258:27 - entropy is
258:29 - big means uh your entropy
258:31 - for binary is generally
258:33 - greater is
258:34 - like this your entropy is generally
258:39 - like this
258:40 - entropy is in between or equals to okay
258:43 - so your entropy will be in in this range
258:46 - so
258:47 - some
258:48 - means uh algorithm follow id3 there is
258:51 - one one algorithm called id3 instance
258:54 - sub subset of uh decision tree algorithm
258:56 - so id3 follows if your entropy is zero
258:59 - then you consider r is small then you
259:01 - consider as a root a leaf node if it is
259:04 - one or large entropy then then you then
259:07 - it needs further splitting okay so
259:10 - that's the entropy and i really hope
259:12 - that you understood entropy in detail so
259:14 - let me make you familiar with what what
259:16 - we have seen so far so we had talked
259:18 - about decision tree which you can
259:19 - reverse back to c more but i'm going to
259:22 - uh recapitulate the entropy so what do i
259:25 - mean by entropy entropy is the measure
259:27 - of a randomness that measures if your
259:30 - attribute needs for the splitting or
259:32 - it's considered as a root node or it
259:34 - could consider as a leaf node or like
259:36 - that okay
259:38 - so we have taken one example of playing
259:40 - golf and then uh and
259:42 - then we have taken us some three
259:45 - scenario where we have seen that it is
259:48 - very hard to split it is very hard to
259:52 - split if you have it is it is
259:55 - it's very hard to
259:57 - get you get information if your entropy
259:59 - is high so it needs for this splitting
260:02 - okay so if you have years to be have 50
260:04 - percent know to be 50 percent then
260:06 - entropy will be one if you have another
260:08 - scenario then then it will be like this
260:11 - i can um just see the cal calculation
260:14 - you can see the calculation if you want
260:16 - to be uh to understand it much better
260:18 - okay so that's what uh
260:20 - these certain trophy is but let's see
260:23 - the diagram of entropy visually it's a
260:26 - bit interesting okay it's a bit
260:28 - interesting so let me draw one diagram
260:31 - of entropy okay so here we have our let
260:35 - me draw one let me draw a good one so
260:39 - here we have zero here we have one okay
260:42 - so
260:43 - i i hope so that i'm i'm not able to
260:45 - draw it but let me try at least okay and
260:49 - the highest entropy is one the highest
260:52 - entropy is one okay is one and this is
260:56 - the diagram of entropy this is the
260:59 - diagram of entropy okay so the highest
261:03 - entropy can be one
261:06 - if you're taking with this equation okay
261:07 - i have already showed you approved you
261:10 - so this is an example of entropy
261:14 - okay
261:16 - great so we have seen the entropy which
261:19 - is a measure of a randomness so now
261:21 - let's talk about the another attribute
261:24 - selection measure which is information
261:27 - gain okay we'll talk about information
261:30 - gain
261:31 - let me write it down
261:34 - in for formation
261:37 - gain
261:38 - and i will take an example
261:41 - of i i will explain you information gain
261:44 - with the help of one data set
261:46 - which is
261:47 - all i have already showed you i thought
261:49 - i will give you a surprise with that but
261:51 - i've already showed you
261:53 - let me show you again
261:55 - so here we have that data set
261:58 - let me show you yeah here is our data
262:01 - set
262:02 - okay let me
262:03 - draw back like this
262:06 - okay so here is our data set which is
262:08 - played tennis okay um this is a play
262:11 - tennis data set and what we will do we
262:14 - will i will make you familiar just see
262:16 - this data set and look at this data set
262:19 - i will be looking i have already looked
262:21 - at okay so here you have a plate and
262:23 - this is target variable and you have
262:25 - these features so we will see which
262:27 - feature to use or which feature to not
262:30 - okay so here um you can just see what
262:33 - i'm uh you have around
262:36 - one two three four five as a no and one
262:41 - two three four five six seven eight nine
262:44 - nine as a yes okay
262:46 - so we will uh we just see the cities and
262:49 - now let's come back to information game
262:51 - to understand first i will give you an
262:53 - overview of what information gain is and
262:56 - then we will dive deep oops where is my
262:59 - i don't know why my computer is lagging
263:01 - just give me a comment why it is very
263:03 - lagging
263:04 - okay so here is my information gain
263:08 - okay great
263:10 - i hope that everyone is able to see
263:13 - yeah okay great so let's consider you
263:16 - have the data set b okay so you have the
263:20 - data set d like this let me consider
263:22 - this as a data set let me consider d
263:26 - oops wow it's we have a data set which
263:29 - is d and what you do you further divide
263:32 - this data set into your uh
263:35 - uh
263:37 - for the data sets for the smaller sub
263:40 - subset of this data set and
263:42 - how we will divide this subset of this
263:44 - data set it means that you divide this
263:48 - data into versions and what versions
263:50 - maybe let's take an example of iris data
263:52 - set okay so what you what you do what
263:55 - you do you divide this uh satosa
263:58 - versicolor and virginica into three data
264:01 - set which concerns citosa
264:03 - versailles color and virginica okay so
264:07 - whatever examples of versitosa
264:09 - will go in this data set whatever
264:11 - examples of virginica will come will go
264:14 - in this data set whatever
264:16 - whatever examples will go where cycler
264:18 - will go in this data set so that's for
264:20 - you what you do you divide your data
264:22 - bases on the number of labels and i'm
264:24 - talking about binary classification
264:26 - classical for classifier or uh
264:28 - classification task over here okay so
264:30 - what you do you divide your data set uh
264:33 - first to divide
264:34 - for d v one then you divide for dv2 then
264:39 - you divide it for dv3 okay dv3 okay and
264:43 - what you do you take out the entropy you
264:46 - take out the entropy of this the v1 you
264:50 - take out the entropy of dv2 then you
264:53 - take out the entropy of dv3 okay and
264:56 - maybe there's this kind of cytosa
264:58 - versicolor virginia you take out entropy
265:01 - and then you take out the entropy of
265:03 - your whole data distribution okay before
265:06 - splitting so you take out the entropy
265:07 - before splitting and then you take out
265:09 - the entropy after splitting okay so take
265:12 - out entropy before splitting like this
265:15 - okay
265:16 - after that you you minus it you subtract
265:20 - you subtract your uh h of d at
265:24 - the function the entropy means
265:27 - previous entropy means previous entropy
265:29 - this entropy h of t which is the
265:32 - entropy before splitting minus
265:36 - minus
265:37 - let me write it down minus
265:40 - the weighted entropy which is this which
265:43 - is whatever the weighted entropy will
265:45 - come so let's see how we that having
265:48 - helped the help of an example what the
265:50 - what i'm talking about uh this how to
265:52 - calculate one one example to make it
265:54 - more familiar uh weighted entropy how do
265:57 - you take of the intubated entropy so you
265:58 - just multiple uh minus it with the
266:00 - weighted entropy okay after splitting
266:03 - entropy after splitting so let's see how
266:05 - it is done in more detail okay so i've
266:08 - just given you you what do what the
266:10 - formula is just to divide your data into
266:13 - success of your data like the divisions
266:15 - and then you take out the entropy before
266:18 - the splitting and then you take out the
266:19 - entropy after splitting okay so let's
266:22 - see
266:24 - so uh first let's take out the entropy
266:27 - of division number one of division
266:30 - number one
266:32 - here i'm going to take out entropy of
266:34 - division number one with the help of
266:35 - that plate in its data set okay so oops
266:41 - h
266:42 - of dv1
266:44 - which is he there we have
266:47 - three
266:48 - five means first time writing for uh
266:50 - three means first i'm writing for yes
266:53 - okay first i'm writing for yes
266:56 - where we have our where we had divided
266:59 - our data data set into a yes or no so
267:02 - there we are having total of five
267:04 - examples where three examples are yes
267:07 - and two examples are no
267:11 - and out of five okay then the entropy
267:14 - will be 0.64 okay but you then again
267:18 - what you do you take out entropy of your
267:19 - division number two
267:21 - you it will be zero and it in the same
267:23 - you take out a division number for
267:24 - division number three zero point ninety
267:26 - seven okay what then what you do you do
267:30 - the you take out the average entropy and
267:32 - that's that's equals to zero point sixty
267:34 - four then that's equals to zero point
267:37 - sixty four and the
267:39 - formula for calculating your weighted
267:42 - entropy is like they just wait for a few
267:44 - seconds the formula for calculating your
267:48 - entropy
267:49 - weighted entropy is like this let me
267:52 - write it down
267:54 - first what you do you take out this i
267:57 - think it says it's not 64 it's yeah so i
268:00 - will just multiply with the first
268:02 - division number one here we
268:05 - at d1 the norm of d1
268:08 - divided by d
268:10 - times
268:11 - the entropy
268:12 - of d1
268:15 - then you what you do you
268:18 - plus
268:20 - d2 the norm of d2
268:24 - times
268:25 - an entropy of d2
268:28 - plus
268:30 - norm of d3 norm of d3 and this is the
268:33 - division number three data set divided
268:35 - by the norm of d okay and this is your
268:38 - full data this is d is a full data so
268:40 - you take out the size of that full data
268:42 - okay then you again d3
268:45 - y okay and then this is your average
268:48 - entropy that you get after all of this
268:51 - after you've taken out the weighted
268:52 - entropy then that that will be
268:55 - equal to some number and then what you
268:57 - do you subtract you subtract your
269:00 - entropy previous entropy you subtract
269:03 - your entropy before the splitting you
269:05 - subtract to entropy before the spitting
269:08 - minus
269:09 - minus you get after splitting so let me
269:12 - write the formal equation for ig what
269:15 - you get okay so id
269:18 - ig
269:19 - equals to y
269:20 - and any var means variable maybe
269:23 - variable can be outlook a variable can
269:25 - be outlook or temperature
269:28 - temperature of that from that or windy
269:31 - or humidity okay so in that we will
269:34 - check if though if the higher the
269:36 - entropy higher the
269:38 - information gain is we can select that
269:40 - as a root node okay so what you do you
269:43 - just
269:45 - you just take the entropy of your data
269:48 - full data and then you
269:51 - pre premise of your data and then you
269:53 - minus it minus i equals to one although
269:56 - all the way on to the key the norm of di
269:59 - means the division of your data and this
270:01 - is simply uh the maybe satosa or then
270:04 - verse cycle or yes or no like that so
270:08 - divided by the full full d
270:11 - times
270:12 - the
270:13 - entropy of di okay
270:16 - so this is your weighted entropy this is
270:18 - your
270:19 - weighted
270:21 - weighted
270:22 - entropy
270:24 - and this is your
270:25 - this is your entropy okay before you're
270:28 - splitting and then you will get the
270:30 - information gain for that you for that
270:33 - variable okay so we will see uh one more
270:36 - example later on when we will be
270:38 - building our own uh
270:41 - decision tree by yourself mathematically
270:43 - so again let's recapitulate what we have
270:46 - seen so far we have simply seen we have
270:48 - simply seen so let's uh go back to that
270:50 - data set let's go back to that data set
270:53 - so here is my data set
270:55 - i don't know actually where yeah
270:58 - here is my data set
271:00 - and here what what we do we take this
271:03 - data set and we simply um
271:06 - divide this data set into multiple
271:08 - divisions into two divisions okay so we
271:11 - divide this data data set into
271:14 - yes
271:16 - and no
271:17 - okay and whatever number of examples
271:19 - will come we take out let's take an
271:20 - example here we have
271:22 - 9 over total number of data examples and
271:25 - here we have a five over total number of
271:27 - examples okay so what you do you simply
271:30 - nine by fourteen
271:32 - log of nine by fourteen minus five by
271:36 - fourteen
271:38 - log of phi by 14 okay then you will get
271:41 - some entropy which is your entropy of
271:44 - your data okay entropy of your
271:47 - data before is splitting okay so that's
271:49 - what the entropy is and i and i hope
271:52 - that you understood what i'm trying to
271:53 - say over here
271:55 - and this is your for yes and this is
271:58 - your for no because you have added a
272:00 - submission of your entropy like this i
272:03 - equals to 1 all the way down to the k
272:05 - then you have a probability of y i minus
272:08 - the log of means with base 2 probability
272:12 - of y i okay so that's what we are doing
272:15 - you are doing the same over here
272:17 - but this time you have 2 so that's what
272:19 - you're doing too and this is only for
272:21 - binary you can see equations for
272:23 - multi-class okay so that's what the an
272:27 - info
272:28 - information gain is and here what what
272:31 - we do we take out data in the our first
272:33 - we take out the entropy of that data and
272:35 - then we divide our data into multiple
272:37 - divisions and here we have three cluster
272:39 - um
272:40 - categories so we divided into three
272:42 - categories with two categories you could
272:43 - develop two categories and then take our
272:45 - entropy of that categories and then you
272:48 - take out the weighted entropy okay
272:51 - without uh rather thinking of the
272:53 - average you take out the weighted
272:54 - entropy of that uh after splitting these
272:57 - all you take out the fader entropy then
272:59 - you subtract and how you take out the
273:01 - weighted entropy here is an equation i'm
273:03 - going to give it to you it's just i have
273:05 - already given but more formally this is
273:07 - the equation for weighted entropy okay
273:10 - so what you do you simply it's the norm
273:13 - of d means no divided by what is the
273:15 - number of a full since here we have
273:18 - number of no number of a number of no
273:21 - divided by total number of examples
273:24 - times the entropy of that di okay so
273:26 - that's why who you how you take out the
273:28 - weighted entropy so after taking out the
273:30 - weighted entropy you subtract the
273:32 - previous entropy minus the weighted
273:34 - entropy okay so that's what we are doing
273:37 - an information gain i really hope that
273:39 - you understood information gain okay
273:42 - okay so please im see if on some blocks
273:44 - if you want uh either you can ask me in
273:47 - discord so i'll be very happy to help
273:49 - you in the newer you can find the
273:50 - discord server in any new era new video
273:53 - or new era you can find at it and you
273:55 - can join and there is a lot more of that
273:58 - you can and also if you want to support
274:00 - please kindly go to newer youtube
274:02 - channel
274:03 - newer youtube channel and please
274:05 - subscribe that youtube channel okay and
274:08 - if you can watch the whole tutorial on
274:10 - new era okay because you are going to
274:12 - get the uh whole at free over there okay
274:15 - so now we have seen entropy then we have
274:17 - seen in formation gain now it's time for
274:20 - uh talking about uh guinea impurity
274:23 - guinea impurity okay so this is also the
274:27 - most famous it's a most dissimilar and
274:30 - most famous that is used today which is
274:33 - guinea impurity
274:35 - gin impurity and it's just equals to
274:39 - it's very very similar
274:40 - to entropy
274:43 - it's a very very similar to entropy let
274:46 - me
274:47 - this is i use things very very similar
274:49 - sign okay
274:51 - don't comment it like this just i have
274:53 - just said it like this it's not i using
274:54 - it's just i have it's very very similar
274:56 - to entropy so let me give you one
274:59 - equation uh the equation for calculating
275:01 - the guinea impurity so i
275:04 - g and it is not an information gain this
275:06 - is a sign for a given impurity
275:08 - of y equals to the
275:11 - 1 minus
275:13 - i equals to 1 all the way around to the
275:16 - k and again it is the your y variable
275:18 - not anything it's the y variable again i
275:21 - have already seen y equals two and yes
275:24 - or no mean two or is it also versus
275:25 - color so unique values in your i
275:29 - times the probability of y i squared
275:33 - okay so that's the that's the thing and
275:36 - again it's if if we take us same
275:39 - scenarios if we how i'm saying it's if
275:42 - you take the same scenario as we have
275:44 - taken entropy some scenarios let's take
275:46 - an example of scenario number one
275:48 - scenario number two scenario number one
275:50 - we are your yes we have let's take a l
275:53 - let's take you have y to be two class
275:55 - category where you have the unique value
275:57 - as a yes or no okay so uh what is the
276:00 - probability means what is the number of
276:03 - yes is
276:04 - 0.5 and which is the number of nodes
276:08 - 50 okay 0.5 okay so what will be the
276:11 - guinea impurity gain impurity will be 1
276:14 - minus
276:15 - 0.25 is
276:17 - 0.25 because if you square this
276:20 - because here we are squaring so if you
276:22 - square this and again you subtract it
276:25 - again you
276:27 - subtract it minus
276:30 - 20
276:31 - uh 0.25
276:33 - 0.25 then you are going to get a 0.5 and
276:37 - 0.5 is maximum and gaining impurity 0.5
276:41 - is maximum in entropy we have one as a
276:44 - maximum
276:45 - if it is this zero point impurity is
276:47 - zero point five then it sneezes for the
276:49 - splitting if it is zero then it's not
276:51 - neat if we can consider that as a leaf
276:53 - node okay so that's the scenario that we
276:55 - have already seen in and if it is in in
276:58 - the case of giving impurity our gain
277:01 - impurity in this case where you have 50
277:02 - percent yes then it that that will be
277:05 - one so we have if you but you may ask
277:08 - here what is the ad advantage of gain
277:11 - impurity use rather than using the
277:13 - entropy so it is an alternative to
277:15 - entropy just to increase the computation
277:18 - just to increase to make it fast because
277:20 - in gain impurity if you have seen we are
277:23 - just taking a
277:24 - h
277:26 - of y equals to the minus the summation i
277:30 - equals to 1 all the way down to the k p
277:32 - of y i
277:34 - minus the log of p of y i so here you
277:39 - can see we are taking a log and take a
277:42 - look takes time okay so as an
277:44 - alternative a researchers comes with a
277:47 - very easy and fun
277:49 - under understandable way one minus and
277:52 - this these are this can be derived these
277:55 - are derived in information theory okay
277:57 - but i'm not going to go in information
277:59 - theory but you can see
278:01 - uh this is the for
278:03 - gain impurity and this is most used as
278:05 - an alternative to guinea impure uh
278:07 - entropy guinea purity is most yields as
278:10 - an alternative to entropy okay
278:12 - so that's the thing and i hope that you
278:15 - understood guinea impurity also so let's
278:17 - uh let me make you familiar with the
278:18 - diagram so here is the diagram let me
278:21 - make first for um
278:23 - entropy first here is for entropy so
278:26 - here we have zero here we have one
278:29 - so here this is for entropy we are here
278:31 - maximum is one
278:33 - and this is for
278:36 - obviously some something will differ so
278:38 - but uh the maximum is 0.5 you know
278:42 - engine impurity so yellow one is guinea
278:44 - impurity and the white one is entropy
278:48 - okay white one is entropy so i hope that
278:50 - you understood the why why i'm saying
278:52 - but why do you use gain impurity because
278:55 - because just and because it is more
278:58 - faster because we are taking log and
279:00 - that takes time this more faster
279:03 - than um entropy okay so that's the whole
279:07 - definition of all decision tree and that
279:09 - is i'm recording till 51 minutes
279:12 - and i hope that you understood all of
279:14 - this i hope that i've written a lot
279:17 - okay
279:18 - so uh we have learned a lot and i really
279:20 - hope that you understood also okay
279:23 - so now we will
279:25 - make one a decision tree classifier and
279:27 - i will show you uh the decision tree
279:29 - numerically okay how we do uh regression
279:32 - task and decision trees okay so
279:36 - first uh let's let's do in a fast way i
279:38 - i i do have not a lot of time over here
279:41 - but i will show you this data set so
279:44 - here is my data set which i'm going to
279:46 - use okay so first of all what we do we
279:49 - take out the entropy okay we take out
279:52 - the entropy we take out the entropy of
279:54 - this whole data set we take out the
279:56 - entropy of this data set h of d
280:00 - oops where is my pen
280:02 - h of d and simply what what we are doing
280:06 - here we have two y's so here we are
280:09 - taking the entropy of our data
280:10 - distribution d
280:12 - okay so that that will simply equal to
280:15 - 0.94
280:16 - as i've told that you have to take out
280:18 - entropy before splitting okay for
280:20 - information gain so we take out the
280:22 - entropy where this of this data set as
280:24 - you have around
280:26 - five no five no and nine yes okay
280:31 - okay so and that way you can take it out
280:34 - uh if if i want to make i can simply
280:36 - make like like this
280:38 - five
280:39 - by fourteen five by fourteen log uh five
280:42 - by 14 minus 9 by 14 log of
280:47 - 9 by 14 okay so after you calculate you
280:51 - will get this okay so but feel free to
280:53 - collect correct me if
280:55 - i do anything wrong in calculation okay
280:58 - feel free to correct me in the
281:00 - comment box okay in mathematics we do
281:03 - i'm just doing it faster just we have to
281:04 - remember the concepts okay so after you
281:07 - calculate the edge of
281:09 - entropy of your distribution now what
281:11 - you do you calculate the information
281:13 - gain you calculate you calculate the
281:17 - information gain you calculate the
281:20 - information
281:22 - you calculate the information gain okay
281:26 - how first you calculate the information
281:28 - gain
281:29 - for you calculate the information gain
281:31 - for whether for why with respect to
281:34 - outlook variable means we have to check
281:36 - how much information that outlook
281:38 - variable contains okay so in output in
281:41 - outlook here we have outlook variable
281:43 - you can see over here that here we have
281:45 - outlook variable so let me uh
281:47 - let me take out so in outlook
281:49 - if you see the y variable we have
281:52 - in sunny in sunny we have two yes and
281:56 - three nos
281:57 - we have two years and three nos then we
281:59 - have in outcast we have four yes and
282:03 - zero nose
282:05 - okay
282:06 - then in rainy we have two yes and three
282:10 - nos
282:11 - okay so this is their outlook variable
282:14 - and here you have a two yes and three
282:16 - knows four yes zero knows two years
282:18 - three knows and this is for sunny this
282:21 - is for overcast and this for rainy and
282:23 - you can see over here okay sunny
282:26 - overcast and rainy okay so this is this
282:30 - you can see that if you take out the
282:32 - entropy of this entropy of
282:34 - this h
282:36 - of d2 d2
282:39 - h of d2 then you will see that this is
282:41 - equals to zero and you can you can take
282:44 - this as a leaf node and it does not need
282:47 - further splitting okay so you can take
282:49 - this as a leaf node you can take this as
282:52 - a leaf node because this does not need
282:54 - further splitting okay now what you do
282:57 - you take out the entropy of this h of
283:00 - d1
283:02 - of y
283:03 - okay then you take out this h of
283:05 - d2
283:06 - d3 y okay so the you have taken this
283:09 - data set large data set okay taken this
283:12 - day it is set and it's split you have
283:14 - taken this feature split it okay so we
283:16 - have this
283:17 - before spreading and then you what you
283:19 - will do you take out the beta entropy
283:21 - you take out the weighted entropy
283:23 - weighted entropy weighted entropy
283:26 - which is equal to 0.69 okay so what you
283:29 - would for information gain you simply
283:31 - subtract 0.94 means the previous entropy
283:35 - minus the bit end drop is 0.69
283:37 - okay and we entropy i've already shown
283:39 - you previously okay and you do the same
283:42 - for
283:43 - uh temperature you do the same for
283:45 - temperature very very temperature you
283:48 - have y
283:50 - in temperature where you have around in
283:53 - you have three classes high
283:56 - mean i think
283:57 - mil
283:58 - let me see
284:00 - hi mild and hot hi hot
284:03 - mild and cold okay so in what we have
284:06 - two years and two nos
284:09 - and here we have in mild we have four
284:10 - years and two nose
284:12 - and then in cool we have three yes and
284:14 - one nose okay then you take out then you
284:17 - take out like this and then you do for
284:18 - humidity then then you do for humidity
284:22 - humidity and then you do for
284:25 - a windy okay then you do and it's found
284:28 - that the that the information gain in
284:30 - over outlook is very high okay so what
284:33 - you do you take that and you take that
284:36 - only that
284:38 - outlook as your root note as your root
284:42 - node
284:43 - okay then then you take that outlook as
284:45 - a root node then you
284:47 - divide this then you divide this so here
284:50 - let me go to one of the one of my
284:52 - favorite
284:53 - decision tree pdf where i i will just
284:56 - explain you what this is okay so you
284:59 - think take this outlook as a root note
285:01 - then what you do you um divide this you
285:04 - divide this as as we have divided into
285:06 - sunny overcast and rainy sunny overcast
285:09 - and rainy and overcast you can see that
285:11 - we have entropy equals to zero so it
285:13 - does not need further splitting so we
285:15 - can consider that as a yes means we have
285:18 - four years so we can consider that as a
285:20 - yes because it's very pure and then its
285:22 - needs for the splitting and this also
285:23 - needs for this spitting and then at some
285:25 - point they are they also become pure
285:27 - where the entropy equals to zero so or
285:29 - the given impurity equals to zero then
285:31 - you consider as a leaf node okay so this
285:34 - is how we make the decision freeze and
285:36 - this is how we calculate the information
285:37 - gain this is how we made our decision
285:39 - free okay
285:41 - okay great now i really hope that you
285:43 - understood decision tree and now it's i
285:46 - i i also enjoy very much when i make
285:49 - these kind of tutorials this kind of
285:50 - tutorials and because it's just amazing
285:53 - just um helping students to make this uh
285:57 - understandable things okay okay great
285:59 - now uh one as we have only talked about
286:02 - classification so as regression is not
286:04 - too too much hard also so in regression
286:06 - let me show you what you are what what
286:08 - what we do in regression so let me take
286:10 - one let me go to the cycle learn
286:13 - decision tree
286:14 - decision tree
286:17 - cycle learn i hope that
286:20 - is stable yeah here it is so it explains
286:23 - very good it's explains very in in very
286:26 - good way so let me uh uh make you what
286:29 - the what do i mean with this so let me
286:32 - take an example of this a parallel and
286:34 - petrol width so in the same way here you
286:37 - what you do your petal length is smaller
286:39 - than or equals to zero two zero two
286:42 - point four five then guinea purity is
286:44 - high then you would split it okay here
286:46 - the guinea purity equals zero then it
286:48 - does not need for the splitting but it's
286:50 - needs for the splitting so it splits
286:52 - that okay so here it seems to be
286:55 - overfilling because
286:57 - if you if you
286:58 - leave the decision tree to be go as to
287:01 - ask as much question then it will over
287:03 - fit then it will overfit so what you do
287:07 - you either stopped at certain depth you
287:09 - either stop your decision to add a
287:11 - certain depth to make it more robust to
287:14 - make it more robust or you prune your
287:16 - decision tree by removing some some
287:19 - branches from here okay and you can see
287:21 - the same way that we have seen that we
287:23 - have made the this kind of this kind of
287:25 - decision boundary decisions uh
287:27 - hyperplanes okay
287:29 - great let's see some more
287:32 - oops
287:32 - i use brave as my browser but soon we'll
287:36 - get
287:36 - but soon we'll try something some please
287:39 - make sure that you can put your
287:41 - comment below if i can see okay and
287:43 - regression what what decision
287:46 - we can apply in regression also so you
287:48 - can see over here that here what what we
287:51 - do let me get back to some good pictures
287:53 - decision
287:55 - uh trees
287:56 - regression regression but i will soon go
288:00 - to documentation to show you uh more
288:02 - sophisticated
288:04 - in a good way okay
288:06 - so here is my
288:09 - decision tree regression
288:12 - and let's take an example of this
288:15 - as you can see from this also yeah so
288:18 - here is here we have a good example so
288:20 - here your predictor here you have a
288:21 - target variable okay so here you what
288:24 - you have taken you take an outlook and
288:25 - then you divide into sunny overcast and
288:27 - rainy and sunny needs for this fitting
288:30 - but overcast does not okay so most of
288:32 - the time you average it and then you
288:34 - take 46.3 okay and then you split it
288:37 - again you what you what you do is split
288:39 - it if
288:40 - you take out the average again i'm
288:42 - saying you take out the average okay
288:45 - that's what you're doing and again if
288:47 - you if i go further into this it is very
288:49 - well explained it is very well explained
288:51 - you can go to this it's very well
288:53 - explained but yeah it's only for
288:55 - regression but it's so much of um but
288:58 - what what we do we simply again the
289:00 - whole the things are same for attribute
289:01 - selection measure you simply uh you can
289:04 - sunny overcast rainy overcast over here
289:07 - is we have four um
289:10 - this is your leaf this is your concept
289:12 - this is a so pure so that's what is
289:14 - considered as a leaf and then what you
289:16 - do you take out the average like this
289:18 - you take out the average and then you
289:20 - take out the 39.8
289:23 - 46.3 over here after taking on average
289:26 - then you split your sunny into false or
289:28 - true then if it is false then your
289:30 - outward output will be 47.7 and if it is
289:33 - true then it is 26.5 in the same way you
289:35 - do the regression okay so i hope that
289:38 - you understood and you can go again to
289:40 - understand it more detail so so what you
289:42 - what you do you take out the hours
289:44 - played and our average standard
289:46 - deviation average and hours played and
289:49 - then you count it and then you simply uh
289:52 - do some
289:53 - calculation and that's not too much hard
289:56 - okay
289:58 - great so we have seen so far about a
290:00 - decision trees regression and i really
290:02 - hope that you understood this also okay
290:05 - so you can go to this node uh this tree
290:08 - uh this
290:09 - website say theresa dot com distribution
290:12 - we regret reg you will be able to
290:14 - understand them but it's more important
290:16 - to understand attribute selection
290:17 - measure because people usually confuse
290:19 - us at this and we have taken lots of
290:20 - examples for this okay okay great so now
290:24 - what we will do we will
290:27 - i will show you i will show you some
290:30 - i will show you the documentation the
290:32 - implementation
290:33 - the implementation for decision tree i
290:36 - will show you the implementation of
290:37 - digital regressor and residential
290:39 - classifier okay so that you can on
290:42 - because it's very important to learn
290:43 - from implementation okay so i will
290:45 - explain you in more intuitive way so let
290:48 - me open my ink to go i hope that i'm not
290:50 - i'm just using it uh let me see if this
290:53 - works for not for me or not okay
290:56 - okay great
290:58 - let me choose this pen yeah so uh here
291:01 - you can go to this website this table
291:04 - dot com and here you will be able to
291:07 - find more uh you can go to
291:08 - cyclelearn.org and documentation of this
291:10 - generic classifier okay so here again it
291:14 - should what is the criteria to choose
291:15 - the
291:16 - attribute here we have guinea and here
291:19 - we have entropy okay so you guinea is a
291:22 - default you can choose entropy also okay
291:25 - the quality of a split supported
291:27 - criteria is guinea and the entropy is
291:29 - for the input and the for the
291:31 - information gain
291:33 - after splitter splitter means do you
291:36 - want to choose the best splitter or
291:38 - random splitter okay best means is which
291:41 - was the best random is any ran randomly
291:45 - okay max that this is very important
291:47 - hyper parameter which you can tune it
291:50 - using great search cv using grid search
291:54 - cv or a randomized search randomized
291:58 - search okay you can tune it okay so
292:01 - that's what you will do
292:03 - and what you do you just you just um
292:06 - make your decision to if you do not make
292:08 - then it will fed or then the new
292:09 - decision will overfit okay so the
292:12 - maximum depth of the tree okay if it is
292:15 - default as none okay um if you do it
292:19 - will learn a lot it will make a lot of
292:21 - decision boundary to learn a lot until
292:23 - unless it's leaves are pr okay so it
292:26 - will learn a lot so that's why it will
292:28 - overfit so this is a very important
292:29 - hyper parameter then again you have a
292:31 - minimum sample split means here the
292:33 - default is two again you have to tune it
292:36 - again you have to tune it the minimum
292:38 - number of samples required to split an
292:40 - internal node okay an internal node is
292:43 - just uh
292:45 - that know the minimum number of splits
292:46 - that require okay this is two but you
292:49 - need to be uh very cautious under this
292:53 - okay
292:54 - then we have minimum sample split then
292:56 - we have minimum samples leaf
292:58 - and then the minimum number of samples
293:01 - required to be at a leaf node okay so
293:04 - what is the minimum number of a samples
293:06 - required to be a leaf node again is one
293:08 - but you can also tune it but it's not
293:10 - that but it's very uh
293:12 - good to tune it using great source cv
293:15 - then we have a minimum weight fraction
293:17 - leaf then we have what is the max
293:19 - features means uh the number of features
293:21 - to consider when looking for the best
293:23 - plate for a larger number of features
293:24 - than you can consider as an uh the
293:26 - default is none but you can use this but
293:28 - it it it also has some disadvantages
293:31 - okay
293:32 - okay then we have a random state control
293:35 - the randomness of your estimator again
293:38 - it's you can read some more details on
293:40 - random state uh max max leaf node the
293:44 - grow of a tree in a best first fashion
293:46 - uh it is the default none it's just like
293:49 - a max leaf node or the minimum purity
293:52 - decrease the node will will be split if
293:56 - the split induces
293:58 - induces a decrease for the impurity
294:00 - greater than or equals to this value but
294:02 - i've not used it uh if i say very much
294:06 - right it's just a limitation that you
294:07 - can make to prevent overfitting okay i
294:10 - think this is deprecated then you have a
294:12 - class weight what is the default is none
294:15 - always then we have alpha non-negative
294:17 - value so that that's the basic intuition
294:20 - okay so we had talked about this and
294:23 - then you can see some examples and then
294:25 - there is something called as uh
294:28 - um let me show you uh you can also use
294:31 - this as a
294:32 - understanding residential structure so i
294:34 - will just show you one example of this
294:37 - okay so here you can use the graphis
294:39 - tool here you can use the graphics tool
294:42 - to plot your decision tree like this
294:44 - yeah uh you can he he has you three dot
294:46 - plot tree it is plotting the tree like
294:49 - this okay you because recently has one
294:51 - more is advantage it is easy to
294:53 - interpret okay so that's the basic
294:56 - intuition behind decision entry okay so
294:58 - let's go to decision tree regression
295:00 - okay so let me see where is regression
295:04 - okay let me see one more
295:06 - great where is decision tree regression
295:10 - here it is okay
295:12 - so in decentralized regression it can be
295:14 - used for this um uh this is uh for
295:16 - regression task also so here uh you have
295:20 - to choose certain criteria the function
295:23 - to measure here we are not using any
295:25 - entropy here we are using the quality of
295:27 - your split you can use mean square error
295:30 - means how how much it how much it
295:32 - differs okay so a mean square error
295:35 - error or mean absolute error or poison
295:38 - so you can see a frying freedman msc but
295:42 - most uses mse or ma or rmse okay
295:47 - a splitter again it's best
295:49 - again the same thing max step obviously
295:51 - to control your adapt to prevent
295:52 - overfitting this is an important hyper
295:54 - parameter again i'm saying this is a
295:55 - very very important
295:57 - vvi
295:58 - this is also very very important to
296:00 - attune okay then you have minimum sample
296:03 - leaf and then you have the same as we
296:05 - have discussed okay and then you can see
296:07 - some examples of decision tree like this
296:09 - how we make and then
296:12 - there are certain methods like plot or
296:14 - etc
296:16 - then you have
296:17 - uh
296:18 - some some some examples which you can
296:20 - see from here and this is usually uh you
296:23 - can use we will talk about ada boost
296:26 - also later on okay so you can see some
296:28 - visualization in this library and this
296:31 - entry is used to fit this curve with
296:32 - addition noise or observation and it's
296:35 - just controlled by the depth of that map
296:38 - by the max step
296:39 - and the blue line considers the two and
296:42 - the max depth of a5 if you take then it
296:45 - will perform very very well on the
296:47 - training set but that interesting set of
296:49 - you do not control your max that okay so
296:52 - we have talked a lot on decision trees
296:55 - and i really hope that you understood
296:57 - decision tree and that okay so in the
297:00 - next section the reason why i've taken
297:02 - this too long to make you understand
297:04 - decision tree because very very
297:06 - important concept to understand and
297:09 - and i think it's very very important
297:11 - okay so you can have a look if you want
297:13 - onto this notes okay but uh you can you
297:16 - can ping me on discord or linkedin i
297:19 - will very happy to give you these notes
297:21 - if you're not able to write either i
297:23 - will recommend you to write these things
297:26 - okay i will i will just
297:28 - you can ask me to make this all wrong
297:30 - okay so that's it for this video for
297:33 - this section so sorry um for this
297:35 - section and i'm my throat is also so
297:37 - much paining but yeah that's it for
297:40 - that's it for this section and in the
297:42 - next section we will start with ensembl
297:45 - learning and again
297:46 - then we will go to unsupervised learning
297:48 - then we'll talk a little bit about
297:49 - neural networks and then we will end up
297:51 - this course and you will be having
297:53 - enough understanding of machine learning
297:56 - to get started making projects in
297:58 - machine learning and getting a job or an
298:00 - internship but you have to lot of
298:02 - practice okay so uh you can do that okay
298:05 - great so thank you for this seeing this
298:08 - section and again if you have any kind
298:10 - of question you can ask me to the new
298:12 - era be sure to subscribe if you wanted
298:13 - to support this content
298:16 - okay so let's meet at the next section
298:18 - till then bye bye okay so now we'll talk
298:21 - about example learning one of my
298:23 - favorite topic to teach and to use in my
298:26 - professional experience
298:28 - so
298:29 - why why i think ensemble learning is one
298:33 - of the
298:34 - best for cargo competitions for cargo
298:37 - competitions and sample learning
298:39 - methods or techniques are most popular
298:42 - 99
298:44 - of the kaggle winners uses some kind of
298:47 - ensemble learning techniques so that's
298:49 - why uh i think that ensemble learning is
298:52 - a must-know technique it does not
298:54 - involve a lot of mathematics but it do
298:56 - involves only techniques concepts and a
299:00 - little bit more uh maths okay but in
299:03 - decision tree we involve some
299:04 - mathematics but here we do not end a lot
299:06 - of mathematics we require a little bit
299:08 - of mathematics but there are a lot of
299:10 - techniques and concepts that we need and
299:12 - approaches that a particular kaggle
299:15 - governor's thieves okay so
299:18 - it's very um we will give david and
299:20 - symbol learning covering the four
299:23 - three techniques i think the three
299:25 - techniques of ensemble learning the
299:27 - first technique will be a bagging which
299:29 - we'll talk about um not in it will will
299:32 - be in a separate section sub sections
299:35 - okay so this is our main section and in
299:37 - a separate subsection we will talk about
299:39 - bagging
299:41 - then we will talk about
299:44 - boosting
299:45 - then we will talk about stacking okay so
299:48 - these are the three techniques that we
299:50 - will talk about in ensembl learning and
299:54 - also we will see the implementation of
299:56 - each one of them and it and i will also
299:59 - show you some of the kaggle competition
300:01 - winners approach or we will make one
300:04 - model
300:05 - seeing the changes for changes they uh
300:08 - bring into your system how do your model
300:10 - accuracy increases okay okay so great
300:14 - but before that let's a little bit uh
300:16 - let me just forget about dominant sample
300:19 - learning let me recall use some concept
300:22 - which is high variance uh concept okay
300:25 - so
300:27 - high variance and high bias concept so
300:29 - it
300:30 - it should make sense to you so let's
300:32 - recall in high variance we have uh
300:35 - overfitting model we have our
300:38 - overfitting model if i'm if i'm correct
300:40 - in high variance we have our overfitting
300:43 - model and in high bias we have our under
300:46 - fitting model okay so our models should
300:49 - be low bias
300:51 - and low variance
300:54 - low variance model if you have a high
300:57 - variance if you have a high variance
300:59 - then you have then your model is
301:01 - overfitting if you have a
301:04 - high bias then your model is under
301:06 - fitting and uh that's that's what the
301:09 - recollection that that we need for this
301:11 - ensemble learning just to make sure that
301:14 - that we are in the same path okay
301:16 - okay so let's start with an a simple
301:19 - example of um of a small example okay
301:24 - so if we have played some quiz okay if
301:27 - you have played some quiz let's take an
301:30 - example that we have played some quiz of
301:32 - uh maybe in kahoot or anything any kind
301:35 - of quiz or if you are in competition you
301:37 - have played some quiz so it's a maximum
301:40 - percent a maximum percentage that the
301:42 - let's take an example that we have some
301:44 - question let's we have some question we
301:46 - have some question here and we have some
301:49 - option which is a
301:50 - b and c okay so let's let's take an
301:53 - example that the particular that the
301:56 - majority let's take an example a is a
301:58 - correct answer so
302:00 - it is it is very obvious that majority
302:03 - of the students will go with a and if
302:06 - the majority is on a then is likely to
302:08 - be a be the correct answer and it's
302:10 - actually the correct answer okay so it's
302:13 - like whatever the majority will say we
302:16 - will go with that okay here majority is
302:19 - saying a and in this case is a correct
302:22 - answer and if you think about the
302:23 - majority is more accurate than one
302:27 - majority is more accurate than one and
302:30 - in some exceptional conditions that can
302:32 - be different but in 99
302:35 - the majority will win okay majority will
302:39 - win
302:40 - if you have seen some quiz okay so if
302:43 - you see that the option has got the
302:45 - highest majority and what also into that
302:47 - then you can think that is the correct
302:49 - answer so in the same way ensemble
302:51 - learning works in ensemble learning is a
302:54 - example of models is ensemble of models
302:58 - okay
303:00 - so let's take one more example to get
303:02 - more feel let's take an example that
303:05 - some election is happening some election
303:07 - is happening some election is happening
303:10 - and in that election and that election
303:13 - uh let's take an example that why we do
303:16 - not take only one person vote and select
303:18 - any prime minister or president why we
303:21 - take the majority the majority of votes
303:23 - which will go on to that party that will
303:26 - win okay so the majority will make a
303:28 - right decision okay we'll we will uh
303:32 - will make a right decision in most cases
303:34 - okay so that's what the ensemble
303:37 - learning also says and semi-learning has
303:40 - ensemble of models so let's uh let me
303:43 - say let me tell you um
303:46 - what what we do in symbol learning we
303:48 - have a model one
303:51 - model two all the way down to the more
303:54 - okay okay so let me make you make this
303:57 - that it is visible yeah okay so you have
303:59 - these kind of models and you train your
304:01 - model you train your model you train
304:04 - your model onto your data okay you train
304:06 - your model onto your data and you can
304:09 - you take predictions from each of the
304:11 - model so let's take an example that
304:13 - you're trying you are making a
304:16 - diabetes prediction system diabetes
304:18 - projection system so your output will be
304:20 - either zero means non-diabetes or one
304:23 - okay so let's take an example that model
304:25 - number one says it's uh it's a zero
304:27 - model number two say it's a zero model
304:29 - number three says zero model of a force
304:31 - is a one and model number five says is
304:33 - zero so the the then what what we have a
304:37 - one more model a big model which which
304:41 - what it will do it will check the
304:43 - majority of votes and here the majority
304:46 - is zero and only one has given one and
304:48 - the majority of zero so we will give our
304:51 - prediction as a zero okay so we will see
304:54 - how it is trained later on but here what
304:57 - the actual thing is what is happening we
304:59 - train our model and each model is giving
305:02 - predictions and in these predictions we
305:04 - are taking into classification we are
305:06 - taking in class classification we are
305:08 - taking majority of votes means majority
305:12 - means m1 is saying is zero and two is
305:14 - saying zero the frequency of zero is
305:16 - more than the frequency of one okay so
305:19 - that's why our final prediction which is
305:21 - y hat is equals to zero
305:24 - okay and it's more it will be it will be
305:27 - high chance that if one model predicts
305:29 - if one model predicts it's a one or zero
305:33 - uh and the ensemble of a model predicts
305:35 - a zero then they are more accurate
305:38 - rather than this okay so that's the um
305:41 - that's the basic overview of ensembl
305:44 - learning and you may think here use in
305:47 - classification we choose the majority of
305:49 - votes but what about regression what
305:52 - about regression
305:54 - what about regression problems in
305:56 - regression problems what we do we take
305:59 - out the mean
306:00 - or a median uh um
306:03 - of
306:05 - out outputted from each model so let's
306:07 - take an example that your model m1 given
306:10 - some prediction which is regression
306:12 - value 2.4 model 2 given 2.6 model 3
306:17 - given 2.5 so what you do the final
306:20 - prediction will be the average of these
306:23 - outputs the average or mean or a median
306:27 - of these outputs okay so that's what
306:30 - that's how we do in regression
306:33 - we do not take the majority we take the
306:36 - mean or the median of the output from
306:38 - the base models and these are called the
306:41 - base models over here okay so these are
306:44 - called the
306:45 - base
306:46 - models and then symbol
306:48 - okay so don't be confused what is base
306:49 - model base motors are the ensemble of
306:52 - models that are being trained
306:54 - uh and
306:55 - okay so that's that's the basic
306:57 - intuition behind our ensemble learning
306:59 - and i really hope that you understood
307:01 - ensemble learning and that okay so um
307:04 - just want to make sure that what how we
307:07 - train uh what are the some of the
307:09 - techniques used in
307:11 - this um used in
307:14 - bagging what means what are the
307:16 - techniques using assemble learning so we
307:18 - have a techniques like bagging then we
307:20 - have a boosting then we have a stacking
307:22 - okay
307:24 - these are and one one more which is
307:26 - cascading which is which which you can
307:28 - learn which is not yet in the industry
307:30 - yet but yeah one was just gas scanning
307:33 - which we will see if we want otherwise
307:35 - it's not necessary okay so in bagging we
307:38 - will see one algorithm which is a random
307:40 - forest which is which is something
307:42 - called as a random forest okay
307:45 - which is just an ensemble of a decision
307:47 - trees and then in boosting we will more
307:50 - probably focus on um
307:53 - we will in boosting we'll more prone to
307:56 - focus on gradient boosting we will more
307:58 - prone to focus on
308:00 - gradient boosting
308:02 - and we will focus on adaptive boosting
308:06 - which is just a advanced uh version of
308:09 - gradient boosting we will focus on
308:11 - adaptive boosting then we will see one
308:15 - winner which is xg boost okay so we will
308:18 - see these algorithms or these techniques
308:21 - in this boosting then in stacking we
308:23 - will see amal extend library how we do
308:25 - this stacking and what's the intuitive
308:27 - understanding and you can see there no
308:29 - money any kind of math this is only the
308:31 - concepts okay so that's how
308:33 - that's what we are going to see and the
308:36 - study motivation for this for ensembl
308:38 - learning why do we study ensembl
308:40 - learning has a great reason behind them
308:44 - the reason being why do we study this is
308:46 - the great question to ask whenever you
308:48 - do any kind of thing why let me use this
308:51 - good color why do we study i think that
308:54 - is not visible in most of the cases let
308:56 - me stick to white okay so why do we
308:59 - study
309:00 - and we study this ensemble learning the
309:02 - reason being is most of the cargo
309:06 - competitions
309:07 - most of the gaggle competition winners
309:10 - most of the kaggle competition winners
309:13 - competition winners
309:17 - uses some kind of ensemble learning
309:19 - either they use bagging either they use
309:21 - boosting either they use stacking either
309:23 - they use cascading they use some kind of
309:26 - ensemble learning techniques if it is a
309:29 - machine learning problem if it is a
309:31 - machine learning problem ml problem okay
309:34 - okay just think that machine learning
309:36 - has also a power okay
309:39 - so but there is a difference in in
309:42 - internet companies like amazon google
309:45 - they also uses these algorithms xgboost
309:49 - adaboost gradient boosting then we have
309:51 - a random forest in their
309:54 - own uh
309:55 - products of import production okay so um
309:59 - cora uses random forest to uh for
310:02 - quotient matching okay so they they also
310:06 - use machine learning these kind of
310:07 - algorithm and these are very very
310:09 - powerful algorithm a very powerful
310:12 - algorithm which is often used in
310:14 - industry also which is often used in
310:17 - many kind of kaggle competitions and
310:19 - around
310:20 - 99 of the kaggle competition winners are
310:24 - uses this kind of um
310:27 - any kind of ensemble learning either if
310:29 - it is a machine learning problem in deep
310:30 - learning problem you obviously go with
310:32 - it if it is image problem you will go
310:34 - with cnn if it is a text
310:37 - text you will go with some word
310:39 - embeddings and then you can use any
310:40 - other techniques and you can use r and n
310:42 - so it depends so you can use any of the
310:44 - technique if you want but in most of the
310:47 - competition in the past we have seen
310:49 - that they are the winners of the user
310:52 - okay so you can see the case studies if
310:54 - you want in detail
310:56 - okay great so we have talked about
310:59 - ensembl learning and in this section and
311:02 - now we will start a sub section which is
311:05 - bagging okay we will start a sub section
311:08 - which is bagging which we will dip dive
311:10 - into the bagging okay so it's also
311:12 - called the bootstrap aggregation or
311:15 - bootstrap aggregated okay so we will see
311:17 - uh late just one second okay so just to
311:20 - recall and sample learning
311:23 - is a b is an example of base model it
311:26 - can be logistically version it can be
311:28 - nine based it can be supported with the
311:30 - machine okay it's a classification
311:32 - algorithm whatever the majority of votes
311:34 - will be it will take the majority of
311:36 - votes and then gives you a y hat okay so
311:39 - that's how it works okay so um let's
311:42 - let's and in regression we take out the
311:44 - mean or median of your values
311:47 - great
311:48 - now we'll start a sub section now we
311:50 - will start a sub section which is
311:52 - something called as bagging
311:54 - subsection which is called as bagging
311:59 - okay so in bagging
312:01 - so in bagging uh it's again ensemble
312:04 - learning technique and sometimes it's
312:06 - called bootstrap aggregation and from
312:09 - bootstrap we deserve we derive the word
312:11 - which is backing like this
312:13 - bootstrap
312:14 - bootstrap
312:16 - aggregation agreement
312:19 - okay i think i'm my spinning is little
312:21 - bit wrong but uh just bear with me bad
312:24 - game okay so that's what the from the
312:27 - derived world from bootstrap aggregation
312:29 - justin shaw okay okay great so
312:32 - it's a statistics term if you've heard
312:34 - about bootstrap
312:36 - aggregation means it's a it's a
312:39 - statistics term if you can relate with
312:41 - your statistics and probability classes
312:43 - a statistics term so let's see the
312:45 - geometric intuition okay let's see the
312:48 - basic overview or intuition behind
312:50 - bagging intuition behind
312:54 - bagging
312:56 - intuition behind bagging so what we do
312:59 - in bagging so let's take an example that
313:02 - you have a data set that we have a data
313:05 - set d okay you have a training data
313:07 - which is d
313:14 - so you have a data so you have a data
313:16 - like this
313:18 - and what you have done you divided your
313:20 - data 80 percent for training and 20
313:24 - for testing okay so now what you do
313:27 - that's just to make sure that you are on
313:28 - the same page on the dividation of your
313:30 - data also okay so you take your training
313:33 - data you trade your training data and
313:36 - your data is just um you take your
313:39 - training data like this and it's for
313:41 - your training it's a supervised learning
313:43 - algorithm so um
313:45 - you have x i and y i so you have your
313:50 - in x i
313:52 - with your label by i for all i
313:56 - one i equals to one all the way down to
313:58 - the m and m r is the length of your
314:00 - training examples okay so this is your
314:02 - data this is your training data this is
314:05 - your training data now what you do you
314:08 - sample
314:10 - some points let's take this sample k
314:12 - point or i uh let's see an example that
314:15 - you sample k points from this data set
314:17 - you sample
314:18 - you sample
314:21 - k points
314:23 - with the resp replacement with the
314:25 - replacement you sample k points with
314:29 - displacement from this data and you feed
314:32 - this to this model which is uh let's uh
314:36 - now you got d
314:38 - one which is d1 okay so you have sampled
314:41 - the subsystem sub subset of a data
314:44 - from this large data set okay sample k
314:48 - points you sample k points and now what
314:50 - you do you train your model using this
314:53 - subset of a data you train your model
314:56 - using this subset of the data and now
314:58 - you've got your model as a m1 okay this
315:01 - is your m1 mark okay but you may think
315:03 - here you just can you repeat it again
315:05 - it's all goes uh all gone above your
315:07 - head no worries again i'm explaining
315:09 - it's usually gone okay so what you do
315:13 - so i'm highlighting i in
315:15 - white so what you do you take your
315:17 - training data which is the which is a
315:19 - supervised running problem where you
315:21 - have a labels now you take out the
315:23 - samples with the replacement samples
315:27 - with a replacement and what do i mean by
315:29 - sample with a replacement i will talk
315:30 - about just after i make another sample
315:33 - okay so
315:34 - as of now just just understand we take
315:37 - out some sample with a replacement
315:39 - around the k points we sample k points
315:42 - or m points and um
315:45 - sam we sample some points um
315:48 - or we take out a sample of a data from
315:50 - this let's take an example this this
315:52 - amount of data from this uh this amount
315:54 - of data which any random data means and
315:58 - we have this is a hybrid parameter we
315:59 - have to choose the number of samples
316:01 - from this data and then we and then we
316:04 - call it as a d-1 okay then we feed to
316:07 - the model means we train our model onto
316:09 - this data okay then what we do we again
316:12 - take out the sample again take out the
316:14 - sample
316:16 - again take out the sample k points with
316:20 - the replacement sample k points with
316:22 - replacement and what do i mean
316:25 - if your data is here if your data is
316:28 - here means if your data
316:30 - is here then it can be also here then it
316:33 - can be also here it is it is not
316:36 - necessary that your data should be
316:38 - different
316:39 - it can be same it is some data can be
316:42 - same here and here also okay so that's
316:45 - the sampling with replacement okay now
316:48 - your samples again that random data and
316:51 - it's not necessary that your data should
316:53 - be different from the d1 it can some
316:55 - data points can be included okay so you
316:58 - again sample k points and the and here
317:01 - you have a sample of a data from the
317:03 - large data and then you train your model
317:05 - onto this data
317:07 - m2
317:08 - okay you train your model onto this m2
317:12 - now again what you do you take out the
317:14 - sample you take out the sample
317:16 - you take out the sample
317:19 - k points
317:20 - you do it for your number of um base
317:23 - models means
317:25 - number of times if this this is also
317:27 - have a parameter okay how much you want
317:29 - to sample until you have your data
317:31 - points
317:32 - till
317:32 - k okay till k
317:36 - till k dash okay and then you train your
317:39 - model till am okay and then what you do
317:42 - you have your k models now you aggregate
317:46 - this into a large model you aggregate
317:48 - this into a large model
317:51 - okay
317:52 - and large m okay and in case of
317:55 - classification the majority of votes the
317:59 - majority of votes will go uh as let's
318:02 - take an example of ensemble learning
318:04 - that we have seen that let's take an
318:05 - example of diabetes and prediction okay
318:07 - so if m1 gives 0 m2 gives 0 and m3 gives
318:11 - 0 and m4 gives less than level 1. so the
318:15 - majority is 0. so the majority of votes
318:18 - will lead to the final prediction by
318:20 - okay in case of classification we think
318:22 - of the majority in case of regression we
318:25 - take out the mean or a median okay so
318:28 - that's the basic intuition behind and
318:31 - bagging and i really hope that you
318:33 - understood okay
318:36 - so let me explain it again those who
318:38 - have not understood please fast this
318:41 - video if you can because many students
318:43 - are still here that are not under that
318:46 - may not understand this i cannot do uh
318:49 - recapitulate or give a summary of this
318:51 - okay
318:53 - great so here what we do we have a large
318:56 - training data set which is d now what we
318:59 - do
319:01 - we sample our data sample k points from
319:04 - that data we sample k points from the
319:07 - large training data and let's say any
319:09 - sample sample sample of a data and then
319:12 - we train our model on these sample which
319:14 - is m1 it can be largest regression okay
319:17 - now we sample again k points with
319:19 - replacement and also it is with a
319:21 - replacement so it is not necessary that
319:23 - your data should be different from the
319:25 - d1 it can be same or it can be some data
319:28 - points can be same and then you again
319:29 - train so
319:32 - let's say example you train support with
319:33 - the machine let's take example you're
319:34 - saying uh nine days okay so you train
319:37 - and the majority of votes is like
319:38 - ensemble learning okay so that's what
319:41 - your backing is intuitively and you can
319:44 - see that we are not involving any
319:45 - mathematics yeah this is just a bunch of
319:48 - concepts okay so um just i will make
319:51 - sure that
319:53 - you all are on the same page that what
319:56 - it helps
319:57 - it is great great question it helps you
320:00 - in reducing the variance
320:03 - bagging let let me write
320:06 - bagging
320:08 - bagging helps you
320:11 - bagging
320:12 - helps you
320:13 - in reducing the variance
320:16 - it's we will discuss uh 10 minutes onto
320:19 - this also okay
320:22 - yeah okay so bagging helps in reducing
320:25 - the variance okay but before that there
320:28 - is one term that i want to highlight
320:30 - over here that
320:33 - here we have our all base models these
320:36 - are our base models m1 m2 and all of
320:39 - them are bmk these are our base models
320:42 - these base models are usually
320:44 - high variance model
320:46 - these are usually high variance
320:50 - with a low bias model with low bias
320:53 - model and what do i mean by this
320:57 - it is usually we do not do a lot of fine
320:59 - tuning we do not do a lot of fine tuning
321:02 - so that's why it is just overfitting and
321:04 - we had done overfilling so that's why
321:06 - just go down to any data so that's why
321:08 - it is not under filling okay so we have
321:10 - our the base models are high variance
321:12 - and low bias model so we do not do lots
321:15 - of fine tuning just we do a simple uh
321:17 - list in random form which just
321:19 - initialized with it with no no number of
321:22 - depth okay it can go as much as they can
321:24 - so it is overwhelming okay so here we
321:26 - have high variance model and low bias so
321:29 - what it helps
321:30 - what it helps backing helps in reducing
321:33 - your variance how it helps in reducing
321:37 - your variance from making your model
321:40 - more robust okay
321:42 - this is just um what it does is combines
321:45 - them
321:47 - so you have a low bias
321:49 - low bias
321:51 - high variance model now if you combine
321:53 - them if you combine the majority of
321:55 - votes then obviously we'll get a good
321:57 - amount of good
321:59 - good
322:00 - output or a
322:02 - correct output okay so you combine the
322:04 - models you combine these models
322:07 - you combine base models
322:10 - and then you get
322:11 - you then then you get low bias
322:15 - and low variance problem
322:17 - low variance
322:19 - okay
322:19 - this is what you get this is what you
322:22 - get after doing backing and this helps
322:25 - this helps in reducing your variance and
322:29 - this is very good and this is very good
322:32 - okay
322:33 - so there is some uh there is some i want
322:36 - to highlight over here
322:38 - that here we are doing the
322:40 - row sampling so just understand that
322:42 - this is a point that bagging helps in
322:45 - reducing your variance because usually
322:47 - your base learners or base models have
322:50 - high variance and low bias the bias and
322:52 - variance of that trade-off that is high
322:54 - variance and low bias models so what you
322:57 - do you combine them uh combined based
322:59 - models with a lot into a large model and
323:01 - then you get a low bias and no variance
323:03 - models
323:04 - low bias and no variance m which is a
323:06 - large model okay so that's the that's
323:09 - the different uh now i think that you've
323:11 - understood why we call it as it reduces
323:13 - variance okay so here
323:17 - okay so here um
323:19 - what how we sample our data how we
323:22 - sample our data okay how we sample this
323:24 - is a great uh topic to talk on how we
323:27 - sample our data
323:29 - okay so here we are doing a row sampling
323:32 - we are doing row sampling we are not
323:35 - doing column sampling we are doing a row
323:38 - sampling so let me write it down
323:40 - while sampling while sampling our data
323:43 - from the large distribution of our data
323:45 - so let's take an example this is my
323:46 - large data in screening data now while
323:49 - sampling what we do we have this we'll
323:52 - do the row sampling we do the
323:55 - row sampling
323:57 - row sampling
323:58 - while sampling our data okay so let's
324:02 - take an example that we have
324:04 - d columns d columns
324:07 - and m
324:08 - are rows okay so we have this
324:11 - we have b columns and we have ambrose
324:14 - okay so we sample only rows and backing
324:18 - we sample only rows in backing okay so
324:22 - it can be like it can it can be go to d1
324:26 - okay only those and backing
324:28 - okay so that's what we do in uh like a
324:31 - row sampling okay so we'll see in random
324:33 - forest we also do the column sampling
324:36 - plus column sampling okay and random
324:39 - forest we do this we do this but in
324:42 - bagging we do not do the column sampling
324:44 - we only do the row sampling so i hope
324:47 - that you understood the bagging also
324:50 - okay it's also got the bootstrap
324:52 - aggregation first your bootstrap and
324:53 - then you aggregate your base models okay
324:56 - so that's why the name it has a
324:58 - bootstrap aggregation okay so just to
325:01 - make sure that you all understood so i'm
325:03 - just recapitulating the sub section as
325:06 - you can reverse the video to know about
325:08 - ensembl learning because i don't want to
325:10 - just spend my time under that okay
325:13 - so here um just to just want to make
325:16 - sure that here you have your training
325:18 - data here let me see here
325:21 - here you have a training data which is
325:23 - you have a training data and then what
325:25 - you have done you take out the sample
325:27 - endpoints where the replacement okay
325:30 - into your data subset of the data and
325:31 - then you train your model m1 which is
325:33 - your base model it can register linear
325:36 - okay then you again sample k points and
325:38 - d2 then you again put a new model onto
325:40 - these subset of a data you do for k you
325:43 - do for k models or k subsets and then
325:45 - you combine the majority of votes
325:47 - majority of what will lead to
325:49 - classification and and if you use this
325:51 - regression problem we take out a mean or
325:52 - median of a most output from the model
325:55 - space models okay so that's the
325:57 - intuition behind bagging and it helps in
326:00 - reducing your variance it helps and
326:04 - reducing your variance because your base
326:06 - models are usually high variance and low
326:09 - bias model so it combines the base
326:11 - models to bring up low bias and low
326:13 - variance model that's actually good okay
326:16 - so and and in bagging we do the row
326:19 - sampling we do the row sampling means we
326:23 - we have a d features and we have m
326:25 - column and rows so we do sample of our m
326:28 - not d okay so we take whole column we
326:31 - take all the columns okay but we make
326:34 - subset of a rows for training okay so
326:36 - that's what we do in uh bagging and i
326:39 - really hope that you understood this
326:40 - bagging technique now it's time for
326:44 - learning well one algorithm would be one
326:47 - good algorithm one powerful one kaggle
326:49 - binning algorithm one production level
326:51 - algorithm which is random forest
326:55 - okay why i think random forest is a very
326:58 - very powerful algorithm to work on is a
327:01 - very very powerful algorithm to work on
327:04 - let me write a random
327:06 - random forests
327:08 - okay
327:09 - random forest it's a bargaining
327:12 - algorithm it's a bagging technique or
327:13 - you can call bagging algorithm okay so
327:16 - why do i call this uh very powerful
327:19 - because in also my professional
327:21 - experience i think that i have also used
327:23 - a random course a lot and it's it seems
327:25 - like it's this very powerful algorithm
327:27 - whether you want to win a card
327:29 - competitions and which is a machine
327:30 - learning problem or you wanted to make a
327:33 - production level machine learning okay
327:35 - so random forest usually used by quora
327:37 - then we have google amazon they they all
327:41 - use this random forest but it has some a
327:44 - basic intuition a basic concept that
327:46 - instructors are not teaching and it's
327:48 - very very important okay so first of all
327:51 - what we do in random forest so let's
327:53 - recall our decision trees let's recall
327:56 - our decision trees into this now our
327:59 - now our decision tree will play a role
328:02 - now here we have a decision tree so
328:04 - let's recall our decision tree so what
328:06 - we are doing in this entry uh we are
328:08 - doing an it is a simple it's makes a
328:11 - decision and splits your node okay so
328:14 - what you're doing it's a simple if and a
328:17 - nested if and else statements nested if
328:21 - and else statements nested if an else
328:25 - statement so we take if the sepal length
328:28 - is smaller than parallel and then you
328:30 - take a y equals to one like this okay
328:32 - which is a nested if and l statements
328:34 - just ask a question
328:35 - is just ask a question is just ask a
328:38 - question to the null and then splits the
328:40 - note and then it splits the note okay so
328:44 - you can the reverse stuff for the
328:45 - section of decision tree we have some
328:47 - attribute selection measure like entropy
328:50 - then we have uh information gain in
328:53 - formation gain then we have a guinea
328:55 - impurity which we have seen in detail in
328:58 - one hour of section of decision tree and
329:01 - i hope that you enjoyed that also okay
329:03 - so that's the decision tree
329:05 - okay so what is random forest random
329:09 - forest
329:10 - random
329:12 - forest
329:13 - is a combination of
329:15 - decision trees bt plus
329:18 - bagging plus
329:20 - bagging plus
329:22 - feature bagging plus feature bagging or
329:26 - we call it as a column sampling column
329:28 - sampling okay so what do i mean with
329:31 - this let's understand this is step by
329:33 - step so it's it makes sense to you also
329:36 - okay so what we do in random products we
329:38 - have our decision trees okay so you know
329:41 - about different trees so we have uh
329:43 - there's a 500 decision tree okay
329:46 - so random forest is an assembled
329:48 - learning algorithm so we have a lot of
329:50 - base models means decision trees lots of
329:52 - base models so here we have a large
329:55 - distribution of a data okay and here we
329:58 - sample our data d1 and we train a
330:00 - decision tree onto this data okay
330:03 - decision tree then we sample the two
330:05 - with the replacement then we train our
330:07 - decision tree onto this subset okay so
330:09 - you're not using different algorithm you
330:11 - are using only decision trees okay with
330:14 - the row sampling with bagging here we
330:17 - are doing bagging means the sample
330:19 - sampling with replacement which here we
330:21 - are doing a row sampling okay plus
330:24 - in bagging you're doing a row sampling
330:26 - row sampling and aggregating your model
330:28 - means whatever the majority of votes you
330:30 - will aggregate your model okay so you're
330:33 - doing the row sampling plus the column
330:36 - sampling also okay so here and this uh
330:39 - in a bagging we have only doing the row
330:41 - sampling we are taking whole column
330:43 - whole features but you are not but you
330:45 - are only taking the rows okay as a
330:47 - subset but here we are taking we are
330:50 - doing also the column sampling okay so
330:52 - let's learn to understand what do i mean
330:54 - by column sampling or feature bagging
330:56 - okay
330:58 - so the column sampling means column
331:00 - sampling means that you have this your
331:03 - data you have this your data like this
331:06 - you have this your data okay now you
331:09 - have
331:10 - d features you have your leaf features
331:13 - d features d columns like a b c d
331:18 - and you have
331:19 - ambrose amaros okay we have ambrose okay
331:24 - so what you do you for replacement you
331:27 - take any rows you sports for sampling
331:30 - you take your rows
331:32 - random rows let's take an example you
331:33 - took this row this row okay this row and
331:37 - and you took a
331:39 - and b as your column and then you train
331:42 - onto this you are not taking full
331:44 - columns or features you have taken this
331:46 - a and b and in their frame and then the
331:48 - next you t you took c
331:50 - and d okay you took c
331:52 - and d
331:53 - okay and then you train with one one row
331:55 - just an example you join this entry so
331:58 - they're different they are different and
332:00 - if they are different it's much higher
332:02 - chance that your model will be very very
332:04 - good okay ensemble learning if your
332:05 - model is different then this is then
332:07 - it's very very good okay okay great so
332:12 - that's the that's the random forest okay
332:15 - so we have a large number of
332:17 - decision-free maintenance base learners
332:19 - as a base learners that are trained
332:21 - using a bagging technique means it's
332:23 - sampling rules with row sampling plus
332:25 - column sampling okay with a row sampling
332:28 - plus column sampling which is column
332:29 - sampling also called the feature bagging
332:32 - okay between different distributors and
332:34 - then you in majority of boats and and
332:36 - then classification you take them
332:38 - authority or in regression you take the
332:40 - mean or a median of the outputs from the
332:42 - base model okay so that's what you do in
332:46 - this so that's what you do in
332:48 - uh this car
332:50 - a random forest and i hope that you
332:52 - understood okay so uh let's understand
332:55 - it uh more intuitively uh that there is
332:59 - something called as oob
333:01 - it is something called as
333:02 - o o b
333:04 - out of bad points outer bag and this is
333:07 - called in that point so it's uh
333:09 - something called as outer back point so
333:11 - let me not recall this concept just now
333:13 - so let's let's take an example let's
333:15 - take an example
333:17 - that what you have done you have this dn
333:21 - you have this uh you have this large
333:24 - blouse training set set which is b okay
333:28 - which is d okay so what you do
333:31 - let's see an example that you've taken
333:33 - this sample of a data as a b1 and the
333:36 - rest of the data is called the outer
333:38 - back points it's called the outer back
333:41 - points so what you do you subtract
333:44 - means the train data minus the d i and i
333:48 - is the sample so these are called the
333:50 - left points after the sampling which is
333:52 - outer bag
333:54 - points okay out of bag
333:57 - out of bag
333:58 - points okay and this this this can be
334:01 - used for cross validation for evaluating
334:04 - your model okay so if you set omc cycle
334:08 - learn there is a very good library which
334:09 - is cycle learn if you set ob score to ob
334:13 - score to true
334:14 - if you said ob score to true then it
334:17 - will uh give you the ob score also okay
334:20 - so that's the basic or
334:22 - out of bag um
334:24 - points and i hope that you understood um
334:27 - out of ob uh
334:29 - points okay
334:31 - so now let's uh let's recapitulate our
334:34 - bagging and a random forest what we have
334:36 - seen in random forest and diamond okay
334:39 - so
334:41 - in bagging we have seen that we have our
334:43 - data we have our data d we have our data
334:47 - d okay what you do you take out a sample
334:51 - you sample with a replacement d1 okay
334:55 - then you train your model under this
334:56 - subset m1 then you're into d2 little
335:00 - trading water onto d2 and what you're
335:02 - doing you're doing is sampling with row
335:04 - sampling plus all i'm sampling with the
335:07 - replacement okay and d3
335:10 - d3 then you getting your model b3
335:14 - getting your model m2 m3 okay so the
335:17 - majority of vote majority will go and a
335:20 - large model means you just aggregate
335:22 - your model aggregate your model and then
335:25 - you get your final prediction which is
335:27 - why
335:27 - okay this is the whole pipeline so in
335:31 - in bagging you want to do the row
335:33 - sampling and random forest you will you
335:35 - do with column sampling as well as you
335:38 - only take decision trees as your base
335:41 - models okay so in bagging into different
335:44 - different kind of models by the decision
335:46 - tree and random forest to take your uh
335:49 - decision tree as your base model and
335:51 - distill through our train or different
335:52 - different data okay so that's the basic
335:55 - uh intuition behind the random forest
335:57 - and i hope that you understood also
335:59 - about what is com column sampling or
336:01 - watch it what is feature bagging okay
336:03 - and
336:05 - obviously this also helps in reducing
336:06 - your uh variance as it is a bagging
336:09 - technique so obviously it will help you
336:10 - to reduce your variance okay so that's
336:13 - the basic intuition behind branham
336:15 - forest so let's see the run time uh
336:18 - train train and run time complexity of
336:21 - this because if you if it is very uh uh
336:24 - it's very required to trade talk about
336:26 - train and run complexity of this random
336:29 - forest okay so in decision trees
336:33 - in decision trees uh the train
336:35 - complexity that
336:37 - the train complexity in decision trees
336:39 - the train complexity let me write in dt
336:42 - the train complexity is order of n log m
336:47 - n log n times d okay times three
336:51 - times uh yeah so it is a in distance we
336:54 - have n log n so in random forest we have
336:56 - d number of decision trees signed k
336:58 - number of samples okay number of models
337:02 - so that's the that's your model that's
337:05 - the uh
337:06 - train and run time control train uh
337:08 - training complexity of your random
337:10 - forest and the decision tree is just a
337:12 - analog n okay so that's the and d here
337:15 - is the number of k is the number of the
337:17 - models okay so uh it it makes sense also
337:21 - if you take an example of your d as a
337:23 - large data set okay let's take an
337:25 - example that you have a d okay now you
337:28 - take out a sample with a replacement
337:29 - with row sampling plus column sampling
337:32 - with like feature packing okay you take
337:35 - out a subset and then you train your
337:36 - model like m1 then you again do the d2
337:39 - then you take out m2 so here the all the
337:42 - way down to the mk here you have a k
337:44 - models and then you have a d uh d
337:46 - decision trees okay so and also this is
337:50 - a trained uh
337:52 - trivially paralyzed it's a trivially
337:54 - paralyzed what do i mean you can train
337:57 - this model onto parallely okay you can
338:00 - train the model you cannot you you can
338:02 - train this parallelly okay you can take
338:04 - out a subset you train d1 parallely d2
338:07 - parallely d3 parallely so this is a
338:09 - trivially
338:11 - paralyzed
338:13 - parallelized parallelized i think i'm
338:16 - pronouncing this correct okay this is a
338:18 - trivially parallelized you can do
338:20 - trivially parallelized also okay so
338:23 - that's the decision i'm sorry i'll train
338:25 - around turn around and complexity of
338:27 - random forest and i hope that we have
338:29 - talked a lot in short span of time and i
338:31 - hope that you're enjoying this video war
338:34 - section also and and i hope that you are
338:37 - enjoying a lot okay
338:39 - so there is one more concept that i will
338:42 - um talk on and end this video which is
338:45 - sort of this section which is extremely
338:48 - a
338:48 - randomized trees okay
338:51 - extremely a randomized tree so what we
338:54 - do with extremely randomized trees is
338:56 - very become popular after the cycle and
338:59 - releases its uh this api which is
339:02 - something called as extremely
339:05 - extremely
339:07 - randomized
339:09 - randomized
339:11 - trees okay
339:12 - trees so what is this this is in random
339:16 - forest we are doing a column sampling
339:19 - plus row sampling with bagging okay with
339:22 - bootstrap aggregation with bootstrap
339:24 - aggregation which is bagging okay so in
339:27 - uh run random forest and rf we are doing
339:30 - like this so in extreme trees uh
339:34 - in extreme trees we try out the possible
339:36 - values of um
339:39 - fi to determine the threshold means the
339:41 - decision trees and decision trees let's
339:44 - take an example that in decision trees
339:46 - we uh we have we have some epsilon and
339:48 - its checks is greater than ordinals like
339:50 - that for identifying in uh
339:53 - decision tree we are trying out every
339:54 - value and that is that is time that is
339:57 - that is taking time that is taking time
340:00 - okay so uh what we can do instead of
340:04 - trying out every values we sample we
340:07 - sample some subset of columns some
340:09 - subset of rows with some supplies of
340:11 - rows and check with that and
340:14 - choose the pressure according to that
340:17 - because
340:17 - in random forest we have a lot of
340:19 - decision trees and identifying the
340:21 - threshold is a key over there okay so if
340:24 - you if you take all possible values then
340:27 - and that will be computationally time
340:29 - complex time taking so what you do you
340:31 - try out the sample of values from that
340:34 - whole
340:35 - column okay then you'll try and that's
340:37 - called the extremely
340:39 - randomized trees okay
340:42 - so that's what i'm going to talk about
340:44 - extremely randomized trees just to make
340:46 - sure that we are on the same place that
340:49 - what what we were doing in random forest
340:51 - we have a lot we have decision trees we
340:53 - have column and row sampling okay
340:57 - okay and that reduces the variance okay
341:00 - so here um instead in random form we are
341:03 - trying out every in
341:04 - indianapolis and we are trying out every
341:06 - possible values and we are for for that
341:09 - epsilon so for a not for it's trying to
341:13 - time taking so what we do we take out
341:16 - the sample of values from that column
341:18 - and as a as a sample and then we check
341:21 - that for that epsilon 2 for getting that
341:24 - epsilon okay so if you're literally
341:26 - getting confused don't worry it's not a
341:29 - popular popular algorithm which is
341:32 - extremely randomized classifier or
341:34 - regressor it is not a popular algorithm
341:37 - the reason being
341:38 - if you take a sample there is a lot more
341:40 - less chance that your moral is good
341:44 - as compared to random forest so we will
341:47 - rarely use i rarely use this extremely
341:49 - randomized foreign
341:53 - popular algorithm okay so we have talked
341:56 - a lot i think that we have talked a lot
341:58 - on to this now you hope that you
342:01 - understood bagging
342:03 - then we have understood random forest
342:05 - then we have understood some decisions
342:07 - we and then we have understood that in
342:08 - symbol learning now we have talked about
342:11 - packing okay now in the next section
342:14 - subsection um
342:16 - point a point two we will talk about uh
342:19 - boosting okay and boosting we'll talk
342:21 - about gradient adaptive xg okay so we
342:25 - will talk about three algorithms here we
342:26 - have talked about the random forest and
342:28 - extremely randomized uh trees so in
342:31 - there we'll talk about three which is
342:33 - gradient adaptive and xg boost and a
342:35 - gradient boosting is also called
342:38 - g
342:38 - b
342:39 - d
342:40 - t g b d p is gradient boosting precision
342:43 - trees because they also use decision
342:45 - tree as their base models one little
342:47 - century as a base models but what are
342:49 - the some of the disadvantages of random
342:52 - forest
342:53 - the some of the disadvantages of random
342:55 - forest that it is very you it is very it
342:59 - is very bad choice to use to use a
343:02 - random forest or decision trees on large
343:04 - data set okay if you don't because it's
343:07 - very time complexive train taking okay
343:10 - don't use that kind of but you can
343:12 - obviously try it out
343:14 - at least okay you can see some more
343:16 - assumption on the internet for this okay
343:18 - great so now we have talked about
343:20 - everything now it's time for getting
343:23 - into the implementation part of random
343:25 - forests okay we will talk about random
343:28 - forest and decision trees okay either
343:31 - way i think that we have talked about
343:32 - decision trees so we'll talk about a
343:34 - random forest okay on cycle learn a a
343:39 - library okay so let's uh let's see the
343:41 - implementation
343:47 - okay so i'm on my grave okay so here i
343:51 - will write i started using brave in some
343:53 - uh just uh just a days ago just some
343:56 - some days ago so here what i will what i
343:59 - will write i will write a random forest
344:03 - random forest
344:06 - cycle
344:09 - okay
344:10 - and we will see one project we will see
344:12 - one project uh which will be doing all
344:15 - of this implementation with grids or cv
344:18 - fine tuning the hyper parameters okay so
344:21 - let's uh let's deep dive into this let's
344:23 - understand this concept
344:26 - let's see the implementation a very
344:28 - finest explanation of a random forest
344:31 - right here so let me take out my ink to
344:33 - go again because i it's my 212 days left
344:37 - that
344:38 - license expires okay
344:40 - so here i'm i will take my pen i will
344:42 - take medium i will take a good red color
344:44 - yeah so you can go to this api which is
344:47 - sk learn and sample you can also import
344:51 - by just calling uh from sklearn from
344:54 - sklearn dot ensemble from sklearn dot
344:58 - ensemble you can go with this and then
344:59 - you can uh use this api so the first um
345:03 - you will now now you can use the random
345:05 - forex classifier this is the first
345:07 - parameter
345:08 - is n estimators the first parameter is n
345:12 - estimators and estimators is the
345:16 - number of decision trees that you want
345:18 - okay
345:19 - like then what is the number of base
345:21 - models that you want what is the number
345:23 - of base models that you want so you have
345:25 - this data and you take this sample this
345:28 - data so what is the number of so you so
345:30 - here you should take 100 decision tree
345:32 - as a default okay
345:35 - but also this is a very important type
345:37 - of parameter so you fine tune it using a
345:40 - grid search cv
345:45 - or randomized search
345:47 - okay we will see implementation of these
345:49 - two
345:52 - okay so you can use this is the number
345:55 - of decision trees
345:58 - after you have what is the criteria what
346:01 - is the criteria to use in a decision
346:05 - tree what is the attribute selection
346:07 - criteria so the default is given
346:09 - impurity as the best impurity either you
346:11 - can use the entropy but this computation
346:13 - little bit expensive means a time time
346:16 - taking okay you can the default is
346:18 - guinea impurity
346:20 - is now uh the what is the number of
346:23 - depth of your tree the minimum number of
346:26 - a sample required to split and
346:28 - sorry the maximum depth of the tree to
346:31 - stop okay
346:32 - then the nodes will expand means if it
346:34 - is none then it will ah it it has a high
346:38 - chance that it will overfill okay now it
346:41 - is also hypergrammar minimum sample is
346:43 - split with number of samples required to
346:45 - split an internal node means
346:49 - what is the minimum number of samples to
346:51 - split okay samples means what is the
346:53 - number of data points okay
346:55 - then you have let me delete this again
346:58 - then you have uh oops
347:00 - here's my pen then you have a minimum
347:03 - sample of leaf which is which we have
347:05 - already seen max features means what is
347:07 - that you want
347:08 - auto or a square root or log you can
347:12 - read the documentation impurity then
347:16 - bootstrap bootstrap obviously equals to
347:18 - true it involves bagging where the row
347:20 - sampling with the column sampling ob
347:23 - score which is out of back data points
347:26 - which is out of the bag after sampling
347:28 - okay which is for n jobs if you take
347:31 - this n drops equals to minus one if you
347:34 - take this and jobs equals to minus one
347:36 - then it will obviously understand your
347:38 - course and then it will run parallely
347:41 - okay it will run results in parallel it
347:43 - is fast if you take adjobs equals to
347:45 - minus one usually people take okay but
347:48 - it's i think it's it's for printing out
347:50 - something texts okay now um you can see
347:54 - the class page let me see i've already
347:55 - also forgotten about class weight let me
347:58 - see class weight
348:00 - is
348:01 - yeah verbosity when filling and
348:03 - predicting class weight is just the
348:07 - weight associated with the class okay so
348:10 - it is obviously if the default is a none
348:13 - but you can see how it is calculated
348:15 - okay it's not max samples if bootstrap
348:18 - equals to what is the number of a max
348:20 - sample if you set it in none then the
348:23 - default is the x dot shape 0 the number
348:25 - of the samples so you can set some max
348:28 - samples okay so you have some attributes
348:31 - base estimator the child template used
348:33 - to create the collection of finished sub
348:35 - estimators then you have a number of
348:36 - classes here number of features the
348:39 - number of uh number of outputs when if
348:42 - it is performed the feature importance
348:44 - it is also you can use feature
348:46 - importance uh this attribute to uh
348:49 - understand what is the number of feature
348:51 - means what is the importance of your
348:53 - each feature in your model is columns ob
348:56 - score if it's obviously it will give you
348:58 - the in the float value okay so that's
349:01 - the decision tree uh sorry random forest
349:04 - and you can see more about this
349:06 - into uh here and you can really read
349:09 - about attributes and this is how the
349:11 - this is how the
349:13 - featured importance looks like means you
349:15 - can also plot it like this you can also
349:18 - plot it to so which feature and you can
349:20 - use it for feature selection okay great
349:24 - let's see the second one is a random
349:27 - forest regressor
349:31 - let me see yeah that i am under the same
349:34 - path okay so let's see again it's very
349:37 - similar to classifier it's very similar
349:39 - to classifier here
349:41 - here we have mst mirror which is number
349:44 - let me oops i don't know why it is
349:46 - very here we have number of estimators
349:49 - criteria to be msc rms mae okay max step
349:54 - max step minimum sample with bootstrap
349:57 - equals to true obviously take there take
349:59 - this okay ob score equals to false you
350:01 - get big yes or no okay somewhat default
350:04 - to get it is quite similar to that and
350:06 - max sample is none and it sticks a
350:08 - default as x dot
350:10 - so i don't know i don't know why why it
350:12 - happened
350:14 - max that is x dot shape the shape of
350:17 - your
350:18 - okay of your samples okay so that's the
350:21 - basic intuition behind this and max the
350:24 - max sample is also one hypergrammar
350:27 - great so we have talked about a lot
350:29 - about bagging and we have spent one hour
350:31 - on to this now you can see some more
350:33 - attributes you can see some more
350:35 - attributes over here to understand it
350:37 - much better so let me show you uh
350:41 - one uh one diagram that i found very
350:44 - interesting okay so you can see uh some
350:47 - examples using a random foreign
350:49 - regressor uh using a stacking so you
350:52 - will also see the stacking okay stacking
350:55 - is also a very good uh technique as a
350:57 - kaggle winner winning winning technique
350:59 - to use okay but um
351:02 - here you are here you can see that we
351:04 - only have mse we don't have rmse okay so
351:08 - rmse is not default you have to make
351:10 - your own function for our messy just
351:13 - squaring the root your mse okay but you
351:16 - cannot use if you want here your rmse
351:20 - okay you have to make your own you have
351:22 - to make your own i don't know why it is
351:24 - not running well i have to complain this
351:26 - okay i think this okay so for rmse
351:30 - you have to make your own okay
351:33 - but here you cannot use with this
351:34 - library either you can make a full
351:36 - request or on cycle or an atm okay just
351:39 - adding your own rmse okay great so now
351:43 - we have seen these algorithms now we
351:45 - have seen yes i'm going to do it
351:47 - so now we have stream extremely random
351:50 - there is one more left which is
351:51 - extremely randomized trees it just all
351:54 - got extremely
351:57 - randomized
351:59 - classifiers
352:02 - that's cycler it's obviously in cyclone
352:04 - because it's a new release of cyclone
352:08 - let's see this sound let me open it
352:10 - again integral it's very important now
352:12 - so here again we have mst meters
352:14 - criteria max depth is just the same and
352:17 - then we have bootstrap equals to false
352:19 - your bootstrap equals to false it should
352:21 - be true you can make this as a true okay
352:24 - then we have some more uh auto square
352:27 - etcetera you can it's just the same as
352:29 - that but there is some difference that
352:31 - is that that i've just told you that
352:34 - we choose randomly but what we do we
352:37 - choose a randomly sorry a sample and
352:40 - then we take out the sample epsilon okay
352:43 - so that's what we do in a random forest
352:46 - or extremely randomized classifier so
352:49 - let's see for regressor and aggressor is
352:52 - just the same i think that i'm not
352:54 - correct over here okay
352:58 - let's use the grasher and here the same
353:00 - thing over as we have seen and here
353:03 - bootstrap equals to false your end jobs
353:05 - is obvious that you are understood to
353:06 - run trivially paralyzed to create that
353:09 - option
353:11 - okay great so now we have seen about a
353:14 - random forest and i hope that you
353:15 - understood everything here okay so now
353:19 - in the next sub section we will talk
353:21 - about boosting now i hope that you will
353:23 - understand that also okay so let's wait
353:26 - at the next section till then bye bye
353:28 - okay so now we will talk about
353:30 - another ensemble technique which is
353:33 - boosting okay so
353:35 - boosting is one of the again one of the
353:37 - most popular as packing that we have
353:39 - already talked about bagging you just
353:41 - have to recalculate something about
353:42 - bagging that is necessary okay so we
353:45 - have talked about bagging and now we
353:46 - will talk about boosting which is one of
353:49 - the technique of ensemble learning and i
353:52 - really hope that you will enjoy this
353:53 - section and in boosting we will talk
353:56 - about
353:57 - in boosting we'll talk about something
353:59 - called as a gradient boosting
354:02 - and gradient boosting
354:05 - and then i will just give you a
354:06 - geometric intuition or i will just show
354:08 - you the implementation of
354:11 - adaptive boosting which is often called
354:13 - as arab boost
354:14 - okay
354:15 - then i will talk about extreme boosting
354:18 - x g boost okay so these three algorithms
354:22 - means xd boost works best in some cases
354:24 - xd boost works best okay so uh gradient
354:27 -  boosting also works best but i
354:30 - am i it is also works best so we will
354:32 - see these three okay so
354:35 - let's start with this tutorial but
354:37 - before that um i i just want to tell you
354:40 - that you can do the problem set which is
354:42 - on github and you can subscribe the
354:43 - youtube channel just by going to the
354:46 - https https
354:50 - on youtube.comera
354:54 - because this highly motivates me to make
354:56 - content like this for you all for
354:57 - absolutely free okay so you can go to
355:00 - this new era to subscribe this youtube
355:02 - channel with 500 uh just just i have a
355:04 - 500 subscribers soon putting a deep
355:06 - learning tutorial there's announcements
355:08 - coming up soon putting a deep learning
355:09 - tutorial soon okay so let's start with
355:12 - this tutorial
355:13 - and uh okay so first of all what is
355:16 - bagging
355:18 - what is bagging that we have already
355:19 - talked about you can re-wash that the
355:21 - bagging section if you want
355:23 - maybe in a fast way so bagging
355:26 - and bagging we have low bias model we
355:30 - have low bias model and high variance uh
355:35 - high variance models okay so our base
355:38 - models usually have low bias
355:41 - and high variance
355:44 - low bias and high variance means our
355:47 - base models usually have this low bias
355:49 - and high variance and using bagging we
355:51 - reduce
355:53 - this we reduce high variance we reduce
355:57 - this variance okay so our output will be
356:00 - after applying bagging we have our low
356:03 - bias and low variance model low bias and
356:07 - low variance model okay so what what we
356:10 - were doing in bagging we we are just
356:13 - simply
356:15 - doing the column sampling as well as the
356:17 - row sampling means we are doing the
356:20 - column sampling as well as the row
356:22 - sampling in case of random forest but
356:25 - it's just just take an example of random
356:27 - forest and then we do the aggregation
356:29 - aggregation
356:31 - okay so that's what we are doing and
356:33 - let's see um let's see uh just just uh
356:36 - just a recap what we do we have this
356:39 - large data set we have this large data
356:42 - set d n
356:43 - and then what we do we simply divide
356:45 - this data set into subset of the data uh
356:48 - with the replacement so i hope that you
356:50 - remember what is breadth replacement
356:52 - that the data which is here the data
356:54 - points which is here and it needs to be
356:56 - needs not to be different here it can be
356:58 - same in the second data set also okay so
357:01 - you sample them points then you again
357:03 - sample endpoints with replacement then
357:06 - you sample endpoints uh so you take in
357:09 - three subsets of your data and then you
357:11 - train your model
357:14 - train your model onto this data like m1
357:16 - onto this data maybe logistic regression
357:19 - maybe linear regression or maybe support
357:22 - vector machine so you have three models
357:24 - and then if it is a classification
357:26 - problem you simply uh take the majority
357:29 - of votes majority of words that this
357:32 - particular example is of a particular
357:34 - class or if it is a regression problem
357:37 - then you do the average or me or you
357:39 - take out the mean or a median okay
357:42 - in case of regression so that's what we
357:44 - are doing and in random forest we this
357:46 - is these these are called our base
357:48 - models and in random forest we have our
357:50 - base models as a decision trees we have
357:53 - as a decision trees okay so the this
357:57 - usually helps in reducing your bias and
358:01 - reducing your bias okay so that's that's
358:04 - the bagging so let's see what what we
358:07 - have in uh boosting boosting is just
358:09 - opposite in case of bias and variance
358:11 - tradeoff
358:13 - so just just now i think that you know
358:15 - why we have learned bias and variance a
358:17 - lot okay so in boosting we have low
358:20 - variance in the in in this case we have
358:22 - high variance but we have a low variance
358:25 - high bias model here we our model is
358:28 - under fitting we have high bias model
358:31 - okay so it is not performing well on the
358:34 - training set okay so here we have a high
358:36 - bias model and then what we do we
358:39 - additively combine
358:41 - additively
358:43 - additively
358:44 - combined what do i mean with this this
358:46 - is a very great uh question this is this
358:48 - is what we do in here in bagging we are
358:50 - doing the randomization we are doing the
358:52 - bagging means column sampling then row
358:55 - sampling then we have aggregating the
358:57 - model okay but in boosting we have
358:59 - additively combined that here it
359:02 - combines the week with converts the weak
359:05 - learners speak models into a strong
359:08 - model okay so different different weak
359:11 - model uh
359:12 - tends to be a great model okay just we
359:16 - will see how it tends to be a great
359:18 - model so it is just combined so let's
359:20 - see let's see the core idea so the the
359:23 - basic idea of using boosting
359:26 - is using boosting is to reduce bias if
359:30 - you have a hard bias model then you
359:33 - likely to use boosting to reduce the
359:35 - bias of that model ah yeah there is uh
359:38 - some other techniques also that that
359:39 - we've already seen but it's just we use
359:42 - boosting to reduce the bias okay so
359:46 - let's see
359:47 - so let's see the the basic intuition
359:50 - about boosting so let's take an example
359:53 - that you have your data you have your
359:55 - training data so i'm just writing my
359:57 - training data
359:58 - uh where do i write here you have your
360:00 - training data which is your
360:03 - training data i'm just writing train d
360:06 - okay which is usually which is this this
360:08 - is a supervised learning
360:11 - and a supervised learning technique so
360:12 - you have x i
360:14 - and y i with which is a label and it
360:18 - goes i equals to 1 or we can write the i
360:21 - equals to 1
360:22 - all the way down to the maybe m okay
360:25 - here m is the number of training
360:26 - examples into that a training data okay
360:29 - and then you make a model and then you
360:31 - make a model
360:32 - then you make a model at m1 so let's
360:35 - take an example that you have made a
360:36 - moral m1 that simply uh that's simply a
360:39 - function f of that is simply a function
360:41 - f of x which is our hypothesis okay so
360:43 - now what we will do this is the this is
360:45 - the core idea behind boosting so so we
360:47 - have a training data you have your
360:49 - training data like which is your
360:51 - training data and you train your m1
360:52 - model onto that now what you have seen
360:54 - now what you have seen you simply take
360:56 - out the error you simply take out the
360:59 - error means the cost function the loss
361:01 - okay loss for either example loss for
361:04 - eight example so for each example you
361:06 - have y i which is a ground truth which
361:09 - is your ground truth minus your moral
361:11 - predicted value while more predicted
361:14 - value is f of x which is uh even when
361:16 - you input x then you get your output so
361:18 - model predicted value is f of x okay
361:21 - this will give you the loss okay the
361:24 - loss for if it is if it is 0 then this
361:27 - is very good if it is large then it is
361:28 - very bad okay so here we are using just
361:31 - a simple regression loss means just a
361:34 - loss so if you add a submission over
361:36 - here if you add a submission i equals to
361:38 - one all the way down to the m y i minus
361:40 - f f of x then this is the like mse but
361:44 - you do a square in msc but now because
361:46 - of the gradient decent to effectively
361:49 - compute the derivative but here uh you
361:51 - can you can just see just just as a
361:53 - simple conversation what we uh just just
361:56 - we are taking the laws for each training
361:58 - example so here let's take an example
362:00 - that we have take take take in a loss
362:04 - and then what we do
362:06 - and then what we do we train our model
362:08 - onto this loss means we train our model
362:11 - to reduce this a residual error
362:14 - to reduce this
362:16 - residual a residual
362:19 - uh error okay we probably focus or we we
362:23 - more focus on to the data which is
362:26 - misclassified or mis uh which is which
362:28 - has a very large uh error okay so we
362:32 - focus on that okay so what you do
362:35 - um so for really so you want to reduce
362:38 - this error so how you want to reduce you
362:40 - want to make a model make a model m
362:44 - that that
362:45 - that is given x i means you fit this
362:47 - residual so let's take an example i'm
362:49 - just i'm just going to take take an
362:51 - example to make you this statement clear
362:54 - that what you do so let's take an
362:55 - example that you have a regression uh
362:58 - prop problem statement so you have a
362:59 - regression problem statement oops i
363:02 - don't know why i'm making a bad
363:05 - yeah
363:07 - why my x-axis is not working great
363:10 - yeah here is my x-axis a bad x-axis and
363:12 - you have an x like this
363:14 - x like this and then what you you have
363:16 - fit in a straw maybe this line okay a
363:19 - straight line so here it for this train
363:22 - example the loss will be very high so it
363:25 - will uh more probably start focusing on
363:27 - that and it'll fit on that residual
363:30 - covering this okay so maybe it will
363:33 - it will do like this okay it will also
363:36 - cover this if the residual is very high
363:38 - so it's always tries to minimize that
363:39 - residual maybe it can make a knowledge
363:42 - either the example is too much alandi
363:44 - but either it can make a nonlinear uh
363:47 - decision sorry hyperplane okay so uh for
363:51 - so what what we do we fit our error so
363:53 - we make up model m1 that minimizes the
363:57 - error by fitting onto the error so here
363:59 - is the li
364:00 - for i equals to 1 all the way around to
364:03 - the m okay for each way example we are
364:05 - fitting a model okay so it is more
364:08 - probably focusing on the data which is
364:10 - either misclassified or which has a high
364:13 - uh the partic mse or mae okay if it is a
364:16 - regression problem then we take msu or
364:18 - it is or which is misclassified so it is
364:20 - more only focusing on that okay so
364:23 - that's the basic intuition so let's let
364:25 - me uh let me make you uh the full
364:28 - equation how it looks like so you have
364:31 - you have f
364:34 - you have f
364:36 - of x f of x with k means and some uh
364:40 - just just a model a big big model means
364:42 - f of x okay
364:45 - for each frame example i equals to zero
364:47 - all the way down to the k okay all the
364:50 - way down to the k you have an alpha you
364:53 - have an alpha
364:54 - times your model i th model so you will
364:57 - not only have one model you have in
365:00 - first model that fits them that second
365:02 - model that covers that that fits that
365:04 - stress residual then third model that
365:07 - fits that residual from this model
365:09 - fourth model that fits that residual
365:10 - from this model means error okay so we
365:13 - have a different different model so we
365:14 - have a large model this k and we go
365:16 - through each and every model with some
365:18 - la uh just as assume as lambda so we
365:20 - have this uh
365:22 - just uh just as of now just consider
365:24 - this as us we have computed this somehow
365:26 - so we will see how it is computed okay
365:28 - we will see uh when we learn about uh
365:30 - some gradient boosting okay so just to
365:33 - assume that we have some uh uh just a
365:35 - lambda a constant okay here this f of i
365:39 - x that is that is trained to fit the
365:42 - residual trained to fit the residual
365:45 - from the previous model okay
365:48 - from the previous model means this model
365:50 - this m2
365:52 - train to fit the error
365:54 - we get on m1 okay so this this model may
365:58 - have some different thing this this
365:59 - model is able to correctly classify the
366:02 - error from this first model this m3 is
366:05 - able to classify the errors from the m2
366:09 - so like like that okay
366:12 - so that's that's the basic intuition
366:14 - behind boosting okay so i think that you
366:17 - have understood about boosting so now
366:20 - this will end it up this this function
366:22 - this function will be ended up giving
366:25 - you a
366:26 - low bias
366:28 - low bias
366:30 - and a low variance model okay but there
366:33 - is a problem there is a problem so you
366:36 - may think hey i use can you name a
366:38 - problem yeah sure i am here to name okay
366:41 - but before that you can take a break if
366:43 - you want because i'm just it will just
366:45 - take more one hour to complete i think
366:47 - so it's my approximating time so it will
366:49 - take one more hour you can take a break
366:51 - or you can do just a prop problem set if
366:54 - you want but start with the section and
366:56 - then complete the section then see the
366:58 - prop problem set then see some
366:59 - challenges given to you in my github and
367:02 - i really understand that you will be
367:03 - able to do that okay so here you have
367:06 - this one first you have a training data
367:08 - then you have a low score loss for your
367:10 - showing example then each model
367:12 - trend each model tend to um
367:16 - each model tend to
367:18 - fit the residual error given from the
367:20 - previous model okay and in that way they
367:23 - end up being a low bias model and it's
367:26 - very good on training set but there is a
367:28 - problem the problem is that if it is too
367:31 - much good under training set means only
367:34 - 100 accuracy on training set then what
367:37 - will happen then what will happen it
367:40 - will start overfitting new training
367:42 - example will come then it will able not
367:43 - to classify or
367:45 - detect a good uh prediction okay so
367:48 - that's way so that's why we have to take
367:50 - care of how many number of base models
367:52 - so that we have a lambda but we will
367:54 - understand this all okay
367:56 - great so we have understood this and so
367:59 - the core idea behind bagging the core
368:02 - idea behind bagging is not too much hard
368:05 - is just saying is we just use bagging
368:08 - sorry oh this is boosting oops it's
368:10 - boosting the core idea behind boosting
368:13 - is to reduce the bias
368:16 - reduce the bias on the frame like that
368:19 - okay
368:20 - this this converts the weak learners
368:23 - into these strong learners and here we
368:25 - have a good fine-tuned models which is
368:27 - converted into majority of words and
368:29 - then in bagging like that okay so let's
368:31 - see um so that's the basic intuition
368:34 - behind boosting so there are some of the
368:36 - techniques that we'll study about like a
368:38 - gradient like gradient
368:42 - gradient boosted
368:44 - gradient boosted
368:46 - gradient booster decision trees
368:49 - decision trees
368:51 - which is often called as g
368:53 - b
368:54 - d d okay
368:56 - uh this is a this is because because in
368:58 - random forest we have our decision tree
369:00 - and here in gradient boosting we have
369:02 - our base learner saturday decision tree
369:04 - and gradient boosting as a base learner
369:06 - has a decision tree and then we have a
369:08 - adapt adaptive boost which is often
369:10 - called as adap boost which is a little
369:13 - bit uh more advanced version of gradient
369:16 - boosting then you have extreme boosting
369:19 - which is x g boost okay which is again a
369:22 - family of a good algorithm and it's
369:24 - always outperform it's very very
369:26 - powerful algorithmic boost as i've seen
369:29 - so far and we'll show you the
369:30 - implementation of xgboost also with some
369:33 - i will show you how it is implemented
369:35 - and everything and this section valley
369:38 - okay so
369:40 - and that's the basic intuition behind
369:42 - bagging and i really hope that you
369:43 - understood bagging in detail just to
369:46 - recap that boost or helps and why i'm
369:49 - saying bag bagging it's a boosting okay
369:51 - so boosting here in boosting we have low
369:55 - variance and high bias model we
369:57 - additively combine with
369:59 - in which we convert our speak learners
370:02 - into strong learners and the core idea
370:05 - is to reduce the bias it simply means
370:08 - that we want to improve our error under
370:11 - training set okay so that's the basic
370:14 - and we have four which we'll cover in
370:16 - this section which is gradient booster
370:18 - decision trees adapt adaptive boost then
370:22 - we have a x g boost okay so uh i think
370:26 - that you are understood about boosting
370:28 - okay so now we will talk about uh
370:32 - gradient boosting which is again a good
370:34 - up a very fantastic brilliant uh uh
370:38 - algorithm okay so to just just use an
370:41 - internet companies or very big pump
370:43 - companies which is used in ml in
370:45 - production okay so which is usually
370:47 - launched in 20s these uh algorithms okay
370:51 - so we'll study in detail to make you
370:53 - understand each and every concept of
370:56 - gradient boosting and then we will see
370:58 - the implementation then we will see the
371:00 - adaptive boost then we will see that xt
371:03 - boost and then we are end up with this
371:05 - ensemble models okay then we will go
371:08 - with uh unsupervised learning techniques
371:11 - okay so uh just uh let's let's start
371:13 - with gradient boosting now we have
371:16 - talked about gradient sorry the boosting
371:19 - uh the basic intuition behind boosting
371:22 - what actually the boosting are so now i
371:24 - will start talking about a gradient
371:27 - boosting okay so gradient boosting is
371:29 - another yet one of the most powerful
371:31 - algorithm that i've seen so far uh yeah
371:34 - one of one of the most powerful
371:36 - algorithm which is uh which is yet to uh
371:38 - uh just learn it's very to have a good
371:41 - in your tool kit okay so i'm on a
371:43 - wikipedia page i'm on a wikipedia page
371:46 - which i found a great machine this
371:49 - great uh
371:52 - algorithm which is again uh which which
371:55 - just tells you a very good
371:57 - intuition behind gradient boosting
371:59 - rather than just i
372:01 - make use of my blackboard either i will
372:03 - make use of my blackboard over here okay
372:06 - so
372:06 - uh so uh what is so what is gradient
372:09 - boosting this is a great question so
372:11 - creatine boosting is a boosting
372:12 - algorithm that just converts the weak
372:14 - learners into these strong learners okay
372:18 - so let's start with in this uh gradient
372:21 - boosting and you can search for gradient
372:23 - boosting wiki and then you will see the
372:25 - gradient boosting wikipedia articles and
372:27 - then you can read the full articles
372:29 - either i will cover everything in sort
372:32 - uh in sort uh pdf period of a time but
372:35 - i've already covered some of them and
372:37 - and of my just i will cover i i have
372:39 - covered more than this wikipedia okay so
372:42 - i will give you some a real world
372:43 - examples of gradient boosting also where
372:46 - it is used and everything okay but first
372:48 - of all let's understand the trend this
372:51 - the
372:52 - this algorithm okay so let me see my pen
372:56 - is at least working or not i hope that
372:58 - this is working
373:00 - yeah this is working great i'm just
373:02 - happy that my ink is working let's try
373:04 - if the ink to go if you're watching
373:06 - please help me to improve this very it
373:08 - is not that much good okay just to
373:10 - improve this but it's very good tool
373:12 - it's some sometimes it lacks but it's a
373:14 - very good tool
373:16 - check it out it's very good great for
373:18 - free okay so you have this training data
373:21 - which is a input training data you have
373:23 - this three input training data which is
373:26 - your which is the set of let me write
373:28 - the training data which is simply
373:31 - your x i
373:33 - and y i
373:34 - and simply goes from i equals to 1 all
373:37 - the way down to the n okay or m which is
373:41 - our let's let's stick to our formal
373:44 - notation which is m which is a number of
373:47 - training examples number of a training
373:49 - or the size of our training samples okay
373:52 - so that's the that's our given data and
373:55 - we have a differentiable cost function
373:58 - then we have a differentiable cost
374:00 - function okay so what do i mean by
374:02 - differentiable cost function
374:05 - differentiable cost function means that
374:07 - your
374:08 - this cost because we take out the
374:10 - derivative of our cost function we take
374:12 - out our derivative of our cost function
374:15 - with respect to some
374:18 - some value okay so let's take a we are
374:20 - taking out the derivative of our j of
374:22 - theta partial derivative over j of theta
374:25 - okay so that's the
374:27 - that's the basic uh about means uh
374:30 - that's the differential equation that i
374:32 - know if you know if you're a calculus
374:34 - student then then you might interpret
374:36 - that we have a differential but as if if
374:38 - you're not able to get what is this
374:39 - differentiable feel free to leave this
374:42 - differentiable just think that it should
374:44 - be derivable okay for our gradient
374:47 - descent or we will be because we have to
374:50 - take out the derivative of this
374:52 - particular loss function with respect to
374:54 - some uh
374:56 - weights okay so we with that if we are
374:59 - given training set which is d train we
375:02 - have a given a training set which is a
375:04 - value x so x i and y i which goes from i
375:07 - equals to 1 all the way down to the m
375:09 - okay
375:10 - where is my eraser
375:12 - i think that this is my eraser yeah
375:15 - i equals to 1 all the way down to the m
375:17 - and then we have a differentiable
375:19 - equation as given so let's stick to the
375:21 - j
375:22 - of y
375:23 - y f of x and this is simply just the
375:26 - error means just a minus
375:28 - the
375:29 - minus uh your moral moderated value for
375:31 - each and particular examples i equals to
375:33 - 1 all the way down to the m and then we
375:36 - square it all up okay so that's the
375:39 - that's the our cost function maybe it
375:41 - can be mean square error or it can be
375:44 - long loss for classification etc okay
375:48 - then we are given the iterations then we
375:50 - are giving the number of iteration which
375:52 - is m and m here is the model m here is
375:56 - the base learners m here is the number
375:59 - of a base learners
376:02 - number of a base learners
376:04 - number of a base learners okay so so
376:07 - this is the number of base learners
376:08 - which is m
376:10 - now let's start with algorithm so what
376:12 - this algorithm tells you so let me
376:14 - choose the different colors so it might
376:16 - make sense so we initialize our model
376:19 - with some constant value lambda with
376:23 - some constant value lambda in that case
376:26 - we have in uh alpha but now we had
376:29 - changed a little bit that we have our
376:31 - favorite lambda okay so we have to find
376:35 - lambda oh no
376:37 - okay
376:38 - let's uh just think of it as that we
376:40 - have a lambda we have a lambda that we
376:43 - have to find that lambda that minimizes
376:47 - this training error this loss function
376:50 - it should be told here but i have told
376:52 - you here just in my excitement so you
376:55 - what you do you initialize your model
376:58 - with some lambda that minimizes this
377:02 - cost function okay so this first to
377:05 - initialize this uh that's and we will
377:08 - see how this lambda is computed here but
377:11 - first of all you initialize it and then
377:13 - what you do you iterate through each and
377:16 - every model okay first you go
377:18 - first you do this for first model then
377:21 - you do again for second monuments you
377:22 - apply a for loop where you for m equals
377:25 - to one first u two m means you want to
377:28 - go one
377:29 - two three all the way down to the m okay
377:32 - so you do this and then
377:36 - let me first of all let me okay so here
377:38 - then what you will do then i hope that
377:41 - then you initialize your model then you
377:43 - compute the residuals
377:45 - you compute the pseudo residuals you
377:48 - compute the pseudo
377:50 - residuals you compute the pseudo
377:52 - residuals and then here it is named as r
377:56 - uh subscript i and m and m here denotes
377:59 - the num which model and i here for each
378:02 - 20 examples okay so here you compute the
378:05 - inm and then you take out the partial
378:08 - derivative the partial derivative oops
378:12 - what is not working
378:14 - partial derivative
378:17 - hey god please help me
378:19 - the partial derivative of your cost
378:22 - function y i of your cost function y i
378:26 - and f of x so this is your loss function
378:29 - with respect to this function okay f of
378:32 - x your moral projected value okay and
378:34 - then you want to fit your model onto
378:36 - your previous uh residuals so for you go
378:40 - to i equals to 1 all the way down to the
378:41 - end so here you take out for f of x
378:45 - means f that means here here you are uh
378:48 - fitting your model means just you are
378:49 - making the model to be f of m minus one
378:52 - means the previous model okay so you
378:54 - compute those residuals and then you fit
378:57 - the base learners okay that i've just
379:00 - showed you in my in my previous uh just
379:02 - in just just in the boosting that we fit
379:05 - the residual so let's take an example we
379:07 - have n m1 m2 and m3 we have taken the
379:10 - residuals we have taken the residuals
379:12 - and the
379:13 - here is give some residuals this m1 is
379:16 - trained to fit the residuals from m1
379:18 - this m2 train to fit the residuals from
379:21 - m2 okay and this is m3 okay so it is
379:24 - trained to fit the residuals of fam too
379:26 - okay so then you fit a base learner or a
379:29 - weak learner let's take an example three
379:32 - closed under scaling of h of mx here is
379:35 - your
379:36 - two residuals to pseudo residuals means
379:39 - to fit the learner to fit the
379:42 - residuals from the
379:44 - residuals got from the previous base
379:46 - learners it is to train it using the
379:49 - training set this one okay and now here
379:53 - m is in our case which is l i
379:57 - on m model okay so then you fit your
380:00 - model that i've already showed you just
380:01 - similar that we have seen and then you
380:03 - come compute the multiplier which is a
380:06 - constant multiplier lambda m for each
380:09 - model you have lambda m okay which is a
380:12 - one dimensional optimization problem
380:16 - for solving the one dimensional
380:18 - optimization problem so you may ask why
380:20 - do we are choosing this lambda m so for
380:23 - solving one dimensional optimization
380:26 - problem going into 1d
380:28 - 1d 1d optimization
380:31 - 1d optimization is out of the boundary
380:33 - course but you can see on the link
380:37 - okay the how you compute you compute
380:39 - lambda for each model that minimizes the
380:43 - loss of y which is ground truth from the
380:46 - previous model plus
380:48 - plus
380:49 - lambda
380:50 - times our just the model that that we
380:54 - have now okay
380:55 - now what you do you update the model now
380:59 - you update the model to be to with the
381:02 - model to be fitted by the
381:05 - the model that fitted the previous
381:07 - residuals okay so f m x here m is our
381:11 - moral number
381:12 - the
381:13 - means model number then we have it then
381:15 - we have this f of m minus one previous
381:18 - model plus
381:19 - lambda m lambda m which is some constant
381:22 - for solving the one-dimensional
381:23 - optimization okay because we are taking
381:26 - the partial derivative of our loss
381:28 - function y i and f of x i with respect
381:31 - to f of x i and f of x i is our model
381:34 - predicted value okay times h of mx and
381:37 - then you get your output as an f big
381:41 - model m m big model all the way down to
381:44 - the x okay so here you when when you
381:47 - cover all of this you when the loop is
381:49 - done then you get the final model which
381:52 - is f m x that is simply f of m minus 1 x
381:57 - plus the previous model this previous
382:00 - model plus the a model that we got after
382:02 - solving this or 1d optimization problem
382:05 - okay so that's the gradient boosting uh
382:08 - algorithm that i really hope that you
382:09 - understood but let's uh let's uh just
382:12 - just as a recapitulation to help you
382:14 - understand a little bit much better to
382:17 - uh understand this problem okay so what
382:20 - we do
382:21 - let's understand what we do over here so
382:24 - we simply first we have our given our
382:26 - training data we have a training data x
382:28 - i and y i going from i equals to 1 all
382:31 - the way down to the n and n here uh
382:34 - and
382:36 - and here
382:38 - i just hope that it should work now
382:40 - and n here is your and here is number
382:44 - for training your number size of your
382:46 - training set then you have a
382:47 - differentiable loss function with the
382:50 - number of base learners that you want
382:52 - okay then you initialize the model with
382:54 - some constant okay then you apply a for
382:57 - loop in that for loop you take out the
382:59 - residuals you take out the residuals for
383:02 - and and then you
383:05 - name it as a r subscript i which is the
383:07 - number of training exam that the index
383:10 - of between example and m is your number
383:12 - in the index of your model okay minus
383:15 - the taking of the derivative for partial
383:17 - derivative for of your uh loss okay
383:21 - okay and then you fit a base learner or
383:24 - a weak learner because there because it
383:25 - just makes you a weak learner to the
383:27 - strong learner okay
383:29 - to
383:30 - closing under h of mx which is your
383:32 - got from the weak model makes you just
383:35 - fit the base learner to to the residuals
383:37 - so it's simply that you know that you
383:38 - are going to fit your model into x i and
383:42 - your l i which is simply l i is this
383:45 - okay
383:47 - now you compute the multiplier lambda m
383:49 - lambda sub 10 for each particular uh m
383:52 - means the model index for solving the
383:54 - one-dimensional problem so it's just to
383:57 - find the lambda m that minimizes the
383:59 - loss that you get y y i comma the output
384:04 - from this model okay this is the whole
384:06 - model now this is a previous model that
384:08 - is this is a new model that is fitted to
384:11 - fit this residual okay and then you
384:13 - update your model okay then you have to
384:17 - output a big model which is m ffmx that
384:19 - is simply
384:21 - this f minus one of x i plus your big
384:25 - model uh now you just after your full
384:28 - iteration you'll be ending up being a
384:30 - big model okay so that's the basic
384:33 - intuition behind gradient boosting i
384:35 - really think that you understood about
384:36 - gradient boosting now uh now it's time
384:40 - for getting into the uh for getting into
384:43 - the something called as a regularization
384:46 - and uh shrinkage okay but before that
384:48 - why do we need even regularization and
384:51 - shrinkage so why do we need as we have
384:53 - already talked about that we have
384:56 - and that we have in boosting we have
384:59 - high bias we have high bias let me see
385:02 - the recordings are on here
385:04 - oops
385:05 - we have our high bias and low variance
385:09 - problem sorry high buy so we so we use
385:11 - boosting to reduce the bias to reduce
385:14 - the bias so high base is just doing
385:17 - barrel training set so if we just after
385:20 - each iteration we are fitting the
385:21 - previous model residual so yeah it is
385:24 - making a knowledge it is doing very very
385:26 - good on training set so very very good
385:29 - on training sets so it may happen that
385:31 - it may start overfitting and our low by
385:34 - variance goes to
385:35 - high where starts goes going to high
385:37 - variance means our low variances start
385:39 - increasing and now it's converged to
385:41 - high variance so that actually can cause
385:43 - overfilling okay so for avoiding we add
385:46 - regularization and shrinkage which is
385:48 - again shown in the wikipedia page let's
385:51 - see so here um i think that i can teach
385:54 - you better than wikipedia page okay so
385:57 - you have you this big model you have
385:59 - this big model f of m
386:02 - x
386:02 - which is here you have a h zero x plus
386:07 - you do for i equals to one all the way
386:09 - down to the h all the way down to the
386:11 - edge it's number for your model
386:13 - lambda m lambda m
386:16 - or you can see m the number of a model
386:18 - okay
386:19 - h
386:20 - of m x okay so that's your model that we
386:24 - and then what do you do then if the
386:25 - number of a base models increase means
386:28 - it will fit more residuals if the it
386:30 - will fit more residuals more residuals
386:33 - then your over fit will then then over
386:36 - then it will start over fitting start
386:38 - over
386:39 - and if it is start overfitting then your
386:41 - variance will start going up okay so
386:44 - that that will cause the problem so what
386:46 - you do you shrink you shrink by a factor
386:49 - of lamb just a there's a greek letter
386:52 - that i even don't know that is something
386:54 - called as a v so let's assume that is a
386:56 - v which is a parameter v okay so we have
386:59 - a parameter we have our parameter v
387:02 - which will help us uh which is just a
387:05 - parameter for controlling the or it's
387:08 - just shrinks your strings it just
387:10 - strings to do not go that much means it
387:13 - gives a weight it is just a learnable
387:15 - parameter just gives weight and
387:17 - empirically it is found that v equals to
387:20 - 0.1 tends to be a dramatic improvements
387:22 - in your models okay so that's that's why
387:26 - we use uh this v this v to be 0.1
387:30 - and
387:32 - again your v should be in between your v
387:35 - should be in between
387:37 - 0 and 1 and it's found that v equals 0.1
387:42 - would be dramatic improvements in your
387:43 - models okay so you add a new weightage
387:46 - to that
387:47 - model means
387:49 - to this model okay you add british to
387:51 - this model that i've just shown to you
387:53 - advantage to that model and that's
387:56 - called a learning rate for how for how
387:59 - much time for how much rate it should
388:01 - learn okay so that's the so that's we
388:03 - add v direct model so let me add that so
388:06 - let me add that
388:08 - so what you do for you just shrinks your
388:10 - model with
388:11 - shrink your model
388:13 - big model
388:14 - by going f of m minus 1 x plus v times
388:19 - lambda m
388:20 - h of m x and v here is in between in
388:25 - between
388:26 - 1 okay and particle is found that b
388:29 - equals 0.1 works best okay so that's the
388:33 - that's about uh gradient boosting and i
388:35 - really hope that you understood this
388:37 - also
388:38 - okay so now it's time for
388:41 - um we will take a look at implementation
388:43 - okay so now we will take a look at the
388:46 - implementation of gradient boosting
388:47 - classifier and gradient boosting a
388:49 - regular eraser okay but before that
388:52 - let's see the training time complexity
388:53 - of your model so uh let's let's recall
388:56 - of decision trees and decision trees uh
388:59 - we have our train and run time
389:00 - complexity so here we and decision tree
389:02 - dp i'm writing dt we have old and oops i
389:06 - am writing this
389:07 - n log
389:09 - b and here d and then random forest you
389:13 - have
389:14 - o order of n log n number of addition
389:18 - treatments k
389:20 - okay now when gradient boosting decision
389:22 - tree means here we we just take our base
389:25 - learners as a as a decision tree rather
389:27 - than different different models so we
389:29 - have o
389:30 - n log
389:32 - d times the number of a models
389:35 - okay so that's the basic uh uh time
389:38 - complexity of your gradient boosting
389:41 - decision trees okay
389:43 - great now we will see something called
389:46 - as uh now we will see the implementation
389:49 - of this uh gradient boosting decision
389:52 - trees and cycle learn api okay so let's
389:55 - see
389:57 - so let me open gradient
389:59 - boosting
390:01 - implementation implementation
390:05 - okay and scale learn
390:09 - let's see yeah here we found
390:13 - this wait for a few seconds is just
390:14 - loading okay great so now here you are
390:18 - you are on a page of cycle learn api
390:20 - gradient boosting classifier
390:22 - and then you can see over here that um
390:26 - now let's see the some of the parameters
390:28 - that we are over here so here that you
390:30 - have a loss that you have a loss which
390:33 - is the deviance deviance refers to the
390:36 - log loss an exponential um
390:39 - refers to the
390:40 - which which is just adaptive version
390:42 - which is if you set exponential then
390:44 - your gradient boosting will go will will
390:47 - be as will be called as a adaptive
390:50 - boosting or ara boost okay so in
390:53 - adaptive boosting it is more pronely we
390:56 - will see the implementation so in ada
390:58 - boost it is more pronely focusing on
391:01 - unclassified okay more more probably
391:05 - focusing on unclassified but it's not
391:07 - being used too much okay so we have a
391:08 - loss equals to deviance which is it was
391:10 - a legislation laws or log loss okay then
391:13 - you have a learning rate means the rate
391:16 - to string the contribution of each tree
391:18 - by learning rate okay so this is used to
391:20 - reduce your uh over uh variance okay so
391:24 - that's your model does not start
391:25 - overfitting okay so uh this is your
391:28 - learning rate which is default 0.1 and
391:30 - leave it 0.1 okay because it's found
391:33 - that most remember dramatically that
391:34 - they work best in most of the cases
391:37 - and then you have a number of estimators
391:39 - which is number of decision trees
391:41 - subsample criterion
391:43 - min sample split min sample leaf min
391:46 - weight fraction max therefore e3 min
391:49 - impurity these are particularly for each
391:51 - freeze and then you have uh let's see
391:54 - something more of
391:56 - that we have a validation internal
391:59 - change and then total ccp alpha that's
392:01 - not not too cool okay so we have this
392:03 - and these are some of the hyper
392:04 - parameters that i know that you had
392:06 - understood everything okay so you can
392:08 - see more about this in the parameters in
392:11 - detail here but we have already talked
392:13 - about decision trees already okay so
392:16 - let's see the implementation means the
392:18 - implementation of this uh gradient
392:20 - boosting is just one line of code which
392:22 - is here and you can use predict
392:24 - probability it simply gives the
392:26 - probability of that being a true okay
392:29 - for that class okay so first you import
392:32 - from scalar dot in symbol input gradient
392:34 - boosting classifier here is your data
392:36 - means and then you call your with an
392:39 - estimators learning rate 1.1 okay 1.0
392:42 - max depth random
392:44 - state and then you fit it and then you
392:46 - get your score okay so that's the basic
392:49 - intuition behind a gradient boosting uh
392:52 - classifier okay now let's see the
392:54 - gradient boosting regressor gradient
392:57 - boosting regressor
393:02 - regression
393:04 - and sk learn
393:07 - okay so this is a very good to learn
393:09 - from the documentation
393:11 - okay this is very good to learn from the
393:13 - documentation
393:14 - so let's see okay here here we are on uh
393:18 - documentation of a cycle learn api now
393:20 - what we will do we will
393:22 - just let's use the pen and then you can
393:24 - see over here that we have a loss
393:26 - function to be optimized miss l as the
393:28 - refers to the least squares l a d means
393:31 - least absolute deviation is more robust
393:34 - okay so if you have a uber then we have
393:36 - a quantile but the default is ls okay
393:40 - then you have a learning rate however
393:41 - how much this is a for shrinkage then
393:43 - you have a number of estimators then you
393:45 - have some sample criterion min sample
393:48 - split for each particular decision trees
393:50 - these are for each particular decision
393:52 - trees and then the same thing that we
393:54 - have seen so far okay so now uh we are
393:58 - uh this is the basic for the decision
394:00 - trees and i hope that you understood
394:02 - okay now let's uh see the implementation
394:05 - of this i'm literally going fast because
394:06 - i have to teach also that xg boost and
394:09 - arab boost okay so you just uh
394:12 - call the a gradient booster pressure
394:14 - then you call the your train just split
394:16 - then you split your data and then you
394:18 - call your gradient boosting restore with
394:19 - the default parameters okay then you fit
394:22 - it okay and then you
394:24 - simply do the gradient boost regressor
394:26 - then you score it and it reuses the sum
394:29 - scoring parameter it's the long loss or
394:31 - sorry not log losses maybe it uses r2 or
394:33 - msc you can see
394:35 - okay
394:36 - so that's the basic intuition behind how
394:38 - we implement a grasshopper and
394:39 - classifier which we will do in project
394:41 - just to showcase you how you can assess
394:43 - from documentation it's very good to
394:44 - learn from the documentation now it's
394:46 - time for learning from for uh now it's
394:49 - time for to that you'll learn about xge
394:52 - boost we'll learn about uh uh but before
394:55 - that let's uh let's learn about ada
394:57 - boost
394:58 - okay
394:59 - adapt
395:02 - so let's see me upside i want implement
395:05 - scalar
395:07 - okay so
395:08 - if you set your uh loss to be
395:11 - exponential okay to be exponential then
395:14 - it will be equivalent to ada boost
395:17 - classifier
395:18 - boost classifier okay so it will set
395:21 - your laws to be like this and it's just
395:23 - the same as that we have already talked
395:24 - about we have two algorithm given by
395:27 - sami and sammer which is in sammer which
395:30 - is also for legit regression if you have
395:32 - seen is the cycle and api okay so how
395:35 - you implement from arab boost classifier
395:38 - then you call this and then you fill
395:40 - your model and then you are done okay
395:42 - it's very simple i i think that you but
395:44 - just remembering the concepts is very
395:47 - very important because it's not always
395:49 - you have to implement maybe your own
395:51 - something algorithm in your company okay
395:53 - you may think yeah you can't we just
395:55 - study the implementation no no you
395:57 - cannot study
395:58 - okay but cyclone api is very very slow
396:02 - very very slow but it's great but what
396:05 - you can do uh you have to in in some
396:07 - companies for production uh because it's
396:09 - a kaggle winning uh algorithm that we
396:12 - need to understand what is happening how
396:14 - we can tune the hyper parameter okay so
396:16 - here you can see again for regressor
396:19 - okay and here you have a loss equals to
396:21 - linear and then you have a square and
396:23 - then you have exponential okay
396:26 - and here maybe we we do have and not
396:29 - lost you can see state the number of the
396:30 - classes how many number of a
396:31 - classification classifier okay so now we
396:35 - know about this and i really hope that
396:37 - you understood uh the following
396:39 - now it's time for uh learning about
396:42 - extreme boosting one of my favorite but
396:45 - i think adaboosh is not used in
396:47 - production uh many um
396:49 - not uses too much in the production
396:51 - maybe uh i'm not right over here but i
396:53 - think so okay so now we will learn about
396:57 - x g boost which is one of the most
397:00 - popular algorithm which i have seen so
397:03 - far okay
397:05 - means a t
397:06 - okay it's a it's a good algorithm it's a
397:08 - good algorithm but it's one of the best
397:10 - algorithm that wins your kaggle
397:12 - competition okay so now we will see what
397:15 - xc boost does it's just the advanced
397:17 - version of gradient boosting
397:20 - it have it
397:22 - it it does have gradient boosting
397:24 - decision trees plus
397:26 - it has
397:28 - randomization with row sampling plus
397:31 - column sampling and in gradient boosting
397:33 - we are not doing this but it's at
397:35 - randomization which is grow sampling
397:37 - plus column sampling so that's why maybe
397:39 - name it as a extreme gradient boosting
397:42 - and it's works best okay this works
397:45 - brilliantly uh since some cases and
397:48 - machine learning problems okay but it
397:50 - needs fine tuning a lot okay so the
397:53 - gradient boosting decision tree now you
397:55 - have a row it's just how we differ from
397:57 - gradient boosting decision trees you
397:59 - have you do the randomization by doing
398:02 - feature bagging and then you have a row
398:04 - sampling okay and it's just for a
398:06 - simplicity let let me explain you what
398:08 - we
398:09 - tend to learn about this
398:11 - what we do we simply sample the rows
398:15 - as well as the columns for our data okay
398:19 - okay and
398:20 - uh and specifically for bagging we don't
398:22 - know columns we don't do column sampling
398:24 - but in a random random forest we do both
398:27 - so in xgboost we do the gradient
398:30 - boosting crystalline trees as well as a
398:32 - random forest plus
398:34 - uh column sampling okay
398:37 - so that's the that's what we do
398:39 - randomization and
398:40 - that's the xd boost okay so now we will
398:43 - see in detail what actually the xg boost
398:47 - xd boost
398:49 - from the official documentation but but
398:53 - it is all it is it is of course
398:55 - implemented
398:57 - in the
398:58 - it is of course
398:59 - implemented in cyclone api but it's uh
399:03 - but it's very good to use because there
399:05 - this is fast actually it is fast
399:07 - actually it's very good to learn from
399:09 - here rather than there
399:12 - okay so i think that we can found get a
399:15 - the
399:17 - python package
399:19 - because we have different different
399:20 - package no
399:23 - setting parameters
399:25 - oops where it is xgboost
399:28 - uh python package
399:34 - okay so here we have some parameters an
399:37 - xg boost i think that my brave is not
399:39 - working i have to again switch to my
399:41 - favorite chrome why i have switched it
399:44 - to this
399:45 - it's bad x uh brave is actually not good
399:48 - for me and since some kids actually i'm
399:50 - like who am i said to say bad but it's
399:52 - good good but it's all of course
399:55 - sometimes it does very bad okay so let's
399:57 - see some of the parameters let's see
399:59 - some of the parameters so we have
400:01 - different different packages that we had
400:02 - that already been implemented this
400:04 - algorithm
400:05 - so here
400:07 - you have booster which is gb3 means
400:10 - gradient boosting tree you can use the
400:12 - gb linear or dart the means vu's will
400:15 - use gb3 then you have a validate
400:19 - parameters default to false means it's
400:21 - just going to validate your parameters
400:22 - or not then default to maximum number of
400:25 - threads then you have an evaluation
400:27 - matrix then
400:29 - e term is learning rate okay is 0.3 okay
400:33 - gamma which we have seen which is the
400:34 - constant which is zero as default and
400:37 - this just we just randomly initialize
400:39 - means and then we
400:41 - find a good gamma
400:42 - and then what is the max depth for each
400:45 - tree and you can read the documentation
400:47 - over here more
400:48 - minimum child weight minimum delta step
400:51 - means what is the step should one uh
400:54 - maximum delta step we allow each leaf
400:57 - output to be if they it means there is
400:59 - no constraint okay if if means it's just
401:02 - like that it's just uh helping you to
401:05 - not too much pruning to overfitting it's
401:08 - more robust model okay so you can see
401:11 - your lambda means l2 regularization like
401:14 - a lasso and this is for red
401:18 - regularization that is alpha
401:20 - regularization okay then we have a tree
401:23 - method which is exhibits construction
401:25 - algorithm using
401:27 - xgboost you can see the reference you
401:29 - can see obviously see the reference it
401:31 - also supports uh hist and etc then it's
401:35 - a have a scale post weight updater which
401:39 - is process type group policy maximum
401:42 - number of leaves but is to point to zero
401:44 - um to be added okay so max bin predictor
401:48 - then we have a gpu cpu but this leads a
401:50 - lot of fine tuning it takes a lot of
401:53 - time in cpu okay so we have this much
401:56 - and you can see more about this it's
401:58 - very long set of parameters but we
402:00 - usually use the main parameters that we
402:03 - have listed okay so you can see a python
402:06 - package first one you want to install it
402:09 - you want to install it you can just pip
402:11 - install xgboost and then we and then you
402:14 - just call
402:15 - xgb dot d matrix first you convert that
402:18 - into a d matrix then you uh
402:22 - uh do that means you can do also for
402:24 - pandas using the cylon api but it's okay
402:28 - to use it but you can see over your
402:29 - implementation sk learn it's also for
402:32 - regressor that we have seen
402:37 - i think that we had they have removed
402:40 - i think not they have they haven't
402:42 - removed no no worries so you can see
402:44 - from here how it is used and how we
402:46 - train this model and how we save this
402:49 - model uh it's just like a neural web as
402:52 - you as you know that
402:53 - tensorflow has also added decision trees
402:55 - and like that in simple learning it
402:57 - started adding because one of the most
402:59 - powerful
403:00 - uh algorithm in stem learning okay so we
403:04 - have seen a lot in in
403:07 - decision trees okay uh sorry in ensembl
403:11 - learning like bagging and boosting okay
403:15 - so now one last step is left is stacking
403:18 - of your uh stacking okay so after this
403:21 - section we will start with the stacking
403:23 - to help you to better understand what
403:25 - actually stacking is and it will
403:28 - obviously help you okay so we have seen
403:30 - a lot of applications of this and i
403:34 - really hope that you enjoyed it also
403:36 - okay so this this section is just
403:38 - amazing we have learned about
403:40 - boosting and we have learned about
403:42 - gradient boosting they are adaptive
403:44 - boosting they have learned about exege
403:46 - boost okay and so one of the projects
403:48 - will fine-tune we'll use xg boost ada
403:50 - boost with fine-tuning okay one of our
403:53 - project okay so uh that's it for this
403:56 - section in the next section we'll start
403:58 - with the stacking there's a one only 20
404:00 - minute session on stacking will take and
404:02 - then we just with some other summary or
404:05 - revision of ensembl learning okay so
404:08 - let's meet at the next section
404:10 - okay so now we'll talk about our lawson
404:13 - symbol learning technique which is uh
404:16 - called stacking of our models okay so
404:21 - we will see the implementations of the
404:23 - stacking so and we will see how it works
404:27 - and how it changes your accuracy okay so
404:30 - let's recall uh something called as bias
404:33 - and variance of our bagging and boosting
404:37 - okay so when bagging and bagging
404:40 - we have
404:42 - high variance
404:44 - high variance
404:46 - and low bias trade-off
404:49 - okay
404:50 - and in boosting and then boosting you
404:53 - have
404:54 - low buy a high bias
404:57 - high bias
404:58 - and low variance tradeoff okay so
405:02 - remember these two uh for stacking okay
405:05 - so here i am i am on my mls extend which
405:09 - is a library for implementing the
405:12 - sacking classifier okay so you can we
405:15 - will see the implementation of this uh
405:18 - stacking classifier but before that we
405:20 - will learn well how actually stacking
405:23 - works you can get to this page by just
405:26 - going to mlx 10 stacking classifier and
405:30 - click on the first link okay so let's
405:32 - start so here is our data set here is
405:36 - our data set so let me take out my
405:38 - favorite
405:39 - uh ink to go i hope that you remember my
405:42 - favorite ink to go sometimes i
405:44 - roast it also but here it is very good
405:47 - just for in annotating uh these these
405:50 - kind of things okay so here uh let let
405:54 - me take the pen that as of now let's
405:56 - take a red which i like a lot let's take
405:59 - a medium okay great so here is you in
406:02 - bagging what what we were doing we have
406:05 - a large training data we have a large
406:07 - training training data and then your
406:09 - multiplier or you are just taking out a
406:11 - subset of this data d and one d n2 the
406:17 - entry with the replacement are training
406:19 - the decision trees or maybe some same
406:22 - base learners okay so in the stacking we
406:25 - have different different base learners
406:28 - we take out the data
406:30 - okay and then we train our model
406:32 - different different model under the each
406:35 - data like a c1 uh is a model which is
406:37 - trained on different data
406:40 - then again means on the data d1 then c2
406:43 - is trained on d2 all the way down to the
406:46 - m okay so here
406:48 - c1 c2 all the way down to the cm
406:52 - are a different are different
406:56 - models okay so what do i mean by our
406:59 - different models
407:01 - is quite simple is let's take an example
407:04 - let's just take an example that you have
407:06 - your favorite legitimate ration
407:09 - okay you have a logistic regression you
407:11 - have a logistic
407:12 - regression as a c1 okay as a c1
407:16 - then you have your support vector
407:18 - machine
407:19 - as a c2 then you have your favorite
407:21 - naive bayes algorithm knife base
407:24 - algorithm with uh maybe with extensive
407:27 - fine tuning using grid search okay so
407:30 - here we have c3 here we have k nearest
407:33 - neighbors
407:35 - uh which is c4 okay with extensive with
407:38 - maybe k equals to four okay um with
407:40 - extensive fine tuning okay so we have
407:43 - four base learners and we have a
407:44 - different legitimate regression support
407:46 - vector machine nine base k nearest
407:49 - neighbors and there are four different
407:51 - models okay and a train or different
407:53 - different thing okay and the major
407:55 - difference between uh the bagging and
407:58 - boosting is in bagging that that i've
408:00 - told you to recall
408:02 - bagging bagging and stacking
408:05 - is in bagging we have high variance high
408:09 - variance
408:10 - and low bias
408:12 - low bias
408:14 - models which is a base learners which is
408:17 - the base learners and in and in bagging
408:20 - we used to be used bagging for reducing
408:22 - the high variance okay so base learners
408:25 - are usually high variance and low bias
408:27 - and trade-off between them okay so what
408:29 - is the difference between stacking
408:32 - in a stacking
408:34 - in stacking
408:35 - our base base models or base learners
408:38 - are highly tuned are highly well tuned
408:42 - okay highly well parameter tuned okay
408:45 - highly well parameter tuned and they
408:47 - have a good bias and variance trade-off
408:50 - okay so in boosting so in bagging we
408:53 - have high variance where our base space
408:55 - owners are not that much good and also
408:57 - when boosting our business are not that
409:00 - much good but in stacking our base
409:03 - learners are quite good are quite good
409:06 - are very good with extensive fine fine
409:08 - tuning so maybe you have changed the
409:10 - legislation fine tuning with the
409:12 - learning rate support vector machine
409:14 - like c your regularization parameter and
409:17 - your gamma and then maybe some
409:20 - of the other parameters okay a nine
409:23 - bayes algorithm we have also done it's
409:25 - not required but you have done some
409:26 - extensive fine tuning you have kink
409:29 - nearest neighbors we have chosen what is
409:30 - the number of k okay so you have done an
409:33 - extensive fine tuning of your model okay
409:36 - so that's what uh what i mean here i'm
409:38 - taking what a classification example
409:40 - okay so here um
409:42 - what what we are doing
409:45 - here what what we are doing is just we
409:48 - are the models are highly trained it's
409:51 - highly fine-tuned okay highly very very
409:54 - very much a train uh extensive fine
409:57 - tuning are very good models they do have
409:59 - a very good bias and variance tradeoff
410:02 - okay and here it gives prediction let's
410:05 - take an example that
410:06 - c1 gives you prediction as a y-hat one
410:10 - then c2 gives you prediction as if i had
410:13 - to and all the brown to the y hat m okay
410:16 - so each model gives your output okay the
410:18 - prediction okay so what you are doing so
410:21 - what you are doing so let me do this so
410:23 - as an as a motivating example so can i
410:26 - delete this if i can yeah let me let me
410:29 - delete that so what you are doing so
410:31 - what you are actually doing is
410:34 - simply uh taking your training data
410:36 - which is straight taking your training
410:38 - data you you are dividing your training
410:41 - data you're dividing a training data
410:43 - into subsets of into subset of training
410:46 - data d1
410:47 - d2
410:49 - and d3 spotting for an example let's
410:51 - take 4d3 okay and you're training your
410:54 - base learners which has a good bias and
410:57 - variance trade-off which has a good bias
410:59 - and variance trade-off okay the base
411:02 - numbers are very good bias and very good
411:04 - model they are not either
411:06 - low bias or high bias because here in
411:08 - bagging again i'm saying in bagging you
411:11 - have high variance high variance and low
411:16 - bias
411:17 - model and what do i mean by high
411:19 - variance it means it performs very very
411:22 - well under training data but it fails to
411:25 - generalize well on a testing data okay
411:28 - so that's why and and that's why it's
411:30 - called high variance and in boosting
411:33 - it is under fitting it means that your
411:36 - model
411:37 - uh your model is either
411:40 - overfill
411:41 - means uh under fitting because it has a
411:43 - low high bias which is not performing
411:45 - well under training data and low
411:48 - variance like that okay so here we have
411:50 - a intuition about bagging and boosting
411:54 - okay so here we have a highly tuned
411:57 - model with extensive fine tuning and
411:59 - then what you do you take out the
412:01 - prediction why hat one why had to why
412:06 - hats we y hat3 okay after you take out
412:10 - this now what you do you train your
412:13 - model you train your model
412:17 - you train your
412:18 - model obtain your meta classifier you
412:21 - train your meta classifier which is just
412:24 - pretty which is just trained to on the
412:27 - on the predicted class labels from the
412:29 - base learners or their probabilities
412:32 - from their ensemble okay so they are
412:35 - usually trained on these things on these
412:39 - on the predicted class of our favorite
412:42 - classification or base learners
412:44 - either they will either take the class
412:46 - labels or the probability of being that
412:48 - class okay so maybe 0.65 or in
412:52 - particular class it may be zero or one
412:54 - or two okay so that's what the basic
412:56 - intuition behind
412:58 - the
412:58 - this uh stacking but again i'm i'm very
413:01 - uh just just i will recalculate you so
413:04 - that it works it makes sense again okay
413:07 - so what you do in stacking so uh let's
413:10 - uh just just for an example in the
413:13 - stacking we are just taking a trading
413:15 - data okay and then you're training and
413:17 - then you're dividing our data into
413:19 - substitute data and then you're training
413:21 - different different classifier onto that
413:23 - data okay here we have a c1 here we have
413:26 - a c2 all about cm which is new data okay
413:29 - new in new data we are training and uh
413:32 - and then what it happens in trains are
413:34 - c1 c2 all the parameters c3 uh scm under
413:38 - the that data and takes out predictions
413:41 - and the major difference is the first
413:43 - difference is that the
413:45 - bias
413:46 - and variance rate of bias and variance
413:50 - trade-off
413:51 - trade-off
413:53 - of
413:54 - of the base learners in the stacking
413:57 - learners
413:58 - in stacking is good
414:01 - and stacking is
414:03 - good okay it's good whereas in bagging
414:07 - we have
414:08 - high variance and low bias okay and in
414:14 - oops what happened
414:16 - and in boosting
414:18 - we have high bias
414:21 - and low variance high bias and low
414:24 - barrier oops what happened
414:27 - high bias and low variance
414:30 - low variance okay so that's the major
414:33 - difference
414:34 - next thing is that
414:36 - after you get the prediction from each
414:38 - of the model by because you have done a
414:40 - lot more fine tuning a third hyper
414:42 - parameter you'll get your p1 p2 all the
414:45 - way down to the pm now you train a
414:48 - big or a meta classifier which you
414:50 - usually call as s dash onto the
414:53 - prediction of
414:55 - h1 of x means the one classifier second
414:58 - s2 of vector second classifier all the
415:01 - way down to the edge m of x either you
415:03 - train onto the probabilities
415:06 - probabilities given by these models
415:08 - probabilities or the predicted class
415:11 - labels from these ensembles okay and in
415:14 - there is in bagging we are aggregating
415:17 - the majority of votes we are aggregating
415:21 - okay the majority of votes or from that
415:23 - models then you're taking that as a
415:25 - final prediction by hat but we have a
415:27 - different chance of here we have
415:29 - different approach okay so let's
415:32 - let's take a quick quick uh quick look
415:34 - at the at the
415:37 - second at the stacking algorithm but
415:40 - it's i have already explained you and
415:42 - just just above but as an uh just as a
415:45 - formal definition here you have your
415:47 - training data which is usually x i and y
415:51 - i
415:52 - which is which goes from
415:54 - x i equals to 1 all the way down to the
415:56 - m where x i is the member of
416:00 - r which has an n dimensional maybe it
416:02 - can have a multiple features and whereas
416:05 - the y i will be the member of the number
416:08 - of the classes of y okay so that's the
416:11 - thing and then what you do and it's
416:13 - output will be the in symbol classifier
416:15 - which is va edge dash or a big edge okay
416:19 - first what you do learn first level
416:22 - classifiers means you learn uh team t
416:26 - classifiers maybe it can be logistic
416:28 - regression
416:29 - knight bass knight base it can be k
416:32 - nearest neighbors and uh
416:34 - [Music]
416:35 - one one
416:36 - all the way down to the t and t here is
416:39 - the number of base models okay based on
416:42 - the distribution data d now you
416:45 - construct new data set now you construct
416:47 - new data set going from i equals to 1
416:50 - all the way down to the m and then if
416:52 - that that constant contains x i hat
416:56 - prime by i where x i it's simply the
417:00 - prediction the prediction from the each
417:03 - model the from the each base learn
417:06 - learners model okay from the each models
417:09 - now what you do you train your second
417:11 - level classifier first to train the
417:13 - first level now you train your second
417:14 - level classifier and here it simply
417:17 - trains together
417:19 - make a hypothesis of training onto these
417:22 - models and these meta class this this
417:24 - meta classifier can be anything this
417:26 - meta classifier can be logistic
417:28 - reduction can be nine base can be
417:31 - uh
417:32 - carriers neighbors can be support with
417:34 - the machine and even model and we are
417:36 - not aggregating we are not taking mean
417:39 - we are not taking anything we are just
417:41 - trading a second level classifier that
417:43 - is just trained on our front base
417:45 - learners and base learners have a good
417:48 - bias and variance tradeoff okay so
417:51 - that's the stacking and i hope that you
417:53 - understood about the stacking now i will
417:56 - just uh take a look at the the the
417:59 - formal
418:01 - i would say the form without the
418:03 - i could say implementation of a stacking
418:06 - the implementation of the stacking okay
418:09 - so you can see over here you can see
418:10 - over here uh the paper
418:13 - which is in some of the research papers
418:14 - they usually call as a stacked
418:18 - generalization you can uh sound some
418:20 - some in some research paper we call that
418:23 - okay
418:24 - okay so let's make a simple stack
418:27 - classification first what you have done
418:29 - over here we have simply loaded the data
418:32 - set from the sql data set which is the
418:34 - iris data set and iris data set is not
418:37 - too much hard we have sepal oops we have
418:40 - a sepal length we have a sepal length
418:43 - petal length petal width and petal
418:46 - length okay so we have four features and
418:49 - bases on that we have to predict what is
418:51 - this species of that flower which is
418:53 - either can be satoshi verse cycler or
418:56 - virginica okay so that's the that's the
418:59 - that's our data set
419:01 - now you can see first we import the
419:03 - model selection which will see what it
419:05 - does then we put the logistic regression
419:07 - from linear model api and then cycle
419:10 - learn then we import caney knn which is
419:13 - a which is again from neighbor from
419:15 - neighbors api and cycle learn and then
419:17 - you employ import gaussian night bass
419:19 - from uh
419:21 - night bass either not gone into too much
419:23 - of algorithm because learning algorithm
419:25 - can just you can see the wikipedia you
419:27 - are now capable of learning any
419:29 - algorithm okay now uh you just import
419:32 - the random forest specifier from ensembl
419:34 - learning uh and symbol api of cycle
419:37 - learn now you import from mlx10 library
419:41 - is classifier import stacking classifier
419:43 - either you have been first you have to
419:45 - install this using pip install if you
419:47 - have a python mlx stand but then you can
419:51 - do this kind of thing okay where is my
419:53 - let me delete this okay after that after
419:57 - that what we have to do we have to
419:59 - simply import the numpy as np is allies
420:03 - and import warnings okay now you want to
420:05 - ignore the warnings given by the models
420:08 - now first your first model is clf one
420:12 - which is k neighbors which with the
420:14 - neighbors of one if it is bagging if it
420:17 - was bagging then we have to if it is run
420:20 - random for us we have taken one of the
420:22 - decision tree but we are taking
420:23 - different different models and that's
420:24 - what makes it perfect
420:26 - okay random classifier gaussian i base
420:30 - legislative regression okay now we to
420:33 - now what what we have done we
420:34 - instantiated our object everything now
420:36 - instantiate our stacking classifier
420:39 - which is the number of the classifier
420:41 - will be clf 1 which is cll k neighbors
420:45 - random forest which is the cl of two and
420:48 - these three which we are these three
420:51 - are zlf2
420:53 - clf3 are the base learners it will give
420:55 - output
420:56 - it will give output like this okay now
420:59 - what what we what you will do you want a
421:02 - meta classifier which will be the
421:03 - logistic regression which with the
421:05 - logistic regression which is the which
421:07 - will the the distribution as i have told
421:09 - you can take legislation as a meta
421:11 - classifier okay now you perform a
421:13 - three-fold clause cross validation
421:16 - right now you perform three-fold
421:18 - cross-validation
421:21 - and now you perform three-fold
421:22 - cross-validation
421:24 - now uh in three four cross validation
421:26 - you are just looping through clf as well
421:30 - as the label it seems uh zipping the clf
421:33 - one cl of two clf three and self okay
421:37 - now k n a random forest knight base and
421:40 - stacking classifier now you select the
421:43 - best model you now you select the base
421:45 - model by training each of the model
421:47 - whether you are taking a scoring equals
421:49 - to accuracy now you check the accuracy
421:52 - and you can see and you can see
421:54 - and you can see that this stacking
421:57 - classifier has around point
422:01 - point four percent of increase uh
422:04 - as is better i means is quite better
422:07 - than this a random word the stacking
422:09 - classifier works best in this case okay
422:12 - and now what what you can do you can
422:15 - oops what about what happened
422:17 - what you can do you can actually plot
422:19 - the k n and how it is plotting means the
422:22 - decision boundaries of the models how
422:24 - they are plotted that decision
422:25 - boundaries or hyperplanes okay during
422:28 - the math clock level so let me and
422:29 - annotate what is doing first you import
422:32 - the math plot lab then you have to
422:34 - import the plot decision regions from
422:35 - mlx 10 then employ the greatest pick
422:38 - then you include the iter tools then you
422:40 - set the set the
422:42 - area then you set the area again you
422:44 - loop through by dipping and then you
422:46 - take out the product and then you fit it
422:49 - and then you plot it and then you apply
422:51 - the decision boundary then you title the
422:53 - lab and lab here is just k n n a random
422:56 - forest night base and stacking
422:57 - classifier okay after you plot it now
423:01 - you are done with the second classifier
423:03 - okay now as i've already stated you
423:06 - either for training the mera classifier
423:08 - you can use either this uh that
423:12 - i could say
423:14 - i could say that uh maybe the uh
423:16 - the
423:17 - prediction from the base learners so you
423:19 - can either take prediction class or the
423:21 - probabilities as the meta features okay
423:25 - so you can say that use probe
423:28 - use probe
423:29 - equals to true
423:31 - use proba equals true and average
423:34 - probably equals to false okay and you
423:36 - can see uh here are a little bit of the
423:39 - documentation over there okay
423:42 - great now we have seen this and again
423:44 - the same thing is not too much harder we
423:46 - are using the
423:47 - thing and now we will see uh here is an
423:50 - example of a stacked classification
423:52 - using grid search it's your task is to
423:55 - do this but i'm just going to annotate
423:57 - what the
423:58 - this kind of thing will do great search
424:01 - so here you are just first of all you
424:04 - are just you now you will tune you will
424:06 - have a good bias and variance trade-off
424:08 - so you are going to check between one to
424:10 - five you are going to check and then
424:12 - meta classifier and the feather grid
424:14 - search you find the grid best grid
424:16 - search then you plot the results means
424:18 - you take out the results what are the
424:20 - best parameters and the accuracy so
424:22 - after applying that you will get a set
424:25 - of values which are the best uh k
424:27 - nearest has these
424:29 - best features and like that okay
424:32 - now you can import the same thing for
424:34 - doing the k nearest neighbors and this
424:36 - and random forest classifier and then we
424:39 - have one
424:42 - which is the meta classifier okay now
424:45 - using the grid search stacking that
424:47 - operator on different subset of features
424:49 - you can also do that by selecting the
424:51 - column separator by calling the make
424:53 - pipeline that selects the two features
424:56 - okay so that's the that you can do and
424:58 - you can use pre-fitted
425:00 - uh classifiers which is already been
425:03 - fitted uh
425:04 - we previously filled out classifiers in
425:06 - your models okay
425:08 - fit base estimator equals to false means
425:11 - you don't want to fit your base esteem
425:13 - errors okay you can also plot roc curve
425:17 - using and you can see the roc curve like
425:19 - this and and this is first of all these
425:21 - four four examples are very very
425:23 - important we feel
425:25 - you can see the rvc curve uh in more
425:27 - detail on the internet
425:30 - okay great so now we have talked a lot
425:32 - about stacking classifier i showed you
425:35 - the implementation of stacking
425:37 - classifier here is it a very interesting
425:40 - and a brilliant diagram on a stacking or
425:43 - algorithm given a stacking this is a
425:45 - good example on stacking that i want to
425:47 - give it to you okay thanks to the author
425:49 - who has given to you full credit goes to
425:51 - them okay there's some add-on just on
425:54 - man annotating okay so now we are done
425:58 - with uh these uh with uh
426:01 - ensembl learning so let's uh let's
426:04 - recapitulate what what we have seen so
426:06 - far
426:07 - we have seen we have seen we have
426:09 - completed we have
426:11 - completed let me write a good
426:14 - accomplishment
426:16 - completed
426:17 - and sample learning so what we have seen
426:20 - we have seen bagging
426:22 - so in bagging the basic intuition is we
426:25 - have a data we take out different
426:26 - different data we train a different
426:28 - different model and then we aggregate
426:30 - the majority of boards from each of the
426:32 - model then you have
426:34 - then in bagging we have learned about
426:36 - one of the algorithm which is a random
426:38 - forest that just uses the base learners
426:40 - with row sampler uh with feature
426:42 - sampling okay feature bagging and then
426:45 - we take out the boosting then we learned
426:47 - about the boosting we're in boosting we
426:49 - learned about the technique okay and
426:51 - then we're kind of converting the weak
426:52 - learners to the strong learners then
426:55 - then we talk about the
426:57 - g
426:58 - gradient
426:59 - boosting decision trees then we have
427:02 - talked about adaptive boosting which is
427:03 - ada boost which is just to the
427:05 - exponential it's a loss and then we
427:07 - talked about x hd boost okay now we are
427:11 - now we in this section in this sub
427:12 - section we have talked about its
427:14 - stacking we have talked about the
427:16 - stacking where we have seen a lot of
427:18 - examples a lot of examples using grid
427:20 - search and saturday using that that that
427:22 - okay so now i hope that you understood
427:25 - everything about machine learning sorry
427:27 - ensemble learning okay so if you're
427:29 - watching till now i am saying that you
427:32 - know
427:33 - that you do everything about supervised
427:35 - learning that you need to crack any kind
427:37 - of interview okay so just to pat your
427:40 - back and
427:42 - and be sure to subscribe my youtube
427:44 - channel it's it just gives you a great
427:47 - motivation as the new deep learning
427:49 - course will is coming soon so you can
427:52 - pre-register there for free
427:55 - and you can re-register that
427:58 - or if you want or if you want you can go
428:01 - to amtran.com
428:03 - for
428:04 - detailed uh cso there is cso1 course
428:07 - which is uh which is on again machine
428:09 - learning but it's it's this it's not
428:12 - that different but it helps you to make
428:15 - a resume based projects it help you to
428:17 - make the uh everything means a lot paper
428:20 - in laricks you will get live down
428:22 - supports etc just as i step two so that
428:25 - uh just as you can go to cs01 see the
428:27 - benefits for the course details etc and
428:30 - the launch video which has already been
428:32 - launched okay so i think that it's you
428:35 - can also apply for a scholarship if
428:37 - you're a college student but it's
428:38 - totally fine forgive but the course
428:41 - price is like this okay but it's totally
428:43 - based upon you if you want you can
428:45 - definitely consider it just supports to
428:47 - make free content more okay so um that
428:51 - just just to me ask a question is is
428:53 - this course
428:54 - the same as cs01 yeah it's
428:57 - yeah but we in that we have talked about
429:00 - till
429:01 - about neural networks then we have
429:02 - talked about gans convolution neural
429:04 - networks you have you will get a
429:07 - one-to-one session you will get jupiter
429:09 - notebooks which are amazing jupiter
429:11 - notebooks you will get early access to
429:13 - my books you will work with the team you
429:15 - will be getting an internship will work
429:17 - on a real world project in lantern etc
429:20 - okay so you can consider android.go for
429:23 - this okay if you want the lab but if you
429:25 - complete this this course you all be
429:27 - very very comfortable in machine
429:28 - learning okay so that's it for this uh
429:31 - section for this whole section on symbol
429:33 - learning from the next section you can
429:35 - consider subscribing obviously from the
429:38 - next section we'll be starting with and
429:40 - in between we can do some projects so
429:42 - from the next section we'll starting
429:43 - with unsupervised learning and i really
429:46 - hope that you will enjoy that series
429:49 - also okay so let's meet at the next
429:51 - section
429:52 - okay so now we have covered supervised
429:55 - learning and you're gonna now consider a
429:57 - comfort table and supervised learning
429:59 - yourself supervised learning is one of
430:01 - the very best was topic in machine
430:03 - learning that you have covered very
430:05 - smoothly and i hope that you understood
430:08 - every each and everything about
430:09 - supervised learning if you have any kind
430:12 - of doubt you can either ask a new or a
430:15 - discord community or you can ask over to
430:18 - the uh
430:20 - the you can find the discord community
430:22 - or you can come comment and then we can
430:24 - answer your questions
430:26 - okay so uh that so let's uh let's start
430:30 - with unsupervised learning so what
430:32 - actually in supervised learning we are
430:34 - doing we have our data set which is x i
430:37 - as well as y i and we have i equals to 1
430:41 - all the way down to the n and actually
430:43 - we have one supervisor which is by i and
430:46 - we know what our output should look like
430:48 - means we know what our output should
430:49 - look like either be and continuous value
430:53 - which is a regression problem or a
430:55 - classification or a classification
430:58 - okay so that that we know that what our
431:01 - output should look like
431:03 - okay so here
431:06 - so we know what our output should look
431:07 - like so now in case of
431:11 - unsupervised learning there is no
431:13 - supervisor so in case of unsupervised
431:16 - learning we have only x i
431:20 - we have only x i okay x1 x2
431:25 - x3 all the way down to the x i which
431:28 - covers i equals to 1 all the way down to
431:30 - the m okay so here in unsupervised
431:33 - learning we don't have any kind of
431:35 - supervisor that will that that will tell
431:37 - us what what will be the either output
431:40 - or will help us to train our model okay
431:42 - and we we we don't know what our aqua
431:44 - should look like either not in
431:46 - continuous
431:47 - and not in specification so you so you
431:50 - cannot you cannot frame your problem and
431:52 - you cannot even scream because if you if
431:54 - you don't have your labels then then you
431:55 - cannot frame it in a supervised learning
431:58 - problem so what i have to do what what
432:01 - we have to do
432:02 - so but i'm going to just want to do is
432:04 - just specify that the data
432:07 - we we have a structured data as well as
432:10 - on a structured data
432:12 - structure data as well as unstructured
432:15 - data and structured data is simply that
432:18 - which is in a table or format
432:21 - and unstructured data which is just
432:24 - images which cannot be fed on tables or
432:27 - csv files okay or in excel okay so here
432:31 - so uh this is our unsupervised learning
432:33 - because uh we don't have our output okay
432:36 - so what what we have to do this is the
432:38 - main question to ask what we have to do
432:41 - if you don't have the labels so let's
432:43 - consider let's consider
432:45 - you have this uh you have this x and y
432:48 - playing let me draw it very nicely so
432:51 - that in this section i'm just going to
432:52 - in this sub section i'm just going to
432:54 - give you an
432:55 - overview understanding and some of the
432:57 - applications of unsupervised learning
432:59 - okay so consider that you are working on
433:03 - uh
433:04 - just just you have your data points just
433:06 - you have your data points like this you
433:09 - have your data points
433:11 - like this into an x and y plane onto the
433:14 - coordinate planes and you have another
433:17 - data points which is like this okay
433:20 - which is like this and you may ask hey i
433:24 - use why can't we make a simple
433:25 - hyperplane but you don't know but you
433:28 - cannot frame it in classification
433:29 - problem just as a motivating example and
433:32 - i'm taking it as an example okay so here
433:35 - just assume that you have this type of
433:37 - data set okay which is true mentioned
433:39 - either you can make that
433:40 - three-dimensional also you can make a
433:43 - three-dimensional also just by
433:44 - converting this and now let's consider
433:47 - that you have a three-dimensional
433:49 - feature so here you have
433:51 - this
433:52 - here you have another example
433:54 - okay so you have this so now you only
433:57 - have these types of data points which is
433:59 - this this one is x1 x2 x3 these types of
434:02 - okay
434:02 - so
434:03 - in
434:04 - unsupervised learning in unsupervised
434:06 - learning what you do you make cluster of
434:09 - your data which is closest to one point
434:11 - you make cluster of your data of your
434:14 - data make cluster of your data so as a
434:18 - motivating example let's take an example
434:21 - of uh let's take an example that you
434:23 - want to segment your customers okay uh
434:26 - let's say example your data scientist at
434:28 - amazon some some companies so you just
434:32 - wanted to
434:34 - segment your customers so how you will
434:36 - segment your customers uh so what do uh
434:38 - you you will just segment to customers
434:41 - we have this data but you don't have the
434:42 - y labels so what you will do you will
434:46 - make the similar person into the one
434:48 - group
434:49 - similar person into the other guru
434:53 - similar person let me do that my bad
434:57 - okay similar person and another group
434:59 - and similar person similar person
435:03 - similar person into the other book
435:05 - similar person on the other group so
435:07 - what you would have done you have
435:09 - divided your customers into segments now
435:11 - data scientists are business
435:12 - stakeholders what they can do they can
435:14 - decide that okay we can give these uh
435:17 - these customers our deal these customers
435:21 - a deal basis on their activity what they
435:23 - are doing or god we can make a sub on
435:25 - another machinery model that will detect
435:27 - what they are really what they want okay
435:30 - and and we can recommend the products we
435:32 - can recommend the products basically
435:34 - these these types of customers like milk
435:36 - or like watching the jewelry or on an on
435:39 - amazon so here uh also on here
435:44 - you it will show the products of books
435:46 - or maybe some jewelleries which are
435:48 - interested
435:49 - and here maybe they will show you some
435:51 - kitchen
435:52 - kitchen groceries maybe these customers
435:55 - are interested in these and then these
435:57 - customers can be toys
435:59 - maybe uh
436:00 - some
436:02 - tvs okay so they will be recommended
436:04 - some products and according to them they
436:06 - earn a huge amount of money from
436:08 - recommending ads etc okay so so that's
436:12 - why you can see that how we how we frame
436:15 - our problem and now you now it's quite
436:17 - clear to understand that as a motivating
436:20 - example of
436:21 - customer segmentation customer
436:24 - segmentation in amazon and and if you
436:26 - may think here you should you see that
436:29 - uh let me go to amazon.com you will see
436:32 - that i'm being i'm being
436:35 - recommending and they know what i
436:36 - recently viewed what i recently do and
436:39 - they are recommending the products they
436:41 - are recommending the products which you
436:43 - can see over here that they are
436:44 - recommending the products basis on my
436:46 - views okay so i'm in some segment i'm in
436:50 - some segment
436:51 - and they are simply uh recommending the
436:55 - basis products and i hope that you
436:57 - understood and and i hope that you are
436:59 - understanding what i'm saying as an
437:00 - unsuper training framing the problem as
437:03 - an unsupervised learning okay so that's
437:06 - what the first customers segmentation or
437:09 - and uh recommendation engine that is
437:12 - happening in amazon okay so just uh just
437:16 - see that just watch the too much talk
437:18 - videos on youtube now what youtube will
437:20 - do youtube will take yourself and add it
437:23 - in a segment of the one who watches
437:26 - stocks and now they will show you dog
437:28 - ads maybe pedigree or etc whatever the
437:31 - food of the dog is or that will
437:32 - recommend you the videos of dogs okay so
437:35 - that's why we have customer segmentation
437:37 - as a whatever example and a
437:39 - recommendation is a more motivating
437:41 - example so now i hope that is start
437:43 - making sense to you about why we call
437:45 - this as unsupervised learning okay now
437:47 - we so there's a this is a in
437:50 - supervised learning in supervised
437:51 - learning we have two two approaches we
437:54 - have two approaches which is the
437:56 - regression which is the regression
437:58 - and next one is specification but in
438:01 - unsupervised learning we have something
438:03 - called as clustering okay so we cluster
438:06 - our outputs we and if you plot in high
438:08 - dimensional space then you will imagine
438:10 - that the most similar items are close to
438:13 - each other and most decimal items are
438:15 - very much far away okay
438:18 - so you can understand like this okay so
438:22 - let's take a let's take a motivating
438:23 - example again so let's see some of the
438:26 - applications of unsupervised learning so
438:28 - i will spend a little bit amount of time
438:30 - telling you about the applications of
438:34 - uh unsupervised learning and in the in
438:36 - this next subject we'll start with the
438:39 - making clusters how what is intra what
438:41 - is enter how we do we make the cluster
438:43 - how do we evaluate our cluster etc okay
438:47 - so uh here i'm not talking about detail
438:49 - i mean clustering about clustering but i
438:51 - will definitely just told you that we
438:53 - divide our customer into segments okay
438:56 - so
438:56 - here
438:58 - here
438:58 - let's take an example we have now we are
439:01 - taking the now we are taking a look at
439:02 - the applications now we are taking a
439:04 - look at the applications of unsupervised
439:08 - learning so the first application of
439:10 - unsupervised learning is in
439:13 - biology which i have taken from
439:15 - wikipedia which is sequence analysis
439:18 - okay
439:19 - sequence analysis and it's simply
439:22 - it's just put your g on just genes into
439:25 - the particular segment and this will
439:28 - help you in a various cases for a
439:30 - biology student then you will understand
439:33 - then you will understand this
439:35 - concept of sequence and analysis because
439:37 - you don't have what you do you segment
439:39 - your genes in a particular
439:41 - set segments and you can diagnose if
439:43 - this person has it again any kind of
439:46 - okay problem the next application which
439:49 - is in business which is in business uh
439:51 - maybe a grouping of similar clusters for
439:54 - business and needs so let's take an
439:56 - example that some company takes your
439:58 - data and then
439:59 - then take your data and then simply
440:01 - group
440:02 - grouping
440:03 - the similar cluster grouping the similar
440:07 - similar
440:09 - clusters basis on the business data and
440:11 - they can see the clusters what they are
440:13 - what their activity is and they can
440:14 - provide deals offers according to
440:17 - activity
440:18 - okay another thing is we have a
440:21 - recommendation engine recommendation
440:23 - engine recommendation engine that
440:26 - recommends the products recommends the
440:28 - product that we have seen okay so in
440:30 - recommendation you have content
440:32 - filtering collaborative filtering
440:34 - content filtering
440:36 - quantum filtering collaborative
440:38 - filtering okay so which you can see uh
440:41 - which which have been which is village
440:42 - advanced but i'm not going to talk about
440:44 - recommendation engine but as a modding
440:46 - example that you whatever you see in
440:48 - amazon or google they just show you what
440:50 - you have seen so far because they have
440:51 - each and every because if you search
440:53 - anything you have the uh they have that
440:55 - data okay for making annual models next
440:58 - is that and the
441:00 - social network analysis facebook if you
441:02 - know about facebook uh they
441:05 - they told hey
441:06 - this this person has to uh just share
441:09 - the post means that we do the social
441:11 - network analysis
441:13 - social
441:14 - network the means these were they
441:17 - the group customers into the segments
441:20 - the group customers into the segments
441:23 - the group customers into the segments
441:24 - and the pro and they showed up
441:26 - accordingly uh profiles okay another is
441:31 - we have in computers uh computer systems
441:34 - is we have our favorite in computer
441:36 - science we have image segmentation so
441:39 - what do i mean by image segment
441:41 - segmentation so you have a mage you have
441:44 - an image
441:45 - and you segment your image you segment
441:48 - if you frame this problem as
441:49 - unsupervised learning so you have your
441:51 - image so you have your image like this
441:54 - and some someone is here someone is here
441:57 - someone is here so you segment these
442:00 - images
442:01 - segment these images okay uh second
442:04 - segment these images as a pixel device
442:06 - you see that they are they have similar
442:08 - pixels segmented uh so so that's what
442:11 - you're saying segmenting and then this
442:12 - can be used for
442:14 - classification or object detection
442:17 - object detection
442:18 - okay
442:19 - object detection like that okay so uh
442:22 - just grouping your images into segments
442:24 - by using maybe pixels etc okay because
442:28 - we don't have uh labels for body another
442:31 - motivating example in nash triangle
442:33 - processing and is sentiment analysis
442:36 - means uh just
442:38 - just seeing whether it be a negative or
442:40 - the positive okay so what uh let's take
442:43 - an example that you have this uh
442:46 - that that we have this sentence okay
442:48 - this sentence and another sentence okay
442:50 - so it will group the positive science
442:52 - sentence and the negative sentence okay
442:55 - so now you will see now now you will see
442:58 - now what what you will do you will go
443:00 - and see one of the sentence you will go
443:01 - and go and see one of the sentence
443:04 - go and see the one of the sentence and
443:06 - see okay if it is positive then you live
443:08 - a whole
443:09 - whole cluster which is maybe 10 000 10
443:12 - 000
443:13 - um
443:14 - sentences as a positive and you date is
443:17 - a to hold then maybe whatever the number
443:19 - of as a negative so me let's just take a
443:22 - word let's
443:23 - let me elaborate this nlp task of
443:26 - segment analysis let's take an example
443:28 - sentiment analysis sentiment
443:31 - analysis
443:33 - so for an example assume that you have a
443:36 - one
443:37 - billion uh text data points in text
443:40 - which are text textual okay so converter
443:44 - is a word embeddings mean numbers now if
443:46 - it is very very hard to label it will
443:49 - compute if it will take time it will
443:52 - take cost it will take because if you
443:54 - hire some people you have to give them
443:56 - money okay so you have to label one
443:58 - billion so how you have to do so what
444:00 - you will do you convert them into a high
444:02 - dimensional space and you segment uh the
444:05 - closest text which is called the word
444:07 - embeddings closest word imbalance the
444:10 - quantum headings and sentences are here
444:13 - and then then you see one sentence is
444:15 - from this cluster one another sentence
444:17 - from this cluster now assume that this
444:19 - cluster is a positive sentence you label
444:21 - all let's say 50 million as a positive
444:25 - and hold 50 million as the negative okay
444:29 - so
444:30 - so you just require it to just you don't
444:33 - require a lot of times for working with
444:35 - nlp tasks okay so that's the uh that's
444:38 - that's for nlp tasks another is anomaly
444:42 - detection okay what is a normal
444:45 - dissection and and in a knowledge
444:47 - section an anomaly
444:49 - you have anomaly
444:52 - anomaly
444:53 - a detection anomaly detection where we
444:56 - determine outliers in your model so as
445:00 - an example that you have the exam age
445:03 - like this
445:04 - now assume that your data points is here
445:07 - so this is actually outlier this is
445:09 - actually outlier so if you cluster it if
445:12 - your cluster here
445:13 - then this will be ignored and this this
445:15 - this can help in in removing button but
445:18 - using maybe the db scan
445:21 - isolation forest they but most many of
445:23 - them may be some k-means
445:26 - just take that outlier into this cluster
445:29 - okay so let's assume there is a then it
445:31 - is also closest to then they take that
445:33 - into that cluster okay so we have a db
445:36 - scan which helps us into a normal
445:38 - distraction which is again an
445:39 - unsupervised learning model okay in a
445:41 - dance-based reasons
445:43 - great so we have seen a lot of
445:45 - applications of unsupervised learning we
445:47 - have seen a lot and i hope that you
445:49 - understood really
445:50 - and in the in the next sub-section we
445:53 - will start talking about clustering okay
445:55 - we will deep dive into the clustering to
445:57 - help you better understand the topic
445:59 - we'll talk about clustering we will talk
446:01 - about entering cluster interact and drop
446:03 - cluster how we evaluate our cluster okay
446:06 - how we if we evaluate our data that we
446:09 - have a good clustering what what are the
446:11 - some of the types of clustering like
446:12 - partial
446:14 - hierarchical okay then we talked about
446:16 - center-based continuity based density
446:19 - based and then we will talk about one
446:21 - formal center-based algorithm which is k
446:23 - means clustering algorithm okay and then
446:25 - we are done with supervised unsupervised
446:27 - learning okay
446:29 - and then i will give you a little bit
446:30 - overview of deep learning okay so that
446:33 - you could better understand your deep
446:34 - learning a journey
446:36 - uh just
446:37 - evaluation and then we will do some
446:39 - projects based on machine learning so
446:41 - that you could get more feel about
446:43 - machine learning and you are more
446:45 - comfortable and be sure to do the
446:47 - problem sets which are uploaded and
446:49 - github to help you understand the topic
446:51 - or master the topic
446:53 - okay so that's it for this section and i
446:56 - hope that you will that you have enjoyed
446:57 - this section
446:58 - okay so now we'll start talking about
447:01 - clustering we will get in the math and
447:02 - we will see some more algorithms like
447:05 - k-means clustering then we will see
447:07 - hierarchical clustering algorithms which
447:09 - is agglomerative and divisive and
447:12 - then we are and with unsupervised
447:15 - learning so we are entering the last
447:18 - phases of this course and i really hope
447:21 - that you enjoyed this course a lot okay
447:24 - as i enjoyed making this course with
447:26 - very curiosity with very energetic
447:29 - moods so i think that you're also very
447:31 - energetic till now and like me and you
447:34 - may also thinking hey are you sure what
447:36 - about the projects and the projects are
447:38 - in the last section to help you to get
447:41 - feel of everything about machine
447:43 - learning means after you learn all of
447:44 - these things performance matrix
447:46 - algorithms now you will be able to build
447:50 - state of the art models okay so i'm very
447:53 - excited to see you all there and it
447:56 - means in this section last section we'll
447:57 - be building back to back project and the
448:00 - course website is also in the
448:01 - description box below you can see what
448:04 - what problem set is that and you can
448:06 - download and start working on that
448:08 - problem set okay so you i i hope that
448:11 - you're watching this video did totally
448:13 - worth it even i was making video was
448:16 - totally worth it okay so what we are
448:19 - going to start talking about we are
448:21 - going to start talking about
448:23 - we are going to start talking about uh
448:26 - clustering in the in our previous
448:27 - section sub section will be we have
448:30 - talked about some of the applications of
448:32 - clustering we have talked about let let
448:34 - me choose a pen a good pen we have
448:36 - talked about
448:38 - applications we have talked about
448:40 - applications of clustering we have seen
448:42 - what the unsupervised learning is
448:45 - what unsupervised learning is and we
448:47 - have seen the diagram digest some a lot
448:50 - of applications like biology and
448:52 - business and etc we have seen the
448:55 - applications of unsupervised learning
448:57 - and then i've showed you the data okay
448:59 - and then i've given you an overview what
449:01 - we do in clustering okay so let's start
449:04 - with uh clustering okay so how what what
449:07 - what with what the clustering is
449:09 - what the clustering is but don't just
449:12 - bear with me with
449:13 - my handwriting because i don't know what
449:15 - happened to my pen it's very working bad
449:18 - but no worries let's start so here uh
449:22 - let's assume that you have this you have
449:25 - this you have the great oops
449:28 - let me white is not being removed
449:32 - let's assume that you have a x and y
449:34 - plane where you have a two two features
449:37 - uh where you have two features
449:39 - like this if i draw a straight line if i
449:41 - draw a straight line
449:45 - okay so here
449:48 - so here you have this and let's assume
449:51 - that you have
449:52 - here is a point here
449:55 - okay you have this as a point and
449:57 - another point and another point
449:59 - is green once
450:01 - which is here okay
450:03 - so no no no
450:05 - in
450:06 - unsupervised learning in unsupervised
450:07 - learning all datas are saying bye i
450:09 - forgot no worries i usually forgot
450:12 - everything okay so what you have you
450:14 - have these features
450:16 - red features and you have this here so
450:18 - what you usually do in uh in in case of
450:22 - clustering you segment your clusters you
450:25 - segment your data into different
450:26 - different clusters oh my god why it is
450:29 - not happening is
450:30 - you segment your cluster so you have
450:33 - this data so you segment this cluster
450:35 - you segment this cluster
450:37 - to be going into this this and the
450:40 - second cluster we're going into this
450:43 - okay so this is the first cluster this
450:45 - is your second cluster okay so this is
450:47 - your basic inter basic uh thing about
450:50 - clustering that that we have talked okay
450:52 - so we'll see some of the terminology in
450:55 - this so let's draw a very good
450:58 - representation of this diagram so let me
451:01 - delete all these links and let me choose
451:03 - a black pen it's works best in the in
451:06 - case of white
451:08 - okay so you let me draw a straight line
451:12 - with x plane okay
451:15 - so you have
451:16 - x and y plane x and y plane and here you
451:22 - have the data point
451:24 - here you have the data point like this
451:26 - and here you have the data point like
451:29 - this
451:30 - okay so what do you do you segment your
451:32 - uh data points into clusters you cluster
451:35 - it out so some of the terminology is you
451:38 - cluster this you cluster this let me
451:41 - draw a good
451:42 - cluster you cluster this and then you
451:45 - cluster this
451:47 - okay so let's leave that i don't want to
451:50 - make it like that let's leave that for
451:51 - now okay so you cluster this out and
451:54 - then what happens so here is a
451:56 - terminology alert
451:58 - means the in terminology we have
452:01 - something called as intra cluster we
452:03 - have something called as
452:05 - intra cluster
452:07 - intra
452:08 - cluster
452:10 - and enter cluster
452:11 - just
452:12 - just listen what i'm saying interrupt
452:14 - cluster and enter into inter cluster so
452:17 - what do i mean with these intra and
452:19 - enter i mean with this intel intro and
452:22 - enter is enter cluster is the distance
452:26 - between the cluster okay between between
452:29 - the clusters across all the clusters so
452:32 - enter cluster is the difference is the
452:34 - distance between across the cluster so
452:37 - here we have one cluster here we have
452:39 - second cluster so intra inter cluster is
452:43 - the distance between
452:45 - this cluster and this cluster it's the
452:47 - distance between this cluster and this
452:49 - cluster so that's why it's known as
452:51 - enter cluster okay the second type of
452:54 - his intra cluster which is the distance
452:56 - between
452:58 - within the cluster that points within
453:00 - the cluster within the cluster so it may
453:02 - be like this this is called the
453:05 - this is called the intracluster this is
453:08 - called the intra cluster
453:10 - i hope that you are uh that is making
453:12 - sense you have this x and y plane and
453:15 - you have this this kind of thing and
453:16 - what to what we have to do this is this
453:18 - is called the intra cluster where we
453:20 - have the distance between two clusters
453:23 - or maybe two or more than clusters
453:25 - across all the clusters and intra
453:27 - cluster is the
453:29 - distance between the data points inside
453:31 - that cluster okay
453:33 - great so
453:34 - we can think think something like that
453:37 - is we want what we want in this case if
453:40 - we are taking as a terminology that so
453:42 - we want our
453:44 - interact cluster to be small
453:47 - interact cluster
453:49 - interact cluster
453:51 - to be small
453:52 - to be small
453:54 - and
453:55 - inter cluster
453:57 - inter cluster to be large
453:59 - what do i mean with this small and large
454:03 - i mean with this small and large is you
454:06 - have this intra cluster the internet
454:08 - cluster is the distance between this and
454:10 - this and the clusters takes whoever is
454:12 - similar or group
454:15 - is a cluster is just as in is a grouping
454:17 - of the similar objects that they are
454:20 - similar to one another so they should be
454:22 - closest the data point should be closest
454:25 - and the intra cluster of these should be
454:28 - closest okay and the inter cluster inter
454:31 - cluster means the similarity
454:33 - dissimilarity between two clusters
454:35 - should be maximum okay so here we have
454:39 - written our optimum optimization
454:40 - objective
454:41 - uh we have we we want uh our enter
454:44 - cluster our inter cluster which i did
454:47 - with i n should be large
454:50 - and i
454:51 - and a should be intracluster should be
454:55 - small okay so that's the that's the
454:58 - basic definition of that's the basic uh
455:01 - basic terminology that we have seen and
455:03 - i hope that is making sense okay so we
455:06 - can frame some problem we can
455:09 - frame something over here what we can
455:11 - frame is we can frame an optimization
455:14 - objective we can frame a
455:17 - evaluation technique but before that why
455:19 - do we even need so let's assume let's
455:22 - assume that you have this you have this
455:25 - cluster you have this cluster
455:27 - you have this cluster like this you have
455:30 - this cluster
455:31 - one two three four five six seven
455:35 - one two three four five six seven
455:40 - okay so here we have this and
455:42 - who can tell you who can tell you that
455:45 - these are the perfect clusters these are
455:48 - the perfect clusters
455:51 - uh either you will tell hey you should
455:53 - i'm able to see i can tell that these
455:55 - are the perfect clusters but assume that
455:57 - we have uh three dimensional we have
455:59 - four dimensional we have fifty
456:00 - dimensional we have eighty dimensional
456:02 - we have hundred dimensional we have lack
456:04 - dimensional so what you will do in that
456:05 - case so we have evaluation techniques
456:09 - okay we have optimum optim
456:11 - evaluation technique that will help us
456:14 - to identify evaluate our clustering or
456:17 - unsupervised learning a clustering model
456:20 - okay clustering
456:21 - model that will help us uh ideally to
456:24 - understand to to if evaluate how good
456:28 - our clustering is okay so let's see how
456:31 - uh some of some of the evaluation uh
456:34 - techniques okay so the first one we have
456:37 - which is called done index okay so the
456:40 - first one we have is called
456:43 - d u n
456:45 - n
456:45 - index so this is this is a very funny
456:48 - name but it's disappearing uh you can
456:50 - still read about in wikipedia page so
456:53 - it's so let me first write the equation
456:55 - so d
456:56 - equals which is a done index equals to
457:00 - the maximum
457:01 - maximum of i
457:04 - and j
457:05 - means the maximum
457:07 - should maximum distance between i
457:10 - and j
457:11 - divided by
457:13 - or by
457:14 - maximum
457:16 - k
457:17 - a maximum distance d dash
457:19 - between k okay so here
457:22 - what i'm telling here we have this
457:26 - we have this
457:27 - intra cluster we have this
457:30 - intra cluster
457:32 - here we have maximum inter cluster
457:35 - distance
457:36 - maximum
457:38 - inter-cluster distance
457:40 - enter clustered distance okay so ideally
457:43 - it is framing our problem of intra and
457:46 - enter that our
457:48 - inter should be small and our interest
457:51 - should be large okay so here we are not
457:53 - assuming should be small we are assuming
457:55 - what is the largest maximum distance
457:58 - okay so if every everyone is small then
458:00 - the largest maybe 0.00 like that okay so
458:03 - maybe something like that will be there
458:05 - so we are just changing this maximum
458:07 - okay we have maximum over here just
458:09 - don't be confused we are telling minim
458:11 - minimum intra that just ideally means
458:14 - that you want the distance between inter
458:16 - cluster to be small so that's why you
458:18 - are taking the largest whoever the
458:20 - largest however the have a largest
458:22 - distance okay so that's why uh so so you
458:25 - so you can evaluate your model and it's
458:28 - this this sim this the denominator
458:31 - simply means that
458:33 - the the distance between your intra
458:35 - cluster okay the distance between your
458:38 - clusters the distance between it should
458:40 - be ideally large not too much small okay
458:44 - so that's the that's the end if you if
458:46 - you've seen if you see if you sense it's
458:47 - math mathematically you can see that d
458:51 - should be high d should be high
458:54 - to be a good good cluster these should
458:56 - be high okay so this is the evaluation
458:59 - technique for clustering your model and
459:01 - i think that you understood done index
459:03 - so let's recapitulate what we have seen
459:05 - so far
459:06 - is we have let me remove this uh let me
459:09 - let me remove this so we have seen that
459:12 - we have some of some of the terminology
459:14 - so we have this small
459:16 - x and y plane where we have this one two
459:19 - three four five six
459:21 - one two three four five six
459:24 - uh again one more okay so here we have
459:27 - this the diff the distance between the
459:30 - the distance between the
459:33 - the distance
459:34 - between two clusters the distance
459:36 - between two clusters
459:38 - is called as
459:40 - intracluster means across all the
459:42 - clusters maybe some cluster will be here
459:44 - another cluster will be here it's across
459:47 - all the clusters this is called the
459:48 - intra cluster
459:50 - and the distance between within the
459:52 - cluster within the data points is known
459:55 - as the inter cluster is known as the
459:57 - inter cluster and core idea is for any
460:01 - evaluation matrix of your clustering
460:03 - model is your intra cluster should be
460:06 - large
460:07 - intra cluster should be large
460:09 - large
460:10 - and enter clusters should be small okay
460:13 - so we have that we have talked about
460:15 - about a done index we have talked about
460:18 - done index
460:20 - we have talked about done index and done
460:22 - index is simply
460:24 - uh
460:26 - evaluation matrix so the done index is
460:28 - written as d
460:30 - equals to the max
460:32 - of
460:33 - the distance between i and j which are
460:35 - two data points which is obviously inter
460:38 - cluster which is obviously the first
460:40 - enumerator
460:41 - is
460:42 - inter
460:44 - cluster
460:46 - okay and the denominator is simply the
460:49 - intra cluster where you want the maximum
460:51 - distance
460:52 - maximum distance between the
460:55 - values okay so this this is the basic
460:57 - definition and you may think here you
460:58 - should have told about entry inter
461:00 - cluster should be small but we are
461:02 - checking the maximum so that we can
461:04 - evaluate we are checking the what is the
461:05 - maximum in that cluster that has the
461:07 - distance so we can evaluate so everyone
461:10 - should minimum so our d should be high
461:12 - in that case
461:13 - okay so i think that you understood done
461:16 - index also so let's see one more uh
461:20 - one more evaluation technique which is
461:22 - for uh clustering which is uh just just
461:26 - i'm telling you just some some
461:27 - constraints to be added i i just have
461:30 - seen the equations just some conditions
461:32 - to be added in ing where here in i here
461:36 - in i
461:37 - i should be
461:39 - i should be
461:40 - is greater than i should be greater than
461:43 - or equals to 1 or it should be
461:46 - and it should be smaller than or equals
461:48 - to j and j should be smaller than or
461:51 - equals to n and n here is the number of
461:53 - training examples and for k constraints
461:56 - of k
461:57 - is your k should be smaller than or
462:00 - equals to um it's sure it should be at
462:03 - least a smaller should be uh smaller
462:05 - than or equals to
462:07 - n okay so that's the that's the basic
462:10 - definition of uh
462:11 - that's that's the basic clock const
462:13 - constraints but i don't find it's very
462:15 - uh kind of thing but here just to
462:16 - understand this the numerator the
462:19 - numerator is just a maximum interrupt in
462:22 - inter cluster and here maximum intra
462:25 - cluster okay and the reason why we we
462:27 - want to evaluate so that's why we are
462:29 - taking the maximum so if it is maximum
462:31 - then it is bad okay so our d index
462:34 - should be high if you sense it
462:35 - mathematically okay so another
462:38 - evaluation technique that that i have
462:40 - seen so far let me let me go back
462:42 - actually okay so here i am on my another
462:45 - thing and let me remove this okay so
462:48 - another tech technique another technique
462:51 - is here in front of you
462:53 - which is the davis baldin index davis
462:59 - davis
463:00 - baldin
463:02 - baldin
463:03 - index
463:05 - this is also like a done index what you
463:08 - want here we denote is that db equals
463:12 - 2
463:14 - we we take it as a db equals 2
463:18 - 1 over
463:19 - and
463:21 - i equals to 1 all the way down to the n
463:24 - and then you take out the maximum they
463:27 - go to maximum where j is not equals to i
463:31 - sigma i plus
463:33 - sigma j
463:35 - divided by the distance between
463:37 - c i and c g okay and this is just like
463:41 - the clusters and for more information
463:44 - about what is this you can refer to an
463:46 - uh do a wikipedia page okay there is the
463:49 - more deviation etc has been already done
463:51 - over there okay so that's the devious
463:54 - balding index but most of most probably
463:56 - this this this the dawn index used
463:58 - properly in the country in the whole
464:01 - except for evaluation of you of your
464:03 - model so let me highlight it
464:06 - this one okay so we have seen the
464:09 - davis board in index now it's time for
464:12 - uh learning a little bit more in that
464:15 - about
464:16 - what the what the approval means what
464:18 - actually the definitions of what was the
464:21 - definition of your favorite clustering
464:24 - okay so one line definition i could tell
464:26 - about clustering
464:27 - is in clustering you have and it's a
464:31 - it's a grouping uh can i write it yeah
464:33 - it's it's better to write it okay this
464:35 - bad or better with me or you can write
464:37 - with me also so a clustering is simply
464:41 - grouping
464:43 - grouping
464:44 - of
464:46 - objects grouping of objects or elements
464:49 - objects such that in such a way i could
464:52 - say in such a way
464:54 - such a way such such a way
464:58 - our
464:59 - our our
465:01 - object
465:02 - our object
465:05 - in a
465:06 - should be
465:07 - should be similar
465:10 - similar to each to the to each group
465:13 - where it is in
465:14 - each group
465:16 - and differ
465:17 - from another cluster cluster differ
465:20 - from
465:21 - another cluster
465:24 - okay so that's the basic definition
465:26 - basic definition of clustering and a
465:28 - very good definition and from clustering
465:31 - in clustering we have two cases intra
465:33 - cluster in inter cluster where we want
465:35 - our intra cluster is the measure of
465:37 - distance between
465:39 - um just a distance within the cluster
465:41 - and inter cluster is difference between
465:43 - across all the clusters okay so this is
465:46 - the basic definition of a clustering and
465:48 - i hope that you understood everything
465:50 - okay so now we have seen done index we
465:52 - have seen clustering now it's time for
465:54 - learning about getting into depth of
465:57 - clustering
465:59 - about
466:00 - types of clustering how many types of
466:02 - clustering we get in our life and then
466:04 - we will just after talking about types
466:06 - of clustering we will end this uh
466:08 - subsection and in the next section we
466:09 - will be talking about uh do one
466:12 - algorithm which is k-means and the next
466:13 - sub-section we're talking about a
466:15 - hierarchical clustering which is
466:17 - agglomerative and diversive clustering
466:19 - okay so but before that let's uh let's
466:22 - see some of the types of clustering okay
466:25 - so the types of clustering which
466:26 - includes
466:27 - the types
466:29 - the types of clustering let me choose it
466:31 - the color so some some of the types of
466:33 - clustering are first one is partitional
466:37 - based clustering
466:38 - partitional i'm just writing in short
466:41 - partitional
466:44 - partitional based approach or clustering
466:48 - okay so what is partitional based
466:50 - clustering so assume assume that you
466:53 - have this uh that you have this x and y
466:55 - plane and you have this data point like
466:58 - this and you have this data point like
466:59 - this okay so what you will do you will
467:02 - partition it you will partition it into
467:04 - two clusters and you are done okay so
467:06 - here we have one algorithm which is
467:08 - called km means algorithm that we'll
467:11 - study in our next subsection okay for in
467:13 - a partitional base approach
467:15 - then we have hierarchical clustering
467:18 - high ra recall hierarchical
467:22 - clustering clustering okay so in these
467:26 - types of hierarchical clustering we have
467:28 - like a dendogram if you have seen a
467:30 - dendogram then you know about a
467:32 - hierarchical cross string just just just
467:34 - as a just if you know so let's assume
467:37 - that you have this data point like this
467:39 - you have this data point uh let me do it
467:42 - here that we have this here like this
467:45 - okay so you have this four points we
467:47 - have this four points and again you have
467:50 - p1
467:51 - p2
467:52 - p3 p4 and if you're plotted the points
467:55 - looks like this so these two this p1 and
467:58 - p2 looks close this p1 and p2 appears
468:01 - this
468:02 - uh
468:03 - p2 and p3 just just assume that this is
468:05 - a p2 and p3 this this this looks close
468:08 - so you just cluster it out okay so the
468:11 - p2 so what you do you just
468:13 - make an endogram just like this uh that
468:15 - p2 and p3 are now a cluster which is the
468:18 - same though which which we can consider
468:19 - p2 union p3 okay now these are the
468:23 - two clusters now if you see the closest
468:26 - structure is this
468:28 - a p4 so what you will do you will again
468:30 - make a nested cluster now i would now
468:33 - this this will look like this and now
468:35 - what you will do you will attach p4 over
468:38 - your pp4 as a dendrogram okay and then
468:41 - what you do then here is this this is
468:43 - the p1 is the closest then you cover it
468:47 - and then this whole and this whole now
468:50 - after that you will be end data being a
468:52 - dendogram you will be able to see a
468:54 - dendrogram which you can see over here
468:57 - so here after which is p1 like this okay
469:01 - now you can see now we cannot burn
469:04 - we have a large cluster which we have a
469:06 - large
469:07 - uh cluster now we are done this this is
469:10 - called the traditional van der graan
469:12 - because you can see on internet about
469:13 - this so what we have seen so far we have
469:16 - we have augmentative structure we are
469:19 - going up means we are uh just we are
469:22 - going up like this means we have this p1
469:24 - p2 p3 p4 we are we these are own
469:27 - clusters by themselves and first these
469:30 - are their own clusters we have four
469:32 - clusters over here we have four clusters
469:34 - now we cluster this p2 and p3 then we
469:37 - close cluster p3 and p4 because they are
469:39 - close to each other then we construct p1
469:42 - to p4 okay so now we got our full
469:45 - dendrogram okay so that's that is
469:47 - usually a agglomerative agglomerative
469:50 - cluster we have something called as
469:52 - diversif we are in diversif and i'm
469:55 - talking about in hierarchical clustering
469:56 - application which is agglomerative and
469:59 - divisive and divisive we have given p1
470:03 - uh p2
470:05 - p2
470:06 - we have something called as p3 let's
470:09 - let's assume that that that we have abcd
470:12 - okay so a it's just it will match if i
470:15 - do that abcd okay so e let's assume e
470:19 - also so you divide this okay so what
470:22 - what what you do you simply you diverge
470:25 - visit okay like this uh first you divide
470:28 - a and b
470:29 - a b as one cluster then you divide c d e
470:32 - then you have c d e
470:34 - okay then you divide a and b into
470:37 - different different clusters so you have
470:39 - this whole dendrogram like structure
470:41 - like this now you are uh now you are
470:44 - this is just opposite of fog glimmer
470:45 - right here we are just here we are
470:47 - making up here we are making up here we
470:49 - are making uh a different different
470:51 - cluster okay now we do divide our c
470:54 - then we have a d e now we divide our d
470:57 - and e now this is our divisive okay so
471:00 - we divide our whole cluster into
471:02 - different different groups which are
471:03 - most closest to each other okay we will
471:06 - study in detail about this uh in in our
471:09 - uh next subsection where we will talking
471:11 - about hierarchical clustering okay after
471:14 - that we have something known as
471:17 - after that we have something known as
471:19 - well separated clusters where it is well
471:22 - separated clusters okay just just i'm
471:25 - writing it's well separated means we you
471:27 - can easily your model can easily uh
471:30 - separate well separated
471:32 - well separated
471:34 - then you have the fourth one which is
471:36 - center-based which is also k-means
471:39 - clustering is this center-based
471:41 - algorithm okay
471:42 - continuity-based we have something
471:44 - called as nearest neighbors k nearest
471:46 - neighbors okay and then we have density
471:50 - based which is often known as db scan db
471:54 - scan okay which which you have you will
471:56 - get in problem set to learn about this
471:59 - uh db scan okay
472:02 - great so we have seen a lot about
472:05 - clustering and i hope that you really
472:07 - enjoyed this session there's some
472:09 - sub section of clustering and from the
472:12 - next section we'll be talking about lots
472:14 - algorithm or k-means clustering but i
472:16 - will definitely try to complete in no
472:18 - time so that you can you could get a
472:20 - more
472:21 - more a prone uh
472:23 - knowledge of clustering and uh able to
472:26 - make uh unsupervised learning models
472:28 - okay so let's see so let's see
472:30 - as just recapitulate what you have seen
472:33 - so far we have seen what is clustering
472:36 - clustering is just a grouping of similar
472:39 - objects in such a way that these objects
472:41 - are similar to each other within the
472:43 - cluster or our inter cluster our end to
472:47 - enter clusters should be different
472:49 - should be maximum and our intra cluster
472:51 - should be small and what is the
472:53 - difference between enter
472:54 - inter and intra in enter we have the
472:57 - distance between uh across all the
473:00 - clusters and that's why we need a
473:01 - maximum and we have intra in which our
473:04 - points our points within the cluster
473:07 - should be minimum okay means more
473:09 - similar okay other than the other
473:12 - clusters okay so that's that's the
473:14 - that's the basic intuition about this
473:16 - and uh
473:18 - the clustering then we have seen how we
473:20 - can evaluate so i have talked about one
473:23 - index which one evaluation index which
473:25 - is done index okay and on index it is
473:28 - used to uh take out the evaluation is
473:31 - used to evaluate your clustering model
473:34 - and what is what what is what it does he
473:37 - it takes out the maximum what is the
473:39 - maximum in inter cluster what is the
473:41 - maximum to evaluate the performance
473:44 - between between two points and it takes
473:46 - out the maximum of the uh this the the
473:50 - the denominator is an intra cluster and
473:53 - a
473:54 - numerator sorry yeah the denominator is
473:57 - intra clusters is the numerator is intra
474:01 - cluster and the denominator is inter
474:03 - cluster okay and then we have something
474:06 - called as davis bounding by bolding
474:08 - block and index this is just it it will
474:11 - take a lot of time to teach this but
474:13 - it's out of the boundary course but it's
474:15 - just here and is the number of clusters
474:17 - where we have a sigma i plus 6 sigma g
474:19 - and where i is not equal to j we want
474:22 - the maximum and then we are taking out
474:23 - the distance between two clusters and
474:25 - then we are dividing it up okay so
474:27 - that's why that's what the
474:29 - full uh clustering base models is
474:32 - and now i hope that you understood about
474:34 - clustering uh now it's time now now it's
474:37 - time for learning about
474:43 - now now now it's time to learn about
474:45 - something new which is in subsection
474:47 - where we will talk about uh where we
474:49 - have talked about
474:51 - four five types of clustering which is
474:53 - partitional based hierarchical
474:55 - clustering and well separated and center
474:58 - based and db scan okay so we will talk
475:01 - about partitional hierarchical and well
475:03 - separated is also in center based where
475:05 - you your prop problem set will be on db
475:08 - scan okay so here we are done with this
475:11 - sub-section now in the next section
475:12 - we'll start talking about k-means till
475:14 - then have a good day okay so now we have
475:17 - talked about various things like
475:18 - clustering we have given a part one in
475:21 - subsection i've given you unsupervised
475:22 - learning applications and then we have
475:24 - talked about various applications of
475:26 - unsupervised learning and then i've just
475:28 - given you an overview of clustering in
475:30 - this first subsection and the next
475:32 - subsection i've given you the intuition
475:34 - behind clustering i've given a formal
475:36 - definition of a clustering we have
475:38 - talked about inter cluster intra cluster
475:41 - we had talked about the evaluation
475:42 - matrix like done index devious balding
475:45 - in index and i've made you understand
475:47 - each and every equations and i've
475:49 - already also helped you to understand
475:51 - that what are the types of clustering
475:53 - which are available like partitional
475:56 - based hierarchical clustering then you
475:58 - have a center based well separated
476:01 - density based continuity based okay so
476:05 - we have this kind of
476:07 - clustering which are already available
476:09 - now we will talk about a partitional and
476:11 - center center based clustering which is
476:14 - k means algorithm as this example was
476:18 - taken from andrew non course of machine
476:20 - learning but he has uh but it's too much
476:22 - uh 37 years old but i have i have made
476:25 - it very very updated for 2020 just that
476:29 - this this example is from andrew nong
476:31 - okay so
476:33 - i've also included k means plus plus
476:36 - algorithm what the k means plus plus
476:38 - algorithm does and some of the
476:40 - variations of k means and then also i
476:43 - have talked about in detail what are the
476:45 - what are the limitations of k-means
476:47 - clustering what how we initialize the
476:50 - centroids what are the time complexity
476:52 - of k-means clustering okay so then we
476:55 - have talked about the full machia full
476:57 - k-means clustering algorithm how we
476:59 - evaluate our k-means clustering
477:01 - algorithm okay with the euclidean
477:04 - distance so that's what we are going to
477:05 - start talk about just be sure to just
477:08 - sit sit somewhere and see and take copy
477:12 - and pen to understand okay but before
477:14 - that what we are going to study is
477:16 - k-means clustering algorithm sometimes
477:19 - so the synonym of came cayman's
477:21 - clustering is lloyd's algorithm it's
477:24 - something sometimes called lloyd's it's
477:27 - sometimes called lawyers
477:30 - algorithm lots algorithm okay so it may
477:35 - be some people pronounce it as a lots
477:37 - algorithm or a k means clustering
477:40 - algorithm okay but i'd like to pronounce
477:43 - what k means okay so uh just to just as
477:46 - as an example we have this uh data set
477:49 - we have this data set over here
477:51 - now
477:52 - what what we do in clustering what we do
477:55 - in clustering we initialize centroid
477:58 - which is k okay we initialize centroid
478:02 - which is denoted by k so here what it is
478:05 - a hyperparameter so what we are going to
478:07 - do we are going to initialize k we are
478:10 - going to initialize k as uh we are going
478:13 - to initialize k which is two uh two
478:16 - centroids and centroids is just uh the
478:20 - the initial you will get to know up with
478:22 - the visualization so what you do you
478:25 - initialize with two points onto this so
478:28 - here you initialize two points like this
478:30 - the the first point is over here the
478:32 - first point is over here and the second
478:35 - point is over here and these are called
478:37 - the centroids
478:39 - you will get to know why we call it as a
478:41 - centroids but these are called the
478:43 - centroids okay these are called the
478:45 - centroids and here in this example k is
478:48 - equals to two because we have taken k
478:50 - equals to two because uh as we have a
478:52 - two centroids and and we randomly
478:55 - initialize these centroids okay so we'll
478:58 - see the initialization uh just after
479:00 - some ppts this has some slides okay so
479:03 - you initialize your model now and now
479:06 - this is the first iteration now in the
479:08 - first and first you initialize then what
479:11 - you do you do the assignment step what
479:14 - do i mean by assignment step first you
479:17 - initialize then what you do you do
479:20 - assignment step like this you assign
479:23 - all the all the particular values red to
479:26 - red color and blue to blue color you can
479:28 - see over here that we have that we have
479:30 - done red to all the red color which are
479:32 - closest to this and centroid and this uh
479:36 - blue we have covered that is all the
479:39 - centers which are closest to that blue
479:40 - okay now what what we will do we will
479:42 - take out the average of these points we
479:45 - will take out the average of these whole
479:47 - blue points and then we will take out
479:49 - the average of this red points and then
479:52 - what and then what we will do we will
479:54 - average it we will average it like this
479:57 - we will average it now after averaging
479:59 - we will make that percent right to at
480:01 - average and then what we will do again
480:03 - we take out the again we do the
480:06 - assignment step like this we just assign
480:08 - we we just update our values which are
480:10 - so closest to this and centroid now you
480:13 - can see that the blue becomes like this
480:15 - now then what and then what we will do
480:17 - we will again move the centroid again we
480:20 - will take take out the average and move
480:22 - the centroid like this we will move the
480:24 - sand centroid and then we will make this
480:27 - uh red red means so those those are
480:29 - closest to
480:30 - blue blue and these are two red okay
480:33 - then again you do then again you do like
480:35 - this as a taking of the average and
480:38 - making the color as blue and red okay
480:41 - now you can see that you were that what
480:43 - you have done you have a very good
480:45 - cluster means you have initialized here
480:48 - and then you taken out the average then
480:50 - you move to that centroid and again you
480:52 - update the updated cluster then again
480:55 - you move that like that okay so we have
480:57 - done like that and i i have just shown
480:59 - you a very good visualizations of this k
481:01 - main so let's see again in a little bit
481:03 - more fundamental way
481:06 - okay so here is our data and then you
481:08 - can see the data is looks like this so
481:11 - here what we had done we had in we had
481:14 - simply initialized two centroids like
481:16 - this and then what we have done we had
481:18 - we had just uh make the
481:20 - make the points which are closer to that
481:23 - blue to blue and red to that red okay
481:26 - now you can see over here then what what
481:28 - we have done we had taken out the
481:29 - average and then we moved our centroid
481:32 - to that average okay and how we take out
481:34 - you do you all know how do we take out
481:36 - the average you you just take out the
481:38 - number of observations and then divide
481:40 - uh or some the num the sum over the
481:42 - observation divided by the frequency
481:43 - over the observation you just do that
481:46 - and then you update and then you again
481:47 - make the whole uh assignment step and
481:49 - then what you do then you again up
481:52 - make take out the average now you again
481:54 - update the points you can see like this
481:57 - and then you again take the average you
481:59 - again make the point says like this okay
482:01 - and after until and unless your
482:04 - centroids are not changing you keep
482:06 - doing this okay so here is informal
482:08 - algorithm
482:10 - here is informal algorithm and you can
482:12 - see over here after seventh iteration it
482:14 - is not changing so we converged we our
482:17 - algorithm is converged okay so this is
482:20 - how whole k-means clustering algorithm
482:22 - works in visualization so let's see uh
482:26 - the algorithm in detail okay so what you
482:29 - do uh first of all here's an algorithm
482:31 - i'm writing just bear with me but just
482:33 - bear with my handwriting so i'm just
482:35 - writing an algorithm so here is my
482:37 - algorithm with the let's write it with a
482:39 - red color so uh let me write here is
482:43 - your
482:44 - algo a rhythm
482:46 - algorithm okay so you do for k centroids
482:50 - k
482:51 - for centroids okay so you you have to
482:54 - choose k okay you have to choose k which
482:57 - is k where is a hyper parameter okay
483:00 - then you repeat this two process then
483:03 - you repeat this two process the first
483:05 - process is cluster assignment
483:08 - cluster assignment you assign all the
483:10 - clusters you assign all the cluster you
483:13 - assign all the cluster and then update
483:15 - take take out the average and then uh
483:17 - take out the clusters time you assign
483:19 - the clusters and then you take out the
483:20 - average and then you make that point so
483:22 - you when then you do the updation of a
483:24 - cluster okay then you up recompute the
483:28 - centroid okay then you recompute the
483:31 - centroid okay then you how you how you
483:34 - recompute the centroid
483:36 - the centroid it simply means you make
483:38 - the and you take out the average and
483:40 - then you assign that cluster okay that
483:43 - cluster to to to the nearest data point
483:45 - okay again you have takeout average
483:48 - until and unless until
483:50 - you do until you do until uh your uh
483:55 - your centroid are not changing your
483:57 - centroid
483:58 - your centroids your centroids are not
484:02 - changing are not changing okay where
484:05 - it's it means that your algorithm is
484:08 - converged now you don't need okay so you
484:10 - repeat these two process like clusters
484:12 - cluster assignment means assign the
484:14 - cluster with blue or red and then you
484:17 - update your centroid and take up by
484:19 - taking out the average and then again
484:21 - doing doing this taking on the average
484:22 - again doing this like that okay so this
484:24 - is the basic algorithm of k-means
484:27 - clustering algorithm and i hope that you
484:29 - understood about k-means so let's under
484:32 - and let's understand a little bit more
484:34 - we is
484:36 - a little bit more further into just a
484:38 - recalculation of k-means k-means
484:41 - clustering is an algorithm also called
484:43 - the lloyd's algorithm then we what what
484:46 - we do so let's go back to our
484:47 - visualizations
484:49 - okay so here is our data and what what
484:51 - we do with into ub randomly we randomly
484:54 - initialize two centroids okay not every
484:57 - case just have taken it is a hyper
484:59 - parameter we have just taken two for
485:01 - this case okay then what you do then you
485:04 - do the second step which is uh which
485:06 - first you do the cluster assignment you
485:08 - do assign all the cluster with the
485:09 - closest with the same points in the end
485:11 - of the cluster then what you do then you
485:14 - just recompute the centroid by taking
485:16 - out the average and moving the centroid
485:18 - okay then you do the cluster assignment
485:20 - then you assign the cluster like this
485:21 - then you again move the centroid okay
485:23 - recompute the centroid then you assign
485:26 - the like like that and then you take out
485:28 - the average and again you uh
485:31 - again you do the same you take out the
485:33 - average and then move your centroid okay
485:35 - now now in the next iterations is not
485:37 - changing now your k-means flush string
485:39 - is converged now you are done okay so
485:43 - here's a good algorithm you will be able
485:45 - to see on the internet the same thing
485:47 - like first you do you choose key how
485:49 - many number of key
485:51 - clusters then you assign the clusters
485:53 - recompute and then until and unless your
485:55 - centroids are not are are are not
485:58 - changing okay so this is whole about
486:00 - k-means clustering algorithm and i
486:02 - really really hope that you understood
486:04 - cayman's clustering algorithm so now
486:07 - let's see some of the evaluation
486:09 - techniques of k means clustering
486:12 - algorithm okay evaluation technique how
486:14 - do we evaluate our k-means clustering
486:17 - algorithm so for an example
486:20 - so for an example here is my example so
486:23 - for a for an example we are given we are
486:26 - given
486:27 - uh no not in foreign example is just a
486:30 - justice time giving you the optimization
486:32 - objective so you are given so you are
486:34 - given
486:35 - x
486:36 - d dimensional space dear dimensional
486:39 - space
486:40 - as well as k and the clusters which are
486:43 - this uh and set i think the dictionary
486:46 - which is not which is in this c1 c2 all
486:50 - the way down to the ck okay we have k
486:53 - clusters okay then what you do you want
486:56 - your uh to optimize c you want to
486:59 - minimize this cost function you want to
487:01 - minimize this cost func function now
487:04 - what you do you take out i equals to 1
487:06 - all the way around to the k we are k
487:09 - where
487:10 - x be the member of c i mean the cluster
487:13 - now you take out the distance
487:15 - of x
487:17 - and c okay you want to minimize this
487:20 - cluster okay so uh just it it will make
487:24 - sense don't worry here we have ci which
487:27 - is equals to the
487:28 - centroid so let's see let's see what do
487:30 - what do i mean with this uh distance
487:33 - between x and c so what we are told that
487:36 - what what we are told like uh we are we
487:39 - are told that we have that that we are
487:41 - given x they dimensional space and we
487:43 - have clusters which is c1
487:45 - c2 all the way down to the ck where we
487:47 - have k clusters now what we have then we
487:50 - have this equation i equals to 1 all the
487:53 - way down to the k we are going to until
487:55 - every clusters where each we are each
487:58 - x where each x is the member of cluster
488:02 - means we are this data point is the
488:04 - member of this cluster okay now you take
488:07 - out the distance between you take out
488:09 - the distance between this data point and
488:11 - this cluster this this cluster okay and
488:15 - this should be this should be minimized
488:18 - your distance should be minimal your
488:21 - distance should be minimal as compared
488:23 - to this your distance should be minimal
488:26 - so that's what it is telling over here
488:28 - okay so i hope that you understood with
488:30 - the help of a visualization okay so ci
488:33 - is the centroid okay cluster centroid
488:36 - okay so how do we take out the distance
488:38 - for taking out the distance we have
488:40 - something called as a euclidean distance
488:43 - euclidean
488:44 - euclidean for taking out the distance we
488:46 - have something called you there are a
488:48 - lot more distances which are already
488:49 - available you can take a look at it in
488:51 - online but it's a very used eupledean
488:54 - distance
488:55 - so what is euclidean distance in
488:57 - euclidean distance we have d
488:59 - uh we have two points p and q okay since
489:02 - we are doing for each and every point i
489:04 - equals to 1 all the way down to the n
489:07 - means number of training training
489:08 - example qi minus pr
489:12 - squared okay and it's taking out the
489:14 - square root of the square root of that
489:16 - okay so this is the this is the
489:18 - euclidean distance that just measures
489:20 - the distance between two points like
489:22 - this and you can see some more about
489:24 - this onto the internet how we derive
489:26 - this equation what is this well who have
489:28 - found it etcetera etcetera etcetera okay
489:31 - and sometimes and this this cost
489:33 - function of k-means clustering is called
489:36 - is called s s e means sum squared error
489:40 - sum squared error and you can also see
489:43 - it is just like the dawn index following
489:44 - the inter and intra cluster here we want
489:47 - to minimize our in
489:49 - our intra cluster over here we want to
489:51 - minimize our intra cluster we want to
489:54 - minimize our
489:55 - intra cluster okay so that's the basic
489:59 - definition that's the whole thing about
490:01 - whole story about a k-means clustering
490:04 - algorithm and i really hope that you
490:05 - understood k-means and then we have
490:07 - talked about evaluation techniques for
490:09 - k-means and
490:11 - that's it for uh k-means and now we will
490:14 - talk about why it matters it's the basic
490:17 - definition of why it matters which the
490:19 - random initialization as we have seen
490:22 - that we initialize our centroids these
490:24 - centroids randomly you can see that we
490:26 - have initialized randomly so why it
490:29 - matters how it can cause the problem it
490:31 - can cause the problem so here we had
490:33 - just we are just choosing you can see
490:35 - over here here here over here here that
490:38 - we have in iteration number one we have
490:40 - three centroids iteration number two we
490:41 - take another average compute then we do
490:43 - the we come we we simply what you're
490:46 - doing we cluster we assign the cluster
490:48 - with the same centroid and then we
490:49 - recompute by taking out the average in
490:51 - the second iteration then in the third
490:53 - iteration then the fourth iteration in
490:54 - the fifth iteration and the sixth
490:56 - situation you can see over here that uh
490:58 - we you can easily see that we have a
491:00 - good cluster over here but you can see
491:03 - in here that you have adjusted it can
491:06 - cause how it can cause problem is
491:08 - iteration number you want you have just
491:10 - randomly initialized now you can see
491:13 - whole story changed whole story changed
491:15 - you can see over here okay so that's the
491:18 - big problem so that's why we do which is
491:20 - very not recommended to to choose it
491:23 - randomly so researchers discussed about
491:25 - it
491:26 - these researchers had talked about it
491:28 - how we can use it how we can make
491:30 - something good so we researchers found
491:33 - that uh k means plus plus something well
491:36 - as k means plus plus algorithm works
491:39 - best works best
491:42 - which is very time which i'm going to
491:44 - tell you okay so kms plus plus algorithm
491:47 - what it does it simply select
491:49 - multiple numbers it simply select
491:52 - multiple numbers as in random we are we
491:54 - are just taking any random but we select
491:56 - multiple numbers and select the smallest
492:00 - error okay so that's that's what the k
492:03 - means plus plus does it selects
492:06 - selects
492:07 - multiple
492:08 - multiple means is just a it's just a
492:11 - multiple a sample from the numbers
492:12 - multiple numbers
492:14 - and checks and checks
492:17 - which number which number minimizes
492:20 - which number minimizes minimizes
492:24 - the sse the sse which is the which
492:27 - minimizes the into intra cluster
492:29 - distance okay so that's the k
492:32 - means plus plus and it is usually used
492:35 - in everywhere okay rather rather than
492:38 - randomly
492:39 - okay so we have talked about uh why why
492:42 - we choose importance why we choose um
492:45 - over uh run why why we choose k means
492:48 - plus plus over i ran randomly because
492:50 - maybe it can happen sometimes okay a
492:53 - very good a very cool god pro if the
492:56 - luck is not with us it can cause a big
492:58 - problem and further okay so how we have
493:01 - to deal with this kind of situations for
493:04 - dealing with these kind of situations we
493:06 - have something called as uh k-means plus
493:10 - plus which will help us today which we
493:12 - just selects the multiple multipliers
493:14 - and selects select the one
493:16 - select the numbers which has a smallest
493:19 - error okay
493:20 - okay so
493:21 - uh let's see uh you may you may think
493:24 - you may think hey ayush hey ayush how do
493:28 - we select how many number of a centroid
493:31 - that we need okay so that's the that's
493:33 - that's that's also the best uh that's
493:36 - that's also the big problem so we have
493:38 - something called as elbow method we have
493:41 - something called as elbow method
493:44 - and what it does we have elbow method
493:46 - like this we have written the k clusters
493:49 - one two three four five six okay now in
493:54 - if you if you have taken k equals to one
493:57 - your error is high
493:58 - to uh if you've taken k equals to two
494:02 - your error is going down
494:03 - like this like an elbow
494:06 - like an elbow okay so here you can see
494:09 - the elbow turns around at three so you
494:12 - select this elbow to select k equals to
494:15 - three okay so this is your loss this is
494:18 - the number of okay and this is your loss
494:19 - which is decreasing sse sse okay so
494:22 - that's why how we use elbow method
494:24 - either you can use grits or cv or random
494:27 - randomized research to student this
494:29 - parameter i think that will not work
494:31 - because
494:32 - we don't have labels but album method
494:35 - works best when you plot it you know
494:36 - when you plot and then see what number
494:38 - of
494:39 - k you need okay so that's it that's
494:42 - that's the following and let's revise so
494:44 - that we are on the same base so what
494:46 - what we do in k-means clustering
494:48 - algorithm we choose number of okay using
494:50 - the elbow method not now just uh just i
494:53 - choose the randomly and then we plot it
494:55 - and then then we choose the k and then
494:57 - what i've done then we repeat a cluster
494:59 - assignment like we assign all the
495:01 - clusters with the same clusters then
495:03 - then we compute the centroid by taking
495:05 - out the average okay then you uh then
495:08 - you keep repeating this antenna and
495:10 - unless your centroids are not changing
495:13 - and then uh the evaluation technique for
495:15 - your k-means or loss function for your
495:17 - k-means is the
495:19 - you want to minimize your intra-cluster
495:21 - by just taking out the distance between
495:23 - two this distance between the
495:26 - the points between points inside the
495:28 - cluster okay and then that's called
495:32 - sum square error and here and you take
495:35 - out the distance using the equilibrium
495:36 - distance that just that just take out
495:38 - the difference between two points by
495:40 - doing the summation over there okay
495:43 - great so uh why how how how we choose
495:46 - the in in how how we choose this cent
495:49 - centroids okay the initializing of the
495:52 - centroids for initializing we have seen
495:54 - seen over here that randomly initialize
495:57 - can cause a very big problem so that's
495:59 - why we have something called as k means
496:01 - plus plus which will help us to select
496:04 - centroids using what it does it select
496:06 - it does for multiple runs and checks
496:09 - where uh and checks the numbers who
496:11 - where uh the sse is a low okay and how
496:15 - we select the number of a key we select
496:17 - the number of okay by using elbow method
496:19 - where it the elbow is where elbow is
496:22 - turning around like in as a hand as a
496:24 - hand if you draw it like this
496:27 - if you draw it like this if i draw a
496:29 - hand
496:30 - over here if you draw it like this
496:33 - okay so your elbow is there so your loss
496:35 - is decreasing with k equals to one is
496:37 - your losses that this this this okay so
496:40 - you choose the elbow k equals to three
496:42 - and it works best
496:44 - okay so we had talked about these things
496:46 - and now it's time for ending up k-means
496:48 - clustering the chapter of k-means
496:50 - clustering which is uh just uh just
496:53 - ending the topic with our favorite what
496:56 - are the some of the limitations of
496:58 - k-means clustering algorithm and what is
497:00 - the first time complexity so the time
497:03 - complexity of k-means clustering
497:04 - algorithm the time complexity the time
497:07 - complexity of k-means clustering
497:09 - algorithm if you don't know about from
497:10 - the if you don't know dsa leave it okay
497:13 - ignore this
497:14 - at the time complexity is order is time
497:18 - complexity the order of
497:20 - n
497:21 - times k and n is the input size k k is
497:24 - the number of clusters i
497:27 - number of iterations d the dimensions
497:30 - okay uh this this is our and this is
497:33 - this this is what the time complexity of
497:35 - that okay so it's depend because the
497:37 - time complexity depends upon your size
497:39 - if you don't know about time complexity
497:41 - i have one something called as dsa
497:43 - mastery course uh soon we're putting
497:46 - putting videos on to that so um first
497:49 - four lectures are based on time
497:52 - complexity you can watch that just go
497:54 - one new where i will just show you where
497:55 - you can go okay
497:57 - uh some some of some of the limitations
497:59 - of k-means clustering algorithm some of
498:01 - the limitations
498:03 - of k-means clustering algorithm is it's
498:06 - it's it's very sensitive to outliers
498:08 - okay so let's assume that you have this
498:11 - that that you have this oops like why uh
498:14 - powerpoint control z does not work i
498:17 - don't know why
498:19 - so uh here we draw an x and y plane and
498:22 - here we have
498:24 - x here we have
498:26 - y and let's assume that we have made it
498:29 - and here we have the outlier here we
498:31 - have it is closest so it will
498:34 - take that outlier in that cluster so we
498:35 - don't want that so it is very prone to
498:38 - outlier means we have we have to detect
498:40 - the outlier and it can be solved using
498:43 - density based uh
498:45 - even i just don't know what is with what
498:48 - what's there so it can be solved
498:50 - outliers problems can be solved using a
498:52 - db scan which you will have a pro
498:54 - problem set to solve okay means you you
498:57 - have to read the wikipedia page uh and
498:59 - write uh go google docs onto the ddb
499:02 - scan what you understood okay and then
499:05 - it's it's it's like different sizes
499:08 - different distances maybe they're
499:09 - causing the problem okay but the main
499:11 - main problem is outlier okay okay says
499:14 - so we have i have given you the thing
499:16 - that db scan hierarchical clustering
499:18 - works on these types of issues okay so
499:21 - that's it for this k-means clustering
499:24 - algorithm and where you can uh record
499:27 - where you can uh find the time
499:29 - complexity videos and it's very very
499:31 - recommend uh just it's a very very very
499:34 - helpful if you subscribe this youtube
499:37 - channel the newer youtube channel which
499:39 - you can find um which way which you can
499:42 - easily is easily find onto the
499:44 - uh youtube just by writing new era where
499:48 - i have 500 true subscribers as of now
499:51 - okay so you can subscribe that and see
499:52 - the dsm mastery course where we have
499:54 - more than 23 videos already uploaded a
499:57 - long lecture so you can learn about time
499:59 - complexity from that also okay so that's
500:02 - it for this sub section you will now
500:04 - have a toolkit of various algorithms
500:06 - various techniques various things okay
500:09 - so now let's meet at the next section
500:11 - where we'll be talking about
500:13 - hierarchical hybridical clustering i
500:15 - will give it a sort so that it should
500:17 - make sense okay so let's meet at the
500:19 - next sub section okay so now we have
500:22 - talked about clustering we have talked
500:24 - about unsupervised learning we have
500:26 - talked about one of the partitional
500:27 - based or center-based approach which is
500:30 - k-means clustering with k means plus
500:32 - plus algorithm for a random
500:34 - initialization okay so i hope that you
500:37 - understood everything in unsupervised
500:39 - learning and if you have gone so much
500:41 - further into untube voice learning now
500:43 - we are capable of learning hierarchical
500:45 - clustering which is one of the most
500:47 - favorite uh means one of the most
500:50 - favorite uh
500:51 - and the best clustering techniques that
500:53 - include including partitional based and
500:56 - then we have a hierarchical clustering
500:58 - okay so this is the this is this this is
501:01 - what we are going to do we are going to
501:02 - start with an introduction to a
501:04 - hierarchical clustering to help you
501:06 - better understand what a hierarchical
501:08 - clustering is then i will go further
501:10 - into different um just just a quick
501:12 - recap onto partitional based okay then i
501:15 - will show you the visual representation
501:18 - of hierarchical clustering and what's
501:20 - the dendogram okay and then we will move
501:23 - further into understanding the two two
501:26 - types of hierarchical clustering which
501:28 - is called agglomerative and divisive
501:31 - okay
501:32 - so agglomerative clustering and
501:34 - diversive clustering we will dig dive
501:36 - into augmentative clustering and we will
501:39 - just to take a look at the diversif okay
501:41 - and then we will go further into
501:43 - understanding the augmentative
501:45 - clustering algorithm and then we will
501:47 - see uh then we'll compute that algorithm
501:50 - manually and then we will see the inter
501:52 - cluster similarity between our two
501:54 - points okay but if
501:56 - if if all the words or technical terms
501:59 - are going above your mind leave it means
502:01 - uh
502:02 - just ignore it the words as of now let's
502:05 - start
502:06 - with hierarchical clustering just
502:08 - introduction to hierarchical clustering
502:11 - okay so what is hierarchical clustering
502:15 - hierarchical clustering is that you have
502:17 - a hierarchy of clusters okay so for an
502:21 - example what i'm going to do what i'm
502:23 - going to do is i'm going to take four
502:25 - points i'm going to take four points p1
502:28 - uh let's let's not take it here let's
502:30 - take p1 here p1
502:33 - then i'm going to take p2
502:36 - then i'm going to take p3
502:38 - then i'm going to take p4 okay
502:41 - for an example i've taken these four
502:43 - points and now we want to cluster it out
502:46 - okay now we want to cluster it out so
502:48 - how do we cluster it so for clustering
502:51 - so for clustering we have our favorite
502:53 - means we can simply see okay this
502:55 - distance is small these are more similar
502:58 - we are going to do this we are going to
503:00 - cluster it out like this
503:04 - and we have this uh p3 and p4 how do we
503:07 - cluster we cluster this p p one and p
503:10 - two as real so we cluster we we put
503:13 - another cluster okay because this
503:17 - this cluster p1 and p2 is p1 union p2 it
503:21 - is now a one cluster now
503:24 - in
503:24 - nearest the data point nearest point
503:26 - between or the nearest
503:28 - these these are their own clusters
503:30 - initially these are their own clusters
503:32 - so we are going to merge it okay
503:36 - so here we have a p1 and p2 now the now
503:39 - that this is
503:40 - smallest distance is p4 now we attach
503:43 - means now we make one more cluster okay
503:46 - now in this big cluster in this cluster
503:48 - where we have three points what is the
503:50 - nearest data point now the nearest state
503:52 - data point is p3 okay so we'll make
503:55 - again one cluster again one big cluster
503:58 - like this until and unless we have one
504:01 - cluster at uh one one one cluster uh at
504:05 - a point okay so here we we are ended up
504:08 - with one cluster okay so it is not
504:10 - making sense i know but we can um just
504:13 - just as a diagram i have made this so
504:15 - let's see how how we do it
504:17 - using a dendogram that that will make
504:20 - more sense okay so here we have a p1
504:23 - here we have a p2 oh oops let me make a
504:26 - little bit more in good
504:29 - oops what happens
504:31 - okay so here we have a p1 let's assume
504:33 - that we have this is the point p1 this
504:35 - is a point p2
504:37 - this is the point p2 and this is the
504:40 - point p3 and this is the point p4 okay
504:43 - now these are the points now what we
504:45 - will do with here you can see we just
504:48 - assume that just assume that this is p1
504:50 - p2 p3 and p4 and you can see this p p1
504:54 - and p2 are smallest so we can make uh we
504:58 - can attach this we can make a
505:00 - we can make like this you can attach
505:03 - this p2 and p3 okay now these are one
505:06 - plus or p2 and p3 are one cluster which
505:09 - usually cause p2 union p3 okay now
505:13 - initially p1 is one cluster c1 p2 is one
505:17 - cluster c2 p3 c3 and p4 c4 okay so these
505:22 - are initial clusters now what now what
505:24 - we'll do now this is the one cluster
505:26 - which is c2 okay so we've we we
505:30 - found and
505:31 - attached it okay now what now what we
505:33 - will do now the nearest state data point
505:35 - is p4 over here
505:38 - okay so what what we will do we'll again
505:40 - attach p4 into this
505:42 - we'll again attach p4 now we have now we
505:46 - have p3 and p4 as one cluster over here
505:48 - okay now we are now we can attach p1
505:52 - now we can attach p1
505:54 - now now we can attach p1 like this
505:58 - now we can attach p1 and now we have our
506:01 - dendrogram which is actually a hierarchy
506:03 - of clusters okay so here we have a
506:05 - traditional
506:07 - dendrogram which uh
506:09 - which which i think that you have all
506:10 - i've seen in your journey so this is
506:12 - your hub this is your dendrogram what
506:14 - you have done you have just who are most
506:16 - similar you are attached to it okay who
506:19 - are more similar you attached it for an
506:21 - example
506:22 - these are two similar you attached it
506:24 - and then these this is now what you
506:26 - attach it like this okay do not merge it
506:28 - do not merge it okay so you have to do
506:31 - like this now here we have until unless
506:34 - we have left with one cluster
506:36 - okay so that's the basic uh hierarchical
506:39 - clustering and i hope that you
506:40 - understood hierarchical clustering the
506:42 - basic intuition but if not let's let's
506:44 - try to again understand a little bit
506:46 - more further into a more sophisticated
506:49 - way okay not supposed to just just uh
506:51 - easy way okay so for the example i'm
506:54 - gonna take a yellow color so here you
506:56 - have a c1 here you have a c2 here you
506:59 - have a c3 here you have a c4
507:02 - okay so this uh this is your c4 now you
507:06 - can this
507:07 - c2 and c3 are your points c2 and c3 are
507:11 - your points okay so these are two more
507:14 - similar so you will attach this like
507:16 - this now c4 here he is here so will you
507:18 - make you so you will make one one more
507:21 - now pc3 and c4 will be attached like
507:23 - this and c1 will be attached onto the up
507:26 - of c4 now this is a traditional
507:28 - dendrogram this is transferred
507:30 - traditional then dendrogram where you
507:32 - convert this cluster of numbers where
507:35 - you convert cluster of numbers
507:37 - c1 these the clusters clusters to a
507:39 - hierarchy of clusters okay so for an
507:42 - intuition what what what i'm trying to
507:45 - see you here so i have one example
507:48 - so for intuition what i'm trying to say
507:50 - you hear that we have a
507:52 - c1 c2 c3 c4 now we're just uh making a
507:56 - attaching as a cluster so c2 union c3
507:58 - etc
507:59 - okay so this is the basic intuition
508:00 - behind hierarchical clustering so there
508:03 - are two types of hierarchical clustering
508:05 - uh some of the types are we have some
508:08 - something called as agglomerative
508:11 - agglomerative clustering and then we
508:14 - have
508:15 - and then we have divisive clustering and
508:18 - then we have diversif clustering okay so
508:22 - we will deep to have an agglomerative
508:24 - clustering i'll just give you an
508:25 - intuition behind
508:26 - diversif clustering okay so what is
508:29 - agglomerative clustering so the
508:31 - agglomerative clustering
508:33 - aglo
508:35 - agglomerative clustering okay so before
508:38 - that let's understand let's uh let's see
508:41 - let's uh let's let's unders understand
508:43 - the divisive clustering to help you
508:45 - better understand that so it is down to
508:48 - it is up to down approach sorry it's a
508:50 - down to up approach it's an
508:52 - agglomerative is a down to up approach
508:56 - and diversif is just opposite it's just
508:59 - a positive
509:00 - diversif diversif
509:03 - is just
509:04 - up to down approach
509:07 - up to down approach so what do i mean by
509:09 - this so for an example
509:11 - for an example let's assume that we have
509:14 - a four points we have a five points
509:17 - in the form of data a
509:19 - b
509:20 - c
509:21 - d and e okay so here what to what you
509:24 - are going to do we are going to divide
509:26 - this cluster of numbers the cluster of
509:28 - numbers into a different different
509:31 - uh a b let's assume that you are divided
509:33 - with a b now this is your c d e c d e
509:37 - c d
509:38 - e as a more similar okay you divided
509:41 - this now what you will do you will
509:42 - devise this a and b a
509:46 - and b now you will divide this
509:48 - c
509:49 - c
509:50 - and
509:51 - d d e okay
509:53 - now you will take the d
509:56 - and e
509:57 - okay so this is the basic uh this what
509:59 - what you are doing you are making the
510:01 - cluster of numbers into separate
510:03 - separate numbers you are making the
510:04 - hierarchy of numbers okay hierarchy of
510:08 - numbers
510:09 - and this is what you are doing okay so
510:11 - you're just uh making a di um hierarchy
510:14 - of numbers and like abcdes you're going
510:17 - to up to down approach from up to down
510:20 - approach but in the case but in the case
510:23 - of but in the case of agglomerative you
510:26 - are doing something different you are
510:28 - here you are going up to down up to down
510:31 - in agglomerative you will take you will
510:34 - take because in agglomerative you have
510:36 - cluster one c2 they are unique clusters
510:38 - means only one cluster so you do merge
510:41 - it okay you do merge it okay so it is
510:44 - agglomerative is up to down approach
510:48 - sorry down to approach down
510:50 - to up
510:51 - okay so that's the basic intuition
510:53 - behind agglomerative and diversif
510:56 - clustering okay so we'll see in detail
510:58 - about agglomerative clustering and
511:00 - diversified clustering to help you
511:01 - better understand all of these algo ah
511:04 - agglomerative and diversif but the basic
511:06 - intuition behind
511:08 - hierarchical of clustering hierarchy of
511:10 - clustering is that you have at some
511:13 - points and what you do you simply you
511:15 - simply
511:16 - you simply merge to cluster because
511:19 - these p1 p2 p3 are before r4 cluster
511:22 - initially you merge through cluster and
511:24 - then you have some kind of similarity
511:26 - matrix okay so you have some some kind
511:28 - of similarity matrix that we will see
511:30 - according to that you merge it and then
511:32 - you make a dendogram or hierarchy of
511:35 - clusters okay so that's the that's
511:37 - that's what agglomerative and
511:39 - acclimative is just down to approach
511:41 - where you are converting the converting
511:43 - the clusters into by merging different
511:46 - different cluster antennas we have one
511:47 - cluster left at the top like this c1
511:50 - okay as an example and in diversif you
511:52 - are actually going
511:54 - up to down approachment dividing the
511:55 - cluster into a single single group okay
511:59 - like a b c d e okay so that's the basic
512:02 - intuition behind this uh agglomerative
512:04 - and diversif clustering
512:07 - okay so let's start with agglomerative
512:10 - clustering deep dive into agglomerative
512:12 - clustering to help you better understand
512:14 - what an algorithm
512:16 - algo agglomerative
512:19 - agglomerative clustering does and we
512:21 - will see a lot more about this okay we
512:24 - will not see the implementation as of
512:26 - now we will see in another section where
512:28 - we now we are now after this i think we
512:30 - are we have we have completed this
512:32 - theory part all those thoughts means we
512:34 - have now have a good knowledge of
512:36 - everything now what what we will do we
512:37 - will make a lots of projects okay
512:40 - so here's an algorithm so first here if
512:43 - you're so first uh let me let me write
512:46 - an algorithm
512:47 - first i will write an algorithm and then
512:49 - i'll then i will make you understand
512:50 - with the help of good examples that i've
512:52 - already listed over here okay okay so
512:55 - here first what what we will do first
512:58 - you we compute the proximity matrix we
513:00 - compute
513:01 - the proximity matrix proxy
513:05 - midi matrix that just tells you the
513:07 - similarity between two points
513:09 - second we will we will see we will see
513:12 - we will see just as now it looks like
513:14 - and then you repeat these two process
513:16 - then then you repeat this two process
513:19 - then you repeat this two process merge
513:22 - merge
513:24 - two clusters
513:25 - merge two clusters
513:27 - and update the cluster update the matrix
513:30 - update the proximity matrix
513:33 - proxy
513:34 - midi matrix okay so that's the basic
513:38 - that's the that you repeat in a for loop
513:40 - and then you until and unless until
513:44 - you have one cluster you have one large
513:46 - cluster left means until you have left
513:48 - you have covered all the cluster okay
513:50 - until you have covered all the cluster
513:52 - okay
513:54 - covered
513:55 - all the cluster or we can say no
513:57 - clusters are left as a single cluster
513:59 - okay but this is this is a more formal
514:01 - definition until you have a good cluster
514:03 - like as as an example that i've showed
514:05 - to you okay so this is a basic algorithm
514:08 - to understand in agglomerative
514:10 - clustering
514:11 - now let's understand this in more detail
514:14 - okay so initially what i've talked about
514:16 - but i've note here what i'm going to
514:18 - note here like i'm going to write note
514:21 - which is each
514:23 - each cluster or p1 p2 p3 each are its
514:27 - own cluster now we'll be able to build a
514:29 - hierarchy of clusters okay so let's uh
514:32 - let's build uh let's build an
514:34 - approximating matrix how it looks like
514:36 - so the approximating matrix looks like
514:38 - this let's iron let's assume that you
514:40 - have
514:41 - p1 p2
514:43 - p3
514:45 - p4 okay i'll just assume as an example
514:48 - now what you do you
514:50 - you do this
514:52 - p1 p2
514:54 - p3 p4 okay
514:57 - now you do this means this is
514:59 - approximately matrix this is the
515:00 - approximate matrix like this
515:05 - okay okay and these diagonals are zero
515:08 - these diagonals are zero these diagonal
515:10 - the diagonals are zero because the
515:12 - distance between the distance between
515:14 - the p1 and p2 will be obviously zero the
515:17 - distance between p1 and p2 maybe some
515:19 - group 2.4 there is p3 p4 like that so we
515:22 - have we have written like that p the
515:24 - distance between p1 p2 and p1 is maybe
515:27 - something like that diagonal distance
515:28 - between p2 and p2 is obviously zero okay
515:31 - so this this is what the basic uh this
515:33 - is what the basic proximity matrix looks
515:35 - like so let's see let's see
515:38 - that how we how we make a dendrogram
515:41 - okay so here we have p1 p2 p3 p4 now
515:46 - assume now we will just assume that uh
515:49 - let's take an example that this uh this
515:51 - is 4.6 to 4.2 6.9
515:55 - point two eleven twelve thirteen
515:58 - fourteen fifteen
516:00 - sixteen seventeen eighteen okay it's a
516:02 - zero okay so the distance between p p
516:04 - four is p four is obviously zero okay so
516:07 - the p2 we we will find the smallest one
516:10 - we will find the smallest
516:12 - similarity here you can see that this
516:14 - this is the smallest similarity p2 and i
516:17 - think uh
516:18 - oops it's a it's a p2 and also i think
516:22 - that i've not drawn a good mirror i i
516:24 - will tell you so here let's let's assume
516:26 - that you have this proximity matrix that
516:28 - you have this proximally matrix just
516:30 - just don't take a take a look at this
516:32 - proximity matrix now what you will do
516:34 - you will find the smallest similarity so
516:37 - the smallest similarity so the smallest
516:39 - similarity over here is
516:41 - this three here we have three and six
516:45 - okay so here we have three and six that
516:47 - we have done first the smallest
516:49 - similarity okay so that's the that's
516:51 - that's what we i'm going to do so assume
516:54 - that this is p1 and p2 has a smallest
516:57 - now we have now what what now the next
516:59 - is the next you can find over here is
517:01 - four means six and four maybe let's see
517:05 - six
517:06 - and four which is here okay so we can go
517:10 - over here also three and four we can see
517:13 - this three and four also okay so we can
517:16 - take this three and four like this it's
517:18 - okay so just assume the next smallest is
517:20 - p3 and the next volts is p4 okay so now
517:23 - we have constructed now let's assume c2
517:26 - p1
517:28 - p p2 p1 then we have a again maybe some
517:31 - p3 and p4 now first you do this then you
517:34 - do this then you make this like this
517:37 - okay so now we have now now you have the
517:38 - hierarchy of clusters okay so that's the
517:42 - basic definition that's the basic
517:44 - algorithm for proximity matrix okay
517:47 - and this is what you do and you update
517:49 - the proximity matrix so how you update
517:51 - now you merge the merged the cluster now
517:54 - what you will do p1 union p2 okay p1
517:58 - union p2 this one will be let's assume
518:00 - p1 and p2 are attached then p1 union p2
518:04 - this will be the cluster okay
518:06 - now let's assume that the 2.7 and these
518:09 - are
518:10 - this are similar means this 2.2.7 and
518:13 - maybe some maybe like that so we can
518:16 - combine the cluster like that i think
518:17 - this is not an actual example the bad
518:20 - example okay but here uh you can you
518:22 - will you will be seeing one of more one
518:24 - more comprehensive example okay so how
518:28 - do we
518:29 - measure the similarity how do we measure
518:32 - the similarity of the inter cluster
518:34 - similarity we can measure the distance
518:36 - between two plus two points or clusters
518:38 - these p1 and p2
518:40 - using maybe euclidean distance euclidean
518:44 - distance
518:45 - manhattan distance we have different
518:46 - different distance similar distance uh
518:49 - distance measures so how do we measure
518:51 - the the similarity between two clusters
518:54 - or enter cluster and inter cluster is
518:56 - nothing much that that similar the this
518:59 - is your one cluster and this is another
519:01 - cluster so what's the distance what the
519:03 - similarity between to merge it okay so
519:06 - that's the that's the inter cluster that
519:08 - we have already talked about in
519:09 - terminology sessions so let's see so we
519:12 - have so we have let's uh let's let's
519:14 - assume that you have this let's assume
519:16 - that you have this cluster where we have
519:18 - x this this this this this let's see
519:21 - another cluster
519:23 - this this so how do we measure the
519:25 - similarity how do we measure the
519:27 - similarity so for measuring the
519:29 - similarity we have i'm going to talk
519:32 - about three methods i'm going to talk
519:34 - about three methods min
519:37 - and the next method and max the next
519:40 - method is group average
519:43 - the next method is grouped average so
519:46 - let's start with min so what do i'm
519:48 - doing in min so let's assume that you
519:50 - have this uh so so you have this data
519:52 - point like this we have this cluster
519:56 - you have this cluster now the second
519:58 - cluster is like this
520:00 - second cluster is like this okay so what
520:03 - you do in minimum what you do in minimum
520:06 - you take out the minimum
520:08 - first to first i'm just just right
520:11 - let me write it mathematically to make
520:12 - it more sense oops what i've done
520:15 - okay so what you what you have to do
520:17 - what you have to do
520:18 - so let's let let me write it
520:20 - mathematically for minimum so minimum
520:24 - is is just the similarity between
520:27 - c1 and c2 which is nothing but equals to
520:31 - nothing but equals to
520:33 - minimum minimum of p i
520:36 - is
520:37 - member member of c one p i to be the
520:41 - member of c one let's assume this is c
520:43 - one so p i may be this point and p j the
520:46 - another cluster should be the member of
520:48 - c two now what you will do you will take
520:51 - out the similarity this the similarity
520:55 - of pi and pg okay these two
520:59 - okay these two distance okay now you
521:02 - take out the distance that you do you
521:04 - take out the distance i'm writing your
521:05 - distance and you you take out the
521:08 - minimum point minimum points who have
521:10 - mental here you with this the distance
521:12 - between these two points is minimum as
521:15 - compared to this point this point this
521:17 - point okay so we will uh just uh
521:21 - what what we will do we will simply uh
521:23 - merge it okay so this is what the basic
521:26 - minimum minimum approach does it just
521:29 - takes out the similarity between c1 and
521:32 - c2 by the taking out a minimum of all
521:35 - the
521:36 - i and js by taking on the distance
521:38 - between all the minimum taking out the
521:39 - minimum distance of all i and js with
521:42 - the member of c1 and c2 okay so that's
521:46 - the that's the minimum so let's see the
521:48 - basic uh basic thing over here
521:51 - to understand it little bit further away
521:53 - and this is this this example is taken
521:55 - from cs6530
521:57 - by cluster analysis class lecture notes
521:59 - this this example okay
522:02 - so here
522:03 - here is your proximity matrix here is
522:05 - your proximity matrix where you have one
522:08 - as a p1 2 as a p2 like that okay now you
522:11 - have the here you have approximately
522:12 - matrix here you have a
522:14 - proximity matrix now here the distance
522:17 - between one and one is zero the distance
522:19 - between one and two is the 0.24 the
522:22 - distance between one and three and small
522:23 - point two two two the distance between
522:25 - one and four is point height 0.37 the
522:28 - distance between 1 and 5 is like this
522:30 - and this in the same way diagonal are 0
522:32 - okay so you can see here the smallest
522:35 - similarity between or smallest distance
522:39 - between two points i and j here we are
522:41 - let's assume this is i and this is j the
522:43 - smallest distance is point eleven point
522:47 - eleven and we have three
522:49 - and six
522:51 - okay so we merge three and six as a
522:53 - first cluster okay
522:55 - now the next now the next
522:58 - smallest similarity
523:00 - or the smallest distance is
523:02 - is uh
523:04 - this one uh let let me choose yeah this
523:07 - this one point 14 okay so five and two
523:10 - okay so this is your next smallest so
523:13 - now what you will do you will merge it
523:14 - at the second cluster now what you will
523:17 - do you will find that this two cluster
523:19 - this the cluster u and this this p
523:23 - five five union two
523:26 - and
523:27 - uh and three union six finds to be uh
523:31 - um
523:32 - has a smallest distance so you merge
523:34 - with a cluster three
523:36 - next is you have one you have one and
523:39 - four now what what you do you this first
523:42 - you take out the just you just you can
523:44 - see first you take a first here we have
523:46 - full
523:47 - in which this union union and this full
523:51 - and this four has the smallest distance
523:53 - so you merge it and then you make a big
523:55 - cluster again and then you are done okay
523:57 - so it might make sense it might not make
523:59 - sense further but i will walk you
524:01 - through go through this example make the
524:04 - dendrogram by yourself or necessary
524:06 - clusters by yourself okay that will make
524:09 - more sense
524:11 - the next type of this is max what do i
524:14 - mean by with max
524:15 - max is simply
524:17 - max
524:18 - it's taking out the similarity
524:21 - between c1 and c2 which starts with the
524:24 - maximum which we which we want the
524:26 - maximum distance
524:28 - maximum distance between pi and pj and
524:32 - pi be the member of c one and p j p j be
524:36 - the member of c
524:38 - two so that's the that's the basic
524:40 - definition uh that's the basic of uh
524:43 - this ends here we are taking the max so
524:46 - what do i mean by max so here we have an
524:48 - uh intuitive or a comprehensive example
524:51 - so here you can see that we have again
524:53 - the same proximity matrix now you can
524:55 - see
524:56 - that the smallest distance is three six
524:59 - okay you merge it now how you will merge
525:02 - this four however why why don't don't we
525:04 - merge with five okay so the distance
525:07 - between the distance between this five
525:10 - and two is at maximum it's very large so
525:12 - obvious this this one obviously will be
525:14 - minimum so your merger that that's
525:16 - that's makes sense that's makes sense
525:18 - obviously okay so this this is what why
525:20 - you're you you take minimum distance but
525:23 - for merging you take the maximum you
525:26 - take out the maximum to merge and here
525:28 - you have taken the maximum and that's
525:30 - how and that's how
525:34 - and that's how all it works and here we
525:36 - have a maximum here we have a minimum so
525:37 - you take out a maximum and then you uh
525:39 - compare and then you take on the minimum
525:41 - and this is obviously the minimum and
525:43 - then you and you can see this is the
525:45 - maximum here and this is the minimum
525:47 - from here so you merge it okay so this
525:50 - is the basic and you can see the
525:51 - dendrogram over here how we made okay
525:54 - the next type of um
525:56 - inter cluster similarity measure the
525:58 - next type of inter cluster similarity
526:00 - measure is group average what do i mean
526:03 - by group average
526:04 - group average so i'm just going to give
526:06 - you the intuitive uh just um
526:09 - as a simple equation which is
526:12 - p i with a member of c 1 and p j where
526:16 - the member of c 2 p i be the member of c
526:19 - 1 and p j with a member of c 2 you take
526:22 - out the distance between p i and p j
526:25 - divided divided by the norm because the
526:28 - freak frequency divided by the norm of c
526:31 - one with whatever the number of points
526:32 - times the i think times the norm of c2
526:37 - okay
526:39 - so this is what you have to do i think
526:40 - it's
526:41 - it may be plus yeah it may be plus yeah
526:44 - okay so you take out the norm of what is
526:45 - the number of points freak frequency
526:47 - okay so that's what you are going to do
526:49 - so you can see over here that we have
526:50 - this dendrogram we have this following
526:52 - and then what you do you take you group
526:54 - you group it look for for example you
526:57 - can see the same thing has been done but
526:58 - i'm going to take another example to
527:00 - help you understand this much better
527:02 - to help you understand this much better
527:04 - so you have this first
527:07 - and then you have this
527:08 - second cluster okay now you have some
527:11 - points you have some points in here you
527:13 - have some points in here and some points
527:15 - in here okay
527:18 - you take each pair you take each pair
527:21 - each pair like this you take each pair
527:25 - okay
527:26 - okay then you average it out okay and
527:28 - then you take out the distance you
527:30 - average it and then here you go okay so
527:32 - for example here you take out the
527:34 - minimum distance is three and six and
527:36 - then you have this four uh then again
527:38 - you merge it using the and that's what
527:40 - what we what we were doing but here we
527:42 - are merging one also the reason being
527:44 - the average between will it will be
527:46 - making sense if you sense it
527:47 - mathematically okay and five and two are
527:50 - closest okay
527:52 - so this is what you are doing in group
527:54 - men and let's see some of the uh some
527:57 - just this minimum this uh
527:59 - disadvantage the minimum disadvantage is
528:01 - it it simply
528:03 - it is it is sensitive to outliers it is
528:06 - sensitive to outliers and bad wrath
528:08 - rather than max is uh will will be less
528:11 - prone to outliers okay
528:13 - so that's the basic uh
528:16 - disadvantage that i've told you and you
528:18 - can see more onto the cs645 530 cluster
528:22 - analysis lecture notes to understand it
528:24 - much better okay
528:26 - so this is what we are doing and if you
528:28 - have not understood it is little bit
528:29 - advanced but it it should make sense
528:31 - little bit what what we do what we do
528:34 - and this we have make hierarchy of
528:35 - clusters like this okay so now we have
528:38 - talked a lot about hierarchical
528:40 - clustering and i hope that you really
528:42 - understood everything you need to know
528:44 - about hierarchical clustering now what i
528:46 - will do i will just name some uh now now
528:49 - what i will do i will name our time
528:51 - complexity i will and the space
528:53 - complexity now i'll name one time
528:54 - complexity and space complexity for
528:57 - agglomerative clustering just to make
528:59 - just to make sure everyone is on the
529:00 - same pace so the space complexity the
529:04 - space complexity
529:06 - is order of n square okay because we
529:09 - have approximate matrix too and time
529:12 - complexity will be order or maybe
529:15 - sometimes it's uh order of n q okay but
529:18 - some sometimes it goes to order of n
529:20 - square
529:21 - log
529:23 - of n
529:25 - okay so this this is your this is your
529:26 - space and time complexity to understand
529:28 - it much better and you can see the
529:30 - limitations pros cons of these onto the
529:34 - wikipedia pages they are very well
529:36 - explained there
529:37 - okay so we have we are done with
529:40 - hierarchical clustering and i really
529:41 - really hope that you understood
529:43 - everything now we are done with
529:44 - unsupervised learning now uh we will we
529:47 - will do a lot of projects and then we
529:49 - will end up this course and i highly
529:50 - highly recommend you to do lots of uh
529:54 - projects also okay and then after
529:56 - learning this machine learning you can
529:57 - get go to new era again i'm going to uh
530:00 - just to now navigate here the url https
530:05 - uh you can slash
530:08 - youtube.comera okay so you can find then
530:11 - uh just just take take take a look at a
530:13 - newly launched deep learning series okay
530:16 - from there you can learn uh advanced
530:18 - machine learning or uh
530:20 - or deep learning okay
530:22 - so that's it for this session i'll be uh
530:25 - so that's it for all this subsection
530:27 - i'll be catching up your next section
530:29 - okay so now we will build or start our
530:32 - last section of this course which is uh
530:36 - project section and in this section we
530:38 - will build two projects maybe some more
530:40 - project but uh initially i plan for two
530:42 - projects maybe i can add more but you
530:44 - can surely go to
530:46 - uh my youtube channel for more projects
530:49 - buzz but these projects will tell you an
530:51 - overview of how a machine learning
530:53 - project would look like and the
530:56 - motivation for starting you a new
530:58 - project because it's better to make your
531:01 - project by yourself just taking the
531:03 - inspiration from other people okay so in
531:06 - this project we will build a heart
531:08 - failure prediction uh
531:10 - model that will predict whether the
531:13 - person whether the person will die based
531:15 - on some of the features or not okay so
531:19 - this is the problem statement and we
531:21 - have certain features like age gender
531:24 - blood pressure smoke whether a person is
531:27 - smoked or not whether a person have
531:28 - diabetes or not what is injection
531:30 - fraction what is the
531:33 - that's what this is long name which i
531:35 - can't
531:36 - pronounce but the this is the this is a
531:39 - problem statement and you can take a
531:41 - look at the data uh we're going to take
531:43 - a look at the data which is available at
531:45 - this link and i hope that you will uh
531:47 - understand this project i i have made
531:50 - i've run step by step to help you
531:52 - understand everything and as i am made
531:54 - just i have not worked on this project
531:56 - so i just want to pick up this heart
531:58 - failure detection system just to make
532:00 - sure that i will be making my own
532:02 - project also and it will be uh and
532:04 - narrating over through this project okay
532:06 - so here uh what i'm going to do is what
532:09 - i'm going to do is i'm going to make a
532:12 - heart failure detection based on these
532:15 - features and the target variable of our
532:19 - which is that that event whether the
532:21 - particular person died or not so that's
532:24 - it with the target variable we will see
532:26 - more about the data but what is the
532:27 - business objective over here every
532:29 - machinery problem has some kind of
532:31 - business objective it simply means
532:34 - that it's some health care problem means
532:37 - we'll be able to build a health care we
532:40 - will be able to build a healthcare in
532:42 - healthcare something ai and healthcare
532:44 - which is simply able to make a machine
532:47 - learning model that will help you in
532:50 - early detection of the person based on
532:52 - particular
532:54 - features and help the person can be
532:57 - saved so that's why we are going to
532:58 - build that model to help you better
533:00 - understand the ai in healthcare we'll be
533:03 - building one more project which is spam
533:05 - detection system that is uh whether the
533:08 - email or messages are spam or not okay
533:11 - so let's start with this uh notebook and
533:14 - uh first of all i've divided first of
533:16 - all i'm going to load the data and sorry
533:20 - sorry import the libraries so i'm going
533:22 - to import pandas numpy seaborn
533:25 - matplotlib and this okay so i will run
533:29 - it down i will run it out and then i
533:32 - will load my data
533:34 - so i don't know why the second time so
533:35 - now i will load the data and my data
533:37 - isn't located in the folder of heart
533:40 - failure data set if you click on data
533:43 - set click on archive and here is my data
533:45 - set okay so there i'm going to do i'm
533:47 - going to just print out head and i want
533:49 - one more thing that i want to clarify
533:51 - over here the reason why i'm not writing
533:53 - or quoting by it here because i i
533:55 - thought like uh it will be better if i
533:57 - narrate the code if i if if i'm writing
534:00 - the code maybe i i forget something or
534:02 - maybe the code is not annotated too much
534:05 - so that's a for a few further references
534:07 - i just took to just write it down over
534:10 - here and then i'm only going to just add
534:11 - it over there okay most of them because
534:14 - because maybe while writing the code i
534:16 - may forget to narrate some of the code
534:19 - but yeah let let me know what you like
534:21 - whether i should write a code or not
534:24 - okay so i'm going to print it out the
534:26 - shape of the data i'm going to do the
534:27 - shape of the data is
534:29 - 29913 which is 13 columns and here we
534:33 - have
534:34 - h anemia cretinite false fokiness
534:39 - diabetes injection fraction hp then
534:42 - battle it serum then what is the gender
534:45 - smoking time and that even okay and that
534:49 - event is our target variable that we
534:51 - need to detect okay so that's our basic
534:55 - intuition that's our basic uh data
534:58 - exploration now what i'm going to do is
535:00 - we will see how much the data we have
535:02 - means we will see what's the shape of
535:05 - the data we have so here we are we are
535:08 - given the shape of the data which is 299
535:11 - rows and 13 columns okay
535:14 - now using a day data dot shape you can
535:17 - do now i'm going to take a look at the
535:18 - information about the data you can
535:21 - calculate or you can take out the
535:22 - information about the data from the data
535:25 - the info method and you can if you see
535:27 - or we hope that it will tell you whether
535:29 - the particular column has no values what
535:31 - is the data type and what is the memory
535:34 - usage and it will also tell you what's
535:37 - the shape of the data by just taking you
535:39 - can also take a look at this and you can
535:40 - see that it starts with zero indexing so
535:43 - we have 13 columns you can also take a
535:46 - look at the description it will simply
535:48 - tell you whoever is the numerical column
535:50 - uh it it will tell you the describing
535:53 - means what is the count what is the mean
535:55 - of the particular column what is the
535:56 - standard deviation what is the minimum
535:58 - what is a 25 of that column and 50
536:01 - percent of that column and 75 percent of
536:03 - that column and max and that column it
536:06 - will surely help in the photo means when
536:09 - if you're a data scientist it will
536:11 - surely help uh maybe something kind of
536:14 - uh you are exploring what's the maximum
536:16 - you can take a look at this you can take
536:18 - a look at what is the standard deviation
536:19 - what does it mean maybe you're
536:21 - formulating some
536:23 - problem based on machine learning so
536:24 - it's very helpful this this data frame
536:27 - you can you can have it spend five
536:29 - minutes understanding what was this and
536:31 - it's very easy it will tell you the
536:33 - count minimum standard deviation etc
536:35 - okay so what we have seen so far we have
536:38 - loaded we have imported the libraries we
536:40 - have loaded the data from my local
536:42 - directory i'm going to take a look at
536:44 - the shape of the data and i'm going to
536:46 - take and i'm going to take a look at
536:47 - information about the data
536:50 - okay so here i'm going to data dot info
536:53 - and that will give me the information
536:56 - about the data okay then i'm going to
536:58 - take a look at the description that's
537:01 - what is the uh well that it will
537:03 - describe our numerical data and then i'm
537:06 - going to take a look at what is the
537:07 - number of unknown values so here uh this
537:11 - will tell you this this will tell you in
537:13 - all the columns how many number of null
537:15 - values are and here we have zero zero
537:18 - zero no values in each and every column
537:22 - okay but if you let's say let's say
537:24 - let's take a second example that you
537:25 - want no i don't want this i just only
537:28 - wanted that how many how many numbers so
537:30 - you can add a sum and then you can run
537:32 - it out to see how it works so you can
537:34 - see that we have a total of zero uh no
537:38 - values okay so this is the basic
537:40 - exploration uh as i can do about the
537:43 - data access let's little bit exploration
537:45 - about the data okay
537:47 - now the main part will come in
537:49 - exploratory data analysis when when we
537:52 - do the so much of eda and a lot more so
537:56 - we will see over how we do the
537:58 - exploratory data analysis and here what
538:01 - do i mean by explorative data analysis
538:04 - in eda it it does not mean it is a very
538:07 - very hard but it does not also mean this
538:09 - is very very easy it's a very very
538:11 - crucial step in machine learning you
538:14 - should know your data how it is working
538:16 - what's the what's the distribution of
538:18 - the data is your data is balanced you
538:21 - have certain questions to ask we will
538:23 - which we'll see over here okay so you
538:25 - have certain questions to ask to your
538:27 - data that should your that using maybe
538:30 - some plots maybe some numbers will see
538:32 - that and you have to find answers of
538:35 - your coach of of your company because if
538:38 - you're a data scientist or data analyst
538:40 - at some company you should work mostly
538:43 - on to understanding and finding your
538:45 - business solutions as i'm a data
538:47 - scientist at artifact i used to see i
538:50 - used to work a lot more with the data
538:52 - i used to work a lot more with the data
538:54 - because i think that i should be able to
538:56 - what actually my data is and what the
538:59 - business objectives are and what's this
539:01 - what's the answer they want from my data
539:04 - okay so that's what i do a lot of ted
539:07 - exploration data analysis there so
539:09 - that's why i picked up this problem i
539:10 - found it very interesting and not picked
539:12 - so much of heart because it should be
539:14 - conserved like advanced house price
539:16 - predictor
539:17 - diabetes prediction system which i
539:19 - already made which is available in my
539:21 - github but i want you to try out make
539:23 - your unique project and showcase on your
539:25 - resume okay so then what we will do then
539:29 - we will simply see the distribution of
539:32 - our classes what do i mean by classes
539:34 - over here
539:35 - for this example we have
539:37 - we have a binary classification problem
539:40 - and this binary classification problem
539:42 - we are given one and zero okay so
539:44 - whether it if if this one then the
539:46 - person died if it is zero then the
539:48 - person doesn't uh not die i think i have
539:50 - to see okay so sometimes yeah so the the
539:53 - person is leaving is zero and the person
539:55 - is dead is one so we have two classes
539:58 - which is a binary classification problem
540:02 - okay so i'm going to take a look first
540:04 - what i will do i will take a look at the
540:06 - distribution of my data and you can see
540:09 - i'm highlighting the code from where i'm
540:11 - taking a look at the distribution of my
540:14 - data and here it simply means that i'm
540:16 - just going to take that's just just
540:18 - going to data then bracket i want to
540:21 - take a look at the event i'm going to
540:23 - count the number of event where the
540:26 - event is equal equals to zero and i'm
540:28 - going to count the same where the event
540:30 - is equal equals to one by taking out the
540:33 - length of each alex or cds okay then and
540:37 - also the pi pi takes an array so i'm
540:40 - going to put in an arrow like this i'm
540:42 - going to put in an arrow so let's let me
540:44 - choose that red color and this uh medium
540:47 - that works good i'm going to put in
540:49 - array and then i'm going to just label
540:51 - it just just to make sure everything is
540:53 - right so i'm going to label it with
540:55 - living and data i'm going to
540:57 - print it out what is the total number of
540:59 - living cases and what is the total
541:01 - number of diet cases okay
541:04 - and then i'm going to plot it out by
541:06 - just p l t dot pi i'm going to plot it a
541:09 - pie chart by giving our arr a r r will
541:13 - contain the length of life and length of
541:17 - depth like this okay and then labels
541:20 - will be the same light living and dyed
541:22 - exploit this is how much to explode
541:24 - amber and shadow what do you do you want
541:27 - your shadow yeah sure i want the shadow
541:29 - so i'm going to run it now so i just
541:31 - hope that i've run the previously so i'm
541:33 - going to run it now and you can see over
541:35 - here that you that's your data is
541:38 - imbalanced
541:39 - uh we are actually working out we are
541:41 - our data is imbalanced data so i will
541:44 - tell you why why this this data is
541:46 - imbalanced but first of all what is
541:48 - first of all if you can see opioid that
541:50 - we have total of 203 living cases and 96
541:54 - which is tight cases and makes sense
541:56 - also because in real world living cases
541:58 - is more than the death cases i don't
542:01 - know actually i'm not but i think so
542:03 - okay so now let's let let me show it to
542:07 - you in particular to help you get a feel
542:09 - that uh what is imbalanced data okay
542:12 - oops what is not working
542:15 - what is imbalanced data so imbalanced
542:18 - data means let's take an example that
542:20 - you have two classes for example here we
542:22 - have two classes living
542:25 - and that okay
542:27 - so you have more examples of living
542:30 - which is here two or three like 203
542:32 - examples but you have a far lesser two
542:35 - times lesser the lesser than examples of
542:38 - 96 okay so here you were actually
542:41 - working on a balance data what what can
542:43 - be the issue of this issue of this can
542:46 - be that your model and most of the model
542:49 - is most trained onto this living so
542:51 - you're uh you can assume that you're
542:53 - that the output of
542:55 - the most of the output of your model
542:57 - will be zero rather than one in some
543:00 - cases that will print one but it will in
543:02 - most of the cases it will be zero okay
543:05 - so here uh we have some examples so
543:08 - maybe it can but your model is more
543:10 - prone to train under 203 and your model
543:14 - may maybe get biased towards some
543:16 - problem means your model and can be like
543:18 - this print
543:20 - zero your model is this this model and
543:22 - it's only printing zero at every time so
543:25 - this happens when you have for one cases
543:28 - you have two on the let's take an
543:29 - example that you have a 400 examples so
543:32 - for one cases you have three nine nine
543:35 - examples and only one example for
543:37 - for death okay so that is causing that
543:40 - will cause the problem okay a big
543:42 - problem this is a big problem which
543:43 - comes as a
543:45 - something called as which was starting
543:46 - in deep learning which is working with
543:48 - imbalanced data okay so this this is
543:51 - what i'm going to highlight that just i
543:53 - just want to take a little take a take
543:55 - take take my answer is my data is
543:57 - imbalanced how much examples for each
543:59 - case do i have so i answered my question
544:02 - that we are actually working we are
544:04 - actually working on imbalanced data
544:06 - which is actually working here on
544:08 - imbalanced data where we have a living
544:09 - cases equals to 203 and diet cases
544:12 - equals to 96. so imbalance simply means
544:16 - that your classes that your classes are
544:19 - not equally distributed are not equally
544:22 - distributed so can i write it out um
544:25 - yeah so let's write the definition so
544:28 - i'm just going to comment it out just to
544:30 - imbalance means imbalance means
544:34 - that your data
544:36 - is your data is
544:38 - not equally
544:40 - uh distributed between classes
544:43 - distributed between classes between
544:46 - classes okay so uh it may happen that
544:50 - if in balanced data our data is equally
544:52 - distributed so for an example for a
544:54 - particular example so for example let's
544:56 - say you have a training length maybe 400
544:59 - so if you have a training length to be
545:00 - the 400 so assume so assume 200 is for
545:05 - death examples 200 is for live example
545:08 - so we have we have equal number of
545:11 - examples in both living
545:14 - and
545:14 - death cases
545:16 - death
545:17 - cases okay so this is this is an example
545:20 - of balanced data and our model works
545:23 - best here okay
545:25 - this is more robust it is not biased
545:26 - towards anything okay so this is the
545:29 - basic uh this is this this is this is
545:31 - our first sticks for which we didn't
545:32 - also take take another reference so what
545:35 - what we have done so far we have simply
545:37 - taken we have simply uh drawn some eda
545:40 - from here by taking out the length and
545:43 - taking out the length of each event for
545:45 - a zero and one and then then i put in an
545:48 - array and then i'm gonna then i have
545:50 - labels which is living in dots and
545:52 - printed something and then i'm gonna
545:54 - plot the pie chart with that this this
545:56 - this this this explode comes with
545:59 - explode and shadow we want the shadow so
546:02 - you might be seeing the shadow over here
546:05 - okay and you can see that what the
546:06 - inference so i answered my question am i
546:09 - working on imbalanced data
546:11 - yes
546:12 - how much here okay two times just an
546:15 - approximate so our thigh face is two
546:18 - times lesser than the living cases or we
546:20 - can put in a percentage by just dividing
546:23 - it out by just dividing it down to the
546:25 - total length of our data okay so you can
546:27 - you can take you can try it out more
546:30 - mathematically but this is what i'm
546:31 - going to show you to you about this
546:33 - informants okay let's move on to the
546:35 - next inference in the next since we
546:37 - enter influence i wanted to take a look
546:39 - at the distribution of our age
546:41 - uh this this this will tell you whether
546:43 - your data is when what range most of
546:46 - your uh most of them the central
546:48 - tendency i think that is that is here
546:50 - the mean the most of the cases most of
546:53 - the edges like from 40 to 95 okay most
546:57 - of the cases 40 to 95 examples examples
547:00 - are starting from
547:02 - 40 to 95 95 and then you can see most of
547:07 - the cases are in around 16 okay and
547:10 - around 60 with some standard deviation
547:12 - okay so this is the distribution of your
547:14 - data you can try out for different
547:16 - different you can try out for definitely
547:18 - for different different uh
547:20 - numbers which i've already shown to you
547:22 - there are a lot more numbers you can
547:23 - definitely try it out okay make a pie
547:26 - chart for class
547:27 - for binary columns like high blood
547:30 - pressure
547:31 - it was or not or maybe gender make that
547:34 - column and see if it works so i will
547:37 - show you how to filter out the columns
547:39 - from there okay so now we have seen the
547:42 - distribution of our data so now what i
547:45 - want i just want to check so maybe my
547:48 - business objective is maybe my my my
547:51 - lead told to me hey uh if your data your
547:54 - data dashboard like this should be
547:57 - answering lots of questions should be
547:59 - answering lots of your questions about
548:01 - the data okay so here the answer that
548:05 - you're working on this data means the
548:06 - total number of type cases is less than
548:09 - the living cases okay which is two times
548:12 - less than the typically living cases
548:14 - okay so that's the that's the that's how
548:18 - you do and here you can see you can say
548:19 - to your stakeholder or whatever the lead
548:21 - that most of the a most of the age rise
548:24 - from 40 to 95 okay so you can see from
548:28 - this and c and you can tell most of the
548:30 - cases fly around from 50 to 70 like that
548:33 - okay that is the distribution of a data
548:36 - so now say that you wanted to check you
548:38 - wanted to check
548:40 - select you want to select the columns
548:42 - that are above age 50 and see they're
548:45 - dyed or not again a very good secret it
548:53 - sql query forum but maybe you just just
548:56 - think about what you want to do in
548:57 - pandas or you want to do it like that
549:00 - okay so it is possible and seek well but
549:03 - not i i just as an example yeah i've
549:06 - made in a python okay so what i'm going
549:08 - to do my business objective is select
549:11 - the columns select the columns
549:14 - sorry number of examples i think that i
549:16 - do you know
549:18 - select rows that are above age 50 and
549:22 - seeing that
549:23 - they are died or not so here what i'm
549:26 - going to do i i want the death event i
549:29 - want the death even because i don't want
549:31 - any any column with the death even whose
549:33 - age is above or equals to 50 and
549:37 - they are living okay and then again the
549:40 - same thing and then again i'm going to
549:42 - take out the length of the same as above
549:44 - i'm
549:48 - okay so if you've been if if i run this
549:51 - you can again see you can see here that
549:54 - here we have living cases here here we
549:56 - have the living cases a lot and you have
549:58 - a small but you can see the diet cases
550:02 - diet cases so if
550:04 - if i write it out i just want to write
550:06 - it out like this so oops i'm going to
550:08 - write a total number of
550:11 - total uh total number of
550:15 - it's a diet cases diet cases i'm going
550:18 - to take out the length
550:20 - length of diet
550:23 - length of that i'm going to
550:25 - do for
550:27 - total number of
550:30 - total
550:32 - number of
550:34 - non-diet cases not diet cases
550:38 - just i'm not able to write because i
550:40 - have two taps in front of me it's very
550:42 - difficult for me to dabble
550:44 - right over here okay so here length not
550:48 - died okay so here if you can see that
550:51 - you can you are able to see that we have
550:53 - total number of right because 85 and
550:56 - total number of not at 167. so just see
550:59 - over here that in total in total we have
551:01 - 203 which is two times lesser than and
551:04 - here this is fairly one times less than
551:07 - that okay so here you can see that most
551:09 - of the cases again died but most of the
551:11 - cases over 50 died okay as comparatively
551:15 - to
551:16 - our plot
551:17 - maybe not not making sense but
551:20 - again i'm sorry going to say that assume
551:22 - that just let's listen to what i'm
551:24 - saying i'm saying like you can see that
551:27 - um in our work plot we have total number
551:29 - of our diet cases in two times our diet
551:33 - cases our diet cases is two times lesser
551:36 - is two times lesser than our living
551:39 - cases and here our diet cases is one
551:43 - times lesser than not diet cases so here
551:46 - you can we can see obviously this is low
551:48 - but here you can see most of the people
551:51 - that are of always 50 died okay from
551:54 - this inference comparatively from the
551:58 - upper plot okay so here that's how we
552:01 - answer the questions from the data and i
552:04 - hope that you understood everything and
552:06 - i think that you will be
552:08 - taking out more influence okay great so
552:12 - let's see one one more one more uh
552:14 - column which is very fairly good column
552:17 - which i think oops get out
552:20 - i'm just going to yeah here it is oops
552:25 - yeah here it is okay so now now just
552:27 - assume that you want the columns that
552:30 - are available 50 and you'll see whether
552:33 - they are died or not i think that i have
552:35 - already already okay so you want that
552:37 - that there are above age 50 oops i think
552:40 - this is uh this is for diabetes so yeah
552:43 - so what you have to see
552:44 - you have to see you have to answer the
552:46 - question that the person is having
552:48 - diabetes that a person is having
552:49 - diabetes how many numbers
552:52 - how many numbers of patients who are
552:54 - diet are having diabetes and how many
552:57 - numbers a patient this dog dies
553:00 - their dead non-diets having diabetes
553:02 - okay so diabetes isn't um
553:05 - where the person is not having diabetes
553:07 - and having diabetes okay
553:10 - so maybe i've done a little bit wrong
553:12 - over here the diabetes should be there
553:15 - the diabetes should be there and we have
553:17 - to see whether the person had died or
553:20 - not okay so you can see diet with
553:23 - diabetes is this and not that with that
553:26 - diabetes is this so there are a lot more
553:28 - but you can again compare with the other
553:31 - plot over here
553:33 - then it will start making more sense
553:36 - okay so we have done extensive data
553:38 - exploration data analysis a lot more can
553:40 - be done to answer a particular business
553:42 - problem like this you can see over here
553:45 - you can answer some more questions from
553:47 - the data but as to give you a taste of
553:50 - this how i do how i like to do the
553:52 - answer the problem using my favorite
553:54 - visualizations okay so you can answer
553:57 - this uh it's it's very good to answer
553:59 - this all uh by just uh visualizing it
554:03 - out and saying to the lead okay so now
554:06 - now we have seen a lot more things we
554:08 - have seen that more of the visualization
554:10 - just don't worry about this the these
554:12 - are again in the course website mlo one
554:14 - dot native app it's a very very uh easy
554:17 - easy to get all these notebooks
554:20 - okay so now you will check the
554:23 - correlation of our variable so what did
554:26 - i mean by
554:27 - take checking the correlation of our
554:29 - variables it simply means that you'll do
554:32 - that how your how your features how your
554:35 - features are correlated so here you have
554:39 - a very good reference i have taken from
554:42 - the style they they have explained very
554:44 - much extensively every some online so
554:47 - here was telling
554:48 - it shows the correlation between
554:51 - variables on each axis and uh it's
554:55 - means this just shows that
554:57 - i will give you the uh plot over here
554:59 - but what is char what it does it simply
555:01 - shows you the correlation ranges from
555:04 - minus one to plus one okay minus one to
555:07 - plus one it simply means that if your
555:10 - variable is closer to minus one then is
555:12 - a very very similar okay if your is is
555:15 - very very similar so you can see value
555:18 - closer to zero means there is a no
555:20 - linear transmission lean linear thing is
555:23 - not there so you can you can't use
555:25 - linear regression over there between two
555:27 - variables means we can each this
555:29 - correlation tell us whether your data is
555:31 - a linear or not and the close to one the
555:34 - correlation is more positively
555:36 - correlated okay more positive means
555:38 - correlation will empty correlation
555:41 - between these two and you can read about
555:42 - pearson correlation for your efficient
555:44 - topic you're going to just use something
555:45 - kind of that okay
555:47 - that is one increase so that the other
555:49 - and close to
555:51 - close to one to the strongest this
555:52 - relationship is means the
555:55 - the one is closer to one the stronger
555:57 - the relationship is the diagonals are
556:00 - all
556:00 - one that simply indicates that the
556:03 - squares are correlating with each
556:05 - variable to itself so it's a perfect
556:08 - correlation so if you have all the data
556:10 - all the all the all the diagonals of one
556:12 - so the perfect sign of perfect
556:15 - correlation and the plot is also
556:17 - symmetrical and i know that you know
556:18 - about symmetrical
556:21 - so you can see over here but i'm going
556:22 - to just uh
556:24 - put it in a form of this
556:27 - i just hope that i'm going to put it
556:29 - like this
556:30 - okay so i'm going to run it out and here
556:33 - you can see that our data is perfect for
556:36 - relation more the dark is minus 5.3 like
556:39 - that
556:40 - is the more correlated okay so you can
556:43 - read that it's very io explain and also
556:45 - you can do the same as your like if you
556:47 - want to do it with the panas so here you
556:50 - are going to do and your diagonals are
556:52 - again one etc okay
556:55 - so we have done talked about various
556:57 - things you have under understand data
556:58 - and etc etc everything okay so now i
557:01 - hope that you got an idea about how you
557:03 - process so now what i will do i will
557:05 - start with data set development as i've
557:07 - talked about that you should devalue
557:09 - your data into training or testing set
557:11 - because for testing you have to check
557:13 - some you have to you you don't have real
557:15 - examples so for validating your model
557:17 - works best so what you will do you will
557:19 - divide your data and do validation
557:22 - segments training and validation set
557:24 - where you are dividing 70 30 okay so 70
557:27 - for training and 30 percent for testing
557:30 - okay so you can run this out we are
557:32 - using the escalant api uh from while
557:35 - importing the trainer split
557:37 - okay so now we have done this and i hope
557:40 - that you understood this also so now we
557:43 - will do now we will i will not do future
557:46 - engineering over here but uh i will just
557:48 - showcase to you what's the what's
557:51 - what we do just a one example of feature
557:53 - in january okay so in featured
557:56 - engineering we add more features we
557:58 - encode our variable we encode our
558:00 - categorical variables we apply some
558:02 - transformations on our data just to
558:04 - insert our feature okay so here is an
558:07 - example of adding the feature okay so
558:10 - here what would here what what we are
558:13 - doing we are adding the interaction term
558:16 - okay so what is interaction term
558:19 - interaction terms means
558:21 - interaction terms means let's for a
558:24 - foreign sake of example assume that you
558:26 - have this data set this data set which
558:28 - is
558:29 - gender
558:30 - and age okay for an example so it will
558:33 - add again one new problem by taking out
558:36 - the product of g z and uh not let's take
558:40 - a bp okay and we think means in
558:42 - numerical so it will take the product
558:44 - and add okay so it is just doing the
558:47 - product of two features and making that
558:49 - call okay so maybe that that will not
558:52 - make sense but this is what the
558:53 - interaction term means means we are just
558:56 - adding the product of two features okay
558:59 - so
559:00 - here is our function for that so first
559:02 - of all we are taking the columns names
559:04 - then we are taking the length because we
559:06 - have to see we have to iterate through
559:08 - um and then i'm going to copy it out so
559:10 - that we can change anything to x and i'm
559:12 - going to um
559:14 - just iterate through all the columns and
559:17 - i column represent the represent of
559:21 - first column and this feature i name
559:24 - that this uh there is this this column
559:26 - i'm going to ask
559:28 - access using the x and then i'm going to
559:30 - range through j because i want to
559:32 - multiply these two so here again the
559:35 - same thing and again i'm going to take
559:36 - out the data and we'll do is just to
559:38 - make it this to just show the name of
559:40 - the column like this that that we
559:42 - multiplied and actually you're
559:44 - multiplying this out and then we are
559:45 - returning the x end okay so this is what
559:48 - and then we are calling on x train and x
559:50 - test and we are done okay
559:54 - so here if you run it out now you can
559:57 - see if if if i show you the code if i
560:00 - show you the x-wing mod
560:05 - x train mod
560:08 - do i run it
560:10 - yep
560:11 - let me run it again
560:14 - you can see that we have 78 columns we
560:18 - have 78 columns from your 30 or 13
560:20 - columns to 78 columns you can try the
560:23 - result how it is working and let me know
560:25 - in the comment box below on our on in
560:27 - our desktop community okay so this is
560:30 - what what we are doing and by adding the
560:33 - interaction term we are feel free to
560:35 - explore more okay now what we'll do we
560:38 - will now we'll start building our model
560:40 - so how do we build just just we will
560:42 - start building our model so first i'm
560:44 - going to make a model for evaluating our
560:46 - model so first i will take a look at the
560:48 - accuracy precision recall and confusion
560:52 - matrix so again if i run it over here
560:54 - now now it will give and we are giving
560:56 - the ground through as well as our
560:58 - predictive okay first of all i will
561:00 - start with legislative question with max
561:02 - iteration to be 1000 the reason why i
561:05 - have given over here because if you it
561:06 - is not converging it is not converging
561:09 - with any solver so for converging if you
561:12 - run it down you can see that lbgs fail
561:15 - to converge what you can do you can
561:18 - increase the number of iterations or or
561:21 - what do what you can do you can simply
561:24 - you can simply uh
561:26 - scale your data maybe my data is not
561:28 - scaled so increase to the iterations 2
561:31 - 000 and it worked okay but it is also
561:34 - telling a process to standardize your
561:36 - data or to scale your data so here for
561:40 - standardizing as well as the building
561:42 - the model so we have something called
561:43 - this make pipeline so what what it will
561:45 - do for any coming example is to
561:47 - standalyze and then it will uh and then
561:50 - we and then it will apply legislation
561:52 - over there okay so we are we are just
561:54 - doing in a small number of and you can
561:56 - compare the result of the
561:58 - standardization and that max iteration
562:01 - so the accuracy is actually better
562:04 - actually better precision is also better
562:08 - recall is also better and this is also
562:10 - better okay confusion matrix
562:14 - okay so i hope that you watch my session
562:17 - on pre-season a recall but let's uh let
562:20 - me show you what those precision and
562:23 - recall confusion matrix means so maybe i
562:26 - have the
562:27 - this stochastic gradient reset yeah so
562:30 - we just just just want to make sure that
562:32 - you are on the same base okay so
562:35 - here i'm going to highlight one
562:37 - algorithm which is
562:39 - optimization algorithm which is same as
562:41 - our favorite gradient decent but here in
562:44 - gradient decent what we were doing it
562:47 - just takes it is taking a lot of time
562:49 - white is taking a lot of time so here
562:52 - assume this this example assume this
562:53 - example i'm going to narrow it over here
562:55 - that
562:57 - let's assume that you have a 10 000 data
562:59 - points 10 000 data points 10 10 000 data
563:02 - points and we have 10 features okay so
563:04 - here you have 10 features and the
563:06 - residuals consist of as many terms as
563:08 - their data points so you have 10 000
563:11 - residuals because we are taking the
563:12 - difference between your predicted and
563:14 - now model predictive model output value
563:16 - so you have around ten thousand term in
563:19 - our case residuals so we need to compute
563:21 - the derivative of the ten thousand term
563:24 - you need to compute the third period of
563:25 - a ten ten thousand term with respect to
563:27 - our features which is ten thousand times
563:29 - ten which is one lakh computation per
563:33 - iteration that is so so much high okay
563:37 - so that's why we have some something
563:39 - called as stochastic gradient adjacent
563:42 - so what what we do so what could we do
563:45 - in stochastic gradient descent this we
563:48 - choose simply us the same thing happens
563:50 - we repeat until analytics our
563:52 - approximation is minimized and then we
563:54 - randomly shuffle and then we do at each
563:58 - step it means we at at one year step so
564:00 - we don't update we do updation as well
564:02 - as the derivation at each step and we
564:04 - are doing for each training examples for
564:07 - each
564:08 - training examples okay so it um you it
564:11 - is a little bit out of course it is
564:13 - usually thoughts and
564:14 - maybe an uh
564:17 - deep learning but i would highly
564:18 - recommend to learn this is just equal
564:20 - equals to the
564:22 - batch gradient decent okay so you will
564:25 - be able to see what's the difference
564:27 - okay so now as
564:29 - i've talked to you that we have
564:31 - something called as pre-season recall
564:33 - accuracy so we have not talked about
564:36 - that so let's talk about i'll just spend
564:39 - a little bit of amount of time onto that
564:41 - so here tp means true positive means
564:45 - true positive means that your outcome
564:47 - that your outcome
564:49 - is
564:50 - that you that your moral outcome
564:52 - correctly predicts the positive class
564:54 - okay so you have in in any model you
564:57 - have two positive and negative classes
564:59 - positive
565:01 - negative classes positive like zero is a
565:04 - positive m one is a negative it'll be
565:06 - positive so your model predicts the same
565:08 - output as your ground through okay in a
565:10 - positive end for a positive class true
565:13 - negative is where the where your model
565:16 - predicted one and your output is also
565:18 - one and true positive means zero and
565:20 - zero these are positive plus and these
565:22 - are negative plus okay
565:26 - here you have false positive which is
565:28 - your model incorrectly your model
565:30 - predicted your model predicted your zero
565:33 - and actually the output is one so it is
565:36 - false positive means positive and false
565:38 - because they are not matching
565:40 - false negative is just the it's your
565:43 - moral your your moral predicted you're
565:46 - more predicted wrongly okay so you're
565:48 - more predictive one and your output is
565:49 - actually zero means negative and
565:51 - positive class
565:52 - okay so that's the that's that's the
565:54 - true positive negative and confusion
565:57 - matrix is simply like this first we have
565:59 - a true positive
566:00 - false negative
566:02 - false positive and true negative that we
566:05 - have just seen it will tell you how many
566:07 - number of are correctly classified as up
566:09 - in a positive class in a negative class
566:11 - in a in a but in the modern model
566:14 - field and a positive class with a
566:16 - moderate fail and this is a true
566:18 - negative where the model actually worked
566:21 - okay so you can see that we will we have
566:22 - seen okay so precedes and recall as we
566:25 - have talked about precision and recall
566:28 - a number of a true positive divided by
566:32 - the number of a troop or was divided by
566:33 - the number of a true positive plus the
566:35 - number of a false positive so true
566:37 - positives t p
566:39 - plot by three t p divided by the number
566:41 - of a true positive plus the number of a
566:44 - false positive okay so this is your
566:47 - output this is your output of the
566:49 - precision and simply answer the question
566:52 - what proportion of positive indications
566:54 - was actually correct okay so it answered
566:57 - what proportion so here we have 0.73
567:00 - which is actually a good proportion but
567:01 - we had it can be improved the equal
567:04 - answer is the question what proportion
567:05 - of actual positive was identified
567:07 - correctly okay okay so it will tell you
567:10 - that what is the proportion of actual
567:12 - positives was identified
567:14 - correctly okay so this is the
567:17 - recall of our model okay so now we will
567:21 - see
567:22 - now we will see uh just just we will to
567:24 - see the that that the every season we
567:27 - call
567:28 - confusion matrix etc okay so now we will
567:31 - see now we have built our legislation
567:33 - with some standardization now we'll
567:35 - build a support vector classifier with a
567:38 - grid search cv with extensive fine
567:41 - tuning we have c which is lambda which
567:43 - is which which controls the width of
567:45 - that margin so we'll try different
567:47 - differences zero point one one ten
567:49 - hundred one thousand gamma one zero
567:51 - point one zero point one zero zero point
567:53 - one and kernel to be rbf kernel and then
567:56 - i will call the grid source to
567:57 - instantiate with the svc classifier ram
568:00 - grid reference to verbals equal to three
568:03 - it will i'm going to fit it it will try
568:05 - for each and every and checks like score
568:08 - and this is what here and this is what
568:10 - the thing is they have done where they
568:11 - have checked and you can find out the
568:13 - best parameter that the model found
568:15 - where c equals to 10 and gamma equals
568:17 - 0.01
568:19 - you can see it's far performs a little
568:21 - bit less with uh compared to logistic
568:24 - progression but it worked okay
568:27 - so we have done with earlier we are done
568:29 - with the support bitter vector
568:30 - classifier as well as logistic
568:32 - regression classifier now what we will
568:34 - do we will do uh this we will we will
568:37 - make a decision a tree classifier okay
568:41 - so what i mean by decision tree
568:43 - classifier is i'm going to import the
568:45 - true as that we've already talked in
568:46 - detail i'm going to import a randomized
568:49 - research we have talked about grid
568:50 - search randomized research is same so
568:52 - i'm going to define a function that
568:54 - takes the parameters take some how many
568:56 - runs to clf what the classifier to use
568:59 - okay
569:00 - then we will
569:02 - then we'll call a randomized on clf
569:04 - which will give the clf which is
569:06 - classification number of iterations etc
569:08 - then if fit it then then you'll find the
569:10 - best parameter then we find the best
569:12 - score and then we'll say this and this
569:14 - this is just a custom-made model but you
569:16 - can surely remove that and just use that
569:18 - randomized search and then put all these
569:20 - so i have already done in some of my
569:22 - projects i've just taken out from there
569:24 - and it's working great okay so i'm gonna
569:27 - it will tell which is the best which
569:29 - criterion is the best whether again drop
569:31 - your guinea a splitter or main weight is
569:33 - i have done a lot of uh fine tuning okay
569:37 - i will run it it will take a little bit
569:39 - amount of time trying all the values and
569:41 - checking the score and you can see the
569:43 - training score is it 0.84 and the test
569:46 - score is
569:48 - 0.75 okay now we'll run this classifier
569:52 - with the same uh with these uh features
569:55 - okay so it it will give me the output
569:58 - like this now i will oops now i will run
570:01 - it out maybe you can you can see okay so
570:04 - you can see how it how well it is
570:05 - performing maybe i have not let's see
570:08 - the best score randomized to search best
570:11 - score okay
570:13 - uh maybe uh yeah so that's that's the
570:15 - basic and you can also try it out maybe
570:17 - i'm a little bit uh you can see uh
570:20 - let's see if it is it is not good or not
570:23 - oops
570:24 - i have to also show okay so it is
570:26 - showing the best classifier so i have to
570:28 - put it over here i don't know why i put
570:31 - it over here but
570:32 - what i have put it now in when what mine
570:35 - but i will let me put it
570:38 - okay let's run it it's actually 0.75 so
570:41 - i've lit i have obviously done some fine
570:43 - tuning and here what i got that's with a
570:46 - good parameter okay so it's not always
570:48 - oh this works best in some of the cases
570:51 - it worked okay so now with the service
570:53 - little bit of fine tuning i'm going to
570:55 - call a random forest specifier then i'm
570:57 - going to run it with this with a with a
571:00 - parameter stack that we got with the
571:02 - random forest okay it will evaluate my
571:05 - model and then 0.86 0.1 actually good
571:08 - okay now what we'll do we will use
571:11 - xgboost okay xg boost is another we have
571:14 - talked about we're learning with 0.1 max
571:17 - step what is the number of parameters
571:19 - then i'm going to put evaluation set
571:21 - into one uh
571:23 - array okay so just uh just just see the
571:26 - log loss at the same time and then i'm
571:28 - gonna run it so it will tell at the log
571:30 - loss of the zero iteration and zero
571:32 - point hard to do is the log loss
571:34 - validation loss okay now we will
571:36 - evaluate and here again 0.85 is more
571:39 - robust model okay it is a robust model
571:41 - if you if you can see the importance
571:45 - it will show what features are more
571:48 - important so time is very important
571:49 - injection is very important so in this
571:51 - way you can select you can discriminate
571:54 - maybe smoking anemia sex creator dying
571:57 - and then means these these three you can
572:00 - remove as a future selection okay the
572:02 - last in that test we are going to uh use
572:05 - is a gradient boosting classifier
572:08 - gradient boosting is mostly used in a
572:10 - cases of
572:12 - images but let's see it how well it
572:14 - works with these hyper parameters you
572:16 - can also fine tune it to get better
572:18 - results than me and it actually worked
572:21 - okay now what i will do i will i will
572:24 - save my xg boost model because eddie
572:27 - boost is more robust so i will save my
572:29 - model by just calling for job lib job
572:31 - lift up dump i'm going to load my job if
572:34 - you can see if i run it now you can see
572:36 - that zero zero one and you can see if i
572:39 - go over here if i go over my heart
572:41 - failure and model.pkl file and you can
572:44 - load this model.pkl file to make a good
572:47 - model okay so that's the that's our
572:50 - that's a basic thing that we need to
572:52 - understand about um that test we need to
572:55 - understand about uh this
572:58 - hurt failure detection system and i hope
573:00 - that you have understood a lot from this
573:04 - okay so thank you for uh seeing uh this
573:07 - section and i really hope that you
573:09 - enjoyed this and we have covered this
573:11 - project in 42 minutes
573:13 - in the next project we will be talking
573:15 - about a small project spam detector
573:18 - system which is again a very cool
573:20 - project which is understanding problem
573:22 - statement and building a good model okay
573:25 - so let's meet at the next project then
573:28 - have a good day so now we'll talk about
573:30 - or we will make one project which is
573:32 - spam and hand detector system so if you
573:35 - have seen your
573:37 - gmail uh or google gmail or microsoft
573:41 - outlook there you are seeing that they
573:43 - are maybe where you have a tab which is
573:45 - spam tab they're your spam emails are
573:49 - there so in the same way we are going to
573:51 - build a spam and ham detector system so
573:55 - spam means means that uh that a
573:57 - particular message may be corrupt and
574:01 - ham means not a spam just oppose it to
574:04 - spam okay so just uh ham means not a
574:08 - spam i don't know why does not work for
574:10 - the first time not a spam
574:12 - okay and here you can see that that text
574:16 - we have a label means uh we are given a
574:20 - message we are given a message and we
574:22 - are given the target label which is our
574:25 - why okay so this this is our this is our
574:28 - message maybe go until journey point
574:31 - crazy and then you and there is a label
574:34 - which is given over there okay and this
574:37 - data set is downloaded
574:39 - this data set is down downloaded from
574:41 - uci repository and here is our data data
574:45 - set so it is in table so i'm not going
574:47 - to use csv i'm going to use table to
574:51 - read that i'm going to separate by a tab
574:53 - header should be none and the names of
574:56 - the columns should be labeled and
574:57 - messages
574:59 - okay so let's take a look at we will
575:02 - take a look at the first few uh
575:06 - data points so let me run this out first
575:08 - of all this and then this
575:10 - and then i'm going to show you one of
575:13 - the messages there so it should start
575:15 - making sense to you
575:17 - so here
575:19 - data oops what happened
575:21 - data and this is the messages
575:24 - it will take a little bit of time
575:26 - then zero position so you can see that
575:29 - go until journey point crazy available
575:31 - etc etc and here it says that is a ham
575:36 - that means not a spam so for a for
575:38 - example let's assume this second number
575:40 - because in second number we have it
575:42 - labeled at the span so free entry it's
575:45 - looking like a spam like it's free entry
575:48 - or where now like that
575:50 - okay
575:51 - so that is the that's that's the basic
575:54 - uh that's the basic exploration of our
575:57 - data and this is downloaded from uci
575:59 - repository okay so i think that you that
576:02 - you understood we are given a corporate
576:05 - for test so here we are not given any
576:07 - numbers here we and we are given here we
576:11 - are not given any number we are given
576:13 - oops what happened what is happening we
576:15 - are given a messages which is x as our
576:18 - messages which is in text format so your
576:21 - neural network argument sorry machine
576:23 - learning model does not work with text
576:26 - so you have to convert the text into
576:29 - numbers so we will see some of our
576:32 - favorite text
576:33 - text a vectorizer to convert this corpus
576:36 - of a test into a matrix or a vector or a
576:39 - number of a vector we will see that we
576:41 - will see that okay
576:42 - so here you can see that uh what here we
576:46 - are given a data which is text and
576:49 - there's one and then we have a label
576:50 - okay so now we will see now we'll start
576:53 - exploring our data set so now we have
576:55 - got our problem statement that we are
576:57 - given a part with our text we are given
577:00 - a text and we need to formative password
577:03 - or pipeline and give it to your output
577:05 - whether it is a ham
577:06 - or a spam or hammond zero and spam means
577:11 - one okay so that's that's that that's
577:14 - the our favorite uh
577:16 - given now we will move forward now now
577:19 - we'll move forward into exploring our
577:22 - data so i've already explored it so let
577:25 - me rerun it again so here i hope that
577:28 - you all are able to see this
577:30 - so maybe even if you're not don't don't
577:33 - worry i will just we're going to take a
577:35 - look at a shape of the data which is 5
577:38 - 72 572
577:42 - with two columns and then we have a no
577:45 - values to be zero because we don't have
577:47 - any no values we have two infos and here
577:51 - which is a count unique values uh what
577:54 - is the frequency and etcetera and
577:56 - obviously they're in the text we do you
577:57 - don't have numerical things so that's
577:59 - why
578:00 - it's it's empty okay
578:03 - great so we explored the data very much
578:06 - now it's time to again start with
578:09 - explorer
578:10 - exploratory data analysis okay so in
578:14 - explorative data analysis we in the in
578:16 - our previous project we have seen that
578:18 - we have seen that we have to see the
578:21 - distribution we have to see uh the
578:23 - distribution
578:25 - we have to see the distribution of the
578:26 - classes okay so here we are seeing the
578:29 - distribution of the classes by just
578:30 - taking out the length and converting
578:32 - that into a length now now here you can
578:35 - see the labels which is hammer spam and
578:38 - it will tell what is the number of total
578:39 - labels with the plotting the pie chart
578:41 - and you can see over here that the
578:43 - number of
578:44 - ham examples is 4
578:47 - 825
578:49 - and spam examples at 747
578:53 - so we are actually working on imbalanced
578:57 - we are actually working on imbalanced
578:59 - data so your model will learn a more
579:02 - about tam rather than spam okay so be
579:06 - sure to keep that in mind
579:08 - next we will uh now it's it's very very
579:12 - important like uh for an example so
579:15 - let's uh let's understand the processing
579:17 - of our text how how we clean our text
579:20 - and why it is why it is there a lot more
579:22 - need so
579:24 - why do i mean like what do i mean by
579:26 - cleaning is for an example let's assume
579:30 - that you have a
579:31 - go
579:32 - okay so you have go oops
579:36 - go okay small g i don't know why it is
579:39 - not working again
579:41 - i like okay so here you have go
579:44 - here you have go okay it says best place
579:47 - small oh okay so
579:50 - these two will be considered different
579:52 - these two will be considered different
579:54 - but this is the same these two will can
579:57 - will be considered different but this is
579:59 - uh this is the same or maybe
580:02 - this hashtag does not need any sense
580:05 - over here so why do we need hashtag over
580:07 - here maybe we don't need like this we
580:10 - don't need emerges but here but in some
580:13 - cases like in sentiment analysis emojis
580:15 - plays an important role but here we are
580:18 - go and go are the similar thing maybe
580:21 - here we have a
580:22 - here we have a
580:24 - these these need if we if he gives to a
580:26 - model these two will be considered
580:28 - differently so that's that's not a good
580:30 - thing so what we will do we will convert
580:34 - all our text into lower text okay now
580:38 - here we are doing some text
580:40 - pre-processing that that you need to
580:42 - know okay just uh just using re okay
580:46 - rejects okay so i'm going to replace
580:49 - here and i'll be given one simple
580:51 - message i'll be given one simple message
580:53 - first of all okay i'm going to first
580:56 - lower it down by converting that into a
580:58 - string then i'm going to replace this
581:01 - this zero if there is any zeros in the
581:03 - text will be replaced by m okay and this
581:07 - this three will be replaced by k and k
581:09 - is thousand k or hundred k or what
581:12 - whatever
581:13 - this uh
581:14 - this comma will be replaced by this
581:17 - sorry uh above i i'm not recalling
581:19 - what's the name and except sorry uh
581:22 - it's uh it's uh i'm not recalling but
581:25 - yeah you can see okay so then you have
581:29 - won't will be here it will be considered
581:31 - different so will not okay can not
581:35 - should be can not
581:37 - can't should be cannot okay he
581:41 - uh we have we are just doing n not
581:43 - equals not what's what is is it's it is
581:48 - that his he is she is she is
581:52 - s own percentage then etc and then your
581:56 - l will okay so this is the this is the
581:59 - basic text preprocessing that i've done
582:01 - over here but one thing that i can also
582:03 - do over here one thing that i can also
582:05 - do over here like for stemming stemming
582:09 - okay
582:10 - stemming
582:11 - limitization
582:13 - limitization limitization so i would
582:16 - like you to explore this i would like to
582:19 - you to explore both of them in
582:21 - implementation okay and uh why what
582:25 - first of all let let me tell you what is
582:27 - stemming okay so stemming it simply
582:29 - means and it's it's in stemming it
582:32 - simply means that
582:34 - for an example for an example so if i go
582:38 - to some website let's take an example
582:40 - that i
582:41 - write play that i write play
582:44 - i write
582:45 - p-l-a-y-e-d
582:48 - then i write player
582:50 - okay so it will it will the stemming
582:53 - will give play and these three quotes
582:56 - can become will will be converted to
582:58 - this single word because they make a
583:00 - similar sense okay so that's the
583:03 - stemming and limitization is just a
583:06 - bigger version of that it it makes a
583:08 - meaningful some sometimes stemming does
583:11 - not make a meaningful word so for making
583:14 - a meaningful word we have lemmetization
583:17 - but again laminization what is just so
583:20 - for example place plays plates played
583:24 - and players
583:25 - so it will convert in play and the the
583:28 - stemming will convert in pla okay so it
583:30 - does not make sense but this limitation
583:33 - is making sense after we levitize our
583:36 - work
583:37 - word or we convert our corporates of a
583:39 - word into a single word okay so that's
583:42 - the seminal limitation but i want you to
583:45 - explore stemming the word stemming
583:49 - limitization using nltga library you can
583:52 - refer to some of my github i've already
583:54 - done that but i want you to do this okay
583:57 - so otherwise you know no tasks will be
583:59 - left for you in this task okay so here
584:03 - what then what then what we'll do then
584:05 - you apply to each messages by making a
584:09 - new column you apply each messages these
584:12 - text pre-processing by doing this all by
584:14 - calling the lambda and
584:16 - calling the laminate will go through
584:18 - each step will it it will it will go to
584:20 - each step and apply the function onto
584:23 - each messages and put that into a
584:25 - processed text so let's take an example
584:29 - of that it
584:30 - will start making more sense if you take
584:33 - a little bit of example
584:35 - okay so what i'm going to do is i'm
584:37 - going to print out i'm going to print
584:39 - out not first which will be our favorite
584:43 - uh not processor text so i'm going to
584:45 - print out first which is not processed
584:48 - text so these are data and then i'm not
584:50 - going to i'm going to post a video now i
584:52 - want to zero element and now i'm going
584:54 - to
584:55 - make a simple line i'm going to make a
584:58 - simple line oops what happened i'm going
585:00 - to make a simple line so it's just mix
585:03 - this
585:04 - and i'm not and then i'm going to just
585:08 - paste it over like this okay so it will
585:11 - show you what is the pre-process text so
585:13 - this pre-processed text is converted
585:16 - like this okay so apply stemming okay by
585:21 - using the porter stemmer you can go to
585:24 - nlp and ltk stamic nltk
585:30 - okay there is something called it's
585:32 - limitization so you can see some of the
585:34 - tutorials which are available in
585:36 - geeks4geeks etc so
585:39 - read it out means you can go to any of
585:41 - them whatever you like it's just
585:43 - converts the words into uh yeah here is
585:46 - a good example so playing play play so
585:49 - it will come common root from play okay
585:52 - so this will convert it like this like
585:54 - stemming is the process of reducing your
585:56 - inflection into words okay so you can
585:58 - read this read this sound this is a very
586:00 - good documentation provided by their
586:02 - camp
586:03 - and you will get to know much better
586:05 - about this but i will be bringing up one
586:08 - full course onto national language
586:10 - processing justice is a sample how do we
586:12 - work with the text but
586:15 - on new era on new era when full course
586:18 - on deep learning where we'll be talking
586:19 - on deep learning we'll cover text
586:21 - working with the textual data okay
586:24 - now we'll go further into now i'll go
586:27 - further into feature engineering what is
586:29 - feature engineering here we are not
586:31 - going to add any features we're just
586:32 - going to encode our hand to zero and
586:34 - expand to one by calling our map method
586:38 - then it's done now we'll divide up a
586:40 - data into train this split now if i run
586:42 - it here you have total number of this
586:44 - and then and then we and then what and
586:47 - then what what we will do now just
586:50 - assume now just see now just see over
586:52 - here that in training set in training
586:55 - set
586:55 - we have our text but
586:58 - neural machine learning will not accept
587:00 - the string or whatever the textual data
587:03 - so what we have to do there is modern
587:05 - means word embeddings then we convert
587:07 - our word and then we convert our word
587:11 - into maybe this word into some numbers
587:16 - into some numbers into some numbers
587:19 - there are a lot more techniques
587:21 - count vectorizer tf idf vectorizer bag
587:25 - of words which i'm not going to again
587:28 - talk about again it's time for you to
587:30 - explore as of now you can just think of
587:32 - it as you can see there you go you can
587:35 - see that what's the mathematical
587:36 - equation for that is a single
587:37 - mathematical equation but is what it
587:40 - does is simply you can go to usq learn
587:42 - feature extraction just extract the
587:44 - features from the text which converts
587:46 - your
587:48 - text into the numbers okay by just we
587:50 - instantiate over here now now with now
587:53 - what it it will do it will fit the
587:55 - training data means android return the
587:57 - matrix and then
587:59 - we don't want to fit the text test
588:02 - testing so that's why we are just
588:04 - transforming our uh text stress to the
588:06 - numerical into the matrix okay that's it
588:09 - okay so this is what we've used to
588:11 - convert our
588:13 - uh
588:14 - text into on vector of numbers okay so
588:18 - if i show you the training data how's
588:21 - the training data is a sparse matrix
588:23 - okay
588:24 - it's a sparse matrix which is with five
588:27 - thousand fifty five thousand two hundred
588:29 - and nine stored elements into that okay
588:32 - now we will use nine base i hope that
588:35 - you understood and i hope that you had a
588:38 - look we're on nine days uh on this as
588:41 - you have told to do the assignment so
588:44 - you hope that you had a look at night
588:45 - base you can read more about knife base
588:48 - this is just a very simple as we talked
588:50 - about some other learning algorithm it's
588:52 - very very simple okay so you may run
588:55 - this and then you just
588:57 - call color protect and here you have
588:59 - accuracy so now let's uh let's give up
589:01 - corpus vertex so let's take and let's
589:03 - stick and take an example here you have
589:05 - a text
589:06 - here you have a text and i'm going to
589:09 - write a y usage is a good boy i think
589:12 - let's see if it is a spam or not spam
589:16 - okay so i'm gonna just want to convert
589:18 - that this it
589:20 - in in production what we do we write a
589:23 - function process we write the function
589:25 - we'll take a text as an input then what
589:28 - it will do we we instead we call our
589:30 - account vectorizer which
589:32 - which we call over here so i'm going to
589:34 - call my count vectorizer like this count
589:36 - vector
589:37 - dot to transform i'm going to transform
589:39 - my text giving uh giving
589:43 - giving this
589:44 - i'm going to do this num okay so it will
589:46 - contain the basis of vectors now i'm
589:48 - going to just call my model which is
589:52 - maybe it will take a model so i'm going
589:54 - to call my model which is here
589:57 - nine days and then it will simply dot
590:00 - predict now it will simply predict my
590:03 - txt okay and then i'm going to oops it's
590:07 - num na i'm just convert that into a noun
590:09 - so it's the prediction i'm going to use
590:11 - the prediction
590:13 - and then what i'm going to do i'm going
590:15 - to read her the prediction okay so here
590:18 - if you call pre-process and then
590:21 - pre-process and predict so it will be it
590:23 - will take text as an input and it will
590:26 - return maybe it's maybe uh some problem
590:29 - maybe i have to do convector that fit
590:32 - transform
590:35 - what happened
590:36 - pre-process iterable over raw documents
590:39 - a string object received
590:41 - okay no worries
590:43 - so maybe
590:53 - what's the problem was causing is
590:56 - is i'm given this messages and instead
591:00 - of this pre-process but we need to give
591:03 - the process takes instead of messages so
591:06 - here we are given the messages now we
591:08 - are just going to providing the series
591:10 - and then i'm going to do count vector
591:12 - transform
591:13 - uh giving this talk and then providing
591:15 - naive bayes dot predict and this this
591:17 - this this will predict whether that it
591:20 - will it is a spam or a non-spam
591:23 - okay so that's the basic uh
591:26 - spam and ham detector system obviously
591:29 - you can try more stacking various
591:32 - various things so we hope just to give
591:34 - you a taste how the natural
591:37 - language processing uh project how we
591:40 - work with the data just to give you the
591:42 - taste of our data okay
591:45 - so i think we are we are completed with
591:47 - pro with this project i'll be i'll be
591:50 - catching up you in the uh maybe uh the
591:53 - next i think that we are done with this
591:55 - uh this course maybe i will do i will
591:58 - maybe we will talk about simple
592:00 - perceptron and then we will wrap up this
592:02 - course okay so thank you for seeing this
592:05 - course i would highly
592:07 - congratulate you for completing this
592:09 - course
592:18 - you

Cleaned transcript:

this machine learning course starts at the beginning and goes all the way to an advanced level teaching you both the theory and applications of machine learning concepts ayush who teaches this course is a data scientist and machine learning engineer hi everyone and welcome to this course of machine learning this course will teach you machine learning from very basics to an advanced level in machine learning in this course this and this course will be having both theoretical plus practical understanding of machine learning algorithms and building real world ai projects after this course you will be you will be able to build your own machine learning applications and realworld applications and many domains okay but wait first who am i my name is ayush and i'm a data scientist at artifact i'm in standard nine from india i've worked on various applications of artificial intelligence like machine learning deep learning i've worked on various domains from deep learning which is another computer vision generative adversarial networks and nash language processing i've also contributed to the large ai projects and routine by andana okay so this is this is my basic uh skills and also i run a small youtube channel which is not as near now not a small a big youtube channel which is around we have a 500 members where we when i where i make a content on machine learning deep learning and various ai things and i put endtoend courses there currently deep learning course is being launched so you can start watching after this completing that start this course that deep learning course okay so that's that's that is from my side and you can connect me on linkedin if you want to know over more about me and i've also cleared some microsoft exams so you can get to know more about there about me okay i'm also a founder of android and ai tech platform and also product based platform okay so that's it from my side and i hope that you will get a lot more from this course now let's discuss the syllabus of this course we will start with the very basics of machine learning covering the fundamentals of machine learning in the section number one and then it will go further into understanding some algorithms like linear regression a logistic regression support victim machine principal common analysis learning theory and some in symbol learning methods like bagging boosting stacking cascading and then we'll talk about unsupervised learning and you may think yeah you sure you would you wanted to teach this much no absolutely no in this this is a 10 plus hours of course so absolutely there is a lot more content so this this course is divided into sections and each sections have a different sub sections so you and i have made a full syllabus talks what topics i'm going to cover in each and every topic or something a section divided in a sub section and you can assess the syllabus by visiting the course website the course website i premade with um are made with my friends friends of andrew so you can definitely go there and assess all the syllabus all the problem sets of this of this course and each and every section you will be you you'll be having one problem set and all of these is in the description down box below okay all of where the time stamps as well as the course world notes okay so are all available on the course website so you can go there see what's assignments are there complete that and join our discord server to just to discuss your assignments and you can also submit it through forum okay so this is the basic syllabus that we are going to follow and i really hope that it worked a lot in preparing the materials for this course teaching you all in the blackboard and understanding you're helping understand each and every topics of machine learning in a very very very easy way and this course has extensive syllabus a very good syllabus uh to um which i have which i haven't seen on youtube youtube okay so please be sure to see the syllabus what we are going to cover just have told you in in just shot the reason is i i want to just start with this uh video so i've given a shot you can see the syllabus by visiting our course website for absolutely free everything for absolutely free you can go to the course website which is the link in the description that box below so let's start with the section number one fundamentals of machine learning okay so now we'll start with machine learning in this section you will get an introduction to machine learning and we'll talk about introduction to machine learning types of machine learning and there are types and we'll see some cool applications and then we will see some problem of overfitting and under fitting and then we'll wrap up this section okay so let's start okay so now we'll answer a question what is machine learning and you may ask here you sure this is very uh can you tell what actually machine learning is yeah you will get to know more and more about what actually the big picture of machine learning means you in depth when when we will go through this course but in simple terms machine learning is like this computer programs that uses algorithms to analyze the data and make intelligent predictions based on the data without being explicitly programmed and you might think hey are you sure what is kind of this um it i'm getting a little bit confused no worries so let's um let's get into this and let me explain you what i'm saying over here in this blackboard so you are given a data you are given a data okay and then you give to the algorithm the algorithm the algorithm analyzes the data analyzes the data analyzes the data and whatever he has analyzed or learned from the data it makes predictions based onto that it makes predictions under that okay so specifically what we were the what what we are doing we want to make a function x that maps out input variable x to the output variable y and you may think here you're sure confusing me what is x what is y no worries x is the input feature x is the input feature means uh let's take a problem statement of predicting the house prices predicting the house prices okay so you want to do this so uh here on the basis of the size of the house so on the basis of size of the house you want to predict the price of the house okay so you give an input variable x and you get outward variable y okay so on the basis of the size of the house you want uh the price of the house okay so you wanted to make a function so you wanted to make a function f that takes input x and maps that to y and that's the definition of machine learning that's the beauty of machine learning so what we were doing we are we want to have we want to map our input variable x maybe it can be maybe the size of the house maybe the number of fans of the house maybe the number of our bedrooms in the house so i'm denoting with a subscript one subscript to subscript three and we want to make a function that maps these input variables to the output variable which which we did denote with y which is the price of the house and that's what and that we are doing and we will learn how to make this functions okay so that's the beauty of machine learning which you can see over here so let's see some of the more formal definitions which you will see you more over the internet then the machine learning is the field of study that gives computer the ability to learn without being explicitly programmed saved by author samuel but one definition that i said to use totally means if you if you if someone asks you hey hey whatever your name uh what is machine learning you just ask hey i i know a better way to define a machine learning you just make a fun geo just to make a function that maps your input variables to the output variable okay and that's the beauty or that that's called the machine learning and i hope that's you that you that you got it what i'm what i'm trying to say you hear and access are the input features that you that you wanted to on the basis of that these are the input input features and the basis of that you want to predict the price okay the another definition of machine learning is the computer program is say to the learn from the experience e with respect to the sum class of a task t and some performance measure by p if its performance on t as measure by p improves with experience e and this mean seems a little bit intimidating but let me clear this definition is very uh my my favorite definition although this this is my favorite definition that i've shown to you but let me tell you what the definition tells you the definition is so before that let me take one example which is let's take an example of checkers okay playing checkers playing checkers i hope that's you no no no let's let's take another because many other people do not play checkers over here okay so let's take a spammed email spam detection system email spam detection detection system which you will make in this course yeah you will make this course you will make this into the course okay so this is a problem statement and what's what's the let's fit that definition onto this problem here t is the detecting the emails means detecting whether the email is a spam or not so let's let's denote zero as uh detecting a spam or one as uh okay so let's say let's say ham and e is the experience of his prediction is the experience here e is the experience of detection and p is the performance how much performance increases upon to the experience so in this way higher the experience is best the system is but i think this is more formally fit to something called a reinforcement learning which will not see the advanced learning but again the definition which you have to take is you wanted to make a function of function f that maps your input variables to the output variable and that's machine learning and or you can say that's the beauty of machine learning okay so some of the applications of machine learning there is um i just listed on a few but there are a lot more selfdriving cars real estate stock price prediction and medical we have or corbin 19 detection maybe using chest radiographs and then uh disease prediction cancer detection etc and then it's just a boom and i highly encourage people to get into this field and try to contribute to the world in a unique way okay so you can see over here some some of the applications of machine learning so how it works so what you do uh let me get to get back to my boat and how it actually works all this how it works it's kind of a very easy how it works uh first you study a problem so again let's let's take a problem let's take a problem of again a spam detection spam detection detection system okay i i think the c okay so to make a span detection system so first you study problem you have a look at the data how actually the data is okay so first you do this the second thing is the basic workflow the second thing you train the algorithm and algorithm is just a function it's just a function okay f of x which you will uh how it is defined which you'll see later on but you just have a function which is algorithm this is this is the algorithm algorithm and you train with this algorithm and then you go further into evaluation evaluation you evaluate it into uh you give a new train new emails and check which is correcting for correct or not and then if it is good then you launch the system then you launch the system launch the system otherwise otherwise you analyze some error you do error analysis you do error analysis and then you go further into tuning or improving your algorithm or evaluating your uh and then you evaluate then again do that do like this so that's what machine learning is called ml is very very iterative process iterative process which you will see in more and more loops why this term that but but if beginner don't worry about it okay but if you want to get it after this course you can get to my gans course or maybe the deep learning course or uh maybe another course which is dsa which which i'll talk about that is very important and then you can head over to the ml oops videos okay so this is the basic you can you can head over to that and learn something new from there okay so uh what are the types of machine learning systems since there are uh i think the three types of main main machine learning systems are three types supervised unsupervised reinforcement learning and although there is few more which is batch learning transfer learning active learning passive learning and etc which you which you can learn obviously when you go further no when you go further means into more into machine learning then you will see that uh how you are learning these all and you learn to grasp each and every content a few minutes okay so what are supervised learning supervised learning uh let's let's let's go get back to my boat again and let's take an example of another example which is my favorite uh no not not my favorite but yeah it's a house price prediction so i'm just providing about house price prediction prediction problem registry system okay so this is a house price prediction so you have a feature uh let's let's let's denote that on the basis of the size of the house size of the house i'm just taking example because in the real world the size of the house thus the fan number of fans in the house number of bedrooms in the house on the base of the butt just for now uh for predicting this from the size of the house you want to predict the price of the house you want to predict the price of the house which is which we denote as a y and whatever we give whatever we take as a feature we denote this as a x okay so there is uh we denote there is only one one feature which is x1 and only we are getting a one output which is y okay so uh we have we provide x1 means the size of the house and we are getting the price of the house as an output okay so uh you can see over here that we have uh size and we have a label means we have given the price and the model can learn from this house the trend is how the trend is on it can recognize patterns okay so you can see over here that our data is labeled as a y means we know what our output so it learned from their label and input that's called the supervised learning how you can identify the problem is supervised because you see the target variable which is called the target this is called a target variable and this is called the features features or variables okay and the one we want to predict is called the target variable so we this is the features or variable so you see that there is a relationship between your input value x and the output value y input value x and output value y well i'm saying it has some relationship because you can see over that we are given the size of the house and going to predict the price of house so you can see over the entirety is that they have some kind of relationship and we know what our output should look like in this case we know what our our output should look like in reduction it's kind of a continuous output our output will be in continuous value so we know what our output should look like and that's called supervised learning okay so i think you i i think it's going good means you're understanding what i'm saying so in simple terms you can see the definition of a hill we feed the data and this the data are labeled means that the output variable which we denote as a y are labeled and which we give which has some relationship between our input value x and the output value y okay so in the unsupervised learning uh which which i'm not going to go to dig dive just now and further i will i will be digging dive into this so we the data are not labeled and we can say that we don't know what our output should look like and there is not kind of any relationship between what are what will be our input variable and what will be the our output variable and we have to recognize our patterns based on the data for doing so we have different algorithm which we'll study later okay so i'm just not digging digging type but in simple terms but in simple terms what i what i'm saying that let me let me tell you what i'm what i'm saying okay so uh let's say you this these are the tshirt sizing you want to you have a different different tshirts and we're denoting this as tshirt so we have a different different tshirt and what else and this is our data this is our data and you have to then you have to simply classify or cluster it out so whatever what your model will do it simply make this as a l it simply makes this as xl and simply mix as an m okay so it's just uh make clusters it makes cluster xl and l and for now i don't recommend to brainstorming these things because we will first we have to understand fully supervised learning then it will most much clear uh unsupervised learning so i don't want to dig dive into unsupervised learning for now but you can see what the definitions are cut to cut okay so let's start let's keep deep diving a little supervised learning so what are supervised learning so in supervised learning um we know our output variable and input variable etc that i would just explain your house price prediction so in supervised learning we have two types of problems the problems of supervised learning can be classified into two types so let me write it a supervised learning problem supervised learning problem can be classified into regression problem regression problem and it can be classified into classification problem classification problem okay so let's keep talking about what is regression what is classification so i'm gonna take take one example which is a house price prediction which is a house price prediction means house price prediction and we can see over here that our output will be in continuous value because super supervised learning and we know what our output is so you can see over that output will be in continuous value continuous value okay so your output is in continuous value and classification and in classification uh let's say given a picture x means the often uh you want to classify an image of a picture as a cat or a noncat or a noncat okay so um you're gonna picture x um you wanted to uh identify this as a cat or noncat okay so you can see here but that is a binary it has only two it is it is a it is called a degree value it is called the degree value means we can now classify that in regression if our output of the problem is in continuous value that's called that that's that's that is a regression problem if our output of the particular problem is in degree value we can classify that as a classification problem and you can see over here the definition is the same okay okay so why we need to divide our data so let's let let me talk about because i'm talking too much about data but what is data it's this question arrives a very good question that i want to ask by myself is data are the they how does data looks like in data let's say let's take an example of an application a system that is a price of the house house price predictor okay so the data will look like this so i'm just just making a data frame so you have a size of the house then you have a number of fans then you have a number of bedrooms then then is the target variable which is the price so these are your x these are your x and this is your y okay and what you do uh let's let's take nine square feet two to twenty two i'm just taking as a thousand et cetera just a thousand dollars i'm just taking as an example don't think that is a nine it's a nine square feet size of the house don't don't think like that okay so uh this this is kind of thing uh so this this is kind of thing and we have a size and we have a number of fans we have a number of bedrooms okay so uh what you do uh here you can see over here that we have a data we have your data and what you do you divide your data into training into training and testing set into test training and testing sets so let's say you have a hundred percent of data if you take 80 percent of your data for training or model and 20 of your data for testing the reason why you take this to evaluate your model because you from where you will get all those uh for testing so you just keep 20 20 for evaluating so check how how best your model is okay so this is the evaluation of the data which we'll see more later on okay so there are two problem that i want to highlight is uh overfitting and under fitting okay so what is overfilling so let's take an example again i just i just i just believe in examples okay so here is your x and y plane i hope that everyone remembers in in in their school days oops what is happens i hope that i drawn correctly okay so you have this uh these features let me draw it very quickly this is your data points and what you do uh you simply draw a straight line you simply draw a straight line to make predictions okay so let's this is your input which is x so it's a 2200 square feet so it will go over here and check what is the price so it will give here okay so like that it will make prediction which we'll see later on so you can see over here that in under fitting in underfitting and under fitting what happens if your model if your model has not performed well onto the training data as well as when testing data means in under fitting your model does not perform well under the training and the testing data means uh your model is performs bad under training and the testing data it means because you don't have a large number of in a large number for data you can you can simply add more data okay but what happens in under fitting can then you will tell me what happens in under fitting so let me highlight this little bit let me so in under fitting if your model has learned too much this is because when you have too much of features so let's say your uh it will try to touch each and every point it will try to touch each and every point and this is called and you can see if you if you have a if your model learned too much and it is generalizing very very well very very well onto the training data on the training data but it fails to generalize well fails to generalize well on testing data testing data then you can say that your model is overfitting okay so you can see over here that the diagram is over here and you can see with that under fitting which your does not feed a straight line a very good way and good fit is a good good good model you can just fit a straight line and in a bad fit over fit it okay so the solutions of this which you'll see later on but before that we'll touch some algorithms and again some notations which i've already taught you x means the input features x1 x2 all the way down to xn y means the output features m means the number of training examples and here let's say 600 training example which you will get to know more further which when when we will go more further into this course okay so now we are done with this uh introduction of machine learning and i really hope that you enjoyed this tutorial and in the next section we'll be talking about one of the algorithm which is linear regression and i hope that you will really enjoy that so let's meet at the next section okay so now we will briefly talk about supervised and unsupervised learning with adaptation and some cases studies and data sets so to fully understand what happens in supervised and unsupervised learning okay so let's start so uh what happens in supervised learning and supervised learning as the name suggests someone is supervising over here i will take an example of a data set to help you understand better okay so in supervised learning uh what i have told you in the in the previous session is about in machine learning that you uh in in supervised learning we make a function f of x that maps your input variable to the output variable okay so here in supervised learning we have the input data input data as well as the output data okay means here as an example that we have this data set we have this data set just assume that we have this data set and here we have this outlook feature temperature feature means x1 x2 then we have a humidity as x3 windy as x4 okay and here this the red one play tennis so here is our problem statement is given on these features outlook temperature and humidity and windy we have to predict whether the whether that boy will play tennis or not okay so this is your target variable this is your target variable or or the variable that you want to predict okay this is the target variable or the variable that we wanted to predict that we want to predict so it is given in this case so it is given in this case so here uh we have our x variable as well as y variable as well as the y okay as well as the y variable okay so we're going to make a function f of x using this data that maps our input value all these features x1 all the way onto x4 uh do a y variable okay so we'll give input whether there is sunny or whether you're hot or high or false and given on this feature the function will give you output whether it will play no or yes okay so here and this is a supervised learning problem because we have our so we have our labels which you can see over here okay so and you can also see that we have a some kind of relationship between our input value and our output value why as you can see that and these are there is there is some kind of relationship like a male stylistic example of house price prediction so given an input feature size you want to predict the price of the house of the house of the house so it is on a shame name so there is some kind of relationship between our input feature x and the output feature why okay another another property of supervised learning is that these features which are input features are our independent features our independent features are independent independent features what do i mean by independent features they do not have to depend on any and any feature they don't have to depend on any feature but this target variable y is a dependent feature because the target of y is depending on these features it's depending on these features to be mapped and is depending on these features so that's why x1 x1 x1 all the way down to the x i i equals to 1 all around to the k means x 1 x 2 x 3 x 4 is a independent feature which you call usually as an indian independent variable or feature and y is your a dependent variable or feature okay so that's the that's that's called the features um the supervised learning so let's um so let's let me write a basic definition or a good definition of supervised learning what what is supervised learning a good definition okay so the good definition of supervised learning is here in supervised learning we have we have our input features x we have our input we have our input features x we have our input feature x large x and just assume that x large x this contains all features in a vector all the way under the x i okay okay so we have input we have our input feature x and also we have our output feature y we have our output feature y output feature y y and there is some kind of there is some kind of relationship some kind of relationship between the input value x and the output value y and and x is called independent feature x x feature circle independent feature and y is the dependent feature because it is dependent on to the input features okay so we have seen here so show you an example that there is a y there is a y that is used to train uh using x okay this is that using x and y okay so we'll be able to uh predict our mod so we will see in the next section how we make a predictive model okay as a part of linear regression so let's see some of the so um but before that i want to i wanted to uh just to show you that there are two parts of supervised learning first one is a regression second one is classification classification so what do i mean by regression you know what your output will look like because here we know that what our output because we have already seen our data so you can see the output is in decreased value what do you mean by degrade value your output is in finite means either it will be yes or no so here if it is integrate value if you know that your output is in degree value then you then you then you consider that as a classification problem how you identify that is a classification problem when your output is in degree value and when your output is in continuous value means um it's not finite maybe the age of the person maybe the stock prices that is a that is continuous okay so that's why if your output is in continuous then it's a regression if your output is degree then it's a classification okay so let's see some of the applications of supervised learning to help you understand more better to get the feel of supervised learning so in supervised learning we have our favorite uh in supervised learning we have maybe the stock price prediction stock price prediction we are you are given closing price high closing high then etc maybe some volume and predict what is the stock price and on the maybe the you want to predict this you can consider c close as a target variable you want to predict what what with the closing price basis on high and volume okay so high in volume are your independent feature and c equals c will be your independent feature which will be the y next is maybe the house price prediction maybe you want to basis on the size like that you want to predict what will be the output why and maybe uh let's do example of a classification problem given you want to identify whether the person has a diabetes or not basis on maybe the age gender bmi etc okay so we have this output variable y okay so these are some of the applications of unsuper sorry supervised learning okay so now let's see so unsupervised learning as i'm not going to go deep dive into this uh unsupervised learning there is a next section that there is a particular section after supervised learning we will cover the in depth about unsupervised learning but the core idea behind unsupervised learning that in this case in supervised learning we are given x i as well as y i for uh for each uh for every i equals to 1 all the way down to the m and m here is the number of training examples means uh okay so that's m here is means we have for we are given i okay so here yeah in super supervised learning in supervised learning we have this in unsupervised learning the unsupervised learning we have only x i's we have only x i's we don't have y eyes you have only x i we have x1 x2 x3 all the way down to the xm okay we don't have the label y i there is no supervisor that will guide you okay and what you have to do let's take an example um you have you have this uh so uh here is your data set so here you have a channel reason fresh milk grocery frozen detergent and delicious so let's take an example that uh unfortunately is used in markets market segmentation segmenting your customers so you have these features and you don't have the whether the person with you what you do you just cluster the person which has similar nature you have you just clustered the person let's take an example that these person use used to eat milk these person used to that so you cluster this out you cluster this out okay then you can hand code it okay these person used to eat milk and then you can send promotion to these people or big deal another thing to these people so you can identify your business needs etc from these clusters either i'm not going to give deep dive into the application etc but i will go deep dive into the application everything but as of now i hope that you understood supervised learning in that okay so that's it for this uh just a small uh video on supervised learning and unsupervised learning and the next section we'll be starting with actually the math and then we'll leave dive into the machine learning the beauty of you will see the beauty of machine learning okay so let's meet at the next section till then do the problem sets so now we have seen an introduction to machine learning and i hope that you have really enjoyed that section now it's time for getting enhance your dirty into the maths now we will see some learning algorithms which is linear regression and then we will do one project which is boston hot springs prediction so i uh so i'm very excited to have your first learning algorithm in a toolkit so head over to the next section okay so now we will see one algorithm which is a linear regression which is a learning algorithm um as in the in our previous section we have seen a machine learning and an introduction to machine learning now we will see how to make that function f of x that maps that maps your input variable x to the output variable of i okay so before that i want to recall something which is in supervised learning in super advised learning we are we were having two types of problems first one is a regression problem the second one is classification problem as you might think okay so linear regression as you know as you can see from the term regression it's a regression algorithm so it's a regression algorithm that we'll study today okay in this section okay so let's recall what is regression it's it's a type it's it's a type of supervised learning and supervised learning algorithm and here we know our output will be in continuous value our output will be in continuous value means let's say let's let's take an example that you want to predict the price of the house let's say you want to predict the price of the house okay so you can see over here the output of this particular problem will be in continuous value we don't have any kind of decreased value so we can identify that this problem is based on to the uh regression problem okay so let's let's let's start see let's ski let's see how this algorithm works in much more detail so that you could get more intuition about and you can ace an interview on linear regression and also i'll be putting some entropy questions over you of what someone can ask you and what someone not okay so let's assume that we have a scattered data so let me make one x and y plane i hope that this is good pretty good and let me make that one okay so i'm just going to make the scatter data that looks like this okay so this is your data and let's take as a problem statement as like this let's take a problem statement which is predicting the price of the house based on the size of the house so let me write that predicting the price of the house predicting the price of the house and this is the end in rupees so price of the house based on the size of the house okay so you will give x which which will be the size of the house and you will get the y which will the price of the house okay okay so we have the scattered data and in x axis we have our size which is our input variable and in yaxis we have our price okay so what we do we fit a straight line we fit a straight in linear regression we fit a straight line like this we fit a straight line which is called the hypothesis which is called a hypothesis and uh regression term this is called the hypothesis which we'll see how we can compute the straight line so we make this straight line and you can see over here that after making the straight line we can make predictions so let's say that this is this is the size and based on this we are making the prediction like this onto the yaxis okay so and again let's say the prime let's say the size of the house is 2200 square feet then the price will be like this uh 2 22 000 etc so like like like this we are making predictions okay and you can see over here this line is little bit far away from the actual data point so that's the issue that that we'll see later on but you just construct a straight line that touches each that that closely touches each point or definitely that is closely uh uh passes through this tray uh scatter data points okay so let's see how we can compute the straight line because linear regression as you know linear means it constructs a linear line that separates the data okay okay so let's see how it works so in for making a straight line as i've already told you this is called the hypothesis so how we construct hypothesis so this is called the hypothesis function we compute hypothesis function like this we have weight of every features so let's say theta 0 times x 0 plus theta 1 theta 0 time times x 0 plus theta 1 times x 1 plus theta 2 times x 2 all the way down to the theta and times x n okay so you're summing it all up so what what i what what you can see over here that what you can see over here that we have the status and we have these features this is th this is the let's say the size of the house let's say this is the maybe the number of fans in the house i'm just taking the problem statement predicting the price of the house so so that's why number of a fans in the house and and etc okay so these are the features x1 x2 and x0 is the biased term is the biased term or the yintercept or the yintercept maybe if you know about interintercept of y means if x0 equals to 0 then your line will be crossing from the origin if x 0 equals to 1 then it will be from 1 if x 0 equals to 2 then it will be from 2. okay so it determines the y intercept from where he wants to make a straight line okay so we have this theta zero times x zero theta one times x one theta two times x two all the way on to theta x times x x n and let's take a particular problem statement and let's understand that but before that you may think hey use what is theta here what is theta here we only have to learn machine only have to learn this theta machine only have to get the best theta now we are able to make prediction now let's say we we take theta zero let's take we take theta zero to be uh uh two okay and theta one to be let's say three theta two to be four okay so just i'm taking only uh two features and one bias term which is the this this is the bias term and these are the two features and x zero is obvious is always equals to one x zero is always equals to one so that's why we never write x zero okay so that's why we never write we just write uh theta zero plus uh theta one times x one we did not write but i just just have showed you so for a clear ratio of those things okay so you can see over here that uh let's let's take an example that this we have two features like the size of the house and the number of fans on the basis of that you have to predict the price so for each feature we learned the weight these these are called the feature weights these are called the feature weights so we learned this and if we get the best feature weight we will getting the best prediction if we get the bad feature weight we'll be getting bad prediction okay so let's say uh let's let's construct the problem so let's say your theta 0 to be 2 times x 0 which is x where x 0 equals to 1 so it's obviously true plus theta 1 which is like let's say theta 1 is 3 as of the end times the size of the house plus the theta two before times the number of fans in the house okay so now this now using this you can make the prediction you can just plug in the size and you can plug in the number of fans and you will be getting your desired output why okay so just now you may think hey machine learning is not we are not it we are only using it as a computational power and you can see over here that how it how it learns theta will which we'll see because machine learning is totally based upon learning parameters okay so you will see how the theta is learned so let me tell you uh thetas we have to only learn theta we have to only learn which will see the techniques where we have to only learn theta we have to only learn theta and if the theta is bad then then you then your hypothesis when the function is bad so this is your function this this constructs your function like this theta one times x one plus theta two times x cubed all the way down to the theta n times x n and and here they denotes the number of features and features are the columns okay and the data okay so uh this is a function and you can use this function to map your input variable to your output variable y okay so that's it that's that's kind of our we have our kind of a function that maps our input variable to our output variable okay okay so now i think the twos that said that we've got how we construct that a straight line and using this function we can construct that a straight line and we have to only learn these these this this is called these are called the feature weights these are called the feature weights and these are called the feature weights and this is the bias term or the y intercept uh from where the the the line should originate as i've showed you earlier okay so uh now i hope that you got a intuition about hypothesis function okay so now let's keep talking about uh the vectorized form of this means the vectorized form is maybe vector vectorization means how here we are separately computing for each values we are computing theta zero then times x zero theta one times x 1 means separately for each value so in vectorization we do at once we do at once so what we do we put over all the thetas so we put our so i'm just writing vectorized form vectorized forum so we put our all theta we put our all theta it will be in joint vector theta and uh let me do this theta zero theta one theta two all the way down to theta and and theta these theta this is the feature vector this is the feature vector which can which is all the weights you will further see that yeah we have to only learn this then you will believe me that yeah we have only have to learn this whether it's a neural network but it's a machine learning okay so you have this base theta into joint vector theta and you take a giant vector x and you store all your x's over there x 0 x 1 x 2 x 3 all the way down to the xn okay so you take this and then you take out the dot product okay so then you take out the dot product and theta times dot product okay so now your hypothesis f of x will be like this okay so you just give this function and thetas what what it will do it will uh theta zero times x one theta one times x one it will sum sum it all up theta one theta two like like this broadcast it okay and it is computing at once okay so you can draw and then some sum it all up okay so so you can write in summation format i equals to 1 all the way down to the n or i equals 0 all the way around to the n theta theta i times x uh let's say i okay so so you are doing it's a vectorized form of that and you can see over here and python is very easy just one line of code uh like like this you just do like this np dot dot theta and x done okay so it's very easy in python so don't worry how how we can code this all it's quite easy okay so now we have seen the hypothesis and and we have seen the vectorized form of this linear regression okay so you may think hey i use how i can get this theta but before that how we can evaluate your theta is best means your thetas are good your theta are good so for evaluating our model we have something called cost function we have something called cost function okay so why we evaluate a model to check how are p if our theta is good or not okay so we check because using that theta we are making prediction we are multiplying with the features and we will get feature these the size we will get from the user we will this game fan number of fans get the user we multiply with the weights and then sum it all up and then we give the result okay so this is the cost function and here uh what why why we use cost function to evaluate our model okay so you you will get to know how what what we do so let's say uh we have a scatter plot so let me plot on a scatter plot like this again the same i'll be doing the same but this time little bit more crunchy yeah i think so okay so this is this is my plot and what we do we simply draw a straight line uh this this is your hypothesis this is your hypothesis which is f of x and what this cost function will do this is your this is your actual data point these are your actual data point and these these are your actual data point it will what it will simply do it will simply take out the distance between predicted this this is the predictor that i'm highlighting and this is the actual okay so this is the predicted this is the sorry this is the predicted and this is the actual this is the predicted this is actual okay so it takes out the difference between or the the it takes a distance between like like this predicted minus the actual value predicted minus the actual value like this uh yeah like this and and then sum it all up means higher the this uh cost function will be better or more or less higher the cost function will be better your moral will be and less the cost function will be good your moral will be the reason why if your if your points are on this line and your cost function will be zero because the predicted will be zero sorry let's say predicted will be all the same and actually will be also the same so it will be resulting in zero so just what what we do we this these are called the residuals in terms of uh cost function so we just take out the distance between predicted and actual value for all data points okay so this is the cost function okay so uh let's rest forward to formulate this in a formula let's formulate this is the foreign formula like this uh let me show you how we can formulate that yeah so you just take out of j of theta i'm just denoting j of theta will be like the uh short form of cost function because we are checking how our theta is good or bad or not okay because it only determines whether your model is good or bad 1 over m 1 over m and m here is the number of data points plus i equals to 1 all the way down to the m and you just model predicted value less let's denote the model predicted value by y hat and how how we have we got y hat yeah we have got y hat like this y hat equals to uh f of x equals to theta times x means dot product of theta and x which is equivalently equals to the hypothesis okay so we let's let's note as a y hat minus y okay and in other words we can write this out like this in other words we can write write this out like this theta transpose x i minus y i and this this is just a hypothesis h of x okay and transpose like this are you you your uh x will be like this so you make this uh theta will to be like this okay so it will be easier like this okay so this so that's what this transpose is doing but if you can do or not just just we are doing the this uh let me write that theta times x okay the dot product between theta and x minus y i okay minus y i for each and every day at a point we are taking out the difference between predicted and actual value and then we're squaring we had a squaring here because it helped us to and further call something called the gradient descent okay for easily derivation of this cost function you will see why i'm taking derivation term over here okay so in other words it's this this this this is called the loss function which is known as mean square error m s e okay which is called the mean square error if you square root this if you make this let me show you what i'm telling if you square root over 1 over m plus i equals to 1 all the way down to the m theta x i minus y i squared if you square root this like this okay this this is called the root mean square error root mean root mean squared error okay and higher this and better your model less okay okay that's just just we are taking the square root okay but we'll stick with this um mmc but in real world a million kaggle competition they have given what they're going to use mainly i have seen rmse to be used very much okay so uh after we got our cost function it tells okay your model is that good or that bad now if your modeling that how you can optimize or how how you can get optimal theta means best theta how you can get the optimal theta this is the great question to ask okay so how are you how you're going to get this optimal theta for getting that we have something called gradient decent something called a gradient decent algorithm gradient decent algorithm which is known as the optimization algorithm which is known as the optimization algorithm which will help us to get the best theta okay optimization algorithm okay so uh let's let's stick dive into this uh algorithm and let's understand how we go get this kind of thing so let's say our the visualization of the cost function will be like this okay just just for the sake of an example i'm visualizing like this okay so this is this is your cost function i'm just writing as a z of theta this is your cost function and now your cos cos here use is your theta where the cost function is very high okay so here is your theta okay so what gradient descent does it tweaks the theta means let's see your theta is zero then simply let's say it's mismakes theta little bit to 0.2 okay it tweaks the theta it changes theta a little bit and if the cost function decreases then updates the theta to be not like this to be like this if the theta go down means the cost function little bit decreases then it changes again 0.3 if the cost function decreases then it's do not make this then it's uh update this theta okay then again it simply tweaks checks if the j of theta going down if yes update the theta okay until and unless your cost function is until unless your cost function is approximately equal to zero okay so that is simply the gradient decent it's very very simple that i've just shown to you so let's let's further formulate this mathematically because it's very very simple when we formulate this as a mathematics so how we simply what what we do for tweaking these things for tweaking the theta we take out the partial derivative we take out the partial derivative of your cost function j of theta now you will think hey i use you have why why you have taken the calculus name i'm not a calculus student i'm not kind of that don't worry at all at all it's kind of it's i just want to give you one definition of a partial derivative partial what if what it does it simply tweaks your theta it simply tweaks your theta and checks if the cost function decreasing okay and it's just like the slope it's just like the slope but you don't need calculus you don't even need calculus yeah if you want to go on a research level then you obviously need but for now for a machine learning you don't need calculus for deep learning even you don't need calculus just um just you can just what what this equation is doing it is just it is just uh tweaking your theta tweaking your theta a little bit so it gives us like this two over m so it gives us two over m plus i equals to one all the way down to the m and this is a y hat minus y squared okay so this the after after deriving this partial we we get like this okay so now after this we do uh we do we take out the partial derivative for every theta means theta zero theta one theta two theta t all around the theta and we do for all theta we take out the partial derivative of all theta and then we up and then we update our theta so here is a full gradient decent algorithm so what what what we do we simply write theta z this is the update kind of assignments theta is a minus the learning rate alpha and the kind of a partial derivative of your okay partial derivative of your cost function okay so what we are doing this is how this this is uh this this is this will be our new theta that i've just shown to you we update the theta so this this is your old theta means the bad theta this is your learning rate and what rate your uh uh this is the hyper parameter which i will talk about in just one second in detail but what we are doing over here we are this this this the alpha determines the rate means if the alpha is too large if the alpha is too large it will go like this it will never converge it will be like diverging like like this if your theta is very small then i think that it will never converge at local minimum it will be like this it will never converge at local minimum so the optimal theta that i've used till now it's a 0.1 for larger data data set 0.01 for okay for a little bit to smaller medium data set 0.001 a little bit more smaller and 0.0001 okay so these these are the optimal uh for me i have seen so far is these alpha but you can tune it you can tune it using um grids or cv or randomized search cv which we will see later on okay okay so i i just say to you why by this theta it just determines the weight of your uh tweaking the parameter okay just going down and this this this gives this is the simply the partial derivative of your cost function and we are updating this this this will be our new theta and this is whole algorithm of gradient descent okay okay this this just just equations tells us the whole algorithm for gradient descent okay so now again i'm going to talk about uh vectorized bottom how we can vectorize this okay because i i totally believe in vectorization so let's tell what what what we can do uh here we are in the pre previously we are taking out the partial derivative of theta zero and then we are taking the partial derivative of theta 1 separately what we can do what we can do and we can simply put that into uh like like this partial derivative into a joint vector theta into a j of theta with respect to zero kind of this and like this all the way down to the n okay so you just put into the giant vector and you just take out the partial derivative of whatever you want to take out and then and then you just uh write the vectorized form theta z theta z minus the learning rate alpha and that gives us like like this 2 over m times the x transpose x theta x theta minus y and this is your new um derived equation which is a vectorized form okay and yeah yeah you can definitely use any any kind of this this is totally okay but for vectorization you can follow or not it's your opponent but for computational powers just just have told to you okay so we have seen so far and now we are done with this we have developed our linear regression model we first have developed the model from making predictions and then then we have moved further to check how our theta is good then we have seen how to how to get optimal theta okay but you may think ask here you see i have to do these kind of things yeah you have to do these these kind of things for getting your and and if i did if i say truth uh the truth is in scikit learn you can implement this in three lines of code you can implement this whole algorithm into three lines of code in some library but in programming assignments you have to implement from scratch this algorithm so that you can ace any kind of interview okay okay so um you may ask there is something called the normal equation there is something called normal equation that that i want to highlight little but normal equation gives you a better theta in just one way means normally patient gives you a theta optimal theta in just one equation like this so equation is x transpose x inverse of that x transpose y and for by you by using this and x here is the data points it means the features so you can simply use this uh formula for getting the for for getting your optimal theta okay this is just the same as doing this but not in every algorithm it will work it will only for linear regression the normal equation is only for linear regression and i hope but having a good intuition of all those because in interview they usually ask this they don't they usually talk about normal equation okay they don't all talk about normal equation the usual talk about this gradient descent etc although there are too many optimization algorithm some as like gradient descent in gradient descent we have this and then we have a stochastic gradient descent we have a stochastic which is called hdd we have a atom optimization algorithm we have rms prop rms prop and then gradient with momentum which we which you will see advanced level in uh i will talk about hdd pattern atom rm rms prop and some more optimization algorithm or convex optimization advanced as um which you will ever see in deep learning okay okay or you can head over to the newer of it and do deep learning courses currently learning and you can learn from there okay okay so now we are done with this and let's little bit let's literally spend some time on to some assumptions of a linear regression okay because in an interview they usually ask why you wanted to choose this algorithm instead of this algorithm or what is the assumptions of this algorithm etc so the sum of assumptions um of a linear regression if the issue it should have a lean linear relationship linear relationship the data should be linear the data should be linear and no or little multicollinearity the code the correlation between uh variables would be uh no nothing okay no or little multicollinearity multicollinearity okay you can see ac internet for more okay so now we have seen some assumptions but i want to just i want to give you the things what is independent and dependent feature independent means the size of the house the pro the number of fans and number of let's say the bedroom so these are the independent features because they are not independent to any feature for the kind of any value but the target variable y is dependent on all these features so that's why the target variable is called the independent sorry dependent and these are called independent okay so this is just a casual information to know because everyone talks about this okay so now i think that we have talked very very much in small amount of time and i hope that you really really enjoy this tutorial and i'm putting all my effort then you can go on to my youtube channel new era new era and you can subscribe that youtube channel if you want okay okay so um now we have talked that and in the next section i'm going to go over uh in theory pattern i'm going to go over polynomial regression but let's spend some more amount of if i have time let's spend two more minutes onto polynomial regression okay so there is something called a polynomial regression as we have seen the assumption that data should be linear but let's say our data is not linear then what we do okay then what we do so let's say your data will be like let's say your data is like this your data is like this your data is like this so you if you feel fit like this then it is obviously overfitting so what you do you just simply transform your data you simply transform your data to be like this into the quadratic form you enter the quadratic forum to be uh you just simply transform this one one degree to the two degrees so it will confirm like this okay so you two will be transformed as let's say four and six uh threes maybe transform that's a nine and whatever what whatever it was just so i'm taking an example okay so you transform your data to be fitting over the linear so you transform your data to be fitting over linear now your uh algorithm will be fitting like this okay so now i hope that you have gone everything about polynomial etc now we will talk about it we'll do some past and house class prediction and then we'll move on to the irregularized linear models okay so let's head over to the uh boston hospital prediction and then we'll move on to the regularized linear models okay so now we have seen linear regression and we have done one project now it's time for getting your hands dirty in the programming assignment you will be able to find the programming assignment description box below in the signin page okay so now we'll start with logistic regression after doing assignment come at the com come again and follow up with this course so now we'll talk about logistic regression and i hope that you will really enjoy this okay so now we have seen linear regression which is one of the regression algorithm now we will see one classification algorithm with this logistic regression don't worry uh don't think that this legislative question is a regression algorithm no it's a classification algorithm so because the name is logistic regression because the underlying working of this algorithm is same as is something similar to linear regression okay so you will get to know about this how it differs from linear regression okay so before that let's uh let's be clear about we are on the same page about close classification what is classification okay so this is a great question to ask to yourself what is classification so let's take an example given in range x you want to classify this image as a cat if it is cat then we will name it as zero if it is non cat then we will name it as a one okay so this is a tweet value our output is indicated value and the classification is a supervised learning approach so this algorithm is a supervised learning algorithm so here we know what our output should look like so here our output is in degree value so we can classify this as a classification task okay so that's the specification and something called the binary classification and we have a multiclass classification also called a multiclass classification means uh maybe the person has a cancer person has a pneumonia etc this means integrated value your output is in finite value value okay so we have this classification and uh this tool so now it's time to study about legit regression in detail and so what we do in legitimation we classify the data we classify the data so uh let's start with hypothesis in linear regression we have our hypothesis which is uh hfx let's stay known as h of x equals to the in legitimation we also do the same theta zero times x zero plus theta one times x one plus theta two times x two all the way down to the theta and times x n okay so in linear regression we are doing the same for drawing a straight line and here we are also doing the same for a function and this is and this this this will be uh for linear regression and the same for a legislation and this is the step this is the fourth step for hypothesis and the second step of hypothesis means the more predicted value equals to the sigmoid of h of x so let's denote this as a short form of z okay so this h of x is g and g here is simply h of x and h of x is here theta zero all over theta so we're gonna name it as a theta transverse x okay so you just here you just do the sigmoid of your head h of x which is which is your prediction function so you just do do the sigmoid of this z and you get your output and you get your output so let's say what the sigma does you get your output from legit logistic regression and this output makes the out this uh the this whatever the output came let's say 22 22 to between zero to one the sigmoid the if if you apply sigmoid to this you apply sigmoid to this then it then it makes your output between the range of zero and one and you then you set the threshold if and you set the threshold if you're the model particular y hat is greater than uh y hat is greater than 0.5 then yeah this picture is a cat okay otherwise if it's smaller than 0.5 then it is a non cat okay and this is what it is this is what we are doing in linear regression we are just this is this this was our hypothesis but in addition we add a sigmoid to our edge of x and the reason why we add sigmoid uh it's it's totally because uh that we want our output between zero and one in the range of zero and one so that we can make prediction like this so uh just you apply sigma and the formula for sigmoid is 1 over 1 plus e to the power minus z and z here is h of x okay so this this this will be your whole hypothesis this is your prediction function okay now you just put the z and theta you have to one learn theta you have to learn these thetas which is called the parameter it's again the same as a linear regression okay so what we are doing we are just uh doing the same as uh first the first step we are doing same as a linear regression and then we are applying a sigma at that h of x and then um we are getting the output which is the which is in the range of zero and one and uh we set a threshold 0.5 is a threshold and if the particular the model predicted y hat from this output between the range is greater than 0.5 then it is a cat otherwise with smaller than uh of 0.5 then it is a noncat if you want to be more uh strict then you can make 0.7 the probability is greater than 0 70 okay so let's say you're more output like this 0. 80 okay so it is equal to the eighty percent your model is saying that a particular uh this image is a eighty percent accurate that this is a cat okay so you just make it as a one round of two one means it is a cat otherwise if it is a 0.4 t then it's 40 that is so you make it as a noncount okay so this is the basic thing that you should understand is a prediction function that we have made and again we have to only learn these thetas um it means we have to get these tt three and these thetas together to get our good output okay so this this was a legit regression and then i and the hypothesis for legit regression okay okay so now in linear question we have seen something called the cost function something called as cost function and cost function simply what this does it simply gives you the accuracy of the model means if the cost function is very very high then then your model is very bad if your cost function is low then your uh then then then your model is good okay so it helps it help us to evaluate your model okay is the the loss function it should be all the cost budget for a good uh for a good model your j of theta means the cost function should be approximately equals to zero okay okay so uh in lecture expression we have defined little bit different this cost function like this uh let's do for one training example like this j of theta j of theta equals to minus 1 times y i the log of h of x i h of x sine plus 1 minus y i minus 1 minus y i log of 1 minus h of x i okay so this this is your cost function for for one training example and you can see over here that we have a cosplay one minus one times the y i times the log of h of x i and one minus y i uh times the log of one minus h of x time so what we are actually doing so let's break down this equation and let's understand step by step okay so what we are doing here we are doing why i is the grand route is the ground root ground with truth and h of x i h of x sign is your model predicted value which is the model predicted value and it's just taking the log of that your model and multiplying with the y i okay so let's say your y is equals to zero your y is equals to zero and your model predictor y hat is also equals to zero then your cost function will be approximately equal to zero because uh they both are same so your boss mentioned will be zero okay will be low if let's say your ground through this one and your model predicted is equals to the zero then this this is a mismatch your model done very bad so your cost function will be very very high okay so this is what the basic integration behind is cost function and this is your basic formula and again uh you can see over here that we do this uh kind of for oops what is okay so uh let let me write the equation for m training example we have done for one training example so let's do for m training example so let me write the equation for that so you have a j of theta you have a j of theta and 1 over m 1 over m i equals to 1 all the way down to the m y i log of h of x i plus 1 minus phi i the log of 1 minus h of x i okay so this is the log loss this is this some sometimes called as log loss in terms of machine learning so you just uh this this is your calls function that is used to uh use as a loss function that we have seen so far and i've given an example when the both the output is correct me on ground truth and your moderator is equals then your cost function will be zero otherwise is if it is different then your cost will be very very high okay so this is the cause function for your legitimacy model so let's recapitulate the two things the hypothesis and your fault cost function so the hypothesis is that h of x equals to the uh sigmoid of z and z here is theta transpose times x okay the dot product between transpose times x and you just uh take the it's the equation which is uh similarly equals to 1 over 1 plus e to the power minus c and z here is just a theta transpose x data transpose okay so uh the theta contains the parameter rates uh theta contains the parameter base and x contains the x one x x zero x one all the way to multiply okay and in y convention we are using x zero equals to one you can rewatch that uh linear regression section once more if you are getting a little bit confused because i have expect i've gone a little bit slow there okay okay so and the gradient isn't for getting the good for reducing this j of theta or for getting the good optimal parameter we use gradient decent algorithm and gradient reason why it does the same here is your theta we have the cost function very very high this is your cost function diagram so your cost function will be very very high when your theta is here when you change theta your a little bit decreases over here again you change again you change means you're taking out the gradient of your cost function and checking if it is going down if it is then you just update your parameter let's say theta 0 was here to be there i want to be here too then you update it out one to be little bit 2.1 then your costs and decreases then you do the same for getting into the global optimum over here okay like this okay so here's an equation for the same so how's the equation uh you just uh i'm doing it here theta is a for t is just means of taking out a partial derivative j of theta equals the one over m this this equation after deriving from cos function the decision equation forms i equals to 1 all around to the m x i minus y i okay and then you just add up some some kind of um x j times x j okay so this this is your calls function that's it this this is the taking of the partial deliberative although it might change a little bit because everyone has a different kind of uh but it's but it's similar to many of them okay and then you just take out the partial derivative of your cos function j of theta and then you uh update the theta by the by taking out the gradient then you update the data like this theta is a theta z minus the learning rate alpha and this is your uh this is your preprevious theta and this is a new theta is updated theta and you are taking another partial derivative of cos punch it and it's just the same you just tweaks your parameter and checks if your cost function is decreasing or not okay okay so we are done with the legislative question and i really hope that you enjoyed so let's recap recap and then a little bit go further into vectorization of this code okay so what we have seen we have seen hypothesis and hypothesis is given by the this sigma of z and is the simple 1 over 1 plus e to the power minus e and z here theta transpose to x okay and then what you do you have a cost function for getting the accuracy different model uh this j of theta which is equal to the minus one times y i the log of this is this is that using phi and and for m training example you have that and the gradient descent you just update the this where you just updated theta and theta say minus the learning rate alpha and is take out the partial derivative of your cost bunch of j of theta okay and the alpha here is simple the datum is the rate of learning that we have seen linear regression okay okay so we have seen so far and now it's time for getting into more detail about vectorization uh what's the vectorization means so factorization means is uh you just you hear you are taking some amount of time but if you want to do at once if you want to do all the calculation at once so here is a vectorized code for uh gram cost function okay so i'm right writing for cos function which is a vectorized code so here it is minus 1 over m times y transpose times the taking of the dot product between y transpose dot h plus 1 minus y t and transpose dot log of 1 minus h okay and h here is your model predicted and y here is a ground throughout okay and as we had just vectorized the code little bit to get your job done okay and a good way okay so the gradient descent also a little bit vectorized so here is a gradient descent theta this theta minus the learning uh this is a partial derivative uh learning rate alpha m times x transpose dot h minus y okay so this is then this is what you get after deriving your partial dedicative okay so this is the basic thing that's you should uh keep in mind about uh when performing legit regression and i really hope that you have enjoyed till now and now if you if you can see but let's summarize a little bit so that you can get a more better feel what we have seen so far okay so legislation is a classification algorithm that will classify our example um that will give the probability after you just apply the sigmoid to the z then you get the probability means in between zero and one you just get between zero and one and then what you do you simply uh take a threshold means if it is zero if it is the if your output is greater than 0.5 then you make it as a one otherwise you make it a zero okay as a convention we take one as a positive indication means that the the image as a as a cat is a positive indication and zero at the images are not cat then it's a negative indication okay you can take anything but for convention you do this kind of thing okay pretty much easy what i'm trying to say over here okay so we have the hypothesis and we have a cost function for a checking accuracy for modern we have a gradient reason for getting your best optimal theta and again we are only learning theta over here using the gradient descent algorithm okay so now i think we are done by the legislative regression and in the next section we will go over to uh project which is breast cancer detection system and then we'll go a little bit further into understanding the support vector machine okay and i really hope that you will enjoy that section also so let's meet at the next section okay so here i am on my jupyter notebook and you can download a jupiter notebook by searching online how to download the juba jupiter notebook and you can follow the tutorials to download a jupiter notebook okay so uh what we will do we will first start with uh important libraries then we will load the data we will understand what data we are working on and then we will follow the feature engineering then we will see how to select features we will do exploratory data analysis like data visualization and data analysis and will perform feature engineering and then before and then we'll see how to select the features on from the correlation of the features and you know you don't need to have any kind of experience with pandas or although you can have a look if you want to in detail but you don't have to be expert in all of these if you are just this is just a beginner project you can also modify it and put it on your resume and make make some changes and what you can do you can save this model and simply deploy it over a website okay okay so i will talk about deployment later on but before that uh let's let's walk through let let me make you walk through this project so first of all we are importing the libraries first we are importing the numpy snp and we are importing np as allies uh pandas as pd pde is also alive to short form a name plotly is another great visualization library but i really use it i don't want to use it for now but in future you can use it plotly just just wanted to show you i uh seaborn which i'm going to use here and mathplotlab is also a visualization library that i'm going to use over here and this macbook live in line tells you to use a matplotlib in the back end okay uh it's kind of a tell smart plot clip to choose the to plot the images in the backend use use the jupyter notebook as a backend okay so uh first of all uh this is the learning thing so we will load the data from the scikitlearn library scikitlearn library is a famous library for machine learning so we'll load the data sets from loadbuster which is a boston house price prediction will make boston house price prediction so you so we want a data set of that okay then we instantiate our load boston and then we take our x which is the data i will tell you what is x and y over here and y which is a load boston.target in our previous tutorials in the introduction to machine learning we have a talk about x and y variables x variables is the independent features which we which which we use to predict the model and this is the y which is the target variable because it's unsupervised so we know what our output is that we know what our output label y is okay so um we will be given this and x and y is the target variable which will be in case in this case is the sales price and this is the features okay and then i call pd.data frame and it con constructs a data frame and we give x which is the features and we give the name of the columns dot feature names there is a dot attribute feature names to get the names of the columns automatically okay and then we make one column here we are making one column which is a sale price we are making a sale price and then we are making it y over here okay ma why why means lord boston.target either you can make this also like this either you can make this also it's just the same okay y is just a target variable and if you just run this now you can see this is the data frame um here you have a crime rate per capita that let's see the column distribution so i just first see let me show you what we have done these are the x variable till s l stat these are the x variable and this this is the y variable that you use to predict and you may think yeah use 24.0 means 24.0 is the dollars is just the price of the house no the price of the house is given 20.0 thousand dollars okay so you can so just just just we will see the whole thing just a second okay so this is the data frame that we constructed okay so now let's take a look at what data we are working on so there are 506 rows and there are 30 numeric and categorical columns and with the median value attribute 14 which is our target variable here i'm giving given is a sale price name but you can give it a median value it's usually the target variable okay so here is the column name is the crime is the per capita rate then the proportion of the residential land proportion of a nonretail business which knocks age what's the proportion of average number of rooms per dwelling in stratfor you can wait over here and the last which is the favorite the target variable which is the median value of the which is the sales price in this case in a thousand dollars so 24 thousand dollars now you know your dream has gone out i think so okay so you're going to read it over here just just you can use dot d c e d e s e r because it is available in the cycle learn so you have this kind of thing to see the information about that data set but in real world we will work on real world data sets so you will see how uv download how we process etc okay so let's understand a little bit more about the data we look at the shape of the data which is 506 rows and 14 columns means rows and then columns then your dot input tells us the information of your data which is nonnull values means what are the data types and is there any null values into that null means missing values into that column okay and all the data sides are float what is the memory usage etc okay and let's uh dot describe will tell you the mean of that particular column the standard deviation the minimum 25 percent of that 70 percent max count etc okay so we had seen how what data we are working on these are the features which is the x variable and this is the target which is why which is a supervised learning problem as we can see over here okay okay so let's just take a look at the no you can use data dot is no dot sum and you can see over here that we have the 0 0 0 all the way and then we can plot a pair plot sns dot pair plot which will plot all the things which with respect to every feature so you can see over here that we are just plotting the pair plot uh you can see but if you we we do not get a lot of information from this pair plot because it's very kind of small and we cannot see what data is it is it pointing on etc okay so we have to definitely take care of that to do to check more uh visual visualization that i made okay just wait for a few seconds then it will show up okay so it's plots and we are unable to see this kind of thing and we are unable to see so it's very hard to see this so what what we do let's let's take out and let's just take all the inferences from the sales price this is which is the target variable let's do some analysis so we plot a distribution plot and you can see over here this is a little bit skewed we want it is we are we are seeing over here this positive skew but here we can add some transformation so what's the seek skewness and word sum could notice so here we have one point one zero eight zero nine eight and one point four nine five one nine seven which are which this this will help us to find out liars and outliers are those who are far away let's say that you are working on uh age okay so uh age is 20 uh 20 years old 50 years old but let's say 150 years this is the outliers okay these are the outliers okay those who are exceptional those were exceptions of the data frame okay so we have to take care of this but before that let's see some relationship with each and every column one you have taken two columns you can try different different columns so where there is a little bit crime there is the sale price is very high and there is a lot more crime there is sale prices very very low okay and what's the age you can also see and you can see over your 100 years old has been sold uh in a smaller rate and uh 20 years old has a little little bit higher ray and you can see see the data visualization over here okay and you can see over here that i've imported sci pi which is again that like numpy i'm just taking out the norm and the skewness so you just plot a distribution plot for seeing this kind of thing means uh for a normal distribution if you know what normal distribution you are just plotting the normal distribution and we and this is your actual this black line and you have this blue line so you have to transform it a little bit so your new which is uh two trend mean is 22.53 and sigma is 9.19 okay so these are some if you know what python you should know about these kind of for formatting etc okay and this is the qq plot which will help us to see the coordinate quantiles which is uh order values you can search more on the internet or go on wikipedia to learn more about this but to our main main focus will be this uh sales price means distribution plot okay so let's run this let's try let's add let's add a log let's let's uh transform our sale price to a little bit more accurate so now you can see over here that is his skewness is over now we have just applied a transformation over here log one p and it's now good okay to avoid outliers okay and this quadrant trial is also uh removed okay so data correlation what a correlation first of all correlation is the is a relation between features okay so if the if it is one then it is uh positive correlated then it's minus one very negatively correlated you can search more internet about it because it's not a statistics class so you see if the diagonal is one all the features are perfectly correlated okay so how do we select the features which are highly correlated okay the features how we select if we have taken the absolute value of the sale price and we are taking the highly correlated feature from this uh statement and there is 12 feature that we get that is highly highly correlated you can choose this but i'm not going to choose you can either delete the rest of the columns except these two all okay and let's just start with model building so you just employ important split and train test please simply from divide your data into training and testing means um let's say you have 80 of the data so sorry hundred percent it will take eighty percent for training and twenty percent for testing and use draw because you don't want x to be sales price and why to be the sales price okay and then you test size then the band random state will tell you the uh means every time you run the data should not be changed okay so if you run this now let's take a look at the shape 404 and 13 columns for training and furniture for testing and for them for labels and one and two labels okay so let's let's start with uh let me make one more little little bit more uh so that it should be clearly visible okay so you just uh import uh from scikitlearn which is a linear regression and you just instantiate it and then you fit the model x strain and y train which we have used for training and why training extreme are the these are the input and this is that by a target variable and then if you run this now it's instantiated now we can now we can make prediction okay so you can see over the actual label because we know we we know what y test is 0 because this actual label and this is the prediction which is 3.36 is a predicted value from the model and three point two one eight eight eight eight seven five eight two nine is etcetera is the is the actual value which is little bit uh different from this but it's um good for perform very very good in terms of linear regression as we have seen so far okay now if you want to check the accuracy for checking the accuracy we have seen a cost function you can run this and msc mean square error and let's say if you want to see msc there is 0.035 which is good and if you want to take out the rmse the square root you just npd or square root and you are getting the rmse so you can just print it out our msc okay and you have seen that it's pretty much good okay you will learn more about how we can improve this by using xgboost tagging boosting etc later on okay now we have done our full prediction project the code will be in uh my github which is in the description down box below there is a lot more project which which is available in computer vision natural language processing which you can take a look if you want to my projects okay so now i think i have not quoted just now because it will take a lot of time so i just wait and have done just annotated each and every line of statement okay so if you have any kind of prop in a search on internet because you have to master google to if you if you have encountered any kind of problem and in the next tutorial we'll be talking about regularized linear models which we'll talk about lasso and which which we'll also use in this uh to check uh as a last one regression and a ridge regression okay so let's let's get into the next uh section okay so now we have talked to talk talked about a linear regression and we have made one project now it's time for getting into the regularized linear models linear models okay so uh if you remember that we have a pointed out or some problem which is uh overfitting which is overfitting which we have pointed out earlier okay so how does overfitting happen let's say if your model has learned too much so let me draw one uh x and y plane and let me draw some data points okay so these these are the data points and let's see or you have a complex model which is a complex function which maps your input variable to output variable so you just uh make the complex function like this which is which is touching each and every line so let's say a new uh example comes in and it's making a bad prediction so you can see over here it learned too much onto the training data which are inner trained and it's it is it is very going bad it is it is uh not generalizing well onto the new examples okay so that's that's called overfitting if your model working better best 100 accuracy under training and working worse on the validation accuracy then your model is likely to fit overfitting okay so how it is cost let's you have a lot of features and you um let's say a thousand features and so it will learn obviously the complex functions and then it will perform very very bad okay so uh for that we have some solution and the solution are uh either uh you do reduce some features reduce some features uh reduce some features this is you can do this another thing is what you can do you can uh this is the same as like this regularization in simple terms regularization is just uh eliminating the features that are not useful okay so it is just equals to this so we give another name which is called the regularization so let's see some other regularization techniques so the first one is lasso regression so let's see a lasso regression so what is last regression last regression is a regularized linear models what we do we just add a simple term with a simple a regularization term at the at the end of the cost function let's say this this term lambda 1 over 2 i equals to 1 all the way down to the n theta squared i okay so you this is uh this is for a ridge regression this is for a ridge regression okay so this is for raised regression i will talk about lasso just just after this okay so just you add this at the end of the cost function so your now new cost function will become like this 1 over m plus i equals to 1 all the way down to the m uh theta transpose x i and this this is the model predicted minus y i squared plus your regularization term uh this one i equals to 1 all the way down to the n theta squared i okay so you can do like this now let's let's understand what is doing it is just let's say you have some features which is the let's say the size of the house let's say the price uh this is the number of fans number of bedrooms and a number of uh grass okay num number for grass so you can see whether this this this seems to be a less important feature so it will it will simply make the theta means the parameter feature means the feature weight of this column to be zero okay so it simply penalizes or closer and closer to zero in rich regression it makes the feature weights closer and closer to zero okay so what is doing it is whatever the less important features are is just penalizing the theta of that and the theta is the is used to make prediction and let's say theta times the number of graphs equals to prediction so let's see it's a very very very very small okay so it just penalizes your theta okay so that's a ridge regression is doing just penalizing or eliminating the or by how how it eliminating just making theta to be equal to zero okay but if a but in ridge regression it is it is making closer and closer to zero but in case of last regression it is simply it is in case of last regression in case of lasso regression i'm talking about lasso regression it's it's whatever the less important feature are it simply makes it simply eliminate it simply make the theta zero so whatever let's say theta times the number of a graph uh so theta equals zero zero times the let's say seven which is equal to zero so this feature says eliminate net so that's a lasso is very strict okay so these two and just just to use l2 norm um in in that case in range regression you are using l1 norm but in lasso you're using l two norm okay just adding the regularization term which is like this uh at the end of the cost function i equals to 1 all the way down to the n the absolute value i and one yeah there's this one okay okay so uh but one one more thing that you can see over here that we we do not penalize our theta zero which is the biased term which is only the bias term so we don't want to penalize this so we start with i goes to 1 so we start with i equals to 1 rather than starting with i 0 so we do separately of all the things okay so what what what we do we just uh take um we just start with the i equals to 1 all the way down to the j which is the theta we do we separately do zero okay uh and it's and i i think it's very clear let me make you clear what i'm saying i'm saying that you do let's say for theta zero j of theta zero you do separately this you do separately this without the regular regularization term without okay but uh for other other thetas one all the way around to the j you do you do at the regularization term at the end of the equation and then you separately update this also uh this theta zero and you separately update this theta 1 and you just take this as a gradient of this theta for theta 1 all the branches of j and this gradient this the gradient of this cos function theta 0 for updating your theta 0 and getting the best theta 0 okay so you do not want to penalize because only the bias term you don't want to penalize this okay so i think that is very clear to you and again for recap regularization is just penalizing or eliminating the less important features by making the parameter weights equals to zero okay now i hope that's pretty much clear now we hope that is very clear and in the next tutorial we'll be working on two uh uh last regression sorry uh largest regression which is the now we'll start with the specification uh which is which will cover logistic regression as a same as a linear regression but it's a classification not regression okay so let's uh i will be happy to see you in the next section okay so now we'll talk about a regularization order one other favorite topic that i like to talk on i will take around 10 to 15 minutes to complete something called as a regularization topic and i think this is one of the most important topic in machine learning or when maybe you go to deep learning okay so we learned about uh l1 arm l1 and l2 regularization which is often called a rich and lasso regularization and i hope that you will understand that and why what is a regularization so first of all this is the problem that should come into mind and what is and why regularization i think these two questions must be your first question over here so but before that i'm going to highlight one uh something called as overfitting and i think overfitting um you all know but just as uh just to those who are forgetting about it let's uh revisit that so uh let's assume that you have an x and y plane x in x here and y here okay and here is here you have a data point okay so you have a data point like this okay and you fit it and your model learns a lot your model learns a lot means your model is performing very very best on the training set let's take an example that it performs it is it is the the error the cost function over to here means that the residual error or the cost function over here will be approximately or very very low to zero and accuracy or on the training set will very very high because this tries to touch each and every point over here okay and here your cost function means the difference between your predicted and actual value um summation of i equals to 1 all around the m will be approximately equals to zero and if it is if it is if you if if it is touching each and every point so it's obvious that it is very very best onto the training set on which it is trained so it is it has learned a lot but let's for the sake of example some example come over here and some example come over here so what will happen your model will fail to generalize well under the testing set okay so that's why i'm telling that your model will fail to generalize well on testing set so you can assume that that this this this you can you can say that this this model is one overfitting because you find out that your model is performing a very very best on a training set and then if you evaluate it then you will see that your model is performing very very bad okay so that's the sign of overfitting so we we always wanted to reduce the overfitting so how we how can we reduce our overfilling we have something called as a regularization and how it happens it can happen if you have a lot of features a lot of features a lot of features or your polynomial degree is very high if you're using polynomial regression okay so the the measure for the problem is lots of features okay okay so now let's see uh how we can remove this uh how how we can prevent or how we can make our our model less prone to overfitting so some we have something called as regularization regularization will help you to eliminate to eliminate the features to eliminate the features which are less important so again i'm saying it will help you it will help you it will help you to eliminate to eliminate the features to eliminate the features which are which are which are less which are less helpful or contains less less information okay so it will eliminate that so that's how we that's how that's what the regularization is doing it is saying that if the feature is less important remove that okay or make the make their respective and make their respective hyper parameter to be equals to zero okay make the respective hyper parameter to be equal to zero means i make make the respective not a hyper primer make the respective theta to be zero so we will see we will see how what what it will do just just for as an example let's assume that it will help you to eliminate the features which are less helpful now let's see how how how it will do okay so let's assume let's assume that you're working on uh some problem which is house price prediction okay so so you're working on house price prediction and there you have some features so here you have x1 so maybe the size of the house my favorite size of the house okay then x2 is maybe your favorite the number of fans in a house number of fans in a house okay number of x3 maybe the number of bedrooms number of bedrooms maybe another feature maybe another feature number of uh maybe some fan no no fancies or well maybe acs okay air conditioners so here we have four features okay and let's uh now what we'll do so we so for each for each feature for each feature for each feature x1 x2 x3 x4 we'll be having some parameter weights we'll be having some parameter which like theta theta one times x one plus theta two times x two plus theta three times x three plus theta four times x four and you can see over here that we have this this is this called the hypothesis function so here these two only the these are the weights these these are the weights of these features and we only have to learn these weights by just tweaking it okay by just tweaking it tweaking means let's take an example i hope that you already seen a linear regression just as an overview that your theta was this equals to zero to two point one theta zero equals to two point one previously and you just take out the partial derivative of your cost function with respect to this theta and then you update the theta okay why and just see the linear regression part you all all will be very clear okay so here if you're if you're if you are being confused please go to linear regression part um you will be not able to further continue so please please go back and lay in your regression if you're not able to understand why what is theta and why it is okay so this theta is a wait for the feature and we can simply give let's take an example that our theta 1 is equals to 2 theta 2 equals to 4 theta 3 equals to 2 okay and theta 4 equals to 2 okay so we can simply multiply so these f these thetas to be learned okay so um our user will give input let's say the size of the house so two times size of the house maybe 24 square feet plus uh then num number of fans though so four times number of fans maybe four plus number of bedrooms two times because here we have theta three equals to two let's assume that the user given two plus uh two times two times uh maybe number of ac is equals to one okay and this the the this this is the y hat of your model so here you learned some weights you learned some weights and usually you do the same you have some parameter weights you have some parameter weights which you learn by by tweaking or by changing and taking a look if it is if you if your model is performing best and we just take out the partial derivative of our cost function with respect to this theta and then see if our if our cost function decreasing if it is then we update the new theta and then we update our old theta with the new theta okay so that's that's that's what we are doing over here and i hope that you are understanding what i'm trying to say over here so just for an um just for this intuitive example i hope that you understood what i'm trying to convey over here can i convey you over here okay so let's assume that you have this now uh let's assume that this number of uh like your model is overfilling okay so what you do in regularization you apply something called as uh rigid so let's see the ridge regression what it does rich regression rich regression okay so the the equation for this regression is just add is just add a regularization term at the end of the cost function okay at the end of the cost function so again here we have theta 0 also here we have oops what happens here we have theta 0 also here we have theta 0 times x 0 just a biased term because then x 0 is always equals to 1 okay so in the range of regression in ridge regression we add uh a regularization term so here here's what i'm here's what i mean so j of theta j of theta equals to 1 over m 1 over m plus 1 over m plus i equals to 1 all the way down to the m theta transpose theta transpose x i theta transpose x i minus y i squared plus i'm saying plus and here we have something called as learning rate and this is just alpha okay so don't assume that is the learning this is just alpha uh or you can say that someone can write it as a lambda okay so it is just a greek letter uh just within note okay so don't don't compare with that uh learning rate alpha do not compare here i've i will tell you i will tell you what is this what is what this alpha does 1 over 1 over 2 i equals to 1 all the way down to the m theta square i okay so here we have added a new uh a new regularization term a regularization term over here a regularization term over here so what is this so this is simply what it does it's simply it simply make it simply take the features which are which are less important and make that parameter weights closer and closer to zero okay so what do i mean with this so for an example let's let's assume let's assume that uh that you that the number of your model this you using the eq this using this equation this is the l1 norm the it is the l1 norm okay so let's assume sorry l2 norm this is l2 norm okay in ridge regression we have l2 norm and here it's simply penalizing your theta who is the very less important so let's assume that the number of ac or modern model find out that the number of ac is less important so what it will do so uh theta 4 our indicating the number of ac though theta 4 is the weight of our number of ac then it will make theta 4 to be to be closer and closer to 0 0.0001 okay so it penalizes your theta it penalizes your theta as it found as you as it found that your number of ac is less important so it penalizes your theta and whenever you are multiply with penalize penalize times the number of ac then it will be also very uh means low okay so that that just helps you to less prone to overfitting okay so it is not doing anything with your with your input value it is doing because if you multiply 0.0001 with whatever the number number feature it will be approximately zero points there is a reservation okay so like like that okay so what it does simply it simply eliminates or penalizes your theta value by just making closer and closer to zero okay so this is the l2 norm okay and here we have something called as alpha and alpha contains alpha contains how harsh or how strict to be on to the solent feature so let's assume that we have set up some alpha obviously we don't touch alpha inside learn but here let's assume that your alpha controls the strictness okay so if your alpha is large i think so if your alpha is large or lambda is large um some people may write this as a lambda also okay so don't uh don't be confused so if you had a lambda is large then it will make it it is making close and closer to zero now it will make theta four equals to zero fully zero okay so it simply eliminates it if you it's it is very strict if you keep this if it is very strict okay so it kit controls it controls the strictness but whatever i think okay but i think what i like to remember is controls the strictness okay so and here you can see that you are taking the l one norm and you are not taking off theta zero you are explicitly doing for theta zero because theta 0 is your bias term and you do not want to penalize your theta 0 theta 0 okay so we are not penalizing we are going from theta i equals to 1 all the way on to the m we are not going to i equals to 0 we are going to each and every theta okay so we are not so we are not uh going to uh theta zero so we explicitly do for theta zero and we it's explicitly between two and tweak our theta or we take out the derivative of our theta explicitly okay because we don't want to penalize our uh bias uh sorry it's uh our biased term okay so this is the rigid regression okay so we have something called as a lasso regression lasso regression lasso regression means lasso regression is very very it's it's it uses l1 norm instead of l2 norm it's just the same it's just the same it's also penalizes the theta value but what it will do i will tell you okay so theta 0 theta 0 equals to whatever your cost function will be i'm just putting 1 2 3 plus now i'm right regularized num writing the regularization term i equals to 1 all the way down to the m you're not penalizing again theta zero the norm of the norm of theta i okay so this this is what you and here you are taking the alpha norm okay so taking the norm you're taking the norm of your theta okay so here what if here you are applying the l1 norm so what it does if he if if the last regression is very strict just assume it's very strict whatever feature he finds whatever i'm saying i'm taking the gender as a he okay or whatever this this last regression finds whatever feature that less important he finds he will directly make that theta four to zero so here we assume here we taken theta four equals closer and closer to now then it lasso it will take a directly to zero okay so it is very harsh so the both have specific use cases okay so these are the this is called the l2 l1 norm and this is called the alpha norm okay so here we have started about a regularization in detail and i hope that you understood very very clearly and uh we have talked a lot and there is one more which is elastic net which you don't need to worry about now it's very kind of a just combination of both of them but it's not used in earth industry as we use this l1 and l2 norm okay so thank you for seeing this video about regularization and and you can head over to the next section to learn more about more about machine learning and completing this course okay so thank you for seeing this video head over to the next section okay so now we will talk about support vector machine in detail so that you could be more powerful in machine learning or you or you will be having a powerful algorithm in your toolkit of machine learning so support vector machine is a supervised learning and learning algorithm which is a both for classification and regression we have seen logistic regression and legislation is for classification and linear regression is for regression so support vector machine is for both which is classification which is classification and one more which is a regression task okay so regression task so support vector machine can be used in classification either your output and degree value or it can be used in continuous value okay okay so uh let's i will take diabetes support like the machine but before that uh let's uh let me tell you what we are going to study in this section so we start with the introduction of support vector machine then we'll go further into what svm do and then we'll talk about linear heart margin then we will typically go further into nonlinear specification and then we'll talk about empirical risk minimization and then a semi supervisor is transductive um svm and then we will talk about svr which is support vector regression okay and the next section we will do one project which is stock price prediction project okay okay so uh what is svm what actually svm does it's it's it's it's simply just what is like this so let me draw one x and y plane so here is my x and y plane i hope that's that's beautiful so here is my x and y plane and let let me make a linear data okay so here we have the one day data point and another data point is over here okay so we have like this and then we have this data okay so let's assume that that you're working on cat and a noncad uh brick off recognition system okay so you are working on cat and noncat recognition system so what actually svm does is here you can see over let's assume that white color is for cat images means the labels are cat and blue color let's take as a noncat okay so these are data and what svm does it makes its its constructor hyper hybrid plane it's construct a hyperplane like this let's construct a hyperplane like this okay and now whatever new point come on or beyond any here then then this example will be cat otherwise if something come here then it will be noncad okay so this is what svm does um but it's i will this is not the full procedure i will tell you but here what it does it simply construct a hybrid plane and two parallel hyperplane and uh one two parallel hyperplane two parallel hyperplane with this margin okay these are called the margin so it always tries to maximize that margin so it may sound a little bit kind of confusing so let's draw it again to let let let me show you once more time what actually it does okay so here is the white examples and here is your blue examples is it noncat and not cat so what it does is construct a hyper plane and a two two parallel hyper plane over here two parallel hyperplane like this okay so and this is called the margin this is called the margin and svm always tries to maximize this margin keeping away the nearest data point far away from the hypomaine what i've said it's very uh crucial to listen what i'm saying i'm saying that what svm does it simply construct a hyperplane and a two parallel hyperplane that separates the data point and at a maximum margin okay so it always wants to as we always wants to maximize that margin in such a way in such a way in such a way so that the nearest data point so that the nearest data point let's say x i is far away from the hyperplane this hyperplane okay it's far away from the hyperplane so that uh so that it would be easily so that whatever comes here then it would classify as an um as a knock as a non cat whatever comes here or here it will be classified as a cat okay and then and and what i'm saying that the nearest data point and the nearest data point is far it should should be the far away from the hyper plane here okay so it would be here so these are called the support vectors who are the nearest data point from the hyperplane okay and that is supported by these are the support vectors which supports this parallel hyperplane to separate this okay again this may sound a little bit unconfusing so let's revisit this again in a more detailed way so let's say uh let let's take another another example that we are building a person has a cancer or a noncancer i think malignant uh let's say a noncancer okay so you build uh x y plane so let's build one x and y plane and then you put uh this blue examples which is which indicates as a cancer and this white example which indicates is a noncancer okay so what is um does simply construct a hyper plane like this oops it simply construct a hyperplane and a two hybrid plane like this and a two hybrid plane and this is this is called the margin and it always tries to maximize this margin so that in such a way in such a way that the nearest data point is far away from the from the main hyperplane okay so you can see over here that this this is the nearest data point is far away so these are called the support vectors these are called the support vectors okay pretty much easy now i think that's is much clearer uh with that we have taken three examples now i think this is much clearer okay so it's me it may sounds you like it's just like a linear regression you have a linear data and you're just spitting a straight line with two hyperplanes what does this mean it obviously means like linear regression but if you come to the more in detail the data are not not linear okay the data never a linear so uh there are two kinds of svm there the first kind of is hard margin classification and soft margin classification okay so let's revis visit us a heart marching first and then we'll revisit uh soft margin okay okay so uh you here you can see over here all that uh this is just like a linear regression but wait for a few seconds few minutes then you will understand why it is not like cleaning your depression although it seems like that you could simply construct a straight line but equation and it's used for classification it's quite quite different okay okay so in it's called the linear svm the what we have seen is called a linear svm where we are constructing a simple hyperplane and separating two data points okay so what are hard margins hard margin means that we are not allowing any data point to come into that margin okay that's what the violating the hot margin so sorry highlighting the margin so we are not allowing any data point to violate that margin so in that way we end up being an overfilling or in that way we we very much um go we our our model is being started overfitted so let's see one of what i'm trying to say of here over over here so let's construct a hyper let's let's construct one x and y plane again so let me construct one x and y plane oops here is my x and y plane and let's uh let's just draw two data point again let me draw two data point like this okay and let's draw a white data point like this okay okay so and now what as we have got simply construct a straight line with two hyperplanes okay with this hyperplane okay so in hard margin we are not allowing any data point that generally of the it comes under in so we simply kind of do like this we simply kind of do means we simply uh minimize this margin like this so we are doing like this all it it is very strict hard margin is very strict hard margin is very strict the reason i'm saying is very strict because it does not allow any data point to come into that margin but in soft margin we allow some data points to violate that margin to avoid overfitting okay so that's what the soft margin and hard margin means hot margin which means we are not allowing any data point to come into that margin and soft production means we are allowing a little bit of data point to come in right between and the width is in the width of the margin this is the width of the margin is is is is uh is adjusted by c okay so if c is very very large then uh your fifth will be very very small like this okay it's let's say c equals to zero this is the margin my margin so this is my margin so let's say your c hundred c equals to hundred so your uh margin will be very very uh the width of the margin is is kind of a low means it's very slow kind of it's very small but if if if c equals to one then your the width of the margin will be very very large okay like like this so it's just kind of any it's kind of a very awkward thing that you can see over here but that's what the gun convention site okay so we have seen um this this kind of thing and maybe you will see sometimes c to be named as a lambda okay it's just it's just the same lambda and c are the same just as convention we give it a c as a name okay so let's just get now is you now you've got the overview of this hot margin and svm so we have seen a lot more things now it's time for getting into the little little mathematics which is how do we construct that hyperplane in linear regression we are just making the straight line and this is theta transpose x but this was our favorite equations like this theta zero times x zero and in uh logistic relation we are just doing the sigmoid of z so these are our hypothesis so this from this equation we are we were making our um straight line or maybe the sigma so uh what happens in case of a supported machine we have our hyper plane is diff our hyperplane should be is defined by w transpose x minus b equals to z this is the condition that our hyperplane should satisfy okay okay so what is this uh this w is our parameter weight is our parameter rate and this guy in linear question we have seen is theta and b is our a biased term which is in case of linear and logistic which is theta 0 okay so we have just just given our new name which is w and b okay and it's okay so we have made a w transpose x minus b and this is our hyperplane that we have made as w and b are the parameter weights okay so we have just just given a new name and transpose you all know linear algebra and this is w is a parameter vector okay so let's define some constraints in for heart margins so let's define some constraints for heart margin how hard margin make predictions okay so whatever whatever the output of your model minus w transpose x minus b is greater than or equals to one then anything on or above this margin will be regarded as one in this case it will be count okay why i'm seeing like this is let's see you have this straight line and you have this and you have the data point and one uh these two parallel lines and again here you have so whatever on this margin or above this margin is regarded as one means the positive attention so it is regarded it's a cap as you as you know okay and whatever below this is regarded as a zero okay as a noncat okay so let's let's let's write the equation for that and it's quite easy it's quite um remember rememberable like double transpose x minus v whatever on or beyond this margin this margin will be regarded as one whatever below this margin will be regarded as a zero okay as a negative attention so that is the heart margin constraints and that's that that's how we make predictions onto uh support vector machine okay pretty much clear what i'm trying to say over here okay so now let's dig dive into some a little bit more further into math is how it truly is it it is being constructed like this so let's say you had made a straight line and this um this margin you can see over here this these margin is is written by this hyperplane this the main hyperplane is written by double transpose x minus b and this margin is equals this margin is equals to 2 over the norm of w so to maximize this margin we wanted to minimize this monitor the minimizer w okay if we want to maximize this margin because svm always has to maximize this margin to maximize this margin we have to minimize this norm of w and this margin is written by two over the norm of w okay and so so as you have said that as we have always tried to maximize so uh that is written by the uh two over uh norm of w and to maximize that you want to minimize some hormone of w so we can write an objective function we can write of objective problem object like like like this the distance between two hyperplane the distance distance between two hyperplane two hyperplane is written by two over the norm of w so to maximize its margin we want to minimize the norm of w with sub subject to subject to y i double transpose x i minus b greater than or equals to one so what i have said so let's understand this equation a little bit more further what i have written over here so you for maximum you this is the minimizing means we want to minimize to maximize that margin with respect to y i which is your ground growth means actual label and this is your moral predicted value moral predicted value and you can show your if it is on or beyond this it will be one otherwise it will be zero so if y i is equals to your border predicted value then your cost function will be zero then your loss function will be zero otherwise if it is not equals to y then then your loss function will be very very high so you want to minimize this normal w to get the good predictions okay so we have started this and i really hope that you had understood the concept that i explained to you and we can write our false function in a hinge loss or i'm talking about some soft margin so we can write our soft margin like this so we can write uh the the loss function the cost function the loss function you can write our loss function like this uh 1 over n plus i'm going to each and every training examples max of max of 0 comma 1 minus y double transpose x i minus b plus the regularized section plus lambda over was times the norm of w straight okay so this is quite confusing a little bit but let me try to explain you in more detail way so you already can see we are we are going to each a restraining example but taking on the max and this is the hinge loss if you can see this is this is called the hinge loss if i will get into more detail about a hinge loss you can have some wikipedia pages for knowing about hinge loss okay and this is your model model predicted value y a y i and the ground this is your ground truth y i and this is your predicted value and this is the lambda times you can write it c also you can write c also because it it it help you to adjust the width of that margin so that's why it is a very very important hyper parameter okay and times the non of w squared okay okay so we are done with a kind of a more linear uh classifier we are lame your svm is linear classification so we have made our good loss function so we have made a prediction function and now it's okay we want to minimize the this norm of w to get the good predictions okay okay so yes yes we have seen only the linears svm so let's let me form firm formulate one example which is like this let me make one again x and y plane number and making too much x and y plane it's best to have a this kind of things okay so let me make one nonlinear classification like this okay so you have this kind of data and this kind of data and let me make the these white examples are the cat images and these white examples are non cat images so now if you can if you want to make the straight line you will be notable to do that means you're not able to um kind of classify it so it's very bad so what you have to do you have to make a nonlinear you have to do the nonlinear classification like this now it will be okay now it will be okay so svm also is also is very kind of powerful in nonlinear specification with something called as kernel trick it's something called as kernel trick so we will elaborate kernel trick in detail so let's start with kernel trick so what what we do in kernel tricks so let me write an algorithm so what you do you write an algorithm in terms of x you write the inner product let's say let me write you write an algorithm you write an algorithm in terms of the inner product of x and z and the these x and z are two data points are two data points so what you do let me tell you what what what we do in normal in a classification we take our data we take our data x and we transform our data to a some more let's say we have um one dimension data to a two dimensional data and nonlinear specification okay so we transform our data to be from onedimensional to twodimensional like like this which okay so we write an algorithm in the form of x and z and x and z are the data points so in simply in kernel trick we transform our data to from one dimensional to higher dimensional space so you will get to know what what we are doing so let's uh let me write the steps so after uh we have written our algorithm in terms of the inner product of x and z now what's what we do we map our input input and this x without i write we map our input x to the phi of x okay to the phi of x so we are just i will tell you what this function is because okay so we write our function we map out x to the phi of x i will tell you what what we do in this case so we we find a way to map our this we find if we find a function so we map our x to the phi of x so we write a function or a final way we find our way so we find the x to be some uh phi of x and it will transform your onedimensional data to the uh maybe and then any kind of your data to be the high dimensional one okay so you write up her you write the function at k we transform a data the phi of x transpose that times the uh phi of z okay so let's see what it does with that help an example and then what we do we replace our x and z with our transformed theta which is phi of x and z to be the beta phi of z okay so this is what we do so let's see um some how what is just and and what faced us so we write uh the kernel functions are one of the famous kernel is rbf kernel that will transform your data excels into the high dimensional space so the kernel function is written by the rv of kernel function written by k of x comma z exponent of minus norm of x minus z squared over 2 over the sigma squared okay and the x and z are the data points okay great and some more kernels are which is polynomial homogeneous polynomial inhomogeneous which you can search on internet but the most famous one is rbf kernel which is widely used in the end of stream okay okay so we have seen various kind of things and about kernel trick how we do the nonlinear the transforming data you're able to do the nonlinear classification so here are some we will discuss one two kind of one primal problem which will help us to state our optimization objective and then we will see the sub gradient okay so uh why why i'm talking about primal problem it will help you to form formalize your objective function so it will help you to formalize your objective function so it's just the same just as written we write that so for each i for each i be the member of one two all the round to the n we introduce a new variable zeta we introduce a new variable zeta where zeta i where is equal to the max of zero comma one minus yi so we introduce a new variable zeta i zero comma one minus y i okay and then in that we write w transpose x minus b okay so this is just a hinge loss where we introduce a new variable that hence ross is a story okay right image you see what i'm trying to say here okay so then we write our function like this you want to minimize you want to minimize 1 over n i equals to 1 all the way down to the end zeta i plus the the regular regularization term c the norm of w is great okay with respect to r is subject to subject to y i double transpose x minus b greater than or equal to 1 minus the zeta i time um is just a where zeta i is greater than or equal to b for all i okay so we have just formulated one problem it is just equal to the hinge loss that we have seen we want to minimize the objective function that we have seen so far is just equal to that so we have formulated in such a way that you can use this okay so we have a object objective function which is our cost function now we can now sum something called a sub gradient something called as sub gradient descent and which what we do we we make a convex function f of w and b we take out the sub gradient of our of of our function we sub take out the sub gradient of our cos function and then we update our parameter w and b okay and that's the sub as the gradient descent what what we are doing okay so it's little bit different than gradient descent here we are taking the sub gradient of our cos function okay so this is what we are doing this is called the primal problem and then we uh with this we we take out the sub gradient of that primal problem okay pretty much easy what i'm trying to say over here okay so one more thing that the that is very popular among beginners are learning theory something known as empirical risk minimization what do you mean by empirical risk minimization given you're given the input x1 x2 all the way down to the xn you want to and you and given y1 all the way down to the yn you want your output you want your output you want your output yn plus 1 given xm plus 1. so it's just the same you give a function x and you want your output y okay and your and the loss and the getting the getting the error should be minimized means the risk should be minimized so that's the empirical risk minimization which we have already seen so we just have to know the definition for itself what is this okay okay so um ss we have talked about nonlinear and linear now it's time for getting into this uh support vector regression uh i'm just going to give you the equations okay it will it will all it will it is kind of a quite easy you want to minimize your one over two the norm of w is great you want to minimize this to get your output with respect to or subject to the y i the absolute value of y i minus the inner product of w and x i hence p times b and it should be greater than or equal to the sum epsilon and epsilon be the smallest positive in teaser okay so just to uh be comfortable into that so i hope that is quite clear and this this is for regression task okay and we will see the implementation in our next section so i hope that you really enjoyed this tutorial this section and we will be carrying out this more more into detail now we have gone too much into math but if you haven't understood any anyone please feel free to put a comment uh put your comment in the comment box i'll be very very happy to take your comment and and provide your answers over there i'll i will be uh taking taking a look at the questions and we will be answering soon at that point just put the timestamp where you're commenting okay so that i could know where you have a problem okay so i think that's how we have gone in too much detail if you haven't understood grammar problems or gradient don't worry it is not required for a beginner machine learning so if you have if you if you learn too much in machine learning and bonus deploying now you can come back to this primal problem to understand what i'm saying but it's quite easy to understand that the kernel trick what i said etc okay so thank you for seeing this video sorry thank you for seeing this section i'll be catching up here in the next section uh till then you can do the programming assignment okay i'll be catching up your next section will be making one project which is stock price predictor okay thank you so now we will make a stock price predictor which is our endtoend machine learning project and here's a demo and you can see over here that i have to use you can just remove the i will show you where i have taken all those things just so i do i'm not a web developer but i had made a good front end of this and also i made a back end using flask okay so we will code as i made a stock price predictor and i will show you how you can uh build the same website like me and you can also uh make a beautify if you're a web developer okay so here is my um here's my jupiter notebook and here first of all i'm going to download the data from yahoo finance and you can simply pip install live finance i've already installed that you can install that so you just want to import first of all the basic libraries let me do that so first of all you want to import the basic libraries like this uh first of all i will import numpy as np then i will import pandas as tv and then i will import matplotlib and i'll implode import matplot left dot pi plot as plt then uh with that i'm going to import the c bar because i'm going to use seaborn now in this case as a visualization library so numpy is a scientific library pandas is they're working with the data the seaborn is an uh visualization library and matplotlib is also a visualization library okay oh and one more thing that i want to import is uh for my data for my data which is import y finance as y f okay as y f and y f is just allies given to that okay let me run this out and yeah i can to add this is optional but i can to add over here like this mat block level line matplotlib inline okay now it should work fine okay so we had done with importation of our uh all the libraries and now it's time for getting in a little bit more uh detail about the data how we can load our data so first of all i'm i'm just going to use um i just want to i'm in this project i will make a stock price predictor of natural gas okay and you can do any of like gold silver just go head over to the yahoo finance just head over to the ua yahoo finance and just head over to that and just to search whatever let's say i want to go for gold so if you go over gold then you will see over here that you have a gc equals to f which is the code of that okay so you just take take copy the code and here's just uh i will just show you how what you can do first of all i will take input i will take input which is enter the code of this talk enter the code of this talk to download enter the code of the stock to download okay now it will take an input now i will just uh make a variable now i'll just make a variable yf dot download and it will take off the code from the stocks okay and it will download from uh it will download from let's say 2008 it will download from 2008 in january to one till uh it will down it download till two two two zero two one till uh zero let's say let's a two let's say one and tell 18. okay so this is the favorite thing and now what you can do we can simply do this kind of thing and let me run this and let's ask the code of this talk okay so you just give the code of the stock so let me give the natural gas equals to f this is the code so it will download a stock like this and then it will simply tell you the data how this looks okay now if you can see see over here that you have open high low close adjust and close and volume okay so one more and one more thing that studies that you can do you can write auto adjust or to adjust equals to true what it does is adjust your uh all of the kind of data frame and then you can see over here like this okay so that's what it's doing till now okay so we are done with this now it's time for getting into a little bit more detail about uh now we have loaded the data now let's take a look at the shape of the data like that so data dot shape and would tell us that we have a total of thousand two hundred fifty six uh training examples and five columns including date one two three four uh three two four five we have five columns and uh information about the data you can take a look we have a nonnull values we have this we have that was the data type you can also take a look at the mean standard deviation maximum minimum of all the stuff so let me do that okay so you just uh see this and now you can see that you have a all of the count the minimum mean standard deviation minimum 25 and etc okay now if you wanted to take a look at the now we are done with data exploration now let's literally go further into how it uh because stock price prediction is very very nonlinear okay but uh one thing that i want to mention over here they do not use it for personal purposes it's only for educational purposes okay only for uh educational purposes the reason why it's very nonlinear and you can't uh and then you and you can't depend on your algorithm to to simply predict the output okay our other good it's it it may give you uh the wrong output i don't know about this very very nonlinear so be sure to do not use it just for educational purposes not working company you're just making a simple project so that you could get a concept of how you implement how the process hold looks like okay so don't immediate by yourself um kind of a use in yourself and do not kind of make a website like that do not it is only for educational purposes okay now if you are done with this now we can analyze our data now if you followed an an analyzer with data you can write this close dot plot you can just plot it out and now it will look like this oops you can fix size let's say i'm just want to make it 10 7 and we have this and here our target variable is close okay our target variable is closed and uh means we it will just tell you the direction of the stock let's say if the close is very high then your direction of a stock is very high means it will close will very high so here's very nonlinear so it just starts with 2008 in very low way and gets up up in 2009 then gone drastically down in 2010 and then um kind of that so you can see the nonlinearity like this so it's very very nonlinear it's not uh you can you can depend on this algorithm or this predictor to predict your output in a good way okay so now now i think that we are done with everything now let me see what i have to do okay now let's take a look at that this how we can plot the distribution plot what's the distribution plot of our open then what's the distribution plot our close okay so it will give us a more feel how we are proceeding with our data or it will help us to choose the algorithm okay so here's the thing that i wanted to mention so first of all um just i'm going to use as c bar and just i'm going to use seaborn and then here i'm going to name as uh data i just want to name it as data and i'm going to put over here uh this open let's say close okay so we will see if this is normally if this is nonlinear etc to take a little bit more field okay so you can see it's a little bit non uh it's just it's a nonnormally distributed okay so you can apply and lock transformation that's called feature engineering but that does not work well in this case so we should leave like this and then we will take a look at this plot and then if you wanted to take a look at the open then you will again see it's again normally disputed now you can do the same for other other things to get the feel of what we are doing let's say we are we have done for high so we are done for high and if you take a look at the highs also like there's a sweet okay so we are done uh we are done with you can you can play with the data visualization and it say take out the inferences about the data and about the data inferences okay now we have understood the data what we have understood okay let's write the conclusion what we have understood till now so we have understood the first and first foremost is the shape of the data shape of the data and then we have understood the uh how a data is distributed how our data is distributed our data is distributed then we have understood that then we have understood how our uh it's it's very very nonlinear it's very very nonlinear okay so you can't cannot use for own purpose maybe you can use deep learning architectures like lstm to get the direction of your stocks and let's say if you uh maybe the 99 95 percent that works correct or remember 80 works correct maybe 725 works correct uh so you can just turn down do not use linear regression or any kind of things to make your own use but definitely in future let's see what the research comes with uh for stock price predictor because stock price prediction is also competitive uh project to work on because it's very very nonlinear okay so we are done with this and now it's time for we have started how much algorithm you have started linear we have started linear then we have studied logistic then we have studied some regularized linear models regularized linear models then we have a started support vector machine then we have studied principle combat analysis which will study uh which we have not studied so we will study principle common analysis and then furthermore okay so we will use support vector machine we will use support vector machine uh but we will see that linear regression and regularized linear models works best in this case and we will go with our saving the model of regularized linear model okay so let's start with linear regression before that let's split our data into x and y and then the training and testing set so here i am um just i'm going to x so i like my convention so i'm just going to make it like this and our x variable will be all the except close so i'm just going to remove this and then an axis number one and then y equals to data and then y equals data dot drop i'm not saying we will not drop it we will just simply keep the close okay now if yeah we we are done with this now x and y data to drop close x now we are done now what what we can do we can simply uh import more uh kind of a moral selection uh which is trained to split we'll import one thing which is train to split which let's say you want to split your data let's you have 100 of data so you will uh split your data 80 for training and 20 for testing to validate your model okay so here i'm doing what i'm see you can see over here we have a x train x test and y train y test okay so this is the you can make the variable and all the training elements the labels of x train will be in y train and label of x test will be in y test like this okay now if you now you have just give x and y and just give the size of that uh test set which is let's say give the 20 percent means you just want to use 20 20 percent of your whole data for testing then you want to do this random state and you may think hey you schwarz run random stage does it simply uh let's say if you if you run it one more time then your data will not be changed to your shuffle because shuffles also so your data will be not changed okay so we will take a look at the shapes of that so that we can get a more feel what we are doing so you could understand what to whom we are working with uh let me just copy and paste one over here and just gonna to make it like this and then i'm just going to make it wide swing and this one by test okay and just meant to make it a little bit more detail okay when you run this you can you can see over here that you have a two thousand six hundred four and four columns and the fifth column is two two thousand uh this the labels of y okay so that's the thing and now what we can do we can go further and we have taken the close as our target variable which will tell us the direction of our stock stocks okay okay so now we are done with splitting now it's time for getting into a little bit more depth is uh modeling part means we are going to first of all i'm going to import the linear regression because everyone thinks linear regression is very bad but let me tell you it's very powerful algorithm when it comes to linearity but here we don't have a linearity but still it works best when you apply your polynomial saturated question okay but let's uh keep let's use the logistics or linear regression and you can see over here that this is a regression problem and so supervised learning problem so we cannot use logistic it will be very very bad for us okay so just i'm going to instantiate just i'm going to instantiate instantiate and i'm just going to call lr.fit and i'm just going to give xtrain and the labels y train which is the labels of xray okay the predict one means i'm going to use that lr which is train model to predict my x test okay now if i run this now if you see the predicted output you can see over here that the uh let's see the first training example so you can see over here oops this y test now so you can see over 2.918 and the predicted is 2.90 and the actual value is 2.918 okay see that things that that is over here this quite uh it's quite very very good because you can see away that's quite working very very good and yeah linear regression works out best but it may happen that may overfit your data but let's see let's calculate a matrix so we are going to use some matrix which is m a we are going to use m a which is uh sorry mse which is a mean square adder which is a mean squared error which we have talked about the cost function for linear regression then we are going to use uh then we are going to use uh rmse and simply is it does simply the square root of a square root of mean square error and then what you do here and then we will calculate the r2 square okay and you can see if you want to get into mathematically we'll we'll talk about some matrices matrix later on but you know the best output of r2 if your model giving output r2 equals to 1.0 then you have a very bad sorry good model and it's a good model if if it's giving good okay so we'll see how much hour r2 etc so i will write one helper function like this we'll write one helper function calculate matrices i'll just write a matrix and then it simply takes the actual value which is a grand truth and it simply strikes the predicted value of your model to calculate and then first of all i'm going to calculate the mse and it's just uh first of all i have to import because you can also make your own function but it's better to use vectorized or cyclone because it's already provided to you but you know it's very kind of easy if you wanted to define msc so you just write and define msc and just take the sum of everyday data point and the residuals and then just square them up and then like that you can do that we have already i think your area have implemented programming assignments okay so you can just to make it import uh let's say oops i don't want to i just want to import the matrix and i'm going to import uh mse and mean square error obviously we do have mean absolute error which you can also use but for now i'm going to use this but by the way we don't have rmse we have to code rmse buyers by ourselves okay we only have r2 squared so first of all let's uh do this kind of thing means being a square giving the for our parameters y test and y and wipe fret and then rmstn you may think here use how how you can calculate the root mean square error just write np dot square root is just taking the square root of mse okay that's easy so r2 score which is r2 scores i'm just now on the right is doing a spelling wrong because maybe it will cause some error if you have a reserved keyword or like that's function okay so you have r2 squared and then uh score and now you just give y test and now you just give y test sorry yeah y test and wipe red okay and these are white as in white red are just so let me write that what is this so why test is your ground truth is your ground truth is your ground truth and why fret why pred is your moral predicted value okay moral predicted predicted value oops i'm i think that i'm doing it wrong uh you can see the spelling okay okay so we are now whatever what i will do i'll just print it out msc then i will print rmse then i will print rmsc then i will print r2 okay r2 is coarse okay and this i'm just gonna to msc uh just going to make it mse like this and here also i'm going to make it rmsc okay and here also i'm going to make r2 square r2 score sorry score it's score okay now i think that it should work now we are done now if you wanted to now we are done with helper function now if you want to calculate the matrix so you where we will just calculate the for a linear regression so we would just give a y test which is our ground truth which i have made while splitting out data now we will make a y prediction y prediction and sorry it's a prediction one uh that that we have made in linear regression predicted okay so you can see the msc is equal equals to zero means approximately equal to zero is quite good because in cost function your cost function should be very very approximately equal to zero your root mean square is also and your r two is zero point nine nine nine this is approximately equals to 1.0 okay so it's quite good linear regression performs quite good okay now let's a little bit let me go go further into uh some regularized linear models like rich and lasso so let's use that from sklearn sklearn dot model sorry linear models linear model i'm just going to import lasso and you if you know if your name may know about this lasso and rich lasso what it's doing simply eliminates the less important features simply eliminates the less important features and rich is just penalizes your less important features okay so now let's uh make the two of them so let's say la as a lasso so i'm just going to fit it over like this is a short form giving the x train and y train is a short form for doing that and then i will do for the same for a rich i'm just going to go for the ridge and it just fits the same thing and oops i should give it r a i think r i l a p i'll just go l a p is the lasso predicted value and then i'm l a x test okay and here also i'm just going to make r r i p equals to r i dot predict and i'm just going to give x test let's run this now we are done now if you want to take a look let's first take a look at the lasso what lasso performs l a first of all we are going to give the ground truth which is y test and then we will gonna give the lap now it's quite uh not good it's zero point it's quite not good because simply it's very strict it simply eliminates so but it's you're you're with lasso your modal in your model is less prone to overfitting but here you can see if i take a look at the rich it's quite uh for now it's quite good because uh it is also a regularization now it's quite a similar to linear regression but this is less prone to overfitting okay it's less prone to overfitting so we are going to use uh rich regression to save our model and build a website under this okay so one one more thing that i want to mention over here that we can use support vector machine i mean support vector regression uh for this task so let's see how we can make this kind of thing so let's let me uh svm so you can just and i think that the portable machine will not work well but it should work well if you have a lot of features like index voltage and then we have a different different features which contain different different uh importance okay so i'm just going to import and here you can obviously will not use it but here you will learn how to so how to do the fine tuning of any other model using grid source cv okay so dot model selection and just going to import the grid source cv okay first of all i'm going to instantiate svr and that is just going to um i'm just going to make it params and then and then i'm going to make it params and then here i'm going to make it c to be uh maybe and c is just a lambda which will tell us the width of your margin so i'm just going to copy it out this i'm just going to write it from my there i've already written over there it's just i'm going to write it to minimize the length of the video okay so it's just like this and i'm taking c as uh to use these values and check how is model performing with different different values and kernel will be obviously the rvf kernel because it's very kind of nonlinear okay now if you now what we'll do we will just uh we will just make this and then i will call my greatsword cv and i'll give my params i just gonna to give my params and svr first of all svr obviously svr and then i'm going to give it the rams red ram grid and then i just want to rough it equal to true and just wrap it will tell you means the warnings you can see the documentation verbose equals to three okay messages done now if you wanted to run it let's fit now now we'll fit grid onto our training to check different different values y twain okay now let's run this it will take a little bit of our own time but yeah i'm just gonna to uh code it further it will take a little bit amount of time it is checking for each and every uh this zero point one zero point twos etcetera and checking the score and whatever works best it just will give out okay just want to make it small okay now let's wait for a few seconds and i think this will uh end up being in a few seconds uh in the meanwhile i'm just going to just copy it out these things because the parameter which we are going to get is like this the c equals to 10 and gamma equals to 0.1 and kernel equals to rbf and if you run this if here you will be left with a very good matrices but it means it is very bad i think so this is we are performing is very very bad because of that we have a don't have a lot of features over here and spr is not able to find learn in the model actually but regular regularized linear models are more powerful in here okay that image is what i'm trying to say you here okay now i'm gonna do is to see this how much it was still running it's just checking for each and every uh this will take 1.8 seconds more to i think it's 1.9 seconds it's just taking a little bit of one time but i'm just going to wait for a few seconds and you can see over here that is trying for each and every value gamma then c then this then that okay so we will just wait and then i will uh let's come back i think we are we will just code it further because um we will just code it for the import job lib and here we will import job left to save our model to save our model because we are going to use a regularized linear models okay so model job lib dot dump job lib dot dum i'll just dumps and just going to save this model dot pkl okay and then i will simply uh if i want to load my model equals to joblib.load i'm just going to if you want to load your model you can just write it down and you can just make it model.pkl okay that's what we are going to do over here and now i think that's done now if you want to like this and now if you want to make it like this now you're done with this kind of thing now if you run this this support victim uh regression and now if you run this now the dumps is not there particularly very good okay so we are done with this now let's see the in folder where we have the pkl file and we can use this model to make predictions okay so we can use this model to make predictions so let's keep making predictions with this so let's me let me go to my let let me go to my uh one of the mlo one and then stock price predictor and here i'm going to open with code okay i do have made which i will just copy if i want to save my time i'll just copy and paste over there to save my time so that it would be more perfect if i just copy the prediction.html because it's just uh simple html blocks you're just going to cut it down because i don't think that this should require further it's just active let me cut it down okay so now i think that we are on to this now what what i can do i can just make a app.pi app.pi and here first of all i'm going to i think that all are able to see ya so from flask i'm just going to import import flask and then i'm going to import the vendor template render template and if you don't know what plan don't worry it's quite uh easy to understand i will walk through each and every process but i don't know why it's not working but it's okay if it's not working it's uh it's my vs code box a lot i don't know why but yeah i will just keep trying it out let me again open with code it's again open with code and then let's see what i can do over here that we have just imported the flash till now and render template now we'll just instantiate my model like this flask uh name oops it's just i think name it's correct yeah so now i'm just to make a route app.route and it's just uh this simple homepage to validate our server is working return render template i just want to take a render template from the index.html index.html and you may think hey you should haven't made index.html so let's make that uh this i'm not made just i'm going to make it over here so flask looks for html files into the templates folder to just make one templates older over here okay just make it and then one more folder you have to make for your images which is static folder okay static and all your images will be here now you can also make from here just to templates like this now just make a new file which is index.html okay now after making index.html you can just type this down like this and now if you go away stock price predictor i just i will just copy it down i will tell you where i have taken all those stops so let me show you where i've taken from these all so but let's see before that how is it working or not like writing a hello world okay just save this down and now if now it's time for uh like this instantiating for setting up your server name equal equals to main and then i will just uh app dot run debug equals to true anything going wrong i think yeah uh no it's true okay now if i save this if i run this down it will take a little bit of time and it will run and so it's starting over here and this is my url address if i see over here now you can see over here that we have a a beautiful website but now you can see why it is running the reason why it's i have to stop that server to get running so let me stop that server because another server is running um into the ml01 projects folder over here which i have to stop it i will debug it i have to reinstall my visual studio code but i will show you where i have taken this all so the first thing first you have to keep in mind from where you have to take this it's from uh see a tail block so i will just annotate the code in my mlo1 projects folder this i will annotate from where i have taken it says from first of all i have imported the cdn first of all i've imported the cdn of bootstrap and talvin css and then i've gone to tailblocks.cc i will gone to tailblocks.cc and grabbed my header grabbed my header then this nav navigation menu then i have to grab my header and then i have this predictor and you can see all the code is in my github okay now if i show you what the prediction.html does it's simply uh first of all what i've done i i have written a form into that you can uh the code will be in the description description elements that get up you can head over to that okay so i'm just using the request to get the form the open the high which is the input variables and then i'm pretty preprocessing it so how it's how i'm preprocessing it and putting into the 2d array to make prediction then i'm loading the model then i'm predicting on the test data and then returning the prediction and then i'm just running the template from prediction.html and prediction equals to prediction which has gone through here so if i go to the prediction.html you can see that i have just extra i have made one layout i use flask flask inheritance to inherit the template from layout or html and you can see the layout of this similar just a chunk of code so prediction is just a prediction and the prediction is derived from here okay and it's just prediction is there's prediction status just given okay pretty much easy let's see if it's working still now or not it's still working so let me put some value so it's just and it will tell the closing price and it will tell when it sells at closing prices tells the direction of the stocks okay so the closing price is four point eight six five eight eight zero five four okay so that's the pretty much easy that we need uh to understand about uh uh making a flask of flask website and endtoend machine learning project i really really hope that you enjoyed this tutorial a section in this project in the next section we will be talking about principal combat analysis then we'll do one of our project and then we have done step 10 now two projects which is an endtoend machine learning project to get on the resume and you can also modify it let me tell you how you can modify it you can see over that that we have an open high low close volume then a research paper or something called the stock price prediction using machine learning they have given what the features they have used like index volatility like uh mean etc selling price of the sorry three three days price three days previous price and nine days pre selling previous price so you can do that kind of features and integrate over there to make it the more powerful model with the complex model okay but do not make it too complex we can see we had we had worked on lots of data to understand and how we understood that this is good for linear regression the reason why we have understood because our data is not multiple linear what do i mean by multiple linear because many of the interviewer asks that how you will perform when your data is multicolinear with linear regression algorithm your answer will be no we cannot perform when a linear regression when your data is multicore linear it's only because it's only because your because the variables linear regression does not work well when your variables are highly intercourse correlated okay when you're let's say on it will be all same means correlated very highly into intercollect correlated so if they ask you what's the way to remove this so you can say okay we can use principal component analysis which will study in the next section so you can say hey we can use principal component analysis to remove the uh multicollinearity from our data and then it's boom you are done with your interview it means kind of just one question as an astronaut interview as i was in one of my interview okay so that's the basic thing that we need to understand and i really hope that you enjoy this section the next section will head over to the pca and we've had done the two projects now it's good to see that all of you are doing projects and it's i hope that you're very enjoying okay you can leave your questions in the comment box i will definitely pick up that question okay thank you for seeing this section i'll be catching up in the next section okay so now we will talk about principle component analysis which is a dimensionality reduction algorithm okay so uh you will get to know what is dimensionality reduction etc but before that we we should have a toolkit of some some other concept of linear algebra like linear combinations or linear transformations and eigenvectors and eigenvalues okay so we will review the linear transformation and eigenvectors and eigenvalues so that we can be on the same page okay so if you want to get in more detail there is a youtube channel named three blue one brown like this you can head over to that they have it he has a very good playlist on linear algebra they have a series of section videos you can watch that if you want to get dick dive into that but for this you don't need that okay but uh what is linear transformation if you have linear transformation just like a is a function as we have seen f of x which is a function so it just transforms your function transform this x to maybe the squared of x so this is just is a function the transform or the transform from one vector space to another is that respects to underlying linear structure of each vector space okay so if you if you have seen the three blue one brown videos he has clearly mentioned that is a function lean linear transformation is a function that transforms your one vector space to another with linear structure okay are we parallel to each other it's a linear structure of each vector space if a little bit of nonlinear gains you will be not able to do the transformation of your vector okay so that's called the linear transformation so linear transformation can be written as t column we are transforming our vector r to that okay okay so here is here's an example of 1d linear uh transformation so here's the function t of x and a be the sum is scalar and their one dimensional linear transformation t of x which is our function that maps your that that maps your from from interval of zero to one to the interval of three to zero so we have a vector the zero to one and it's just scales okay by the factor of three but a factor of three to the three end to inter looks like this okay so that's the linear transformation if you head over to the three blue one brown channel for more detail so uh i know vectors are nice and values i'm not going to take dividend math of eigenvectors and eigenvalues but it's just like what it does let's say you have the new transform vector it's just a scaled version of the original vector so you have some vector let's say well v you have a vector we have a vector let's say this and it's the new transform it's just a scale means the uh the new vector is just scaled from this vector like this if i choose new pen yeah so it's like this then the original vector then the original vector is the eisen vector of the original matrix okay so you just if your new transform you just scale from the original then your original vector is known as to be a eigenvector and the factor by which it is stretched like this green color is known as eyes in values okay and vectors that have this characteristics are known as eyes and vectors okay and eisen values means the factor by which it is scaled or stretched are known as the eigenvalues which is denoted by this symbol which is lambda okay so that's the simple idea behind eigenvectors and eigenvalues again let's revise what we have studied uh till now until now we have studied about linear transformation and a linear transformation is a function that transforms you from one vector space to another with respect to lying under a linear structure of each vector space okay we can write out here because we can write our value linear transformation as a t of x uh for example for only one d linear equals to a x and a b to some a linear sorry scalar okay so what we are doing over in this example here we have this vector of form from the interval of zero to one we are transforming it to zero to three by scaling it by two by a factor of three okay that's the linear transformation okay and here an eigenvectorized value we have a new transform vector which is the linear transformation which is happening okay it's a linear transformation which is a new transform vector it's a scale from the original vector means from the original vector like this it has been shown you over here then it is it is the original vector is known as the eisen vector of the original matrix otherwise it's just a vector and the factor by which it is scaled here is three the factor by which is scale here is three then the three is your eigenvalue okay it's this is what the simple eisen vector analyzing values are okay pretty much easy what i'm trying to say you here okay if you want to get in more detail there is a video of give by gilbert strang gilbert i think i'm pronouncing correct gilbert strang lean new algebra videos or a book by introduction to lean your ass bra introduction to linear algebra you can have a look by gilbert strand or you can have a look for a quick look at three blue one brown video the blue one brand video on linear algebra on youtube okay so that's the uh kind of uh resources to learn more but for now if you know this then you are good to learn about principle covenant analysis okay so you may think yeah i don't want to do so much of math etc so you have a library known as numpy which you can have a look which i have given the notebook in the description downloads below about numpad panda so you can have a look so we can just implement we can just implement by this la la is allies l a is allies as a linear algebra we are taking out the eyes e i z of the input and input here is our vector okay and this is your the eigenvector and either value as in vector of the or this matrix sorry yeah this is a matrix okay so and this this matrix is just a 2 comma minus 1 4 okay so that's the matrix of 2 by 2 matrix okay so we have started about um linear um algebra that is required for us for a principal common analysis now it's time for understanding why we are studying this all and why why we need dimensionality reduction so let's say you're working on kind of a large amount of dataset so this is 3 000 dimensions and what do you mean by dimensions is like the size of the house is one dimension then floor of a house is second dimension the number of fans is a third dimension then etc so unlikely that we have three thousand features okay so we have three thousand features so for that it you first of all it will cause storage second it will cost time it will even take months to train your model so it may even take months so you don't have too much of computer resources okay so that's why but in real world we have a millions of dimensions data available so what we do we simply use dimensionality reduction method or technique which is a pca to reduce your model feature with data features or variables okay and we typically see this in text data or image data so let's say you have some image let me draw one image of mine so here's my image so it will the eye has one dimension and it may be a millions of dimensional data sets only one image millions of dimensions one image i have worked on i have worked on to that which is which has 75 dimensions 75 dimensions so we have what we have to work on this typically will be seen on your text data where you will working on ash range processing like what embeddings or image data will be working on images okay so you need the principal common analysis okay so what is principal common analysis principle common analysis is a method for dimensionality reduction that is used to reduce the variables or the dimensions of the data by transforming large set of features large set of features into smaller ones that contains most of the information so let's see you have x1 then you have x2 then you have x3 and all the parameters let's say x 40 let's say 50 okay so what it will common analysis does it ask you a component let's say you have given a two component so it will try to put it will try to put most of the information into the first component x1 and it will try to put let's say p1 and and and in the second component most of the most of the information in these two components because we have say to do reduce from 40 dimension to two dimensions okay so so it will simply um compress that like that or put all the information into the first data variation first and second if you say it is one so it will try to put every with most of the information in the first and it will remove this all so obviously you will lose some of the information from the data but it's good to have uh not more than dimensions okay i will give a tip when you when you have to work on principle component analysis okay so what is the basic intuition basic intuition behind principal common analysis is that we have a principal components which is a new variable which are the new variable like let's say i have i given you know p1 and p2 they are the new principal components which are new variables okay that are constructed as a linear combinations of the initial variables okay so what what what we do uh let's say we have x1 x2 all the way down to x40 so we just try to put in all the first and second so it's v it's a hyperbranner two is a complex number of accomplish the high parameter so let's say we have taken two okay so it will try to put most of the information into p1 and p2 and these are the new vectors or the unit vectors or the variables like this all and it's just a linear combination of these variables okay of the initial variables okay you will get to know the through visualization what i'm saying and these combinations are done in such a way that the principal components are uncorrelated they are uncorrelated and most of the information from these variables i mean size branch etc will be compressed into the first components and so on okay and we're projecting each data point on t1 onto only the first few components to obtain a lower dimensions of data please preserving as much as of the data variation as possible so what is this we are projecting etc if you have seen orthogonality concept into an uh linear algebra orthogonality so what it tells so here's an uh visualization of that so here we have a data and what we do we take out the two columns let's say we have two components like this uh first dimension and then we have a second dimension like this okay so we have a second dimension like this okay is these these are the principal components which are constructed which is which are constructed as the linear combinations of the initial variables so what is what we do we project our data point onto this we project our each and every data point onto these diamond uh principle components like this and now our data point will be on this so here's the visualization which is showing more about this so we are projecting each data point onto the two components here we have first component and here we have second component okay this is the basic contribution behind principal components so basically we have let's say this and let's say this one and you have a data point like this okay so you just project the data point onto here you project data point under here to reduce the dimension of the data preserving as much as information as you can in the first component okay so we will see the algorithm so let's start seeing the algorithm to understand a little bit more detail what what we are doing okay but for that let's review some other concept from previous uh sites okay so principal components are the unit vectors uh means they are the unit vectors like the new variables that come out as a p one and p two whatever the p orbital p and p c is the number of components as constructed because from the linear combinations of the initial variables and these combination combinations are done in such a way that the principal components are uncorrelated okay you will see the algorithm by this one correlated etc and most of your information within the initial variables are just in a compressed in the first and then second like this number of components you are given okay very much easy what i'm trying to say here okay and we have seen the basic intuition now it's time for getting into the algorithm so the first step and the first and foremost step of this principal common analysis is data preprocessing what do i mean by data preprocessing means we have to standardize our data so in this step you standardize your data it simply means that your data should be falling in the same range okay so let's say you are working on a sum system like let's say the h uh like the one one one where you have a one variable which is the age so you have eight and let's say the first person is twenty second person is 40 like like this so let's say a new percentage is 1 200 is far away or far different from these means it is it's called an outlier it's called an outlier which is which which is which is not in the range of age okay and it's which is not in the range of the common ones okay so let's say your data is like 20 40 it's a two three so let's use the five four four thousand so you this is this is kind of a outlier and principal combat analysis is sensitive to outliers okay so what it would do for them for so uh so that's why we do the standardization of the data some sometimes we do normalization also so we do the standardization of the data so our data falls in the same range and the reason why it's critical form because it's quite sensitive regarding the variances of the initial variables okay if you have seen the variance and mean if you and the formula for this is x scale equals to x minus the mean of x x i by the standard deviations okay standard deviation and then you will get the scale formula of your um data and don't worry how to implement this you can also implement this just by coding in python so let's say you have made a function this is standardized it takes the value of x then you should make a new variable x scale then you subtract x minus the mean is np dot mean of x divided by the np dot standard deviation of x okay you can do this but if more formula vectorized code is in scikitlearn you can use scikitlearn to implement it just three lines of code okay don't worry if you're if you are um not able to implement from scratch after first step after you standardize your data now it's time for getting into the computing your covariance matrix of your data so what do you mean by covariance maintenance in the cover is basically a p by p symmetric matrix where the diagonal are the variances of whatever the um data but if you will t you can have i will go to internet what about what is covariance matrix but here after taking out the covariance matrix it will tell you that um that that tell us how to feature how the features of the input data set is varying from the mean with respect to each other okay so here's tells the correlation like that that's not a really correlation but here we have an input date data set like x and it's va out of how much the input data set are varying from the mean with respect to each other means the x1 how it's varying from x2 and etc it is sometimes important because they are some variables highly uh are highly correlated and they contain unnecessary information to work on okay so you should you have to you can remove that okay so that's how we compute the covariance matrix pretty much easy one i'm trying to save here okay so you just denote covariance matrix with c and for implementing covariance matrix you can use the again numpy for the scientific numpy dot np dot cough and you just give the data as your features let's say x and you'll get your output as a covariance matrix okay pretty much just see i'm trying to say you here so let's um see whatever i've seen so far we've seen first we have to preprocess your data like a state of standardization or normalization then we have to compute the covariance matrix of your data which tells you how the input variables are varying from the mean with respect to each other variables okay because it's sometimes important because some variables highly correlated and they contain unnecessary information okay the next step is computing the eisen vectors and eigenvalues of the covariance matrix so let's review what we have seen in eigenvectors and eigenvalues so in either vectors we have seen that if our new transform vector is just a scale from the original vector and the factor is called the horizon vectors and the factored by which is stretched is known as eisen values okay and so that's the eigenvectors and either values the reason why i made this ppt is i if if i write in blackboard that would be not beneficial for you because i would be saying so i had megan know so you can have a look on the future also to see how it's working and it's better to have a text onto the screen to uh while you're listening okay okay so what we do you compute the eyes and vectorize a value of the covariance matrix means you come from eigenvectors are the transform vector from the original vector and the factor by which the is stretched is called the eigenvalues okay you can easily compute the eigenvectors and eigenvalues in python and then what you do you sort the columns of eisen vectors matrix v and i's in value matrix d in order of decreasing value what do you mean by step four let's say your computer eisen vectors are nice and values and those who has um high means high information or high numbers so you just sort the means the larger word in the first then larger one in the first and larger second second third fourth year six seven like this okay and then after that what you do you simply um you'll see oops let me do that you simply uh compute the cumulative energy content how much the content is each eisen vector is having okay and then you select a subset of eigenvectors as a basis vector means let's say you are in cyclone there is a sorry and any other you should choose how many number of components to use okay that's the main thing so what you do you simply sort in decrease in decreasing order and you come the content of each engine vector and then you select who has the high energy or content from the top and if it is your if you choose the principal component two then only two highest to highest will be choose those who have highest number of information okay and then you take this and then you take this two and to project onto the final you project data onto the new basis okay so you prob you have a large amount of again and and then what you do you remove this or you project this um pretty simple component uh this eigenvector onto the new vectors okay and this is the formula and this is random device and this is the feature vector transpose okay so we have seen so far and here's uh uh sap what's the algorithm of steps and i have not written last step which is uh projecting the data you can have a look but because my uh kind of was not fitting okay so first you cross preprocess your data then you compute the covariance matrix then you compute the eigenvector and either values of the covariance matrix then you rearrange the eigenvectors and either values then you compute the cumulative energy content of each engine vectors although it is not necessary because when you sort the integrating order you the top will be having the highest information and then you select a subset of the eigenvectors as basis vectors okay so i think that we have seen so far and i really really hope that you have enjoyed this tutorial and in this section uh previously i think you may find it's quite uh intimidating now i think that you are able to grasp that con concept of linear regression logistic regression support vector machine principal common analysis and then we have current projects and then you have coded boston health risk prediction stock price prediction one classification project you have coded logistic and linear from scratch now in the next section we'll we will cover the principal component analysis from scratch we will do by uh with ourselves to get the more feel of the principal color analysis okay so i really hope that you have enjoyed i'll be catching up your next section uh so let's start with the next section to learn something new okay so now we'll start with learning theory again one of the most important concept to learn in machine learning and i think gaining some something or less we will see the topics which will start in this course in this section is we will see why it is very important means maybe it might look a little bit more nonsense over here but maybe if you are going to tell advanced version of machine learning like deep learning or nlp or computer vision it should surely make sense type that learning theory actually works and in learning theory in this section we'll learn about these three topics our main uh main communication main talk on to this like bias and variance tradeoff and then we'll move on to approximation estimation error then we will move on empirical versus minimization and this this will be our new concept this this this this will be this is these are two just a definition just i don't just just just a problem framed okay just a definition which which is which is needed because in many of these research papers they have listed uh empirical risk minimization of or approximation estimation error the reason why they have maybe some in history they may might be have different something out of different choices okay so we will study we will just see the definition of these and and it will surely make sense but if it is not please be sure to ignore it for now continue with this course and you are free for your feel free to come again okay you're feel free to come again and then watch this do concept because it will surely make sense okay so let's start with bias and variance okay so in bias and variance here we will study about bias and various tradeoffs and here is your warning warning is is learning is is this is one of the easiest concept to learn as instructed by even uh whenever i heard that this easiest concept to learn and it seems to easiest but it's very hard to master very hard to master and i hope that you heard andrew nung saying this and i think this this actually makes sense if you're a beginner then it might not because you will understand everything but it when you are actually developing the product it's a very very important to keep track of bias and various tradeoffs and etc okay so let's start with bias and variance but before that we are going to recall our two problems which is my favorite overfitting oops not my favorite it's an overfitting and under fitting okay so here is my favorite diagram uh from the google so here uh let's assume that we have a time and x axis and values and yaxis okay so maybe some kind of problem okay so here you have these data points here you have this data points and what you do you just flip a straight line that's a simple linear regression simple simple linear regression okay you just fitted a simple linear regression which is just theta zero times uh x0 plus theta 1 times x1 okay so um plus theta 2 times x2 okay so here you just assume that we have a straight line using a linear regression okay but you can see over here that the tree it is not performing well on the training set also means this is my training set so it is not performing well uh the the residual error or the cost function will be very very high will be very very high okay the cost function which is j of theta which will be very very high in this case so we call it as under fill okay so the major problem makes a major major problem that make this problem occur is that you have a low amount of features low amount of features or you have low amount of data or you have a low amount or you have a low amount of data okay so these two causes the problem so your low amount of features low amount of data okay and that can be that that can be sensed using just by adding more data or adding more feature or if you don't have feature you can do feature engineering to generate more features okay so uh just to do not focus on future engineering for now because it's not a data science course but obviously you just need a simple feature engineering means it's just generating more features based on our features so let's what an example that you are building a spam detection system so let's assume that we are building a spam detection system where you have a one column which is of text another column which is the label whether the whether that text is a spam or ham so it is a label okay so you can generate more feature like length of the text what is the now how many number what is the number of a text in that what is the number of words in that text what is the number of characters so you can you take you using this this this text feature you generate more three features and that's called a feature engineering okay so i think we if you if you if you see i'll be very happy to make a video on a feature engineering okay it will it will be a full place data science course okay so here after this we have our simple linear question which is just like this now this is called underfitted and major problem that i've seen so far in my experience is a low amount of feature stack that we have okay so in general the underfooted me the under underfitting means is just that your model is not performing well on the training set and it's obvious that you'll not perform well onto the testing set so that's why we call this under fitting okay the next picture of here is good fit slash robust robust means it will it will be very robust which is a very good fit you can see you it is a very good fit the cost the residual error is low the residual error is low and it says we have a very good polynomial kind of thing um a nonlinear uh or or i can see here against a nonlinear or a polynomial regression over here we have applied polynomial regression and here's what we get the as a as a as a hypothesis okay so here you can see that is a very good fit and this is this is the robust model okay so we can say that this model is performing well under the training set as well as on the testing set because whatever example will come here the residual error will be low okay so like like that is perfecting well under training and testing set another picture which tells you about overfitting what do you mean by overfitting overfitting simply means that your model performs very very well or i can say that your model wants very very well under training set where your cost function your cost function of j of theta is equals to zero okay where you you don't have any residual error or approximately equals to zero okay so your cost function is very very low so you can assume that your model learned a lot which is touching each and every examples your model learned a lot so that's why your cost function is very very low and cost function is just denoted by the submission over i equals to 1 all the way down to the m h of x i h of x i minus y i squared okay and just taking out the difference between the predicted and actual value and here the the predicted and actual value are on the same line so here you you your model want a very nonlinear hypothesis it all it happens that if if you have a lot of features a lot of features and here you have a low features and here if you have a lot of features that happens okay and maybe you have used too much of degree in polynomial regression so that's why it happens or maybe something kind of a other no a very kind of complex architecture or you have or you have made a very complex function f of x with the highest x4 etc like that like that okay so this is this is the this is the problem for overfitting and whatever new example come over here your model will be very very high whatever come here the residual layer will be very very high okay so your model will fail to generalize well onto the new training examples okay so in general overfitting means over overfitting means that your model perform bad or or against your model perform very very well under training setting which your cost function is low is is it is equal to zero which is actually good but but you you may think it is good but just just wait that your testing set error is very very high okay so that indicates the problem of overfitting so we can prevent overfilling by selecting some of the important features selecting important features or regularization so regularization is just advanced version of selection of features so let's see what it does okay so i have already told you about regularization now in our regularized linear models and i hope that you understood that okay so now we will uh see the bias and variance tradeoff by taking a look at some scenario of your model okay so let's assume that you are building some model okay so you are building some model and your model gives one percent error one percent error on a training set so you have one training training set like this and you divided this training set into uh training and evaluation set so you have this whole data you have this whole data and you divided this in training and evaluation set okay so what you've done you've taken a one percent adder under the training set one percent adder on a training set which is uh if you see oh you one percent error one percent error on a training set and fifteen percent error on the evaluation set so you can assume that your model is you can see that your model is overfilling because your error is very very low end training set but your error in validation set is actually 15 which is very high okay according to this okay so it is performing a very very well on a training set but it's fails to generalize well onto the testing set so it is overfitting and in this case we say that the model is having high variance and we use bagging we use bagging to reduce high variance which you will see in ensembl learning methods or sections so don't don't worry you can come back again to this section to watch this okay so this is this is how you identify if your model is having high variance next next is that let's assume that your model is giving a 15 percent adder on a training set on the training set okay 15 percent addon training set and sixteen percent adderall on evaluation set so it is not performing well under training set obviously to not perform well on the evaluation set so it seems to be underfitting so here it has high bias and we use boosting we use boosting to reduce bias okay so this is this this is what i'm saying and let's take let's stick for the sake of an example again again example that your model is having both high bias and high variance where you have a 15 percent error which is obviously high variance and 30 percent error on evaluation which is obviously high bias okay so it is both overfilling and unfitting and obviously it has a high bias and high variance okay the next our favor and last example of this bias and variance tradeoff is your model gives 0.5 percent model gifts 0.5 percent or training set and one percent underscore testing set so it seems to be a perfect model or a robust model where it's not learned too much on training setting for it is a very robust and good model okay here it seems to be a good so we can say it is it has a low bias where it has a very small error and it has a low variance where it has on training set is a very good okay so this is this is what we consider for low bias and low variance and all of these all of these we take assumption do you know what assumption oops you don't know but because you're watching but uh when we take an assumption that base error or human level performance or human or human level performance human level performance is approximately equal to zero percent is approximately equal to zero percent so what do i mean with this assumption i what what do i mean with this assumption that we take our base error to be base error base error to be approximately zero percent in all of these examples in all of this example this example this example this example okay so let's see what's that human level of bayes error is so here you can see that you're you're you're going to build some uh classification model or maybe the face detection model okay so your build your you have built the face detection or face recognition or real time face recognition so your algorithm even you will fail to identify this person even i will fail to identify this person the reason why because it's very blurred very very very with blood okay so even a human even a human human error okay hlp you even in human error will be very very high very very high because he will be not able to he will be not able to uh either identify who's this person is okay so so so and you can cannot expect that your model should be very great over here you can expect that your model is very your model is also giving the same error as you are giving because you are also not able to identify as well as your model also not not able to identify and actually this is not this is here the hlp hlp is very very high or i can say the base error is very very high so we can say that here um you can you cannot expect your algorithm to work best but let's assume that that you have a fresh image and where the hlp is equals to zero means human level performance is equal to zero and you now you can expect your algorithm performance to be good because it is the human performance is equals to zero so that's called the base error and and i hope that you understood the next uh we we have talked about bias and variance tradeoff you can again rebound this video to understand again but what is approximation estimation error this is just a definition so the approximation estimation error approximation error in some data is the difference between exact value and the approximation of it and this approximation indicates your f of x means the outputted model uh the output from the model so we here your f x given some approximation and this is the ground truth which is y hat okay so difference between these both is called as approximation error okay so here i've taken one example from wikipedia again it's a scale example but that's that's that's generally mean i i already told you 9 cost function you take out the difference between that's an approximation estimation error okay so it's just like this if the exact value is 50 and the approximation is 449.9 then the error will be 0.1 and that's actually what you do when taking out the error for one training example you just subtract this and the regression problem what you do you just subtract y hat minus y and then and you get your answer okay and then you add submission for every i for every eye etc okay so this is what you do and this is just a definition because you will see a lot in your research papers okay next one is empirical risk minimization again we have seen so an algorithm receives as an input on a training set so i'm going to just i make you familiar with this what i'm saying that an algorithm receives as an input a training set as means we we get and we get our training set which is a sample from the large distribution d okay so we get our sample from the distribution d means large we just take out some sample and label by some target function y okay so here we have our training set as well as we'll be having the labels for it because this is a this is framed on supervised learning okay so here we will be having label as well as the samples for each training example okay and should make a predictor we should make a f the predictor that maps our input variable x means these features to the output variable y okay and the goal of this algorithm is to minimize the error outputted with the respect to the unknown d means now we will feed a new example that a model has not have even seen and your model should be very minimal or you or your or your model should be audio model errors should be very minimal okay so this is what the full definition is saying and it simply means that we want to come up with the predictor l subscript s h we're going to come up with the l of h with sub subscript s where s emphasis the fact that the output predictor depends on s okay so whatever the output will be it depends on s because we have taken we have learned we have learned the weights we have learned the w we have learned the theta one theta two all around n from these s so that's emphasizes that minimizes the risk or the error which is called the erm which is called the empirical risk minimization okay so i hope that you understood this concept very much clearly and i really hope that you had enjoyed seeing this section and we i have talked a lot on empirical risk minimization learning theory and et cetera so i hope that you will utilize this uh way and we have already talked about uh the job and now you can continue further if you haven't understood anything you can feel free to ask in the comment box below i'll be very happy to take your down and be sure to have a look at the course website which is already available in the description box below so meet you in the next section okay a very warm welcome in this section and in this section we will be talking about decision tree one of my favorite topic to talk on as i will go in depth of decision tree to make you understand everything and decision free with intuitive examples with solved examples of decision tree as i have seen on youtube that they are there some instructors are doing great job but they are not doing that into decision tree means for free so i just want to make you familiar with decision tree whoever is watching this tutorial into depth and i really hope that you will enjoy this section but before that what we are going to cover in this section are as follows first we will start with the introduction geometric intuition a basic intuition about decision tree what the actual the decision trees are and then we will go further into how we were building that decision tree so for building we will learn some sub tasks of concept which is like entropy information gain a guinea impurity okay then after that we will build our own decision trees and then i will show you the implementation of decision tree okay but before that let's uh understand the basic intuition of decision tree as there will be more topics which we'll cover as i will discuss later on okay okay so let's start so uh first of all what is decision tree decision tree is a supervised learning algorithm okay so it is a supervised learning algorithm and what do i mean by supervised learning is that we are having our uh x rx 1 with our label y1 all the way down to the x2 then we have i2 all the way down to the xn and we have y okay so we are having labels so it is a supervised learning algorithm and it is used for both like support with the machine is used for both regression classification so it is used for both uh classification and regression okay so uh you will see how we do how we construct the distant tree like that okay so let's start with um the basic intuition of decision tree so the definition of decision trees that they are nested if an else statements okay if you're a programmer then you will be relating this concept which is if and else and the python is a prerequisite or any programming language is a prerequisite so what is this entry it is just a nested if and l statement so it is a nested it is a nested if and else statement so i don't know why it is so bold so it is a nested if and else statement um so is what it does is just ask a question and it splits the data okay so let me write the formal definition to make your more uh intuitive intuition behind so they are nested nested if and else statements okay so he's just ask questions is just ask questions is just ask questions and splits the data okay so it's just ask question and splits the data so let me take one example of iris data set let me take one example of iris data set okay so what we do when iris data set so but what let me make you familiar with what is that this data set to make you more clear understanding of this topic okay so iris data is simply like this you have a data set which has four features like sepal length sepal with petal and parallel petalworth okay and you have the label which is the species of the flower okay so this is a task of flower species detection under the basis of four features okay so this is a classification data set a binary class classification data set so you were having and like this so let me change my color i don't know why it is so bold okay so you have like this uh first you have sepal length sepal length and then i i i hope that you understand what is sepal and what is parallel so sepal width then you have petal length and then you have a petal width okay and then you have a one more column which is the label which indicates for the species so let's take an example 2.2 4.30 that's a 3.2 4.6 and the label is um acetosa satosa okay so you have three classes in this data set as a label which is cetosa which we label as one sorry zero versicolor versicolor which we label as one and virginica virginica which is labeled as two okay so the output will be either zero means a tossa then either it will be one means we're cycler or virginica as in quotas as two okay so that's the iris data set that i had just make you familiar with okay so let's what what we will do we will not make use of any library will not be used and then anything we will simply what what we will do we will simply make a decision tree by yourself by making just if an else condition okay so we'll make a simple classifier obviously it is not so formal but we'll make a simple classifier that will simply classify your flowers okay so that's what we are going to do so let me remove this and i really hope that you understand what this data set is and more uh understand uh if you want to more in detail about what the data set is you can search online this is a famous data set like iris state data set which is just for flower species detection system okay so let's start so first uh here we have an um variable x's here we have our x's which is sepal length sepal width parallel length and parallel width okay so we are having these features and we have a y i which indicates either one or two or two or zero or two okay so that's the basic intuition uh means of the data set part we are given this data set now what we will do we will make classifier like this first if we write if let me choose another pen okay i i hope that i should choose a better pen like this blue okay okay so if the parallel length is smaller than some a and may a may be some number a maybe some number let's say let's say 2.3 a maybe some number if petal length is smaller than a then consider y to be um for cycler okay so let's consider y to be one okay if not if it is parallel length is greater than a then what do what what to do oops i hope that it is getting not clear what what happened i have to buy my new computer why do i don't know what to why it is so much lagging okay so you'd if it is smaller than a the parallel length then consider your flower is means of a versailles color and we have we have made one one and if if it is parallel and if your parallel length is not is is greater than a then what you will do you will write else if separate you take again one feature you take a game one feature and says if it is smaller than b if sepal length is smaller than b then you will you consider your y to be uh virginians too okay if it is not if it is not if both is both condition fails then say if both condition fails then say that your output is setosa okay so here is our simple decision tree we're using two features we have made the decision trees using two features so let me make it more intuitive i i i hope so that you are able to understand okay so that's why i'm speaking very slow so here let me tell you what i'm if petal length here we are we have taken two features which is petal length and sepal length okay we had not taken this uh this two features okay but you can make that but this is not a formal decision tree this is just for an example this is obviously not correct okay so you had to make a mid one if condition that if the parallel length is smaller than some a and a can be anything 2.3 4.3 that that is usually i'm taking anything but it is usually taken uh which will see um in one of our data set we will see how it is chosen and you will obviously see how it is selected okay so if it is smaller than a parallel length then consider that y to be equals to one if it is not let me check that this recording is on here okay regarding is on okay so we if the parallel length smaller than a then we consider our y to be this uh versionica okay if the pedal length is greater than a or is it this this this condition fails this condition fails it then goes to else condition and in else condition it this is again a nested loop nested sorry not if an assess control flow just check if your sepal length is smaller than b if it is then you say that y equals to virginica okay and otherwise if this condition also fails then it says else your y means y should be satosa and you have this hole into the this nested loop in this and you have this whole classifier and this is your whole classifier so that this is the decision tree yeah so let me make this diagrammatically in the terms of decision tree so in terms of decision tree we can write this equation this uh this if statement first we have our root node this uh we have first we make our root node like this let me make one root node here we have our root node with this condition if a parallel length parallel length is smaller than a okay then if it is if it is yes then you say your y to be one okay if it is no if your parallel length is no okay you consider you again make one more condition which is sepal length is smaller than b if it is yes then you what you do you classify this y equals to two if it is not if it is not then you take it as a zero and your whole three variable uh target variables are covered and this is the decision tree and this is whole this is the decision tree i have made in yellow this is the decision tree is just ask a question on the data set if the pedal is smaller than a if it is then consider y equals to one if it is not then again we have made another another decision and then we uh if it is yes or if it is known like this okay so that's the this is the decision tree it's damn is like this okay so here again i'm saying this is what you do just believe me yeah we had this is the decision tree and how it is constructed we will see okay so we have made this as a final statement yesterday if an else statement like this and this is what the decision tree is so here are certain terminology that we will have to see over here so here are the the details that we should know okay so the the the first node or head node is no is known as root node is known as a root node or parent node okay this is this is a root node obviously this is also a parent node and these are the child node these are the child node okay child node and this is the parents node and this is also the parent node and this is the terminal node this is the terminal or leaf node because you are not splitting this node into further nodes so this is called the terminal and this is also a terminal node this is also a terminal node okay this is also terminal or a leaf node this is some sometimes called a leaf node when you are not spitting further okay so this is a leaf node or you consider it as a leaf node this is the whole thing is called the branch this whole thing is called branch use this whole thing is called branch okay and that's the basic terminology of this okay and this is the splitting of your data okay this is the this is what you are doing doing which is splitting okay if you're removing some node let's take an example this then you are pruning it okay then you are pruning this node but we and we don't know we don't want right now okay so that's the that's what that's the decision free and i hope that you understood this example clearly and i really really hope that you will uh that you got a very good intuition of decision tree in much smaller span of time in much easy way okay so i hope that you remember this terminology either i will make you familiar with terminology by the time also if it is not required for remembering all those things okay but this is it's it's best to take a paper and a pen and write notes with me whatever i'm writing okay and just listen me carefully after listening me you can make notes okay so now let's see what's the decision boundaries will look like okay what's the decision boundaries will look like or the hyperplanes will look like but what do i mean with hype airplanes i mean with hyperplane decision boundary is let's take an example of linear regression in linear regression we are making a straight line this is called the hypothesis decision boundary then we have a hyperplane it's called the hyperplane in support victim machine we are also making hyperplane in logistic regression we are also making hyperplane means a decision boundary so in the decision decision tree we also have the diffusion boundaries okay or hydroplanes so let's see how it is constructed so i don't know i will be able to make that image or not but i will fully try that okay so here uh let let me make one x and y plane x and y oops i'm please anyone help me to make this okay let me do that oops i'm just freaking out let me do it again yeah okay great so i have made one and this is my xaxis this is this is my xaxis and this is my yaxis and we have a two features which is sample length and uh parallel uh length i think so yeah so we have parallel length in the xaxis and we have separate length in the yaxis okay so we i i have just made it you can remove this yaxis maybe it will confuse you in in our x's we have petal length and y axis pf zeppelin because we have taken only two features in this example we have we are not taking more features like parallel with and past apple width okay so what what we consider what we have done we have considered we have considered this full reason we have considered this full reason this full reason to be y equals to one okay this hyperplane this hyperplane list let's name it as a first type of plane so this full reason is our y equals to one means whatever data point will come is considered y equals to one and this is just this is just the if statement that we have seen if parallel length if parallel length is smaller than a okay then y equals to one so that's this is the full reason okay means we have not for this bit so it is just a full reason where y equals to one if that condition passes okay then another hyperplane we can construct let me choose another pen another hyperplane be construct that this reason this reason would consider y equals to 2 okay y equals to 2. if the sepal length is smaller than b if the points come in this region then it is it will consider y equals to 2. another we have hyper plane let me take another pen that let me take another pen let's take an example of blue okay another outcome we can consider that as a y equals to three okay if that if that falls in this region so here we are constructing hyper planes and if some with something come here then control y goes to one it's y equals to two or y equals to three with these two features obviously it will be more dimensionally high when you plot the four features okay so you can see that we have a hyper planes where we are able to make predictions okay and we have made a simple classifier okay but something to note over here that all your hyper planes are axis parallel okay our x is parallel means this is parallel and this is parallel so you can see over here that all the hyperplanes are x is parallel okay so that's the i i hope that you understood decision trees in that and um this is the basic exam intuition that i want to give it to you in more uh sophisticated way or not sophisticated it's just a good way okay okay so as i've tried it to keep it as simple as i can and i kept it okay so let's uh let's let's start building or let's start with mathematical region that's how we construct these kind of decision trees these kind of decision trees how we construct okay so but before that we have what what what we do we uh how we choose the variable or how we choose the feature to be the root node or the bran or this this how we split so we have attribute selection measure and you if you select run randomly like i have choose a petal land of you if you choose ran randomly then you will be ended a very bad model so we have different attribute selection measure we like entropy information gain gain impurity which we'll see in detail to understand the how we select the attribute to be as a root node or like this okay so let's take a let's take an example of this data set if you want to split this data set what feature you will use you what are you going to use outlook as your feature root node or temperature as a root nor or humidity as a root node or when as a root node okay and play tennis is our uh label so which you will use if you choose run randomly maybe you will be end up ending up with a bad model okay so you have to do that kind of thing no so we will we will uh scientists or researchers have done a very great job even you all have to do all this kind of thing research and please keep contributing to the ai community that maybe and i'm also doing research in machine learning and definitely will come up with something extra okay so um different measures different measures are different attribute selection measure are entropy we have entropy then we have the second number we have information gain information gain information gain which we usually write as ig then we have guinea impurity then we have guinea impurity and is simply uh i g okay so we denote like this okay so uh we will talk about all of these three and i and i hope that you will uh understand each of them okay so let's start with entropy okay so uh entropy let me write it more formally yeah so what first of all what is entropy entropy is the attribute selection measure it's the measure of a randomness okay how pure or how pure that attribute is to be used as some nodes or a root node okay so it's the measure of randomness so let me write the definition because definition is also important and if you want this kind of all my notes you can simply write me right with me along either you can comment or join the newer community discord community and ask me there i will be able to give okay so ask me there i will be able to give all this entropy etc is the measure is the measure of randomness it's the measure of randomness okay the higher the entropy is the higher the the higher the entropy is the harder to draw any information from them okay so it's if the higher the entropy is it's very hard to break your uh node okay or to choose the node so um our entropy should be low to to be considered as is uh leaf node but still don't don't worry i will dig dive into the cases to make you more understand what do i mean with these terms okay but first of all uh let's take and i will show you one equation and then i will show you um how some first of all one example and then i will show you properties of entropy okay so first of all uh let's take an example where you were given you have y to be maybe uh y1 y2 all the way down to the y k and in this case you are naughty this is not examples this is a this this is like maybe satosa means what is the number of classes you have okay so um maybe you have binary classifier or you have a multiclass classifier okay so you what is the number of a classifier so maybe you have in the in the iris satosa we have here's uh versus tosa vergenic and ver cycler so we here we have y equals y equals to y1 to vctosa then we have virginica then we have very cycler means three wise okay so that's what i mean with this okay so let's first of all let me give you um let let me give you the equation okay so the equation is defined as like this h we define our entropy by h equals to let me choose white color because i like white much okay minus mini uh this is this minus is very important minus the submission i equals to 1 all the way around to the k and k here is the number of your what is the class what is the number of a class okay p of y probability being y i log of base and b is usually taken as 2 or e okay to a 2.713 okay so b is usually taken as 2 or 3 but usually take b as a 2. so if you were taking p as a 2 then you can consider it as l g if you're taking b as a e then then you take as l and natural logarithm and you have a log 2 base a log 2 um with a log with a base 2 okay this means lg okay so you take log of p of y i okay and that's the full equation of your entropy means it's just measures the randomness okay so let's let's take one example because it is i i i i know that is making no sense to you and i know that is making no sense to you but i will make sure that it will make sense okay so first is you we want to measure our randomness for playing golf okay you want to measure your randomness for playing golf okay so let me write play golf oops uh let me write the data set first what's the data set we'll be using so we have this play golf data set play goal data set where if it is what is the number of yes which is 9 and what is the number of uh no which is 5 okay so this is our data set like this and let me make this also okay so this is a daytoday data set and you want to take out the entropy of playing golf okay playing golf okay and here we want to take out entropy of being no being no and being yes okay so what you do first you take out the entropy entropy of 0.36 log 2 0.36 minus means this is your first this is your first y i this is your first y means yes sorry no this is for no and minus let me make it up okay minus 0.64 log base 2 0.64 okay this is what we have and the answer is 0.94 okay so here what we what what we are doing over here that first we are writing this this equation p of y i times the log of for no and then we are writing for a yes okay and there is subtracting and we have um entropy at 0.94 and it can be further splitted okay okay so this this this was the basic calculation of entropy but let's see some cases of entropy to make you more sense of this uh entropy um attribute selection measure okay so we will see some properties so let's uh consider let's consider that that we have y to be two class means we have a binary classifier we have where we have two class one is yes one is yes and other one is no okay any kind of yes or no whether it is playing tennis or etcetera that's yes or no okay so let's take an example of let's let's take one scenario let's take one scenario number one okay so here is our scenario which tells we here use data here is your data and number of a yes is a 99 number of a yes is 99 in your data means these are the your y labels so we have two unique values in your y labels so here you have yes and no so in that case your yes is around 99 and your no is about one percent is about one percent okay this is your case one so let's take out the entropy for this h of y minus you're taking minus 0.99 means 99 log means lg i'm writing log not two maybe i'm writing a log of 0.99 minus this this is for my yes means this is for my yes because we have added a summation for each for each uh y variable so we are for we are doing for each for each y variable okay minus 0.01 the log of 0.01 and your output is 0.0801 okay so that's the your entropy okay so let's take one more scenario let's take one more scenario scenario number two and here let's take an example of your data having the yes to be around 50 and your no is around 50 okay so um if you take out entropy of this if you take out entropy of this minus 0.5 log of 0.5 minus 0.5 log of 0.5 which is equals to 1 which is equals to 1 and the maximum maximum entropy is 1 and it is and this is very very hard to add to split this to split this it's very very hard okay so it's maximum entropy is one let's take another scenario and if you have a binary classifier i'm taking an example your maximum entropy is one if you have a binary classifier if you have a multiclass then the equation changes okay which you can see on internet but most of most of the cases if you understand binary you will be able to understand multiclass okay let's take another scenario scenario number three okay scenario number three tells you so now your number tells you that you're a d which has yes to be around zero percent and you have no to be around hundred percent so you're in trophy over here would be zero okay your entropy will be zero and minimum entropy is zero over here okay so you can see some cases that is if you have id3 follows if you have um if you have a some algorithm means a decision tree follows that if you have entropy equals to zero then you consider that as a leaf node and what is leaf node as a your prediction if your entropy is zero then you consider that as a leaf node if your entropy is one then it needs further splitting or if your entropy is big means uh your entropy for binary is generally greater is like this your entropy is generally like this entropy is in between or equals to okay so your entropy will be in in this range so some means uh algorithm follow id3 there is one one algorithm called id3 instance sub subset of uh decision tree algorithm so id3 follows if your entropy is zero then you consider r is small then you consider as a root a leaf node if it is one or large entropy then then you then it needs further splitting okay so that's the entropy and i really hope that you understood entropy in detail so let me make you familiar with what what we have seen so far so we had talked about decision tree which you can reverse back to c more but i'm going to uh recapitulate the entropy so what do i mean by entropy entropy is the measure of a randomness that measures if your attribute needs for the splitting or it's considered as a root node or it could consider as a leaf node or like that okay so we have taken one example of playing golf and then uh and then we have taken us some three scenario where we have seen that it is very hard to split it is very hard to split if you have it is it is it's very hard to get you get information if your entropy is high so it needs for this splitting okay so if you have years to be have 50 percent know to be 50 percent then entropy will be one if you have another scenario then then it will be like this i can um just see the cal calculation you can see the calculation if you want to be uh to understand it much better okay so that's what uh these certain trophy is but let's see the diagram of entropy visually it's a bit interesting okay it's a bit interesting so let me draw one diagram of entropy okay so here we have our let me draw one let me draw a good one so here we have zero here we have one okay so i i hope so that i'm i'm not able to draw it but let me try at least okay and the highest entropy is one the highest entropy is one okay is one and this is the diagram of entropy this is the diagram of entropy okay so the highest entropy can be one if you're taking with this equation okay i have already showed you approved you so this is an example of entropy okay great so we have seen the entropy which is a measure of a randomness so now let's talk about the another attribute selection measure which is information gain okay we'll talk about information gain let me write it down in for formation gain and i will take an example of i i will explain you information gain with the help of one data set which is all i have already showed you i thought i will give you a surprise with that but i've already showed you let me show you again so here we have that data set let me show you yeah here is our data set okay let me draw back like this okay so here is our data set which is played tennis okay um this is a play tennis data set and what we will do we will i will make you familiar just see this data set and look at this data set i will be looking i have already looked at okay so here you have a plate and this is target variable and you have these features so we will see which feature to use or which feature to not okay so here um you can just see what i'm uh you have around one two three four five as a no and one two three four five six seven eight nine nine as a yes okay so we will uh we just see the cities and now let's come back to information game to understand first i will give you an overview of what information gain is and then we will dive deep oops where is my i don't know why my computer is lagging just give me a comment why it is very lagging okay so here is my information gain okay great i hope that everyone is able to see yeah okay great so let's consider you have the data set b okay so you have the data set d like this let me consider this as a data set let me consider d oops wow it's we have a data set which is d and what you do you further divide this data set into your uh uh for the data sets for the smaller sub subset of this data set and how we will divide this subset of this data set it means that you divide this data into versions and what versions maybe let's take an example of iris data set okay so what you what you do what you do you divide this uh satosa versicolor and virginica into three data set which concerns citosa versailles color and virginica okay so whatever examples of versitosa will go in this data set whatever examples of virginica will come will go in this data set whatever whatever examples will go where cycler will go in this data set so that's for you what you do you divide your data bases on the number of labels and i'm talking about binary classification classical for classifier or uh classification task over here okay so what you do you divide your data set uh first to divide for d v one then you divide for dv2 then you divide it for dv3 okay dv3 okay and what you do you take out the entropy you take out the entropy of this the v1 you take out the entropy of dv2 then you take out the entropy of dv3 okay and maybe there's this kind of cytosa versicolor virginia you take out entropy and then you take out the entropy of your whole data distribution okay before splitting so you take out the entropy before splitting and then you take out the entropy after splitting okay so take out entropy before splitting like this okay after that you you minus it you subtract you subtract your uh h of d at the function the entropy means previous entropy means previous entropy this entropy h of t which is the entropy before splitting minus minus let me write it down minus the weighted entropy which is this which is whatever the weighted entropy will come so let's see how we that having helped the help of an example what the what i'm talking about uh this how to calculate one one example to make it more familiar uh weighted entropy how do you take of the intubated entropy so you just multiple uh minus it with the weighted entropy okay after splitting entropy after splitting so let's see how it is done in more detail okay so i've just given you you what do what the formula is just to divide your data into success of your data like the divisions and then you take out the entropy before the splitting and then you take out the entropy after splitting okay so let's see so uh first let's take out the entropy of division number one of division number one here i'm going to take out entropy of division number one with the help of that plate in its data set okay so oops h of dv1 which is he there we have three five means first time writing for uh three means first i'm writing for yes okay first i'm writing for yes where we have our where we had divided our data data set into a yes or no so there we are having total of five examples where three examples are yes and two examples are no and out of five okay then the entropy will be 0.64 okay but you then again what you do you take out entropy of your division number two you it will be zero and it in the same you take out a division number for division number three zero point ninety seven okay what then what you do you do the you take out the average entropy and that's that's equals to zero point sixty four then that's equals to zero point sixty four and the formula for calculating your weighted entropy is like they just wait for a few seconds the formula for calculating your entropy weighted entropy is like this let me write it down first what you do you take out this i think it says it's not 64 it's yeah so i will just multiply with the first division number one here we at d1 the norm of d1 divided by d times the entropy of d1 then you what you do you plus d2 the norm of d2 times an entropy of d2 plus norm of d3 norm of d3 and this is the division number three data set divided by the norm of d okay and this is your full data this is d is a full data so you take out the size of that full data okay then you again d3 y okay and then this is your average entropy that you get after all of this after you've taken out the weighted entropy then that that will be equal to some number and then what you do you subtract you subtract your entropy previous entropy you subtract your entropy before the splitting you subtract to entropy before the spitting minus minus you get after splitting so let me write the formal equation for ig what you get okay so id ig equals to y and any var means variable maybe variable can be outlook a variable can be outlook or temperature temperature of that from that or windy or humidity okay so in that we will check if though if the higher the entropy higher the information gain is we can select that as a root node okay so what you do you just you just take the entropy of your data full data and then you pre premise of your data and then you minus it minus i equals to one although all the way on to the key the norm of di means the division of your data and this is simply uh the maybe satosa or then verse cycle or yes or no like that so divided by the full full d times the entropy of di okay so this is your weighted entropy this is your weighted weighted entropy and this is your this is your entropy okay before you're splitting and then you will get the information gain for that you for that variable okay so we will see uh one more example later on when we will be building our own uh decision tree by yourself mathematically so again let's recapitulate what we have seen so far we have simply seen we have simply seen so let's uh go back to that data set let's go back to that data set so here is my data set i don't know actually where yeah here is my data set and here what what we do we take this data set and we simply um divide this data set into multiple divisions into two divisions okay so we divide this data data set into yes and no okay and whatever number of examples will come we take out let's take an example here we have 9 over total number of data examples and here we have a five over total number of examples okay so what you do you simply nine by fourteen log of nine by fourteen minus five by fourteen log of phi by 14 okay then you will get some entropy which is your entropy of your data okay entropy of your data before is splitting okay so that's what the entropy is and i and i hope that you understood what i'm trying to say over here and this is your for yes and this is your for no because you have added a submission of your entropy like this i equals to 1 all the way down to the k then you have a probability of y i minus the log of means with base 2 probability of y i okay so that's what we are doing you are doing the same over here but this time you have 2 so that's what you're doing too and this is only for binary you can see equations for multiclass okay so that's what the an info information gain is and here what what we do we take out data in the our first we take out the entropy of that data and then we divide our data into multiple divisions and here we have three cluster um categories so we divided into three categories with two categories you could develop two categories and then take our entropy of that categories and then you take out the weighted entropy okay without uh rather thinking of the average you take out the weighted entropy of that uh after splitting these all you take out the fader entropy then you subtract and how you take out the weighted entropy here is an equation i'm going to give it to you it's just i have already given but more formally this is the equation for weighted entropy okay so what you do you simply it's the norm of d means no divided by what is the number of a full since here we have number of no number of a number of no divided by total number of examples times the entropy of that di okay so that's why who you how you take out the weighted entropy so after taking out the weighted entropy you subtract the previous entropy minus the weighted entropy okay so that's what we are doing an information gain i really hope that you understood information gain okay okay so please im see if on some blocks if you want uh either you can ask me in discord so i'll be very happy to help you in the newer you can find the discord server in any new era new video or new era you can find at it and you can join and there is a lot more of that you can and also if you want to support please kindly go to newer youtube channel newer youtube channel and please subscribe that youtube channel okay and if you can watch the whole tutorial on new era okay because you are going to get the uh whole at free over there okay so now we have seen entropy then we have seen in formation gain now it's time for uh talking about uh guinea impurity guinea impurity okay so this is also the most famous it's a most dissimilar and most famous that is used today which is guinea impurity gin impurity and it's just equals to it's very very similar to entropy it's a very very similar to entropy let me this is i use things very very similar sign okay don't comment it like this just i have just said it like this it's not i using it's just i have it's very very similar to entropy so let me give you one equation uh the equation for calculating the guinea impurity so i g and it is not an information gain this is a sign for a given impurity of y equals to the 1 minus i equals to 1 all the way around to the k and again it is the your y variable not anything it's the y variable again i have already seen y equals two and yes or no mean two or is it also versus color so unique values in your i times the probability of y i squared okay so that's the that's the thing and again it's if if we take us same scenarios if we how i'm saying it's if you take the same scenario as we have taken entropy some scenarios let's take an example of scenario number one scenario number two scenario number one we are your yes we have let's take a l let's take you have y to be two class category where you have the unique value as a yes or no okay so uh what is the probability means what is the number of yes is 0.5 and which is the number of nodes 50 okay 0.5 okay so what will be the guinea impurity gain impurity will be 1 minus 0.25 is 0.25 because if you square this because here we are squaring so if you square this and again you subtract it again you subtract it minus 20 uh 0.25 0.25 then you are going to get a 0.5 and 0.5 is maximum and gaining impurity 0.5 is maximum in entropy we have one as a maximum if it is this zero point impurity is zero point five then it sneezes for the splitting if it is zero then it's not neat if we can consider that as a leaf node okay so that's the scenario that we have already seen in and if it is in in the case of giving impurity our gain impurity in this case where you have 50 percent yes then it that that will be one so we have if you but you may ask here what is the ad advantage of gain impurity use rather than using the entropy so it is an alternative to entropy just to increase the computation just to increase to make it fast because in gain impurity if you have seen we are just taking a h of y equals to the minus the summation i equals to 1 all the way down to the k p of y i minus the log of p of y i so here you can see we are taking a log and take a look takes time okay so as an alternative a researchers comes with a very easy and fun under understandable way one minus and this these are this can be derived these are derived in information theory okay but i'm not going to go in information theory but you can see uh this is the for gain impurity and this is most used as an alternative to guinea impure uh entropy guinea purity is most yields as an alternative to entropy okay so that's the thing and i hope that you understood guinea impurity also so let's uh let me make you familiar with the diagram so here is the diagram let me make first for um entropy first here is for entropy so here we have zero here we have one so here this is for entropy we are here maximum is one and this is for obviously some something will differ so but uh the maximum is 0.5 you know engine impurity so yellow one is guinea impurity and the white one is entropy okay white one is entropy so i hope that you understood the why why i'm saying but why do you use gain impurity because because just and because it is more faster because we are taking log and that takes time this more faster than um entropy okay so that's the whole definition of all decision tree and that is i'm recording till 51 minutes and i hope that you understood all of this i hope that i've written a lot okay so uh we have learned a lot and i really hope that you understood also okay so now we will make one a decision tree classifier and i will show you uh the decision tree numerically okay how we do uh regression task and decision trees okay so first uh let's let's do in a fast way i i i do have not a lot of time over here but i will show you this data set so here is my data set which i'm going to use okay so first of all what we do we take out the entropy okay we take out the entropy we take out the entropy of this whole data set we take out the entropy of this data set h of d oops where is my pen h of d and simply what what we are doing here we have two y's so here we are taking the entropy of our data distribution d okay so that that will simply equal to 0.94 as i've told that you have to take out entropy before splitting okay for information gain so we take out the entropy where this of this data set as you have around five no five no and nine yes okay okay so and that way you can take it out uh if if i want to make i can simply make like like this five by fourteen five by fourteen log uh five by 14 minus 9 by 14 log of 9 by 14 okay so after you calculate you will get this okay so but feel free to collect correct me if i do anything wrong in calculation okay feel free to correct me in the comment box okay in mathematics we do i'm just doing it faster just we have to remember the concepts okay so after you calculate the edge of entropy of your distribution now what you do you calculate the information gain you calculate you calculate the information gain you calculate the information you calculate the information gain okay how first you calculate the information gain for you calculate the information gain for whether for why with respect to outlook variable means we have to check how much information that outlook variable contains okay so in output in outlook here we have outlook variable you can see over here that here we have outlook variable so let me uh let me take out so in outlook if you see the y variable we have in sunny in sunny we have two yes and three nos we have two years and three nos then we have in outcast we have four yes and zero nose okay then in rainy we have two yes and three nos okay so this is their outlook variable and here you have a two yes and three knows four yes zero knows two years three knows and this is for sunny this is for overcast and this for rainy and you can see over here okay sunny overcast and rainy okay so this is this you can see that if you take out the entropy of this entropy of this h of d2 d2 h of d2 then you will see that this is equals to zero and you can you can take this as a leaf node and it does not need further splitting okay so you can take this as a leaf node you can take this as a leaf node because this does not need further splitting okay now what you do you take out the entropy of this h of d1 of y okay then you take out this h of d2 d3 y okay so the you have taken this data set large data set okay taken this day it is set and it's split you have taken this feature split it okay so we have this before spreading and then you what you will do you take out the beta entropy you take out the weighted entropy weighted entropy weighted entropy which is equal to 0.69 okay so what you would for information gain you simply subtract 0.94 means the previous entropy minus the bit end drop is 0.69 okay and we entropy i've already shown you previously okay and you do the same for uh temperature you do the same for temperature very very temperature you have y in temperature where you have around in you have three classes high mean i think mil let me see hi mild and hot hi hot mild and cold okay so in what we have two years and two nos and here we have in mild we have four years and two nose and then in cool we have three yes and one nose okay then you take out then you take out like this and then you do for humidity then then you do for humidity humidity and then you do for a windy okay then you do and it's found that the that the information gain in over outlook is very high okay so what you do you take that and you take that only that outlook as your root note as your root node okay then then you take that outlook as a root node then you divide this then you divide this so here let me go to one of the one of my favorite decision tree pdf where i i will just explain you what this is okay so you think take this outlook as a root note then what you do you um divide this you divide this as as we have divided into sunny overcast and rainy sunny overcast and rainy and overcast you can see that we have entropy equals to zero so it does not need further splitting so we can consider that as a yes means we have four years so we can consider that as a yes because it's very pure and then its needs for the splitting and this also needs for this spitting and then at some point they are they also become pure where the entropy equals to zero so or the given impurity equals to zero then you consider as a leaf node okay so this is how we make the decision freeze and this is how we calculate the information gain this is how we made our decision free okay okay great now i really hope that you understood decision tree and now it's i i i also enjoy very much when i make these kind of tutorials this kind of tutorials and because it's just amazing just um helping students to make this uh understandable things okay okay great now uh one as we have only talked about classification so as regression is not too too much hard also so in regression let me show you what you are what what what we do in regression so let me take one let me go to the cycle learn decision tree decision tree cycle learn i hope that is stable yeah here it is so it explains very good it's explains very in in very good way so let me uh uh make you what the what do i mean with this so let me take an example of this a parallel and petrol width so in the same way here you what you do your petal length is smaller than or equals to zero two zero two point four five then guinea purity is high then you would split it okay here the guinea purity equals zero then it does not need for the splitting but it's needs for the splitting so it splits that okay so here it seems to be overfilling because if you if you leave the decision tree to be go as to ask as much question then it will over fit then it will overfit so what you do you either stopped at certain depth you either stop your decision to add a certain depth to make it more robust to make it more robust or you prune your decision tree by removing some some branches from here okay and you can see the same way that we have seen that we have made the this kind of this kind of decision boundary decisions uh hyperplanes okay great let's see some more oops i use brave as my browser but soon we'll get but soon we'll try something some please make sure that you can put your comment below if i can see okay and regression what what decision we can apply in regression also so you can see over here that here what what we do let me get back to some good pictures decision uh trees regression regression but i will soon go to documentation to show you uh more sophisticated in a good way okay so here is my decision tree regression and let's take an example of this as you can see from this also yeah so here is here we have a good example so here your predictor here you have a target variable okay so here you what you have taken you take an outlook and then you divide into sunny overcast and rainy and sunny needs for this fitting but overcast does not okay so most of the time you average it and then you take 46.3 okay and then you split it again you what you what you do is split it if you take out the average again i'm saying you take out the average okay that's what you're doing and again if you if i go further into this it is very well explained it is very well explained you can go to this it's very well explained but yeah it's only for regression but it's so much of um but what what we do we simply again the whole the things are same for attribute selection measure you simply uh you can sunny overcast rainy overcast over here is we have four um this is your leaf this is your concept this is a so pure so that's what is considered as a leaf and then what you do you take out the average like this you take out the average and then you take out the 39.8 46.3 over here after taking on average then you split your sunny into false or true then if it is false then your outward output will be 47.7 and if it is true then it is 26.5 in the same way you do the regression okay so i hope that you understood and you can go again to understand it more detail so so what you what you do you take out the hours played and our average standard deviation average and hours played and then you count it and then you simply uh do some calculation and that's not too much hard okay great so we have seen so far about a decision trees regression and i really hope that you understood this also okay so you can go to this node uh this tree uh this website say theresa dot com distribution we regret reg you will be able to understand them but it's more important to understand attribute selection measure because people usually confuse us at this and we have taken lots of examples for this okay okay great so now what we will do we will i will show you i will show you some i will show you the documentation the implementation the implementation for decision tree i will show you the implementation of digital regressor and residential classifier okay so that you can on because it's very important to learn from implementation okay so i will explain you in more intuitive way so let me open my ink to go i hope that i'm not i'm just using it uh let me see if this works for not for me or not okay okay great let me choose this pen yeah so uh here you can go to this website this table dot com and here you will be able to find more uh you can go to cyclelearn.org and documentation of this generic classifier okay so here again it should what is the criteria to choose the attribute here we have guinea and here we have entropy okay so you guinea is a default you can choose entropy also okay the quality of a split supported criteria is guinea and the entropy is for the input and the for the information gain after splitter splitter means do you want to choose the best splitter or random splitter okay best means is which was the best random is any ran randomly okay max that this is very important hyper parameter which you can tune it using great search cv using grid search cv or a randomized search randomized search okay you can tune it okay so that's what you will do and what you do you just you just um make your decision to if you do not make then it will fed or then the new decision will overfit okay so the maximum depth of the tree okay if it is default as none okay um if you do it will learn a lot it will make a lot of decision boundary to learn a lot until unless it's leaves are pr okay so it will learn a lot so that's why it will overfit so this is a very important hyper parameter then again you have a minimum sample split means here the default is two again you have to tune it again you have to tune it the minimum number of samples required to split an internal node okay an internal node is just uh that know the minimum number of splits that require okay this is two but you need to be uh very cautious under this okay then we have minimum sample split then we have minimum samples leaf and then the minimum number of samples required to be at a leaf node okay so what is the minimum number of a samples required to be a leaf node again is one but you can also tune it but it's not that but it's very uh good to tune it using great source cv then we have a minimum weight fraction leaf then we have what is the max features means uh the number of features to consider when looking for the best plate for a larger number of features than you can consider as an uh the default is none but you can use this but it it it also has some disadvantages okay okay then we have a random state control the randomness of your estimator again it's you can read some more details on random state uh max max leaf node the grow of a tree in a best first fashion uh it is the default none it's just like a max leaf node or the minimum purity decrease the node will will be split if the split induces induces a decrease for the impurity greater than or equals to this value but i've not used it uh if i say very much right it's just a limitation that you can make to prevent overfitting okay i think this is deprecated then you have a class weight what is the default is none always then we have alpha nonnegative value so that that's the basic intuition okay so we had talked about this and then you can see some examples and then there is something called as uh um let me show you uh you can also use this as a understanding residential structure so i will just show you one example of this okay so here you can use the graphis tool here you can use the graphics tool to plot your decision tree like this yeah uh you can he he has you three dot plot tree it is plotting the tree like this okay you because recently has one more is advantage it is easy to interpret okay so that's the basic intuition behind decision entry okay so let's go to decision tree regression okay so let me see where is regression okay let me see one more great where is decision tree regression here it is okay so in decentralized regression it can be used for this um uh this is uh for regression task also so here uh you have to choose certain criteria the function to measure here we are not using any entropy here we are using the quality of your split you can use mean square error means how how much it how much it differs okay so a mean square error error or mean absolute error or poison so you can see a frying freedman msc but most uses mse or ma or rmse okay a splitter again it's best again the same thing max step obviously to control your adapt to prevent overfitting this is an important hyper parameter again i'm saying this is a very very important vvi this is also very very important to attune okay then you have minimum sample leaf and then you have the same as we have discussed okay and then you can see some examples of decision tree like this how we make and then there are certain methods like plot or etc then you have uh some some some examples which you can see from here and this is usually uh you can use we will talk about ada boost also later on okay so you can see some visualization in this library and this entry is used to fit this curve with addition noise or observation and it's just controlled by the depth of that map by the max step and the blue line considers the two and the max depth of a5 if you take then it will perform very very well on the training set but that interesting set of you do not control your max that okay so we have talked a lot on decision trees and i really hope that you understood decision tree and that okay so in the next section the reason why i've taken this too long to make you understand decision tree because very very important concept to understand and and i think it's very very important okay so you can have a look if you want onto this notes okay but uh you can you can ping me on discord or linkedin i will very happy to give you these notes if you're not able to write either i will recommend you to write these things okay i will i will just you can ask me to make this all wrong okay so that's it for this video for this section so sorry um for this section and i'm my throat is also so much paining but yeah that's it for that's it for this section and in the next section we will start with ensembl learning and again then we will go to unsupervised learning then we'll talk a little bit about neural networks and then we will end up this course and you will be having enough understanding of machine learning to get started making projects in machine learning and getting a job or an internship but you have to lot of practice okay so uh you can do that okay great so thank you for this seeing this section and again if you have any kind of question you can ask me to the new era be sure to subscribe if you wanted to support this content okay so let's meet at the next section till then bye bye okay so now we'll talk about example learning one of my favorite topic to teach and to use in my professional experience so why why i think ensemble learning is one of the best for cargo competitions for cargo competitions and sample learning methods or techniques are most popular 99 of the kaggle winners uses some kind of ensemble learning techniques so that's why uh i think that ensemble learning is a mustknow technique it does not involve a lot of mathematics but it do involves only techniques concepts and a little bit more uh maths okay but in decision tree we involve some mathematics but here we do not end a lot of mathematics we require a little bit of mathematics but there are a lot of techniques and concepts that we need and approaches that a particular kaggle governor's thieves okay so it's very um we will give david and symbol learning covering the four three techniques i think the three techniques of ensemble learning the first technique will be a bagging which we'll talk about um not in it will will be in a separate section sub sections okay so this is our main section and in a separate subsection we will talk about bagging then we will talk about boosting then we will talk about stacking okay so these are the three techniques that we will talk about in ensembl learning and also we will see the implementation of each one of them and it and i will also show you some of the kaggle competition winners approach or we will make one model seeing the changes for changes they uh bring into your system how do your model accuracy increases okay okay so great but before that let's a little bit uh let me just forget about dominant sample learning let me recall use some concept which is high variance uh concept okay so high variance and high bias concept so it it should make sense to you so let's recall in high variance we have uh overfitting model we have our overfitting model if i'm if i'm correct in high variance we have our overfitting model and in high bias we have our under fitting model okay so our models should be low bias and low variance low variance model if you have a high variance if you have a high variance then you have then your model is overfitting if you have a high bias then your model is under fitting and uh that's that's what the recollection that that we need for this ensemble learning just to make sure that that we are in the same path okay okay so let's start with an a simple example of um of a small example okay so if we have played some quiz okay if you have played some quiz let's take an example that we have played some quiz of uh maybe in kahoot or anything any kind of quiz or if you are in competition you have played some quiz so it's a maximum percent a maximum percentage that the let's take an example that we have some question let's we have some question we have some question here and we have some option which is a b and c okay so let's let's take an example that the particular that the majority let's take an example a is a correct answer so it is it is very obvious that majority of the students will go with a and if the majority is on a then is likely to be a be the correct answer and it's actually the correct answer okay so it's like whatever the majority will say we will go with that okay here majority is saying a and in this case is a correct answer and if you think about the majority is more accurate than one majority is more accurate than one and in some exceptional conditions that can be different but in 99 the majority will win okay majority will win if you have seen some quiz okay so if you see that the option has got the highest majority and what also into that then you can think that is the correct answer so in the same way ensemble learning works in ensemble learning is a example of models is ensemble of models okay so let's take one more example to get more feel let's take an example that some election is happening some election is happening some election is happening and in that election and that election uh let's take an example that why we do not take only one person vote and select any prime minister or president why we take the majority the majority of votes which will go on to that party that will win okay so the majority will make a right decision okay we'll we will uh will make a right decision in most cases okay so that's what the ensemble learning also says and semilearning has ensemble of models so let's uh let me say let me tell you um what what we do in symbol learning we have a model one model two all the way down to the more okay okay so let me make you make this that it is visible yeah okay so you have these kind of models and you train your model you train your model you train your model onto your data okay you train your model onto your data and you can you take predictions from each of the model so let's take an example that you're trying you are making a diabetes prediction system diabetes projection system so your output will be either zero means nondiabetes or one okay so let's take an example that model number one says it's uh it's a zero model number two say it's a zero model number three says zero model of a force is a one and model number five says is zero so the the then what what we have a one more model a big model which which what it will do it will check the majority of votes and here the majority is zero and only one has given one and the majority of zero so we will give our prediction as a zero okay so we will see how it is trained later on but here what the actual thing is what is happening we train our model and each model is giving predictions and in these predictions we are taking into classification we are taking in class classification we are taking majority of votes means majority means m1 is saying is zero and two is saying zero the frequency of zero is more than the frequency of one okay so that's why our final prediction which is y hat is equals to zero okay and it's more it will be it will be high chance that if one model predicts if one model predicts it's a one or zero uh and the ensemble of a model predicts a zero then they are more accurate rather than this okay so that's the um that's the basic overview of ensembl learning and you may think here use in classification we choose the majority of votes but what about regression what about regression what about regression problems in regression problems what we do we take out the mean or a median uh um of out outputted from each model so let's take an example that your model m1 given some prediction which is regression value 2.4 model 2 given 2.6 model 3 given 2.5 so what you do the final prediction will be the average of these outputs the average or mean or a median of these outputs okay so that's what that's how we do in regression we do not take the majority we take the mean or the median of the output from the base models and these are called the base models over here okay so these are called the base models and then symbol okay so don't be confused what is base model base motors are the ensemble of models that are being trained uh and okay so that's that's the basic intuition behind our ensemble learning and i really hope that you understood ensemble learning and that okay so um just want to make sure that what how we train uh what are the some of the techniques used in this um used in bagging what means what are the techniques using assemble learning so we have a techniques like bagging then we have a boosting then we have a stacking okay these are and one one more which is cascading which is which which you can learn which is not yet in the industry yet but yeah one was just gas scanning which we will see if we want otherwise it's not necessary okay so in bagging we will see one algorithm which is a random forest which is which is something called as a random forest okay which is just an ensemble of a decision trees and then in boosting we will more probably focus on um we will in boosting we'll more prone to focus on gradient boosting we will more prone to focus on gradient boosting and we will focus on adaptive boosting which is just a advanced uh version of gradient boosting we will focus on adaptive boosting then we will see one winner which is xg boost okay so we will see these algorithms or these techniques in this boosting then in stacking we will see amal extend library how we do this stacking and what's the intuitive understanding and you can see there no money any kind of math this is only the concepts okay so that's how that's what we are going to see and the study motivation for this for ensembl learning why do we study ensembl learning has a great reason behind them the reason being why do we study this is the great question to ask whenever you do any kind of thing why let me use this good color why do we study i think that is not visible in most of the cases let me stick to white okay so why do we study and we study this ensemble learning the reason being is most of the cargo competitions most of the gaggle competition winners most of the kaggle competition winners competition winners uses some kind of ensemble learning either they use bagging either they use boosting either they use stacking either they use cascading they use some kind of ensemble learning techniques if it is a machine learning problem if it is a machine learning problem ml problem okay okay just think that machine learning has also a power okay so but there is a difference in in internet companies like amazon google they also uses these algorithms xgboost adaboost gradient boosting then we have a random forest in their own uh products of import production okay so um cora uses random forest to uh for quotient matching okay so they they also use machine learning these kind of algorithm and these are very very powerful algorithm a very powerful algorithm which is often used in industry also which is often used in many kind of kaggle competitions and around 99 of the kaggle competition winners are uses this kind of um any kind of ensemble learning either if it is a machine learning problem in deep learning problem you obviously go with it if it is image problem you will go with cnn if it is a text text you will go with some word embeddings and then you can use any other techniques and you can use r and n so it depends so you can use any of the technique if you want but in most of the competition in the past we have seen that they are the winners of the user okay so you can see the case studies if you want in detail okay great so we have talked about ensembl learning and in this section and now we will start a sub section which is bagging okay we will start a sub section which is bagging which we will dip dive into the bagging okay so it's also called the bootstrap aggregation or bootstrap aggregated okay so we will see uh late just one second okay so just to recall and sample learning is a b is an example of base model it can be logistically version it can be nine based it can be supported with the machine okay it's a classification algorithm whatever the majority of votes will be it will take the majority of votes and then gives you a y hat okay so that's how it works okay so um let's let's and in regression we take out the mean or median of your values great now we'll start a sub section now we will start a sub section which is something called as bagging subsection which is called as bagging okay so in bagging so in bagging uh it's again ensemble learning technique and sometimes it's called bootstrap aggregation and from bootstrap we deserve we derive the word which is backing like this bootstrap bootstrap aggregation agreement okay i think i'm my spinning is little bit wrong but uh just bear with me bad game okay so that's what the from the derived world from bootstrap aggregation justin shaw okay okay great so it's a statistics term if you've heard about bootstrap aggregation means it's a it's a statistics term if you can relate with your statistics and probability classes a statistics term so let's see the geometric intuition okay let's see the basic overview or intuition behind bagging intuition behind bagging intuition behind bagging so what we do in bagging so let's take an example that you have a data set that we have a data set d okay you have a training data which is d so you have a data so you have a data like this and what you have done you divided your data 80 percent for training and 20 for testing okay so now what you do that's just to make sure that you are on the same page on the dividation of your data also okay so you take your training data you trade your training data and your data is just um you take your training data like this and it's for your training it's a supervised learning algorithm so um you have x i and y i so you have your in x i with your label by i for all i one i equals to one all the way down to the m and m r is the length of your training examples okay so this is your data this is your training data this is your training data now what you do you sample some points let's take this sample k point or i uh let's see an example that you sample k points from this data set you sample you sample k points with the resp replacement with the replacement you sample k points with displacement from this data and you feed this to this model which is uh let's uh now you got d one which is d1 okay so you have sampled the subsystem sub subset of a data from this large data set okay sample k points you sample k points and now what you do you train your model using this subset of a data you train your model using this subset of the data and now you've got your model as a m1 okay this is your m1 mark okay but you may think here you just can you repeat it again it's all goes uh all gone above your head no worries again i'm explaining it's usually gone okay so what you do so i'm highlighting i in white so what you do you take your training data which is the which is a supervised running problem where you have a labels now you take out the samples with the replacement samples with a replacement and what do i mean by sample with a replacement i will talk about just after i make another sample okay so as of now just just understand we take out some sample with a replacement around the k points we sample k points or m points and um sam we sample some points um or we take out a sample of a data from this let's take an example this this amount of data from this uh this amount of data which any random data means and we have this is a hybrid parameter we have to choose the number of samples from this data and then we and then we call it as a d1 okay then we feed to the model means we train our model onto this data okay then what we do we again take out the sample again take out the sample again take out the sample k points with the replacement sample k points with replacement and what do i mean if your data is here if your data is here means if your data is here then it can be also here then it can be also here it is it is not necessary that your data should be different it can be same it is some data can be same here and here also okay so that's the sampling with replacement okay now your samples again that random data and it's not necessary that your data should be different from the d1 it can some data points can be included okay so you again sample k points and the and here you have a sample of a data from the large data and then you train your model onto this data m2 okay you train your model onto this m2 now again what you do you take out the sample you take out the sample you take out the sample k points you do it for your number of um base models means number of times if this this is also have a parameter okay how much you want to sample until you have your data points till k okay till k till k dash okay and then you train your model till am okay and then what you do you have your k models now you aggregate this into a large model you aggregate this into a large model okay and large m okay and in case of classification the majority of votes the majority of votes will go uh as let's take an example of ensemble learning that we have seen that let's take an example of diabetes and prediction okay so if m1 gives 0 m2 gives 0 and m3 gives 0 and m4 gives less than level 1. so the majority is 0. so the majority of votes will lead to the final prediction by okay in case of classification we think of the majority in case of regression we take out the mean or a median okay so that's the basic intuition behind and bagging and i really hope that you understood okay so let me explain it again those who have not understood please fast this video if you can because many students are still here that are not under that may not understand this i cannot do uh recapitulate or give a summary of this okay great so here what we do we have a large training data set which is d now what we do we sample our data sample k points from that data we sample k points from the large training data and let's say any sample sample sample of a data and then we train our model on these sample which is m1 it can be largest regression okay now we sample again k points with replacement and also it is with a replacement so it is not necessary that your data should be different from the d1 it can be same or it can be some data points can be same and then you again train so let's say example you train support with the machine let's take example you're saying uh nine days okay so you train and the majority of votes is like ensemble learning okay so that's what your backing is intuitively and you can see that we are not involving any mathematics yeah this is just a bunch of concepts okay so um just i will make sure that you all are on the same page that what it helps it is great great question it helps you in reducing the variance bagging let let me write bagging bagging helps you bagging helps you in reducing the variance it's we will discuss uh 10 minutes onto this also okay yeah okay so bagging helps in reducing the variance okay but before that there is one term that i want to highlight over here that here we have our all base models these are our base models m1 m2 and all of them are bmk these are our base models these base models are usually high variance model these are usually high variance with a low bias model with low bias model and what do i mean by this it is usually we do not do a lot of fine tuning we do not do a lot of fine tuning so that's why it is just overfitting and we had done overfilling so that's why just go down to any data so that's why it is not under filling okay so we have our the base models are high variance and low bias model so we do not do lots of fine tuning just we do a simple uh list in random form which just initialized with it with no no number of depth okay it can go as much as they can so it is overwhelming okay so here we have high variance model and low bias so what it helps what it helps backing helps in reducing your variance how it helps in reducing your variance from making your model more robust okay this is just um what it does is combines them so you have a low bias low bias high variance model now if you combine them if you combine the majority of votes then obviously we'll get a good amount of good good output or a correct output okay so you combine the models you combine these models you combine base models and then you get you then then you get low bias and low variance problem low variance okay this is what you get this is what you get after doing backing and this helps this helps in reducing your variance and this is very good and this is very good okay so there is some uh there is some i want to highlight over here that here we are doing the row sampling so just understand that this is a point that bagging helps in reducing your variance because usually your base learners or base models have high variance and low bias the bias and variance of that tradeoff that is high variance and low bias models so what you do you combine them uh combined based models with a lot into a large model and then you get a low bias and no variance models low bias and no variance m which is a large model okay so that's the that's the different uh now i think that you've understood why we call it as it reduces variance okay so here okay so here um what how we sample our data how we sample our data okay how we sample this is a great uh topic to talk on how we sample our data okay so here we are doing a row sampling we are doing row sampling we are not doing column sampling we are doing a row sampling so let me write it down while sampling while sampling our data from the large distribution of our data so let's take an example this is my large data in screening data now while sampling what we do we have this we'll do the row sampling we do the row sampling row sampling while sampling our data okay so let's take an example that we have d columns d columns and m are rows okay so we have this we have b columns and we have ambrose okay so we sample only rows and backing we sample only rows in backing okay so it can be like it can it can be go to d1 okay only those and backing okay so that's what we do in uh like a row sampling okay so we'll see in random forest we also do the column sampling plus column sampling okay and random forest we do this we do this but in bagging we do not do the column sampling we only do the row sampling so i hope that you understood the bagging also okay it's also got the bootstrap aggregation first your bootstrap and then you aggregate your base models okay so that's why the name it has a bootstrap aggregation okay so just to make sure that you all understood so i'm just recapitulating the sub section as you can reverse the video to know about ensembl learning because i don't want to just spend my time under that okay so here um just to just want to make sure that here you have your training data here let me see here here you have a training data which is you have a training data and then what you have done you take out the sample endpoints where the replacement okay into your data subset of the data and then you train your model m1 which is your base model it can register linear okay then you again sample k points and d2 then you again put a new model onto these subset of a data you do for k you do for k models or k subsets and then you combine the majority of votes majority of what will lead to classification and and if you use this regression problem we take out a mean or median of a most output from the model space models okay so that's the intuition behind bagging and it helps in reducing your variance it helps and reducing your variance because your base models are usually high variance and low bias model so it combines the base models to bring up low bias and low variance model that's actually good okay so and and in bagging we do the row sampling we do the row sampling means we we have a d features and we have m column and rows so we do sample of our m not d okay so we take whole column we take all the columns okay but we make subset of a rows for training okay so that's what we do in uh bagging and i really hope that you understood this bagging technique now it's time for learning well one algorithm would be one good algorithm one powerful one kaggle binning algorithm one production level algorithm which is random forest okay why i think random forest is a very very powerful algorithm to work on is a very very powerful algorithm to work on let me write a random random forests okay random forest it's a bargaining algorithm it's a bagging technique or you can call bagging algorithm okay so why do i call this uh very powerful because in also my professional experience i think that i have also used a random course a lot and it's it seems like it's this very powerful algorithm whether you want to win a card competitions and which is a machine learning problem or you wanted to make a production level machine learning okay so random forest usually used by quora then we have google amazon they they all use this random forest but it has some a basic intuition a basic concept that instructors are not teaching and it's very very important okay so first of all what we do in random forest so let's recall our decision trees let's recall our decision trees into this now our now our decision tree will play a role now here we have a decision tree so let's recall our decision tree so what we are doing in this entry uh we are doing an it is a simple it's makes a decision and splits your node okay so what you're doing it's a simple if and a nested if and else statements nested if and else statements nested if an else statement so we take if the sepal length is smaller than parallel and then you take a y equals to one like this okay which is a nested if and l statements just ask a question is just ask a question is just ask a question to the null and then splits the note and then it splits the note okay so you can the reverse stuff for the section of decision tree we have some attribute selection measure like entropy then we have uh information gain in formation gain then we have a guinea impurity which we have seen in detail in one hour of section of decision tree and i hope that you enjoyed that also okay so that's the decision tree okay so what is random forest random forest random forest is a combination of decision trees bt plus bagging plus bagging plus feature bagging plus feature bagging or we call it as a column sampling column sampling okay so what do i mean with this let's understand this is step by step so it's it makes sense to you also okay so what we do in random products we have our decision trees okay so you know about different trees so we have uh there's a 500 decision tree okay so random forest is an assembled learning algorithm so we have a lot of base models means decision trees lots of base models so here we have a large distribution of a data okay and here we sample our data d1 and we train a decision tree onto this data okay decision tree then we sample the two with the replacement then we train our decision tree onto this subset okay so you're not using different algorithm you are using only decision trees okay with the row sampling with bagging here we are doing bagging means the sample sampling with replacement which here we are doing a row sampling okay plus in bagging you're doing a row sampling row sampling and aggregating your model means whatever the majority of votes you will aggregate your model okay so you're doing the row sampling plus the column sampling also okay so here and this uh in a bagging we have only doing the row sampling we are taking whole column whole features but you are not but you are only taking the rows okay as a subset but here we are taking we are doing also the column sampling okay so let's learn to understand what do i mean by column sampling or feature bagging okay so the column sampling means column sampling means that you have this your data you have this your data like this you have this your data okay now you have d features you have your leaf features d features d columns like a b c d and you have ambrose amaros okay we have ambrose okay so what you do you for replacement you take any rows you sports for sampling you take your rows random rows let's take an example you took this row this row okay this row and and you took a and b as your column and then you train onto this you are not taking full columns or features you have taken this a and b and in their frame and then the next you t you took c and d okay you took c and d okay and then you train with one one row just an example you join this entry so they're different they are different and if they are different it's much higher chance that your model will be very very good okay ensemble learning if your model is different then this is then it's very very good okay okay great so that's the that's the random forest okay so we have a large number of decisionfree maintenance base learners as a base learners that are trained using a bagging technique means it's sampling rules with row sampling plus column sampling okay with a row sampling plus column sampling which is column sampling also called the feature bagging okay between different distributors and then you in majority of boats and and then classification you take them authority or in regression you take the mean or a median of the outputs from the base model okay so that's what you do in this so that's what you do in uh this car a random forest and i hope that you understood okay so uh let's understand it uh more intuitively uh that there is something called as oob it is something called as o o b out of bad points outer bag and this is called in that point so it's uh something called as outer back point so let me not recall this concept just now so let's let's take an example let's take an example that what you have done you have this dn you have this uh you have this large blouse training set set which is b okay which is d okay so what you do let's see an example that you've taken this sample of a data as a b1 and the rest of the data is called the outer back points it's called the outer back points so what you do you subtract means the train data minus the d i and i is the sample so these are called the left points after the sampling which is outer bag points okay out of bag out of bag points okay and this this this can be used for cross validation for evaluating your model okay so if you set omc cycle learn there is a very good library which is cycle learn if you set ob score to ob score to true if you said ob score to true then it will uh give you the ob score also okay so that's the basic or out of bag um points and i hope that you understood um out of ob uh points okay so now let's uh let's recapitulate our bagging and a random forest what we have seen in random forest and diamond okay so in bagging we have seen that we have our data we have our data d we have our data d okay what you do you take out a sample you sample with a replacement d1 okay then you train your model under this subset m1 then you're into d2 little trading water onto d2 and what you're doing you're doing is sampling with row sampling plus all i'm sampling with the replacement okay and d3 d3 then you getting your model b3 getting your model m2 m3 okay so the majority of vote majority will go and a large model means you just aggregate your model aggregate your model and then you get your final prediction which is why okay this is the whole pipeline so in in bagging you want to do the row sampling and random forest you will you do with column sampling as well as you only take decision trees as your base models okay so in bagging into different different kind of models by the decision tree and random forest to take your uh decision tree as your base model and distill through our train or different different data okay so that's the basic uh intuition behind the random forest and i hope that you understood also about what is com column sampling or watch it what is feature bagging okay and obviously this also helps in reducing your uh variance as it is a bagging technique so obviously it will help you to reduce your variance okay so that's the basic intuition behind branham forest so let's see the run time uh train train and run time complexity of this because if you if it is very uh uh it's very required to trade talk about train and run complexity of this random forest okay so in decision trees in decision trees uh the train complexity that the train complexity in decision trees the train complexity let me write in dt the train complexity is order of n log m n log n times d okay times three times uh yeah so it is a in distance we have n log n so in random forest we have d number of decision trees signed k number of samples okay number of models so that's the that's your model that's the uh train and run time control train uh training complexity of your random forest and the decision tree is just a analog n okay so that's the and d here is the number of k is the number of the models okay so uh it it makes sense also if you take an example of your d as a large data set okay let's take an example that you have a d okay now you take out a sample with a replacement with row sampling plus column sampling with like feature packing okay you take out a subset and then you train your model like m1 then you again do the d2 then you take out m2 so here the all the way down to the mk here you have a k models and then you have a d uh d decision trees okay so and also this is a trained uh trivially paralyzed it's a trivially paralyzed what do i mean you can train this model onto parallely okay you can train the model you cannot you you can train this parallelly okay you can take out a subset you train d1 parallely d2 parallely d3 parallely so this is a trivially paralyzed parallelized parallelized i think i'm pronouncing this correct okay this is a trivially parallelized you can do trivially parallelized also okay so that's the decision i'm sorry i'll train around turn around and complexity of random forest and i hope that we have talked a lot in short span of time and i hope that you're enjoying this video war section also and and i hope that you are enjoying a lot okay so there is one more concept that i will um talk on and end this video which is sort of this section which is extremely a randomized trees okay extremely a randomized tree so what we do with extremely randomized trees is very become popular after the cycle and releases its uh this api which is something called as extremely extremely randomized randomized trees okay trees so what is this this is in random forest we are doing a column sampling plus row sampling with bagging okay with bootstrap aggregation with bootstrap aggregation which is bagging okay so in uh run random forest and rf we are doing like this so in extreme trees uh in extreme trees we try out the possible values of um fi to determine the threshold means the decision trees and decision trees let's take an example that in decision trees we uh we have we have some epsilon and its checks is greater than ordinals like that for identifying in uh decision tree we are trying out every value and that is that is time that is that is taking time that is taking time okay so uh what we can do instead of trying out every values we sample we sample some subset of columns some subset of rows with some supplies of rows and check with that and choose the pressure according to that because in random forest we have a lot of decision trees and identifying the threshold is a key over there okay so if you if you take all possible values then and that will be computationally time complex time taking so what you do you try out the sample of values from that whole column okay then you'll try and that's called the extremely randomized trees okay so that's what i'm going to talk about extremely randomized trees just to make sure that we are on the same place that what what we were doing in random forest we have a lot we have decision trees we have column and row sampling okay okay and that reduces the variance okay so here um instead in random form we are trying out every in indianapolis and we are trying out every possible values and we are for for that epsilon so for a not for it's trying to time taking so what we do we take out the sample of values from that column and as a as a sample and then we check that for that epsilon 2 for getting that epsilon okay so if you're literally getting confused don't worry it's not a popular popular algorithm which is extremely randomized classifier or regressor it is not a popular algorithm the reason being if you take a sample there is a lot more less chance that your moral is good as compared to random forest so we will rarely use i rarely use this extremely randomized foreign popular algorithm okay so we have talked a lot i think that we have talked a lot on to this now you hope that you understood bagging then we have understood random forest then we have understood some decisions we and then we have understood that in symbol learning now we have talked about packing okay now in the next section subsection um point a point two we will talk about uh boosting okay and boosting we'll talk about gradient adaptive xg okay so we will talk about three algorithms here we have talked about the random forest and extremely randomized uh trees so in there we'll talk about three which is gradient adaptive and xg boost and a gradient boosting is also called g b d t g b d p is gradient boosting precision trees because they also use decision tree as their base models one little century as a base models but what are the some of the disadvantages of random forest the some of the disadvantages of random forest that it is very you it is very it is very bad choice to use to use a random forest or decision trees on large data set okay if you don't because it's very time complexive train taking okay don't use that kind of but you can obviously try it out at least okay you can see some more assumption on the internet for this okay great so now we have talked about everything now it's time for getting into the implementation part of random forests okay we will talk about random forest and decision trees okay either way i think that we have talked about decision trees so we'll talk about a random forest okay on cycle learn a a library okay so let's uh let's see the implementation okay so i'm on my grave okay so here i will write i started using brave in some uh just uh just a days ago just some some days ago so here what i will what i will write i will write a random forest random forest cycle okay and we will see one project we will see one project uh which will be doing all of this implementation with grids or cv fine tuning the hyper parameters okay so let's uh let's deep dive into this let's understand this concept let's see the implementation a very finest explanation of a random forest right here so let me take out my ink to go again because i it's my 212 days left that license expires okay so here i'm i will take my pen i will take medium i will take a good red color yeah so you can go to this api which is sk learn and sample you can also import by just calling uh from sklearn from sklearn dot ensemble from sklearn dot ensemble you can go with this and then you can uh use this api so the first um you will now now you can use the random forex classifier this is the first parameter is n estimators the first parameter is n estimators and estimators is the number of decision trees that you want okay like then what is the number of base models that you want what is the number of base models that you want so you have this data and you take this sample this data so what is the number of so you so here you should take 100 decision tree as a default okay but also this is a very important type of parameter so you fine tune it using a grid search cv or randomized search okay we will see implementation of these two okay so you can use this is the number of decision trees after you have what is the criteria what is the criteria to use in a decision tree what is the attribute selection criteria so the default is given impurity as the best impurity either you can use the entropy but this computation little bit expensive means a time time taking okay you can the default is guinea impurity is now uh the what is the number of depth of your tree the minimum number of a sample required to split and sorry the maximum depth of the tree to stop okay then the nodes will expand means if it is none then it will ah it it has a high chance that it will overfill okay now it is also hypergrammar minimum sample is split with number of samples required to split an internal node means what is the minimum number of samples to split okay samples means what is the number of data points okay then you have let me delete this again then you have uh oops here's my pen then you have a minimum sample of leaf which is which we have already seen max features means what is that you want auto or a square root or log you can read the documentation impurity then bootstrap bootstrap obviously equals to true it involves bagging where the row sampling with the column sampling ob score which is out of back data points which is out of the bag after sampling okay which is for n jobs if you take this n drops equals to minus one if you take this and jobs equals to minus one then it will obviously understand your course and then it will run parallely okay it will run results in parallel it is fast if you take adjobs equals to minus one usually people take okay but it's i think it's it's for printing out something texts okay now um you can see the class page let me see i've already also forgotten about class weight let me see class weight is yeah verbosity when filling and predicting class weight is just the weight associated with the class okay so it is obviously if the default is a none but you can see how it is calculated okay it's not max samples if bootstrap equals to what is the number of a max sample if you set it in none then the default is the x dot shape 0 the number of the samples so you can set some max samples okay so you have some attributes base estimator the child template used to create the collection of finished sub estimators then you have a number of classes here number of features the number of uh number of outputs when if it is performed the feature importance it is also you can use feature importance uh this attribute to uh understand what is the number of feature means what is the importance of your each feature in your model is columns ob score if it's obviously it will give you the in the float value okay so that's the decision tree uh sorry random forest and you can see more about this into uh here and you can really read about attributes and this is how the this is how the featured importance looks like means you can also plot it like this you can also plot it to so which feature and you can use it for feature selection okay great let's see the second one is a random forest regressor let me see yeah that i am under the same path okay so let's see again it's very similar to classifier it's very similar to classifier here here we have mst mirror which is number let me oops i don't know why it is very here we have number of estimators criteria to be msc rms mae okay max step max step minimum sample with bootstrap equals to true obviously take there take this okay ob score equals to false you get big yes or no okay somewhat default to get it is quite similar to that and max sample is none and it sticks a default as x dot so i don't know i don't know why why it happened max that is x dot shape the shape of your okay of your samples okay so that's the basic intuition behind this and max the max sample is also one hypergrammar great so we have talked about a lot about bagging and we have spent one hour on to this now you can see some more attributes you can see some more attributes over here to understand it much better so let me show you uh one uh one diagram that i found very interesting okay so you can see uh some examples using a random foreign regressor uh using a stacking so you will also see the stacking okay stacking is also a very good uh technique as a kaggle winner winning winning technique to use okay but um here you are here you can see that we only have mse we don't have rmse okay so rmse is not default you have to make your own function for our messy just squaring the root your mse okay but you cannot use if you want here your rmse okay you have to make your own you have to make your own i don't know why it is not running well i have to complain this okay i think this okay so for rmse you have to make your own okay but here you cannot use with this library either you can make a full request or on cycle or an atm okay just adding your own rmse okay great so now we have seen these algorithms now we have seen yes i'm going to do it so now we have stream extremely random there is one more left which is extremely randomized trees it just all got extremely randomized classifiers that's cycler it's obviously in cyclone because it's a new release of cyclone let's see this sound let me open it again integral it's very important now so here again we have mst meters criteria max depth is just the same and then we have bootstrap equals to false your bootstrap equals to false it should be true you can make this as a true okay then we have some more uh auto square etcetera you can it's just the same as that but there is some difference that is that that i've just told you that we choose randomly but what we do we choose a randomly sorry a sample and then we take out the sample epsilon okay so that's what we do in a random forest or extremely randomized classifier so let's see for regressor and aggressor is just the same i think that i'm not correct over here okay let's use the grasher and here the same thing over as we have seen and here bootstrap equals to false your end jobs is obvious that you are understood to run trivially paralyzed to create that option okay great so now we have seen about a random forest and i hope that you understood everything here okay so now in the next sub section we will talk about boosting now i hope that you will understand that also okay so let's wait at the next section till then bye bye okay so now we will talk about another ensemble technique which is boosting okay so boosting is one of the again one of the most popular as packing that we have already talked about bagging you just have to recalculate something about bagging that is necessary okay so we have talked about bagging and now we will talk about boosting which is one of the technique of ensemble learning and i really hope that you will enjoy this section and in boosting we will talk about in boosting we'll talk about something called as a gradient boosting and gradient boosting and then i will just give you a geometric intuition or i will just show you the implementation of adaptive boosting which is often called as arab boost okay then i will talk about extreme boosting x g boost okay so these three algorithms means xd boost works best in some cases xd boost works best okay so uh gradient boosting also works best but i am i it is also works best so we will see these three okay so let's start with this tutorial but before that um i i just want to tell you that you can do the problem set which is on github and you can subscribe the youtube channel just by going to the https https on youtube.comera because this highly motivates me to make content like this for you all for absolutely free okay so you can go to this new era to subscribe this youtube channel with 500 uh just just i have a 500 subscribers soon putting a deep learning tutorial there's announcements coming up soon putting a deep learning tutorial soon okay so let's start with this tutorial and uh okay so first of all what is bagging what is bagging that we have already talked about you can rewash that the bagging section if you want maybe in a fast way so bagging and bagging we have low bias model we have low bias model and high variance uh high variance models okay so our base models usually have low bias and high variance low bias and high variance means our base models usually have this low bias and high variance and using bagging we reduce this we reduce high variance we reduce this variance okay so our output will be after applying bagging we have our low bias and low variance model low bias and low variance model okay so what what we were doing in bagging we we are just simply doing the column sampling as well as the row sampling means we are doing the column sampling as well as the row sampling in case of random forest but it's just just take an example of random forest and then we do the aggregation aggregation okay so that's what we are doing and let's see um let's see uh just just uh just a recap what we do we have this large data set we have this large data set d n and then what we do we simply divide this data set into subset of the data uh with the replacement so i hope that you remember what is breadth replacement that the data which is here the data points which is here and it needs to be needs not to be different here it can be same in the second data set also okay so you sample them points then you again sample endpoints with replacement then you sample endpoints uh so you take in three subsets of your data and then you train your model train your model onto this data like m1 onto this data maybe logistic regression maybe linear regression or maybe support vector machine so you have three models and then if it is a classification problem you simply uh take the majority of votes majority of words that this particular example is of a particular class or if it is a regression problem then you do the average or me or you take out the mean or a median okay in case of regression so that's what we are doing and in random forest we this is these these are called our base models and in random forest we have our base models as a decision trees we have as a decision trees okay so the this usually helps in reducing your bias and reducing your bias okay so that's that's the bagging so let's see what what we have in uh boosting boosting is just opposite in case of bias and variance tradeoff so just just now i think that you know why we have learned bias and variance a lot okay so in boosting we have low variance in the in in this case we have high variance but we have a low variance high bias model here we our model is under fitting we have high bias model okay so it is not performing well on the training set okay so here we have a high bias model and then what we do we additively combine additively additively combined what do i mean with this this is a very great uh question this is this is what we do in here in bagging we are doing the randomization we are doing the bagging means column sampling then row sampling then we have aggregating the model okay but in boosting we have additively combined that here it combines the week with converts the weak learners speak models into a strong model okay so different different weak model uh tends to be a great model okay just we will see how it tends to be a great model so it is just combined so let's see let's see the core idea so the the basic idea of using boosting is using boosting is to reduce bias if you have a hard bias model then you likely to use boosting to reduce the bias of that model ah yeah there is uh some other techniques also that that we've already seen but it's just we use boosting to reduce the bias okay so let's see so let's see the the basic intuition about boosting so let's take an example that you have your data you have your training data so i'm just writing my training data uh where do i write here you have your training data which is your training data i'm just writing train d okay which is usually which is this this is a supervised learning and a supervised learning technique so you have x i and y i with which is a label and it goes i equals to 1 or we can write the i equals to 1 all the way down to the maybe m okay here m is the number of training examples into that a training data okay and then you make a model and then you make a model then you make a model at m1 so let's take an example that you have made a moral m1 that simply uh that's simply a function f of that is simply a function f of x which is our hypothesis okay so now what we will do this is the this is the core idea behind boosting so so we have a training data you have your training data like which is your training data and you train your m1 model onto that now what you have seen now what you have seen you simply take out the error you simply take out the error means the cost function the loss okay loss for either example loss for eight example so for each example you have y i which is a ground truth which is your ground truth minus your moral predicted value while more predicted value is f of x which is uh even when you input x then you get your output so model predicted value is f of x okay this will give you the loss okay the loss for if it is if it is 0 then this is very good if it is large then it is very bad okay so here we are using just a simple regression loss means just a loss so if you add a submission over here if you add a submission i equals to one all the way down to the m y i minus f f of x then this is the like mse but you do a square in msc but now because of the gradient decent to effectively compute the derivative but here uh you can you can just see just just as a simple conversation what we uh just just we are taking the laws for each training example so here let's take an example that we have take take take in a loss and then what we do and then what we do we train our model onto this loss means we train our model to reduce this a residual error to reduce this residual a residual uh error okay we probably focus or we we more focus on to the data which is misclassified or mis uh which is which has a very large uh error okay so we focus on that okay so what you do um so for really so you want to reduce this error so how you want to reduce you want to make a model make a model m that that that is given x i means you fit this residual so let's take an example i'm just i'm just going to take take an example to make you this statement clear that what you do so let's take an example that you have a regression uh prop problem statement so you have a regression problem statement oops i don't know why i'm making a bad yeah why my xaxis is not working great yeah here is my xaxis a bad xaxis and you have an x like this x like this and then what you you have fit in a straw maybe this line okay a straight line so here it for this train example the loss will be very high so it will uh more probably start focusing on that and it'll fit on that residual covering this okay so maybe it will it will do like this okay it will also cover this if the residual is very high so it's always tries to minimize that residual maybe it can make a knowledge either the example is too much alandi but either it can make a nonlinear uh decision sorry hyperplane okay so uh for so what what we do we fit our error so we make up model m1 that minimizes the error by fitting onto the error so here is the li for i equals to 1 all the way around to the m okay for each way example we are fitting a model okay so it is more probably focusing on the data which is either misclassified or which has a high uh the partic mse or mae okay if it is a regression problem then we take msu or it is or which is misclassified so it is more only focusing on that okay so that's the basic intuition so let's let me uh let me make you uh the full equation how it looks like so you have you have f you have f of x f of x with k means and some uh just just a model a big big model means f of x okay for each frame example i equals to zero all the way down to the k okay all the way down to the k you have an alpha you have an alpha times your model i th model so you will not only have one model you have in first model that fits them that second model that covers that that fits that stress residual then third model that fits that residual from this model fourth model that fits that residual from this model means error okay so we have a different different model so we have a large model this k and we go through each and every model with some la uh just as assume as lambda so we have this uh just uh just as of now just consider this as us we have computed this somehow so we will see how it is computed okay we will see uh when we learn about uh some gradient boosting okay so just to assume that we have some uh uh just a lambda a constant okay here this f of i x that is that is trained to fit the residual trained to fit the residual from the previous model okay from the previous model means this model this m2 train to fit the error we get on m1 okay so this this model may have some different thing this this model is able to correctly classify the error from this first model this m3 is able to classify the errors from the m2 so like like that okay so that's that's the basic intuition behind boosting okay so i think that you have understood about boosting so now this will end it up this this function this function will be ended up giving you a low bias low bias and a low variance model okay but there is a problem there is a problem so you may think hey i use can you name a problem yeah sure i am here to name okay but before that you can take a break if you want because i'm just it will just take more one hour to complete i think so it's my approximating time so it will take one more hour you can take a break or you can do just a prop problem set if you want but start with the section and then complete the section then see the prop problem set then see some challenges given to you in my github and i really understand that you will be able to do that okay so here you have this one first you have a training data then you have a low score loss for your showing example then each model trend each model tend to um each model tend to fit the residual error given from the previous model okay and in that way they end up being a low bias model and it's very good on training set but there is a problem the problem is that if it is too much good under training set means only 100 accuracy on training set then what will happen then what will happen it will start overfitting new training example will come then it will able not to classify or detect a good uh prediction okay so that's way so that's why we have to take care of how many number of base models so that we have a lambda but we will understand this all okay great so we have understood this and so the core idea behind bagging the core idea behind bagging is not too much hard is just saying is we just use bagging sorry oh this is boosting oops it's boosting the core idea behind boosting is to reduce the bias reduce the bias on the frame like that okay this this converts the weak learners into these strong learners and here we have a good finetuned models which is converted into majority of words and then in bagging like that okay so let's see um so that's the basic intuition behind boosting so there are some of the techniques that we'll study about like a gradient like gradient gradient boosted gradient boosted gradient booster decision trees decision trees which is often called as g b d d okay uh this is a this is because because in random forest we have our decision tree and here in gradient boosting we have our base learner saturday decision tree and gradient boosting as a base learner has a decision tree and then we have a adapt adaptive boost which is often called as adap boost which is a little bit uh more advanced version of gradient boosting then you have extreme boosting which is x g boost okay which is again a family of a good algorithm and it's always outperform it's very very powerful algorithmic boost as i've seen so far and we'll show you the implementation of xgboost also with some i will show you how it is implemented and everything and this section valley okay so and that's the basic intuition behind bagging and i really hope that you understood bagging in detail just to recap that boost or helps and why i'm saying bag bagging it's a boosting okay so boosting here in boosting we have low variance and high bias model we additively combine with in which we convert our speak learners into strong learners and the core idea is to reduce the bias it simply means that we want to improve our error under training set okay so that's the basic and we have four which we'll cover in this section which is gradient booster decision trees adapt adaptive boost then we have a x g boost okay so uh i think that you are understood about boosting okay so now we will talk about uh gradient boosting which is again a good up a very fantastic brilliant uh uh algorithm okay so to just just use an internet companies or very big pump companies which is used in ml in production okay so which is usually launched in 20s these uh algorithms okay so we'll study in detail to make you understand each and every concept of gradient boosting and then we will see the implementation then we will see the adaptive boost then we will see that xt boost and then we are end up with this ensemble models okay then we will go with uh unsupervised learning techniques okay so uh just uh let's let's start with gradient boosting now we have talked about gradient sorry the boosting uh the basic intuition behind boosting what actually the boosting are so now i will start talking about a gradient boosting okay so gradient boosting is another yet one of the most powerful algorithm that i've seen so far uh yeah one of one of the most powerful algorithm which is uh which is yet to uh uh just learn it's very to have a good in your tool kit okay so i'm on a wikipedia page i'm on a wikipedia page which i found a great machine this great uh algorithm which is again uh which which just tells you a very good intuition behind gradient boosting rather than just i make use of my blackboard either i will make use of my blackboard over here okay so uh so uh what is so what is gradient boosting this is a great question so creatine boosting is a boosting algorithm that just converts the weak learners into these strong learners okay so let's start with in this uh gradient boosting and you can search for gradient boosting wiki and then you will see the gradient boosting wikipedia articles and then you can read the full articles either i will cover everything in sort uh in sort uh pdf period of a time but i've already covered some of them and and of my just i will cover i i have covered more than this wikipedia okay so i will give you some a real world examples of gradient boosting also where it is used and everything okay but first of all let's understand the trend this the this algorithm okay so let me see my pen is at least working or not i hope that this is working yeah this is working great i'm just happy that my ink is working let's try if the ink to go if you're watching please help me to improve this very it is not that much good okay just to improve this but it's very good tool it's some sometimes it lacks but it's a very good tool check it out it's very good great for free okay so you have this training data which is a input training data you have this three input training data which is your which is the set of let me write the training data which is simply your x i and y i and simply goes from i equals to 1 all the way down to the n okay or m which is our let's let's stick to our formal notation which is m which is a number of training examples number of a training or the size of our training samples okay so that's the that's our given data and we have a differentiable cost function then we have a differentiable cost function okay so what do i mean by differentiable cost function differentiable cost function means that your this cost because we take out the derivative of our cost function we take out our derivative of our cost function with respect to some some value okay so let's take a we are taking out the derivative of our j of theta partial derivative over j of theta okay so that's the that's the basic uh about means uh that's the differential equation that i know if you know if you're a calculus student then then you might interpret that we have a differential but as if if you're not able to get what is this differentiable feel free to leave this differentiable just think that it should be derivable okay for our gradient descent or we will be because we have to take out the derivative of this particular loss function with respect to some uh weights okay so we with that if we are given training set which is d train we have a given a training set which is a value x so x i and y i which goes from i equals to 1 all the way down to the m okay where is my eraser i think that this is my eraser yeah i equals to 1 all the way down to the m and then we have a differentiable equation as given so let's stick to the j of y y f of x and this is simply just the error means just a minus the minus uh your moral moderated value for each and particular examples i equals to 1 all the way down to the m and then we square it all up okay so that's the that's the our cost function maybe it can be mean square error or it can be long loss for classification etc okay then we are given the iterations then we are giving the number of iteration which is m and m here is the model m here is the base learners m here is the number of a base learners number of a base learners number of a base learners okay so so this is the number of base learners which is m now let's start with algorithm so what this algorithm tells you so let me choose the different colors so it might make sense so we initialize our model with some constant value lambda with some constant value lambda in that case we have in uh alpha but now we had changed a little bit that we have our favorite lambda okay so we have to find lambda oh no okay let's uh just think of it as that we have a lambda we have a lambda that we have to find that lambda that minimizes this training error this loss function it should be told here but i have told you here just in my excitement so you what you do you initialize your model with some lambda that minimizes this cost function okay so this first to initialize this uh that's and we will see how this lambda is computed here but first of all you initialize it and then what you do you iterate through each and every model okay first you go first you do this for first model then you do again for second monuments you apply a for loop where you for m equals to one first u two m means you want to go one two three all the way down to the m okay so you do this and then let me first of all let me okay so here then what you will do then i hope that then you initialize your model then you compute the residuals you compute the pseudo residuals you compute the pseudo residuals you compute the pseudo residuals and then here it is named as r uh subscript i and m and m here denotes the num which model and i here for each 20 examples okay so here you compute the inm and then you take out the partial derivative the partial derivative oops what is not working partial derivative hey god please help me the partial derivative of your cost function y i of your cost function y i and f of x so this is your loss function with respect to this function okay f of x your moral projected value okay and then you want to fit your model onto your previous uh residuals so for you go to i equals to 1 all the way down to the end so here you take out for f of x means f that means here here you are uh fitting your model means just you are making the model to be f of m minus one means the previous model okay so you compute those residuals and then you fit the base learners okay that i've just showed you in my in my previous uh just in just just in the boosting that we fit the residual so let's take an example we have n m1 m2 and m3 we have taken the residuals we have taken the residuals and the here is give some residuals this m1 is trained to fit the residuals from m1 this m2 train to fit the residuals from m2 okay and this is m3 okay so it is trained to fit the residuals of fam too okay so then you fit a base learner or a weak learner let's take an example three closed under scaling of h of mx here is your two residuals to pseudo residuals means to fit the learner to fit the residuals from the residuals got from the previous base learners it is to train it using the training set this one okay and now here m is in our case which is l i on m model okay so then you fit your model that i've already showed you just similar that we have seen and then you come compute the multiplier which is a constant multiplier lambda m for each model you have lambda m okay which is a one dimensional optimization problem for solving the one dimensional optimization problem so you may ask why do we are choosing this lambda m so for solving one dimensional optimization problem going into 1d 1d 1d optimization 1d optimization is out of the boundary course but you can see on the link okay the how you compute you compute lambda for each model that minimizes the loss of y which is ground truth from the previous model plus plus lambda times our just the model that that we have now okay now what you do you update the model now you update the model to be to with the model to be fitted by the the model that fitted the previous residuals okay so f m x here m is our moral number the means model number then we have it then we have this f of m minus one previous model plus lambda m lambda m which is some constant for solving the onedimensional optimization okay because we are taking the partial derivative of our loss function y i and f of x i with respect to f of x i and f of x i is our model predicted value okay times h of mx and then you get your output as an f big model m m big model all the way down to the x okay so here you when when you cover all of this you when the loop is done then you get the final model which is f m x that is simply f of m minus 1 x plus the previous model this previous model plus the a model that we got after solving this or 1d optimization problem okay so that's the gradient boosting uh algorithm that i really hope that you understood but let's uh let's uh just just as a recapitulation to help you understand a little bit much better to uh understand this problem okay so what we do let's understand what we do over here so we simply first we have our given our training data we have a training data x i and y i going from i equals to 1 all the way down to the n and n here uh and and here i just hope that it should work now and n here is your and here is number for training your number size of your training set then you have a differentiable loss function with the number of base learners that you want okay then you initialize the model with some constant okay then you apply a for loop in that for loop you take out the residuals you take out the residuals for and and then you name it as a r subscript i which is the number of training exam that the index of between example and m is your number in the index of your model okay minus the taking of the derivative for partial derivative for of your uh loss okay okay and then you fit a base learner or a weak learner because there because it just makes you a weak learner to the strong learner okay to closing under h of mx which is your got from the weak model makes you just fit the base learner to to the residuals so it's simply that you know that you are going to fit your model into x i and your l i which is simply l i is this okay now you compute the multiplier lambda m lambda sub 10 for each particular uh m means the model index for solving the onedimensional problem so it's just to find the lambda m that minimizes the loss that you get y y i comma the output from this model okay this is the whole model now this is a previous model that is this is a new model that is fitted to fit this residual okay and then you update your model okay then you have to output a big model which is m ffmx that is simply this f minus one of x i plus your big model uh now you just after your full iteration you'll be ending up being a big model okay so that's the basic intuition behind gradient boosting i really think that you understood about gradient boosting now uh now it's time for getting into the uh for getting into the something called as a regularization and uh shrinkage okay but before that why do we need even regularization and shrinkage so why do we need as we have already talked about that we have and that we have in boosting we have high bias we have high bias let me see the recordings are on here oops we have our high bias and low variance problem sorry high buy so we so we use boosting to reduce the bias to reduce the bias so high base is just doing barrel training set so if we just after each iteration we are fitting the previous model residual so yeah it is making a knowledge it is doing very very good on training set so very very good on training sets so it may happen that it may start overfitting and our low by variance goes to high where starts goes going to high variance means our low variances start increasing and now it's converged to high variance so that actually can cause overfilling okay so for avoiding we add regularization and shrinkage which is again shown in the wikipedia page let's see so here um i think that i can teach you better than wikipedia page okay so you have you this big model you have this big model f of m x which is here you have a h zero x plus you do for i equals to one all the way down to the h all the way down to the edge it's number for your model lambda m lambda m or you can see m the number of a model okay h of m x okay so that's your model that we and then what do you do then if the number of a base models increase means it will fit more residuals if the it will fit more residuals more residuals then your over fit will then then over then it will start over fitting start over and if it is start overfitting then your variance will start going up okay so that that will cause the problem so what you do you shrink you shrink by a factor of lamb just a there's a greek letter that i even don't know that is something called as a v so let's assume that is a v which is a parameter v okay so we have a parameter we have our parameter v which will help us uh which is just a parameter for controlling the or it's just shrinks your strings it just strings to do not go that much means it gives a weight it is just a learnable parameter just gives weight and empirically it is found that v equals to 0.1 tends to be a dramatic improvements in your models okay so that's that's why we use uh this v this v to be 0.1 and again your v should be in between your v should be in between 0 and 1 and it's found that v equals 0.1 would be dramatic improvements in your models okay so you add a new weightage to that model means to this model okay you add british to this model that i've just shown to you advantage to that model and that's called a learning rate for how for how much time for how much rate it should learn okay so that's the so that's we add v direct model so let me add that so let me add that so what you do for you just shrinks your model with shrink your model big model by going f of m minus 1 x plus v times lambda m h of m x and v here is in between in between 1 okay and particle is found that b equals 0.1 works best okay so that's the that's about uh gradient boosting and i really hope that you understood this also okay so now it's time for um we will take a look at implementation okay so now we will take a look at the implementation of gradient boosting classifier and gradient boosting a regular eraser okay but before that let's see the training time complexity of your model so uh let's let's recall of decision trees and decision trees uh we have our train and run time complexity so here we and decision tree dp i'm writing dt we have old and oops i am writing this n log b and here d and then random forest you have o order of n log n number of addition treatments k okay now when gradient boosting decision tree means here we we just take our base learners as a as a decision tree rather than different different models so we have o n log d times the number of a models okay so that's the basic uh uh time complexity of your gradient boosting decision trees okay great now we will see something called as uh now we will see the implementation of this uh gradient boosting decision trees and cycle learn api okay so let's see so let me open gradient boosting implementation implementation okay and scale learn let's see yeah here we found this wait for a few seconds is just loading okay great so now here you are you are on a page of cycle learn api gradient boosting classifier and then you can see over here that um now let's see the some of the parameters that we are over here so here that you have a loss that you have a loss which is the deviance deviance refers to the log loss an exponential um refers to the which which is just adaptive version which is if you set exponential then your gradient boosting will go will will be as will be called as a adaptive boosting or ara boost okay so in adaptive boosting it is more pronely we will see the implementation so in ada boost it is more pronely focusing on unclassified okay more more probably focusing on unclassified but it's not being used too much okay so we have a loss equals to deviance which is it was a legislation laws or log loss okay then you have a learning rate means the rate to string the contribution of each tree by learning rate okay so this is used to reduce your uh over uh variance okay so that's your model does not start overfitting okay so uh this is your learning rate which is default 0.1 and leave it 0.1 okay because it's found that most remember dramatically that they work best in most of the cases and then you have a number of estimators which is number of decision trees subsample criterion min sample split min sample leaf min weight fraction max therefore e3 min impurity these are particularly for each freeze and then you have uh let's see something more of that we have a validation internal change and then total ccp alpha that's not not too cool okay so we have this and these are some of the hyper parameters that i know that you had understood everything okay so you can see more about this in the parameters in detail here but we have already talked about decision trees already okay so let's see the implementation means the implementation of this uh gradient boosting is just one line of code which is here and you can use predict probability it simply gives the probability of that being a true okay for that class okay so first you import from scalar dot in symbol input gradient boosting classifier here is your data means and then you call your with an estimators learning rate 1.1 okay 1.0 max depth random state and then you fit it and then you get your score okay so that's the basic intuition behind a gradient boosting uh classifier okay now let's see the gradient boosting regressor gradient boosting regressor regression and sk learn okay so this is a very good to learn from the documentation okay this is very good to learn from the documentation so let's see okay here here we are on uh documentation of a cycle learn api now what we will do we will just let's use the pen and then you can see over here that we have a loss function to be optimized miss l as the refers to the least squares l a d means least absolute deviation is more robust okay so if you have a uber then we have a quantile but the default is ls okay then you have a learning rate however how much this is a for shrinkage then you have a number of estimators then you have some sample criterion min sample split for each particular decision trees these are for each particular decision trees and then the same thing that we have seen so far okay so now uh we are uh this is the basic for the decision trees and i hope that you understood okay now let's uh see the implementation of this i'm literally going fast because i have to teach also that xg boost and arab boost okay so you just uh call the a gradient booster pressure then you call the your train just split then you split your data and then you call your gradient boosting restore with the default parameters okay then you fit it okay and then you simply do the gradient boost regressor then you score it and it reuses the sum scoring parameter it's the long loss or sorry not log losses maybe it uses r2 or msc you can see okay so that's the basic intuition behind how we implement a grasshopper and classifier which we will do in project just to showcase you how you can assess from documentation it's very good to learn from the documentation now it's time for learning from for uh now it's time for to that you'll learn about xge boost we'll learn about uh uh but before that let's uh let's learn about ada boost okay adapt so let's see me upside i want implement scalar okay so if you set your uh loss to be exponential okay to be exponential then it will be equivalent to ada boost classifier boost classifier okay so it will set your laws to be like this and it's just the same as that we have already talked about we have two algorithm given by sami and sammer which is in sammer which is also for legit regression if you have seen is the cycle and api okay so how you implement from arab boost classifier then you call this and then you fill your model and then you are done okay it's very simple i i think that you but just remembering the concepts is very very important because it's not always you have to implement maybe your own something algorithm in your company okay you may think yeah you can't we just study the implementation no no you cannot study okay but cyclone api is very very slow very very slow but it's great but what you can do uh you have to in in some companies for production uh because it's a kaggle winning uh algorithm that we need to understand what is happening how we can tune the hyper parameter okay so here you can see again for regressor okay and here you have a loss equals to linear and then you have a square and then you have exponential okay and here maybe we we do have and not lost you can see state the number of the classes how many number of a classification classifier okay so now we know about this and i really hope that you understood uh the following now it's time for uh learning about extreme boosting one of my favorite but i think adaboosh is not used in production uh many um not uses too much in the production maybe uh i'm not right over here but i think so okay so now we will learn about x g boost which is one of the most popular algorithm which i have seen so far okay means a t okay it's a it's a good algorithm it's a good algorithm but it's one of the best algorithm that wins your kaggle competition okay so now we will see what xc boost does it's just the advanced version of gradient boosting it have it it it does have gradient boosting decision trees plus it has randomization with row sampling plus column sampling and in gradient boosting we are not doing this but it's at randomization which is grow sampling plus column sampling so that's why maybe name it as a extreme gradient boosting and it's works best okay this works brilliantly uh since some cases and machine learning problems okay but it needs fine tuning a lot okay so the gradient boosting decision tree now you have a row it's just how we differ from gradient boosting decision trees you have you do the randomization by doing feature bagging and then you have a row sampling okay and it's just for a simplicity let let me explain you what we tend to learn about this what we do we simply sample the rows as well as the columns for our data okay okay and uh and specifically for bagging we don't know columns we don't do column sampling but in a random random forest we do both so in xgboost we do the gradient boosting crystalline trees as well as a random forest plus uh column sampling okay so that's the that's what we do randomization and that's the xd boost okay so now we will see in detail what actually the xg boost xd boost from the official documentation but but it is all it is it is of course implemented in the it is of course implemented in cyclone api but it's uh but it's very good to use because there this is fast actually it is fast actually it's very good to learn from here rather than there okay so i think that we can found get a the python package because we have different different package no setting parameters oops where it is xgboost uh python package okay so here we have some parameters an xg boost i think that my brave is not working i have to again switch to my favorite chrome why i have switched it to this it's bad x uh brave is actually not good for me and since some kids actually i'm like who am i said to say bad but it's good good but it's all of course sometimes it does very bad okay so let's see some of the parameters let's see some of the parameters so we have different different packages that we had that already been implemented this algorithm so here you have booster which is gb3 means gradient boosting tree you can use the gb linear or dart the means vu's will use gb3 then you have a validate parameters default to false means it's just going to validate your parameters or not then default to maximum number of threads then you have an evaluation matrix then e term is learning rate okay is 0.3 okay gamma which we have seen which is the constant which is zero as default and this just we just randomly initialize means and then we find a good gamma and then what is the max depth for each tree and you can read the documentation over here more minimum child weight minimum delta step means what is the step should one uh maximum delta step we allow each leaf output to be if they it means there is no constraint okay if if means it's just like that it's just uh helping you to not too much pruning to overfitting it's more robust model okay so you can see your lambda means l2 regularization like a lasso and this is for red regularization that is alpha regularization okay then we have a tree method which is exhibits construction algorithm using xgboost you can see the reference you can see obviously see the reference it also supports uh hist and etc then it's a have a scale post weight updater which is process type group policy maximum number of leaves but is to point to zero um to be added okay so max bin predictor then we have a gpu cpu but this leads a lot of fine tuning it takes a lot of time in cpu okay so we have this much and you can see more about this it's very long set of parameters but we usually use the main parameters that we have listed okay so you can see a python package first one you want to install it you want to install it you can just pip install xgboost and then we and then you just call xgb dot d matrix first you convert that into a d matrix then you uh uh do that means you can do also for pandas using the cylon api but it's okay to use it but you can see over your implementation sk learn it's also for regressor that we have seen i think that we had they have removed i think not they have they haven't removed no no worries so you can see from here how it is used and how we train this model and how we save this model uh it's just like a neural web as you as you know that tensorflow has also added decision trees and like that in simple learning it started adding because one of the most powerful uh algorithm in stem learning okay so we have seen a lot in in decision trees okay uh sorry in ensembl learning like bagging and boosting okay so now one last step is left is stacking of your uh stacking okay so after this section we will start with the stacking to help you to better understand what actually stacking is and it will obviously help you okay so we have seen a lot of applications of this and i really hope that you enjoyed it also okay so this this section is just amazing we have learned about boosting and we have learned about gradient boosting they are adaptive boosting they have learned about exege boost okay and so one of the projects will finetune we'll use xg boost ada boost with finetuning okay one of our project okay so uh that's it for this section in the next section we'll start with the stacking there's a one only 20 minute session on stacking will take and then we just with some other summary or revision of ensembl learning okay so let's meet at the next section okay so now we'll talk about our lawson symbol learning technique which is uh called stacking of our models okay so we will see the implementations of the stacking so and we will see how it works and how it changes your accuracy okay so let's recall uh something called as bias and variance of our bagging and boosting okay so when bagging and bagging we have high variance high variance and low bias tradeoff okay and in boosting and then boosting you have low buy a high bias high bias and low variance tradeoff okay so remember these two uh for stacking okay so here i am i am on my mls extend which is a library for implementing the sacking classifier okay so you can we will see the implementation of this uh stacking classifier but before that we will learn well how actually stacking works you can get to this page by just going to mlx 10 stacking classifier and click on the first link okay so let's start so here is our data set here is our data set so let me take out my favorite uh ink to go i hope that you remember my favorite ink to go sometimes i roast it also but here it is very good just for in annotating uh these these kind of things okay so here uh let let me take the pen that as of now let's take a red which i like a lot let's take a medium okay great so here is you in bagging what what we were doing we have a large training data we have a large training training data and then your multiplier or you are just taking out a subset of this data d and one d n2 the entry with the replacement are training the decision trees or maybe some same base learners okay so in the stacking we have different different base learners we take out the data okay and then we train our model different different model under the each data like a c1 uh is a model which is trained on different data then again means on the data d1 then c2 is trained on d2 all the way down to the m okay so here c1 c2 all the way down to the cm are a different are different models okay so what do i mean by our different models is quite simple is let's take an example let's just take an example that you have your favorite legitimate ration okay you have a logistic regression you have a logistic regression as a c1 okay as a c1 then you have your support vector machine as a c2 then you have your favorite naive bayes algorithm knife base algorithm with uh maybe with extensive fine tuning using grid search okay so here we have c3 here we have k nearest neighbors uh which is c4 okay with extensive with maybe k equals to four okay um with extensive fine tuning okay so we have four base learners and we have a different legitimate regression support vector machine nine base k nearest neighbors and there are four different models okay and a train or different different thing okay and the major difference between uh the bagging and boosting is in bagging that that i've told you to recall bagging bagging and stacking is in bagging we have high variance high variance and low bias low bias models which is a base learners which is the base learners and in and in bagging we used to be used bagging for reducing the high variance okay so base learners are usually high variance and low bias and tradeoff between them okay so what is the difference between stacking in a stacking in stacking our base base models or base learners are highly tuned are highly well tuned okay highly well parameter tuned okay highly well parameter tuned and they have a good bias and variance tradeoff okay so in boosting so in bagging we have high variance where our base space owners are not that much good and also when boosting our business are not that much good but in stacking our base learners are quite good are quite good are very good with extensive fine fine tuning so maybe you have changed the legislation fine tuning with the learning rate support vector machine like c your regularization parameter and your gamma and then maybe some of the other parameters okay a nine bayes algorithm we have also done it's not required but you have done some extensive fine tuning you have kink nearest neighbors we have chosen what is the number of k okay so you have done an extensive fine tuning of your model okay so that's what uh what i mean here i'm taking what a classification example okay so here um what what we are doing here what what we are doing is just we are the models are highly trained it's highly finetuned okay highly very very very much a train uh extensive fine tuning are very good models they do have a very good bias and variance tradeoff okay and here it gives prediction let's take an example that c1 gives you prediction as a yhat one then c2 gives you prediction as if i had to and all the brown to the y hat m okay so each model gives your output okay the prediction okay so what you are doing so what you are doing so let me do this so as an as a motivating example so can i delete this if i can yeah let me let me delete that so what you are doing so what you are actually doing is simply uh taking your training data which is straight taking your training data you you are dividing your training data you're dividing a training data into subsets of into subset of training data d1 d2 and d3 spotting for an example let's take 4d3 okay and you're training your base learners which has a good bias and variance tradeoff which has a good bias and variance tradeoff okay the base numbers are very good bias and very good model they are not either low bias or high bias because here in bagging again i'm saying in bagging you have high variance high variance and low bias model and what do i mean by high variance it means it performs very very well under training data but it fails to generalize well on a testing data okay so that's why and and that's why it's called high variance and in boosting it is under fitting it means that your model uh your model is either overfill means uh under fitting because it has a low high bias which is not performing well under training data and low variance like that okay so here we have a intuition about bagging and boosting okay so here we have a highly tuned model with extensive fine tuning and then what you do you take out the prediction why hat one why had to why hats we y hat3 okay after you take out this now what you do you train your model you train your model you train your model obtain your meta classifier you train your meta classifier which is just pretty which is just trained to on the on the predicted class labels from the base learners or their probabilities from their ensemble okay so they are usually trained on these things on these on the predicted class of our favorite classification or base learners either they will either take the class labels or the probability of being that class okay so maybe 0.65 or in particular class it may be zero or one or two okay so that's what the basic intuition behind the this uh stacking but again i'm i'm very uh just just i will recalculate you so that it works it makes sense again okay so what you do in stacking so uh let's uh just just for an example in the stacking we are just taking a trading data okay and then you're training and then you're dividing our data into substitute data and then you're training different different classifier onto that data okay here we have a c1 here we have a c2 all about cm which is new data okay new in new data we are training and uh and then what it happens in trains are c1 c2 all the parameters c3 uh scm under the that data and takes out predictions and the major difference is the first difference is that the bias and variance rate of bias and variance tradeoff tradeoff of of the base learners in the stacking learners in stacking is good and stacking is good okay it's good whereas in bagging we have high variance and low bias okay and in oops what happened and in boosting we have high bias and low variance high bias and low barrier oops what happened high bias and low variance low variance okay so that's the major difference next thing is that after you get the prediction from each of the model by because you have done a lot more fine tuning a third hyper parameter you'll get your p1 p2 all the way down to the pm now you train a big or a meta classifier which you usually call as s dash onto the prediction of h1 of x means the one classifier second s2 of vector second classifier all the way down to the edge m of x either you train onto the probabilities probabilities given by these models probabilities or the predicted class labels from these ensembles okay and in there is in bagging we are aggregating the majority of votes we are aggregating okay the majority of votes or from that models then you're taking that as a final prediction by hat but we have a different chance of here we have different approach okay so let's let's take a quick quick uh quick look at the at the second at the stacking algorithm but it's i have already explained you and just just above but as an uh just as a formal definition here you have your training data which is usually x i and y i which is which goes from x i equals to 1 all the way down to the m where x i is the member of r which has an n dimensional maybe it can have a multiple features and whereas the y i will be the member of the number of the classes of y okay so that's the thing and then what you do and it's output will be the in symbol classifier which is va edge dash or a big edge okay first what you do learn first level classifiers means you learn uh team t classifiers maybe it can be logistic regression knight bass knight base it can be k nearest neighbors and uh one one all the way down to the t and t here is the number of base models okay based on the distribution data d now you construct new data set now you construct new data set going from i equals to 1 all the way down to the m and then if that that constant contains x i hat prime by i where x i it's simply the prediction the prediction from the each model the from the each base learn learners model okay from the each models now what you do you train your second level classifier first to train the first level now you train your second level classifier and here it simply trains together make a hypothesis of training onto these models and these meta class this this meta classifier can be anything this meta classifier can be logistic reduction can be nine base can be uh carriers neighbors can be support with the machine and even model and we are not aggregating we are not taking mean we are not taking anything we are just trading a second level classifier that is just trained on our front base learners and base learners have a good bias and variance tradeoff okay so that's the stacking and i hope that you understood about the stacking now i will just uh take a look at the the the formal i would say the form without the i could say implementation of a stacking the implementation of the stacking okay so you can see over here you can see over here uh the paper which is in some of the research papers they usually call as a stacked generalization you can uh sound some some in some research paper we call that okay okay so let's make a simple stack classification first what you have done over here we have simply loaded the data set from the sql data set which is the iris data set and iris data set is not too much hard we have sepal oops we have a sepal length we have a sepal length petal length petal width and petal length okay so we have four features and bases on that we have to predict what is this species of that flower which is either can be satoshi verse cycler or virginica okay so that's the that's the that's our data set now you can see first we import the model selection which will see what it does then we put the logistic regression from linear model api and then cycle learn then we import caney knn which is a which is again from neighbor from neighbors api and cycle learn and then you employ import gaussian night bass from uh night bass either not gone into too much of algorithm because learning algorithm can just you can see the wikipedia you are now capable of learning any algorithm okay now uh you just import the random forest specifier from ensembl learning uh and symbol api of cycle learn now you import from mlx10 library is classifier import stacking classifier either you have been first you have to install this using pip install if you have a python mlx stand but then you can do this kind of thing okay where is my let me delete this okay after that after that what we have to do we have to simply import the numpy as np is allies and import warnings okay now you want to ignore the warnings given by the models now first your first model is clf one which is k neighbors which with the neighbors of one if it is bagging if it was bagging then we have to if it is run random for us we have taken one of the decision tree but we are taking different different models and that's what makes it perfect okay random classifier gaussian i base legislative regression okay now we to now what what we have done we instantiated our object everything now instantiate our stacking classifier which is the number of the classifier will be clf 1 which is cll k neighbors random forest which is the cl of two and these three which we are these three are zlf2 clf3 are the base learners it will give output it will give output like this okay now what what we what you will do you want a meta classifier which will be the logistic regression which with the logistic regression which is the which will the the distribution as i have told you can take legislation as a meta classifier okay now you perform a threefold clause cross validation right now you perform threefold crossvalidation and now you perform threefold crossvalidation now uh in three four cross validation you are just looping through clf as well as the label it seems uh zipping the clf one cl of two clf three and self okay now k n a random forest knight base and stacking classifier now you select the best model you now you select the base model by training each of the model whether you are taking a scoring equals to accuracy now you check the accuracy and you can see and you can see and you can see that this stacking classifier has around point point four percent of increase uh as is better i means is quite better than this a random word the stacking classifier works best in this case okay and now what what you can do you can oops what about what happened what you can do you can actually plot the k n and how it is plotting means the decision boundaries of the models how they are plotted that decision boundaries or hyperplanes okay during the math clock level so let me and annotate what is doing first you import the math plot lab then you have to import the plot decision regions from mlx 10 then employ the greatest pick then you include the iter tools then you set the set the area then you set the area again you loop through by dipping and then you take out the product and then you fit it and then you plot it and then you apply the decision boundary then you title the lab and lab here is just k n n a random forest night base and stacking classifier okay after you plot it now you are done with the second classifier okay now as i've already stated you either for training the mera classifier you can use either this uh that i could say i could say that uh maybe the uh the prediction from the base learners so you can either take prediction class or the probabilities as the meta features okay so you can say that use probe use probe equals to true use proba equals true and average probably equals to false okay and you can see uh here are a little bit of the documentation over there okay great now we have seen this and again the same thing is not too much harder we are using the thing and now we will see uh here is an example of a stacked classification using grid search it's your task is to do this but i'm just going to annotate what the this kind of thing will do great search so here you are just first of all you are just you now you will tune you will have a good bias and variance tradeoff so you are going to check between one to five you are going to check and then meta classifier and the feather grid search you find the grid best grid search then you plot the results means you take out the results what are the best parameters and the accuracy so after applying that you will get a set of values which are the best uh k nearest has these best features and like that okay now you can import the same thing for doing the k nearest neighbors and this and random forest classifier and then we have one which is the meta classifier okay now using the grid search stacking that operator on different subset of features you can also do that by selecting the column separator by calling the make pipeline that selects the two features okay so that's the that you can do and you can use prefitted uh classifiers which is already been fitted uh we previously filled out classifiers in your models okay fit base estimator equals to false means you don't want to fit your base esteem errors okay you can also plot roc curve using and you can see the roc curve like this and and this is first of all these four four examples are very very important we feel you can see the rvc curve uh in more detail on the internet okay great so now we have talked a lot about stacking classifier i showed you the implementation of stacking classifier here is it a very interesting and a brilliant diagram on a stacking or algorithm given a stacking this is a good example on stacking that i want to give it to you okay thanks to the author who has given to you full credit goes to them okay there's some addon just on man annotating okay so now we are done with uh these uh with uh ensembl learning so let's uh let's recapitulate what what we have seen so far we have seen we have seen we have completed we have completed let me write a good accomplishment completed and sample learning so what we have seen we have seen bagging so in bagging the basic intuition is we have a data we take out different different data we train a different different model and then we aggregate the majority of boards from each of the model then you have then in bagging we have learned about one of the algorithm which is a random forest that just uses the base learners with row sampler uh with feature sampling okay feature bagging and then we take out the boosting then we learned about the boosting we're in boosting we learned about the technique okay and then we're kind of converting the weak learners to the strong learners then then we talk about the g gradient boosting decision trees then we have talked about adaptive boosting which is ada boost which is just to the exponential it's a loss and then we talked about x hd boost okay now we are now we in this section in this sub section we have talked about its stacking we have talked about the stacking where we have seen a lot of examples a lot of examples using grid search and saturday using that that that okay so now i hope that you understood everything about machine learning sorry ensemble learning okay so if you're watching till now i am saying that you know that you do everything about supervised learning that you need to crack any kind of interview okay so just to pat your back and and be sure to subscribe my youtube channel it's it just gives you a great motivation as the new deep learning course will is coming soon so you can preregister there for free and you can reregister that or if you want or if you want you can go to amtran.com for detailed uh cso there is cso1 course which is uh which is on again machine learning but it's it's this it's not that different but it helps you to make a resume based projects it help you to make the uh everything means a lot paper in laricks you will get live down supports etc just as i step two so that uh just as you can go to cs01 see the benefits for the course details etc and the launch video which has already been launched okay so i think that it's you can also apply for a scholarship if you're a college student but it's totally fine forgive but the course price is like this okay but it's totally based upon you if you want you can definitely consider it just supports to make free content more okay so um that just just to me ask a question is is this course the same as cs01 yeah it's yeah but we in that we have talked about till about neural networks then we have talked about gans convolution neural networks you have you will get a onetoone session you will get jupiter notebooks which are amazing jupiter notebooks you will get early access to my books you will work with the team you will be getting an internship will work on a real world project in lantern etc okay so you can consider android.go for this okay if you want the lab but if you complete this this course you all be very very comfortable in machine learning okay so that's it for this uh section for this whole section on symbol learning from the next section you can consider subscribing obviously from the next section we'll be starting with and in between we can do some projects so from the next section we'll starting with unsupervised learning and i really hope that you will enjoy that series also okay so let's meet at the next section okay so now we have covered supervised learning and you're gonna now consider a comfort table and supervised learning yourself supervised learning is one of the very best was topic in machine learning that you have covered very smoothly and i hope that you understood every each and everything about supervised learning if you have any kind of doubt you can either ask a new or a discord community or you can ask over to the uh the you can find the discord community or you can come comment and then we can answer your questions okay so uh that so let's uh let's start with unsupervised learning so what actually in supervised learning we are doing we have our data set which is x i as well as y i and we have i equals to 1 all the way down to the n and actually we have one supervisor which is by i and we know what our output should look like means we know what our output should look like either be and continuous value which is a regression problem or a classification or a classification okay so that that we know that what our output should look like okay so here so we know what our output should look like so now in case of unsupervised learning there is no supervisor so in case of unsupervised learning we have only x i we have only x i okay x1 x2 x3 all the way down to the x i which covers i equals to 1 all the way down to the m okay so here in unsupervised learning we don't have any kind of supervisor that will that that will tell us what what will be the either output or will help us to train our model okay and we we we don't know what our aqua should look like either not in continuous and not in specification so you so you cannot you cannot frame your problem and you cannot even scream because if you if you don't have your labels then then you cannot frame it in a supervised learning problem so what i have to do what what we have to do so but i'm going to just want to do is just specify that the data we we have a structured data as well as on a structured data structure data as well as unstructured data and structured data is simply that which is in a table or format and unstructured data which is just images which cannot be fed on tables or csv files okay or in excel okay so here so uh this is our unsupervised learning because uh we don't have our output okay so what what we have to do this is the main question to ask what we have to do if you don't have the labels so let's consider let's consider you have this uh you have this x and y playing let me draw it very nicely so that in this section i'm just going to in this sub section i'm just going to give you an overview understanding and some of the applications of unsupervised learning okay so consider that you are working on uh just just you have your data points just you have your data points like this you have your data points like this into an x and y plane onto the coordinate planes and you have another data points which is like this okay which is like this and you may ask hey i use why can't we make a simple hyperplane but you don't know but you cannot frame it in classification problem just as a motivating example and i'm taking it as an example okay so here just assume that you have this type of data set okay which is true mentioned either you can make that threedimensional also you can make a threedimensional also just by converting this and now let's consider that you have a threedimensional feature so here you have this here you have another example okay so you have this so now you only have these types of data points which is this this one is x1 x2 x3 these types of okay so in unsupervised learning in unsupervised learning what you do you make cluster of your data which is closest to one point you make cluster of your data of your data make cluster of your data so as a motivating example let's take an example of uh let's take an example that you want to segment your customers okay uh let's say example your data scientist at amazon some some companies so you just wanted to segment your customers so how you will segment your customers uh so what do uh you you will just segment to customers we have this data but you don't have the y labels so what you will do you will make the similar person into the one group similar person into the other guru similar person let me do that my bad okay similar person and another group and similar person similar person similar person into the other book similar person on the other group so what you would have done you have divided your customers into segments now data scientists are business stakeholders what they can do they can decide that okay we can give these uh these customers our deal these customers a deal basis on their activity what they are doing or god we can make a sub on another machinery model that will detect what they are really what they want okay and and we can recommend the products we can recommend the products basically these these types of customers like milk or like watching the jewelry or on an on amazon so here uh also on here you it will show the products of books or maybe some jewelleries which are interested and here maybe they will show you some kitchen kitchen groceries maybe these customers are interested in these and then these customers can be toys maybe uh some tvs okay so they will be recommended some products and according to them they earn a huge amount of money from recommending ads etc okay so so that's why you can see that how we how we frame our problem and now you now it's quite clear to understand that as a motivating example of customer segmentation customer segmentation in amazon and and if you may think here you should you see that uh let me go to amazon.com you will see that i'm being i'm being recommending and they know what i recently viewed what i recently do and they are recommending the products they are recommending the products which you can see over here that they are recommending the products basis on my views okay so i'm in some segment i'm in some segment and they are simply uh recommending the basis products and i hope that you understood and and i hope that you are understanding what i'm saying as an unsuper training framing the problem as an unsupervised learning okay so that's what the first customers segmentation or and uh recommendation engine that is happening in amazon okay so just uh just see that just watch the too much talk videos on youtube now what youtube will do youtube will take yourself and add it in a segment of the one who watches stocks and now they will show you dog ads maybe pedigree or etc whatever the food of the dog is or that will recommend you the videos of dogs okay so that's why we have customer segmentation as a whatever example and a recommendation is a more motivating example so now i hope that is start making sense to you about why we call this as unsupervised learning okay now we so there's a this is a in supervised learning in supervised learning we have two two approaches we have two approaches which is the regression which is the regression and next one is specification but in unsupervised learning we have something called as clustering okay so we cluster our outputs we and if you plot in high dimensional space then you will imagine that the most similar items are close to each other and most decimal items are very much far away okay so you can understand like this okay so let's take a let's take a motivating example again so let's see some of the applications of unsupervised learning so i will spend a little bit amount of time telling you about the applications of uh unsupervised learning and in the in this next subject we'll start with the making clusters how what is intra what is enter how we do we make the cluster how do we evaluate our cluster etc okay so uh here i'm not talking about detail i mean clustering about clustering but i will definitely just told you that we divide our customer into segments okay so here here let's take an example we have now we are taking the now we are taking a look at the applications now we are taking a look at the applications of unsupervised learning so the first application of unsupervised learning is in biology which i have taken from wikipedia which is sequence analysis okay sequence analysis and it's simply it's just put your g on just genes into the particular segment and this will help you in a various cases for a biology student then you will understand then you will understand this concept of sequence and analysis because you don't have what you do you segment your genes in a particular set segments and you can diagnose if this person has it again any kind of okay problem the next application which is in business which is in business uh maybe a grouping of similar clusters for business and needs so let's take an example that some company takes your data and then then take your data and then simply group grouping the similar cluster grouping the similar similar clusters basis on the business data and they can see the clusters what they are what their activity is and they can provide deals offers according to activity okay another thing is we have a recommendation engine recommendation engine recommendation engine that recommends the products recommends the product that we have seen okay so in recommendation you have content filtering collaborative filtering content filtering quantum filtering collaborative filtering okay so which you can see uh which which have been which is village advanced but i'm not going to talk about recommendation engine but as a modding example that you whatever you see in amazon or google they just show you what you have seen so far because they have each and every because if you search anything you have the uh they have that data okay for making annual models next is that and the social network analysis facebook if you know about facebook uh they they told hey this this person has to uh just share the post means that we do the social network analysis social network the means these were they the group customers into the segments the group customers into the segments the group customers into the segments and the pro and they showed up accordingly uh profiles okay another is we have in computers uh computer systems is we have our favorite in computer science we have image segmentation so what do i mean by image segment segmentation so you have a mage you have an image and you segment your image you segment if you frame this problem as unsupervised learning so you have your image so you have your image like this and some someone is here someone is here someone is here so you segment these images segment these images okay uh second segment these images as a pixel device you see that they are they have similar pixels segmented uh so so that's what you're saying segmenting and then this can be used for classification or object detection object detection okay object detection like that okay so uh just grouping your images into segments by using maybe pixels etc okay because we don't have uh labels for body another motivating example in nash triangle processing and is sentiment analysis means uh just just seeing whether it be a negative or the positive okay so what uh let's take an example that you have this uh that that we have this sentence okay this sentence and another sentence okay so it will group the positive science sentence and the negative sentence okay so now you will see now now you will see now what what you will do you will go and see one of the sentence you will go and go and see one of the sentence go and see the one of the sentence and see okay if it is positive then you live a whole whole cluster which is maybe 10 000 10 000 um sentences as a positive and you date is a to hold then maybe whatever the number of as a negative so me let's just take a word let's let me elaborate this nlp task of segment analysis let's take an example sentiment analysis sentiment analysis so for an example assume that you have a one billion uh text data points in text which are text textual okay so converter is a word embeddings mean numbers now if it is very very hard to label it will compute if it will take time it will take cost it will take because if you hire some people you have to give them money okay so you have to label one billion so how you have to do so what you will do you convert them into a high dimensional space and you segment uh the closest text which is called the word embeddings closest word imbalance the quantum headings and sentences are here and then then you see one sentence is from this cluster one another sentence from this cluster now assume that this cluster is a positive sentence you label all let's say 50 million as a positive and hold 50 million as the negative okay so so you just require it to just you don't require a lot of times for working with nlp tasks okay so that's the uh that's that's for nlp tasks another is anomaly detection okay what is a normal dissection and and in a knowledge section an anomaly you have anomaly anomaly a detection anomaly detection where we determine outliers in your model so as an example that you have the exam age like this now assume that your data points is here so this is actually outlier this is actually outlier so if you cluster it if your cluster here then this will be ignored and this this this can help in in removing button but using maybe the db scan isolation forest they but most many of them may be some kmeans just take that outlier into this cluster okay so let's assume there is a then it is also closest to then they take that into that cluster okay so we have a db scan which helps us into a normal distraction which is again an unsupervised learning model okay in a dancebased reasons great so we have seen a lot of applications of unsupervised learning we have seen a lot and i hope that you understood really and in the in the next subsection we will start talking about clustering okay we will deep dive into the clustering to help you better understand the topic we'll talk about clustering we will talk about entering cluster interact and drop cluster how we evaluate our cluster okay how we if we evaluate our data that we have a good clustering what what are the some of the types of clustering like partial hierarchical okay then we talked about centerbased continuity based density based and then we will talk about one formal centerbased algorithm which is k means clustering algorithm okay and then we are done with supervised unsupervised learning okay and then i will give you a little bit overview of deep learning okay so that you could better understand your deep learning a journey uh just evaluation and then we will do some projects based on machine learning so that you could get more feel about machine learning and you are more comfortable and be sure to do the problem sets which are uploaded and github to help you understand the topic or master the topic okay so that's it for this section and i hope that you will that you have enjoyed this section okay so now we'll start talking about clustering we will get in the math and we will see some more algorithms like kmeans clustering then we will see hierarchical clustering algorithms which is agglomerative and divisive and then we are and with unsupervised learning so we are entering the last phases of this course and i really hope that you enjoyed this course a lot okay as i enjoyed making this course with very curiosity with very energetic moods so i think that you're also very energetic till now and like me and you may also thinking hey are you sure what about the projects and the projects are in the last section to help you to get feel of everything about machine learning means after you learn all of these things performance matrix algorithms now you will be able to build state of the art models okay so i'm very excited to see you all there and it means in this section last section we'll be building back to back project and the course website is also in the description box below you can see what what problem set is that and you can download and start working on that problem set okay so you i i hope that you're watching this video did totally worth it even i was making video was totally worth it okay so what we are going to start talking about we are going to start talking about we are going to start talking about uh clustering in the in our previous section sub section will be we have talked about some of the applications of clustering we have talked about let let me choose a pen a good pen we have talked about applications we have talked about applications of clustering we have seen what the unsupervised learning is what unsupervised learning is and we have seen the diagram digest some a lot of applications like biology and business and etc we have seen the applications of unsupervised learning and then i've showed you the data okay and then i've given you an overview what we do in clustering okay so let's start with uh clustering okay so how what what what with what the clustering is what the clustering is but don't just bear with me with my handwriting because i don't know what happened to my pen it's very working bad but no worries let's start so here uh let's assume that you have this you have this you have the great oops let me white is not being removed let's assume that you have a x and y plane where you have a two two features uh where you have two features like this if i draw a straight line if i draw a straight line okay so here so here you have this and let's assume that you have here is a point here okay you have this as a point and another point and another point is green once which is here okay so no no no in unsupervised learning in unsupervised learning all datas are saying bye i forgot no worries i usually forgot everything okay so what you have you have these features red features and you have this here so what you usually do in uh in in case of clustering you segment your clusters you segment your data into different different clusters oh my god why it is not happening is you segment your cluster so you have this data so you segment this cluster you segment this cluster to be going into this this and the second cluster we're going into this okay so this is the first cluster this is your second cluster okay so this is your basic inter basic uh thing about clustering that that we have talked okay so we'll see some of the terminology in this so let's draw a very good representation of this diagram so let me delete all these links and let me choose a black pen it's works best in the in case of white okay so you let me draw a straight line with x plane okay so you have x and y plane x and y plane and here you have the data point here you have the data point like this and here you have the data point like this okay so what do you do you segment your uh data points into clusters you cluster it out so some of the terminology is you cluster this you cluster this let me draw a good cluster you cluster this and then you cluster this okay so let's leave that i don't want to make it like that let's leave that for now okay so you cluster this out and then what happens so here is a terminology alert means the in terminology we have something called as intra cluster we have something called as intra cluster intra cluster and enter cluster just just listen what i'm saying interrupt cluster and enter into inter cluster so what do i mean with these intra and enter i mean with this intel intro and enter is enter cluster is the distance between the cluster okay between between the clusters across all the clusters so enter cluster is the difference is the distance between across the cluster so here we have one cluster here we have second cluster so intra inter cluster is the distance between this cluster and this cluster it's the distance between this cluster and this cluster so that's why it's known as enter cluster okay the second type of his intra cluster which is the distance between within the cluster that points within the cluster within the cluster so it may be like this this is called the this is called the intracluster this is called the intra cluster i hope that you are uh that is making sense you have this x and y plane and you have this this kind of thing and what to what we have to do this is this is called the intra cluster where we have the distance between two clusters or maybe two or more than clusters across all the clusters and intra cluster is the distance between the data points inside that cluster okay great so we can think think something like that is we want what we want in this case if we are taking as a terminology that so we want our interact cluster to be small interact cluster interact cluster to be small to be small and inter cluster inter cluster to be large what do i mean with this small and large i mean with this small and large is you have this intra cluster the internet cluster is the distance between this and this and the clusters takes whoever is similar or group is a cluster is just as in is a grouping of the similar objects that they are similar to one another so they should be closest the data point should be closest and the intra cluster of these should be closest okay and the inter cluster inter cluster means the similarity dissimilarity between two clusters should be maximum okay so here we have written our optimum optimization objective uh we have we we want uh our enter cluster our inter cluster which i did with i n should be large and i and a should be intracluster should be small okay so that's the that's the basic definition of that's the basic uh basic terminology that we have seen and i hope that is making sense okay so we can frame some problem we can frame something over here what we can frame is we can frame an optimization objective we can frame a evaluation technique but before that why do we even need so let's assume let's assume that you have this you have this cluster you have this cluster you have this cluster like this you have this cluster one two three four five six seven one two three four five six seven okay so here we have this and who can tell you who can tell you that these are the perfect clusters these are the perfect clusters uh either you will tell hey you should i'm able to see i can tell that these are the perfect clusters but assume that we have uh three dimensional we have four dimensional we have fifty dimensional we have eighty dimensional we have hundred dimensional we have lack dimensional so what you will do in that case so we have evaluation techniques okay we have optimum optim evaluation technique that will help us to identify evaluate our clustering or unsupervised learning a clustering model okay clustering model that will help us uh ideally to understand to to if evaluate how good our clustering is okay so let's see how uh some of some of the evaluation uh techniques okay so the first one we have which is called done index okay so the first one we have is called d u n n index so this is this is a very funny name but it's disappearing uh you can still read about in wikipedia page so it's so let me first write the equation so d equals which is a done index equals to the maximum maximum of i and j means the maximum should maximum distance between i and j divided by or by maximum k a maximum distance d dash between k okay so here what i'm telling here we have this we have this intra cluster we have this intra cluster here we have maximum inter cluster distance maximum intercluster distance enter clustered distance okay so ideally it is framing our problem of intra and enter that our inter should be small and our interest should be large okay so here we are not assuming should be small we are assuming what is the largest maximum distance okay so if every everyone is small then the largest maybe 0.00 like that okay so maybe something like that will be there so we are just changing this maximum okay we have maximum over here just don't be confused we are telling minim minimum intra that just ideally means that you want the distance between inter cluster to be small so that's why you are taking the largest whoever the largest however the have a largest distance okay so that's why uh so so you so you can evaluate your model and it's this this sim this the denominator simply means that the the distance between your intra cluster okay the distance between your clusters the distance between it should be ideally large not too much small okay so that's the that's the end if you if you've seen if you see if you sense it's math mathematically you can see that d should be high d should be high to be a good good cluster these should be high okay so this is the evaluation technique for clustering your model and i think that you understood done index so let's recapitulate what we have seen so far is we have let me remove this uh let me let me remove this so we have seen that we have some of some of the terminology so we have this small x and y plane where we have this one two three four five six one two three four five six uh again one more okay so here we have this the diff the distance between the the distance between the the distance between two clusters the distance between two clusters is called as intracluster means across all the clusters maybe some cluster will be here another cluster will be here it's across all the clusters this is called the intra cluster and the distance between within the cluster within the data points is known as the inter cluster is known as the inter cluster and core idea is for any evaluation matrix of your clustering model is your intra cluster should be large intra cluster should be large large and enter clusters should be small okay so we have that we have talked about about a done index we have talked about done index we have talked about done index and done index is simply uh evaluation matrix so the done index is written as d equals to the max of the distance between i and j which are two data points which is obviously inter cluster which is obviously the first enumerator is inter cluster okay and the denominator is simply the intra cluster where you want the maximum distance maximum distance between the values okay so this this is the basic definition and you may think here you should have told about entry inter cluster should be small but we are checking the maximum so that we can evaluate we are checking the what is the maximum in that cluster that has the distance so we can evaluate so everyone should minimum so our d should be high in that case okay so i think that you understood done index also so let's see one more uh one more evaluation technique which is for uh clustering which is uh just just i'm telling you just some some constraints to be added i i just have seen the equations just some conditions to be added in ing where here in i here in i i should be i should be is greater than i should be greater than or equals to 1 or it should be and it should be smaller than or equals to j and j should be smaller than or equals to n and n here is the number of training examples and for k constraints of k is your k should be smaller than or equals to um it's sure it should be at least a smaller should be uh smaller than or equals to n okay so that's the that's the basic definition of uh that's that's the basic clock const constraints but i don't find it's very uh kind of thing but here just to understand this the numerator the numerator is just a maximum interrupt in inter cluster and here maximum intra cluster okay and the reason why we we want to evaluate so that's why we are taking the maximum so if it is maximum then it is bad okay so our d index should be high if you sense it mathematically okay so another evaluation technique that that i have seen so far let me let me go back actually okay so here i am on my another thing and let me remove this okay so another tech technique another technique is here in front of you which is the davis baldin index davis davis baldin baldin index this is also like a done index what you want here we denote is that db equals 2 we we take it as a db equals 2 1 over and i equals to 1 all the way down to the n and then you take out the maximum they go to maximum where j is not equals to i sigma i plus sigma j divided by the distance between c i and c g okay and this is just like the clusters and for more information about what is this you can refer to an uh do a wikipedia page okay there is the more deviation etc has been already done over there okay so that's the devious balding index but most of most probably this this this the dawn index used properly in the country in the whole except for evaluation of you of your model so let me highlight it this one okay so we have seen the davis board in index now it's time for uh learning a little bit more in that about what the what the approval means what actually the definitions of what was the definition of your favorite clustering okay so one line definition i could tell about clustering is in clustering you have and it's a it's a grouping uh can i write it yeah it's it's better to write it okay this bad or better with me or you can write with me also so a clustering is simply grouping grouping of objects grouping of objects or elements objects such that in such a way i could say in such a way such a way such such a way our our our object our object in a should be should be similar similar to each to the to each group where it is in each group and differ from another cluster cluster differ from another cluster okay so that's the basic definition basic definition of clustering and a very good definition and from clustering in clustering we have two cases intra cluster in inter cluster where we want our intra cluster is the measure of distance between um just a distance within the cluster and inter cluster is difference between across all the clusters okay so this is the basic definition of a clustering and i hope that you understood everything okay so now we have seen done index we have seen clustering now it's time for learning about getting into depth of clustering about types of clustering how many types of clustering we get in our life and then we will just after talking about types of clustering we will end this uh subsection and in the next section we will be talking about uh do one algorithm which is kmeans and the next subsection we're talking about a hierarchical clustering which is agglomerative and diversive clustering okay so but before that let's uh let's see some of the types of clustering okay so the types of clustering which includes the types the types of clustering let me choose it the color so some some of the types of clustering are first one is partitional based clustering partitional i'm just writing in short partitional partitional based approach or clustering okay so what is partitional based clustering so assume assume that you have this uh that you have this x and y plane and you have this data point like this and you have this data point like this okay so what you will do you will partition it you will partition it into two clusters and you are done okay so here we have one algorithm which is called km means algorithm that we'll study in our next subsection okay for in a partitional base approach then we have hierarchical clustering high ra recall hierarchical clustering clustering okay so in these types of hierarchical clustering we have like a dendogram if you have seen a dendogram then you know about a hierarchical cross string just just just as a just if you know so let's assume that you have this data point like this you have this data point uh let me do it here that we have this here like this okay so you have this four points we have this four points and again you have p1 p2 p3 p4 and if you're plotted the points looks like this so these two this p1 and p2 looks close this p1 and p2 appears this uh p2 and p3 just just assume that this is a p2 and p3 this this this looks close so you just cluster it out okay so the p2 so what you do you just make an endogram just like this uh that p2 and p3 are now a cluster which is the same though which which we can consider p2 union p3 okay now these are the two clusters now if you see the closest structure is this a p4 so what you will do you will again make a nested cluster now i would now this this will look like this and now what you will do you will attach p4 over your pp4 as a dendrogram okay and then what you do then here is this this is the p1 is the closest then you cover it and then this whole and this whole now after that you will be end data being a dendogram you will be able to see a dendrogram which you can see over here so here after which is p1 like this okay now you can see now we cannot burn we have a large cluster which we have a large uh cluster now we are done this this is called the traditional van der graan because you can see on internet about this so what we have seen so far we have we have augmentative structure we are going up means we are uh just we are going up like this means we have this p1 p2 p3 p4 we are we these are own clusters by themselves and first these are their own clusters we have four clusters over here we have four clusters now we cluster this p2 and p3 then we close cluster p3 and p4 because they are close to each other then we construct p1 to p4 okay so now we got our full dendrogram okay so that's that is usually a agglomerative agglomerative cluster we have something called as diversif we are in diversif and i'm talking about in hierarchical clustering application which is agglomerative and divisive and divisive we have given p1 uh p2 p2 we have something called as p3 let's let's assume that that that we have abcd okay so a it's just it will match if i do that abcd okay so e let's assume e also so you divide this okay so what what what you do you simply you diverge visit okay like this uh first you divide a and b a b as one cluster then you divide c d e then you have c d e okay then you divide a and b into different different clusters so you have this whole dendrogram like structure like this now you are uh now you are this is just opposite of fog glimmer right here we are just here we are making up here we are making up here we are making uh a different different cluster okay now we do divide our c then we have a d e now we divide our d and e now this is our divisive okay so we divide our whole cluster into different different groups which are most closest to each other okay we will study in detail about this uh in in our uh next subsection where we will talking about hierarchical clustering okay after that we have something known as after that we have something known as well separated clusters where it is well separated clusters okay just just i'm writing it's well separated means we you can easily your model can easily uh separate well separated well separated then you have the fourth one which is centerbased which is also kmeans clustering is this centerbased algorithm okay continuitybased we have something called as nearest neighbors k nearest neighbors okay and then we have density based which is often known as db scan db scan okay which which you have you will get in problem set to learn about this uh db scan okay great so we have seen a lot about clustering and i hope that you really enjoyed this session there's some sub section of clustering and from the next section we'll be talking about lots algorithm or kmeans clustering but i will definitely try to complete in no time so that you can you could get a more more a prone uh knowledge of clustering and uh able to make uh unsupervised learning models okay so let's see so let's see as just recapitulate what you have seen so far we have seen what is clustering clustering is just a grouping of similar objects in such a way that these objects are similar to each other within the cluster or our inter cluster our end to enter clusters should be different should be maximum and our intra cluster should be small and what is the difference between enter inter and intra in enter we have the distance between uh across all the clusters and that's why we need a maximum and we have intra in which our points our points within the cluster should be minimum okay means more similar okay other than the other clusters okay so that's that's the that's the basic intuition about this and uh the clustering then we have seen how we can evaluate so i have talked about one index which one evaluation index which is done index okay and on index it is used to uh take out the evaluation is used to evaluate your clustering model and what is what what is what it does he it takes out the maximum what is the maximum in inter cluster what is the maximum to evaluate the performance between between two points and it takes out the maximum of the uh this the the the denominator is an intra cluster and a numerator sorry yeah the denominator is intra clusters is the numerator is intra cluster and the denominator is inter cluster okay and then we have something called as davis bounding by bolding block and index this is just it it will take a lot of time to teach this but it's out of the boundary course but it's just here and is the number of clusters where we have a sigma i plus 6 sigma g and where i is not equal to j we want the maximum and then we are taking out the distance between two clusters and then we are dividing it up okay so that's why that's what the full uh clustering base models is and now i hope that you understood about clustering uh now it's time now now it's time for learning about now now now it's time to learn about something new which is in subsection where we will talk about uh where we have talked about four five types of clustering which is partitional based hierarchical clustering and well separated and center based and db scan okay so we will talk about partitional hierarchical and well separated is also in center based where you your prop problem set will be on db scan okay so here we are done with this subsection now in the next section we'll start talking about kmeans till then have a good day okay so now we have talked about various things like clustering we have given a part one in subsection i've given you unsupervised learning applications and then we have talked about various applications of unsupervised learning and then i've just given you an overview of clustering in this first subsection and the next subsection i've given you the intuition behind clustering i've given a formal definition of a clustering we have talked about inter cluster intra cluster we had talked about the evaluation matrix like done index devious balding in index and i've made you understand each and every equations and i've already also helped you to understand that what are the types of clustering which are available like partitional based hierarchical clustering then you have a center based well separated density based continuity based okay so we have this kind of clustering which are already available now we will talk about a partitional and center center based clustering which is k means algorithm as this example was taken from andrew non course of machine learning but he has uh but it's too much uh 37 years old but i have i have made it very very updated for 2020 just that this this example is from andrew nong okay so i've also included k means plus plus algorithm what the k means plus plus algorithm does and some of the variations of k means and then also i have talked about in detail what are the what are the limitations of kmeans clustering what how we initialize the centroids what are the time complexity of kmeans clustering okay so then we have talked about the full machia full kmeans clustering algorithm how we evaluate our kmeans clustering algorithm okay with the euclidean distance so that's what we are going to start talk about just be sure to just sit sit somewhere and see and take copy and pen to understand okay but before that what we are going to study is kmeans clustering algorithm sometimes so the synonym of came cayman's clustering is lloyd's algorithm it's something sometimes called lloyd's it's sometimes called lawyers algorithm lots algorithm okay so it may be some people pronounce it as a lots algorithm or a k means clustering algorithm okay but i'd like to pronounce what k means okay so uh just to just as as an example we have this uh data set we have this data set over here now what what we do in clustering what we do in clustering we initialize centroid which is k okay we initialize centroid which is denoted by k so here what it is a hyperparameter so what we are going to do we are going to initialize k we are going to initialize k as uh we are going to initialize k which is two uh two centroids and centroids is just uh the the initial you will get to know up with the visualization so what you do you initialize with two points onto this so here you initialize two points like this the the first point is over here the first point is over here and the second point is over here and these are called the centroids you will get to know why we call it as a centroids but these are called the centroids okay these are called the centroids and here in this example k is equals to two because we have taken k equals to two because uh as we have a two centroids and and we randomly initialize these centroids okay so we'll see the initialization uh just after some ppts this has some slides okay so you initialize your model now and now this is the first iteration now in the first and first you initialize then what you do you do the assignment step what do i mean by assignment step first you initialize then what you do you do assignment step like this you assign all the all the particular values red to red color and blue to blue color you can see over here that we have that we have done red to all the red color which are closest to this and centroid and this uh blue we have covered that is all the centers which are closest to that blue okay now what what we will do we will take out the average of these points we will take out the average of these whole blue points and then we will take out the average of this red points and then what and then what we will do we will average it we will average it like this we will average it now after averaging we will make that percent right to at average and then what we will do again we take out the again we do the assignment step like this we just assign we we just update our values which are so closest to this and centroid now you can see that the blue becomes like this now then what and then what we will do we will again move the centroid again we will take take out the average and move the centroid like this we will move the sand centroid and then we will make this uh red red means so those those are closest to blue blue and these are two red okay then again you do then again you do like this as a taking of the average and making the color as blue and red okay now you can see that you were that what you have done you have a very good cluster means you have initialized here and then you taken out the average then you move to that centroid and again you update the updated cluster then again you move that like that okay so we have done like that and i i have just shown you a very good visualizations of this k main so let's see again in a little bit more fundamental way okay so here is our data and then you can see the data is looks like this so here what we had done we had in we had simply initialized two centroids like this and then what we have done we had we had just uh make the make the points which are closer to that blue to blue and red to that red okay now you can see over here then what what we have done we had taken out the average and then we moved our centroid to that average okay and how we take out you do you all know how do we take out the average you you just take out the number of observations and then divide uh or some the num the sum over the observation divided by the frequency over the observation you just do that and then you update and then you again make the whole uh assignment step and then what you do then you again up make take out the average now you again update the points you can see like this and then you again take the average you again make the point says like this okay and after until and unless your centroids are not changing you keep doing this okay so here is informal algorithm here is informal algorithm and you can see over here after seventh iteration it is not changing so we converged we our algorithm is converged okay so this is how whole kmeans clustering algorithm works in visualization so let's see uh the algorithm in detail okay so what you do uh first of all here's an algorithm i'm writing just bear with me but just bear with my handwriting so i'm just writing an algorithm so here is my algorithm with the let's write it with a red color so uh let me write here is your algo a rhythm algorithm okay so you do for k centroids k for centroids okay so you you have to choose k okay you have to choose k which is k where is a hyper parameter okay then you repeat this two process then you repeat this two process the first process is cluster assignment cluster assignment you assign all the clusters you assign all the cluster you assign all the cluster and then update take take out the average and then uh take out the clusters time you assign the clusters and then you take out the average and then you make that point so you when then you do the updation of a cluster okay then you up recompute the centroid okay then you recompute the centroid okay then you how you how you recompute the centroid the centroid it simply means you make the and you take out the average and then you assign that cluster okay that cluster to to to the nearest data point okay again you have takeout average until and unless until you do until you do until uh your uh your centroid are not changing your centroid your centroids your centroids are not changing are not changing okay where it's it means that your algorithm is converged now you don't need okay so you repeat these two process like clusters cluster assignment means assign the cluster with blue or red and then you update your centroid and take up by taking out the average and then again doing doing this taking on the average again doing this like that okay so this is the basic algorithm of kmeans clustering algorithm and i hope that you understood about kmeans so let's under and let's understand a little bit more we is a little bit more further into just a recalculation of kmeans kmeans clustering is an algorithm also called the lloyd's algorithm then we what what we do so let's go back to our visualizations okay so here is our data and what what we do with into ub randomly we randomly initialize two centroids okay not every case just have taken it is a hyper parameter we have just taken two for this case okay then what you do then you do the second step which is uh which first you do the cluster assignment you do assign all the cluster with the closest with the same points in the end of the cluster then what you do then you just recompute the centroid by taking out the average and moving the centroid okay then you do the cluster assignment then you assign the cluster like this then you again move the centroid okay recompute the centroid then you assign the like like that and then you take out the average and again you uh again you do the same you take out the average and then move your centroid okay now now in the next iterations is not changing now your kmeans flush string is converged now you are done okay so here's a good algorithm you will be able to see on the internet the same thing like first you do you choose key how many number of key clusters then you assign the clusters recompute and then until and unless your centroids are not are are are not changing okay so this is whole about kmeans clustering algorithm and i really really hope that you understood cayman's clustering algorithm so now let's see some of the evaluation techniques of k means clustering algorithm okay evaluation technique how do we evaluate our kmeans clustering algorithm so for an example so for an example here is my example so for a for an example we are given we are given uh no not in foreign example is just a justice time giving you the optimization objective so you are given so you are given x d dimensional space dear dimensional space as well as k and the clusters which are this uh and set i think the dictionary which is not which is in this c1 c2 all the way down to the ck okay we have k clusters okay then what you do you want your uh to optimize c you want to minimize this cost function you want to minimize this cost func function now what you do you take out i equals to 1 all the way around to the k we are k where x be the member of c i mean the cluster now you take out the distance of x and c okay you want to minimize this cluster okay so uh just it it will make sense don't worry here we have ci which is equals to the centroid so let's see let's see what do what do i mean with this uh distance between x and c so what we are told that what what we are told like uh we are we are told that we have that that we are given x they dimensional space and we have clusters which is c1 c2 all the way down to the ck where we have k clusters now what we have then we have this equation i equals to 1 all the way down to the k we are going to until every clusters where each we are each x where each x is the member of cluster means we are this data point is the member of this cluster okay now you take out the distance between you take out the distance between this data point and this cluster this this cluster okay and this should be this should be minimized your distance should be minimal your distance should be minimal as compared to this your distance should be minimal so that's what it is telling over here okay so i hope that you understood with the help of a visualization okay so ci is the centroid okay cluster centroid okay so how do we take out the distance for taking out the distance we have something called as a euclidean distance euclidean euclidean for taking out the distance we have something called you there are a lot more distances which are already available you can take a look at it in online but it's a very used eupledean distance so what is euclidean distance in euclidean distance we have d uh we have two points p and q okay since we are doing for each and every point i equals to 1 all the way down to the n means number of training training example qi minus pr squared okay and it's taking out the square root of the square root of that okay so this is the this is the euclidean distance that just measures the distance between two points like this and you can see some more about this onto the internet how we derive this equation what is this well who have found it etcetera etcetera etcetera okay and sometimes and this this cost function of kmeans clustering is called is called s s e means sum squared error sum squared error and you can also see it is just like the dawn index following the inter and intra cluster here we want to minimize our in our intra cluster over here we want to minimize our intra cluster we want to minimize our intra cluster okay so that's the basic definition that's the whole thing about whole story about a kmeans clustering algorithm and i really hope that you understood kmeans and then we have talked about evaluation techniques for kmeans and that's it for uh kmeans and now we will talk about why it matters it's the basic definition of why it matters which the random initialization as we have seen that we initialize our centroids these centroids randomly you can see that we have initialized randomly so why it matters how it can cause the problem it can cause the problem so here we had just we are just choosing you can see over here here here over here here that we have in iteration number one we have three centroids iteration number two we take another average compute then we do the we come we we simply what you're doing we cluster we assign the cluster with the same centroid and then we recompute by taking out the average in the second iteration then in the third iteration then the fourth iteration in the fifth iteration and the sixth situation you can see over here that uh we you can easily see that we have a good cluster over here but you can see in here that you have adjusted it can cause how it can cause problem is iteration number you want you have just randomly initialized now you can see whole story changed whole story changed you can see over here okay so that's the big problem so that's why we do which is very not recommended to to choose it randomly so researchers discussed about it these researchers had talked about it how we can use it how we can make something good so we researchers found that uh k means plus plus something well as k means plus plus algorithm works best works best which is very time which i'm going to tell you okay so kms plus plus algorithm what it does it simply select multiple numbers it simply select multiple numbers as in random we are we are just taking any random but we select multiple numbers and select the smallest error okay so that's that's what the k means plus plus does it selects selects multiple multiple means is just a it's just a multiple a sample from the numbers multiple numbers and checks and checks which number which number minimizes which number minimizes minimizes the sse the sse which is the which minimizes the into intra cluster distance okay so that's the k means plus plus and it is usually used in everywhere okay rather rather than randomly okay so we have talked about uh why why we choose importance why we choose um over uh run why why we choose k means plus plus over i ran randomly because maybe it can happen sometimes okay a very good a very cool god pro if the luck is not with us it can cause a big problem and further okay so how we have to deal with this kind of situations for dealing with these kind of situations we have something called as uh kmeans plus plus which will help us today which we just selects the multiple multipliers and selects select the one select the numbers which has a smallest error okay okay so uh let's see uh you may you may think you may think hey ayush hey ayush how do we select how many number of a centroid that we need okay so that's the that's that's that's also the best uh that's that's also the big problem so we have something called as elbow method we have something called as elbow method and what it does we have elbow method like this we have written the k clusters one two three four five six okay now in if you if you have taken k equals to one your error is high to uh if you've taken k equals to two your error is going down like this like an elbow like an elbow okay so here you can see the elbow turns around at three so you select this elbow to select k equals to three okay so this is your loss this is the number of okay and this is your loss which is decreasing sse sse okay so that's why how we use elbow method either you can use grits or cv or random randomized research to student this parameter i think that will not work because we don't have labels but album method works best when you plot it you know when you plot and then see what number of k you need okay so that's it that's that's the following and let's revise so that we are on the same base so what what we do in kmeans clustering algorithm we choose number of okay using the elbow method not now just uh just i choose the randomly and then we plot it and then then we choose the k and then what i've done then we repeat a cluster assignment like we assign all the clusters with the same clusters then then we compute the centroid by taking out the average okay then you uh then you keep repeating this antenna and unless your centroids are not changing and then uh the evaluation technique for your kmeans or loss function for your kmeans is the you want to minimize your intracluster by just taking out the distance between two this distance between the the points between points inside the cluster okay and then that's called sum square error and here and you take out the distance using the equilibrium distance that just that just take out the difference between two points by doing the summation over there okay great so uh why how how how we choose the in in how how we choose this cent centroids okay the initializing of the centroids for initializing we have seen seen over here that randomly initialize can cause a very big problem so that's why we have something called as k means plus plus which will help us to select centroids using what it does it select it does for multiple runs and checks where uh and checks the numbers who where uh the sse is a low okay and how we select the number of a key we select the number of okay by using elbow method where it the elbow is where elbow is turning around like in as a hand as a hand if you draw it like this if you draw it like this if i draw a hand over here if you draw it like this okay so your elbow is there so your loss is decreasing with k equals to one is your losses that this this this okay so you choose the elbow k equals to three and it works best okay so we had talked about these things and now it's time for ending up kmeans clustering the chapter of kmeans clustering which is uh just uh just ending the topic with our favorite what are the some of the limitations of kmeans clustering algorithm and what is the first time complexity so the time complexity of kmeans clustering algorithm the time complexity the time complexity of kmeans clustering algorithm if you don't know about from the if you don't know dsa leave it okay ignore this at the time complexity is order is time complexity the order of n times k and n is the input size k k is the number of clusters i number of iterations d the dimensions okay uh this this is our and this is this this is what the time complexity of that okay so it's depend because the time complexity depends upon your size if you don't know about time complexity i have one something called as dsa mastery course uh soon we're putting putting videos on to that so um first four lectures are based on time complexity you can watch that just go one new where i will just show you where you can go okay uh some some of some of the limitations of kmeans clustering algorithm some of the limitations of kmeans clustering algorithm is it's it's it's very sensitive to outliers okay so let's assume that you have this that that you have this oops like why uh powerpoint control z does not work i don't know why so uh here we draw an x and y plane and here we have x here we have y and let's assume that we have made it and here we have the outlier here we have it is closest so it will take that outlier in that cluster so we don't want that so it is very prone to outlier means we have we have to detect the outlier and it can be solved using density based uh even i just don't know what is with what what's there so it can be solved outliers problems can be solved using a db scan which you will have a pro problem set to solve okay means you you have to read the wikipedia page uh and write uh go google docs onto the ddb scan what you understood okay and then it's it's it's like different sizes different distances maybe they're causing the problem okay but the main main problem is outlier okay okay says so we have i have given you the thing that db scan hierarchical clustering works on these types of issues okay so that's it for this kmeans clustering algorithm and where you can uh record where you can uh find the time complexity videos and it's very very recommend uh just it's a very very very helpful if you subscribe this youtube channel the newer youtube channel which you can find um which way which you can easily is easily find onto the uh youtube just by writing new era where i have 500 true subscribers as of now okay so you can subscribe that and see the dsm mastery course where we have more than 23 videos already uploaded a long lecture so you can learn about time complexity from that also okay so that's it for this sub section you will now have a toolkit of various algorithms various techniques various things okay so now let's meet at the next section where we'll be talking about hierarchical hybridical clustering i will give it a sort so that it should make sense okay so let's meet at the next sub section okay so now we have talked about clustering we have talked about unsupervised learning we have talked about one of the partitional based or centerbased approach which is kmeans clustering with k means plus plus algorithm for a random initialization okay so i hope that you understood everything in unsupervised learning and if you have gone so much further into untube voice learning now we are capable of learning hierarchical clustering which is one of the most favorite uh means one of the most favorite uh and the best clustering techniques that include including partitional based and then we have a hierarchical clustering okay so this is the this is this this is what we are going to do we are going to start with an introduction to a hierarchical clustering to help you better understand what a hierarchical clustering is then i will go further into different um just just a quick recap onto partitional based okay then i will show you the visual representation of hierarchical clustering and what's the dendogram okay and then we will move further into understanding the two two types of hierarchical clustering which is called agglomerative and divisive okay so agglomerative clustering and diversive clustering we will dig dive into augmentative clustering and we will just to take a look at the diversif okay and then we will go further into understanding the augmentative clustering algorithm and then we will see uh then we'll compute that algorithm manually and then we will see the inter cluster similarity between our two points okay but if if if all the words or technical terms are going above your mind leave it means uh just ignore it the words as of now let's start with hierarchical clustering just introduction to hierarchical clustering okay so what is hierarchical clustering hierarchical clustering is that you have a hierarchy of clusters okay so for an example what i'm going to do what i'm going to do is i'm going to take four points i'm going to take four points p1 uh let's let's not take it here let's take p1 here p1 then i'm going to take p2 then i'm going to take p3 then i'm going to take p4 okay for an example i've taken these four points and now we want to cluster it out okay now we want to cluster it out so how do we cluster it so for clustering so for clustering we have our favorite means we can simply see okay this distance is small these are more similar we are going to do this we are going to cluster it out like this and we have this uh p3 and p4 how do we cluster we cluster this p p one and p two as real so we cluster we we put another cluster okay because this this cluster p1 and p2 is p1 union p2 it is now a one cluster now in nearest the data point nearest point between or the nearest these these are their own clusters initially these are their own clusters so we are going to merge it okay so here we have a p1 and p2 now the now that this is smallest distance is p4 now we attach means now we make one more cluster okay now in this big cluster in this cluster where we have three points what is the nearest data point now the nearest state data point is p3 okay so we'll make again one cluster again one big cluster like this until and unless we have one cluster at uh one one one cluster uh at a point okay so here we we are ended up with one cluster okay so it is not making sense i know but we can um just just as a diagram i have made this so let's see how how we do it using a dendogram that that will make more sense okay so here we have a p1 here we have a p2 oh oops let me make a little bit more in good oops what happens okay so here we have a p1 let's assume that we have this is the point p1 this is a point p2 this is the point p2 and this is the point p3 and this is the point p4 okay now these are the points now what we will do with here you can see we just assume that just assume that this is p1 p2 p3 and p4 and you can see this p p1 and p2 are smallest so we can make uh we can attach this we can make a we can make like this you can attach this p2 and p3 okay now these are one plus or p2 and p3 are one cluster which usually cause p2 union p3 okay now initially p1 is one cluster c1 p2 is one cluster c2 p3 c3 and p4 c4 okay so these are initial clusters now what now what we'll do now this is the one cluster which is c2 okay so we've we we found and attached it okay now what now what we will do now the nearest state data point is p4 over here okay so what what we will do we'll again attach p4 into this we'll again attach p4 now we have now we have p3 and p4 as one cluster over here okay now we are now we can attach p1 now we can attach p1 now now we can attach p1 like this now we can attach p1 and now we have our dendrogram which is actually a hierarchy of clusters okay so here we have a traditional dendrogram which uh which which i think that you have all i've seen in your journey so this is your hub this is your dendrogram what you have done you have just who are most similar you are attached to it okay who are more similar you attached it for an example these are two similar you attached it and then these this is now what you attach it like this okay do not merge it do not merge it okay so you have to do like this now here we have until unless we have left with one cluster okay so that's the basic uh hierarchical clustering and i hope that you understood hierarchical clustering the basic intuition but if not let's let's try to again understand a little bit more further into a more sophisticated way okay not supposed to just just uh easy way okay so for the example i'm gonna take a yellow color so here you have a c1 here you have a c2 here you have a c3 here you have a c4 okay so this uh this is your c4 now you can this c2 and c3 are your points c2 and c3 are your points okay so these are two more similar so you will attach this like this now c4 here he is here so will you make you so you will make one one more now pc3 and c4 will be attached like this and c1 will be attached onto the up of c4 now this is a traditional dendrogram this is transferred traditional then dendrogram where you convert this cluster of numbers where you convert cluster of numbers c1 these the clusters clusters to a hierarchy of clusters okay so for an intuition what what what i'm trying to see you here so i have one example so for intuition what i'm trying to say you hear that we have a c1 c2 c3 c4 now we're just uh making a attaching as a cluster so c2 union c3 etc okay so this is the basic intuition behind hierarchical clustering so there are two types of hierarchical clustering uh some of the types are we have some something called as agglomerative agglomerative clustering and then we have and then we have divisive clustering and then we have diversif clustering okay so we will deep to have an agglomerative clustering i'll just give you an intuition behind diversif clustering okay so what is agglomerative clustering so the agglomerative clustering aglo agglomerative clustering okay so before that let's understand let's uh let's see let's uh let's let's unders understand the divisive clustering to help you better understand that so it is down to it is up to down approach sorry it's a down to up approach it's an agglomerative is a down to up approach and diversif is just opposite it's just a positive diversif diversif is just up to down approach up to down approach so what do i mean by this so for an example for an example let's assume that we have a four points we have a five points in the form of data a b c d and e okay so here what to what you are going to do we are going to divide this cluster of numbers the cluster of numbers into a different different uh a b let's assume that you are divided with a b now this is your c d e c d e c d e as a more similar okay you divided this now what you will do you will devise this a and b a and b now you will divide this c c and d d e okay now you will take the d and e okay so this is the basic uh this what what you are doing you are making the cluster of numbers into separate separate numbers you are making the hierarchy of numbers okay hierarchy of numbers and this is what you are doing okay so you're just uh making a di um hierarchy of numbers and like abcdes you're going to up to down approach from up to down approach but in the case but in the case of but in the case of agglomerative you are doing something different you are here you are going up to down up to down in agglomerative you will take you will take because in agglomerative you have cluster one c2 they are unique clusters means only one cluster so you do merge it okay you do merge it okay so it is agglomerative is up to down approach sorry down to approach down to up okay so that's the basic intuition behind agglomerative and diversif clustering okay so we'll see in detail about agglomerative clustering and diversified clustering to help you better understand all of these algo ah agglomerative and diversif but the basic intuition behind hierarchical of clustering hierarchy of clustering is that you have at some points and what you do you simply you simply you simply merge to cluster because these p1 p2 p3 are before r4 cluster initially you merge through cluster and then you have some kind of similarity matrix okay so you have some some kind of similarity matrix that we will see according to that you merge it and then you make a dendogram or hierarchy of clusters okay so that's the that's that's what agglomerative and acclimative is just down to approach where you are converting the converting the clusters into by merging different different cluster antennas we have one cluster left at the top like this c1 okay as an example and in diversif you are actually going up to down approachment dividing the cluster into a single single group okay like a b c d e okay so that's the basic intuition behind this uh agglomerative and diversif clustering okay so let's start with agglomerative clustering deep dive into agglomerative clustering to help you better understand what an algorithm algo agglomerative agglomerative clustering does and we will see a lot more about this okay we will not see the implementation as of now we will see in another section where we now we are now after this i think we are we have we have completed this theory part all those thoughts means we have now have a good knowledge of everything now what what we will do we will make a lots of projects okay so here's an algorithm so first here if you're so first uh let me let me write an algorithm first i will write an algorithm and then i'll then i will make you understand with the help of good examples that i've already listed over here okay okay so here first what what we will do first you we compute the proximity matrix we compute the proximity matrix proxy midi matrix that just tells you the similarity between two points second we will we will see we will see we will see just as now it looks like and then you repeat these two process then then you repeat this two process then you repeat this two process merge merge two clusters merge two clusters and update the cluster update the matrix update the proximity matrix proxy midi matrix okay so that's the basic that's the that you repeat in a for loop and then you until and unless until you have one cluster you have one large cluster left means until you have left you have covered all the cluster okay until you have covered all the cluster okay covered all the cluster or we can say no clusters are left as a single cluster okay but this is this is a more formal definition until you have a good cluster like as as an example that i've showed to you okay so this is a basic algorithm to understand in agglomerative clustering now let's understand this in more detail okay so initially what i've talked about but i've note here what i'm going to note here like i'm going to write note which is each each cluster or p1 p2 p3 each are its own cluster now we'll be able to build a hierarchy of clusters okay so let's uh let's build uh let's build an approximating matrix how it looks like so the approximating matrix looks like this let's iron let's assume that you have p1 p2 p3 p4 okay i'll just assume as an example now what you do you you do this p1 p2 p3 p4 okay now you do this means this is approximately matrix this is the approximate matrix like this okay okay and these diagonals are zero these diagonals are zero these diagonal the diagonals are zero because the distance between the distance between the p1 and p2 will be obviously zero the distance between p1 and p2 maybe some group 2.4 there is p3 p4 like that so we have we have written like that p the distance between p1 p2 and p1 is maybe something like that diagonal distance between p2 and p2 is obviously zero okay so this this is what the basic uh this is what the basic proximity matrix looks like so let's see let's see that how we how we make a dendrogram okay so here we have p1 p2 p3 p4 now assume now we will just assume that uh let's take an example that this uh this is 4.6 to 4.2 6.9 point two eleven twelve thirteen fourteen fifteen sixteen seventeen eighteen okay it's a zero okay so the distance between p p four is p four is obviously zero okay so the p2 we we will find the smallest one we will find the smallest similarity here you can see that this this is the smallest similarity p2 and i think uh oops it's a it's a p2 and also i think that i've not drawn a good mirror i i will tell you so here let's let's assume that you have this proximity matrix that you have this proximally matrix just just don't take a take a look at this proximity matrix now what you will do you will find the smallest similarity so the smallest similarity so the smallest similarity over here is this three here we have three and six okay so here we have three and six that we have done first the smallest similarity okay so that's the that's that's what we i'm going to do so assume that this is p1 and p2 has a smallest now we have now what what now the next is the next you can find over here is four means six and four maybe let's see six and four which is here okay so we can go over here also three and four we can see this three and four also okay so we can take this three and four like this it's okay so just assume the next smallest is p3 and the next volts is p4 okay so now we have constructed now let's assume c2 p1 p p2 p1 then we have a again maybe some p3 and p4 now first you do this then you do this then you make this like this okay so now we have now now you have the hierarchy of clusters okay so that's the basic definition that's the basic algorithm for proximity matrix okay and this is what you do and you update the proximity matrix so how you update now you merge the merged the cluster now what you will do p1 union p2 okay p1 union p2 this one will be let's assume p1 and p2 are attached then p1 union p2 this will be the cluster okay now let's assume that the 2.7 and these are this are similar means this 2.2.7 and maybe some maybe like that so we can combine the cluster like that i think this is not an actual example the bad example okay but here uh you can you will you will be seeing one of more one more comprehensive example okay so how do we measure the similarity how do we measure the similarity of the inter cluster similarity we can measure the distance between two plus two points or clusters these p1 and p2 using maybe euclidean distance euclidean distance manhattan distance we have different different distance similar distance uh distance measures so how do we measure the the similarity between two clusters or enter cluster and inter cluster is nothing much that that similar the this is your one cluster and this is another cluster so what's the distance what the similarity between to merge it okay so that's the that's the inter cluster that we have already talked about in terminology sessions so let's see so we have so we have let's uh let's let's assume that you have this let's assume that you have this cluster where we have x this this this this this let's see another cluster this this so how do we measure the similarity how do we measure the similarity so for measuring the similarity we have i'm going to talk about three methods i'm going to talk about three methods min and the next method and max the next method is group average the next method is grouped average so let's start with min so what do i'm doing in min so let's assume that you have this uh so so you have this data point like this we have this cluster you have this cluster now the second cluster is like this second cluster is like this okay so what you do in minimum what you do in minimum you take out the minimum first to first i'm just just right let me write it mathematically to make it more sense oops what i've done okay so what you what you have to do what you have to do so let's let let me write it mathematically for minimum so minimum is is just the similarity between c1 and c2 which is nothing but equals to nothing but equals to minimum minimum of p i is member member of c one p i to be the member of c one let's assume this is c one so p i may be this point and p j the another cluster should be the member of c two now what you will do you will take out the similarity this the similarity of pi and pg okay these two okay these two distance okay now you take out the distance that you do you take out the distance i'm writing your distance and you you take out the minimum point minimum points who have mental here you with this the distance between these two points is minimum as compared to this point this point this point okay so we will uh just uh what what we will do we will simply uh merge it okay so this is what the basic minimum minimum approach does it just takes out the similarity between c1 and c2 by the taking out a minimum of all the i and js by taking on the distance between all the minimum taking out the minimum distance of all i and js with the member of c1 and c2 okay so that's the that's the minimum so let's see the basic uh basic thing over here to understand it little bit further away and this is this this example is taken from cs6530 by cluster analysis class lecture notes this this example okay so here here is your proximity matrix here is your proximity matrix where you have one as a p1 2 as a p2 like that okay now you have the here you have approximately matrix here you have a proximity matrix now here the distance between one and one is zero the distance between one and two is the 0.24 the distance between one and three and small point two two two the distance between one and four is point height 0.37 the distance between 1 and 5 is like this and this in the same way diagonal are 0 okay so you can see here the smallest similarity between or smallest distance between two points i and j here we are let's assume this is i and this is j the smallest distance is point eleven point eleven and we have three and six okay so we merge three and six as a first cluster okay now the next now the next smallest similarity or the smallest distance is is uh this one uh let let me choose yeah this this one point 14 okay so five and two okay so this is your next smallest so now what you will do you will merge it at the second cluster now what you will do you will find that this two cluster this the cluster u and this this p five five union two and uh and three union six finds to be uh um has a smallest distance so you merge with a cluster three next is you have one you have one and four now what what you do you this first you take out the just you just you can see first you take a first here we have full in which this union union and this full and this four has the smallest distance so you merge it and then you make a big cluster again and then you are done okay so it might make sense it might not make sense further but i will walk you through go through this example make the dendrogram by yourself or necessary clusters by yourself okay that will make more sense the next type of this is max what do i mean by with max max is simply max it's taking out the similarity between c1 and c2 which starts with the maximum which we which we want the maximum distance maximum distance between pi and pj and pi be the member of c one and p j p j be the member of c two so that's the that's the basic definition uh that's the basic of uh this ends here we are taking the max so what do i mean by max so here we have an uh intuitive or a comprehensive example so here you can see that we have again the same proximity matrix now you can see that the smallest distance is three six okay you merge it now how you will merge this four however why why don't don't we merge with five okay so the distance between the distance between this five and two is at maximum it's very large so obvious this this one obviously will be minimum so your merger that that's that's makes sense that's makes sense obviously okay so this this is what why you're you you take minimum distance but for merging you take the maximum you take out the maximum to merge and here you have taken the maximum and that's how and that's how and that's how all it works and here we have a maximum here we have a minimum so you take out a maximum and then you uh compare and then you take on the minimum and this is obviously the minimum and then you and you can see this is the maximum here and this is the minimum from here so you merge it okay so this is the basic and you can see the dendrogram over here how we made okay the next type of um inter cluster similarity measure the next type of inter cluster similarity measure is group average what do i mean by group average group average so i'm just going to give you the intuitive uh just um as a simple equation which is p i with a member of c 1 and p j where the member of c 2 p i be the member of c 1 and p j with a member of c 2 you take out the distance between p i and p j divided divided by the norm because the freak frequency divided by the norm of c one with whatever the number of points times the i think times the norm of c2 okay so this is what you have to do i think it's it may be plus yeah it may be plus yeah okay so you take out the norm of what is the number of points freak frequency okay so that's what you are going to do so you can see over here that we have this dendrogram we have this following and then what you do you take you group you group it look for for example you can see the same thing has been done but i'm going to take another example to help you understand this much better to help you understand this much better so you have this first and then you have this second cluster okay now you have some points you have some points in here you have some points in here and some points in here okay you take each pair you take each pair each pair like this you take each pair okay okay then you average it out okay and then you take out the distance you average it and then here you go okay so for example here you take out the minimum distance is three and six and then you have this four uh then again you merge it using the and that's what what we what we were doing but here we are merging one also the reason being the average between will it will be making sense if you sense it mathematically okay and five and two are closest okay so this is what you are doing in group men and let's see some of the uh some just this minimum this uh disadvantage the minimum disadvantage is it it simply it is it is sensitive to outliers it is sensitive to outliers and bad wrath rather than max is uh will will be less prone to outliers okay so that's the basic uh disadvantage that i've told you and you can see more onto the cs645 530 cluster analysis lecture notes to understand it much better okay so this is what we are doing and if you have not understood it is little bit advanced but it it should make sense little bit what what we do what we do and this we have make hierarchy of clusters like this okay so now we have talked a lot about hierarchical clustering and i hope that you really understood everything you need to know about hierarchical clustering now what i will do i will just name some uh now now what i will do i will name our time complexity i will and the space complexity now i'll name one time complexity and space complexity for agglomerative clustering just to make just to make sure everyone is on the same pace so the space complexity the space complexity is order of n square okay because we have approximate matrix too and time complexity will be order or maybe sometimes it's uh order of n q okay but some sometimes it goes to order of n square log of n okay so this this is your this is your space and time complexity to understand it much better and you can see the limitations pros cons of these onto the wikipedia pages they are very well explained there okay so we have we are done with hierarchical clustering and i really really hope that you understood everything now we are done with unsupervised learning now uh we will we will do a lot of projects and then we will end up this course and i highly highly recommend you to do lots of uh projects also okay and then after learning this machine learning you can get go to new era again i'm going to uh just to now navigate here the url https uh you can slash youtube.comera okay so you can find then uh just just take take take a look at a newly launched deep learning series okay from there you can learn uh advanced machine learning or uh or deep learning okay so that's it for this session i'll be uh so that's it for all this subsection i'll be catching up your next section okay so now we will build or start our last section of this course which is uh project section and in this section we will build two projects maybe some more project but uh initially i plan for two projects maybe i can add more but you can surely go to uh my youtube channel for more projects buzz but these projects will tell you an overview of how a machine learning project would look like and the motivation for starting you a new project because it's better to make your project by yourself just taking the inspiration from other people okay so in this project we will build a heart failure prediction uh model that will predict whether the person whether the person will die based on some of the features or not okay so this is the problem statement and we have certain features like age gender blood pressure smoke whether a person is smoked or not whether a person have diabetes or not what is injection fraction what is the that's what this is long name which i can't pronounce but the this is the this is a problem statement and you can take a look at the data uh we're going to take a look at the data which is available at this link and i hope that you will uh understand this project i i have made i've run step by step to help you understand everything and as i am made just i have not worked on this project so i just want to pick up this heart failure detection system just to make sure that i will be making my own project also and it will be uh and narrating over through this project okay so here uh what i'm going to do is what i'm going to do is i'm going to make a heart failure detection based on these features and the target variable of our which is that that event whether the particular person died or not so that's it with the target variable we will see more about the data but what is the business objective over here every machinery problem has some kind of business objective it simply means that it's some health care problem means we'll be able to build a health care we will be able to build a healthcare in healthcare something ai and healthcare which is simply able to make a machine learning model that will help you in early detection of the person based on particular features and help the person can be saved so that's why we are going to build that model to help you better understand the ai in healthcare we'll be building one more project which is spam detection system that is uh whether the email or messages are spam or not okay so let's start with this uh notebook and uh first of all i've divided first of all i'm going to load the data and sorry sorry import the libraries so i'm going to import pandas numpy seaborn matplotlib and this okay so i will run it down i will run it out and then i will load my data so i don't know why the second time so now i will load the data and my data isn't located in the folder of heart failure data set if you click on data set click on archive and here is my data set okay so there i'm going to do i'm going to just print out head and i want one more thing that i want to clarify over here the reason why i'm not writing or quoting by it here because i i thought like uh it will be better if i narrate the code if i if if i'm writing the code maybe i i forget something or maybe the code is not annotated too much so that's a for a few further references i just took to just write it down over here and then i'm only going to just add it over there okay most of them because because maybe while writing the code i may forget to narrate some of the code but yeah let let me know what you like whether i should write a code or not okay so i'm going to print it out the shape of the data i'm going to do the shape of the data is 29913 which is 13 columns and here we have h anemia cretinite false fokiness diabetes injection fraction hp then battle it serum then what is the gender smoking time and that even okay and that event is our target variable that we need to detect okay so that's our basic intuition that's our basic uh data exploration now what i'm going to do is we will see how much the data we have means we will see what's the shape of the data we have so here we are we are given the shape of the data which is 299 rows and 13 columns okay now using a day data dot shape you can do now i'm going to take a look at the information about the data you can calculate or you can take out the information about the data from the data the info method and you can if you see or we hope that it will tell you whether the particular column has no values what is the data type and what is the memory usage and it will also tell you what's the shape of the data by just taking you can also take a look at this and you can see that it starts with zero indexing so we have 13 columns you can also take a look at the description it will simply tell you whoever is the numerical column uh it it will tell you the describing means what is the count what is the mean of the particular column what is the standard deviation what is the minimum what is a 25 of that column and 50 percent of that column and 75 percent of that column and max and that column it will surely help in the photo means when if you're a data scientist it will surely help uh maybe something kind of uh you are exploring what's the maximum you can take a look at this you can take a look at what is the standard deviation what does it mean maybe you're formulating some problem based on machine learning so it's very helpful this this data frame you can you can have it spend five minutes understanding what was this and it's very easy it will tell you the count minimum standard deviation etc okay so what we have seen so far we have loaded we have imported the libraries we have loaded the data from my local directory i'm going to take a look at the shape of the data and i'm going to take and i'm going to take a look at information about the data okay so here i'm going to data dot info and that will give me the information about the data okay then i'm going to take a look at the description that's what is the uh well that it will describe our numerical data and then i'm going to take a look at what is the number of unknown values so here uh this will tell you this this will tell you in all the columns how many number of null values are and here we have zero zero zero no values in each and every column okay but if you let's say let's say let's take a second example that you want no i don't want this i just only wanted that how many how many numbers so you can add a sum and then you can run it out to see how it works so you can see that we have a total of zero uh no values okay so this is the basic exploration uh as i can do about the data access let's little bit exploration about the data okay now the main part will come in exploratory data analysis when when we do the so much of eda and a lot more so we will see over how we do the exploratory data analysis and here what do i mean by explorative data analysis in eda it it does not mean it is a very very hard but it does not also mean this is very very easy it's a very very crucial step in machine learning you should know your data how it is working what's the what's the distribution of the data is your data is balanced you have certain questions to ask we will which we'll see over here okay so you have certain questions to ask to your data that should your that using maybe some plots maybe some numbers will see that and you have to find answers of your coach of of your company because if you're a data scientist or data analyst at some company you should work mostly on to understanding and finding your business solutions as i'm a data scientist at artifact i used to see i used to work a lot more with the data i used to work a lot more with the data because i think that i should be able to what actually my data is and what the business objectives are and what's this what's the answer they want from my data okay so that's what i do a lot of ted exploration data analysis there so that's why i picked up this problem i found it very interesting and not picked so much of heart because it should be conserved like advanced house price predictor diabetes prediction system which i already made which is available in my github but i want you to try out make your unique project and showcase on your resume okay so then what we will do then we will simply see the distribution of our classes what do i mean by classes over here for this example we have we have a binary classification problem and this binary classification problem we are given one and zero okay so whether it if if this one then the person died if it is zero then the person doesn't uh not die i think i have to see okay so sometimes yeah so the the person is leaving is zero and the person is dead is one so we have two classes which is a binary classification problem okay so i'm going to take a look first what i will do i will take a look at the distribution of my data and you can see i'm highlighting the code from where i'm taking a look at the distribution of my data and here it simply means that i'm just going to take that's just just going to data then bracket i want to take a look at the event i'm going to count the number of event where the event is equal equals to zero and i'm going to count the same where the event is equal equals to one by taking out the length of each alex or cds okay then and also the pi pi takes an array so i'm going to put in an arrow like this i'm going to put in an arrow so let's let me choose that red color and this uh medium that works good i'm going to put in array and then i'm going to just label it just just to make sure everything is right so i'm going to label it with living and data i'm going to print it out what is the total number of living cases and what is the total number of diet cases okay and then i'm going to plot it out by just p l t dot pi i'm going to plot it a pie chart by giving our arr a r r will contain the length of life and length of depth like this okay and then labels will be the same light living and dyed exploit this is how much to explode amber and shadow what do you do you want your shadow yeah sure i want the shadow so i'm going to run it now so i just hope that i've run the previously so i'm going to run it now and you can see over here that you that's your data is imbalanced uh we are actually working out we are our data is imbalanced data so i will tell you why why this this data is imbalanced but first of all what is first of all if you can see opioid that we have total of 203 living cases and 96 which is tight cases and makes sense also because in real world living cases is more than the death cases i don't know actually i'm not but i think so okay so now let's let let me show it to you in particular to help you get a feel that uh what is imbalanced data okay oops what is not working what is imbalanced data so imbalanced data means let's take an example that you have two classes for example here we have two classes living and that okay so you have more examples of living which is here two or three like 203 examples but you have a far lesser two times lesser the lesser than examples of 96 okay so here you were actually working on a balance data what what can be the issue of this issue of this can be that your model and most of the model is most trained onto this living so you're uh you can assume that you're that the output of the most of the output of your model will be zero rather than one in some cases that will print one but it will in most of the cases it will be zero okay so here uh we have some examples so maybe it can but your model is more prone to train under 203 and your model may maybe get biased towards some problem means your model and can be like this print zero your model is this this model and it's only printing zero at every time so this happens when you have for one cases you have two on the let's take an example that you have a 400 examples so for one cases you have three nine nine examples and only one example for for death okay so that is causing that will cause the problem okay a big problem this is a big problem which comes as a something called as which was starting in deep learning which is working with imbalanced data okay so this this is what i'm going to highlight that just i just want to take a little take a take take take my answer is my data is imbalanced how much examples for each case do i have so i answered my question that we are actually working we are actually working on imbalanced data which is actually working here on imbalanced data where we have a living cases equals to 203 and diet cases equals to 96. so imbalance simply means that your classes that your classes are not equally distributed are not equally distributed so can i write it out um yeah so let's write the definition so i'm just going to comment it out just to imbalance means imbalance means that your data is your data is not equally uh distributed between classes distributed between classes between classes okay so uh it may happen that if in balanced data our data is equally distributed so for an example for a particular example so for example let's say you have a training length maybe 400 so if you have a training length to be the 400 so assume so assume 200 is for death examples 200 is for live example so we have we have equal number of examples in both living and death cases death cases okay so this is this is an example of balanced data and our model works best here okay this is more robust it is not biased towards anything okay so this is the basic uh this is this this is this is our first sticks for which we didn't also take take another reference so what what we have done so far we have simply taken we have simply uh drawn some eda from here by taking out the length and taking out the length of each event for a zero and one and then then i put in an array and then i'm gonna then i have labels which is living in dots and printed something and then i'm gonna plot the pie chart with that this this this this this explode comes with explode and shadow we want the shadow so you might be seeing the shadow over here okay and you can see that what the inference so i answered my question am i working on imbalanced data yes how much here okay two times just an approximate so our thigh face is two times lesser than the living cases or we can put in a percentage by just dividing it out by just dividing it down to the total length of our data okay so you can you can take you can try it out more mathematically but this is what i'm going to show you to you about this informants okay let's move on to the next inference in the next since we enter influence i wanted to take a look at the distribution of our age uh this this this will tell you whether your data is when what range most of your uh most of them the central tendency i think that is that is here the mean the most of the cases most of the edges like from 40 to 95 okay most of the cases 40 to 95 examples examples are starting from 40 to 95 95 and then you can see most of the cases are in around 16 okay and around 60 with some standard deviation okay so this is the distribution of your data you can try out for different different you can try out for definitely for different different uh numbers which i've already shown to you there are a lot more numbers you can definitely try it out okay make a pie chart for class for binary columns like high blood pressure it was or not or maybe gender make that column and see if it works so i will show you how to filter out the columns from there okay so now we have seen the distribution of our data so now what i want i just want to check so maybe my business objective is maybe my my my lead told to me hey uh if your data your data dashboard like this should be answering lots of questions should be answering lots of your questions about the data okay so here the answer that you're working on this data means the total number of type cases is less than the living cases okay which is two times less than the typically living cases okay so that's the that's the that's how you do and here you can see you can say to your stakeholder or whatever the lead that most of the a most of the age rise from 40 to 95 okay so you can see from this and c and you can tell most of the cases fly around from 50 to 70 like that okay that is the distribution of a data so now say that you wanted to check you wanted to check select you want to select the columns that are above age 50 and see they're dyed or not again a very good secret it sql query forum but maybe you just just think about what you want to do in pandas or you want to do it like that okay so it is possible and seek well but not i i just as an example yeah i've made in a python okay so what i'm going to do my business objective is select the columns select the columns sorry number of examples i think that i do you know select rows that are above age 50 and seeing that they are died or not so here what i'm going to do i i want the death event i want the death even because i don't want any any column with the death even whose age is above or equals to 50 and they are living okay and then again the same thing and then again i'm going to take out the length of the same as above i'm okay so if you've been if if i run this you can again see you can see here that here we have living cases here here we have the living cases a lot and you have a small but you can see the diet cases diet cases so if if i write it out i just want to write it out like this so oops i'm going to write a total number of total uh total number of it's a diet cases diet cases i'm going to take out the length length of diet length of that i'm going to do for total number of total number of nondiet cases not diet cases just i'm not able to write because i have two taps in front of me it's very difficult for me to dabble right over here okay so here length not died okay so here if you can see that you can you are able to see that we have total number of right because 85 and total number of not at 167. so just see over here that in total in total we have 203 which is two times lesser than and here this is fairly one times less than that okay so here you can see that most of the cases again died but most of the cases over 50 died okay as comparatively to our plot maybe not not making sense but again i'm sorry going to say that assume that just let's listen to what i'm saying i'm saying like you can see that um in our work plot we have total number of our diet cases in two times our diet cases our diet cases is two times lesser is two times lesser than our living cases and here our diet cases is one times lesser than not diet cases so here you can we can see obviously this is low but here you can see most of the people that are of always 50 died okay from this inference comparatively from the upper plot okay so here that's how we answer the questions from the data and i hope that you understood everything and i think that you will be taking out more influence okay great so let's see one one more one more uh column which is very fairly good column which i think oops get out i'm just going to yeah here it is oops yeah here it is okay so now now just assume that you want the columns that are available 50 and you'll see whether they are died or not i think that i have already already okay so you want that that there are above age 50 oops i think this is uh this is for diabetes so yeah so what you have to see you have to see you have to answer the question that the person is having diabetes that a person is having diabetes how many numbers how many numbers of patients who are diet are having diabetes and how many numbers a patient this dog dies their dead nondiets having diabetes okay so diabetes isn't um where the person is not having diabetes and having diabetes okay so maybe i've done a little bit wrong over here the diabetes should be there the diabetes should be there and we have to see whether the person had died or not okay so you can see diet with diabetes is this and not that with that diabetes is this so there are a lot more but you can again compare with the other plot over here then it will start making more sense okay so we have done extensive data exploration data analysis a lot more can be done to answer a particular business problem like this you can see over here you can answer some more questions from the data but as to give you a taste of this how i do how i like to do the answer the problem using my favorite visualizations okay so you can answer this uh it's it's very good to answer this all uh by just uh visualizing it out and saying to the lead okay so now now we have seen a lot more things we have seen that more of the visualization just don't worry about this the these are again in the course website mlo one dot native app it's a very very uh easy easy to get all these notebooks okay so now you will check the correlation of our variable so what did i mean by take checking the correlation of our variables it simply means that you'll do that how your how your features how your features are correlated so here you have a very good reference i have taken from the style they they have explained very much extensively every some online so here was telling it shows the correlation between variables on each axis and uh it's means this just shows that i will give you the uh plot over here but what is char what it does it simply shows you the correlation ranges from minus one to plus one okay minus one to plus one it simply means that if your variable is closer to minus one then is a very very similar okay if your is is very very similar so you can see value closer to zero means there is a no linear transmission lean linear thing is not there so you can you can't use linear regression over there between two variables means we can each this correlation tell us whether your data is a linear or not and the close to one the correlation is more positively correlated okay more positive means correlation will empty correlation between these two and you can read about pearson correlation for your efficient topic you're going to just use something kind of that okay that is one increase so that the other and close to close to one to the strongest this relationship is means the the one is closer to one the stronger the relationship is the diagonals are all one that simply indicates that the squares are correlating with each variable to itself so it's a perfect correlation so if you have all the data all the all the all the diagonals of one so the perfect sign of perfect correlation and the plot is also symmetrical and i know that you know about symmetrical so you can see over here but i'm going to just uh put it in a form of this i just hope that i'm going to put it like this okay so i'm going to run it out and here you can see that our data is perfect for relation more the dark is minus 5.3 like that is the more correlated okay so you can read that it's very io explain and also you can do the same as your like if you want to do it with the panas so here you are going to do and your diagonals are again one etc okay so we have done talked about various things you have under understand data and etc etc everything okay so now i hope that you got an idea about how you process so now what i will do i will start with data set development as i've talked about that you should devalue your data into training or testing set because for testing you have to check some you have to you you don't have real examples so for validating your model works best so what you will do you will divide your data and do validation segments training and validation set where you are dividing 70 30 okay so 70 for training and 30 percent for testing okay so you can run this out we are using the escalant api uh from while importing the trainer split okay so now we have done this and i hope that you understood this also so now we will do now we will i will not do future engineering over here but uh i will just showcase to you what's the what's what we do just a one example of feature in january okay so in featured engineering we add more features we encode our variable we encode our categorical variables we apply some transformations on our data just to insert our feature okay so here is an example of adding the feature okay so here what would here what what we are doing we are adding the interaction term okay so what is interaction term interaction terms means interaction terms means let's for a foreign sake of example assume that you have this data set this data set which is gender and age okay for an example so it will add again one new problem by taking out the product of g z and uh not let's take a bp okay and we think means in numerical so it will take the product and add okay so it is just doing the product of two features and making that call okay so maybe that that will not make sense but this is what the interaction term means means we are just adding the product of two features okay so here is our function for that so first of all we are taking the columns names then we are taking the length because we have to see we have to iterate through um and then i'm going to copy it out so that we can change anything to x and i'm going to um just iterate through all the columns and i column represent the represent of first column and this feature i name that this uh there is this this column i'm going to ask access using the x and then i'm going to range through j because i want to multiply these two so here again the same thing and again i'm going to take out the data and we'll do is just to make it this to just show the name of the column like this that that we multiplied and actually you're multiplying this out and then we are returning the x end okay so this is what and then we are calling on x train and x test and we are done okay so here if you run it out now you can see if if if i show you the code if i show you the xwing mod x train mod do i run it yep let me run it again you can see that we have 78 columns we have 78 columns from your 30 or 13 columns to 78 columns you can try the result how it is working and let me know in the comment box below on our on in our desktop community okay so this is what what we are doing and by adding the interaction term we are feel free to explore more okay now what we'll do we will now we'll start building our model so how do we build just just we will start building our model so first i'm going to make a model for evaluating our model so first i will take a look at the accuracy precision recall and confusion matrix so again if i run it over here now now it will give and we are giving the ground through as well as our predictive okay first of all i will start with legislative question with max iteration to be 1000 the reason why i have given over here because if you it is not converging it is not converging with any solver so for converging if you run it down you can see that lbgs fail to converge what you can do you can increase the number of iterations or or what do what you can do you can simply you can simply uh scale your data maybe my data is not scaled so increase to the iterations 2 000 and it worked okay but it is also telling a process to standardize your data or to scale your data so here for standardizing as well as the building the model so we have something called this make pipeline so what what it will do for any coming example is to standalyze and then it will uh and then we and then it will apply legislation over there okay so we are we are just doing in a small number of and you can compare the result of the standardization and that max iteration so the accuracy is actually better actually better precision is also better recall is also better and this is also better okay confusion matrix okay so i hope that you watch my session on preseason a recall but let's uh let me show you what those precision and recall confusion matrix means so maybe i have the this stochastic gradient reset yeah so we just just just want to make sure that you are on the same base okay so here i'm going to highlight one algorithm which is optimization algorithm which is same as our favorite gradient decent but here in gradient decent what we were doing it just takes it is taking a lot of time white is taking a lot of time so here assume this this example assume this example i'm going to narrow it over here that let's assume that you have a 10 000 data points 10 000 data points 10 10 000 data points and we have 10 features okay so here you have 10 features and the residuals consist of as many terms as their data points so you have 10 000 residuals because we are taking the difference between your predicted and now model predictive model output value so you have around ten thousand term in our case residuals so we need to compute the derivative of the ten thousand term you need to compute the third period of a ten ten thousand term with respect to our features which is ten thousand times ten which is one lakh computation per iteration that is so so much high okay so that's why we have some something called as stochastic gradient adjacent so what what we do so what could we do in stochastic gradient descent this we choose simply us the same thing happens we repeat until analytics our approximation is minimized and then we randomly shuffle and then we do at each step it means we at at one year step so we don't update we do updation as well as the derivation at each step and we are doing for each training examples for each training examples okay so it um you it is a little bit out of course it is usually thoughts and maybe an uh deep learning but i would highly recommend to learn this is just equal equals to the batch gradient decent okay so you will be able to see what's the difference okay so now as i've talked to you that we have something called as preseason recall accuracy so we have not talked about that so let's talk about i'll just spend a little bit of amount of time onto that so here tp means true positive means true positive means that your outcome that your outcome is that you that your moral outcome correctly predicts the positive class okay so you have in in any model you have two positive and negative classes positive negative classes positive like zero is a positive m one is a negative it'll be positive so your model predicts the same output as your ground through okay in a positive end for a positive class true negative is where the where your model predicted one and your output is also one and true positive means zero and zero these are positive plus and these are negative plus okay here you have false positive which is your model incorrectly your model predicted your model predicted your zero and actually the output is one so it is false positive means positive and false because they are not matching false negative is just the it's your moral your your moral predicted you're more predicted wrongly okay so you're more predictive one and your output is actually zero means negative and positive class okay so that's the that's that's the true positive negative and confusion matrix is simply like this first we have a true positive false negative false positive and true negative that we have just seen it will tell you how many number of are correctly classified as up in a positive class in a negative class in a in a but in the modern model field and a positive class with a moderate fail and this is a true negative where the model actually worked okay so you can see that we will we have seen okay so precedes and recall as we have talked about precision and recall a number of a true positive divided by the number of a troop or was divided by the number of a true positive plus the number of a false positive so true positives t p plot by three t p divided by the number of a true positive plus the number of a false positive okay so this is your output this is your output of the precision and simply answer the question what proportion of positive indications was actually correct okay so it answered what proportion so here we have 0.73 which is actually a good proportion but we had it can be improved the equal answer is the question what proportion of actual positive was identified correctly okay okay so it will tell you that what is the proportion of actual positives was identified correctly okay so this is the recall of our model okay so now we will see now we will see uh just just we will to see the that that the every season we call confusion matrix etc okay so now we will see now we have built our legislation with some standardization now we'll build a support vector classifier with a grid search cv with extensive fine tuning we have c which is lambda which is which which controls the width of that margin so we'll try different differences zero point one one ten hundred one thousand gamma one zero point one zero point one zero zero point one and kernel to be rbf kernel and then i will call the grid source to instantiate with the svc classifier ram grid reference to verbals equal to three it will i'm going to fit it it will try for each and every and checks like score and this is what here and this is what the thing is they have done where they have checked and you can find out the best parameter that the model found where c equals to 10 and gamma equals 0.01 you can see it's far performs a little bit less with uh compared to logistic progression but it worked okay so we have done with earlier we are done with the support bitter vector classifier as well as logistic regression classifier now what we will do we will do uh this we will we will make a decision a tree classifier okay so what i mean by decision tree classifier is i'm going to import the true as that we've already talked in detail i'm going to import a randomized research we have talked about grid search randomized research is same so i'm going to define a function that takes the parameters take some how many runs to clf what the classifier to use okay then we will then we'll call a randomized on clf which will give the clf which is classification number of iterations etc then if fit it then then you'll find the best parameter then we find the best score and then we'll say this and this this is just a custommade model but you can surely remove that and just use that randomized search and then put all these so i have already done in some of my projects i've just taken out from there and it's working great okay so i'm gonna it will tell which is the best which criterion is the best whether again drop your guinea a splitter or main weight is i have done a lot of uh fine tuning okay i will run it it will take a little bit amount of time trying all the values and checking the score and you can see the training score is it 0.84 and the test score is 0.75 okay now we'll run this classifier with the same uh with these uh features okay so it it will give me the output like this now i will oops now i will run it out maybe you can you can see okay so you can see how it how well it is performing maybe i have not let's see the best score randomized to search best score okay uh maybe uh yeah so that's that's the basic and you can also try it out maybe i'm a little bit uh you can see uh let's see if it is it is not good or not oops i have to also show okay so it is showing the best classifier so i have to put it over here i don't know why i put it over here but what i have put it now in when what mine but i will let me put it okay let's run it it's actually 0.75 so i've lit i have obviously done some fine tuning and here what i got that's with a good parameter okay so it's not always oh this works best in some of the cases it worked okay so now with the service little bit of fine tuning i'm going to call a random forest specifier then i'm going to run it with this with a with a parameter stack that we got with the random forest okay it will evaluate my model and then 0.86 0.1 actually good okay now what we'll do we will use xgboost okay xg boost is another we have talked about we're learning with 0.1 max step what is the number of parameters then i'm going to put evaluation set into one uh array okay so just uh just just see the log loss at the same time and then i'm gonna run it so it will tell at the log loss of the zero iteration and zero point hard to do is the log loss validation loss okay now we will evaluate and here again 0.85 is more robust model okay it is a robust model if you if you can see the importance it will show what features are more important so time is very important injection is very important so in this way you can select you can discriminate maybe smoking anemia sex creator dying and then means these these three you can remove as a future selection okay the last in that test we are going to uh use is a gradient boosting classifier gradient boosting is mostly used in a cases of images but let's see it how well it works with these hyper parameters you can also fine tune it to get better results than me and it actually worked okay now what i will do i will i will save my xg boost model because eddie boost is more robust so i will save my model by just calling for job lib job lift up dump i'm going to load my job if you can see if i run it now you can see that zero zero one and you can see if i go over here if i go over my heart failure and model.pkl file and you can load this model.pkl file to make a good model okay so that's the that's our that's a basic thing that we need to understand about um that test we need to understand about uh this hurt failure detection system and i hope that you have understood a lot from this okay so thank you for uh seeing uh this section and i really hope that you enjoyed this and we have covered this project in 42 minutes in the next project we will be talking about a small project spam detector system which is again a very cool project which is understanding problem statement and building a good model okay so let's meet at the next project then have a good day so now we'll talk about or we will make one project which is spam and hand detector system so if you have seen your gmail uh or google gmail or microsoft outlook there you are seeing that they are maybe where you have a tab which is spam tab they're your spam emails are there so in the same way we are going to build a spam and ham detector system so spam means means that uh that a particular message may be corrupt and ham means not a spam just oppose it to spam okay so just uh ham means not a spam i don't know why does not work for the first time not a spam okay and here you can see that that text we have a label means uh we are given a message we are given a message and we are given the target label which is our why okay so this this is our this is our message maybe go until journey point crazy and then you and there is a label which is given over there okay and this data set is downloaded this data set is down downloaded from uci repository and here is our data data set so it is in table so i'm not going to use csv i'm going to use table to read that i'm going to separate by a tab header should be none and the names of the columns should be labeled and messages okay so let's take a look at we will take a look at the first few uh data points so let me run this out first of all this and then this and then i'm going to show you one of the messages there so it should start making sense to you so here data oops what happened data and this is the messages it will take a little bit of time then zero position so you can see that go until journey point crazy available etc etc and here it says that is a ham that means not a spam so for a for example let's assume this second number because in second number we have it labeled at the span so free entry it's looking like a spam like it's free entry or where now like that okay so that is the that's that's the basic uh that's the basic exploration of our data and this is downloaded from uci repository okay so i think that you that you understood we are given a corporate for test so here we are not given any numbers here we and we are given here we are not given any number we are given oops what happened what is happening we are given a messages which is x as our messages which is in text format so your neural network argument sorry machine learning model does not work with text so you have to convert the text into numbers so we will see some of our favorite text text a vectorizer to convert this corpus of a test into a matrix or a vector or a number of a vector we will see that we will see that okay so here you can see that uh what here we are given a data which is text and there's one and then we have a label okay so now we will see now we'll start exploring our data set so now we have got our problem statement that we are given a part with our text we are given a text and we need to formative password or pipeline and give it to your output whether it is a ham or a spam or hammond zero and spam means one okay so that's that's that that's the our favorite uh given now we will move forward now now we'll move forward into exploring our data so i've already explored it so let me rerun it again so here i hope that you all are able to see this so maybe even if you're not don't don't worry i will just we're going to take a look at a shape of the data which is 5 72 572 with two columns and then we have a no values to be zero because we don't have any no values we have two infos and here which is a count unique values uh what is the frequency and etcetera and obviously they're in the text we do you don't have numerical things so that's why it's it's empty okay great so we explored the data very much now it's time to again start with explorer exploratory data analysis okay so in explorative data analysis we in the in our previous project we have seen that we have seen that we have to see the distribution we have to see uh the distribution we have to see the distribution of the classes okay so here we are seeing the distribution of the classes by just taking out the length and converting that into a length now now here you can see the labels which is hammer spam and it will tell what is the number of total labels with the plotting the pie chart and you can see over here that the number of ham examples is 4 825 and spam examples at 747 so we are actually working on imbalanced we are actually working on imbalanced data so your model will learn a more about tam rather than spam okay so be sure to keep that in mind next we will uh now it's it's very very important like uh for an example so let's uh let's understand the processing of our text how how we clean our text and why it is why it is there a lot more need so why do i mean like what do i mean by cleaning is for an example let's assume that you have a go okay so you have go oops go okay small g i don't know why it is not working again i like okay so here you have go here you have go okay it says best place small oh okay so these two will be considered different these two will be considered different but this is the same these two will can will be considered different but this is uh this is the same or maybe this hashtag does not need any sense over here so why do we need hashtag over here maybe we don't need like this we don't need emerges but here but in some cases like in sentiment analysis emojis plays an important role but here we are go and go are the similar thing maybe here we have a here we have a these these need if we if he gives to a model these two will be considered differently so that's that's not a good thing so what we will do we will convert all our text into lower text okay now here we are doing some text preprocessing that that you need to know okay just uh just using re okay rejects okay so i'm going to replace here and i'll be given one simple message i'll be given one simple message first of all okay i'm going to first lower it down by converting that into a string then i'm going to replace this this zero if there is any zeros in the text will be replaced by m okay and this this three will be replaced by k and k is thousand k or hundred k or what whatever this uh this comma will be replaced by this sorry uh above i i'm not recalling what's the name and except sorry uh it's uh it's uh i'm not recalling but yeah you can see okay so then you have won't will be here it will be considered different so will not okay can not should be can not can't should be cannot okay he uh we have we are just doing n not equals not what's what is is it's it is that his he is she is she is s own percentage then etc and then your l will okay so this is the this is the basic text preprocessing that i've done over here but one thing that i can also do over here one thing that i can also do over here like for stemming stemming okay stemming limitization limitization limitization so i would like you to explore this i would like to you to explore both of them in implementation okay and uh why what first of all let let me tell you what is stemming okay so stemming it simply means and it's it's in stemming it simply means that for an example for an example so if i go to some website let's take an example that i write play that i write play i write played then i write player okay so it will it will the stemming will give play and these three quotes can become will will be converted to this single word because they make a similar sense okay so that's the stemming and limitization is just a bigger version of that it it makes a meaningful some sometimes stemming does not make a meaningful word so for making a meaningful word we have lemmetization but again laminization what is just so for example place plays plates played and players so it will convert in play and the the stemming will convert in pla okay so it does not make sense but this limitation is making sense after we levitize our work word or we convert our corporates of a word into a single word okay so that's the seminal limitation but i want you to explore stemming the word stemming limitization using nltga library you can refer to some of my github i've already done that but i want you to do this okay so otherwise you know no tasks will be left for you in this task okay so here what then what then what we'll do then you apply to each messages by making a new column you apply each messages these text preprocessing by doing this all by calling the lambda and calling the laminate will go through each step will it it will it will go to each step and apply the function onto each messages and put that into a processed text so let's take an example of that it will start making more sense if you take a little bit of example okay so what i'm going to do is i'm going to print out i'm going to print out not first which will be our favorite uh not processor text so i'm going to print out first which is not processed text so these are data and then i'm not going to i'm going to post a video now i want to zero element and now i'm going to make a simple line i'm going to make a simple line oops what happened i'm going to make a simple line so it's just mix this and i'm not and then i'm going to just paste it over like this okay so it will show you what is the preprocess text so this preprocessed text is converted like this okay so apply stemming okay by using the porter stemmer you can go to nlp and ltk stamic nltk okay there is something called it's limitization so you can see some of the tutorials which are available in geeks4geeks etc so read it out means you can go to any of them whatever you like it's just converts the words into uh yeah here is a good example so playing play play so it will come common root from play okay so this will convert it like this like stemming is the process of reducing your inflection into words okay so you can read this read this sound this is a very good documentation provided by their camp and you will get to know much better about this but i will be bringing up one full course onto national language processing justice is a sample how do we work with the text but on new era on new era when full course on deep learning where we'll be talking on deep learning we'll cover text working with the textual data okay now we'll go further into now i'll go further into feature engineering what is feature engineering here we are not going to add any features we're just going to encode our hand to zero and expand to one by calling our map method then it's done now we'll divide up a data into train this split now if i run it here you have total number of this and then and then we and then what and then what what we will do now just assume now just see now just see over here that in training set in training set we have our text but neural machine learning will not accept the string or whatever the textual data so what we have to do there is modern means word embeddings then we convert our word and then we convert our word into maybe this word into some numbers into some numbers into some numbers there are a lot more techniques count vectorizer tf idf vectorizer bag of words which i'm not going to again talk about again it's time for you to explore as of now you can just think of it as you can see there you go you can see that what's the mathematical equation for that is a single mathematical equation but is what it does is simply you can go to usq learn feature extraction just extract the features from the text which converts your text into the numbers okay by just we instantiate over here now now with now what it it will do it will fit the training data means android return the matrix and then we don't want to fit the text test testing so that's why we are just transforming our uh text stress to the numerical into the matrix okay that's it okay so this is what we've used to convert our uh text into on vector of numbers okay so if i show you the training data how's the training data is a sparse matrix okay it's a sparse matrix which is with five thousand fifty five thousand two hundred and nine stored elements into that okay now we will use nine base i hope that you understood and i hope that you had a look we're on nine days uh on this as you have told to do the assignment so you hope that you had a look at night base you can read more about knife base this is just a very simple as we talked about some other learning algorithm it's very very simple okay so you may run this and then you just call color protect and here you have accuracy so now let's uh let's give up corpus vertex so let's take and let's stick and take an example here you have a text here you have a text and i'm going to write a y usage is a good boy i think let's see if it is a spam or not spam okay so i'm gonna just want to convert that this it in in production what we do we write a function process we write the function we'll take a text as an input then what it will do we we instead we call our account vectorizer which which we call over here so i'm going to call my count vectorizer like this count vector dot to transform i'm going to transform my text giving uh giving giving this i'm going to do this num okay so it will contain the basis of vectors now i'm going to just call my model which is maybe it will take a model so i'm going to call my model which is here nine days and then it will simply dot predict now it will simply predict my txt okay and then i'm going to oops it's num na i'm just convert that into a noun so it's the prediction i'm going to use the prediction and then what i'm going to do i'm going to read her the prediction okay so here if you call preprocess and then preprocess and predict so it will be it will take text as an input and it will return maybe it's maybe uh some problem maybe i have to do convector that fit transform what happened preprocess iterable over raw documents a string object received okay no worries so maybe what's the problem was causing is is i'm given this messages and instead of this preprocess but we need to give the process takes instead of messages so here we are given the messages now we are just going to providing the series and then i'm going to do count vector transform uh giving this talk and then providing naive bayes dot predict and this this this this will predict whether that it will it is a spam or a nonspam okay so that's the basic uh spam and ham detector system obviously you can try more stacking various various things so we hope just to give you a taste how the natural language processing uh project how we work with the data just to give you the taste of our data okay so i think we are we are completed with pro with this project i'll be i'll be catching up you in the uh maybe uh the next i think that we are done with this uh this course maybe i will do i will maybe we will talk about simple perceptron and then we will wrap up this course okay so thank you for seeing this course i would highly congratulate you for completing this course you
