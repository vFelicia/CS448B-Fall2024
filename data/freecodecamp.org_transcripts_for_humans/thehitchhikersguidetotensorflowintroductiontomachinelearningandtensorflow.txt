With timestamps:

00:03 - [Music]
00:21 - hey hello everyone how is it going
00:24 - good
00:25 - what about the party yesterday did you
00:27 - stay long
00:29 - nice that's a good feeling i was about
00:30 - to stay long enough was like nah maybe i
00:33 - need to work on my slide a bit more and
00:35 - maybe i should have stayed longer so
00:37 - we'll see okay
00:39 - so as you have seen um
00:41 - you know this uh title of my talk is
00:44 - about tensorflow and uh
00:46 - i kind of like had a bit of like hard
00:47 - time to see um
00:49 - how deep we are in a topic so um if you
00:52 - can put your hands up
00:54 - how many of you
00:55 - do some machine learning like i don't
00:57 - know from time to time
00:59 - oh that's amazing okay how many of you
01:01 - did some neural networks
01:04 - nice and deep learning
01:07 - cool and tensorflow
01:09 - i like your people okay so since
01:12 - you know depending on the city sometimes
01:14 - background is like a bit harder right uh
01:17 - for instance in munich um i also
01:19 - organize machine learning meetup when we
01:21 - have like a bunch of talks about i don't
01:23 - know all kind of deep learning right and
01:25 - um
01:26 - you know sometimes you know that the
01:28 - city is like a bit more prepared so like
01:30 - a general audience is like a bit
01:32 - um aware of things here i wanted to kind
01:35 - of start with the small things and after
01:37 - i go like deeper and more high level so
01:40 - hopefully even if you i don't know
01:42 - android developer or um like web
01:44 - developer you're not going to be feeling
01:46 - lost it's more like we will get there so
01:48 - we'll start slowly and after i get
01:50 - somewhere else um as you also noticed uh
01:53 - those slides didn't look like super
01:54 - amazing like for instance like pictures
01:56 - like super small you know why because
01:58 - it's in jupiter and there is a real gs
02:00 - that rendering that that also means that
02:02 - uh all the codes that they're going to
02:04 - be showing today and they're going to be
02:05 - a bunch of it
02:06 - you can just download jupiter notebook
02:08 - and just like run through it so um it's
02:10 - kind of excuse for myself like why it
02:12 - doesn't look that amazing
02:14 - yes um
02:16 - i mean uh
02:17 - one of the parts as well that you know
02:19 - people start talking like all this
02:20 - machine learning stuff right and
02:22 - it's all amazing right google changed
02:24 - from mobile first to ai first like and
02:27 - uh sometimes it feels like high pipe
02:29 - hype right and i didn't want to bring
02:31 - like many examples like how you can do
02:33 - like image classification is in this
02:35 - part so
02:36 - since we are talking about hitchhiker
02:38 - guys to the galaxy i brought this like
02:40 - babel fish like who's a wire what is
02:42 - that
02:43 - yes at least a couple of people travel
02:45 - the galaxy so in the original movie
02:47 - right they had this uh small babble fish
02:49 - right that um one of the actors kind of
02:52 - like putting inside of the ear right and
02:54 - this fish is translating to no matter
02:56 - what language you are listening to right
02:58 - into your own language basically right
03:01 - so it sounds pretty cool right you don't
03:02 - need to learn a land which you can go to
03:04 - whatever country and it just like does
03:06 - it for you
03:07 - um turns out uh it's not like you know
03:10 - futuristic and super crazy if you have
03:12 - seen uh you know announcement event from
03:14 - google
03:15 - i don't know maybe a couple of weeks ago
03:17 - they also announced like google pixel um
03:20 - buds right so those like headphones that
03:22 - you can tap on them and they're gonna be
03:24 - doing translation right
03:26 - um and it's kind of like pretty close
03:27 - what battlefish basically does right but
03:30 - you can basically buy it more or less
03:32 - right now and it's already going to be
03:33 - working
03:34 - um what is interesting about that that
03:37 - i don't i don't know i think like a huge
03:38 - percentage of that is basically based on
03:40 - the machine learning and deep learning
03:42 - right um on this case on this picture
03:45 - you can see just like a nice animation
03:46 - how google does uh
03:49 - one shot learning right so they do um
03:52 - like corp they have a corpus like of
03:53 - different languages right and uh
03:55 - essentially they are able to you know
03:57 - like build embeddings that means that uh
03:59 - you know you can uh um
04:02 - if you have different words right and
04:04 - based like how words are used right
04:05 - there is some common sense what they
04:07 - call the distributed presentations right
04:10 - and based on this information if you um
04:12 - give your network like a huge amount of
04:14 - text right you can learn that uh
04:16 - i don't know stage is uh somehow similar
04:19 - uh to the speaker right or clause in the
04:21 - um embedding space and what they also
04:23 - using like for uh translation like as a
04:26 - part of it right um another hand like
04:28 - right now even uh you know uh generating
04:31 - these audio waves is uh also in many
04:34 - cases like way better if you use like
04:37 - deep learning there so there was like an
04:38 - article from apple and this uh one from
04:41 - deepmind and they basically switch it
04:43 - more or less completely right and the
04:45 - sounds uh of you know what google home
04:48 - saying what is uh uh other part of
04:50 - google is saying and most likely this
04:51 - google buzz they sounds also like way
04:54 - better like way realistic right because
04:56 - you don't do concatenation of like
04:57 - smaller pieces but the network does is
04:59 - like end-to-end basically it's a wavenet
05:01 - yes
05:02 - and uh you know when you're starting to
05:04 - talk about all those uh um
05:06 - i don't know like machine learning and
05:07 - deep learning stuff usually you see this
05:10 - picture like how many of you have seen
05:11 - that
05:13 - yeah it's quite many especially at
05:14 - google i o and other place and you know
05:16 - i mean it's cool like it's showing you
05:18 - some information there are some layers
05:20 - right and
05:22 - i know like kind of a structure right
05:23 - and
05:24 - it's magically kind of works right but
05:26 - the problem right that uh sometimes it's
05:29 - kind of like missing all the details
05:30 - right you're like okay i got data i put
05:33 - it inside pom pom and it already works
05:35 - right it always remind me of this like
05:37 - oh how you do that you do circles
05:40 - pom-pom and here we go like he's already
05:41 - oh
05:42 - and what is even more funny and like the
05:44 - same time is like helpful right that
05:47 - many people that i was like meeting like
05:49 - lately right they were like so what they
05:51 - do i do some i don't know data science
05:53 - machine learning is all like oh yeah i
05:54 - can do data science and machine learning
05:56 - like i did a course like on udacity you
05:58 - put data inside bum bum and it already
06:00 - works right and i mean on one hand it's
06:02 - fine right because
06:04 - people feel motivated on the other hand
06:06 - like
06:06 - it's not that easy right otherwise we're
06:08 - not gonna be get paid for that
06:11 - and uh i wanted to go like a bit more in
06:14 - details right but is it gonna be like
06:16 - all this crazy about formulas and uh
06:19 - basically this is a formula uh i think
06:22 - that was for gans right how you can do
06:23 - that um
06:25 - no like i i think it's it doesn't make
06:27 - sense right because i mean we don't have
06:30 - like time for that and uh maybe
06:32 - you know you need like more your own
06:34 - time to digest it and like feel good
06:36 - about that so we kind of like have like
06:38 - a different approach we kind of go
06:40 - through a bunch of like cod samples um
06:42 - trying to you know like show some pain
06:45 - points and from there explain okay why
06:47 - did you do that or like what was
06:49 - happening there um yeah and the some
06:52 - first part is basically
06:54 - um it's just how we do kind of logistic
06:56 - regression just to give you a feeling
06:58 - like what is that about and after we
06:59 - will you know go like deeper a bit um
07:02 - yes
07:03 - if any moment you feel like what's
07:06 - happening just put your hands up and uh
07:09 - i will react on that and uh i don't know
07:11 - we will
07:12 - slow down and maybe do something crazy
07:14 - um okay so
07:16 - i think if you were doing i don't know
07:19 - computer science or um
07:21 - other uh related subjects uh most likely
07:24 - you have heard about logistic regression
07:26 - right and you know already how is it
07:28 - working and uh like have some ideas um
07:30 - it's a very basic and uh super
07:33 - simplified approach that
07:34 - you have some nice
07:36 - kitten right because everybody loves
07:38 - them and you have some
07:40 - you know vectors that you transfer it
07:42 - afterwards right and uh theoretically
07:45 - you can
07:45 - you know learn some kind of like
07:47 - representation that uh you'll be able to
07:50 - you know
07:51 - have some uh um
07:53 - activations or like hot points like on
07:55 - the pictures that will say okay because
07:58 - i'm getting you know positive values
08:00 - here right and negative like somewhere
08:02 - else right i can uh basically detect
08:04 - that it looks like cat like in that
08:05 - direction right and uh because we don't
08:08 - want to do it uh super simple we can
08:10 - also add some non-linearity right that
08:12 - in future we can
08:14 - use it for something more complicated
08:15 - right
08:16 - and i mean there's like a bunch of
08:18 - formulas how you can uh you know in
08:20 - terms of like mathematics define it
08:22 - right and um
08:24 - yeah so you can uh define your functions
08:27 - that is uh based on uh your weights
08:29 - right your input vector or some bias you
08:31 - can uh uh add some activation on top of
08:33 - it and uh you can have some loss
08:35 - function right so you can understand how
08:38 - bad you are right and
08:40 - on top of it you can have like a cost
08:41 - functions that you're trying to minimize
08:42 - right
08:45 - next one um yeah but
08:47 - you know
08:48 - if you have this part you still need to
08:50 - learn like what weights are coming from
08:52 - right and i'm not really going like that
08:54 - much deep in details because i think um
08:57 - it might be like a good topic to talk
08:58 - about but you can also like easily
09:00 - google how exactly back propagation
09:02 - works but ideas that um you know you
09:04 - have
09:05 - the way how you compute your cost
09:07 - function right and you can understand uh
09:09 - how to take like derivative of that so
09:11 - you know okay what smaller pieces you're
09:13 - taking from there and uh um
09:16 - if you will have like a small uh
09:18 - implementation in i don't know like a
09:20 - numpy for instance um
09:22 - it's not going to be like super
09:23 - complicated right in that direction so
09:25 - uh the formulas that you have seen
09:27 - before like it just
09:28 - goes like in the presentation of a numpy
09:31 - right and
09:32 - um once you analytically compute like
09:35 - derivatives you can also like measure
09:37 - how much they're coming from right and
09:39 - um when you do like in direction of
09:41 - optimization right what you do is
09:43 - basically um you compute your gradients
09:45 - right you know that okay you have some
09:48 - learning rate how much we kind of like
09:49 - going deeper and uh like how fast we are
09:53 - um but overall it's about you know step
09:55 - by step trying to adjust like your
09:57 - weights and the like biases in the
09:59 - direction
10:01 - and i mean okay it's not that hard right
10:04 - you can also um you got this working you
10:06 - got like your weights and after you
10:08 - basically compute the same functions
10:09 - that you had even before right and uh
10:12 - yeah
10:14 - sounds good in that direction right and
10:15 - i mean i'm not focusing that much on
10:17 - those slides because they still gonna be
10:18 - like available online and i better spend
10:21 - a bit more time like this uh tensorflow
10:23 - it's just like to show you how that you
10:25 - know
10:26 - it's not like totally crazy
10:28 - um yeah and uh essentially your model is
10:31 - basically um what it does like it
10:34 - initializes those like waste and biases
10:36 - right you do some optimization steps
10:38 - that you showed before and um when it's
10:41 - uh get like into proximity of your good
10:43 - parameters you say like okay we get from
10:45 - there um you know it's kind of like
10:48 - taking some time and uh depending like
10:51 - on uh structure because we had just
10:53 - logistic regression right it's pretty
10:54 - straightforward but if you go to like a
10:56 - deeper um like
10:58 - i don't know you could do like a
10:59 - multi-layer perceptron even um it's
11:01 - getting more complicated because you
11:03 - still need to um do some gradient
11:05 - checking now like other techniques that
11:07 - help you to understand that your
11:09 - implementation is still working right
11:11 - and i mean um especially right now
11:13 - there's like a bunch of companies that
11:15 - uh um do all those like frameworks for
11:18 - neural networks
11:21 - and i mean
11:22 - sometimes i have a feeling that um you
11:25 - know everybody wants to invent their own
11:26 - right there's like amazon there's uh
11:28 - google there's uh facebook with cafe too
11:31 - and stuff like that but today we're
11:32 - gonna be talking more about tensorflow
11:34 - right
11:35 - so tensorflow is kind of uh like a big
11:37 - animal right um
11:39 - it has many things that not really super
11:41 - visible for us like for instance
11:43 - all this uh super useful but uh
11:46 - not super you know
11:48 - applicable by like big percentage of
11:50 - people is uh execution engine right that
11:52 - knows like okay how do i work like with
11:54 - your symbolic graphs like how do i
11:56 - schedule them how like what to do with
11:58 - that right
11:59 - and plus some like
12:01 - uh optimizations as well that
12:03 - can run your vector operations like even
12:05 - faster on the all kind of hardware right
12:07 - so you don't need to think like okay i
12:10 - implemented like a numpy now i need to
12:13 - use like uh i think it's called like
12:14 - scipy there's a python package that you
12:16 - can
12:17 - not like sci-fi but to cooper
12:20 - that can run it like on a good
12:21 - architecture but uh
12:23 - in this case uh um tensorflow is kind of
12:25 - like taking care of all those things and
12:27 - even if it's like tpu you don't need to
12:28 - like you know implement the stuff like
12:30 - on your own um on top of it there is
12:32 - like a front end right like that it
12:34 - gives you ability to write some python
12:36 - stuff and
12:37 - um even on top of it there is also like
12:40 - layers that
12:41 - give some you know a structure that you
12:43 - need to re-implement it
12:45 - uh lately they also release like data
12:47 - sets that help you to you know like
12:50 - since you already have um gpus right for
12:53 - like fast learning but in many cases
12:55 - like pre-processing the data is like
12:57 - getting like a bottleneck and say trying
12:59 - to build like a good uh wrapper on that
13:01 - to make it even faster um and on top of
13:04 - it there is like a keras that is also
13:06 - going to cover in the talks that gives
13:08 - like even higher level obstructions
13:09 - there
13:10 - and what is kind of relatively new is
13:12 - like kent estimators if you use
13:15 - a skylarkit or psychic learn
13:17 - it's kind of in a very similar format
13:19 - you can just create like dnn and
13:22 - say fit and it's like kind of magically
13:24 - works so um theoretically you can also
13:26 - use that but practically it feels like
13:29 - more that you know you're working on
13:30 - that if you're like defining something
13:32 - like customize and architecture-wise is
13:34 - also more helpful um
13:37 - if you give like a bit of concepts
13:39 - introduction right um
13:41 - so there is like tensorflow as a word
13:44 - right like it has like two different
13:45 - parts like one is like tensor and
13:47 - another one is flow right quite obvious
13:50 - obviously but uh so if you're talking
13:52 - about tensors right um
13:54 - so it's like two diff like different
13:56 - pieces right in mathematics there is a
13:57 - different definition of tensors um but
14:00 - in tensorflow world is basically you can
14:03 - define um you know different uh ways of
14:05 - i don't know in this case like constant
14:07 - right but multiplication is also going
14:09 - to be like a part of this operation or
14:11 - like in this case if you print it right
14:13 - first is going to be tensor
14:16 - oh sorry
14:17 - but the result is also tensor right so
14:20 - you can define your graph basically in
14:21 - those like tensors
14:23 - what is also interesting right that you
14:25 - know if you do like this multiplication
14:27 - here and we print result at the end of
14:30 - the day it doesn't really show us result
14:32 - right like why is it happening because
14:34 - all the concepts that uh you know
14:36 - tensorflow and this like scheduling
14:37 - engine it does it later so it's like
14:40 - lazy uh evaluation and um you know like
14:43 - it still can do some crazy stuff like
14:45 - how to optimize it because i mean for
14:46 - this case there is nothing to optimize
14:48 - but in general case there is something
14:50 - more advanced for that if you have like
14:52 - uh deep network but what uh is kind of
14:55 - essential for that that uh once you have
14:57 - tensorflow session right you can say
14:59 - okay there's a um you know this
15:01 - operation set or tensors that uh i would
15:04 - like to execute right and when you do
15:06 - session run it's kind of okay does some
15:08 - scheduling some magic in the background
15:11 - and only after it does evaluation and
15:13 - execution of this lazy formula that you
15:15 - had right
15:17 - and what you can do is basically it's
15:20 - kind of like a hacky way and not super
15:21 - visible right now but
15:23 - wait a second
15:24 - so once you define it like in the
15:26 - current scope of your script or jupyter
15:28 - notebook right you can also use a
15:31 - jupyter uh sorry with a tensorboard you
15:33 - can try to visualize it and since since
15:36 - this one isn't like sliding betting not
15:37 - really good we have this one that
15:39 - basically shows that uh for the
15:41 - operation that we were showing right
15:42 - it's going to have the graph like that
15:44 - right and um if you were surprised that
15:46 - this like multiplication doesn't look
15:48 - very you know comfortable for you you
15:50 - can still use like a different sign like
15:53 - depending like on what kind of
15:54 - multiplication you have um yeah but
15:56 - basically you have session session
15:58 - basically based on what um back-end
16:01 - you're using and uh like where to
16:03 - execute those things
16:04 - yes um what is kind of essential for
16:07 - that is also being able to you know pass
16:09 - some variables so like in this case we
16:11 - are saying that okay i'm creating like a
16:13 - placeholder right for x with um yeah
16:17 - some information that i'm going to be
16:18 - using afterwards and
16:21 - you can afterwards pass it inside of
16:24 - uh your session so that's how you're
16:26 - also going to be um like learning your
16:28 - models
16:30 - um yeah if we
16:32 - uh you know like go in direction uh of
16:35 - initializing parameters right because
16:36 - it's what we usually do in the beginning
16:39 - um
16:40 - it's where tensorflow is kind of like
16:42 - getting verbose right because every time
16:44 - when you okay i'm defining like a
16:46 - variable for my ways right and it's not
16:48 - like
16:49 - how you would do in production system
16:51 - but it's more like a visible like what's
16:52 - happening there right and uh
16:55 - when you're defining that you will also
16:57 - say okay like what is the shape of
17:00 - this part right and um
17:02 - in many cases like you need to okay sit
17:06 - and like understand what you're going to
17:07 - be doing there um but you know there's
17:09 - like some complexity with this part is
17:11 - happening and i will mention it like a
17:12 - bit later like why is it important um
17:15 - yeah and there's also like some fancy
17:16 - way like how you can do like proper
17:18 - initialization like this uh like uh
17:21 - javier utilization for instance and
17:22 - stuff like that but uh what i would like
17:25 - you to just like see that uh okay we
17:27 - initializing parameters and uh you need
17:29 - to know like uh shapes of the layers
17:31 - what you're going to be using right
17:33 - and when you were talking about uh you
17:35 - know um there's like a loss function
17:37 - like and how we evaluate all those
17:39 - things right before we were like
17:41 - implementing like our own right and uh
17:43 - depending like okay is it um what kind
17:45 - of classification is it like multi-label
17:47 - right you still need to do like your own
17:49 - uh jobs there right um with that case
17:52 - like you know because tensorflow is
17:54 - already like a framework right they
17:55 - already have all things like in place um
17:58 - and it's also kind of like just going
18:00 - like a bit ahead uh sometimes in keras
18:03 - you like missing some parts that uh um
18:06 - what they call like or um
18:09 - i can curse it's like a low level but uh
18:11 - even though for multi-level
18:12 - classification we have some issues that
18:14 - we need to like implement stuff um yeah
18:16 - but back to um
18:18 - this part so you can basically just use
18:20 - uh cross-entropy with sludges and in
18:23 - your code is basically gonna be pretty
18:25 - straightforward right you're getting um
18:28 - you know your labels your lodges and
18:30 - after you can just uh pass it like as a
18:32 - convention um
18:34 - yeah
18:35 - so it doesn't really go like super crazy
18:36 - right um we still you know like in
18:39 - original uh
18:41 - uh part with logistic regression we had
18:43 - some forward propagation and uh um
18:46 - that's basically what we have here right
18:48 - um we have like a separate uh uh you
18:50 - know the parts that has like our
18:52 - parameters right that you wanna pass on
18:54 - like if you do like inside of the batch
18:56 - but basically um what you do is pretty
18:59 - similar what you did like in numpy
19:00 - beforehand right
19:02 - just like it's different prefix
19:04 - um yeah and they already have like all
19:06 - kind of like activations like relu or
19:08 - leaky will lose that kind of like a part
19:10 - of the story for you
19:12 - um yeah if you feel like that you know
19:14 - you don't really know like what
19:16 - directions we should be like is it relu
19:18 - like or sigmoid or why are we talking
19:19 - about those things just like catch me
19:21 - afterwards and we can have like a long
19:22 - discussion like how
19:24 - i know things are helpful like for um
19:27 - you know gradient vanishing like an
19:29 - explosion like afterwards but i'm afraid
19:31 - that here on the stage you just like
19:33 - take it as a given and after you can
19:35 - always go deeper and see like why i
19:37 - don't know i'm using relu and uh um not
19:40 - uh like proper sigmoid here um but uh i
19:43 - wouldn't go like that much in details
19:46 - yes and after if you you know like um
19:49 - defining kind of uh the model like in
19:52 - tensorflow way right um besides like
19:54 - having the bullet plates that we kind of
19:57 - do some reshaping part right um
20:00 - we have like a placeholder like
20:01 - parameters that we showed before right
20:03 - but
20:04 - essentially it's pretty similar right
20:06 - you have like a forward propagation uh
20:08 - what you did before right you were like
20:11 - uh analytically computing like your
20:13 - gradient right and after trying to like
20:15 - implement it um what tensorflow gives
20:18 - you is they have like a set of like
20:20 - optimizers right that
20:21 - depending like okay is it going to be uh
20:24 - granny and descend or stochastic
20:25 - gradient descent or the one is momentum
20:28 - right um
20:29 - just like to you know for those of you
20:31 - who are not familiar with that just
20:33 - depending like how you you know you have
20:35 - a function that you're trying to find uh
20:37 - i don't know like maximum or minimum
20:39 - basically what you're optimizing for
20:41 - there's like a different uh um numerical
20:43 - way to do that and uh there are like a
20:45 - different behavioral things right so for
20:48 - instance um like adam might be do some
20:51 - adaptive stuff that this more
20:52 - sophisticated than just using like
20:54 - stochastic gradient descent um but
20:56 - there's somebody who just want to play
20:58 - around with that you just can you know
21:00 - like use
21:01 - like item optimizers like one of default
21:03 - ones and uh just get it from there and
21:05 - what you can do afterwards is okay
21:06 - you're providing like a learning rate
21:08 - and you can say like minimize my cost to
21:10 - define beforehand right
21:12 - and even if you remember like cost
21:14 - function was
21:15 - not that
21:17 - complicated to define right so it's just
21:18 - like a sigmoid cross entropy
21:23 - right now it's like a bit complicated
21:24 - but after we will like switch into keras
21:27 - when it's going to be like way simpler
21:28 - just like to show you also like a part
21:30 - of complexity
21:31 - um yeah and what you could do afterwards
21:34 - you have your sessions that you are
21:36 - running right um here they kind of like
21:38 - do some um
21:40 - like mini batch part but basically ideas
21:42 - that you have like a session that you're
21:43 - running with your uh optimizer and like
21:46 - cost right and uh um yeah essentially it
21:49 - just uh uh
21:51 - if you run this model it's going to be
21:53 - showing like okay like after every epoch
21:55 - and how is your loss is basically
21:58 - changing so it goes pretty far pretty
22:00 - good right
22:01 - and again um i'm gonna share uh jupyter
22:05 - notebook afterwards so you can like
22:06 - click those things and try to change the
22:08 - parameters and
22:09 - make them available
22:11 - yes um
22:13 - okay so we can write those things right
22:15 - but one of the problems why the things
22:17 - was not taking off is like neural
22:19 - networks right i mean they're like
22:20 - multiple theoretical things right that
22:22 - you are not able to train them deep
22:24 - enough right but another problem
22:26 - resources right i remember like back in
22:28 - i don't know 2007 i believe like when
22:31 - you're like using some neural networks
22:33 - for um like as a kind of a student
22:35 - project thing for uh
22:37 - i i think like detecting some faces and
22:40 - like classifying like other things right
22:42 - we had like a separate machine that was
22:43 - running like for quite some days and it
22:45 - was like training on like on its own
22:47 - right
22:48 - and uh you know it was like machined
22:50 - with cpu right so it's like gonna be
22:52 - like super slow but the problem is that
22:54 - as you know human individuals right or
22:57 - like your personal project hobby one
22:59 - it's like take some time right to train
23:01 - those things
23:02 - um hopefully for us like there are like
23:04 - a bunch of uh
23:06 - cool companies that invest in like a
23:07 - good amount of resources that make it
23:09 - available
23:10 - and they're also working like on
23:12 - building like a cool architecture so
23:13 - like in this case it's inception model
23:15 - from google and uh um you can like
23:18 - download already pre-trained models like
23:21 - you think like okay we say train for
23:23 - some cases right
23:24 - um but turns out that if you haven't
23:26 - just like like the players right um
23:29 - after having like a bunch of you know
23:31 - you have like a bunch of classes right
23:33 - and in this case i think they use like
23:35 - uh um in some cases like it's google net
23:37 - uh coolness sorry imagenet uh like data
23:40 - set with like hundred thousands of
23:41 - images google has their own data set but
23:44 - basically they learning you know to um
23:47 - uh understand like to classify different
23:49 - classes right and meanwhile network uh
23:52 - also learns different representations
23:53 - right so if before you were coming from
23:56 - computer vision background and you're
23:57 - gonna use like uh sift or serve feature
24:00 - descriptors right now you can just use
24:03 - uh one of those like networks and get
24:05 - depending like what uh you know like
24:07 - level of presentation already for you
24:08 - and you can do like crazy stuff that i
24:10 - will show in a second
24:11 - um and i mean there are like a bunch of
24:13 - like a different
24:14 - uh you know
24:15 - network architectures and they already
24:17 - pre-trained one of more famous one is
24:19 - like vgg16 and it's like also super old
24:22 - uh what i want to show like on this uh
24:24 - graph is basically uh especially if you
24:26 - want to port it like for mobile or like
24:28 - some low-level uh hardware and if you
24:31 - want to you know optimize for inference
24:33 - um you will see that you know like on
24:35 - one access you will see like number of
24:37 - operations so like how much you know
24:39 - time it takes and also uh resources and
24:42 - another one like accuracy right and uh
24:45 - turns out not the most you know like
24:46 - number of operations are getting like
24:48 - the highest accuracy right so uh
24:50 - sometimes you can pick up like us
24:52 - inception v3 that uh relatively or like
24:54 - resnet from microsoft that uh like in
24:57 - terms of operations it's like pretty low
24:59 - right but in terms of accuracy is pretty
25:01 - high so just like keep in mind that uh
25:03 - you know there is like a good uh
25:05 - comparisons of things and uh i mean
25:07 - which g16 is cool but there's like other
25:09 - free train network that you can be using
25:11 - and there's also like a nice paper on
25:14 - archive basically that you can read on
25:15 - those things
25:16 - yes um okay so imagine that google
25:20 - trains this network for you right can we
25:22 - make it easier and like use it for
25:24 - something from us right so in many cases
25:26 - they uh sharing their models like in the
25:29 - protobuffer definition um and you can
25:31 - just like load it as as we do like in
25:33 - this case right so uh you can define
25:35 - like a graph definition and you can like
25:37 - read a file but basically essentially um
25:40 - yeah if you load it again like it's
25:42 - tensorboard visualizations that shows
25:44 - you
25:44 - um how simplified it looks like if you
25:46 - click on those blocks they're actually
25:48 - going to be extending so it's going to
25:49 - be as original image
25:51 - inception model um but basically you get
25:54 - the thing is running right so
25:56 - we got the model right like and uh what
25:59 - we can do afterwards is just basically
26:01 - um
26:02 - if you know like you define uh your
26:04 - network right usually uh you will have a
26:07 - um okay just like different layers right
26:09 - if you're familiar with topic there's
26:11 - some convolution layers that also um
26:14 - take into account not only the value of
26:16 - the point right but also um you know
26:19 - proximity so you're basically having
26:20 - like a bigger high level features um but
26:23 - usually if it's you know like multiple
26:26 - classes and zen zones a day you're gonna
26:27 - use like soft max right as a like last
26:29 - layer
26:30 - and what's happening here right that
26:32 - before soft max you're gonna have some i
26:34 - don't know fully connected layer just to
26:36 - like learn some things there um and
26:39 - maybe some pulling like on top of it um
26:41 - and what you can do is basically use
26:43 - this information like as a feature
26:44 - descriptor right and in this case like
26:46 - i'm taking uh i don't know i think like
26:48 - one of these intro pictures actually um
26:51 - and uh passing like inside and i will
26:53 - get like a vector of uh
26:56 - i think like 2048 or something if i'm
26:59 - not wrong but basically this um
27:02 - a bunch of digits here is going to be
27:04 - like a really good
27:05 - feature descriptor for you so you can
27:07 - easily uh implement uh you know like if
27:10 - you again like go to tensorboard and you
27:12 - show some
27:13 - uh
27:14 - i think in this case it's like pca but
27:15 - you can also do like a disney it's just
27:17 - like a way how you can put like a
27:19 - multi-dimensional data like in three
27:21 - dimension in this case but basically you
27:23 - will see that you know images that uh
27:25 - kind of look alike right will have like
27:27 - a similar image vectors right so you can
27:30 - easily implement the image similarity
27:32 - without i don't know spending much time
27:34 - so i've been at this like hackathon in
27:37 - zurich like months ago right and we had
27:39 - like one of projects that we wanted to
27:40 - add like image similarity and it took us
27:43 - like there was like one girl who was
27:44 - doing uh i think like data science at
27:46 - yandex and she was like are going to be
27:48 - using like surf and shift and i was like
27:50 - okay and meanwhile i will try to use
27:52 - some feature description from inception
27:54 - and uh it was like way faster on my side
27:56 - because you know like with all this like
27:57 - opencv stuff that takes some time it
27:59 - didn't really help that much
28:01 - yeah
28:02 - and if you go like more in production
28:04 - direction with all this like image
28:05 - similarity there's a library called uh
28:08 - like annoy like very nice name but it's
28:11 - basically built by spotify and they do
28:12 - like approximate nearest neighbor
28:15 - oh yeah like cisco how they call library
28:17 - but the basic idea is that once you have
28:19 - those you know um
28:22 - feature representations of your images
28:24 - right you can have some um approximate
28:27 - like neighborhoods right and it's super
28:29 - fast basically to
28:30 - say like okay i have this image that
28:32 - like belongs somewhere here right give
28:35 - me like a neighborhood of images that
28:37 - look look alike right so you don't need
28:38 - to do like some k n um but you can just
28:41 - like extract it from this index so if
28:43 - you do it in production it's like super
28:44 - cool project
28:46 - all those are like a couple of tricks so
28:47 - if you're going to be using this just
28:48 - like ask me or i don't know like ping me
28:51 - i will tell you that
28:52 - um yeah so
28:54 - you know you have seen that it's getting
28:55 - easier right you don't need to implement
28:57 - stuff but it's still pretty robust right
28:59 - there's like much things happening uh
29:01 - fortunately for us uh yeah there was
29:03 - like this library keras right um and uh
29:06 - they make it even better so they like
29:09 - wrap up things like together and um they
29:12 - also like add some um you know like
29:14 - proper way to like handle you know the
29:17 - ways that you need to think that you
29:19 - need to implement tensorflow on your own
29:20 - but basically if you're building like a
29:22 - simple model is as simple as it is right
29:24 - you have like a layers um yeah that like
29:27 - could be convolutions like or max
29:28 - pooling or whatever else like you can
29:30 - you know i can uh tell you afterwards
29:32 - but basically what you have afterwards
29:34 - you have a model and you adding like all
29:36 - the layers like in between so you do
29:38 - need to think like okay what is uh a
29:40 - shape of the layer before like how do i
29:42 - connect them together it's like you're
29:44 - focusing on like more important parts
29:46 - than just like thinking about shapes so
29:49 - it's pretty good right and uh yeah you
29:51 - can also do like a pretty
29:54 - second learn approach of uh you know
29:56 - model fit with like all your data and uh
29:59 - it's pretty
30:00 - good yeah and after if you want to go
30:02 - more in details you can also do like a
30:04 - model summary that shows you okay what
30:06 - layers you're having like number of
30:08 - parameters if you want to like decrease
30:10 - number of parameters because you wanna i
30:11 - don't know move uh to like smaller
30:13 - device and you wanna replace some fully
30:15 - connected layers with convolution and
30:17 - stuff like that
30:18 - yeah and if you do like evaluation it's
30:20 - basically also pretty simple afterwards
30:22 - right
30:23 - um what you can do afterwards is also
30:25 - like saving this stuff so you know like
30:27 - once you train it you can get it yet in
30:30 - different format for keras here but
30:31 - basically um yeah it will generate you
30:34 - like uh one is uh like a graph
30:36 - definition and another one ways
30:37 - basically that you can easily load
30:39 - afterwards
30:41 - um
30:42 - yeah and it's like a way how you can
30:44 - load the stuff um and uh there was
30:46 - examples that i trained like on a news
30:48 - data set and uh
30:50 - yeah it was like at the end of the day
30:52 - if you um
30:54 - you have like original image and you can
30:56 - uh yeah model predict that gets your
30:59 - like image and you can reshape to the
31:01 - proper shape but basically it will show
31:03 - you that okay
31:05 - it's like fours basically class that has
31:07 - it so it's basically look like four
31:10 - um yeah and uh if it was not simple
31:13 - right you can make it even simpler so
31:14 - like keras in this case they have
31:16 - already like applications and like in
31:18 - this case it's deception victory right
31:21 - and from there you can just uh define it
31:24 - and uh you know like you can say like
31:26 - weights are coming from image snare
31:27 - drive and uh um yeah and you can have
31:30 - like a graph already like working here
31:32 - right
31:33 - and uh yeah if you have the graph and
31:36 - you can load it you can just use a
31:37 - prediction from there
31:39 - um and this example that we had this uh
31:42 - image and uh depending like on you know
31:45 - uh um
31:47 - classes that the imagenet already having
31:49 - it's gonna be good but what you can do
31:51 - is basically um freeze like entire
31:54 - architecture besides the last layer and
31:56 - it will um like retrain not entire
31:58 - network because it can screw up the ways
32:00 - but only like your parts that you know
32:02 - it's using like a feature
32:04 - representations and like mapping a
32:05 - feature representation to your own
32:06 - classes you can go like even as far as
32:09 - uh using like one shot learning as uh
32:12 - you know like having like very few
32:13 - images that you can train on top of it
32:15 - um
32:16 - yes
32:18 - and uh you know it's already given like
32:20 - a pretty good idea that if you really
32:22 - want to use it you don't need to you
32:24 - know like know all the details it's like
32:26 - a similar direction of you know as i was
32:28 - saying if you want to drive a car right
32:30 - you don't need to know how exactly your
32:32 - engine works right you can just be like
32:34 - studying the wheel and like making it
32:35 - working and it's basically what's
32:37 - happening with like many deep learning
32:38 - models right if you know like a couple
32:40 - concepts right how you get like image
32:42 - features right you can always like build
32:44 - on top of it so it's kind of a lego game
32:46 - right and one of examples is like image
32:48 - captioning i didn't really bring the
32:50 - code inside but uh i can share with you
32:52 - if you interested
32:54 - but ideas there is that you also have
32:55 - image right you have like some
32:57 - convolutional parts that might be based
32:59 - like or i know like one of well-known
33:01 - networks right and after you do some
33:03 - like uh um
33:05 - iron and part right that can also maps
33:08 - the part of the words that you are
33:09 - saying right and uh if you have like
33:11 - once a data set right you can say okay
33:14 - this image as a data set has some
33:15 - descriptions that i don't know like uh
33:17 - um
33:19 - this like fly or broad display
33:21 - um and after a network you will learn it
33:24 - right so it's pretty good and you can go
33:25 - like that crazy as you know like even
33:28 - combining like more advanced right you
33:30 - know you're getting like uh questions
33:32 - that you know goes through some lstm
33:34 - right um
33:36 - yeah and uh after you have the same like
33:39 - feature descriptors and after um if you
33:41 - don't use like sequential model but
33:43 - basically functional approach for keras
33:45 - you can just join it in the same model
33:46 - so it's more about data that you're
33:48 - having but uh your tool set is basically
33:50 - staying the same
33:52 - yeah and in terms of deployment since uh
33:55 - you know it was
33:56 - pretty fast and i think like many of you
33:58 - is like what's happening i need to check
34:00 - jupiter afterwards um there's like many
34:02 - ways to do that right like one is a way
34:04 - is your own kind of way and uh you have
34:07 - like tensorflow servings that optimize
34:10 - for you have your model and can run it
34:12 - like in the background and uh
34:14 - it has you can use like nvidia docker
34:16 - and some kubernetes that you already
34:18 - most likely see and talk about that but
34:20 - basically you will have your own
34:21 - infrastructure like on gpus that shows
34:24 - those things yeah
34:25 - um and for android people of you and
34:28 - even android things of you um there is
34:31 - also like a version of tensorflow right
34:34 - that you can train on your um like a
34:36 - separate cluster for instance and after
34:38 - just saves the weights um but
34:40 - essentially what you would do is you
34:42 - have like a grading dependency right and
34:45 - you will you know basically uh define
34:48 - like uh um
34:51 - yes it's a part like where your
34:53 - protobuffer model is lies right so you
34:55 - can put it into your resources and um
34:59 - oops
35:01 - um you can also define where you're
35:03 - fitting it so like all those network
35:04 - architecture right they have like a
35:06 - specific names right so you can say okay
35:09 - feed it in direction of like input right
35:11 - and give me results like of output right
35:13 - in this case we don't really use like a
35:15 - feature presentation but we use it like
35:17 - original glasses and uh um yeah and it
35:19 - will get you pretty much working um
35:23 - and uh yeah in this case you can run the
35:25 - same one for android or like a small
35:29 - android things device uh the only thing
35:31 - that i also don't cover here is like how
35:34 - to optimize it right um because if you
35:37 - optimize for inference on mobile phones
35:38 - there is like a bunch of like other
35:40 - steps it might be doing like reducing um
35:44 - um like you know like how many bits you
35:46 - are storing like per weights right
35:47 - because sometimes it's like
35:48 - representation is pretty high sometimes
35:50 - you can also be more efficient on uh um
35:53 - archiving those models so um you can
35:55 - easily you know like decrease the weight
35:57 - of the models that you saving like by a
35:59 - factor of like 20 i believe um so if you
36:02 - um like interested about this part being
36:05 - me on twitter like i should have like a
36:06 - slide from munich when i was talking
36:07 - about uh doing deployments like for
36:09 - android
36:10 - but overall it's basically um it's
36:13 - pretty straightforward um so what i
36:15 - wanted basically to say here is uh
36:17 - you know there are like many different
36:19 - pieces right you can go like pretty low
36:21 - level you can go like pretty high level
36:23 - right um but it's like your own choice
36:26 - right if you want you can go pretty high
36:28 - level with keras with some free training
36:30 - models and
36:31 - get results like in a matter of hours so
36:34 - don't be afraid of like trying that and
36:36 - you can always go deeper right then be
36:38 - you know like scared of that okay i need
36:40 - to do like you know all those like
36:42 - derivatives like partial derivatives and
36:44 - uh no like bunch of mathematics it's not
36:47 - that much of rocket science like you can
36:48 - always go on that level but for the
36:51 - beginning you can just do like clicky
36:53 - clicky stuff like combining models and
36:55 - it still looks pretty cool like if it's
36:56 - really working for you so
36:58 - um yeah like there was
37:00 - lots of pieces kind of missing and it's
37:03 - like was pretty fast but i hope it's
37:05 - kind of like give you like a road map
37:07 - right and um like a guide basically
37:10 - right what things are there and uh if
37:12 - you have particular questions on like
37:14 - similar topics just like catch me up and
37:16 - we can talk about all cool for
37:18 - cool cans like for one megapixel and
37:20 - stuff like that
37:21 - yeah with that i finished my talk please
37:23 - thank you
37:24 - [Applause]
37:27 - [Music]

Cleaned transcript:

hey hello everyone how is it going good what about the party yesterday did you stay long nice that's a good feeling i was about to stay long enough was like nah maybe i need to work on my slide a bit more and maybe i should have stayed longer so we'll see okay so as you have seen um you know this uh title of my talk is about tensorflow and uh i kind of like had a bit of like hard time to see um how deep we are in a topic so um if you can put your hands up how many of you do some machine learning like i don't know from time to time oh that's amazing okay how many of you did some neural networks nice and deep learning cool and tensorflow i like your people okay so since you know depending on the city sometimes background is like a bit harder right uh for instance in munich um i also organize machine learning meetup when we have like a bunch of talks about i don't know all kind of deep learning right and um you know sometimes you know that the city is like a bit more prepared so like a general audience is like a bit um aware of things here i wanted to kind of start with the small things and after i go like deeper and more high level so hopefully even if you i don't know android developer or um like web developer you're not going to be feeling lost it's more like we will get there so we'll start slowly and after i get somewhere else um as you also noticed uh those slides didn't look like super amazing like for instance like pictures like super small you know why because it's in jupiter and there is a real gs that rendering that that also means that uh all the codes that they're going to be showing today and they're going to be a bunch of it you can just download jupiter notebook and just like run through it so um it's kind of excuse for myself like why it doesn't look that amazing yes um i mean uh one of the parts as well that you know people start talking like all this machine learning stuff right and it's all amazing right google changed from mobile first to ai first like and uh sometimes it feels like high pipe hype right and i didn't want to bring like many examples like how you can do like image classification is in this part so since we are talking about hitchhiker guys to the galaxy i brought this like babel fish like who's a wire what is that yes at least a couple of people travel the galaxy so in the original movie right they had this uh small babble fish right that um one of the actors kind of like putting inside of the ear right and this fish is translating to no matter what language you are listening to right into your own language basically right so it sounds pretty cool right you don't need to learn a land which you can go to whatever country and it just like does it for you um turns out uh it's not like you know futuristic and super crazy if you have seen uh you know announcement event from google i don't know maybe a couple of weeks ago they also announced like google pixel um buds right so those like headphones that you can tap on them and they're gonna be doing translation right um and it's kind of like pretty close what battlefish basically does right but you can basically buy it more or less right now and it's already going to be working um what is interesting about that that i don't i don't know i think like a huge percentage of that is basically based on the machine learning and deep learning right um on this case on this picture you can see just like a nice animation how google does uh one shot learning right so they do um like corp they have a corpus like of different languages right and uh essentially they are able to you know like build embeddings that means that uh you know you can uh um if you have different words right and based like how words are used right there is some common sense what they call the distributed presentations right and based on this information if you um give your network like a huge amount of text right you can learn that uh i don't know stage is uh somehow similar uh to the speaker right or clause in the um embedding space and what they also using like for uh translation like as a part of it right um another hand like right now even uh you know uh generating these audio waves is uh also in many cases like way better if you use like deep learning there so there was like an article from apple and this uh one from deepmind and they basically switch it more or less completely right and the sounds uh of you know what google home saying what is uh uh other part of google is saying and most likely this google buzz they sounds also like way better like way realistic right because you don't do concatenation of like smaller pieces but the network does is like endtoend basically it's a wavenet yes and uh you know when you're starting to talk about all those uh um i don't know like machine learning and deep learning stuff usually you see this picture like how many of you have seen that yeah it's quite many especially at google i o and other place and you know i mean it's cool like it's showing you some information there are some layers right and i know like kind of a structure right and it's magically kind of works right but the problem right that uh sometimes it's kind of like missing all the details right you're like okay i got data i put it inside pom pom and it already works right it always remind me of this like oh how you do that you do circles pompom and here we go like he's already oh and what is even more funny and like the same time is like helpful right that many people that i was like meeting like lately right they were like so what they do i do some i don't know data science machine learning is all like oh yeah i can do data science and machine learning like i did a course like on udacity you put data inside bum bum and it already works right and i mean on one hand it's fine right because people feel motivated on the other hand like it's not that easy right otherwise we're not gonna be get paid for that and uh i wanted to go like a bit more in details right but is it gonna be like all this crazy about formulas and uh basically this is a formula uh i think that was for gans right how you can do that um no like i i think it's it doesn't make sense right because i mean we don't have like time for that and uh maybe you know you need like more your own time to digest it and like feel good about that so we kind of like have like a different approach we kind of go through a bunch of like cod samples um trying to you know like show some pain points and from there explain okay why did you do that or like what was happening there um yeah and the some first part is basically um it's just how we do kind of logistic regression just to give you a feeling like what is that about and after we will you know go like deeper a bit um yes if any moment you feel like what's happening just put your hands up and uh i will react on that and uh i don't know we will slow down and maybe do something crazy um okay so i think if you were doing i don't know computer science or um other uh related subjects uh most likely you have heard about logistic regression right and you know already how is it working and uh like have some ideas um it's a very basic and uh super simplified approach that you have some nice kitten right because everybody loves them and you have some you know vectors that you transfer it afterwards right and uh theoretically you can you know learn some kind of like representation that uh you'll be able to you know have some uh um activations or like hot points like on the pictures that will say okay because i'm getting you know positive values here right and negative like somewhere else right i can uh basically detect that it looks like cat like in that direction right and uh because we don't want to do it uh super simple we can also add some nonlinearity right that in future we can use it for something more complicated right and i mean there's like a bunch of formulas how you can uh you know in terms of like mathematics define it right and um yeah so you can uh define your functions that is uh based on uh your weights right your input vector or some bias you can uh uh add some activation on top of it and uh you can have some loss function right so you can understand how bad you are right and on top of it you can have like a cost functions that you're trying to minimize right next one um yeah but you know if you have this part you still need to learn like what weights are coming from right and i'm not really going like that much deep in details because i think um it might be like a good topic to talk about but you can also like easily google how exactly back propagation works but ideas that um you know you have the way how you compute your cost function right and you can understand uh how to take like derivative of that so you know okay what smaller pieces you're taking from there and uh um if you will have like a small uh implementation in i don't know like a numpy for instance um it's not going to be like super complicated right in that direction so uh the formulas that you have seen before like it just goes like in the presentation of a numpy right and um once you analytically compute like derivatives you can also like measure how much they're coming from right and um when you do like in direction of optimization right what you do is basically um you compute your gradients right you know that okay you have some learning rate how much we kind of like going deeper and uh like how fast we are um but overall it's about you know step by step trying to adjust like your weights and the like biases in the direction and i mean okay it's not that hard right you can also um you got this working you got like your weights and after you basically compute the same functions that you had even before right and uh yeah sounds good in that direction right and i mean i'm not focusing that much on those slides because they still gonna be like available online and i better spend a bit more time like this uh tensorflow it's just like to show you how that you know it's not like totally crazy um yeah and uh essentially your model is basically um what it does like it initializes those like waste and biases right you do some optimization steps that you showed before and um when it's uh get like into proximity of your good parameters you say like okay we get from there um you know it's kind of like taking some time and uh depending like on uh structure because we had just logistic regression right it's pretty straightforward but if you go to like a deeper um like i don't know you could do like a multilayer perceptron even um it's getting more complicated because you still need to um do some gradient checking now like other techniques that help you to understand that your implementation is still working right and i mean um especially right now there's like a bunch of companies that uh um do all those like frameworks for neural networks and i mean sometimes i have a feeling that um you know everybody wants to invent their own right there's like amazon there's uh google there's uh facebook with cafe too and stuff like that but today we're gonna be talking more about tensorflow right so tensorflow is kind of uh like a big animal right um it has many things that not really super visible for us like for instance all this uh super useful but uh not super you know applicable by like big percentage of people is uh execution engine right that knows like okay how do i work like with your symbolic graphs like how do i schedule them how like what to do with that right and plus some like uh optimizations as well that can run your vector operations like even faster on the all kind of hardware right so you don't need to think like okay i implemented like a numpy now i need to use like uh i think it's called like scipy there's a python package that you can not like scifi but to cooper that can run it like on a good architecture but uh in this case uh um tensorflow is kind of like taking care of all those things and even if it's like tpu you don't need to like you know implement the stuff like on your own um on top of it there is like a front end right like that it gives you ability to write some python stuff and um even on top of it there is also like layers that give some you know a structure that you need to reimplement it uh lately they also release like data sets that help you to you know like since you already have um gpus right for like fast learning but in many cases like preprocessing the data is like getting like a bottleneck and say trying to build like a good uh wrapper on that to make it even faster um and on top of it there is like a keras that is also going to cover in the talks that gives like even higher level obstructions there and what is kind of relatively new is like kent estimators if you use a skylarkit or psychic learn it's kind of in a very similar format you can just create like dnn and say fit and it's like kind of magically works so um theoretically you can also use that but practically it feels like more that you know you're working on that if you're like defining something like customize and architecturewise is also more helpful um if you give like a bit of concepts introduction right um so there is like tensorflow as a word right like it has like two different parts like one is like tensor and another one is flow right quite obvious obviously but uh so if you're talking about tensors right um so it's like two diff like different pieces right in mathematics there is a different definition of tensors um but in tensorflow world is basically you can define um you know different uh ways of i don't know in this case like constant right but multiplication is also going to be like a part of this operation or like in this case if you print it right first is going to be tensor oh sorry but the result is also tensor right so you can define your graph basically in those like tensors what is also interesting right that you know if you do like this multiplication here and we print result at the end of the day it doesn't really show us result right like why is it happening because all the concepts that uh you know tensorflow and this like scheduling engine it does it later so it's like lazy uh evaluation and um you know like it still can do some crazy stuff like how to optimize it because i mean for this case there is nothing to optimize but in general case there is something more advanced for that if you have like uh deep network but what uh is kind of essential for that that uh once you have tensorflow session right you can say okay there's a um you know this operation set or tensors that uh i would like to execute right and when you do session run it's kind of okay does some scheduling some magic in the background and only after it does evaluation and execution of this lazy formula that you had right and what you can do is basically it's kind of like a hacky way and not super visible right now but wait a second so once you define it like in the current scope of your script or jupyter notebook right you can also use a jupyter uh sorry with a tensorboard you can try to visualize it and since since this one isn't like sliding betting not really good we have this one that basically shows that uh for the operation that we were showing right it's going to have the graph like that right and um if you were surprised that this like multiplication doesn't look very you know comfortable for you you can still use like a different sign like depending like on what kind of multiplication you have um yeah but basically you have session session basically based on what um backend you're using and uh like where to execute those things yes um what is kind of essential for that is also being able to you know pass some variables so like in this case we are saying that okay i'm creating like a placeholder right for x with um yeah some information that i'm going to be using afterwards and you can afterwards pass it inside of uh your session so that's how you're also going to be um like learning your models um yeah if we uh you know like go in direction uh of initializing parameters right because it's what we usually do in the beginning um it's where tensorflow is kind of like getting verbose right because every time when you okay i'm defining like a variable for my ways right and it's not like how you would do in production system but it's more like a visible like what's happening there right and uh when you're defining that you will also say okay like what is the shape of this part right and um in many cases like you need to okay sit and like understand what you're going to be doing there um but you know there's like some complexity with this part is happening and i will mention it like a bit later like why is it important um yeah and there's also like some fancy way like how you can do like proper initialization like this uh like uh javier utilization for instance and stuff like that but uh what i would like you to just like see that uh okay we initializing parameters and uh you need to know like uh shapes of the layers what you're going to be using right and when you were talking about uh you know um there's like a loss function like and how we evaluate all those things right before we were like implementing like our own right and uh depending like okay is it um what kind of classification is it like multilabel right you still need to do like your own uh jobs there right um with that case like you know because tensorflow is already like a framework right they already have all things like in place um and it's also kind of like just going like a bit ahead uh sometimes in keras you like missing some parts that uh um what they call like or um i can curse it's like a low level but uh even though for multilevel classification we have some issues that we need to like implement stuff um yeah but back to um this part so you can basically just use uh crossentropy with sludges and in your code is basically gonna be pretty straightforward right you're getting um you know your labels your lodges and after you can just uh pass it like as a convention um yeah so it doesn't really go like super crazy right um we still you know like in original uh uh part with logistic regression we had some forward propagation and uh um that's basically what we have here right um we have like a separate uh uh you know the parts that has like our parameters right that you wanna pass on like if you do like inside of the batch but basically um what you do is pretty similar what you did like in numpy beforehand right just like it's different prefix um yeah and they already have like all kind of like activations like relu or leaky will lose that kind of like a part of the story for you um yeah if you feel like that you know you don't really know like what directions we should be like is it relu like or sigmoid or why are we talking about those things just like catch me afterwards and we can have like a long discussion like how i know things are helpful like for um you know gradient vanishing like an explosion like afterwards but i'm afraid that here on the stage you just like take it as a given and after you can always go deeper and see like why i don't know i'm using relu and uh um not uh like proper sigmoid here um but uh i wouldn't go like that much in details yes and after if you you know like um defining kind of uh the model like in tensorflow way right um besides like having the bullet plates that we kind of do some reshaping part right um we have like a placeholder like parameters that we showed before right but essentially it's pretty similar right you have like a forward propagation uh what you did before right you were like uh analytically computing like your gradient right and after trying to like implement it um what tensorflow gives you is they have like a set of like optimizers right that depending like okay is it going to be uh granny and descend or stochastic gradient descent or the one is momentum right um just like to you know for those of you who are not familiar with that just depending like how you you know you have a function that you're trying to find uh i don't know like maximum or minimum basically what you're optimizing for there's like a different uh um numerical way to do that and uh there are like a different behavioral things right so for instance um like adam might be do some adaptive stuff that this more sophisticated than just using like stochastic gradient descent um but there's somebody who just want to play around with that you just can you know like use like item optimizers like one of default ones and uh just get it from there and what you can do afterwards is okay you're providing like a learning rate and you can say like minimize my cost to define beforehand right and even if you remember like cost function was not that complicated to define right so it's just like a sigmoid cross entropy right now it's like a bit complicated but after we will like switch into keras when it's going to be like way simpler just like to show you also like a part of complexity um yeah and what you could do afterwards you have your sessions that you are running right um here they kind of like do some um like mini batch part but basically ideas that you have like a session that you're running with your uh optimizer and like cost right and uh um yeah essentially it just uh uh if you run this model it's going to be showing like okay like after every epoch and how is your loss is basically changing so it goes pretty far pretty good right and again um i'm gonna share uh jupyter notebook afterwards so you can like click those things and try to change the parameters and make them available yes um okay so we can write those things right but one of the problems why the things was not taking off is like neural networks right i mean they're like multiple theoretical things right that you are not able to train them deep enough right but another problem resources right i remember like back in i don't know 2007 i believe like when you're like using some neural networks for um like as a kind of a student project thing for uh i i think like detecting some faces and like classifying like other things right we had like a separate machine that was running like for quite some days and it was like training on like on its own right and uh you know it was like machined with cpu right so it's like gonna be like super slow but the problem is that as you know human individuals right or like your personal project hobby one it's like take some time right to train those things um hopefully for us like there are like a bunch of uh cool companies that invest in like a good amount of resources that make it available and they're also working like on building like a cool architecture so like in this case it's inception model from google and uh um you can like download already pretrained models like you think like okay we say train for some cases right um but turns out that if you haven't just like like the players right um after having like a bunch of you know you have like a bunch of classes right and in this case i think they use like uh um in some cases like it's google net uh coolness sorry imagenet uh like data set with like hundred thousands of images google has their own data set but basically they learning you know to um uh understand like to classify different classes right and meanwhile network uh also learns different representations right so if before you were coming from computer vision background and you're gonna use like uh sift or serve feature descriptors right now you can just use uh one of those like networks and get depending like what uh you know like level of presentation already for you and you can do like crazy stuff that i will show in a second um and i mean there are like a bunch of like a different uh you know network architectures and they already pretrained one of more famous one is like vgg16 and it's like also super old uh what i want to show like on this uh graph is basically uh especially if you want to port it like for mobile or like some lowlevel uh hardware and if you want to you know optimize for inference um you will see that you know like on one access you will see like number of operations so like how much you know time it takes and also uh resources and another one like accuracy right and uh turns out not the most you know like number of operations are getting like the highest accuracy right so uh sometimes you can pick up like us inception v3 that uh relatively or like resnet from microsoft that uh like in terms of operations it's like pretty low right but in terms of accuracy is pretty high so just like keep in mind that uh you know there is like a good uh comparisons of things and uh i mean which g16 is cool but there's like other free train network that you can be using and there's also like a nice paper on archive basically that you can read on those things yes um okay so imagine that google trains this network for you right can we make it easier and like use it for something from us right so in many cases they uh sharing their models like in the protobuffer definition um and you can just like load it as as we do like in this case right so uh you can define like a graph definition and you can like read a file but basically essentially um yeah if you load it again like it's tensorboard visualizations that shows you um how simplified it looks like if you click on those blocks they're actually going to be extending so it's going to be as original image inception model um but basically you get the thing is running right so we got the model right like and uh what we can do afterwards is just basically um if you know like you define uh your network right usually uh you will have a um okay just like different layers right if you're familiar with topic there's some convolution layers that also um take into account not only the value of the point right but also um you know proximity so you're basically having like a bigger high level features um but usually if it's you know like multiple classes and zen zones a day you're gonna use like soft max right as a like last layer and what's happening here right that before soft max you're gonna have some i don't know fully connected layer just to like learn some things there um and maybe some pulling like on top of it um and what you can do is basically use this information like as a feature descriptor right and in this case like i'm taking uh i don't know i think like one of these intro pictures actually um and uh passing like inside and i will get like a vector of uh i think like 2048 or something if i'm not wrong but basically this um a bunch of digits here is going to be like a really good feature descriptor for you so you can easily uh implement uh you know like if you again like go to tensorboard and you show some uh i think in this case it's like pca but you can also do like a disney it's just like a way how you can put like a multidimensional data like in three dimension in this case but basically you will see that you know images that uh kind of look alike right will have like a similar image vectors right so you can easily implement the image similarity without i don't know spending much time so i've been at this like hackathon in zurich like months ago right and we had like one of projects that we wanted to add like image similarity and it took us like there was like one girl who was doing uh i think like data science at yandex and she was like are going to be using like surf and shift and i was like okay and meanwhile i will try to use some feature description from inception and uh it was like way faster on my side because you know like with all this like opencv stuff that takes some time it didn't really help that much yeah and if you go like more in production direction with all this like image similarity there's a library called uh like annoy like very nice name but it's basically built by spotify and they do like approximate nearest neighbor oh yeah like cisco how they call library but the basic idea is that once you have those you know um feature representations of your images right you can have some um approximate like neighborhoods right and it's super fast basically to say like okay i have this image that like belongs somewhere here right give me like a neighborhood of images that look look alike right so you don't need to do like some k n um but you can just like extract it from this index so if you do it in production it's like super cool project all those are like a couple of tricks so if you're going to be using this just like ask me or i don't know like ping me i will tell you that um yeah so you know you have seen that it's getting easier right you don't need to implement stuff but it's still pretty robust right there's like much things happening uh fortunately for us uh yeah there was like this library keras right um and uh they make it even better so they like wrap up things like together and um they also like add some um you know like proper way to like handle you know the ways that you need to think that you need to implement tensorflow on your own but basically if you're building like a simple model is as simple as it is right you have like a layers um yeah that like could be convolutions like or max pooling or whatever else like you can you know i can uh tell you afterwards but basically what you have afterwards you have a model and you adding like all the layers like in between so you do need to think like okay what is uh a shape of the layer before like how do i connect them together it's like you're focusing on like more important parts than just like thinking about shapes so it's pretty good right and uh yeah you can also do like a pretty second learn approach of uh you know model fit with like all your data and uh it's pretty good yeah and after if you want to go more in details you can also do like a model summary that shows you okay what layers you're having like number of parameters if you want to like decrease number of parameters because you wanna i don't know move uh to like smaller device and you wanna replace some fully connected layers with convolution and stuff like that yeah and if you do like evaluation it's basically also pretty simple afterwards right um what you can do afterwards is also like saving this stuff so you know like once you train it you can get it yet in different format for keras here but basically um yeah it will generate you like uh one is uh like a graph definition and another one ways basically that you can easily load afterwards um yeah and it's like a way how you can load the stuff um and uh there was examples that i trained like on a news data set and uh yeah it was like at the end of the day if you um you have like original image and you can uh yeah model predict that gets your like image and you can reshape to the proper shape but basically it will show you that okay it's like fours basically class that has it so it's basically look like four um yeah and uh if it was not simple right you can make it even simpler so like keras in this case they have already like applications and like in this case it's deception victory right and from there you can just uh define it and uh you know like you can say like weights are coming from image snare drive and uh um yeah and you can have like a graph already like working here right and uh yeah if you have the graph and you can load it you can just use a prediction from there um and this example that we had this uh image and uh depending like on you know uh um classes that the imagenet already having it's gonna be good but what you can do is basically um freeze like entire architecture besides the last layer and it will um like retrain not entire network because it can screw up the ways but only like your parts that you know it's using like a feature representations and like mapping a feature representation to your own classes you can go like even as far as uh using like one shot learning as uh you know like having like very few images that you can train on top of it um yes and uh you know it's already given like a pretty good idea that if you really want to use it you don't need to you know like know all the details it's like a similar direction of you know as i was saying if you want to drive a car right you don't need to know how exactly your engine works right you can just be like studying the wheel and like making it working and it's basically what's happening with like many deep learning models right if you know like a couple concepts right how you get like image features right you can always like build on top of it so it's kind of a lego game right and one of examples is like image captioning i didn't really bring the code inside but uh i can share with you if you interested but ideas there is that you also have image right you have like some convolutional parts that might be based like or i know like one of wellknown networks right and after you do some like uh um iron and part right that can also maps the part of the words that you are saying right and uh if you have like once a data set right you can say okay this image as a data set has some descriptions that i don't know like uh um this like fly or broad display um and after a network you will learn it right so it's pretty good and you can go like that crazy as you know like even combining like more advanced right you know you're getting like uh questions that you know goes through some lstm right um yeah and uh after you have the same like feature descriptors and after um if you don't use like sequential model but basically functional approach for keras you can just join it in the same model so it's more about data that you're having but uh your tool set is basically staying the same yeah and in terms of deployment since uh you know it was pretty fast and i think like many of you is like what's happening i need to check jupiter afterwards um there's like many ways to do that right like one is a way is your own kind of way and uh you have like tensorflow servings that optimize for you have your model and can run it like in the background and uh it has you can use like nvidia docker and some kubernetes that you already most likely see and talk about that but basically you will have your own infrastructure like on gpus that shows those things yeah um and for android people of you and even android things of you um there is also like a version of tensorflow right that you can train on your um like a separate cluster for instance and after just saves the weights um but essentially what you would do is you have like a grading dependency right and you will you know basically uh define like uh um yes it's a part like where your protobuffer model is lies right so you can put it into your resources and um oops um you can also define where you're fitting it so like all those network architecture right they have like a specific names right so you can say okay feed it in direction of like input right and give me results like of output right in this case we don't really use like a feature presentation but we use it like original glasses and uh um yeah and it will get you pretty much working um and uh yeah in this case you can run the same one for android or like a small android things device uh the only thing that i also don't cover here is like how to optimize it right um because if you optimize for inference on mobile phones there is like a bunch of like other steps it might be doing like reducing um um like you know like how many bits you are storing like per weights right because sometimes it's like representation is pretty high sometimes you can also be more efficient on uh um archiving those models so um you can easily you know like decrease the weight of the models that you saving like by a factor of like 20 i believe um so if you um like interested about this part being me on twitter like i should have like a slide from munich when i was talking about uh doing deployments like for android but overall it's basically um it's pretty straightforward um so what i wanted basically to say here is uh you know there are like many different pieces right you can go like pretty low level you can go like pretty high level right um but it's like your own choice right if you want you can go pretty high level with keras with some free training models and get results like in a matter of hours so don't be afraid of like trying that and you can always go deeper right then be you know like scared of that okay i need to do like you know all those like derivatives like partial derivatives and uh no like bunch of mathematics it's not that much of rocket science like you can always go on that level but for the beginning you can just do like clicky clicky stuff like combining models and it still looks pretty cool like if it's really working for you so um yeah like there was lots of pieces kind of missing and it's like was pretty fast but i hope it's kind of like give you like a road map right and um like a guide basically right what things are there and uh if you have particular questions on like similar topics just like catch me up and we can talk about all cool for cool cans like for one megapixel and stuff like that yeah with that i finished my talk please thank you
