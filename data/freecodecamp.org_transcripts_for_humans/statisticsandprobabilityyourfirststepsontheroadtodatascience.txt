With timestamps:

00:11 - all right
00:12 - welcome everybody my name is joe merlo
00:15 - we're going to go through real quick
00:16 - some of the install instructions and
00:18 - then we'll get through and start doing
00:20 - some
00:21 - expectation management those kinds of
00:23 - things
00:25 - most of you have probably done the
00:26 - install instructions already so i'm just
00:28 - going to cover those briefly a couple
00:30 - tools we want to have on our systems i
00:33 - tend to prefer using
00:34 - a tool called conda to help me do
00:37 - package management
00:39 - some specific libraries that we're going
00:40 - to install we'll walk through those
00:42 - we'll go through how we test for
00:44 - installation and talk a little bit about
00:46 - why we're doing things with this way
00:48 - [Music]
00:50 - one of the things that i often recommend
00:51 - read all the steps ahead of time get a
00:53 - sense that you understand what the steps
00:55 - mean some steps may say install thus and
00:58 - turns out you already have it installed
00:59 - so you may not have to do that
01:03 - for this tutorial i highly recommend
01:05 - using cond as a package manager because
01:07 - there are some libraries that are kind
01:09 - of sucked into this process that are not
01:11 - necessarily python libraries so some
01:13 - python package managers may not be real
01:15 - good for this
01:18 - conda has a virtual environment manager
01:20 - to help manage your virtual environments
01:22 - we'll talk a bit about what that means
01:25 - the material for this has been tested
01:26 - using conda but it has not been tested
01:28 - with pip it has not been tested with
01:30 - virtual and etc
01:32 - if you already have conda installed you
01:35 - can test that by typing conda on the
01:37 - command line and if you get something
01:39 - back that says usage conda
01:42 - you're good
01:43 - if not the instruction should walk you
01:45 - through it
01:46 - for this course material we're using
01:48 - python version 3 dot x
01:51 - when you say python equals three and one
01:53 - of the commands we'll do in a minute
01:54 - it'll give you the latest version of
01:56 - python
01:57 - um
01:59 - from my experience the most common
02:01 - problem that i see when people start to
02:03 - do this
02:04 - is they they miss a step right our eyes
02:06 - tend to glaze over and we miss things so
02:09 - if you have a problem uh
02:12 - scroll back check to see if you've done
02:13 - all the things if not we have a set of
02:16 - mentors in the room uh and myself we can
02:19 - walk around and help you especially
02:20 - during the part where we do exercises
02:22 - all right
02:24 - there are a set of instructions for
02:25 - doing this in windows and mac and linux
02:30 - you can confirm whether conda's been
02:31 - installed
02:32 - by doing conda or condoles
02:46 - this is high tech guys
02:49 - all right
02:53 - next
02:55 - all right so let's talk a little bit
02:56 - about what we're doing when we're
02:57 - installing python and some of the other
02:58 - things you're going to make a directory
03:00 - called stats you're going to change into
03:02 - that directory so now you're inside that
03:04 - folder
03:05 - and we're going to create a virtual
03:07 - environment
03:08 - at the bottom of this material i have
03:09 - kind of a write-up as to why virtual
03:11 - environments are important and how they
03:12 - can be useful to you and i'll leave that
03:14 - up to you to read it but the the big
03:16 - picture for virtual environments and why
03:17 - you might want to use one is that it
03:20 - creates a sandbox
03:21 - some of you have python already
03:23 - installed in your computers and you
03:24 - maybe use it for work and you don't want
03:26 - to corrupt or mess up your existing
03:28 - version of python or your existing
03:29 - libraries that use with python so the
03:31 - virtual environment makes a sandbox what
03:33 - we do goes in the sandbox and it doesn't
03:35 - interfere with anything that happens
03:37 - right
03:39 - once we've made a virtual environment we
03:41 - have to activate it and if you've
03:43 - activated a virtual environment you're
03:44 - going to see these little parenthetical
03:46 - off to the side to say you're now using
03:49 - that virtual environment and now using
03:50 - the version of python that you installed
03:52 - for that environment
03:54 - and then next we can say conda install
03:57 - and you can tell it all the libraries
03:59 - that you would like to use in this case
04:01 - we have five main libraries that we
04:03 - intend to explore
04:05 - all right
04:06 - once you've installed those
04:08 - we'll type jupyter space lab
04:11 - and hopefully a lab environment will
04:13 - open up if you do not have one let us
04:16 - know and we'll get you get you taken
04:18 - care of
04:19 - you kind of raise your hand i'm going to
04:20 - pass out some stickies as well in a
04:22 - little bit
04:23 - all right
04:24 - next we have class material it is up on
04:26 - github
04:28 - i'll put the links back up for those in
04:30 - a second you guys can go look for that
04:33 - all right
04:35 - as we go through the process you'll see
04:37 - these green post-it notes in the
04:38 - material
04:39 - all the stuff i want you to do
04:41 - basically stops there if you want to
04:43 - keep reading you can go ahead but
04:45 - you can typically stop wherever a green
04:46 - post-it note is
04:48 - for those who really want to know more
04:49 - details about all of these things
04:52 - at the bottom of this lesson i have a
04:54 - big picture description of why we use
04:55 - virtual environments what is conda doing
04:57 - why are we using it and all that stuff
04:59 - and so you can scroll through and read
05:01 - all of all of that content at your
05:03 - leisure we're not going to go into it
05:05 - all right
05:07 - so with that in
05:08 - mind all right
05:11 - i'm going to walk you through a little
05:13 - bit about kind of how this class itself
05:15 - is going to play out and the types of
05:17 - things that we want to do
05:19 - all right
05:21 - first off i appreciate
05:23 - pycon
05:25 - my family friends who suffered through
05:27 - me trying to get this material ready
05:29 - my company that helps to get me here
05:31 - booz allen hamilton
05:33 - the pycon tutorial selection committee
05:35 - the mentors who are here in the room who
05:37 - are going to be helping you guys and
05:38 - especially you for being willing to come
05:40 - out and go through this statistics and
05:43 - probability exploration with me
05:46 - to give you an idea of what to expect
05:48 - and what not to expect right
05:50 - we'll do an overview of some probability
05:52 - and statistics print
05:54 - so it's a tough word right it's hard
05:56 - english is tough um we're going to do an
05:58 - overview of probability and statistics
06:00 - principles and techniques
06:02 - we will have some snippets of python
06:04 - code i'm going to warn you right now the
06:06 - code that chalmer wrote for here should
06:09 - never be used
06:10 - in a production environment
06:13 - the things that i wrote are more to demo
06:15 - principles to give you an idea of how
06:17 - things work kind of under the hood they
06:18 - are not for true statistical analysis
06:21 - and i'll prove it i'll show you why
06:23 - there's going to be plenty of
06:24 - opportunities for you to level up your
06:26 - skills we'll have exercises that you
06:28 - guys can walk through and we'll give you
06:29 - a certain amount of time in this
06:31 - tutorial to work on those myself and the
06:33 - mentors will help you
06:36 - i will highlight a few of the gotchas to
06:38 - look out for things that you might be uh
06:41 - experiencing as you go through this
06:42 - journey on your own when you get back to
06:44 - your house etc
06:46 - and we're going to provide some
06:46 - resources to help you continue your
06:49 - learning journey when you go home what
06:50 - are some good books to read or were some
06:52 - good things to look at et cetera
06:54 - so what not to expect
06:56 - if you think this through a typical
06:58 - college class is about 40 some odd hours
07:02 - of sitting in a lecture hall
07:04 - lots of homework in between sitting in
07:06 - lecture halls
07:07 - we have three and a half hours and if we
07:09 - bring biology and taking breaks and
07:11 - stuff into this story we have about
07:13 - three hours
07:14 - right
07:15 - so you're not going to get
07:17 - a whole lot out of this my hope though
07:20 - is that
07:21 - you will get
07:23 - a flavor and that flavor will drive you
07:25 - to go home and keep learning
07:27 - um you are not going to get out of
07:28 - chalmer robust industrialized code we
07:31 - spoke about that
07:32 - and in terms of deep dives we're not
07:34 - going to have the time so some folks may
07:36 - ask some questions like hey i want to
07:37 - know a little bit more about these types
07:39 - of distributions and how these are
07:40 - related to that we're probably not going
07:42 - to have the time for a lot of that
07:45 - we could have maybe conversations about
07:47 - that outside of this i really want to
07:48 - give you guys this nice high level
07:51 - overview
07:52 - in terms of logistics
07:56 - pair practice is used in some tutorials
07:59 - because working closely with a partner
08:01 - helps you kind of identify what's going
08:02 - wrong and helping each other out i'm not
08:04 - going to force that upon anyone
08:06 - if you want to work with someone who
08:08 - sits next to you and say hey why don't
08:09 - we work on the code together or why
08:10 - don't we work through these exercises as
08:12 - a pair i'll leave that up to you and
08:14 - your level of comfort
08:16 - we're going to distribute out some
08:18 - post-it notes for you when you get to
08:20 - the end of a period of exercises you put
08:22 - your post-it note at the top of your
08:24 - monitor so i can look out when i see a
08:25 - sea of green i know it's time to kind of
08:28 - move on
08:29 - if you run into a problem you'll have a
08:31 - red post-it note that will hand out to
08:33 - you you put it on your monitor myself or
08:35 - the mentors will look out and go oh red
08:37 - post it red post it and we'll come to
08:39 - you right so you don't have to do this
08:40 - whole embarrassing hey i got a problem
08:41 - thing
08:42 - um there will be a survey and i'll get
08:44 - you the link to that later i really want
08:46 - to get your feedback okay
08:48 - so how do we get the most out of this
08:50 - experience
08:51 - um i love this picture and let me zoom
08:54 - down so you can kind of see it
08:56 - the top and i apologize it's a small
08:57 - font it says how do you actually learn
08:59 - any new programming concept
09:01 - by changing stuff and seeing what
09:03 - happens
09:04 - one of the cool things about python
09:07 - is that you can try something run it and
09:10 - see what happens you go wow that was
09:12 - cool let me change this number or let me
09:14 - do this thing and you run it again and
09:16 - you get an instantaneous kind of
09:18 - response
09:19 - so i heavily encourage you play with
09:22 - things when you do an exercise and you
09:23 - get done a little early try and go back
09:25 - and do it again tweak something
09:29 - you're gonna have questions that might
09:30 - come up like hey
09:31 - chalmer what if or what will happen if
09:33 - we do this
09:35 - and i love to hear those questions those
09:37 - are great
09:39 - i will caveat that though with i also
09:41 - love to see folks have that question in
09:44 - their head and they go try it themselves
09:46 - because sure i can demo it for you but
09:49 - man how much fun and excitement it is to
09:51 - try it and see some cool response
09:54 - some people say well i don't want to
09:56 - break anything i don't want to do it
09:57 - wrong
09:58 - and that's a legit fear so i'm not going
10:00 - to minimize that
10:01 - but generally with python you're not
10:03 - really going to break much
10:04 - and if you do you can kind of reboot
10:07 - and often if you do quote unquote break
10:09 - a thing there's going to be some error
10:11 - message and you're going to skim it and
10:12 - maybe it's confusing but you're going to
10:14 - see new words new terms and you're going
10:16 - to start to learn things because those
10:17 - error messages as scary as they might
10:20 - look will often teach you things
10:22 - especially when you see them over and
10:23 - over again so
10:25 - try not to be scared
10:28 - there's a couple other things in here
10:29 - and i'm not going to go through them in
10:30 - the interest of time but
10:32 - they're there and they talk about the
10:34 - psychology of learning stuff
10:37 - but this quote here is kind of neat
10:40 - being a programmer basically requires
10:42 - you to deal with these extended periods
10:43 - of feeling like a complete
10:46 - punctuated by very brief periods of
10:48 - feeling like a genius right
10:50 - um
10:51 - that's my life every day i'm standing up
10:54 - here trying to teach you guys a thing
10:55 - but most of my life is i don't know how
10:58 - to get my code to do this thing and i
10:59 - don't know why and then all of a sudden
11:01 - it works
11:02 - and i feel like that guy on the titanic
11:05 - no
11:06 - right and i feel great and then my boss
11:09 - is like we'll solve this other problem
11:10 - now that that's done
11:12 - okay so let's get rolling
11:15 - let's talk about statistics
11:18 - all right so this is kind of the the
11:20 - main meat of the thing
11:21 - um i'm going to disappear behind the
11:23 - podium and grab those post-its and have
11:24 - one of my colleagues pass them around
11:27 - all right
11:28 - and then i'll come back
11:33 - i'm still here
11:36 - voila
11:37 - all right
11:38 - everybody gets one green one red
11:40 - not one pad one green post-it one red
11:43 - posted
11:44 - you don't know what he's going to do
11:46 - all right
11:48 - so let's get started this first
11:50 - conversation is going to talk about
11:52 - statistics right
11:54 - and what we can do with that and then a
11:56 - little later on we're going to move into
11:57 - probability okay
11:59 - um
12:00 - our main goal right now for this first
12:03 - little bit
12:04 - is to understand you know some
12:06 - techniques for counting things
12:08 - determining what the minimum value is
12:10 - maybe in a data set figure out what the
12:12 - maximum value is
12:14 - and then we will look at these things
12:16 - that we call central tendencies
12:18 - that the fast version is what's the
12:20 - average and we'll explore different ways
12:21 - to look at at that
12:23 - and then we will talk about well how
12:26 - widely does stuff kind of deviate from
12:28 - that average is my data really spread
12:30 - out or not okay
12:34 - let me try and blow this up a little bit
12:35 - maybe okay
12:37 - um
12:38 - we're going to look at the data and
12:39 - we're going to look at these techniques
12:40 - and these processes through a couple
12:42 - different tools we're going to start off
12:43 - with some simple data sets just a couple
12:46 - numbers so we can kind of visually see
12:47 - what the thing is
12:49 - we will then go through a little bit
12:50 - larger data set a little more
12:52 - sophisticated
12:53 - we're going to have some hand developed
12:55 - code that's chalmers
12:57 - do not use this in production code
13:00 - and then i'm going to walk you through a
13:01 - couple of standard libraries that have
13:03 - some functions that do what my code does
13:06 - but does it way better all right
13:09 - to kind of get us in the right frame of
13:11 - mind
13:12 - i'm going to use a
13:14 - i'm going to use that big data set that
13:15 - i mentioned we'll look at it and we'll
13:18 - display it on the screen in a graph
13:20 - and then we're going to use tools to
13:21 - kind of
13:22 - figure out what some of those data
13:24 - points are
13:25 - okay by hand as it were
13:27 - all right
13:28 - so let's pretend i'm a manufacturing
13:30 - plant and you know every day i produce a
13:33 - new batch of stuff
13:35 - on some days my machinery is well tuned
13:38 - and the number of batches that i produce
13:40 - or the batch that i produce has very few
13:43 - defects in it
13:45 - but other days my machinery is starting
13:47 - to fall apart things are breaking and
13:49 - all of a sudden i get larger quantities
13:51 - of defects so i may want to track these
13:53 - on a day-to-day basis
13:54 - all right so i have this data and it is
13:57 - this number of defects
13:59 - i purposely kind of organized it so it's
14:01 - kind of bigger numbers at the top
14:03 - smaller numbers at the bottom they're
14:04 - not quite sorted but
14:06 - so we see some things like there's a 99
14:08 - there's a 52 there's a 42.
14:11 - uh
14:12 - at the bottom we have some twos and
14:14 - threes and fours i don't know there's
14:16 - like 208 or some some odd numbers we'll
14:18 - figure that out
14:21 - i will warn you we're not going to do a
14:22 - deep dive into matplotlib i'm going to
14:24 - gloss over this real quick
14:26 - i just wanted to give you a graph but
14:29 - i use matplotlib here to import
14:32 - some capabilities that will enable me to
14:35 - make a very basic plot
14:37 - i also have a tool called the counter
14:40 - tool and we'll talk a bit about it in a
14:41 - minute
14:42 - that's going to help me count things
14:45 - and now i want to make a simple
14:46 - histogram a simple graph
14:49 - what we're going to do is try and start
14:51 - off by making this display and we're
14:53 - going to use a tool called most common
14:56 - which is found in the counter object and
14:58 - you'll see how that works out
15:00 - all right so
15:02 - i start off by taking all of those
15:05 - values that i had number of defects
15:08 - and i drop it into my counter object and
15:10 - that's going to produce a thing that
15:11 - looks like a dictionary but it's not
15:12 - quite
15:13 - and so i call it defect counts
15:16 - and then i say all right
15:19 - show me the five most common values that
15:21 - occurred in
15:23 - all of my number of defects so we run
15:25 - that code
15:26 - and so the number 8 showed up 24 times
15:29 - the number 6 showed up 24 times
15:32 - and the number 7 showed up 18.
15:34 - all right
15:35 - i mentioned that counters look a little
15:37 - bit like dictionaries
15:39 - there's two nuances that you should know
15:41 - they have this kind of extra method that
15:42 - we just saw called most common
15:45 - that allows us to find out what are the
15:46 - most common things and i can tell that i
15:48 - want to see the two most common items
15:51 - and it'll give me that or i can say i
15:52 - want to see the five most common items
15:54 - it'll give me more
15:56 - right
15:57 - but
15:58 - one other nuance that is fun is that if
16:00 - you've ever played with a dictionary and
16:02 - you try and
16:06 - access a value that doesn't access a key
16:08 - that doesn't exist your dictionary will
16:11 - vomit on you and it throws up this
16:12 - little error and says hey you tried to
16:14 - look at something that doesn't exist
16:16 - counters are cool that they don't do
16:18 - that
16:19 - if i try to access the number 77 which
16:22 - is not
16:23 - in my defect count
16:25 - it goes that's fine and it just gives me
16:27 - back a zero
16:29 - if i try and access a number that does
16:31 - exist like an eight it'll look into the
16:33 - counter and go oh there's a 24 stored
16:35 - there and it'll give me back at 24.
16:37 - so this is kind of cool and we'll take
16:39 - advantage of that particular
16:41 - functionality in a second
16:43 - all right so i want to create a list of
16:45 - x values to go on the bottom of my chart
16:47 - and i want to see
16:49 - all of those y values that are in my
16:52 - defect count
16:54 - the 8 or the 24 and the 24 and those
16:56 - things
16:58 - and i want to store them in two separate
17:00 - lists so i can dump them into matplotlib
17:03 - so
17:04 - for those who haven't seen it this is a
17:06 - list comprehension syntax i'm not going
17:08 - to go into it but
17:11 - it's very useful for doing analysis
17:14 - i'm not going to talk about these these
17:16 - are all just the things that we use for
17:17 - matplotlib and it's going to take all of
17:20 - the x values
17:21 - that we just made and all of the y
17:23 - values that we made and it's going to
17:25 - plot them all right
17:26 - and so we get
17:29 - this nice little chart
17:32 - and a couple things that we can see
17:33 - right off the bat
17:34 - where are most of the things
17:40 - low end right
17:43 - there appear to be two little spikes
17:45 - do you guys remember what numbers those
17:47 - spikes were at what were the most common
17:49 - values
17:52 - six and eight
17:54 - right
17:55 - um when we looked at the data and i said
17:57 - hey i got this stuff kind of organized
17:59 - there was a big number at the front it
18:01 - was a 99 and sure enough we see there's
18:03 - a little spike over there by the 99
18:05 - turns out maybe that's an outlier
18:07 - maybe not right
18:09 - okay
18:11 - so this visually shows us a lot of cool
18:13 - things i want to figure out how do we
18:15 - get to some of these data points using
18:16 - code
18:20 - we'll start off with
18:22 - using count maximum and minimum
18:26 - what function do we use to count things
18:27 - in python
18:30 - len right stands for length
18:33 - so if i have number of defects and i
18:35 - drop it into the len function
18:38 - it will tell me that i have 204 data
18:40 - points and you can essentially count
18:41 - just about anything in python using len
18:44 - all right if i want to find the biggest
18:46 - value in a set or the smallest value set
18:48 - what what functions do i use
18:51 - max and min all right so let's do that
18:54 - let's take number defects we'll drop it
18:56 - into max drop it into min
18:58 - and we get that big value of 99 and our
19:01 - smallest value happen to be a two
19:03 - sweet
19:04 - all right
19:09 - a lot of statistics is basically telling
19:12 - you stuff about your data
19:15 - how many pieces of data do i have
19:17 - what is the highest thing what's the
19:19 - smallest thing
19:22 - one of the things that we often talk
19:24 - about like what's the average grade in a
19:25 - class or what's the average weight of
19:27 - people in doing this thing right what's
19:30 - the average of age of folks in a
19:31 - particular group
19:33 - python has tools to to look at that
19:36 - and when statisticians look at that kind
19:39 - of information they typically point to
19:41 - three main things
19:43 - mean median and mode
19:46 - mean is also often referred to as
19:48 - average and it's probably the one you're
19:50 - most commonly associated with
19:52 - so i'm going to walk you through how we
19:53 - can calculate means medians and modes
19:55 - using my lousy code
19:58 - all right
19:59 - so here we'll start off with calculating
20:01 - a mean
20:02 - if i drop a series of values into this
20:04 - particular function
20:05 - it will try and figure out a
20:08 - what is all of the a values added
20:10 - together and then it will divide it by
20:12 - how many values do we have
20:14 - okay
20:15 - so do that
20:17 - and
20:18 - so let's just use a really simple set of
20:20 - values these four things the average
20:22 - should be like two and a half
20:24 - if my math is right and if i do this one
20:27 - the average should be three right pretty
20:29 - straightforward
20:32 - anyone want to take a guess what the
20:33 - average is for
20:35 - our bigger data set
20:38 - any thoughts
20:43 - wow
20:46 - that's amazing well done
20:49 - all right
20:53 - all right
20:55 - now
20:56 - i'll show you in a little bit some other
20:57 - libraries that walk you through doing
20:59 - means and we'll talk about some of the
21:00 - benefits of using those all right but
21:02 - now i basically have an idea of kind of
21:06 - where is
21:07 - the average number and it's somewhere in
21:09 - here between 9 and 10. okay
21:12 - now let's go look at medians
21:15 - so median is a little interesting
21:17 - uh the point of medians is to find the
21:21 - center-most value
21:23 - if i've got 11 things it'll find
21:25 - whatever's at position six if i've got
21:27 - five things it'll find whatever is at
21:29 - position three right
21:30 - it doesn't really care if it's big
21:32 - little tiny whatever it just says you've
21:34 - got this number of things let me find
21:36 - whatever's stored in the center
21:39 - all right but there's a caveat
21:41 - if i have an odd number of things like 1
21:44 - 3 and 5 the 3 is clearly in the middle
21:47 - but if i have 1 3 5 and 7 what's in the
21:51 - middle
21:52 - and how we typically solve this is we
21:54 - take an average of whatever the two
21:55 - things are in the center and so my code
21:57 - will do that
22:01 - the nuance here is before you find
22:04 - whatever's in the middle you need to
22:05 - sort them so we're going to sort all the
22:07 - values we'll calculate how many values
22:10 - we have we'll figure out what is the
22:12 - midpoint
22:13 - and then we will return it if we find
22:17 - out that there are an even number of
22:18 - values we're going to do this thing
22:20 - where we
22:23 - we average we find out there's an odd
22:25 - number of values we just give you the
22:26 - center point
22:28 - all right so i'm not going to walk you
22:29 - through the code in too much detail you
22:31 - can take time to look at that if you
22:32 - want but let's just see if it works sure
22:34 - enough it gives me a 2.
22:36 - this one remember we have to sort first
22:39 - so it's going to move the 42 to the end
22:43 - and it'll find whatever's between the 5
22:45 - and 6 which is a 5.5
22:47 - all right
22:48 - and
22:50 - i know this guy's already done the math
22:52 - in his head right he knows what the
22:54 - number of median number defects it's an
22:56 - 8.
22:57 - okay
22:59 - so we can take an average which you're
23:01 - used to we can take the median find the
23:03 - middle most point
23:04 - mode
23:05 - finds whatever shows up most frequently
23:09 - all right
23:10 - for this library i'm also going to use
23:12 - counter to help us with this
23:14 - we're going to count all the values
23:16 - we will find whatever value shows up
23:19 - most frequently
23:21 - how many times it shows up
23:23 - and then we will go in using another
23:25 - list comprehension and if you're not
23:27 - familiar with these i highly recommend
23:28 - you go figure them out because they're
23:30 - really awesome
23:31 - we'll go and say all right the maximum
23:33 - number of things was 24 things showed up
23:35 - let's go see how many items showed up 24
23:38 - times and this list comprehension will
23:40 - give me every value that had 24 entries
23:43 - in my count
23:44 - so let's go take a look
23:46 - here
23:47 - the number four is going to show up
23:49 - three times so it will show up most
23:50 - frequently so we should get back a four
23:53 - um notice
23:55 - just a nuance here
23:56 - with mode i choosing to return a list of
23:59 - uh of items
24:02 - because sometimes
24:04 - certain things more than one thing may
24:05 - show up most frequently like this list
24:08 - one shows up three times five shows up
24:11 - three times so i want to get both of
24:12 - those back
24:14 - so it's going to return a list with both
24:16 - of the things that showed up most
24:17 - frequently
24:19 - the one and the five
24:21 - um
24:22 - just a nuance about that right
24:25 - we talk about kind of the average
24:27 - most the time in our heads we tend to
24:29 - think of there is only a single average
24:31 - when you start talking mode you can have
24:33 - bimodal or trimodal data sets where
24:36 - spikes of things occur
24:38 - there's a book that uh that i kind of
24:40 - like for folks who are new to statistics
24:43 - head first statistics and they talk
24:45 - about this ages for this group of folks
24:48 - in this class
24:49 - and it's a class for adults and children
24:52 - to do like swimming together or
24:54 - something i don't know
24:55 - and when you look at the ages the
24:57 - average ages you have these very young
24:59 - children and you have these older adults
25:02 - and so your average age is very
25:03 - different and it's split
25:05 - right so that's the thing that you'll
25:07 - see in many cases with mode
25:09 - all right so let's go look at the
25:11 - most frequent values in number of
25:13 - defects it was 8 and 6 just like we saw
25:15 - earlier
25:16 - all right
25:17 - so a couple of nuances of when we might
25:19 - use these and and some of the the
25:21 - benefits of using them i've got a little
25:23 - table here
25:24 - mean
25:25 - you do this sum of the values and you
25:27 - count how many values you have you do
25:28 - the math
25:30 - this is
25:32 - most commonly used when your data kind
25:34 - of has
25:35 - symmetry to it and it has a single trend
25:38 - one single spike
25:40 - the median is often used with data that
25:42 - might be skewed a little bit to one side
25:45 - or the other and might have some
25:47 - outliers it's kind of a way of of
25:49 - dealing with the fact that your outliers
25:51 - will throw off some of your results
25:54 - and then mode it's different from some
25:57 - of the others because you can actually
25:58 - use mode with things that are called
25:59 - categorical data and you'll hear that in
26:01 - statistics what categorical data means
26:04 - is it doesn't have a number value
26:06 - like if i had a list of data and the
26:08 - data just simply said
26:10 - male female or the data said you know
26:14 - part a part b part a part a part b part
26:17 - b those are all categories right and so
26:20 - modes can show us what is the most
26:21 - frequent part that showed up
26:23 - what is the most frequent
26:26 - examples of things and you don't have to
26:27 - have a number for them so categorical
26:29 - data can be done with modes
26:31 - and it's also good for things as we
26:33 - mentioned that have more than one trend
26:36 - all right
26:39 - we did a fancy histogram graph but
26:42 - sometimes just having a quick frequency
26:43 - table can be really useful
26:45 - and so a frequency table would be
26:48 - something like this
26:50 - where it shows hey the value 9 showed up
26:52 - 3 times the value 6 showed up twice
26:55 - it's much like that counter example we
26:56 - looked at
26:58 - if we look at
27:00 - our defect counts
27:04 - the frequency table is not specific to
27:06 - mode it is the counts of all your values
27:09 - mode is highlighting the things that
27:11 - show up most frequently the frequency
27:13 - table shows up the values of all of them
27:15 - notice
27:16 - where did it go
27:18 - in my frequency table it showed up that
27:19 - eight appeared only once where mode is
27:22 - going to show me the things that
27:23 - appeared most frequently mode would give
27:24 - me the value 9 showed up three times
27:27 - or would give me the value 8 and 6
27:29 - showed up 24 times does that help
27:32 - good
27:33 - all right
27:36 - so what i'd like you guys to do and i'm
27:37 - going to
27:38 - shrink this down
27:39 - give you guys a few moments to kind of
27:41 - start to wrap your head around some of
27:42 - these things
27:43 - um
27:44 - i'd like for you to calculate and you
27:46 - can use my functions if you'd like
27:47 - they're good enough for government work
27:49 - here
27:50 - and go through this calculate the mean
27:52 - the mode the median
27:54 - do a count on these things
27:55 - and go through the exercises and we'll
27:57 - give you guys a few minutes to do this
28:01 - i want to caveat this for just a moment
28:03 - though some people may not finish all
28:05 - the exercises in the time allotted
28:07 - that's totally fine
28:08 - go home re-read the material do the
28:10 - exercises again finish the exercises you
28:13 - didn't finish that's all good
28:16 - just a little back story here right
28:19 - and i'll show you my list of books that
28:21 - i've read i've read the statistics books
28:24 - of various sorts
28:25 - over and over again
28:27 - and even in the course of preparing this
28:29 - particular
28:30 - set of material
28:33 - last night in my hotel putting final
28:34 - touches on i was still picking up
28:36 - nuances that i had not seen before and
28:38 - still learning new facts and details
28:40 - that had kind of escaped me so there's a
28:42 - lot to cover as we get further on in
28:44 - this in this conversation so don't hand
28:46 - if you're like oh man i didn't get all
28:47 - of it i didn't capture it yeah i still
28:49 - go back and reread some of these books
28:50 - and catch nuances so all right
28:53 - um we'll give you guys probably about 10
28:54 - minutes or so
28:56 - and we'll wander around and ask answer
28:58 - questions
29:42 - uh
30:00 - again if you guys run into any snags
30:13 - is
31:10 - sure
31:11 - so
31:12 - when you have
31:14 - just one heavy
31:38 - some of your things
33:17 - notes
33:46 - all
33:50 - desiring right
37:14 - so i think it's been about 10 minutes
37:23 - all right
37:24 - the little microphone appears to be back
37:27 - all right
37:28 - i'm not going to do the entire exercise
37:29 - i'm just going to highlight one or two
37:31 - things
37:34 - so mean
37:36 - let's see grab some of these guys
37:40 - and
37:42 - say values
37:44 - right
37:45 - and this was a nuance that i think jeff
37:47 - had mentioned
37:52 - right
37:53 - if
37:54 - you have two commands in a single cell
37:58 - both of the commands will run but only
37:59 - the last command will display to the
38:02 - screen
38:03 - so if you wanted to
38:06 - have both of these display you have two
38:08 - options you could either put each of
38:09 - them mean and median in two separate
38:11 - cells that works fine that works fine
38:15 - or
38:16 - you can do some of that extra typing
38:18 - and you can put the word print in here
38:21 - for the first one
38:23 - and
38:24 - it will print
38:26 - and you can put median values
38:28 - so it will print the first one and then
38:30 - it will execute the second one
38:33 - notice we get a slightly different
38:35 - output
38:36 - print actually displays to the screen
38:39 - median values actually executes and is
38:43 - released as an output but that's a
38:45 - nuance
38:46 - all right
38:48 - so let's see
38:49 - let's talk about
38:51 - measures of dispersion
38:53 - how widely spread is your data is your
38:55 - data really tightly clustered or is your
38:57 - data just all over the map
39:00 - okay
39:01 - you will sometimes hear in statistical
39:03 - books about things like measures of
39:04 - variability how much does the data vary
39:06 - or measures of spread they all
39:08 - essentially mean the same thing
39:11 - a fast and dirty measure of
39:14 - spread is simply let's look at the
39:16 - minimum look at the max and see how far
39:18 - apart they are
39:19 - right and so that's what this does my
39:21 - data range function just says what's the
39:23 - max what's the min
39:24 - and divide or subtract one from the
39:27 - other and so with my little data set
39:29 - five three four two and one the smallest
39:32 - thing was a one the biggest thing was a
39:34 - five and the spread is four points
39:39 - notice with my batch defects the
39:42 - smallest value was a two the biggest was
39:43 - a 99 so my spread is 97. that's a lot
39:48 - remember that 99 is potentially even an
39:49 - outlier or something so here i can see
39:52 - that my data is really far away from the
39:54 - median and the mode and the mean right
39:57 - so this may be a flag or maybe something
39:59 - of interest
40:01 - it will depend on your data
40:04 - all right
40:05 - a couple of the downsides though of
40:06 - using simple spread are the fact that
40:09 - they are very susceptible to outliers
40:11 - here i have two data sets that are
40:12 - almost identical except for the last two
40:14 - values the 8 and the 99 you would
40:16 - probably say these these data sets are
40:18 - are pretty much the same
40:20 - and so when i have this one thing with
40:22 - this minor outlier man it throws
40:24 - everything completely out of whack
40:26 - and it makes it really hard for me to
40:28 - realize or to know that essentially
40:31 - these data sets are basically the same
40:34 - all right so how do we get past that
40:37 - that's where things called quantiles
40:40 - and interquartile ranges come into play
40:44 - let me zoom in on this just to smidge
40:46 - all right
40:47 - so you're going to hear some of these
40:48 - words
40:50 - these are the words that that really
40:51 - bothered me i never knew what they meant
40:52 - for a long time
40:53 - um
40:56 - a quantile
40:58 - is
40:58 - it's a cut point or a dividing point
41:00 - right in a sequence of values
41:04 - and those cut points will break those
41:05 - values up into what we call contiguous
41:08 - intervals or
41:09 - intervals that butt right up against
41:11 - each other so they have a nice
41:13 - continuous flow
41:14 - and
41:15 - those cut points are de defined
41:18 - essentially
41:19 - so that they break up all of your values
41:21 - into equal probabilities the stuff in
41:24 - this lower quantile has as much
41:26 - probability as appearing as the stuff in
41:27 - the middle et cetera et cetera
41:30 - quartiles
41:31 - are values that cut your data into
41:33 - quarters they are essentially a quantile
41:35 - that breaks things up into every 25
41:37 - percent
41:39 - an interquartile range
41:41 - is a range between
41:43 - your
41:44 - lower quartile and your upper quartile
41:46 - normally that's between 25 and 75
41:50 - although you might see them with
41:51 - different values
41:52 - all right so let's put this into
41:53 - practice and see what we got
41:55 - all right quantiles
41:57 - so again these are kind of these cut
41:58 - points
41:59 - um if i have six values and i've got a
42:01 - cut point in the middle
42:03 - it breaks my values into two sections
42:06 - that middle in our case would be the
42:08 - median
42:10 - if i have a lot more values i have a
42:13 - value 1 and 62 63 and 64 65 and 70. this
42:18 - breaks up my range of values into 10
42:20 - quantiles
42:22 - and potentially if i want to kind of
42:23 - weed out some of those outliers i could
42:26 - say i really only care about all the
42:27 - things that fit between this lower
42:30 - quantile and this upper quantile
42:33 - and so i kind of filter out whatever's
42:35 - on on each end and that gets rid of the
42:37 - one it gets rid of the 99
42:41 - all right so let's make a function that
42:42 - helps us calculate where a given
42:44 - quantile falls
42:48 - so i make this very simple function
42:50 - give it a handful of values
42:54 - and tell it where you'd like your your
42:55 - quantile to break
42:57 - and it will then figure out in a list of
43:00 - values or sequence of values where does
43:02 - that fall
43:03 - what is the index of that point and it
43:05 - allows you to get back a value from your
43:08 - list or your sequence
43:09 - again this is not robust code do not
43:11 - ever qualify this or use this in
43:13 - production but it's good enough for for
43:15 - what we need to do here
43:17 - all right so i've got a list of like
43:19 - school grades there's 10 values and i
43:21 - say hey i want to find
43:23 - the break point whatever is in the
43:25 - middle essentially
43:27 - trying to find a almost a median
43:29 - it sorts everything first
43:32 - 55 ends up at the bottom 96 at the top
43:35 - and then it roots through
43:37 - i'm going to caveat this right
43:39 - this code was not sophisticated enough
43:41 - to realize that if i have even numbers i
43:44 - should take an average between the two
43:45 - this is again just to give you guys a
43:47 - demo
43:49 - if i had
43:50 - an odd number of values 11 in this case
43:56 - we can use that as well but again it's
43:58 - not going to be very precise
44:00 - all right
44:02 - what if i want to find those quartiles
44:04 - the 25 value and the 75 value i take
44:08 - these grades and i say hey look for
44:10 - whatever grade is closest to 25
44:13 - of this sequence of values
44:16 - and give me whatever is closest to 75
44:19 - and so 67 is kind of the lower lower
44:21 - bound of the lower 25 percent of my
44:24 - students and 91 is kind of the upper
44:26 - bound of the
44:27 - upper 25 percent of my students
44:30 - now
44:34 - all
44:34 - right if i want to kind of see where my
44:38 - defects break out using a variety of
44:40 - percentiles
44:41 - like the lower 10 percent the lower
44:43 - quarter the upper quarter 90 95 and 99
44:48 - i can do that
44:49 - and so
44:50 - the value of 4 is right at the boundary
44:53 - of the lower 10 percent value of 6 is at
44:55 - the boundary of the lower 25
44:59 - we notice that value of 99
45:01 - is way above
45:03 - the 95 percentile
45:05 - okay
45:06 - so if i were to say i only want to see
45:08 - stuff between the 25 and 75 i filter out
45:11 - all the lower end stuff i filter out all
45:13 - the high-end stuff and this is a great
45:15 - way to kind of
45:16 - get a sense of what the middle of the
45:18 - pack looks like
45:19 - so let's do that
45:21 - we'll apply what we just created to to
45:24 - look at some interquartile ranges um
45:26 - commonly you'll see like 10 and 90 20
45:28 - and 80.
45:30 - depends on what you need
45:33 - in our case
45:34 - we'll have a lower quartile boundary an
45:36 - upper quartile boundary
45:38 - and
45:41 - i tell it hey here's the values we're
45:42 - going to give
45:43 - it's going to use my function quantile
45:45 - for a minute ago and say
45:47 - 75 is my default value 25 is my not
45:50 - default or my lower boundary
45:52 - and let's see how this works
45:55 - it says chalmer if you give me these 10
45:57 - values
45:58 - 3 is roughly around 25 percent of the
46:00 - way up and eight is roughly 75 percent
46:03 - of the way up
46:04 - all right
46:10 - if i want to then do that math and say
46:13 - how big a spread is this i just subtract
46:15 - one of them from the other
46:17 - and we see that
46:19 - 8 minus 3 is 5.
46:22 - so let's do that with my batch of
46:23 - defects
46:25 - and it says hey chalmer if i'm only
46:27 - looking at 25
46:28 - and 75
46:30 - your range of values was only six
46:33 - it's only a spread of six
46:35 - right
46:37 - now that function i created seems a
46:39 - little weak because it's built in it
46:41 - hardwired in 75 and 25.
46:44 - so let's
46:46 - build upon our function a little bit and
46:48 - let's give ourselves the option now
46:50 - of adding an upper bound of our own
46:52 - choosing in the lower bound of our own
46:54 - choosing okay
46:56 - and so i'm going to look at my number of
46:57 - defects but this time i want to look at
46:59 - everything from 10 percent all the way
47:01 - up to 90 percent i'm going to see how
47:03 - big a spread that is
47:05 - and here that spread is a little bit
47:07 - bigger a little bit wider all right
47:12 - so what are the downsides of using an
47:13 - interquartile range it seems like hey i
47:15 - can kind of filter out those those
47:17 - outliers that's good
47:21 - interquartile ranges
47:23 - they only tell you really the difference
47:25 - between a high value and a low value
47:31 - how far apart are they
47:32 - they don't really tell you how closely
47:35 - they
47:35 - are knit to things
47:37 - it doesn't tell you how frequently those
47:39 - high values occur or how frequently the
47:41 - low values occur
47:42 - versus how frequently the stuff in the
47:44 - middle occurs
47:46 - so we would theoretically want a method
47:48 - to more accurately measure variability
47:49 - and we'll look at that in a minute so
47:51 - we'll give you guys a break
47:53 - if people need to walk around stretch
47:54 - whatever you can do that as well
47:57 - spend a couple minutes here
47:59 - say five
48:01 - walk through calculating a simple spread
48:03 - calculating some quantiles
48:05 - and then calculate an inner quantile
48:07 - range for these numbers
48:08 - and of course i'll ask questions or i'll
48:10 - answer questions
48:11 - one nuance for this second one you guys
48:13 - should pay attention here
48:16 - we're going to use the range function to
48:19 - create a sequence of values from 200 all
48:21 - the way up to
48:22 - but not including 300. so if you've
48:24 - never used the range object to create a
48:26 - sequence of numbers for you
48:28 - we have that here this is how you would
48:30 - do it
48:31 - all right
48:33 - and we'll cut you loose
48:35 - when you're done put up your little
48:36 - green stickies if your green sticky is
48:38 - still up take it down
56:58 - all right
56:59 - let's get started
57:07 - awesome
57:08 - all right folks
57:26 - so if i want to bang out an
57:27 - inter-quartile range for
57:32 - all these guys i can say range
57:35 - 200
57:37 - to 300
57:39 - with a step of 5
57:42 - for those who are not familiar with the
57:43 - range function
57:45 - the second value that you put
57:47 - range will go all the way up to it but
57:48 - it will not include that value
57:51 - and this third number you can give the
57:53 - range function tells you what step to
57:54 - take
57:55 - and let's see to calculate my
57:57 - interquartile range i want a
57:59 - 0.25
58:02 - and a 0.75
58:04 - but those are the defaults
58:07 - so heck with it
58:09 - let's delete that and we should get back
58:11 - a 50.
58:13 - and that sounds about right because
58:14 - there's about 100 difference between the
58:16 - two
58:17 - all right
58:18 - so let's talk about something way more
58:19 - fun
58:21 - let's talk about variances in standard
58:22 - deviation
58:24 - all right
58:25 - so there's a couple of different
58:26 - techniques that we can use to evaluate
58:28 - the spread of data that's a bit more
58:30 - effective than simple interquartile
58:31 - ranges or simple spreads
58:34 - interquartile ranges is good for fast
58:36 - and dirty it's very nice but variance
58:38 - and standard deviation are
58:40 - one of the the workhorses for
58:42 - statistical evaluation um
58:45 - one thing that you may be tempted to say
58:47 - is well if i want to get kind of figure
58:49 - out how much things vary i could take
58:51 - the average of
58:52 - you know what is
58:56 - i take the average and i could subtract
58:57 - that from each of my values and i get
58:59 - this average difference from the mean
59:02 - and that may look like it'll work
59:04 - but what ends up happening is all of the
59:06 - things that are above your mean and all
59:08 - things that below your mean cancel out
59:10 - i'll let you guys read the details we're
59:11 - just going to skip right by that
59:13 - let's talk more about variances okay
59:16 - um
59:18 - with a variance we do something very
59:20 - similar
59:21 - we have
59:23 - an average
59:25 - and then we subtract
59:27 - the first value from the average the
59:29 - second value from the average the third
59:30 - value from the average
59:32 - and we square that
59:34 - to get some sequence of numbers
59:37 - the benefit of squaring which doesn't
59:40 - happen in that previous
59:42 - thing that i skimmed over is that these
59:44 - all end up being positive numbers now
59:46 - they can't cancel each other out because
59:48 - some are positive and some are negative
59:50 - and so in this case i have these three
59:52 - numbers
59:53 - one two and nine
59:55 - the average is a four
59:56 - i calculate what's called the variance
59:58 - and i get this number 38
60:01 - and that gives me some sense of
60:05 - how much or gives me a total 38 and then
60:07 - i divide it by 3 sorry math is hard i
60:10 - divide by 3 and i get a 12.6 so it gives
60:13 - me some sense of what the variance is
60:16 - and you may look in your head and you go
60:17 - i don't even understand what variance
60:19 - means because
60:20 - how did i get a 12.6 to tell me how much
60:23 - stuff spreads
60:25 - when my numbers don't even get up to 12.
60:29 - i have a one two and a nine and you're
60:30 - going to tell me quote unquote the
60:31 - variance is this 12.6 thing
60:35 - and so some of you are sitting there and
60:36 - you have this quizzical look on your
60:37 - face and that's the same critical look
60:39 - that everybody has which is why we go
60:42 - one step further we use a thing called
60:43 - standard deviation
60:46 - before i talk about standard deviation
60:48 - the nuance here though that you can get
60:50 - is if i were to change
60:53 - these numbers
60:54 - and spread them out a little further
60:56 - potentially my variance may get bigger
60:59 - my variance gets smaller so if i have
61:01 - two sets of data and one variance is
61:03 - large one variance is small
61:05 - the one with a larger variance is spread
61:08 - out more the one with the smaller
61:09 - variance is spread out less
61:11 - so the number itself may not jump out at
61:13 - you and you go that means something
61:15 - but numbers or variances from separate
61:18 - data sets can give you a sense of one
61:20 - spreads out more than the other
61:22 - but again variance is kind of this
61:24 - nuanced thing like people like i don't
61:25 - even know what that means
61:27 - so
61:28 - we'll we'll do a function we'll look at
61:29 - this happening and working and then
61:31 - we'll move on to standard deviations
61:33 - all right
61:34 - so
61:35 - i calculate
61:37 - this by using
61:39 - the total number of values i have a
61:41 - function that calculates the difference
61:43 - between the means i square them i will
61:45 - let you guys do this again this is not
61:47 - production code this is chalmers sitting
61:49 - in a hotel room
61:50 - um all right
61:53 - well let's try and detect or determine
61:55 - what the number the variance is for our
61:56 - number of defects and we need some
61:58 - bizarre number
62:00 - our variance is 80 and again that means
62:02 - nothing to me right i don't have a sense
62:04 - for what that means
62:08 - because no one gets a sense some folks
62:10 - thought this through and they're like
62:12 - is there maybe a better way and standard
62:14 - deviation is a potentially better way
62:16 - and i'll show you some examples of why
62:18 - to get the standard deviation you
62:19 - calculate the variance and then all you
62:21 - do is you take the square root of it
62:23 - it's pretty straightforward
62:25 - so i calculate the variance
62:28 - same way i get 38 divide that by the
62:31 - total number of items i get a 12.6 and i
62:34 - take the square root of that and i get
62:35 - 3.55
62:37 - and again you kind of may be saying in
62:38 - your head i don't understand what that
62:39 - means
62:41 - the nuance is that as your standard
62:43 - deviation gets bigger
62:44 - it means it spreads more as it gets
62:46 - smaller it spreads less but
62:49 - we'll see some graphs related to this
62:50 - later that standard deviation
62:53 - fits very nicely on your graphs in a way
62:55 - that helps you to get a good sense of
62:57 - how things play out
62:59 - all right
63:04 - when we use data sets and we calculate a
63:06 - standard deviation
63:11 - one thing that they have found is that
63:13 - on a typical kind of bell-shaped
63:15 - distribution a normal distribution
63:17 - and a lot of data tends to fall into
63:19 - that category
63:20 - if i calculate the standard deviation
63:23 - kind of how wide is the spread away from
63:25 - the mean
63:27 - 65 percent of all of my values are going
63:30 - to be within one standard deviation of
63:32 - my mean
63:33 - 95 percent of all my values are going to
63:35 - be within two standard deviations
63:37 - and 99 will be within three standard
63:40 - deviations so let me shrink this down
63:42 - just a smidge
63:43 - so we can see this all on the screen
63:45 - there all right
63:47 - so
63:48 - i have an average i have a mean in the
63:50 - middle i've got some sort of bell
63:52 - shapish curve
63:54 - and if i can calculate my standard
63:56 - deviation
63:57 - right here
63:58 - standard deviation
64:00 - above the mean and one standard
64:01 - deviation below the mean everything in
64:03 - this gap is going to be 65 of all of my
64:06 - numbers
64:07 - will fall right there in that that
64:09 - middle zone
64:11 - if i stretch out two standard deviations
64:13 - above the mean and two standard
64:14 - deviations below the mean
64:16 - 95 of every one of my numbers is going
64:19 - to fit nicely in that little that little
64:21 - grouping
64:22 - and
64:23 - if i calculate out three standard
64:24 - deviations 99 of stuff say well how do i
64:27 - use this what does this mean
64:29 - well much like we use the interquartile
64:31 - range to say let's drop all the values
64:33 - that are 25 percent or below all the
64:35 - values that are 75 or below or above
64:38 - we can use standard deviations to say i
64:41 - only want to see
64:43 - the 99 of the values that are closest to
64:45 - the mean and any of these little
64:46 - outliers that are way out there in the
64:48 - far corners let's ditch those
64:51 - or i really want to get kind of a little
64:53 - closer and i want to see 95 of my values
64:56 - that are closest to the mean and so
64:58 - standard deviations can help us
65:01 - grab those when we're using something
65:03 - like a normal distribution
65:04 - this may not apply with other
65:06 - distributions but it works quite nicely
65:07 - with normal distributions these
65:09 - bell-shaped curves
65:10 - all right
65:14 - let's see
65:16 - this first picture kind of spiky
65:19 - the data is fairly closely clustered on
65:21 - the average
65:23 - this next picture a little less spiky
65:28 - it's a little wider
65:30 - and in this case because the graph is a
65:32 - little less spiky
65:34 - my standard deviation happens to be
65:35 - bigger
65:36 - and so remember i mentioned that like if
65:38 - you're looking at two different data
65:39 - sets and a standard deviation is bigger
65:41 - it means that data set spreads out more
65:44 - and so because this spreads out more my
65:46 - standard deviation is bigger but the
65:48 - same rule applies even though this
65:49 - spreads out more if i want to get 99 of
65:52 - all my numbers and drop off the one
65:54 - percent outliers i measure out three
65:57 - standard deviations and boom i've got
65:59 - the 99 that i care about
66:02 - okay
66:04 - all right so i've got a fairly
66:06 - straightforward
66:08 - and let me make sure i ran the variance
66:10 - formula earlier
66:12 - let's see
66:15 - so i got a fairly straightforward
66:17 - standard deviation calculation here
66:20 - it uses my variance function that i
66:22 - created earlier
66:24 - does the math
66:26 - i have a fairly narrow data set all the
66:29 - stuff's pretty close together the mean
66:31 - is five we have another one that's a
66:33 - little bit broader it goes from one to
66:35 - nine but the mean is also still five
66:39 - and so let's look at how these two
66:41 - things calculate out
66:43 - the mean is five
66:45 - my standard deviation was 1.4
66:48 - this is a little bit broader data set
66:50 - still has the same average but my
66:52 - standard deviation is a bit bigger so
66:54 - now i can immediately go this one is a
66:57 - flatter bell than this one potentially
66:59 - right
67:01 - all things being equal
67:04 - okay
67:06 - how do you interpret that
67:09 - what does it mean
67:11 - all right
67:13 - the nuance here essentially is that
67:18 - when you're looking at your data and you
67:20 - want to kind of know
67:22 - i have an average
67:24 - how much does stuff spread out on one
67:26 - side or the other or both the standard
67:28 - deviation is going to
67:30 - point you in the right direction to say
67:32 - this is really close to the mean
67:34 - or these are very far from the mean
67:38 - and so in this case
67:40 - you know my numbers start at three they
67:42 - go to seven they're all really tightly
67:44 - clustered around the mean this one
67:46 - starts at one it goes up to nine they're
67:48 - spread further out i can immediately
67:50 - tell that there's a bigger spread
67:51 - between two data sets
67:53 - just looking at one data set and knowing
67:55 - that okay the standard deviation is 1.4
67:58 - may not tell me a lot about that one
67:59 - data set
68:02 - but being able to compare them is really
68:04 - useful
68:06 - another thing you know as that number
68:08 - gets smaller and smaller it means your
68:09 - your
68:10 - your spike is a little spikier right
68:12 - things are narrower things are closer
68:16 - uh
68:17 - and a key role for the standard
68:19 - deviation again is kind of helping you
68:21 - figure out how do i get rid of some of
68:22 - those outliers
68:24 - how do i look at my data set and say i
68:26 - only want to see the stuff that's
68:29 - from like one percent all the way up to
68:31 - 99 and not look at the things outside of
68:33 - it or
68:35 - where should my cut points be to look at
68:37 - just the 95 percent where should my cut
68:39 - points be look at just 65 percent of the
68:41 - data
68:42 - and so standard deviation can help you
68:43 - with that
68:45 - all right
68:47 - did that help
68:49 - good
68:54 - let's talk about how real pythonistas
68:57 - calculate standard deviations and
68:58 - variances and those types of things
69:00 - using real python libraries instead of
69:02 - my
69:03 - hotel code
69:05 - okay
69:06 - we're going to look quickly at four
69:07 - different libraries
69:09 - and
69:10 - i will highlight a gotcha
69:14 - that may strike if you do not pay
69:16 - attention and if you don't kind of dive
69:17 - into the nuts and bolts so the four
69:20 - libraries we're going to look at there
69:21 - is a statistics library this is brand
69:23 - new in python as a version 3.4
69:27 - it incorporates a sequence of
69:29 - statistical functions
69:32 - and it comes with python so if you
69:34 - download python all by itself you've got
69:35 - it you don't need to get any third-party
69:37 - libraries which is quite nice
69:40 - we'll look at numpy
69:41 - numpy allows you to build
69:44 - these array objects and allows you to do
69:47 - various fist calculations on these types
69:49 - of objects that are very fast
69:53 - as techniques and tools for integrating
69:54 - c and c plus plus libraries and fortran
69:57 - code again to get closer to the bare
69:59 - metal and make your code more efficient
70:00 - and more
70:02 - faster
70:03 - it has techniques to be able to
70:05 - broadcast
70:09 - calculations and evaluations against
70:11 - large arrays of data
70:13 - without having to write for loops and
70:15 - stuff
70:17 - and it's useful for like linear algebra
70:18 - and those types of things
70:21 - scipy library
70:23 - has a collection of mathematical
70:25 - algorithms it's got some convenience
70:26 - functions that are built on top of numpy
70:28 - because it uses numpy under the hood
70:30 - adds a lot of power to your python
70:32 - sessions
70:34 - and then we'll look at pandas which is a
70:35 - common data science
70:37 - library does data analysis and those
70:39 - types of things all right
70:42 - so we'll start off by importing each of
70:44 - these
70:45 - for some of these libraries it's fairly
70:46 - common to import them with an alias like
70:48 - import numpy as np it makes it easier to
70:51 - type some of the commands you might want
70:53 - to use later
70:54 - all right
70:56 - i'm going to start off by creating a
70:57 - simple numpy array
70:59 - and we're going to use my defects batch
71:02 - file okay
71:03 - [Music]
71:05 - one of the things that i often mentioned
71:07 - to students
71:08 - who are using a new tool a new library
71:10 - and they're making new data types
71:13 - i often recommend to them that they do a
71:15 - couple of things
71:17 - when you make a new object often tell
71:18 - them
71:19 - go find out what the heck this thing is
71:21 - that you just made
71:22 - and so i say hey what is defects
71:25 - and it says hey chalmer defects is a
71:27 - numpy array
71:29 - and
71:31 - if i've never used a numpy array i maybe
71:34 - need to figure out what that means if it
71:36 - spat out and said hey chalmer you just
71:37 - made a list i'm pretty familiar with
71:39 - lists
71:40 - because this is a numpy array and i
71:42 - don't really know a lot about what numpy
71:44 - rays right
71:45 - i might want to try and get a sense of
71:47 - what types of functions or methods are
71:49 - available to me so we're going to use a
71:51 - technique called tab completion
71:53 - and this is really useful in jupiter
71:54 - notebooks
71:56 - i type out defects i put a dot
71:58 - and i hit tab
71:59 - and it brings up this list of all the
72:01 - types of methods and functions that are
72:03 - available to me
72:05 - all right
72:06 - there we go
72:08 - nothing like moving your laptop in the
72:10 - middle of a talk
72:12 - okay
72:13 - um
72:14 - notice this is in alphabetical order
72:16 - right so it says things like all and any
72:18 - and da da da and there now we're going
72:20 - to the b's and the c's and the d's and
72:24 - this is a huge list of things
72:26 - that you if you are mathematically and
72:28 - statistically minded can do with a numpy
72:30 - array you can't do these with lists etc
72:33 - um we are not going to go into the
72:35 - depths of this i'm just going to kind of
72:36 - scroll through
72:38 - get a sense there's a lot of things here
72:41 - notice they do have a method in here
72:43 - called std
72:45 - short for standard deviation
72:47 - they have a method called var which is
72:49 - standard for vary or short for variance
72:51 - all right
72:54 - i'm going to start off simple and i'm
72:55 - going to say hey let's use the mean
72:56 - function
72:57 - and so we'll calculate mean
72:59 - and sure enough the average is 9.96 as
73:01 - this fine gentleman mentioned earlier
73:06 - a wheel caveat there is no median
73:08 - function associated with an numpy array
73:12 - the numpy library has a median function
73:15 - and you can drop your array into the
73:18 - median function but there is no median
73:20 - function that hangs off of your array
73:22 - which i found very interesting as i was
73:24 - researching this
73:25 - um so we say give me the the median and
73:28 - sure enough it spits out an 8 and that's
73:30 - quite nice
73:31 - if i want to look up the variance and
73:33 - the standard deviation without using
73:34 - chalmers crappy code we get an 80.8 and
73:37 - we get an 8.9
73:39 - awesome
73:42 - let's turn to scipy
73:44 - i'm going to run all four of those mean
73:46 - median var and standard deviation
73:49 - um
73:51 - we get 9.96 we get an 8.0 80.8 and 8.9
73:56 - looks good
73:58 - one thing you should know as i mentioned
74:00 - sci-fi kind of rides right on top of
74:02 - numpy
74:03 - so if i go in here and i say
74:06 - i like this numpy mean method but i'm
74:09 - not real sure how it works i'd like to
74:11 - know more about it you can ask this
74:12 - question mark and you put the question
74:15 - mark in there and they'll give you the
74:16 - help file for it so look at that
74:19 - and now we have access to
74:21 - all of the
74:23 - arguments that i can give it i give it
74:24 - my array and if i want to do certain
74:26 - things i can have it change its behavior
74:30 - i don't know what any of these mean
74:32 - right axis d type what is all of that
74:34 - well i can scroll through and it will
74:36 - define for me oh here's what axis means
74:38 - and here's what d type means and so i
74:40 - can figure some of those things out
74:42 - tells me what it gives me back it says
74:44 - i'm going to give you back
74:46 - this that or the other and you can kind
74:47 - of get some sense of what's going on
74:49 - might give you some notes as to other
74:51 - things you might want to look at
74:53 - to see if other types of calculations
74:55 - might be useful to you that's cool
75:00 - happens to be really nice and give you
75:01 - some sample code
75:03 - if you tried to get it to work and it
75:05 - failed maybe you look at the sample code
75:06 - and it helps you out that way
75:09 - all right
75:10 - gives you some caveats in certain cases
75:13 - this might be slightly inaccurate buyer
75:15 - beware
75:17 - okay
75:18 - it tells you where it pulled it from and
75:20 - it said hey you know what
75:21 - we got this out of the numpy library and
75:24 - it's from this thing called
75:25 - fromnumeric.pi which is awesome
75:28 - if i were to do this same thing with
75:29 - scipy.mean
75:31 - we see
75:32 - i can call psi pi.mean
75:35 - but
75:36 - interestingly enough all the
75:38 - documentation is exactly the same and
75:40 - when i get down to the bottom
75:41 - sure enough it actually just calls numpy
75:43 - under the hood so
75:45 - um
75:46 - like i said your mileage may vary okay
75:50 - the statistics library
75:52 - statistics library has mean median
75:55 - variance and standard deviation
75:57 - notice the spelling is different
76:00 - right they actually call it variance
76:01 - instead of r they call it stdev instead
76:05 - of std
76:07 - all right
76:08 - and if i run that
76:11 - what's wrong
76:15 - my numbers are different
76:17 - in particular which two numbers are
76:18 - different
76:21 - the variance and the standard deviation
76:23 - here are not the same as the ones we saw
76:24 - before so let's go take a look
76:27 - 81.2 and 90.0
76:30 - oh there's a lot of stuff here
76:32 - and we had 80.8 and 80.9 8.9 so they're
76:37 - different
76:39 - all right
76:41 - why
76:42 - anyone know why
76:48 - yes
76:50 - he mentions there's a difference between
76:51 - population variance or population
76:53 - standard deviation and sample variance
76:56 - or sample standard deviation
76:58 - all right so now that our heads explode
77:00 - let's go take a look at what that means
77:04 - when you calculate a what's called a
77:06 - population standard deviation
77:08 - you are looking at
77:11 - the amount of dispersion for an entire
77:12 - population and we use a particular
77:15 - formula for that
77:17 - this formula
77:19 - we take
77:21 - the difference from the mean for every
77:23 - one of our values
77:25 - take the square
77:26 - we divide by n
77:29 - and we
77:30 - then take the square root so n is this
77:33 - denominator
77:35 - and in this case for population standard
77:37 - deviation the n is a larger denominator
77:40 - than the next example we'll look at
77:42 - all right and for your convenience and
77:44 - later reading i spell out what each of
77:45 - the symbols is and why they're there
77:47 - let's go look at a sample standard
77:49 - deviation
77:50 - a sample standard deviation is just a
77:52 - sample that estimates
77:54 - what your deviation for a bigger
77:56 - population should be
77:58 - if we take a random sample out of that
78:00 - bigger population
78:01 - and it uses a slightly different var
78:04 - value as the denominator
78:07 - and minus 1. because n minus 1 is
78:10 - smaller than n
78:12 - the size of this standard deviation
78:14 - tends to be a little bigger than
78:17 - for populations
78:19 - all right
78:21 - so when do we use population versus
78:23 - sample
78:26 - we tend to use the population when we
78:28 - know the entire population we have all
78:30 - of the data in our hands we use the
78:32 - sample version if we are looking at a
78:34 - subset of a much bigger
78:36 - group of folks so if i'm a teacher and i
78:38 - have 25 students and i have all 25
78:41 - grades
78:42 - i can use the population because i know
78:44 - everybody's grades
78:46 - if
78:47 - i am looking potentially at
78:50 - my students grades as some sort of a
78:52 - sample of the grades across the school
78:54 - or across the school district i don't
78:56 - have all the grades for the larger
78:58 - population i just have my sample so i
79:00 - have to use the sample standard
79:01 - deviation
79:03 - all right
79:04 - another example if i'm a researcher and
79:07 - i'm looking at the relationship between
79:08 - women exercise and blood pressure right
79:11 - i might use a sample standard deviation
79:13 - because i only have a subset of folks
79:15 - that i
79:16 - polled or surveyed or researched on i
79:18 - don't have all the folks in the world
79:20 - right
79:21 - okay so that's why we have this
79:23 - difference because that silly
79:25 - denominator at the bottom is off by a
79:27 - smidge because we're either looking at a
79:29 - sample or looking at a population all
79:31 - right
79:32 - the numbers are typically very very
79:34 - close together
79:37 - if you're doing comparisons one to
79:39 - another but you use the same formula
79:41 - your comparisons will give you an order
79:42 - of magnitude
79:44 - difference
79:45 - all right
79:47 - if you were in a competition like a data
79:48 - science competition and you need to have
79:50 - the right answer you may want to choose
79:52 - the right function
79:54 - all right
79:55 - so let's go look at one last example
79:57 - this is the pandas library and it has
80:00 - mean median var standard deviation
80:02 - notice they went back to this kind of
80:04 - spelling of var and std
80:06 - let's run these guys
80:09 - it uses that same version
80:12 - of variance and standard deviation that
80:14 - the statistics library did okay all
80:18 - right so just a nuance be aware that it
80:19 - happens
80:23 - oh sweet
80:25 - for those who don't know
80:27 - pandas in this library allows you to
80:29 - create a set of data
80:31 - and
80:34 - i take a list i drop it into this series
80:36 - function
80:38 - and i ask python
80:39 - what do i get back pd
80:42 - i say hey you have a series and you go
80:44 - okay so what is a series
80:45 - a series essentially is a column
80:49 - in a data set you can imagine a series
80:51 - being like a column in an excel
80:53 - spreadsheet
80:54 - so it takes this list of things and
80:55 - throws it into a column you say what
80:57 - does that look like in real world
81:00 - defects pd
81:03 - printed out
81:04 - and so it says hey row 0 had a 99 in it
81:08 - row 1 had a 52 row 2 had a 42 and it's
81:11 - got all 204
81:13 - pieces of data
81:15 - this is not a pandas class but
81:18 - with a panda series you've got all sorts
81:20 - of capabilities like you can do
81:22 - aggregations and you can do groupings
81:24 - and you can calculate means and medians
81:26 - and all sorts of other things there's
81:28 - about 224 different types of things you
81:31 - can do to a panda series to help you do
81:33 - your data analysis you can break it up
81:35 - by quantiles they have a whole library
81:37 - for helping you with a whole module for
81:38 - helping with quantiles and stuff
81:40 - it's a lot of cool things
81:42 - all right did that help
81:46 - okay
81:47 - two more questions go
81:49 - how
81:59 - um
82:10 - so what if your data set for example
82:12 - doesn't fall into kind of a nice normal
82:14 - bell-shaped curve
82:15 - all right
82:18 - so that's that's a really good question
82:20 - that i do not know the answer to of how
82:22 - well your data needs to fit in in the
82:24 - normal the normal distribution for that
82:26 - to work well
82:27 - um
82:28 - i don't know if alan has any insight
82:30 - into that the question essentially is
82:33 - yeah
82:34 - there's there's lots of curves but the
82:36 - question was when you have a data set if
82:39 - it's not necessarily a nice bell curve
82:41 - and i try and do a standard deviation
82:44 - how easy is it to basically shoot myself
82:46 - in the foot right if if my data doesn't
82:48 - fit a normal curve is my standard
82:49 - deviation just going to give me really
82:51 - wonky answers
83:09 - sure
83:20 - so
83:22 - that is one of those nuances that
83:24 - regularly using
83:26 - these tools and reading about it again
83:29 - this is a three-hour class right right
83:31 - diving into this um
83:33 - one of the great things that you'll see
83:35 - when you start looking at research
83:36 - papers where people are using statistics
83:38 - to prove a point is they use statistics
83:41 - incorrectly
83:43 - and the point they're trying to prove is
83:45 - not what the data really shows right and
83:47 - it's not because necessarily that
83:50 - they're being malicious just because
83:51 - they're trying to apply a thing you know
83:53 - round peg into a square hole kind of a
83:55 - thing and that just doesn't work
83:57 - so it takes time it takes effort to dive
83:59 - into this research it figure it out i
84:02 - will show you
84:03 - some of the things that are available to
84:04 - us in some of the tools like scipy and
84:07 - just it is mind-blowing the number of
84:09 - options that we have available to us and
84:11 - so that would play into kind of your
84:13 - question
84:15 - yeah you had a question too
84:29 - all right so if a standard deviation is
84:31 - larger
84:32 - it tends to be
84:34 - sample if it is smaller use population
84:37 - so let's go back and look
84:40 - right
84:42 - well if i if i dump the same data set
84:45 - and i'm going to let me get rid of this
84:46 - guy clear output
84:48 - if i have the exact same data set which
84:51 - i do i i'm using num defects and i drop
84:54 - it into scipy
84:55 - i get a slightly smaller value
84:58 - than i got
85:00 - when i
85:04 - put it into
85:06 - the statistics library
85:08 - so
85:08 - a smaller value
85:11 - means a library is using population
85:13 - standard deviation a larger value means
85:15 - as being sample but having said all that
85:17 - there are ways to tell the library to do
85:19 - the thing that you want so let's take a
85:20 - quick look at that
85:21 - all right
85:27 - okay so
85:28 - [Music]
85:30 - psi pi dot
86:00 - in the scipy library for standard
86:02 - deviation they have a thing called this
86:05 - delta degrees of freedom and it
86:08 - identifies the divisor that you want to
86:10 - use
86:11 - and so you can have n minus something
86:13 - and then the normal is n minus one right
86:16 - the default that they use is zero so if
86:18 - i needed
86:19 - psi pi to do
86:21 - the reverse of what it normally does i
86:23 - can simply go into the function and i
86:26 - can set this
86:28 - degrees of freedom to be 1 versus 0
86:30 - which is the default
86:32 - all right so again it's just a matter of
86:33 - you need to know that it's there you
86:35 - need to know it's kind of a problem that
86:36 - you have to kind of answer
86:38 - um
86:41 - so all right let's see what else we got
86:43 - um
86:44 - i think in the interest of time holy cow
86:48 - how did the day go by this quickly we're
86:50 - going to skip the exercises
86:52 - here's a list of cool books
86:55 - and i start from
86:57 - the lower end of the scale to the higher
86:59 - end of the scale my first book i ever
87:01 - read on stats outside of high school was
87:03 - this cartoon guide uh it was a low
87:06 - pressure guide to statistics it covers
87:09 - way more than we're going to cover in
87:10 - these three hours the manga guide i got
87:12 - from my kid he liked it
87:14 - head first statistics by o'reilly
87:17 - is a book that um
87:20 - spells things out in a way that i find
87:22 - to be really really uh useful
87:24 - naked statistics is a little less about
87:28 - how one does it and the maths and more
87:30 - about oh my gosh how do you not do it
87:33 - wrong
87:34 - um and he talks about a lot of good kind
87:36 - of case studies and examples of people
87:38 - using statistics in the pros and cons
87:40 - he's very light on the math more on the
87:42 - this is awesome statistic-ness so this
87:44 - is a great read statistics in a nutshell
87:47 - that's fairly dense
87:49 - it's a good reference book
87:51 - i like it because it puts all the stuff
87:52 - in a small amount of space
87:54 - but i found that
87:56 - had i read it before i read maybe head
87:58 - first or even the manga guide that might
88:00 - have been a little too intense for me
88:03 - i think stats think python and think
88:05 - bays are great and for those who don't
88:07 - know
88:08 - that guy over there
88:10 - he wrote them
88:12 - and
88:14 - this one um
88:17 - is a little wonky and if you go to
88:18 - amazon and you look at the cover of this
88:20 - you're like oh my gosh
88:21 - but it is very compact and it spells out
88:24 - a thing called bayes theorem and it
88:26 - spells it out in a way that's kind of
88:27 - visual and it was quite nice
88:30 - all right
88:31 - and for the record
88:32 - uh mr allen
88:34 - uh
88:35 - who literally wrote the book yesterday
88:37 - we're talking he's like hey do you want
88:38 - a mentor in your class
88:39 - and i'm like yes
88:43 - okay
88:44 - so he's judging me by the way
88:46 - all right thanks
88:48 - um
88:50 - so let's move on to the next thing and
88:52 - let's cover this let's go through this
88:55 - we're going to shift gears
88:57 - we're going to talk about probability
88:58 - now the likelihood of something happen
89:04 - we're going to
89:05 - figure out how we can calculate the
89:06 - probability of something happening
89:09 - we will
89:10 - explore probabilities using what we call
89:12 - venn diagrams
89:14 - we'll explore probabilities using
89:15 - probability trees
89:17 - and we will talk about the principles
89:18 - behind the law of total probability and
89:21 - behind bayes theorem and we'll see a
89:22 - couple of examples of that
89:25 - all right
89:26 - uh i like the definition from sarah in
89:29 - statistics in a nutshell probability
89:31 - tells us how often something is likely
89:33 - to occur
89:34 - if we repeat an experiment right
89:38 - so let's expand our understanding of
89:40 - probability with a couple of definitions
89:43 - you'll hear reference such a thing
89:44 - called trials or experiments or
89:46 - observations
89:48 - a trial is some event
89:50 - where you don't yet know the outcome
89:53 - trials can be crazy easy i'm going to
89:55 - flip a coin i'm going to roll a dice or
89:58 - it could be
90:00 - someone has a low birth weight
90:03 - will they
90:05 - graduate from college 22 years later
90:08 - right
90:11 - sample space
90:12 - is essentially all of the possible
90:15 - outcomes of a trial so i have a six
90:17 - sided die
90:18 - i roll it all the possible outcomes are
90:21 - one two three four five and six
90:25 - say i drop four coins in a bag
90:27 - i've got a quarter a dime nickel and a
90:29 - penny if i draw one of those out my
90:31 - sample space will be quarter dime nickel
90:33 - and penny
90:35 - an event is the actual outcome of a
90:38 - trial
90:40 - events could essentially be singles or
90:42 - could be groups of things we will often
90:45 - designate an exam an event with an e
90:48 - so
90:49 - if i roll a die
90:51 - and
90:53 - my event is that i get a one on my die
90:56 - e would be this set with one in it
91:00 - if i want to specify that
91:03 - um
91:04 - my event is that i get an even number
91:07 - my e would be a 2 a 4 or a 6 when i roll
91:10 - that die so you can have more than one
91:11 - thing in your event
91:14 - now if i'm going to calculate a
91:15 - probability this is pretty
91:16 - straightforward
91:17 - i take how many elements are in my event
91:21 - divide that by how many elements are in
91:22 - the sample space and i get the
91:24 - probability
91:26 - so the probability of rolling a one on a
91:28 - six-sided die
91:29 - is one divided by six
91:32 - and that math turns out to be like
91:35 - 0.16 or something
91:38 - so let's throw together a pretty
91:39 - straightforward
91:42 - function that'll help us do this
91:44 - for those who do not play d and d in
91:46 - those types of games a d6 means that
91:48 - your die has six sides a d8 means it has
91:51 - eight sides
91:52 - so let's make a real quick function that
91:55 - returns a one on a d6 and so i would
91:58 - calculate 1 divided by 6
92:01 - and i get back sure enough
92:04 - to do
92:06 - 0.16
92:07 - and that's crazy limited you would never
92:09 - want to write multiple functions
92:11 - for every single case so maybe we want
92:13 - to expand this a little bit make our
92:14 - probability function
92:18 - better able to handle a large sample
92:20 - size
92:21 - or better able to handle an event
92:24 - so i set my count to be one
92:27 - and i divide it by the sample size
92:32 - all right so if my event was i roll a
92:34 - four on a six sided die the probability
92:37 - of a four showing up is this the astute
92:40 - observer though goes wait wait chalmer
92:43 - we dumped in event but we never actually
92:45 - used it that's screwy let's go fix that
92:48 - all right
92:51 - if my event is composed of more than one
92:54 - thing
92:55 - i want to determine if i get a 2 a 4 or
92:57 - a 6.
92:59 - we need to have a way to determine that
93:04 - all right
93:05 - so i'm going to make a small list
93:08 - let's say my event is i roll less than a
93:11 - four i roll one two or three on my die
93:14 - um
93:15 - i start off with saying hey let me check
93:17 - did chalmer just give me a list or a
93:18 - tuple or did it give me a single value
93:20 - if he gave me a list we'll count how
93:22 - many events are in it one two three
93:24 - and we'll use that to do the math
93:26 - if he gives me a single item then we'll
93:28 - just call it one it's all good
93:31 - all right so
93:32 - one thing that we often do in in python
93:34 - is alias things maybe give them shorter
93:37 - names i do not want to type probability
93:39 - a lot so
93:40 - i'm going to give that function a new
93:42 - name called p so it'll make it easier to
93:45 - type stuff
93:46 - so if i have a six sided die i have six
93:48 - items in my sample space and i'm looking
93:51 - for a two
93:54 - the probability is point one six
93:58 - on the other hand if i'm curious like
94:01 - what what is the probability of getting
94:02 - a four five or a six
94:05 - out of a sample space with six items
94:09 - that's one half
94:13 - all right
94:14 - if i'm looking for odd numbers on a six
94:17 - sided die one three and five
94:20 - again i have a 50 chance of getting an
94:22 - odd number
94:28 - alrighty
94:32 - out how many items are in a six-sided
94:34 - die is pretty straightforward
94:36 - but when things start to get a little
94:37 - more complicated
94:39 - that's where venn diagrams come in and
94:40 - you guys have probably all seen these
94:43 - we use these to represent elements in
94:45 - your sample space using very simple
94:48 - pictures
94:50 - so i'm going to show you a
94:50 - representation of rolling the odd
94:52 - numbers on a d10
94:57 - all right
94:58 - so i've got a d10
95:01 - it is fairly common in venn diagram land
95:03 - to put some sort of a rectangle in that
95:05 - rectangle represents all the possible
95:07 - values that you could have
95:09 - it is also fairly common to draw some
95:11 - sort of an oval or something or a circle
95:13 - to show the things that you really care
95:14 - about and in this case i only care about
95:16 - odd numbers and i go ahead and i label
95:19 - those one three five seven and nine
95:21 - um
95:23 - i meticulously went ahead and said
95:25 - everything outside of that oval is all
95:27 - the other stuff
95:28 - i do that for clarity but most the time
95:31 - we don't bother right
95:33 - it is presumed or assumed that
95:35 - everything in the rectangle is all the
95:36 - other stuff if i need more than one oval
95:40 - to represent two kind of related
95:42 - events that i care about i can put more
95:44 - than one over we'll see that in a bit
95:46 - um make sure to miss any of the things
95:49 - okay
95:55 - i'm going to have you guys go through
95:57 - your little notebooks etc
95:59 - um
96:00 - sketch out a couple of simple venn
96:02 - diagrams you don't have to make them
96:03 - huge or anything
96:05 - start wrap your head around this idea
96:08 - so this first one for example we're
96:10 - going to have one thing that we care
96:11 - about out of a list of 20 items on a d
96:15 - 20.
96:16 - and then i would like you to do is put
96:19 - together some python code that
96:20 - calculates the probability of getting 1
96:22 - on a d20 this next event is a little
96:25 - bigger i'm looking at just the odd items
96:27 - on a d10
96:30 - i've got an example i want you to
96:31 - consider what would we put together to
96:33 - represent
96:35 - i think it's all of the
96:38 - aces
96:40 - oh picking a single ace out of a deck of
96:43 - 52 cards
96:45 - right
96:46 - and so write some code to do that
96:49 - you have to figure out what your event
96:50 - space looks like or your your um
96:53 - your event looks like and what your
96:54 - sample space looks like so spend a few
96:55 - minutes do that
96:58 - and put your green stickies up when you
97:00 - get done
97:01 - there's about five or six
97:03 - i think what we'll do is we'll give this
97:04 - about
97:06 - seven minutes
97:08 - and then we'll roll on
97:11 - so i'm gonna set a timer
97:13 - seven minutes
97:34 - all right
98:11 - okay
101:46 - um
102:20 - yes
102:38 - got about two minutes left then we'll
102:40 - roll on
103:33 - don't panic right
103:39 - none of us is walking out of this room a
103:41 - guru
103:42 - except for that guy
103:55 - thing is though he walked into the room
103:57 - a guru so
103:59 - he had a leg up on all of us
104:11 - about 23 seconds
104:28 - all
104:32 - right so let's take a quick look at this
104:36 - i'll look at the one that kind of raised
104:38 - the most questions numerous people asked
104:40 - about this
104:41 - so p
104:41 - [Music]
104:43 - say i have 52 cards in my sample space
104:47 - and i have four items in my event number
104:50 - of people typed in 52 comma 4.
104:53 - our code is not yet sophisticated enough
104:54 - to deal with that our code blocks
104:57 - what we need in our code at the moment
104:59 - is to put in a list of items right so
105:02 - you know an
105:05 - ace of clubs a
105:08 - ace of hearts
105:09 - and ace of spades
105:13 - typing is a horrible thing in front of
105:14 - people and an ace of diamonds right
105:18 - and i'd say hey
105:19 - it's about a seven percent chance of
105:21 - getting an ace out of a 52 card deck
105:24 - right
105:25 - if i were to type in a four
105:28 - get a much lower percentage
105:30 - and the reason being if we go back and
105:31 - look at the code
105:34 - the code said
105:36 - if it's a list tell me how many elements
105:38 - are in the list
105:39 - if it's just a number
105:42 - we're going to consider that to be a one
105:44 - um
105:45 - so we've discovered kind of weakness in
105:47 - the code like hey this this doesn't
105:48 - quite play nice let's go fix that
105:51 - all right
105:52 - but the long story short of these
105:54 - problems here
105:55 - and these are kind of one dimensional
105:56 - style problems is what's the size of my
105:58 - sample space and how many elements are
106:00 - in
106:01 - my event space
106:04 - all right so let's go look at our code
106:07 - to do that though we kind of want to
106:09 - expand on a few other things and then
106:10 - we'll get there let's talk about
106:13 - exclusive events and intersections
106:18 - most of what we looked at are just very
106:20 - simple venn diagrams little circle with
106:22 - a certain number of things in it
106:23 - there are some cases though where as i
106:25 - potentially try to create a venn diagram
106:27 - i might notice that wait i'm looking at
106:29 - maybe two different types of things and
106:33 - trying to lump them together in my
106:36 - event
106:38 - for an example
106:40 - say i had a d10 dice
106:43 - and
106:45 - want to know the probability of rolling
106:46 - an even so i have 10 sides
106:49 - evens are 2 4 6 8 and 10. that's 5. so
106:54 - that's 50 chance of getting an even
106:57 - chance of getting an odd is also 50
107:01 - so the chance of getting either an even
107:03 - or an odd is
107:04 - a guarantee
107:06 - if i roll my dice i will get either an
107:07 - even or odd and so i can very nicely add
107:10 - these two things together and boom i can
107:12 - calculate what are the odds of getting
107:13 - or what is the probability of getting an
107:15 - even or odd
107:16 - so yes i have my little odd circle my
107:19 - little even circle and there's a total
107:21 - of 10 things in it
107:23 - my s
107:25 - space has got 10 things so it's all good
107:28 - but what happens
107:30 - if i do something slightly different
107:33 - what is my probability of getting
107:34 - something that is greater than a five
107:37 - when i roll that ten sided dice i have a
107:39 - six seven eight nine or a ten
107:42 - what is my probability of getting a
107:43 - number that is even two four six eight
107:45 - or ten
107:48 - my sample space is 1 through 10.
107:51 - notice
107:52 - greater than 5 and even have these kind
107:55 - of overlapping spots where 6 8 and 10
107:58 - fall into both of those ovals
108:03 - if my probability getting greater than
108:05 - five
108:06 - is fifty percent my probability getting
108:08 - even is fifty percent and i add those
108:11 - together
108:13 - that answer is not
108:15 - right
108:16 - it would say that i have a probability
108:18 - of getting
108:19 - or i have a guaranteed probability of
108:21 - getting one of those two things and we
108:22 - know that's not quite true
108:24 - the correct answer of getting either
108:26 - greater than five or even is actually
108:28 - about point seven
108:30 - and i use the word about and it's quite
108:32 - literally exact right
108:34 - i have seven things in this kind of
108:36 - conjoined
108:38 - event one two three four five six seven
108:42 - my total sample space is ten so seven
108:45 - divided by 10 is 0.7
108:48 - so what went wrong
108:50 - our original kind of let's add these two
108:53 - things together
108:55 - ignored unfortunately the fact that
108:57 - there's a little bit of overlap so we
108:59 - have this very cool formula that allows
109:00 - us to account for overlap
109:03 - i have the number of things in one event
109:05 - the number of things in a second event
109:07 - and if there's any overlap i just
109:09 - subtract out how many things overlap so
109:11 - i don't double count that ensures that i
109:13 - single count those
109:15 - divide that by the sample space and i
109:17 - get
109:18 - the union or the or
109:20 - of a and b
109:22 - all right so that's generic formula
109:24 - you notice i have this kind of u shape
109:26 - thing and i've got this fun of uh
109:28 - upside down u
109:31 - the upside down u means the intersection
109:34 - where things overlap
109:35 - uh sometimes you'll see that referred to
109:37 - as a cap
109:40 - so the number of things that are
109:42 - intersected between a and b
109:44 - this u
109:46 - stands for union it's kind of an or
109:48 - this is the number of things that are
109:50 - included
109:52 - in a or b
109:54 - all right
109:55 - so sure enough we do the math
109:58 - greater than 5 is a 50 chance there are
110:00 - five elements there
110:02 - odd is five elements there's an overlap
110:04 - of three we do the math we get seven
110:06 - over ten
110:09 - okay
110:11 - so let's start to explore this in
110:12 - practice we use my little python
110:14 - probability function
110:16 - i put in anything that's greater than 5
110:18 - anything that's even and we subtract
110:21 - manually the things that we know overlap
110:24 - and let's get an answer
110:26 - and sure enough we get 0.7
110:30 - so what's the probability of drawing a
110:32 - single red card from a standard deck
110:36 - or drawing a king
110:39 - well if i were to put that into my
110:41 - probability function
110:43 - we would see very quickly that this
110:45 - would just suck
110:46 - because i'd have to type out this big
110:48 - giant list with ace of diamonds two of
110:51 - diamonds three diamonds four diamonds
110:54 - etc and nobody wants to type that that's
110:56 - lame
110:58 - so
110:58 - let's tweak our probability function to
111:00 - say
111:01 - my sample size is maybe 52 cards
111:06 - my event
111:08 - could be a single element or if i
111:09 - already know how big the event is i can
111:11 - give it the event size
111:13 - there are 26 red cards i'll just say
111:15 - that the event size is 26.
111:18 - and then we add a little nuance in here
111:19 - it says hey
111:20 - if event size is a list count how many
111:23 - things are in the list so we still have
111:25 - that functionality if event size is an
111:28 - integer
111:29 - just use that as my count so we used a 4
111:32 - before right
111:33 - all right so let's run this boom
111:35 - probability of a red card or a king
111:39 - there are 26 red cards in a standard
111:41 - deck
111:42 - there are four kings in a standard deck
111:44 - two of those kings are red
111:48 - boom
111:51 - let's go take a look at the answer
111:55 - before we get to the answer though
111:57 - sure enough with 26 red cards out of 52
112:00 - i have a 50 chance of getting a red card
112:03 - with four kings out of a deck i have a
112:06 - 0.7 chance of getting a king but that
112:08 - little bit of overlap that we kind of
112:09 - have to suck out of there that's 0.3
112:13 - and i get an answer of
112:16 - there we go
112:17 - my chances of getting either a red card
112:19 - or a king are 0.53 it's a little bit
112:21 - above half which is what we expect
112:24 - all right
112:26 - so what's the probability of drawing a
112:28 - red card or getting a face card a king a
112:31 - queen or a jack
112:33 - well how many king queens and jacks are
112:35 - there in a standard deck
112:40 - how many jacks queens and kings
112:43 - 12.
112:44 - all right so i say hey i've got 12 here
112:47 - there's 26 red cards
112:50 - how many jacks kings and queens
112:53 - are red
112:56 - six so i want to get rid of those
112:58 - because we do not want to double count
112:59 - them
113:00 - and sure enough
113:02 - it's a little bit higher because now
113:03 - we're looking at a few extra cards
113:06 - all right now you might say but chalmer
113:10 - why do i want to do all this math and
113:11 - write all this code because if we think
113:13 - about it
113:16 - all i need to know is how many reds are
113:18 - there
113:19 - how many
113:20 - face cards are there and take away
113:23 - how many duplicates and i get 32. so i
113:25 - can actually just say
113:27 - my sample space or my my event space is
113:30 - 32
113:32 - cards are either red
113:34 - or they're kings queens and jacks
113:37 - and so i don't necessarily have to do
113:38 - this if i can kind of do it in my head
113:41 - or or do it manually you just got to
113:44 - make sure that you get event a event b
113:46 - and you eliminate that duplicate and
113:48 - boom we get the same value awesome
113:53 - so i'm gonna
113:56 - for those who don't know
114:01 - pycon has open spaces where people can
114:04 - gather with folks who do things that
114:06 - they like to do and one of those open
114:07 - spaces is board gaming
114:09 - alright so here's a board gaming example
114:11 - i have three games i have pandemic i
114:13 - have clank and i have carcassonne
114:15 - and in my board gaming group
114:17 - we have a number of folks who play
114:19 - pandemic a number of folks who play
114:21 - carcassonne
114:22 - the pronunciation of this french word is
114:24 - probably mangled by me my apologies and
114:27 - then we have clank
114:30 - some of these folks
114:31 - happen to be
114:33 - players of pandemic and carcassonne some
114:36 - of them play clank and carcassonne
114:38 - i have no duplicates or overlap between
114:40 - these two games
114:42 - now everybody in this oval this 12 and
114:45 - this six they're all part of a group so
114:46 - there's actually 18 people in this group
114:49 - this group has how many folks in the big
114:51 - circle
114:54 - 16 plus
114:57 - 26 and then the clank group has how many
115:00 - people in it
115:04 - 12.
115:05 - right
115:06 - um
115:07 - when i was putting this example together
115:08 - in my head i kept forgetting that these
115:11 - six folks were with these six folks and
115:13 - so my math was always wrong it was very
115:15 - annoying um that's why i pointed out
115:18 - pandemic folks there's 18 of them there
115:20 - are 12 clankers but some of them
115:23 - play more than one game all right
115:26 - so what is the probability of finding a
115:28 - pandemic player in my board gaming group
115:30 - who is also a carcassonne player
115:33 - huh okay well there's 18 of the
115:38 - pandemicers there's 26 carcass owners
115:41 - and then there's this nice little
115:43 - overlap of six we do the math
115:45 - and about 86 percent of my board gamers
115:48 - play those two games
115:51 - um
115:52 - but again if i don't want to type all
115:54 - this nonsense as long as i do the math
115:56 - 18 plus 26 minus 6 gives me a 34. we're
116:00 - all good all right there we go
116:02 - and the math failed epically for some
116:04 - reason why did that fail
116:07 - [Music]
116:09 - 18 26 is
116:12 - 34.
116:18 - my event size is 36.
116:21 - there we go
116:23 - that didn't work either
116:28 - 18
116:30 - is 26
116:31 - minus 6.
116:35 - 18 plus 26 is what
116:38 - 38.
116:42 - all right
116:46 - this is awesome
117:03 - i'm gonna come back to this this is
117:04 - great
117:06 - all right
117:11 - based on the fact that the code may be
117:14 - horribly wrong in some incredibly
117:15 - awesome way we're just going to skip
117:17 - those exercises and move on let's talk
117:19 - about conditionals
117:22 - all right
117:25 - during the next break i'll take a look
117:26 - at that and try and figure out what what
117:27 - where where my math and and all of that
117:29 - stuff went to rye all right
117:31 - let's talk about conditionals because
117:33 - this is going to lead to some fun stuff
117:36 - um
117:40 - one of the things that we really want to
117:42 - do when we start looking at
117:43 - probabilities
117:45 - is not just know when things kind of
117:46 - overlap but
117:47 - we want to understand
117:49 - if one thing occurs what is the
117:52 - probability that something else is going
117:54 - to occur
117:56 - if i exhibit certain symptoms
117:59 - cough cough hack hack
118:01 - sniffle sniffle what is the probability
118:03 - that i have a cold versus i have the
118:05 - what's the probability of i have the flu
118:07 - or the probability that if i have a
118:09 - tummy ache and some cough cough that i
118:12 - might have
118:13 - um food poisoning or something right
118:15 - so if you have one condition what is the
118:18 - probability that you have something else
118:22 - when we talk about probabilities we
118:24 - often hear the word given so if i
118:26 - know
118:28 - that a particular card
118:30 - is black
118:31 - what is the probability if i'm given
118:33 - that it is black what is the probability
118:35 - that it is also a king
118:37 - so i take a card out of a deck and i say
118:39 - it's black
118:40 - you can tell me what the probability is
118:43 - that it happens to be a king
118:45 - if i tell you i rolled a ten sided die
118:48 - and the number came back and it was a an
118:50 - even number you can tell me the
118:52 - probability that it was a 10. right
118:55 - to help us do that venn diagrams
118:56 - sometimes break down a little bit
118:58 - so a really useful feature or really
119:00 - useful thing that people will point to
119:02 - is this idea of a probability tree
119:05 - so for example
119:07 - i have a deck of cards
119:09 - they have 52
119:12 - cards total some of them are black some
119:14 - of them are red
119:15 - i know that 26 out of 52 are black 26
119:18 - out of 52 are red
119:22 - if i tell you that a particular card is
119:25 - black
119:26 - and i want to know what is the
119:27 - probability that it is a king
119:29 - i know that out of all of my black cards
119:32 - i have some that are kings and some that
119:34 - are not kings there are two black kings
119:36 - so there's two out of 26
119:39 - right and there are 24 out of 26 that
119:41 - are not kings so there's 26 black items
119:44 - and they kind of fall out in this way
119:46 - same thing with red kings
119:50 - a couple of things
119:53 - we often talk about kind of levels on
119:54 - the probability tree
119:59 - so we have one level of my probability
120:01 - tree we have a second level
120:03 - with any
120:04 - set of branches
120:06 - here or a set of branches here
120:09 - the math always has to add up so that
120:12 - the total probability on that set of
120:14 - branches is 1.
120:17 - all right
120:19 - so for example
120:21 - 2 out of 26 plus 24 out of 26 is 1.
120:25 - right 26 out of 52 plus 26 out of 52 you
120:28 - add that up you get one
120:30 - you can have more than two branches if
120:32 - you play roulette
120:34 - you'll know that the squares on a
120:36 - roulette table are red they are black
120:38 - and there's two of them thrown in there
120:39 - for good measure that are green so i
120:41 - could have a roulette table probability
120:43 - tree that might say black square red
120:44 - square green square and i could have
120:46 - three branches but nonetheless the
120:48 - probabilities will all add up to be one
120:50 - on any individual level with a grouping
120:52 - of of branches okay
120:56 - to solve kind of across a single branch
121:00 - to figure out what is the probability of
121:01 - getting to the end of a branch you
121:03 - multiply the probabilities together
121:06 - so if i want to say
121:08 - i have a deck of cards what is the
121:09 - probability that i will have a black
121:11 - king i multiply 26 over 52 by 2 over 26
121:17 - and that will tell me the probability
121:19 - that i'm holding one of the two black
121:21 - kings
121:22 - so 26 over 52 times 2
121:25 - over 26 and i have a
121:28 - roughly 3 4 chance of holding a black
121:30 - king
121:36 - and so
121:37 - if
121:38 - 52 items 26 multiply that by 26 and 2
121:43 - i get this
121:45 - now
121:47 - the rest of the branches play out the
121:49 - same way
121:50 - black and not a king
121:52 - red and a king
121:54 - red and not a king
121:56 - the cool thing is
121:57 - the probabilities at the end of each of
121:59 - the branches
122:02 - the probability is way out here
122:05 - three percent three percent
122:08 - and then
122:09 - like 47 and 47
122:12 - they all add up to be one as well
122:15 - right
122:16 - so 46
122:18 - it's about three or four percent another
122:19 - 46. and so when we add this up and we
122:21 - round it because you know math being
122:23 - hard
122:24 - um the total probability for any single
122:26 - branch when you add them all up is a
122:28 - total of one and that makes sense
122:30 - right
122:33 - okay
122:34 - now
122:35 - when we draw probability trees sometimes
122:38 - we throw out generic probability trees
122:41 - that other one was kind of specific king
122:43 - not king
122:44 - so you'll see this kind of nomenclature
122:46 - and syntax
122:48 - if i care about all the elements in a
122:51 - group called b
122:52 - anything that's not in that group
122:54 - you'll often see it referred to as b
122:56 - prime
122:58 - you might also see tilde b it just means
123:00 - anything that's not b
123:03 - so here
123:05 - probability that i get a b
123:07 - probability that i don't get b
123:09 - this is b this is not b
123:12 - um there's an a up there not a a and not
123:14 - a
123:18 - let's shrink this down a little bit
123:20 - all right all right so you'll see b
123:23 - prime a prime
123:24 - um
123:26 - you'll also see this nomenclature here
123:30 - that nomenclature is read in the
123:31 - following way
123:33 - probability of a
123:35 - given b
123:37 - so what is the probability that i get an
123:38 - a given that i'm on the b branch is
123:41 - essentially what that means
123:43 - here what is the probability to get an a
123:44 - if i'm on the
123:46 - not b branch or the b prime branch right
123:48 - so probability of a given b given not b
123:53 - okay
123:55 - and all that's spelled out in the text
123:58 - all that leads us to a formula
124:00 - if i want to know what is the
124:02 - probability
124:03 - that i get an a
124:05 - if i'm given a b
124:07 - i can calculate for
124:09 - the union of a and b or the intersection
124:12 - of a and b and then divide that by b
124:16 - if we pull out our algebra hats and we
124:18 - spin that around
124:21 - the probability of a or b
124:25 - is the probability of a given b times b
124:28 - say okay what does all that mean
124:32 - all right
124:36 - if i want to know
124:38 - the probability across a branch i simply
124:41 - multiply one of these by the other and
124:43 - i'll get the probability for that branch
124:46 - and this is going to be really useful to
124:47 - us in a second but that's what this
124:49 - second formula means to get to the end
124:51 - of the branch i multiply the first level
124:54 - times the second level for the branch i
124:56 - care about
124:57 - now
124:58 - a lot of times when we're given data and
125:01 - we're going to try and make this really
125:02 - cool probability tree we're not given
125:03 - all the data that'll be way too easy so
125:06 - there's a couple of rules and helpful
125:07 - hints that allow us to build out a tree
125:11 - first rule is or the first step we want
125:13 - to take is try and define the level of
125:16 - the tree
125:18 - in my black card red card king not king
125:22 - my definition of levels was okay i could
125:24 - get a black or a red it's a first level
125:27 - i can get a king or not king i could get
125:28 - a king or not king and i defined each of
125:30 - the branches
125:32 - if i have facts go ahead and fill them
125:34 - in
125:35 - put them down on the paper i'll show you
125:37 - an example that with a couple of
125:38 - pictures here in a sec
125:40 - once i've filled in all the facts i know
125:42 - i can do a little bit of simple math and
125:44 - fill in a few of the facts i don't know
125:46 - and then i can start to complete the
125:48 - branch groups
125:49 - knowing that the probabilities always
125:51 - add up to one
125:52 - and i can use that cool formula to then
125:56 - figure out the last remaining
125:57 - probabilities so let's see how this
125:58 - works
126:03 - i go out with a bunch of my friends at
126:04 - work some of them eat burgers some do
126:06 - not some eat dessert some do not
126:09 - right so maybe i want to figure out the
126:11 - probabilities associated with each of
126:12 - the branches given that some of the
126:14 - folks in the company eat burgers or
126:15 - don't eat burgers eat desserts don't eat
126:17 - desserts and i'm given three initial
126:19 - pieces of information
126:21 - the people who eat burgers
126:23 - two out of every three people eat
126:25 - burgers
126:27 - given
126:28 - that somebody is not a burger eater
126:31 - and they eat dessert that happens in one
126:33 - out of four cases
126:35 - and
126:36 - given somebody eats burgers and dessert
126:39 - that happens eight out of 15 cases so
126:41 - let's start to fill this in
126:44 - all right
126:45 - picture
126:50 - probability of eating a burger
126:51 - given that they don't eat a burger
126:54 - that you desert
126:55 - and then probability across a branch
126:58 - they eat burger and dessert
127:00 - so as i start to fill this in
127:03 - probability eat a burger is two-thirds
127:06 - probability that they didn't eat a
127:08 - burger but they ate dessert is
127:09 - one-fourth
127:10 - and the probability that they had a
127:12 - burger and dessert was eight fifteenths
127:15 - we know
127:16 - that this and this have to equal one so
127:18 - i go ahead and start to fill this in
127:20 - we know that this and this must equal
127:22 - one so i fill in the extra value so
127:25 - we're moving along making good progress
127:31 - one thing that we're kind of missing
127:33 - is this guy out here
127:37 - i know this and i know this and i know
127:39 - if i multiply this by this i get that
127:42 - so i can back out and figure out what
127:44 - this piece is if i know him and him and
127:46 - it's just algebra and when i say just
127:48 - algebra some folks suffer with algebra
127:50 - in high school etc don't panic
127:54 - just takes a little bit of practice
127:57 - so i don't mean to say that algebra is
127:59 - crazy easy
128:00 - all right
128:04 - so my formula says
128:06 - if i'm trying to figure out
128:09 - what is the probability of dessert and
128:11 - burger
128:12 - if i know he ate a burger and we know
128:14 - that uh
128:15 - he hit dessert and we multiplied that by
128:17 - the probability of burger
128:19 - this doesn't help me because i'm kind of
128:20 - missing something in the middle right
128:21 - i'm missing this guy
128:23 - but i know
128:25 - 8 15 i know two thirds
128:27 - we can do the algebra flip this over and
128:29 - put him on the other side and now when i
128:31 - multiply 8 times 3 and 15 times 2
128:35 - i round it all down i end up getting a 4
128:38 - out of 5.
128:40 - so i put 4 out of 5
128:42 - up here
128:44 - and if we kind of go back and double
128:46 - check our math right
128:47 - 2 times 4 is eight three times five is
128:51 - fifteen it worked out just the way we
128:53 - wanted
128:54 - i know these two have to add up to one
128:56 - so
128:57 - i figure out what that is
128:59 - now i have
129:01 - all of the probabilities for every
129:02 - single branch i know i can multiply this
129:05 - by that to get here
129:06 - this by that to get here and there so
129:09 - now i can fill out the probabilities
129:11 - all the way across the branch
129:14 - okay
129:15 - so this is useful
129:19 - i now know
129:21 - that
129:22 - if somebody bought a burger
129:25 - and they didn't have a dessert that
129:27 - happens 2 out of 15 of my friends
129:31 - if somebody didn't buy a burger and they
129:32 - didn't get a dessert three out of 12 of
129:34 - my friends are in that horrible horrible
129:36 - group where they don't eat burgers and
129:37 - they don't eat desserts
129:39 - all right
129:40 - okay
129:42 - so let's do some math here with our our
129:43 - script
129:46 - right
129:52 - here i pulled all the values off that
129:54 - chart and i started to drop them in here
129:56 - for branch one
129:58 - probability
130:00 - of burger knot burger was two out of
130:02 - three so two out of three
130:04 - one out of three
130:06 - probability of dessert not dessert four
130:07 - out of five one out of five one out of
130:09 - four three out of four
130:11 - and if i add up all of these
130:15 - it should turn out to be one
130:18 - and sure enough it does
130:20 - all right so i have a reasonable level
130:21 - of confidence that my numbers came out
130:23 - the way we expected
130:25 - all right
130:27 - and this is going to set us up for a
130:28 - situation in a little bit where we can
130:30 - now move beyond this and we can answer
130:32 - some really interesting questions
130:34 - all right
130:36 - but for now we'll take a little bit of a
130:38 - break you guys kind of turn through this
130:40 - um
130:42 - what time does this thing end i always
130:45 - forget
130:47 - 4 20
130:50 - for something
130:52 - 4 40. sweet so we have a little bit of
130:54 - time
130:55 - all right so i'm going to turn it over
130:56 - to you folks
130:58 - all right
130:59 - i want you guys
131:01 - to take
131:03 - some of these pictures i produced for
131:04 - you
131:05 - and this is going to mirror exactly what
131:07 - we just went through
131:08 - you'll have some data i want you to
131:10 - maybe put on a piece of paper or
131:11 - whatever start to sketch this out fill
131:13 - in the things that you know start to
131:15 - fill in the things you don't and then
131:17 - we'll go from there
131:19 - meanwhile i'm going to go back and look
131:20 - at those
131:21 - those two functions and figure out why i
131:23 - suck at math
131:28 - okay
131:29 - why did this fail
131:37 - 52 sure supposed to be a 46. you are
131:39 - totally right
131:41 - i could have swore i changed this
131:42 - because i saw it and i could have swore
131:44 - i changed it
131:46 - yeah that's it
131:52 - i'm good thank you sir
131:58 - so everybody just fled the room
132:02 - but they left their laptops which means
132:03 - it's open season on
132:05 - unattended laptops pick the ones you
132:07 - want
132:09 - and i'll come back with your question
132:16 - turn this off
132:35 - two thirds
132:52 - the reasons
133:02 - um
133:18 - this is
133:34 - uh
134:27 - right
134:44 - okay
135:57 - oh
136:59 - uh
137:29 - um
140:47 - foreign
140:59 - um
141:31 - uh
142:18 - so the whole way down
143:07 - wouldn't i wouldn't give for microsoft
143:08 - paint
143:42 - all right
143:55 - so when i first started going down this
143:56 - road
143:58 - um
143:59 - i'm gonna be perfectly honest
144:01 - lots of swiggly lines lots of slashes
144:03 - parentheses
144:05 - crazy letters and numbers and things
144:07 - that mean absolutely nothing yeah my
144:09 - mind exploded
144:10 - um
144:12 - it took doing this multiple times
144:16 - over and over again
144:17 - reading the topic in book a
144:20 - rereading the same topic because they
144:22 - didn't understand it in book b
144:24 - and then maybe sometimes rereading the
144:25 - same topic in book c and going ah
144:28 - i see what you did there
144:30 - right
144:31 - um
144:32 - so
144:33 - having said all of that right if you're
144:35 - trying to go through things and maybe
144:36 - you're drawing little probability trees
144:38 - and you're like i don't know what number
144:39 - goes where
144:40 - you're in good hands half the people in
144:42 - this room might have been in that very
144:44 - same same thing
144:46 - and be willing to admit it there's a
144:48 - bunch of other people in the room who
144:49 - are in the same boat but we're not
144:50 - willing to admit it
144:51 - okay
144:54 - in some of our examples thus far right
144:59 - we were given things here's a
145:01 - probability
145:03 - here is a probability of something
145:06 - happened given that i have
145:07 - a precursor i have a condition
145:10 - and then we have the probability that
145:13 - two things happen this n is kind of like
145:15 - an intersection it means and probably
145:16 - the guy had a dessert burger and a
145:18 - dessert
145:20 - if we
145:21 - picture this
145:22 - and this just those two for right now
145:26 - single probability and a probability
145:28 - with this given symbol in the middle of
145:30 - it
145:31 - and we scroll back up here
145:34 - when i just have a probability it goes
145:37 - first
145:38 - when i have a given it goes second
145:42 - and so this given probability is up on
145:44 - this upper branch because it's telling
145:46 - me
145:47 - this probability of not getting an a
145:49 - only applies if i'm on the b branch
145:52 - this probability of getting an a only
145:54 - applies if i'm on the not b branch so
145:57 - this given statement helps you figure
145:59 - out where that
146:01 - particular
146:02 - value fits in any one of these four
146:05 - things
146:08 - and then
146:09 - the
146:11 - intersection
146:15 - of hey my friend
146:17 - adaberger andy also or she also ate a
146:20 - dessert
146:21 - that intersection is at the end of our
146:24 - chain
146:28 - if i know the probability ate a burger
146:30 - and i know the probability had a dessert
146:32 - given that they had a burger i can
146:34 - figure out
146:36 - that intersection
146:38 - so kind of mental model where these
146:40 - three things fit
146:42 - probability
146:44 - probability given that i'm on a
146:46 - particular branch
146:47 - and then the intersection and so
146:49 - hopefully that will help you start to
146:50 - flesh out where these things go but
146:52 - again i read book after book looked at
146:54 - it multiple ways some authors are really
146:56 - horrible at explaining stuff some
146:58 - authors are really good
147:00 - some authors are genius
147:03 - all right so
147:05 - yep
147:07 - right there
147:09 - this picture
147:10 - yeah
147:23 - yes
147:24 - the reason they would equal one is i
147:26 - have four possible options
147:29 - there's no other options that my friends
147:31 - could have went down they had a burger
147:33 - didn't have one they had dessert they
147:34 - didn't so four possible options
147:37 - i have to fit into one of those four
147:39 - categories and so the probability of
147:41 - getting any of them is going to be one
147:44 - all right
147:45 - and
147:46 - here when i solve for the probability of
147:48 - branch 1 branch 2 branch 3
147:50 - and then i
147:52 - add up all four probabilities sure
147:54 - enough i get a 1.
147:56 - all right so that's that
148:02 - so
148:03 - let's wrap up this conversation here
148:04 - with this idea of the law of total
148:06 - probability and the law of bayes theorem
148:08 - our bayes theorem all right
148:12 - when we looked at those first
148:13 - probability trees
148:15 - it was fairly easy to kind of hop from
148:17 - one step to the next
148:19 - um
148:20 - hey my friend had a burger and
148:23 - you know
148:25 - 10 of my friends who ate burgers all ate
148:27 - desserts that's great
148:30 - but
148:31 - how do i reverse that question
148:34 - if
148:35 - i'm talking to a friend
148:38 - and my friend says to me
148:40 - you know what man i went to the
148:42 - restaurant i had this awesome dessert it
148:44 - was crazy good a little pecan tart
148:48 - how do i figure out
148:50 - whether my friend ate a burger or didn't
148:53 - how do i determine the probability of
148:55 - whether he ate a burger or didn't
148:58 - because if he says or she says i ate a
149:00 - dessert i may know this value like my
149:03 - friend is either on this branch or my
149:05 - friend is on this branch but i don't
149:08 - want to pry
149:09 - i would like to just kind of figure out
149:11 - the likelihood that they ate a burger
149:13 - how do we get back to that
149:16 - and that's where the law of total
149:18 - probability and bayes theorem come into
149:19 - play
149:20 - so let's start with looking at the law
149:22 - of total probability
149:24 - i'm going to apologize right there's
149:25 - lots of mathy symboly things so again
149:27 - you're going to have to go back review
149:29 - this look at this
149:31 - and kind of work through this
149:33 - i'll blow this up a little bit so the
149:34 - font is slightly larger
149:37 - okay
149:38 - so let us presume that i want to solve
149:40 - the following problem
149:42 - given that my friend said yep that
149:44 - dessert was tasty
149:45 - how do i determine the probability they
149:47 - ate a
149:48 - burger all right
149:51 - we know
149:53 - that to solve for this
149:55 - i need to know these two things it's a
149:57 - formula we had further up on the page
150:00 - what is the probability of the ada
150:01 - burger and dessert divided by the
150:03 - probability that they ate a dessert
150:08 - we may look at this and say well chalmer
150:10 - already gave us a formula to kind of
150:12 - figure this out
150:13 - if i want to know what that is
150:15 - i just need to figure out what's the
150:16 - probability ada dessert given the head
150:18 - of burger times burger that's exactly
150:20 - what we just did a few minutes ago
150:22 - so okay check we can we can solve this
150:25 - it's going to take a little math but we
150:26 - can solve that
150:29 - how do i figure out the probability they
150:31 - had a dessert
150:34 - so that's something we're going to have
150:35 - to kind of figure out
150:39 - if i take
150:44 - that little bit and replace
150:46 - whatever was in the numerator before
150:49 - okay
150:50 - if i replace this with this so
150:53 - we're going to make a little bigger
150:54 - formula but again we kind of know all of
150:56 - these values here we still don't know
150:57 - what dessert is quite yet um but we're
151:01 - getting there we're filling this in with
151:03 - things that we can answer
151:04 - i can look up the probability one of my
151:06 - friends normally eats burgers and i can
151:08 - figure out what the probability is that
151:10 - they had dessert if they had a burger
151:12 - to figure this part out
151:14 - i simply go out to the ends of each of
151:16 - the branches and i look at the two
151:17 - branches that say dessert on them and i
151:19 - say what's the probability that somebody
151:22 - had a burger and had a dessert what's
151:23 - probably they didn't have a burger and
151:25 - they had dessert and just add those two
151:26 - things together if i can add those two
151:29 - together i can get the overall
151:30 - probability that one of my friends ate a
151:32 - dessert
151:34 - now
151:36 - the magic becomes
151:43 - these
151:44 - break them out a little bit and we can
151:46 - solve for what
151:48 - the probabilities they desert
151:50 - and that is the law of total probability
151:53 - all right
151:57 - let's take a quick look at this for a
151:58 - sec
152:09 - so
152:14 - knowing what we know we can go through
152:16 - and do the same process and start to
152:17 - fill in the little blocks we can start
152:19 - to multiply things out
152:21 - we figure out the probabilities that i
152:23 - received spam or didn't receive spam
152:25 - probabilities that there were keywords
152:27 - in the email or there wasn't keywords in
152:29 - the email
152:30 - probability that something went all the
152:32 - way across a branch when you figure out
152:33 - these numbers at the end
152:35 - and with all of those things
152:39 - i can go back
152:45 - too big
152:47 - and i can start to fill in
152:51 - this part of this this equation and
152:54 - figure out what the probability is the
152:55 - guy had to desert
152:56 - okay
152:58 - once you know that
153:04 - we can take that value
153:06 - probability they had a dessert replace
153:08 - it with all this nonsense
153:10 - and now on this side of the equation
153:13 - i can essentially go and look at my
153:15 - chart that i sketched out
153:17 - and i can start to put a number in every
153:20 - single one of these spots
153:22 - hey he had a burger i know what is does
153:24 - how much a probability he had dessert
153:27 - i know the probability they had burgers
153:29 - these two guys are exactly the same
153:32 - i know he didn't have a burger and i
153:33 - know the probability they had dessert et
153:35 - cetera and so you can start filling all
153:36 - those things
153:37 - and if you can get those six values
153:42 - i can now tell precisely the odds that
153:44 - my friend says they had a dessert i know
153:46 - they had a burger it didn't right
153:48 - so let's put this to the test
153:52 - there's a lot of things going on there
153:54 - let's take a quick look
153:58 - given that a
154:00 - spamish style keyword
154:02 - was found inside of a message
154:05 - what is the probability that is
154:07 - classified as not really being spam
154:09 - right so given a keyword is present what
154:11 - is the probability that it's not
154:13 - classified as spam you say well that
154:14 - seems kind of weird if there are bad
154:16 - spanish words in there doesn't that
154:18 - automatically mean it's spanish
154:20 - not necessarily my friend says hey
154:22 - chalmer here's a great book on getting
154:26 - rich quickly
154:27 - right
154:28 - um he's not spamming me he's sharing
154:30 - something that he found whereas if i got
154:32 - an email from somebody
154:34 - you know in a foreign country hey you
154:35 - want to get rich quick
154:37 - maybe that's spam
154:38 - okay so you could have keywords but the
154:41 - email may not necessarily be spam
154:43 - all right
154:45 - so i start off i've got some values
154:48 - we know from some of the research we've
154:50 - done that
154:52 - [Music]
154:53 - seven tenths of the email that comes in
154:55 - is going to be nutspam
154:57 - so i have a number to go with not spam
154:59 - we know that if something is on the not
155:01 - spam branch
155:03 - the probability that a spammish keyword
155:06 - is there is one-tenth
155:08 - and if we know that
155:10 - or we can also calculate that given
155:12 - something is spam and doesn't have any
155:15 - keywords is three out of a hundred
155:18 - things so let's start to fill in that a
155:20 - little bit
155:22 - all right
155:23 - so we start to put numbers down
155:25 - seven tenths of my emails not spam three
155:27 - tenths of spam
155:29 - uh
155:30 - something was classified as spam but it
155:32 - didn't have any keywords maybe they're
155:34 - starting a new spam trend to write
155:36 - only three out of ten things are spam
155:38 - but don't have any keywords
155:40 - um
155:42 - this one is
155:45 - keyword given the fact that it wasn't
155:47 - spam only one tenth of the things that
155:50 - aren't spam have those keywords
155:52 - so
155:53 - now we do
155:54 - all the things right
155:56 - make sure each of these branches is
155:58 - equal to one these branches are equal to
156:00 - one these are equal to one
156:02 - we back this number out from there
156:05 - and we start to fill this in
156:09 - all right
156:10 - and then we do the last bit of the math
156:12 - we multiply
156:13 - this times that so 3 times 9 gives me 27
156:17 - 10 times 10 gives me a hundred
156:19 - 7 times 1 gives me 7. 10 times 10 gives
156:22 - me 100. fill in all these
156:24 - all right
156:27 - with every one of these values filled
156:29 - out like this
156:31 - and it's
156:32 - as we practice and as we get used to it
156:34 - it becomes fairly straightforward to get
156:36 - to this point
156:39 - apologize for the small fun i can
156:41 - essentially pluck values right off this
156:43 - chart and start going boom boom boom
156:45 - boom boom boom boom and i can fill in
156:46 - all six values and now i can tell you
156:49 - if i got an email that had some really
156:51 - cool spammish keyword what's the
156:53 - likelihood that it really isn't spam
156:56 - all right
156:58 - so let's blow this up a little bit
157:02 - so on the top i say let's go find out
157:07 - if it isn't spam
157:09 - and there's a keyword present what is
157:10 - that
157:12 - so that is
157:14 - one out of ten
157:16 - so i put my event size is one i have 10
157:19 - items
157:20 - uh
157:21 - if it is not spam that's a 7 out of 10.
157:24 - this is a 1 out of 10 7 out of 10
157:27 - and i fill in all six of these
157:30 - and there we go
157:32 - if there is a spammish keyword in my
157:35 - email inbox get rich quick
157:38 - uh
157:39 - cialis viagra
157:41 - the odds that it is not spam in this
157:43 - made up example is 20 percent
157:49 - and so with bayes theorem
157:51 - this is a way to answer questions that
157:53 - might otherwise seem very difficult to
157:55 - get to
157:58 - my friend tells me they had a dessert
157:59 - what are the odds
158:01 - um
158:05 - another place where
158:06 - something like this might be used would
158:09 - be maybe like a b testing i give you one
158:11 - version of a website i give somebody
158:13 - else a different version of the website
158:14 - and we get a sense of if they picked
158:16 - something here what is the chance they
158:18 - were using this version of the website
158:21 - if they bought a thing or they clicked
158:22 - on an ad what is the probability that
158:24 - they were looking at a particular type
158:26 - of ad
158:27 - so here's an exercise for you folks
158:32 - i give you basically the same three
158:34 - types of data
158:35 - sketch out your little probability tree
158:37 - start to fill out the tree until you
158:39 - have all the values populated
158:41 - and then
158:45 - much like we did up here go ahead and
158:47 - work out those six items in the formula
158:51 - and answer the question
158:54 - after some of my friends played two
158:56 - different versions of a board game
158:59 - talking to my friend the friend said hey
159:01 - i really want to buy this game
159:03 - what is the probability that that tester
159:05 - played version b of the game versus
159:07 - version a
159:14 - i'll give you guys a few minutes to go
159:15 - through that
159:17 - give you about seven eight minutes
159:29 - all right
159:44 - oh my gosh
160:05 - you
160:33 - you
161:57 - you
164:01 - if you get this finished put your little
165:41 - questions
167:26 - okay
167:54 - all right
167:57 - okay
168:02 - the big sticking point here
168:04 - is figuring out what each of these
168:06 - things are
168:08 - just as i kind of walked around and
168:10 - talked to a couple people and listened
168:12 - to some of the comments right
168:14 - the process of getting from point a to
168:16 - point b
168:20 - is essentially the hard part
168:23 - and how this will normally play out in
168:25 - these types of examples
168:29 - you will potentially be given
168:31 - one of these two values on a branch so
168:34 - you have to do the math
168:35 - to get the other
168:37 - you'll be given
168:39 - two values here and you can get the
168:41 - third you'll be given two values here
168:43 - and you need to get the middle one those
168:45 - kinds of things
168:47 - and so as you get practice and you get
168:49 - practice by doing right you do this over
168:51 - and over again
168:52 - um
168:54 - you will grow accustomed to oh i've got
168:56 - these three facts or these four facts
168:58 - and i can start to fill in
169:00 - and then once you get this down and
169:02 - things are working out really well
169:04 - then you can start to apply this to real
169:06 - world problems
169:07 - okay
169:09 - but once this chart is filled in
169:12 - the next step becomes
169:14 - take each one of those things put them
169:16 - into the six spots and then the math
169:18 - should theoretically work out
169:20 - all right
169:23 - i'm going to let you guys read this
169:25 - section on independent events and we're
169:26 - going to move on to lesson 3 in the
169:28 - interest of time
169:30 - so you guys can go back and read that on
169:31 - your own
169:33 - we want to look really quickly at what
169:35 - we call discrete probability
169:37 - distributions
169:39 - and then we want to understand a little
169:40 - bit about factorials well
169:43 - permutations and combinations and what
169:44 - those are for and what they mean
169:47 - in the middle of this we're going to do
169:48 - a field trip i'm going to take you guys
169:50 - out onto the wild wild internets and we
169:53 - will look at some things that are out
169:55 - there that might be of interest and use
169:56 - to you
169:58 - and we'll talk a little bit about how
170:00 - this discrete probability distribution
170:02 - can apply to other things but let's get
170:04 - started with the discrete probability
170:06 - distribution
170:08 - one of the kind of the classic i guess
170:10 - examples of a discrete probability
170:13 - distribution
170:14 - is related to slot machines
170:18 - by discrete we mean it's broken up into
170:22 - individual components as opposed to like
170:25 - a nice curve right
170:28 - [Music]
170:30 - with this slot machine example i have
170:33 - three slot machine wheels
170:35 - every wheel has certain symbols on it it
170:37 - might have an apple it might have an
170:39 - orange it might have a quarter might
170:41 - have other random things
170:44 - depending on how the slot machine plays
170:46 - out if i were to get
170:49 - an a and a and a and apple and apple and
170:51 - apple on the three wheels
170:53 - i get four dollars
170:55 - i had to pay 20 cents to play so my gain
170:59 - is going to be 3.80
171:02 - if
171:03 - i got an apple apple orange
171:06 - they give me three bucks but again i
171:08 - spent 20 cents to play so i really only
171:10 - gained two dollars and 80 cents orange
171:12 - orange orange i get two dollars
171:16 - i want to highlight this bit
171:18 - this apple apple orange is any order
171:21 - if i got an apple an orange and an apple
171:25 - that still qualifies i still get my
171:26 - three bucks woohoo
171:28 - all right they're still ripping me off
171:30 - okay now on any given wheel i have a
171:34 - certain number of oranges i have a
171:35 - certain number of apples a certain
171:36 - number of quarters and stuff on that
171:38 - wheel and the probability of getting an
171:40 - apple is one in ten
171:42 - the probability of getting an orange on
171:44 - a single wheel is going to be two out of
171:46 - ten probability getting quarters two out
171:48 - of ten and all the other symbols the
171:50 - cruft
171:51 - that's
171:52 - fifty percent probability of getting
171:53 - some other random symbol okay
171:57 - what i'm going to start doing here is
171:58 - i'm gonna start building out a table of
172:00 - details
172:01 - i'm going to go kind of step by step
172:03 - building out the table and it's going to
172:04 - take me to a point where i can figure
172:06 - out
172:07 - what is my average win at the casino
172:10 - air quoting the word win what is my
172:12 - average loss at the casino
172:14 - so here are my wheels
172:17 - here's how much they pay
172:19 - here's how much i get
172:22 - or how much i pay so
172:24 - normally when i screw up and i get
172:25 - nothing none of the wheels helps me i'm
172:27 - gonna immediately lose 20 cents if i get
172:29 - three quarters
172:31 - i get back 80 cents because i've spent
172:33 - 20 to get there
172:35 - um we know the probability of getting an
172:37 - orange
172:39 - so
172:40 - 2 percent
172:41 - or
172:42 - 20 probability of getting an orange 20
172:44 - probably getting another one 20
172:46 - probability getting a third the chances
172:48 - of me getting three oranges in a row is
172:51 - eight out of a thousand
172:53 - um similarly i can do the math to figure
172:55 - out what is the probability of getting
172:57 - all apples that's one in a thousand
173:00 - probability of getting all quarters is
173:02 - eight out of a thousand
173:04 - and the probability of being a sucker
173:07 - is
173:08 - 996 times out of a thousand i lose cash
173:13 - straight up
173:15 - all right if you are a gambling
173:16 - aficionado please don't be insulted when
173:18 - i say sucker that's a colloquialism all
173:21 - right
173:23 - so if i translate gains and losses
173:27 - um we can assign a probability of
173:29 - getting any specific gain and here
173:33 - i'm going to stop calling them gains and
173:34 - losses i'm going to say x
173:36 - so i have a capital x and a lowercase x
173:39 - x is
173:41 - this random variable
173:43 - um
173:44 - and the little x is any individual item
173:47 - and i've only got four or five options
173:48 - here so out of these five options that
173:51 - fall into this big random variable
173:54 - and so i know the probability of getting
173:56 - any of those
173:57 - five options and i know how much money i
173:59 - get
174:01 - and that's going to help me figure out
174:02 - my average win or loss
174:05 - all right
174:07 - in our previous discussions we talked
174:09 - about averages we use the word mean
174:11 - when we talk about these distributions
174:13 - we use the phrase expectation
174:15 - little mood lighting sweet is somebody
174:17 - leaning on a light
174:18 - switch all right
174:23 - it was getting crazy cozy in here
174:26 - all right
174:30 - so
174:31 - given any particular trial i might lose
174:34 - i might win is there a way to figure out
174:35 - my average and that is using expectation
174:39 - to figure out our expectation
174:41 - we use a formula much like we had before
174:43 - we say all right if i have a particular
174:46 - x
174:47 - what is the probability that i'll get
174:48 - that x
174:50 - and let me add up all of those
174:52 - and that will give me my mean
174:57 - e
174:58 - x is called expectation but we also
175:00 - often call it mean so you'll run into it
175:02 - as both and matter of fact we might use
175:04 - the symbol for mean which is this
175:07 - uh
175:09 - this greek mu
175:10 - all right
175:11 - so for starters i multiply the
175:13 - probability
175:15 - times the
175:16 - the value of the variable and i get
175:18 - these results
175:19 - a bunch of them come out positive
175:21 - and then we have this suckers category
175:24 - which comes out very negative
175:26 - and if i do all the math and i add all
175:28 - five of those results up my average loss
175:31 - every single time i play this game if i
175:33 - played it a lot of times my average loss
175:35 - will be 16 cents every time i play this
175:37 - game
175:40 - all right
175:41 - sure i might win four bucks
175:44 - once in a while but on average i'll lose
175:46 - 16 cents every time i play
175:48 - all right
175:51 - now
175:52 - knowing the mean is kind of cool but we
175:54 - also often want to know how broad that
175:57 - spectrum is
175:59 - is there a possibility i might have a
176:00 - really broad spectrum and maybe i'll get
176:02 - really lucky on one end of the spectrum
176:04 - to solve that we essentially solve for
176:06 - variance
176:07 - right so the variance of any given
176:09 - probability distribution
176:11 - is the expectation of
176:14 - the value
176:15 - minus
176:16 - the average squared
176:19 - right
176:21 - so let's get in here
176:24 - this is essentially the same chart we
176:26 - had before but i take
176:29 - the value
176:30 - minus the average
176:32 - remember the average was negative i'm
176:34 - losing money on this so i subtract a
176:36 - negative value
176:38 - and i get this
176:41 - um
176:43 - once i have taken the average and
176:45 - subtract it from all five values i'm
176:47 - gonna have to go back and square it
176:50 - so we jump in here
176:52 - we take each of those values we just
176:53 - calculated a second ago we go ahead and
176:55 - square them all
176:56 - and once we have a square
176:58 - we multiply it by the probability and we
177:00 - get all these things
177:02 - again you go back reread this kind of
177:04 - absorb it take your time
177:06 - but ultimately
177:08 - once i've multiplied
177:10 - the square value times the probability
177:13 - i can get a variance and i can tell with
177:15 - this particular data set
177:18 - it's wide it's narrow things are really
177:20 - close to the mean a lot of times things
177:22 - are far away from the mean a lot of
177:23 - times but again variance is such an ugly
177:25 - number nobody likes variance
177:27 - so we have standard deviation and that's
177:29 - just the square root of the variance
177:31 - all right so your first question might
177:33 - be
177:34 - holy cow how do we write code that does
177:36 - all of that
177:38 - well we're not going to we're going to
177:39 - skip that part right and we're going to
177:40 - go on a field trip we're going to look
177:42 - at some libraries these are your
177:44 - takeaways these are things you can go
177:46 - home and play with and explore and
177:47 - consider i'm going to look at a couple
177:49 - of libraries
177:51 - and figure out how the pros
177:53 - have put these things together for our
177:54 - use
177:55 - um the first place we're going to start
177:57 - is the stats field trip and for your
178:00 - reference don't try to like read out the
178:02 - the url because that's that's just going
178:04 - to like blind your eyes
178:06 - all of these are linked at the bottom
178:08 - and so i have all the urls to get to
178:10 - each of these down at the bottom okay so
178:12 - let's start with the sci-fi stats
178:14 - library
178:15 - load this up a bit
178:17 - okay
178:19 - [Music]
178:20 - the sci-fi library itself
178:23 - has some tutorials that'll kind of walk
178:25 - you through a series of things certain
178:27 - basic functions they might have or
178:29 - statistical functions that are present
178:31 - etc
178:33 - i'm going to dive into
178:35 - the scipy.stats library
178:38 - i'm basically going to kind of scroll
178:40 - through this and point out a few things
178:42 - the nuance here that i want you to walk
178:43 - away with is there's a heck of a lot of
178:45 - good work that's been put into solving
178:47 - some of these statistical problems that
178:49 - i should take advantage of instead of
178:50 - using chalmers crappy code
178:52 - all right
178:54 - we mentioned a minute ago discrete
178:55 - probability distributions where things
178:57 - take certain values
178:59 - a 3.80 return a 2.80 return well there's
179:03 - other distributions called continuous
179:05 - and so i'm going to kind of scroll
179:06 - through this right they're all
179:08 - alphabetical order a so we got alpha
179:10 - arcsin
179:11 - these are all continuous distributions
179:14 - and a lot of work has been done to try
179:16 - and create
179:18 - these objects in python that you can use
179:21 - to look at distributions of data in
179:23 - various ways and we'll dive in on one of
179:25 - these in a few moments
179:27 - but there's a lot right
179:30 - so when we talk about you starting your
179:31 - statistics journey
179:34 - this is step one this is the first three
179:36 - hours or something of a 40 hour college
179:38 - class on intro to stats and this is you
179:41 - know graduate level whatever right but
179:43 - there is a destination you can get to
179:45 - and in many cases you don't have to go
179:47 - all the way you don't know and memorize
179:48 - every one of these none of us have that
179:50 - memorized
179:52 - we build on the basics and then when we
179:55 - need something particular we go and try
179:57 - and hunt down the thing that will help
179:58 - us
179:59 - we have what's called multivariate
180:00 - distributions that look at various types
180:02 - of
180:03 - multiple variables that correlate with
180:05 - things we have some discrete
180:07 - distributions which is what we were
180:09 - looking at a moment ago there's various
180:11 - ways to handle particular types of
180:13 - discrete distributions
180:15 - and then of course they've got
180:17 - a whole slew of statistical functions
180:20 - like mode
180:21 - and
180:24 - calculating for skew and for variation
180:26 - and
180:27 - standard deviation etc so let's go dive
180:30 - in on one of these
180:32 - this is in the stats library and this is
180:34 - related to a particular discrete random
180:36 - variable it's called the binomial
180:38 - discrete random variable
180:40 - and
180:43 - the way to calculate certain values that
180:45 - come out of this they have this really
180:46 - funky formula we're not going to spell
180:48 - that out i'll let you guys figure it out
180:50 - but you provide it with
180:51 - a couple of values and it will allow you
180:53 - to build
180:55 - kind of this body of information that
180:56 - you can then go
180:58 - and explore
181:00 - and your exploration might lead you to
181:02 - making graphs that kind of show patterns
181:04 - in the behavior
181:07 - and if you want to know specific details
181:09 - about the data that you could use to
181:11 - make that graph they have a whole slew
181:14 - of additional kind of nested functions
181:16 - that allow you to dig right into
181:19 - that distribution and understand more
181:21 - about it etc right i'm not going to walk
181:24 - you through all these things but they're
181:25 - there
181:27 - so that's the first part of the field
181:28 - trip sci-fi stats the next part of the
181:31 - field trip
181:33 - we mentioned a library called numpy
181:36 - numpy's got
181:38 - much like the scipy library
181:40 - an incredible set of documentation where
181:42 - you can start to dive into particular
181:44 - things that interest you and we're not
181:46 - going to explore this one the way we did
181:47 - sci pi stats
181:48 - pandas also has
181:50 - again kind of this incredible wealth of
181:53 - information about how you can calculate
181:56 - information using data
181:59 - the python statistics library
182:02 - a couple of us were looking at this a
182:03 - few minutes ago there's really only
182:05 - about
182:06 - 10 or 12 different types of functions
182:08 - here this is more the
182:11 - uh
182:12 - the meat and potatoes kind of things
182:13 - that you're most regularly and
182:14 - frequently might use this does not get
182:17 - into any of the details like sci-fi
182:18 - stats and and numpy and stuff will allow
182:20 - you um but it's there and you don't have
182:22 - to import it you don't have the weight
182:24 - of importing a lot of things from
182:25 - third-party libraries so this is still
182:27 - useful for the things that show up most
182:28 - frequently
182:30 - all right so with that
182:33 - so that was our field trip
182:38 - i mentioned this idea of these discrete
182:40 - probability distributions you go home
182:43 - you start to wrap your head around that
182:45 - one of the really cool things that you
182:46 - can do once you have a good
182:48 - understanding of a discrete probability
182:50 - distribution
182:51 - is that you can apply what we call
182:53 - transforms
182:55 - in order to get to kind of this point
182:58 - i had to multiply certain things by
183:00 - hey this this is the probability that
183:02 - something's going to happen or this is
183:04 - the gains and the losses et cetera well
183:06 - what if
183:07 - my slot machine owner says hey we're
183:09 - going to upgrade your slot machine and
183:10 - it's no longer going to be four bucks if
183:12 - you win this but everything is going to
183:14 - be increased by a quarter you'll earn
183:16 - four dollars and a quarter three dollars
183:18 - and a quarter um instead of having to go
183:20 - back and redo this these transforms will
183:22 - allow me if you guys study up on this to
183:25 - very simply
183:27 - reevaluate my variances without having
183:29 - to do a lot of crazy math so that's
183:30 - pretty cool
183:32 - um so you'll want to research
183:34 - transforms
183:36 - on discrete probability functions
183:39 - so we've got 10 minutes i'm going to
183:40 - walk you through combinations and
183:42 - permutations with a sprinkling of
183:44 - factorials
183:46 - if you recall a few minutes ago
183:49 - i said hey look at this
183:51 - if i get an apple an apple and an orange
183:56 - i'm going to win something
183:58 - but i also illuminated the fact that it
184:01 - really really wasn't
184:03 - just apple apple orange it was any order
184:06 - of apple apple orange so i get orange
184:08 - and then an apple on the second wheel
184:10 - apple on the third wheel
184:12 - and when i calculated the probabilities
184:14 - for this i took that into account so i
184:16 - got apple apple orange plus apple orange
184:19 - apple plus orange apple apple say that
184:22 - three times quickly
184:24 - um
184:25 - this was easy because it was only three
184:27 - things i only had like kind of three
184:29 - combinations of this
184:30 - or three arrangements of it sorry it's
184:32 - probably a better term
184:35 - but what if i had lots of things
184:37 - and i had all sorts of arrangements
184:39 - is there a way to do that mathematically
184:41 - and do it easier that's where factorials
184:44 - combinations and permutations come into
184:46 - play
184:47 - all right
184:49 - we'll start off with factorials
184:52 - you might have seen this button on your
184:53 - calculator never known what it does
184:54 - there's often on calculators a button
184:57 - that will have something like x with an
184:58 - exclamation or an n with an exclamation
185:01 - that represents a factorial and what a
185:03 - factorial is is simply
185:05 - i will take whatever number you give me
185:06 - and multiply it by all the things that
185:09 - are decremented down by ones so a 2
185:11 - factorial
185:13 - is 2 times 1 a 4 factorial is 4 times 3
185:16 - times 2 times 1
185:19 - 10 factorial is spelled out
185:23 - it's a nice way
185:24 - of
185:26 - very simply creating
185:27 - very large numbers
185:30 - that are composed of things
185:33 - you might say well what kind of use
185:35 - would this be
185:36 - let's say that i have
185:39 - four books for example
185:42 - um and i want to put them on my
185:43 - bookshelf and i'm kind of particular
185:44 - about what order i put them in with the
185:46 - four books in my hand i could pick my
185:48 - first book i have four choices and i
185:50 - throw the first book down how many
185:52 - choices do i now have left in my hand
185:56 - i have four books to start with and i
185:58 - put one on the shelf how many choices do
186:00 - i have left how many books do i have
186:00 - left in my hand
186:02 - three
186:03 - so now i pick one out of the three and i
186:05 - put that on there how many choices do i
186:07 - have left in my hand
186:08 - two right so these factorials are often
186:11 - used in these kind of things we need to
186:12 - organize and arrange things
186:15 - if i have a bunch of horses and they're
186:16 - in a horse race
186:18 - by the way chalmers not a gambler but
186:19 - yes say i have horses and they're in
186:21 - horse race
186:22 - i have 20 horses
186:24 - which horse could come first have 20
186:26 - options which horse could then come in
186:28 - second i only have 19 options which
186:30 - horse could come in third i only have 18
186:32 - more options right so that's where
186:34 - factorials come into play
186:36 - a great thing about factorials is that
186:38 - if i have to do division of one
186:40 - factorial by another it's pretty easy
186:43 - because
186:44 - three times two times one over three
186:45 - times these cross out and i'm just left
186:47 - with five times four so it makes the
186:50 - math pretty pretty straightforward
186:52 - um
186:54 - i've got a little function here we'll
186:56 - calculate this calculate that
186:58 - and so
186:59 - i'll let you figure out the details of
187:01 - the function but i've got a function
187:02 - that will calculate factorials for us
187:05 - i want to highlight
187:08 - in vivid terms what i meant by chalmers
187:11 - code sucks and other code is better
187:13 - by looking at a real-world solution
187:16 - the calculation of factorials looks like
187:18 - it's pretty straightforward
187:20 - but
187:22 - there's a lot going on to the hood
187:24 - for example if you're on a 32-bit piece
187:27 - of hardware
187:29 - the size of an integer maxes out at
187:31 - about 12 factorial if you're on 64-bit
187:34 - hardware it maxes out around 20
187:36 - factorial maybe your computer might want
187:39 - to build or calculate something larger
187:40 - than that so you might use floating
187:42 - point approximations or representations
187:44 - of those values and that will nudge you
187:46 - a little bit past those points
187:48 - or maybe in terms of speed
187:51 - you don't want to calculate
187:54 - 40 times 39 times 38 you might want to
187:56 - have a lookup table for certain low
187:58 - level factorials and then do the
188:00 - calculations on higher ones
188:03 - or you may not want to do the
188:04 - calculations at all so you might use an
188:06 - approximation like sterling's formula to
188:08 - figure this out
188:09 - so real world functions not chalmers
188:12 - will do things to help improve the speed
188:14 - or the reliability of it
188:16 - and i just want to show you what we mean
188:17 - by the speed of
188:18 - it so i created a factorial function we
188:21 - just looked at it a second ago but there
188:23 - is actually in python's math library
188:26 - a function called factorial and i'm
188:27 - going to import it as f so that the two
188:29 - names don't don't overwrite each other
188:31 - and if i calculate the factorial of four
188:34 - it's going to give me back some number
188:37 - and so let's go look at that make sure
188:38 - we get something back
188:40 - we get 24.
188:43 - returns 24 as expected there we go
188:47 - if you've never used jupiter to do this
188:48 - it's kind of fun
188:50 - there is the ability to time certain um
188:55 - statements or expressions etc in in
188:57 - python so i'm going to say use chalmers
189:00 - factorial function and calculate 40
189:02 - factorial and time it and show us how
189:05 - long it takes to do this and then we'll
189:07 - use
189:08 - the library in or the function in the
189:10 - math library and we'll see how well it
189:11 - works
189:12 - so we'll run that
189:14 - the time it functions kind of cool
189:16 - it will run this multiple times and
189:19 - every time it runs it it will do it some
189:21 - number of times like a hundred thousand
189:23 - times
189:24 - so it took
189:25 - about seven micro seconds to do it with
189:28 - chalmers crappy homegrown code
189:34 - and it took
189:36 - 300 nanoseconds
189:39 - to do it
189:40 - with legit code that is really good at
189:42 - this and optimized for this right that
189:45 - is a massive difference like a thousand
189:47 - times difference right something like
189:48 - that
189:49 - or ten times difference whatever it is
189:51 - math is not my thing
189:53 - don't trust me for your maths all right
189:56 - three seconds or three minutes to go
189:58 - good grief
190:01 - we'll talk about permutations
190:02 - combinations and products
190:06 - um
190:13 - with permutations
190:16 - we will look at how we can arrange
190:18 - things for example
190:20 - how many ways can i arrange four out of
190:22 - five books on my shelf got five books i
190:25 - only have room for four let me figure
190:27 - out which four i want to pick
190:29 - or
190:30 - if i know that i care about three of the
190:32 - ten horses that win because i'm going to
190:34 - bet on three of them
190:36 - how many different options are there
190:38 - that three will cross the finish line
190:39 - right
190:41 - combinations on the other hand
190:44 - are things where
190:46 - we don't have to worry about the order
190:49 - of them with the horses right if if
190:51 - sally blue finishes in front of you know
190:53 - denver dan
190:55 - versus denver dan finishing first the
190:56 - order was crazy important with that
190:57 - permutation
190:59 - but with combinations order doesn't
191:00 - matter
191:01 - what did you have in your salad i had
191:03 - walnuts i had romaine lettuce maybe i
191:05 - didn't have iceberg
191:07 - had croutons the order doesn't matter if
191:10 - i said croutons and iceberg lettuce it
191:12 - doesn't matter
191:14 - products are a lot like permutations
191:17 - but
191:19 - you not only care about the order but
191:20 - you start to replace things
191:23 - so for example i pull a ball out of a
191:25 - lottery cage i read the ball i throw the
191:26 - ball back in and i have the chance of
191:28 - pulling that same ball out again but the
191:30 - order of the numbers matters and then
191:32 - combinations with replacements it's the
191:34 - same as combinations but i put stuff
191:36 - back in the pool so i got a handy little
191:38 - chart here do i replace stuff yes or no
191:41 - with those books i couldn't replace them
191:43 - because i only have one copy of each
191:44 - book
191:45 - um
191:46 - with the lottery balls i could put the
191:47 - lottery ball back in the in the in the
191:49 - bucket right order matters order doesn't
191:51 - matter
191:56 - right so we can calculate permutations
191:58 - combinations products
192:00 - and stuff
192:03 - one thing that i'll leave you guys with
192:04 - and then we're pretty much done
192:07 - again rolling your own not so good
192:10 - there is
192:12 - a library called intertools that has a
192:14 - function built in to do each of these
192:16 - and real quick we'll look i have three
192:18 - things
192:19 - i want to figure out kind of groupings
192:22 - or arrangements of them two at a time
192:26 - when
192:27 - order doesn't matter i only have three
192:29 - possible arrangements but if order does
192:31 - matter
192:32 - did one come before two or did two
192:35 - come in front of one
192:37 - et cetera
192:38 - all right i'll skip all of that
192:41 - there we go
192:42 - and those are the links to all the
192:44 - libraries
192:45 - you folks have been amazingly patient
192:47 - through the day
192:49 - brains are all fried by now i'm sure
192:52 - i'm glad you came
192:54 - i appreciate any feedback i will get a
192:57 - survey link up on
192:59 - the screen here
193:01 - i
193:02 - urge you to go to
193:04 - this particular location and give me
193:06 - feedback because feedback is something
193:08 - that
193:09 - i need
193:11 - so
193:12 - let's see
193:14 - www.surveymonkey.com
193:20 - and if i remember right i think
193:22 - surveymonkey's done in python
193:25 - all right and this is a capital hk
193:28 - 8 2
193:30 - 6
193:31 - 8.
193:33 - let me make sure i got this right
193:34 - surveymonkey.com
193:36 - r
193:37 - h g k
193:38 - 8 2 6 8.
193:41 - all right
193:42 - um
193:44 - if you guys need to get a hold of me
193:46 - i've sent you guys some emails and they
193:47 - have like my twitter handle in them you
193:48 - can reach out to me that way
193:50 - my email is there you can reach out to
193:52 - me if you want to ask questions
193:54 - please please fill out the survey
193:56 - that'll help me be better
193:58 - and i appreciate your time glad you came
194:00 - thank you
194:02 - [Applause]

Cleaned transcript:

all right welcome everybody my name is joe merlo we're going to go through real quick some of the install instructions and then we'll get through and start doing some expectation management those kinds of things most of you have probably done the install instructions already so i'm just going to cover those briefly a couple tools we want to have on our systems i tend to prefer using a tool called conda to help me do package management some specific libraries that we're going to install we'll walk through those we'll go through how we test for installation and talk a little bit about why we're doing things with this way one of the things that i often recommend read all the steps ahead of time get a sense that you understand what the steps mean some steps may say install thus and turns out you already have it installed so you may not have to do that for this tutorial i highly recommend using cond as a package manager because there are some libraries that are kind of sucked into this process that are not necessarily python libraries so some python package managers may not be real good for this conda has a virtual environment manager to help manage your virtual environments we'll talk a bit about what that means the material for this has been tested using conda but it has not been tested with pip it has not been tested with virtual and etc if you already have conda installed you can test that by typing conda on the command line and if you get something back that says usage conda you're good if not the instruction should walk you through it for this course material we're using python version 3 dot x when you say python equals three and one of the commands we'll do in a minute it'll give you the latest version of python um from my experience the most common problem that i see when people start to do this is they they miss a step right our eyes tend to glaze over and we miss things so if you have a problem uh scroll back check to see if you've done all the things if not we have a set of mentors in the room uh and myself we can walk around and help you especially during the part where we do exercises all right there are a set of instructions for doing this in windows and mac and linux you can confirm whether conda's been installed by doing conda or condoles this is high tech guys all right next all right so let's talk a little bit about what we're doing when we're installing python and some of the other things you're going to make a directory called stats you're going to change into that directory so now you're inside that folder and we're going to create a virtual environment at the bottom of this material i have kind of a writeup as to why virtual environments are important and how they can be useful to you and i'll leave that up to you to read it but the the big picture for virtual environments and why you might want to use one is that it creates a sandbox some of you have python already installed in your computers and you maybe use it for work and you don't want to corrupt or mess up your existing version of python or your existing libraries that use with python so the virtual environment makes a sandbox what we do goes in the sandbox and it doesn't interfere with anything that happens right once we've made a virtual environment we have to activate it and if you've activated a virtual environment you're going to see these little parenthetical off to the side to say you're now using that virtual environment and now using the version of python that you installed for that environment and then next we can say conda install and you can tell it all the libraries that you would like to use in this case we have five main libraries that we intend to explore all right once you've installed those we'll type jupyter space lab and hopefully a lab environment will open up if you do not have one let us know and we'll get you get you taken care of you kind of raise your hand i'm going to pass out some stickies as well in a little bit all right next we have class material it is up on github i'll put the links back up for those in a second you guys can go look for that all right as we go through the process you'll see these green postit notes in the material all the stuff i want you to do basically stops there if you want to keep reading you can go ahead but you can typically stop wherever a green postit note is for those who really want to know more details about all of these things at the bottom of this lesson i have a big picture description of why we use virtual environments what is conda doing why are we using it and all that stuff and so you can scroll through and read all of all of that content at your leisure we're not going to go into it all right so with that in mind all right i'm going to walk you through a little bit about kind of how this class itself is going to play out and the types of things that we want to do all right first off i appreciate pycon my family friends who suffered through me trying to get this material ready my company that helps to get me here booz allen hamilton the pycon tutorial selection committee the mentors who are here in the room who are going to be helping you guys and especially you for being willing to come out and go through this statistics and probability exploration with me to give you an idea of what to expect and what not to expect right we'll do an overview of some probability and statistics print so it's a tough word right it's hard english is tough um we're going to do an overview of probability and statistics principles and techniques we will have some snippets of python code i'm going to warn you right now the code that chalmer wrote for here should never be used in a production environment the things that i wrote are more to demo principles to give you an idea of how things work kind of under the hood they are not for true statistical analysis and i'll prove it i'll show you why there's going to be plenty of opportunities for you to level up your skills we'll have exercises that you guys can walk through and we'll give you a certain amount of time in this tutorial to work on those myself and the mentors will help you i will highlight a few of the gotchas to look out for things that you might be uh experiencing as you go through this journey on your own when you get back to your house etc and we're going to provide some resources to help you continue your learning journey when you go home what are some good books to read or were some good things to look at et cetera so what not to expect if you think this through a typical college class is about 40 some odd hours of sitting in a lecture hall lots of homework in between sitting in lecture halls we have three and a half hours and if we bring biology and taking breaks and stuff into this story we have about three hours right so you're not going to get a whole lot out of this my hope though is that you will get a flavor and that flavor will drive you to go home and keep learning um you are not going to get out of chalmer robust industrialized code we spoke about that and in terms of deep dives we're not going to have the time so some folks may ask some questions like hey i want to know a little bit more about these types of distributions and how these are related to that we're probably not going to have the time for a lot of that we could have maybe conversations about that outside of this i really want to give you guys this nice high level overview in terms of logistics pair practice is used in some tutorials because working closely with a partner helps you kind of identify what's going wrong and helping each other out i'm not going to force that upon anyone if you want to work with someone who sits next to you and say hey why don't we work on the code together or why don't we work through these exercises as a pair i'll leave that up to you and your level of comfort we're going to distribute out some postit notes for you when you get to the end of a period of exercises you put your postit note at the top of your monitor so i can look out when i see a sea of green i know it's time to kind of move on if you run into a problem you'll have a red postit note that will hand out to you you put it on your monitor myself or the mentors will look out and go oh red post it red post it and we'll come to you right so you don't have to do this whole embarrassing hey i got a problem thing um there will be a survey and i'll get you the link to that later i really want to get your feedback okay so how do we get the most out of this experience um i love this picture and let me zoom down so you can kind of see it the top and i apologize it's a small font it says how do you actually learn any new programming concept by changing stuff and seeing what happens one of the cool things about python is that you can try something run it and see what happens you go wow that was cool let me change this number or let me do this thing and you run it again and you get an instantaneous kind of response so i heavily encourage you play with things when you do an exercise and you get done a little early try and go back and do it again tweak something you're gonna have questions that might come up like hey chalmer what if or what will happen if we do this and i love to hear those questions those are great i will caveat that though with i also love to see folks have that question in their head and they go try it themselves because sure i can demo it for you but man how much fun and excitement it is to try it and see some cool response some people say well i don't want to break anything i don't want to do it wrong and that's a legit fear so i'm not going to minimize that but generally with python you're not really going to break much and if you do you can kind of reboot and often if you do quote unquote break a thing there's going to be some error message and you're going to skim it and maybe it's confusing but you're going to see new words new terms and you're going to start to learn things because those error messages as scary as they might look will often teach you things especially when you see them over and over again so try not to be scared there's a couple other things in here and i'm not going to go through them in the interest of time but they're there and they talk about the psychology of learning stuff but this quote here is kind of neat being a programmer basically requires you to deal with these extended periods of feeling like a complete punctuated by very brief periods of feeling like a genius right um that's my life every day i'm standing up here trying to teach you guys a thing but most of my life is i don't know how to get my code to do this thing and i don't know why and then all of a sudden it works and i feel like that guy on the titanic no right and i feel great and then my boss is like we'll solve this other problem now that that's done okay so let's get rolling let's talk about statistics all right so this is kind of the the main meat of the thing um i'm going to disappear behind the podium and grab those postits and have one of my colleagues pass them around all right and then i'll come back i'm still here voila all right everybody gets one green one red not one pad one green postit one red posted you don't know what he's going to do all right so let's get started this first conversation is going to talk about statistics right and what we can do with that and then a little later on we're going to move into probability okay um our main goal right now for this first little bit is to understand you know some techniques for counting things determining what the minimum value is maybe in a data set figure out what the maximum value is and then we will look at these things that we call central tendencies that the fast version is what's the average and we'll explore different ways to look at at that and then we will talk about well how widely does stuff kind of deviate from that average is my data really spread out or not okay let me try and blow this up a little bit maybe okay um we're going to look at the data and we're going to look at these techniques and these processes through a couple different tools we're going to start off with some simple data sets just a couple numbers so we can kind of visually see what the thing is we will then go through a little bit larger data set a little more sophisticated we're going to have some hand developed code that's chalmers do not use this in production code and then i'm going to walk you through a couple of standard libraries that have some functions that do what my code does but does it way better all right to kind of get us in the right frame of mind i'm going to use a i'm going to use that big data set that i mentioned we'll look at it and we'll display it on the screen in a graph and then we're going to use tools to kind of figure out what some of those data points are okay by hand as it were all right so let's pretend i'm a manufacturing plant and you know every day i produce a new batch of stuff on some days my machinery is well tuned and the number of batches that i produce or the batch that i produce has very few defects in it but other days my machinery is starting to fall apart things are breaking and all of a sudden i get larger quantities of defects so i may want to track these on a daytoday basis all right so i have this data and it is this number of defects i purposely kind of organized it so it's kind of bigger numbers at the top smaller numbers at the bottom they're not quite sorted but so we see some things like there's a 99 there's a 52 there's a 42. uh at the bottom we have some twos and threes and fours i don't know there's like 208 or some some odd numbers we'll figure that out i will warn you we're not going to do a deep dive into matplotlib i'm going to gloss over this real quick i just wanted to give you a graph but i use matplotlib here to import some capabilities that will enable me to make a very basic plot i also have a tool called the counter tool and we'll talk a bit about it in a minute that's going to help me count things and now i want to make a simple histogram a simple graph what we're going to do is try and start off by making this display and we're going to use a tool called most common which is found in the counter object and you'll see how that works out all right so i start off by taking all of those values that i had number of defects and i drop it into my counter object and that's going to produce a thing that looks like a dictionary but it's not quite and so i call it defect counts and then i say all right show me the five most common values that occurred in all of my number of defects so we run that code and so the number 8 showed up 24 times the number 6 showed up 24 times and the number 7 showed up 18. all right i mentioned that counters look a little bit like dictionaries there's two nuances that you should know they have this kind of extra method that we just saw called most common that allows us to find out what are the most common things and i can tell that i want to see the two most common items and it'll give me that or i can say i want to see the five most common items it'll give me more right but one other nuance that is fun is that if you've ever played with a dictionary and you try and access a value that doesn't access a key that doesn't exist your dictionary will vomit on you and it throws up this little error and says hey you tried to look at something that doesn't exist counters are cool that they don't do that if i try to access the number 77 which is not in my defect count it goes that's fine and it just gives me back a zero if i try and access a number that does exist like an eight it'll look into the counter and go oh there's a 24 stored there and it'll give me back at 24. so this is kind of cool and we'll take advantage of that particular functionality in a second all right so i want to create a list of x values to go on the bottom of my chart and i want to see all of those y values that are in my defect count the 8 or the 24 and the 24 and those things and i want to store them in two separate lists so i can dump them into matplotlib so for those who haven't seen it this is a list comprehension syntax i'm not going to go into it but it's very useful for doing analysis i'm not going to talk about these these are all just the things that we use for matplotlib and it's going to take all of the x values that we just made and all of the y values that we made and it's going to plot them all right and so we get this nice little chart and a couple things that we can see right off the bat where are most of the things low end right there appear to be two little spikes do you guys remember what numbers those spikes were at what were the most common values six and eight right um when we looked at the data and i said hey i got this stuff kind of organized there was a big number at the front it was a 99 and sure enough we see there's a little spike over there by the 99 turns out maybe that's an outlier maybe not right okay so this visually shows us a lot of cool things i want to figure out how do we get to some of these data points using code we'll start off with using count maximum and minimum what function do we use to count things in python len right stands for length so if i have number of defects and i drop it into the len function it will tell me that i have 204 data points and you can essentially count just about anything in python using len all right if i want to find the biggest value in a set or the smallest value set what what functions do i use max and min all right so let's do that let's take number defects we'll drop it into max drop it into min and we get that big value of 99 and our smallest value happen to be a two sweet all right a lot of statistics is basically telling you stuff about your data how many pieces of data do i have what is the highest thing what's the smallest thing one of the things that we often talk about like what's the average grade in a class or what's the average weight of people in doing this thing right what's the average of age of folks in a particular group python has tools to to look at that and when statisticians look at that kind of information they typically point to three main things mean median and mode mean is also often referred to as average and it's probably the one you're most commonly associated with so i'm going to walk you through how we can calculate means medians and modes using my lousy code all right so here we'll start off with calculating a mean if i drop a series of values into this particular function it will try and figure out a what is all of the a values added together and then it will divide it by how many values do we have okay so do that and so let's just use a really simple set of values these four things the average should be like two and a half if my math is right and if i do this one the average should be three right pretty straightforward anyone want to take a guess what the average is for our bigger data set any thoughts wow that's amazing well done all right all right now i'll show you in a little bit some other libraries that walk you through doing means and we'll talk about some of the benefits of using those all right but now i basically have an idea of kind of where is the average number and it's somewhere in here between 9 and 10. okay now let's go look at medians so median is a little interesting uh the point of medians is to find the centermost value if i've got 11 things it'll find whatever's at position six if i've got five things it'll find whatever is at position three right it doesn't really care if it's big little tiny whatever it just says you've got this number of things let me find whatever's stored in the center all right but there's a caveat if i have an odd number of things like 1 3 and 5 the 3 is clearly in the middle but if i have 1 3 5 and 7 what's in the middle and how we typically solve this is we take an average of whatever the two things are in the center and so my code will do that the nuance here is before you find whatever's in the middle you need to sort them so we're going to sort all the values we'll calculate how many values we have we'll figure out what is the midpoint and then we will return it if we find out that there are an even number of values we're going to do this thing where we we average we find out there's an odd number of values we just give you the center point all right so i'm not going to walk you through the code in too much detail you can take time to look at that if you want but let's just see if it works sure enough it gives me a 2. this one remember we have to sort first so it's going to move the 42 to the end and it'll find whatever's between the 5 and 6 which is a 5.5 all right and i know this guy's already done the math in his head right he knows what the number of median number defects it's an 8. okay so we can take an average which you're used to we can take the median find the middle most point mode finds whatever shows up most frequently all right for this library i'm also going to use counter to help us with this we're going to count all the values we will find whatever value shows up most frequently how many times it shows up and then we will go in using another list comprehension and if you're not familiar with these i highly recommend you go figure them out because they're really awesome we'll go and say all right the maximum number of things was 24 things showed up let's go see how many items showed up 24 times and this list comprehension will give me every value that had 24 entries in my count so let's go take a look here the number four is going to show up three times so it will show up most frequently so we should get back a four um notice just a nuance here with mode i choosing to return a list of uh of items because sometimes certain things more than one thing may show up most frequently like this list one shows up three times five shows up three times so i want to get both of those back so it's going to return a list with both of the things that showed up most frequently the one and the five um just a nuance about that right we talk about kind of the average most the time in our heads we tend to think of there is only a single average when you start talking mode you can have bimodal or trimodal data sets where spikes of things occur there's a book that uh that i kind of like for folks who are new to statistics head first statistics and they talk about this ages for this group of folks in this class and it's a class for adults and children to do like swimming together or something i don't know and when you look at the ages the average ages you have these very young children and you have these older adults and so your average age is very different and it's split right so that's the thing that you'll see in many cases with mode all right so let's go look at the most frequent values in number of defects it was 8 and 6 just like we saw earlier all right so a couple of nuances of when we might use these and and some of the the benefits of using them i've got a little table here mean you do this sum of the values and you count how many values you have you do the math this is most commonly used when your data kind of has symmetry to it and it has a single trend one single spike the median is often used with data that might be skewed a little bit to one side or the other and might have some outliers it's kind of a way of of dealing with the fact that your outliers will throw off some of your results and then mode it's different from some of the others because you can actually use mode with things that are called categorical data and you'll hear that in statistics what categorical data means is it doesn't have a number value like if i had a list of data and the data just simply said male female or the data said you know part a part b part a part a part b part b those are all categories right and so modes can show us what is the most frequent part that showed up what is the most frequent examples of things and you don't have to have a number for them so categorical data can be done with modes and it's also good for things as we mentioned that have more than one trend all right we did a fancy histogram graph but sometimes just having a quick frequency table can be really useful and so a frequency table would be something like this where it shows hey the value 9 showed up 3 times the value 6 showed up twice it's much like that counter example we looked at if we look at our defect counts the frequency table is not specific to mode it is the counts of all your values mode is highlighting the things that show up most frequently the frequency table shows up the values of all of them notice where did it go in my frequency table it showed up that eight appeared only once where mode is going to show me the things that appeared most frequently mode would give me the value 9 showed up three times or would give me the value 8 and 6 showed up 24 times does that help good all right so what i'd like you guys to do and i'm going to shrink this down give you guys a few moments to kind of start to wrap your head around some of these things um i'd like for you to calculate and you can use my functions if you'd like they're good enough for government work here and go through this calculate the mean the mode the median do a count on these things and go through the exercises and we'll give you guys a few minutes to do this i want to caveat this for just a moment though some people may not finish all the exercises in the time allotted that's totally fine go home reread the material do the exercises again finish the exercises you didn't finish that's all good just a little back story here right and i'll show you my list of books that i've read i've read the statistics books of various sorts over and over again and even in the course of preparing this particular set of material last night in my hotel putting final touches on i was still picking up nuances that i had not seen before and still learning new facts and details that had kind of escaped me so there's a lot to cover as we get further on in this in this conversation so don't hand if you're like oh man i didn't get all of it i didn't capture it yeah i still go back and reread some of these books and catch nuances so all right um we'll give you guys probably about 10 minutes or so and we'll wander around and ask answer questions uh again if you guys run into any snags is sure so when you have just one heavy some of your things notes all desiring right so i think it's been about 10 minutes all right the little microphone appears to be back all right i'm not going to do the entire exercise i'm just going to highlight one or two things so mean let's see grab some of these guys and say values right and this was a nuance that i think jeff had mentioned right if you have two commands in a single cell both of the commands will run but only the last command will display to the screen so if you wanted to have both of these display you have two options you could either put each of them mean and median in two separate cells that works fine that works fine or you can do some of that extra typing and you can put the word print in here for the first one and it will print and you can put median values so it will print the first one and then it will execute the second one notice we get a slightly different output print actually displays to the screen median values actually executes and is released as an output but that's a nuance all right so let's see let's talk about measures of dispersion how widely spread is your data is your data really tightly clustered or is your data just all over the map okay you will sometimes hear in statistical books about things like measures of variability how much does the data vary or measures of spread they all essentially mean the same thing a fast and dirty measure of spread is simply let's look at the minimum look at the max and see how far apart they are right and so that's what this does my data range function just says what's the max what's the min and divide or subtract one from the other and so with my little data set five three four two and one the smallest thing was a one the biggest thing was a five and the spread is four points notice with my batch defects the smallest value was a two the biggest was a 99 so my spread is 97. that's a lot remember that 99 is potentially even an outlier or something so here i can see that my data is really far away from the median and the mode and the mean right so this may be a flag or maybe something of interest it will depend on your data all right a couple of the downsides though of using simple spread are the fact that they are very susceptible to outliers here i have two data sets that are almost identical except for the last two values the 8 and the 99 you would probably say these these data sets are are pretty much the same and so when i have this one thing with this minor outlier man it throws everything completely out of whack and it makes it really hard for me to realize or to know that essentially these data sets are basically the same all right so how do we get past that that's where things called quantiles and interquartile ranges come into play let me zoom in on this just to smidge all right so you're going to hear some of these words these are the words that that really bothered me i never knew what they meant for a long time um a quantile is it's a cut point or a dividing point right in a sequence of values and those cut points will break those values up into what we call contiguous intervals or intervals that butt right up against each other so they have a nice continuous flow and those cut points are de defined essentially so that they break up all of your values into equal probabilities the stuff in this lower quantile has as much probability as appearing as the stuff in the middle et cetera et cetera quartiles are values that cut your data into quarters they are essentially a quantile that breaks things up into every 25 percent an interquartile range is a range between your lower quartile and your upper quartile normally that's between 25 and 75 although you might see them with different values all right so let's put this into practice and see what we got all right quantiles so again these are kind of these cut points um if i have six values and i've got a cut point in the middle it breaks my values into two sections that middle in our case would be the median if i have a lot more values i have a value 1 and 62 63 and 64 65 and 70. this breaks up my range of values into 10 quantiles and potentially if i want to kind of weed out some of those outliers i could say i really only care about all the things that fit between this lower quantile and this upper quantile and so i kind of filter out whatever's on on each end and that gets rid of the one it gets rid of the 99 all right so let's make a function that helps us calculate where a given quantile falls so i make this very simple function give it a handful of values and tell it where you'd like your your quantile to break and it will then figure out in a list of values or sequence of values where does that fall what is the index of that point and it allows you to get back a value from your list or your sequence again this is not robust code do not ever qualify this or use this in production but it's good enough for for what we need to do here all right so i've got a list of like school grades there's 10 values and i say hey i want to find the break point whatever is in the middle essentially trying to find a almost a median it sorts everything first 55 ends up at the bottom 96 at the top and then it roots through i'm going to caveat this right this code was not sophisticated enough to realize that if i have even numbers i should take an average between the two this is again just to give you guys a demo if i had an odd number of values 11 in this case we can use that as well but again it's not going to be very precise all right what if i want to find those quartiles the 25 value and the 75 value i take these grades and i say hey look for whatever grade is closest to 25 of this sequence of values and give me whatever is closest to 75 and so 67 is kind of the lower lower bound of the lower 25 percent of my students and 91 is kind of the upper bound of the upper 25 percent of my students now all right if i want to kind of see where my defects break out using a variety of percentiles like the lower 10 percent the lower quarter the upper quarter 90 95 and 99 i can do that and so the value of 4 is right at the boundary of the lower 10 percent value of 6 is at the boundary of the lower 25 we notice that value of 99 is way above the 95 percentile okay so if i were to say i only want to see stuff between the 25 and 75 i filter out all the lower end stuff i filter out all the highend stuff and this is a great way to kind of get a sense of what the middle of the pack looks like so let's do that we'll apply what we just created to to look at some interquartile ranges um commonly you'll see like 10 and 90 20 and 80. depends on what you need in our case we'll have a lower quartile boundary an upper quartile boundary and i tell it hey here's the values we're going to give it's going to use my function quantile for a minute ago and say 75 is my default value 25 is my not default or my lower boundary and let's see how this works it says chalmer if you give me these 10 values 3 is roughly around 25 percent of the way up and eight is roughly 75 percent of the way up all right if i want to then do that math and say how big a spread is this i just subtract one of them from the other and we see that 8 minus 3 is 5. so let's do that with my batch of defects and it says hey chalmer if i'm only looking at 25 and 75 your range of values was only six it's only a spread of six right now that function i created seems a little weak because it's built in it hardwired in 75 and 25. so let's build upon our function a little bit and let's give ourselves the option now of adding an upper bound of our own choosing in the lower bound of our own choosing okay and so i'm going to look at my number of defects but this time i want to look at everything from 10 percent all the way up to 90 percent i'm going to see how big a spread that is and here that spread is a little bit bigger a little bit wider all right so what are the downsides of using an interquartile range it seems like hey i can kind of filter out those those outliers that's good interquartile ranges they only tell you really the difference between a high value and a low value how far apart are they they don't really tell you how closely they are knit to things it doesn't tell you how frequently those high values occur or how frequently the low values occur versus how frequently the stuff in the middle occurs so we would theoretically want a method to more accurately measure variability and we'll look at that in a minute so we'll give you guys a break if people need to walk around stretch whatever you can do that as well spend a couple minutes here say five walk through calculating a simple spread calculating some quantiles and then calculate an inner quantile range for these numbers and of course i'll ask questions or i'll answer questions one nuance for this second one you guys should pay attention here we're going to use the range function to create a sequence of values from 200 all the way up to but not including 300. so if you've never used the range object to create a sequence of numbers for you we have that here this is how you would do it all right and we'll cut you loose when you're done put up your little green stickies if your green sticky is still up take it down all right let's get started awesome all right folks so if i want to bang out an interquartile range for all these guys i can say range 200 to 300 with a step of 5 for those who are not familiar with the range function the second value that you put range will go all the way up to it but it will not include that value and this third number you can give the range function tells you what step to take and let's see to calculate my interquartile range i want a 0.25 and a 0.75 but those are the defaults so heck with it let's delete that and we should get back a 50. and that sounds about right because there's about 100 difference between the two all right so let's talk about something way more fun let's talk about variances in standard deviation all right so there's a couple of different techniques that we can use to evaluate the spread of data that's a bit more effective than simple interquartile ranges or simple spreads interquartile ranges is good for fast and dirty it's very nice but variance and standard deviation are one of the the workhorses for statistical evaluation um one thing that you may be tempted to say is well if i want to get kind of figure out how much things vary i could take the average of you know what is i take the average and i could subtract that from each of my values and i get this average difference from the mean and that may look like it'll work but what ends up happening is all of the things that are above your mean and all things that below your mean cancel out i'll let you guys read the details we're just going to skip right by that let's talk more about variances okay um with a variance we do something very similar we have an average and then we subtract the first value from the average the second value from the average the third value from the average and we square that to get some sequence of numbers the benefit of squaring which doesn't happen in that previous thing that i skimmed over is that these all end up being positive numbers now they can't cancel each other out because some are positive and some are negative and so in this case i have these three numbers one two and nine the average is a four i calculate what's called the variance and i get this number 38 and that gives me some sense of how much or gives me a total 38 and then i divide it by 3 sorry math is hard i divide by 3 and i get a 12.6 so it gives me some sense of what the variance is and you may look in your head and you go i don't even understand what variance means because how did i get a 12.6 to tell me how much stuff spreads when my numbers don't even get up to 12. i have a one two and a nine and you're going to tell me quote unquote the variance is this 12.6 thing and so some of you are sitting there and you have this quizzical look on your face and that's the same critical look that everybody has which is why we go one step further we use a thing called standard deviation before i talk about standard deviation the nuance here though that you can get is if i were to change these numbers and spread them out a little further potentially my variance may get bigger my variance gets smaller so if i have two sets of data and one variance is large one variance is small the one with a larger variance is spread out more the one with the smaller variance is spread out less so the number itself may not jump out at you and you go that means something but numbers or variances from separate data sets can give you a sense of one spreads out more than the other but again variance is kind of this nuanced thing like people like i don't even know what that means so we'll we'll do a function we'll look at this happening and working and then we'll move on to standard deviations all right so i calculate this by using the total number of values i have a function that calculates the difference between the means i square them i will let you guys do this again this is not production code this is chalmers sitting in a hotel room um all right well let's try and detect or determine what the number the variance is for our number of defects and we need some bizarre number our variance is 80 and again that means nothing to me right i don't have a sense for what that means because no one gets a sense some folks thought this through and they're like is there maybe a better way and standard deviation is a potentially better way and i'll show you some examples of why to get the standard deviation you calculate the variance and then all you do is you take the square root of it it's pretty straightforward so i calculate the variance same way i get 38 divide that by the total number of items i get a 12.6 and i take the square root of that and i get 3.55 and again you kind of may be saying in your head i don't understand what that means the nuance is that as your standard deviation gets bigger it means it spreads more as it gets smaller it spreads less but we'll see some graphs related to this later that standard deviation fits very nicely on your graphs in a way that helps you to get a good sense of how things play out all right when we use data sets and we calculate a standard deviation one thing that they have found is that on a typical kind of bellshaped distribution a normal distribution and a lot of data tends to fall into that category if i calculate the standard deviation kind of how wide is the spread away from the mean 65 percent of all of my values are going to be within one standard deviation of my mean 95 percent of all my values are going to be within two standard deviations and 99 will be within three standard deviations so let me shrink this down just a smidge so we can see this all on the screen there all right so i have an average i have a mean in the middle i've got some sort of bell shapish curve and if i can calculate my standard deviation right here standard deviation above the mean and one standard deviation below the mean everything in this gap is going to be 65 of all of my numbers will fall right there in that that middle zone if i stretch out two standard deviations above the mean and two standard deviations below the mean 95 of every one of my numbers is going to fit nicely in that little that little grouping and if i calculate out three standard deviations 99 of stuff say well how do i use this what does this mean well much like we use the interquartile range to say let's drop all the values that are 25 percent or below all the values that are 75 or below or above we can use standard deviations to say i only want to see the 99 of the values that are closest to the mean and any of these little outliers that are way out there in the far corners let's ditch those or i really want to get kind of a little closer and i want to see 95 of my values that are closest to the mean and so standard deviations can help us grab those when we're using something like a normal distribution this may not apply with other distributions but it works quite nicely with normal distributions these bellshaped curves all right let's see this first picture kind of spiky the data is fairly closely clustered on the average this next picture a little less spiky it's a little wider and in this case because the graph is a little less spiky my standard deviation happens to be bigger and so remember i mentioned that like if you're looking at two different data sets and a standard deviation is bigger it means that data set spreads out more and so because this spreads out more my standard deviation is bigger but the same rule applies even though this spreads out more if i want to get 99 of all my numbers and drop off the one percent outliers i measure out three standard deviations and boom i've got the 99 that i care about okay all right so i've got a fairly straightforward and let me make sure i ran the variance formula earlier let's see so i got a fairly straightforward standard deviation calculation here it uses my variance function that i created earlier does the math i have a fairly narrow data set all the stuff's pretty close together the mean is five we have another one that's a little bit broader it goes from one to nine but the mean is also still five and so let's look at how these two things calculate out the mean is five my standard deviation was 1.4 this is a little bit broader data set still has the same average but my standard deviation is a bit bigger so now i can immediately go this one is a flatter bell than this one potentially right all things being equal okay how do you interpret that what does it mean all right the nuance here essentially is that when you're looking at your data and you want to kind of know i have an average how much does stuff spread out on one side or the other or both the standard deviation is going to point you in the right direction to say this is really close to the mean or these are very far from the mean and so in this case you know my numbers start at three they go to seven they're all really tightly clustered around the mean this one starts at one it goes up to nine they're spread further out i can immediately tell that there's a bigger spread between two data sets just looking at one data set and knowing that okay the standard deviation is 1.4 may not tell me a lot about that one data set but being able to compare them is really useful another thing you know as that number gets smaller and smaller it means your your your spike is a little spikier right things are narrower things are closer uh and a key role for the standard deviation again is kind of helping you figure out how do i get rid of some of those outliers how do i look at my data set and say i only want to see the stuff that's from like one percent all the way up to 99 and not look at the things outside of it or where should my cut points be to look at just the 95 percent where should my cut points be look at just 65 percent of the data and so standard deviation can help you with that all right did that help good let's talk about how real pythonistas calculate standard deviations and variances and those types of things using real python libraries instead of my hotel code okay we're going to look quickly at four different libraries and i will highlight a gotcha that may strike if you do not pay attention and if you don't kind of dive into the nuts and bolts so the four libraries we're going to look at there is a statistics library this is brand new in python as a version 3.4 it incorporates a sequence of statistical functions and it comes with python so if you download python all by itself you've got it you don't need to get any thirdparty libraries which is quite nice we'll look at numpy numpy allows you to build these array objects and allows you to do various fist calculations on these types of objects that are very fast as techniques and tools for integrating c and c plus plus libraries and fortran code again to get closer to the bare metal and make your code more efficient and more faster it has techniques to be able to broadcast calculations and evaluations against large arrays of data without having to write for loops and stuff and it's useful for like linear algebra and those types of things scipy library has a collection of mathematical algorithms it's got some convenience functions that are built on top of numpy because it uses numpy under the hood adds a lot of power to your python sessions and then we'll look at pandas which is a common data science library does data analysis and those types of things all right so we'll start off by importing each of these for some of these libraries it's fairly common to import them with an alias like import numpy as np it makes it easier to type some of the commands you might want to use later all right i'm going to start off by creating a simple numpy array and we're going to use my defects batch file okay one of the things that i often mentioned to students who are using a new tool a new library and they're making new data types i often recommend to them that they do a couple of things when you make a new object often tell them go find out what the heck this thing is that you just made and so i say hey what is defects and it says hey chalmer defects is a numpy array and if i've never used a numpy array i maybe need to figure out what that means if it spat out and said hey chalmer you just made a list i'm pretty familiar with lists because this is a numpy array and i don't really know a lot about what numpy rays right i might want to try and get a sense of what types of functions or methods are available to me so we're going to use a technique called tab completion and this is really useful in jupiter notebooks i type out defects i put a dot and i hit tab and it brings up this list of all the types of methods and functions that are available to me all right there we go nothing like moving your laptop in the middle of a talk okay um notice this is in alphabetical order right so it says things like all and any and da da da and there now we're going to the b's and the c's and the d's and this is a huge list of things that you if you are mathematically and statistically minded can do with a numpy array you can't do these with lists etc um we are not going to go into the depths of this i'm just going to kind of scroll through get a sense there's a lot of things here notice they do have a method in here called std short for standard deviation they have a method called var which is standard for vary or short for variance all right i'm going to start off simple and i'm going to say hey let's use the mean function and so we'll calculate mean and sure enough the average is 9.96 as this fine gentleman mentioned earlier a wheel caveat there is no median function associated with an numpy array the numpy library has a median function and you can drop your array into the median function but there is no median function that hangs off of your array which i found very interesting as i was researching this um so we say give me the the median and sure enough it spits out an 8 and that's quite nice if i want to look up the variance and the standard deviation without using chalmers crappy code we get an 80.8 and we get an 8.9 awesome let's turn to scipy i'm going to run all four of those mean median var and standard deviation um we get 9.96 we get an 8.0 80.8 and 8.9 looks good one thing you should know as i mentioned scifi kind of rides right on top of numpy so if i go in here and i say i like this numpy mean method but i'm not real sure how it works i'd like to know more about it you can ask this question mark and you put the question mark in there and they'll give you the help file for it so look at that and now we have access to all of the arguments that i can give it i give it my array and if i want to do certain things i can have it change its behavior i don't know what any of these mean right axis d type what is all of that well i can scroll through and it will define for me oh here's what axis means and here's what d type means and so i can figure some of those things out tells me what it gives me back it says i'm going to give you back this that or the other and you can kind of get some sense of what's going on might give you some notes as to other things you might want to look at to see if other types of calculations might be useful to you that's cool happens to be really nice and give you some sample code if you tried to get it to work and it failed maybe you look at the sample code and it helps you out that way all right gives you some caveats in certain cases this might be slightly inaccurate buyer beware okay it tells you where it pulled it from and it said hey you know what we got this out of the numpy library and it's from this thing called fromnumeric.pi which is awesome if i were to do this same thing with scipy.mean we see i can call psi pi.mean but interestingly enough all the documentation is exactly the same and when i get down to the bottom sure enough it actually just calls numpy under the hood so um like i said your mileage may vary okay the statistics library statistics library has mean median variance and standard deviation notice the spelling is different right they actually call it variance instead of r they call it stdev instead of std all right and if i run that what's wrong my numbers are different in particular which two numbers are different the variance and the standard deviation here are not the same as the ones we saw before so let's go take a look 81.2 and 90.0 oh there's a lot of stuff here and we had 80.8 and 80.9 8.9 so they're different all right why anyone know why yes he mentions there's a difference between population variance or population standard deviation and sample variance or sample standard deviation all right so now that our heads explode let's go take a look at what that means when you calculate a what's called a population standard deviation you are looking at the amount of dispersion for an entire population and we use a particular formula for that this formula we take the difference from the mean for every one of our values take the square we divide by n and we then take the square root so n is this denominator and in this case for population standard deviation the n is a larger denominator than the next example we'll look at all right and for your convenience and later reading i spell out what each of the symbols is and why they're there let's go look at a sample standard deviation a sample standard deviation is just a sample that estimates what your deviation for a bigger population should be if we take a random sample out of that bigger population and it uses a slightly different var value as the denominator and minus 1. because n minus 1 is smaller than n the size of this standard deviation tends to be a little bigger than for populations all right so when do we use population versus sample we tend to use the population when we know the entire population we have all of the data in our hands we use the sample version if we are looking at a subset of a much bigger group of folks so if i'm a teacher and i have 25 students and i have all 25 grades i can use the population because i know everybody's grades if i am looking potentially at my students grades as some sort of a sample of the grades across the school or across the school district i don't have all the grades for the larger population i just have my sample so i have to use the sample standard deviation all right another example if i'm a researcher and i'm looking at the relationship between women exercise and blood pressure right i might use a sample standard deviation because i only have a subset of folks that i polled or surveyed or researched on i don't have all the folks in the world right okay so that's why we have this difference because that silly denominator at the bottom is off by a smidge because we're either looking at a sample or looking at a population all right the numbers are typically very very close together if you're doing comparisons one to another but you use the same formula your comparisons will give you an order of magnitude difference all right if you were in a competition like a data science competition and you need to have the right answer you may want to choose the right function all right so let's go look at one last example this is the pandas library and it has mean median var standard deviation notice they went back to this kind of spelling of var and std let's run these guys it uses that same version of variance and standard deviation that the statistics library did okay all right so just a nuance be aware that it happens oh sweet for those who don't know pandas in this library allows you to create a set of data and i take a list i drop it into this series function and i ask python what do i get back pd i say hey you have a series and you go okay so what is a series a series essentially is a column in a data set you can imagine a series being like a column in an excel spreadsheet so it takes this list of things and throws it into a column you say what does that look like in real world defects pd printed out and so it says hey row 0 had a 99 in it row 1 had a 52 row 2 had a 42 and it's got all 204 pieces of data this is not a pandas class but with a panda series you've got all sorts of capabilities like you can do aggregations and you can do groupings and you can calculate means and medians and all sorts of other things there's about 224 different types of things you can do to a panda series to help you do your data analysis you can break it up by quantiles they have a whole library for helping you with a whole module for helping with quantiles and stuff it's a lot of cool things all right did that help okay two more questions go how um so what if your data set for example doesn't fall into kind of a nice normal bellshaped curve all right so that's that's a really good question that i do not know the answer to of how well your data needs to fit in in the normal the normal distribution for that to work well um i don't know if alan has any insight into that the question essentially is yeah there's there's lots of curves but the question was when you have a data set if it's not necessarily a nice bell curve and i try and do a standard deviation how easy is it to basically shoot myself in the foot right if if my data doesn't fit a normal curve is my standard deviation just going to give me really wonky answers sure so that is one of those nuances that regularly using these tools and reading about it again this is a threehour class right right diving into this um one of the great things that you'll see when you start looking at research papers where people are using statistics to prove a point is they use statistics incorrectly and the point they're trying to prove is not what the data really shows right and it's not because necessarily that they're being malicious just because they're trying to apply a thing you know round peg into a square hole kind of a thing and that just doesn't work so it takes time it takes effort to dive into this research it figure it out i will show you some of the things that are available to us in some of the tools like scipy and just it is mindblowing the number of options that we have available to us and so that would play into kind of your question yeah you had a question too all right so if a standard deviation is larger it tends to be sample if it is smaller use population so let's go back and look right well if i if i dump the same data set and i'm going to let me get rid of this guy clear output if i have the exact same data set which i do i i'm using num defects and i drop it into scipy i get a slightly smaller value than i got when i put it into the statistics library so a smaller value means a library is using population standard deviation a larger value means as being sample but having said all that there are ways to tell the library to do the thing that you want so let's take a quick look at that all right okay so psi pi dot in the scipy library for standard deviation they have a thing called this delta degrees of freedom and it identifies the divisor that you want to use and so you can have n minus something and then the normal is n minus one right the default that they use is zero so if i needed psi pi to do the reverse of what it normally does i can simply go into the function and i can set this degrees of freedom to be 1 versus 0 which is the default all right so again it's just a matter of you need to know that it's there you need to know it's kind of a problem that you have to kind of answer um so all right let's see what else we got um i think in the interest of time holy cow how did the day go by this quickly we're going to skip the exercises here's a list of cool books and i start from the lower end of the scale to the higher end of the scale my first book i ever read on stats outside of high school was this cartoon guide uh it was a low pressure guide to statistics it covers way more than we're going to cover in these three hours the manga guide i got from my kid he liked it head first statistics by o'reilly is a book that um spells things out in a way that i find to be really really uh useful naked statistics is a little less about how one does it and the maths and more about oh my gosh how do you not do it wrong um and he talks about a lot of good kind of case studies and examples of people using statistics in the pros and cons he's very light on the math more on the this is awesome statisticness so this is a great read statistics in a nutshell that's fairly dense it's a good reference book i like it because it puts all the stuff in a small amount of space but i found that had i read it before i read maybe head first or even the manga guide that might have been a little too intense for me i think stats think python and think bays are great and for those who don't know that guy over there he wrote them and this one um is a little wonky and if you go to amazon and you look at the cover of this you're like oh my gosh but it is very compact and it spells out a thing called bayes theorem and it spells it out in a way that's kind of visual and it was quite nice all right and for the record uh mr allen uh who literally wrote the book yesterday we're talking he's like hey do you want a mentor in your class and i'm like yes okay so he's judging me by the way all right thanks um so let's move on to the next thing and let's cover this let's go through this we're going to shift gears we're going to talk about probability now the likelihood of something happen we're going to figure out how we can calculate the probability of something happening we will explore probabilities using what we call venn diagrams we'll explore probabilities using probability trees and we will talk about the principles behind the law of total probability and behind bayes theorem and we'll see a couple of examples of that all right uh i like the definition from sarah in statistics in a nutshell probability tells us how often something is likely to occur if we repeat an experiment right so let's expand our understanding of probability with a couple of definitions you'll hear reference such a thing called trials or experiments or observations a trial is some event where you don't yet know the outcome trials can be crazy easy i'm going to flip a coin i'm going to roll a dice or it could be someone has a low birth weight will they graduate from college 22 years later right sample space is essentially all of the possible outcomes of a trial so i have a six sided die i roll it all the possible outcomes are one two three four five and six say i drop four coins in a bag i've got a quarter a dime nickel and a penny if i draw one of those out my sample space will be quarter dime nickel and penny an event is the actual outcome of a trial events could essentially be singles or could be groups of things we will often designate an exam an event with an e so if i roll a die and my event is that i get a one on my die e would be this set with one in it if i want to specify that um my event is that i get an even number my e would be a 2 a 4 or a 6 when i roll that die so you can have more than one thing in your event now if i'm going to calculate a probability this is pretty straightforward i take how many elements are in my event divide that by how many elements are in the sample space and i get the probability so the probability of rolling a one on a sixsided die is one divided by six and that math turns out to be like 0.16 or something so let's throw together a pretty straightforward function that'll help us do this for those who do not play d and d in those types of games a d6 means that your die has six sides a d8 means it has eight sides so let's make a real quick function that returns a one on a d6 and so i would calculate 1 divided by 6 and i get back sure enough to do 0.16 and that's crazy limited you would never want to write multiple functions for every single case so maybe we want to expand this a little bit make our probability function better able to handle a large sample size or better able to handle an event so i set my count to be one and i divide it by the sample size all right so if my event was i roll a four on a six sided die the probability of a four showing up is this the astute observer though goes wait wait chalmer we dumped in event but we never actually used it that's screwy let's go fix that all right if my event is composed of more than one thing i want to determine if i get a 2 a 4 or a 6. we need to have a way to determine that all right so i'm going to make a small list let's say my event is i roll less than a four i roll one two or three on my die um i start off with saying hey let me check did chalmer just give me a list or a tuple or did it give me a single value if he gave me a list we'll count how many events are in it one two three and we'll use that to do the math if he gives me a single item then we'll just call it one it's all good all right so one thing that we often do in in python is alias things maybe give them shorter names i do not want to type probability a lot so i'm going to give that function a new name called p so it'll make it easier to type stuff so if i have a six sided die i have six items in my sample space and i'm looking for a two the probability is point one six on the other hand if i'm curious like what what is the probability of getting a four five or a six out of a sample space with six items that's one half all right if i'm looking for odd numbers on a six sided die one three and five again i have a 50 chance of getting an odd number alrighty out how many items are in a sixsided die is pretty straightforward but when things start to get a little more complicated that's where venn diagrams come in and you guys have probably all seen these we use these to represent elements in your sample space using very simple pictures so i'm going to show you a representation of rolling the odd numbers on a d10 all right so i've got a d10 it is fairly common in venn diagram land to put some sort of a rectangle in that rectangle represents all the possible values that you could have it is also fairly common to draw some sort of an oval or something or a circle to show the things that you really care about and in this case i only care about odd numbers and i go ahead and i label those one three five seven and nine um i meticulously went ahead and said everything outside of that oval is all the other stuff i do that for clarity but most the time we don't bother right it is presumed or assumed that everything in the rectangle is all the other stuff if i need more than one oval to represent two kind of related events that i care about i can put more than one over we'll see that in a bit um make sure to miss any of the things okay i'm going to have you guys go through your little notebooks etc um sketch out a couple of simple venn diagrams you don't have to make them huge or anything start wrap your head around this idea so this first one for example we're going to have one thing that we care about out of a list of 20 items on a d 20. and then i would like you to do is put together some python code that calculates the probability of getting 1 on a d20 this next event is a little bigger i'm looking at just the odd items on a d10 i've got an example i want you to consider what would we put together to represent i think it's all of the aces oh picking a single ace out of a deck of 52 cards right and so write some code to do that you have to figure out what your event space looks like or your your um your event looks like and what your sample space looks like so spend a few minutes do that and put your green stickies up when you get done there's about five or six i think what we'll do is we'll give this about seven minutes and then we'll roll on so i'm gonna set a timer seven minutes all right okay um yes got about two minutes left then we'll roll on don't panic right none of us is walking out of this room a guru except for that guy thing is though he walked into the room a guru so he had a leg up on all of us about 23 seconds all right so let's take a quick look at this i'll look at the one that kind of raised the most questions numerous people asked about this so p say i have 52 cards in my sample space and i have four items in my event number of people typed in 52 comma 4. our code is not yet sophisticated enough to deal with that our code blocks what we need in our code at the moment is to put in a list of items right so you know an ace of clubs a ace of hearts and ace of spades typing is a horrible thing in front of people and an ace of diamonds right and i'd say hey it's about a seven percent chance of getting an ace out of a 52 card deck right if i were to type in a four get a much lower percentage and the reason being if we go back and look at the code the code said if it's a list tell me how many elements are in the list if it's just a number we're going to consider that to be a one um so we've discovered kind of weakness in the code like hey this this doesn't quite play nice let's go fix that all right but the long story short of these problems here and these are kind of one dimensional style problems is what's the size of my sample space and how many elements are in my event space all right so let's go look at our code to do that though we kind of want to expand on a few other things and then we'll get there let's talk about exclusive events and intersections most of what we looked at are just very simple venn diagrams little circle with a certain number of things in it there are some cases though where as i potentially try to create a venn diagram i might notice that wait i'm looking at maybe two different types of things and trying to lump them together in my event for an example say i had a d10 dice and want to know the probability of rolling an even so i have 10 sides evens are 2 4 6 8 and 10. that's 5. so that's 50 chance of getting an even chance of getting an odd is also 50 so the chance of getting either an even or an odd is a guarantee if i roll my dice i will get either an even or odd and so i can very nicely add these two things together and boom i can calculate what are the odds of getting or what is the probability of getting an even or odd so yes i have my little odd circle my little even circle and there's a total of 10 things in it my s space has got 10 things so it's all good but what happens if i do something slightly different what is my probability of getting something that is greater than a five when i roll that ten sided dice i have a six seven eight nine or a ten what is my probability of getting a number that is even two four six eight or ten my sample space is 1 through 10. notice greater than 5 and even have these kind of overlapping spots where 6 8 and 10 fall into both of those ovals if my probability getting greater than five is fifty percent my probability getting even is fifty percent and i add those together that answer is not right it would say that i have a probability of getting or i have a guaranteed probability of getting one of those two things and we know that's not quite true the correct answer of getting either greater than five or even is actually about point seven and i use the word about and it's quite literally exact right i have seven things in this kind of conjoined event one two three four five six seven my total sample space is ten so seven divided by 10 is 0.7 so what went wrong our original kind of let's add these two things together ignored unfortunately the fact that there's a little bit of overlap so we have this very cool formula that allows us to account for overlap i have the number of things in one event the number of things in a second event and if there's any overlap i just subtract out how many things overlap so i don't double count that ensures that i single count those divide that by the sample space and i get the union or the or of a and b all right so that's generic formula you notice i have this kind of u shape thing and i've got this fun of uh upside down u the upside down u means the intersection where things overlap uh sometimes you'll see that referred to as a cap so the number of things that are intersected between a and b this u stands for union it's kind of an or this is the number of things that are included in a or b all right so sure enough we do the math greater than 5 is a 50 chance there are five elements there odd is five elements there's an overlap of three we do the math we get seven over ten okay so let's start to explore this in practice we use my little python probability function i put in anything that's greater than 5 anything that's even and we subtract manually the things that we know overlap and let's get an answer and sure enough we get 0.7 so what's the probability of drawing a single red card from a standard deck or drawing a king well if i were to put that into my probability function we would see very quickly that this would just suck because i'd have to type out this big giant list with ace of diamonds two of diamonds three diamonds four diamonds etc and nobody wants to type that that's lame so let's tweak our probability function to say my sample size is maybe 52 cards my event could be a single element or if i already know how big the event is i can give it the event size there are 26 red cards i'll just say that the event size is 26. and then we add a little nuance in here it says hey if event size is a list count how many things are in the list so we still have that functionality if event size is an integer just use that as my count so we used a 4 before right all right so let's run this boom probability of a red card or a king there are 26 red cards in a standard deck there are four kings in a standard deck two of those kings are red boom let's go take a look at the answer before we get to the answer though sure enough with 26 red cards out of 52 i have a 50 chance of getting a red card with four kings out of a deck i have a 0.7 chance of getting a king but that little bit of overlap that we kind of have to suck out of there that's 0.3 and i get an answer of there we go my chances of getting either a red card or a king are 0.53 it's a little bit above half which is what we expect all right so what's the probability of drawing a red card or getting a face card a king a queen or a jack well how many king queens and jacks are there in a standard deck how many jacks queens and kings 12. all right so i say hey i've got 12 here there's 26 red cards how many jacks kings and queens are red six so i want to get rid of those because we do not want to double count them and sure enough it's a little bit higher because now we're looking at a few extra cards all right now you might say but chalmer why do i want to do all this math and write all this code because if we think about it all i need to know is how many reds are there how many face cards are there and take away how many duplicates and i get 32. so i can actually just say my sample space or my my event space is 32 cards are either red or they're kings queens and jacks and so i don't necessarily have to do this if i can kind of do it in my head or or do it manually you just got to make sure that you get event a event b and you eliminate that duplicate and boom we get the same value awesome so i'm gonna for those who don't know pycon has open spaces where people can gather with folks who do things that they like to do and one of those open spaces is board gaming alright so here's a board gaming example i have three games i have pandemic i have clank and i have carcassonne and in my board gaming group we have a number of folks who play pandemic a number of folks who play carcassonne the pronunciation of this french word is probably mangled by me my apologies and then we have clank some of these folks happen to be players of pandemic and carcassonne some of them play clank and carcassonne i have no duplicates or overlap between these two games now everybody in this oval this 12 and this six they're all part of a group so there's actually 18 people in this group this group has how many folks in the big circle 16 plus 26 and then the clank group has how many people in it 12. right um when i was putting this example together in my head i kept forgetting that these six folks were with these six folks and so my math was always wrong it was very annoying um that's why i pointed out pandemic folks there's 18 of them there are 12 clankers but some of them play more than one game all right so what is the probability of finding a pandemic player in my board gaming group who is also a carcassonne player huh okay well there's 18 of the pandemicers there's 26 carcass owners and then there's this nice little overlap of six we do the math and about 86 percent of my board gamers play those two games um but again if i don't want to type all this nonsense as long as i do the math 18 plus 26 minus 6 gives me a 34. we're all good all right there we go and the math failed epically for some reason why did that fail 18 26 is 34. my event size is 36. there we go that didn't work either 18 is 26 minus 6. 18 plus 26 is what 38. all right this is awesome i'm gonna come back to this this is great all right based on the fact that the code may be horribly wrong in some incredibly awesome way we're just going to skip those exercises and move on let's talk about conditionals all right during the next break i'll take a look at that and try and figure out what what where where my math and and all of that stuff went to rye all right let's talk about conditionals because this is going to lead to some fun stuff um one of the things that we really want to do when we start looking at probabilities is not just know when things kind of overlap but we want to understand if one thing occurs what is the probability that something else is going to occur if i exhibit certain symptoms cough cough hack hack sniffle sniffle what is the probability that i have a cold versus i have the what's the probability of i have the flu or the probability that if i have a tummy ache and some cough cough that i might have um food poisoning or something right so if you have one condition what is the probability that you have something else when we talk about probabilities we often hear the word given so if i know that a particular card is black what is the probability if i'm given that it is black what is the probability that it is also a king so i take a card out of a deck and i say it's black you can tell me what the probability is that it happens to be a king if i tell you i rolled a ten sided die and the number came back and it was a an even number you can tell me the probability that it was a 10. right to help us do that venn diagrams sometimes break down a little bit so a really useful feature or really useful thing that people will point to is this idea of a probability tree so for example i have a deck of cards they have 52 cards total some of them are black some of them are red i know that 26 out of 52 are black 26 out of 52 are red if i tell you that a particular card is black and i want to know what is the probability that it is a king i know that out of all of my black cards i have some that are kings and some that are not kings there are two black kings so there's two out of 26 right and there are 24 out of 26 that are not kings so there's 26 black items and they kind of fall out in this way same thing with red kings a couple of things we often talk about kind of levels on the probability tree so we have one level of my probability tree we have a second level with any set of branches here or a set of branches here the math always has to add up so that the total probability on that set of branches is 1. all right so for example 2 out of 26 plus 24 out of 26 is 1. right 26 out of 52 plus 26 out of 52 you add that up you get one you can have more than two branches if you play roulette you'll know that the squares on a roulette table are red they are black and there's two of them thrown in there for good measure that are green so i could have a roulette table probability tree that might say black square red square green square and i could have three branches but nonetheless the probabilities will all add up to be one on any individual level with a grouping of of branches okay to solve kind of across a single branch to figure out what is the probability of getting to the end of a branch you multiply the probabilities together so if i want to say i have a deck of cards what is the probability that i will have a black king i multiply 26 over 52 by 2 over 26 and that will tell me the probability that i'm holding one of the two black kings so 26 over 52 times 2 over 26 and i have a roughly 3 4 chance of holding a black king and so if 52 items 26 multiply that by 26 and 2 i get this now the rest of the branches play out the same way black and not a king red and a king red and not a king the cool thing is the probabilities at the end of each of the branches the probability is way out here three percent three percent and then like 47 and 47 they all add up to be one as well right so 46 it's about three or four percent another 46. and so when we add this up and we round it because you know math being hard um the total probability for any single branch when you add them all up is a total of one and that makes sense right okay now when we draw probability trees sometimes we throw out generic probability trees that other one was kind of specific king not king so you'll see this kind of nomenclature and syntax if i care about all the elements in a group called b anything that's not in that group you'll often see it referred to as b prime you might also see tilde b it just means anything that's not b so here probability that i get a b probability that i don't get b this is b this is not b um there's an a up there not a a and not a let's shrink this down a little bit all right all right so you'll see b prime a prime um you'll also see this nomenclature here that nomenclature is read in the following way probability of a given b so what is the probability that i get an a given that i'm on the b branch is essentially what that means here what is the probability to get an a if i'm on the not b branch or the b prime branch right so probability of a given b given not b okay and all that's spelled out in the text all that leads us to a formula if i want to know what is the probability that i get an a if i'm given a b i can calculate for the union of a and b or the intersection of a and b and then divide that by b if we pull out our algebra hats and we spin that around the probability of a or b is the probability of a given b times b say okay what does all that mean all right if i want to know the probability across a branch i simply multiply one of these by the other and i'll get the probability for that branch and this is going to be really useful to us in a second but that's what this second formula means to get to the end of the branch i multiply the first level times the second level for the branch i care about now a lot of times when we're given data and we're going to try and make this really cool probability tree we're not given all the data that'll be way too easy so there's a couple of rules and helpful hints that allow us to build out a tree first rule is or the first step we want to take is try and define the level of the tree in my black card red card king not king my definition of levels was okay i could get a black or a red it's a first level i can get a king or not king i could get a king or not king and i defined each of the branches if i have facts go ahead and fill them in put them down on the paper i'll show you an example that with a couple of pictures here in a sec once i've filled in all the facts i know i can do a little bit of simple math and fill in a few of the facts i don't know and then i can start to complete the branch groups knowing that the probabilities always add up to one and i can use that cool formula to then figure out the last remaining probabilities so let's see how this works i go out with a bunch of my friends at work some of them eat burgers some do not some eat dessert some do not right so maybe i want to figure out the probabilities associated with each of the branches given that some of the folks in the company eat burgers or don't eat burgers eat desserts don't eat desserts and i'm given three initial pieces of information the people who eat burgers two out of every three people eat burgers given that somebody is not a burger eater and they eat dessert that happens in one out of four cases and given somebody eats burgers and dessert that happens eight out of 15 cases so let's start to fill this in all right picture probability of eating a burger given that they don't eat a burger that you desert and then probability across a branch they eat burger and dessert so as i start to fill this in probability eat a burger is twothirds probability that they didn't eat a burger but they ate dessert is onefourth and the probability that they had a burger and dessert was eight fifteenths we know that this and this have to equal one so i go ahead and start to fill this in we know that this and this must equal one so i fill in the extra value so we're moving along making good progress one thing that we're kind of missing is this guy out here i know this and i know this and i know if i multiply this by this i get that so i can back out and figure out what this piece is if i know him and him and it's just algebra and when i say just algebra some folks suffer with algebra in high school etc don't panic just takes a little bit of practice so i don't mean to say that algebra is crazy easy all right so my formula says if i'm trying to figure out what is the probability of dessert and burger if i know he ate a burger and we know that uh he hit dessert and we multiplied that by the probability of burger this doesn't help me because i'm kind of missing something in the middle right i'm missing this guy but i know 8 15 i know two thirds we can do the algebra flip this over and put him on the other side and now when i multiply 8 times 3 and 15 times 2 i round it all down i end up getting a 4 out of 5. so i put 4 out of 5 up here and if we kind of go back and double check our math right 2 times 4 is eight three times five is fifteen it worked out just the way we wanted i know these two have to add up to one so i figure out what that is now i have all of the probabilities for every single branch i know i can multiply this by that to get here this by that to get here and there so now i can fill out the probabilities all the way across the branch okay so this is useful i now know that if somebody bought a burger and they didn't have a dessert that happens 2 out of 15 of my friends if somebody didn't buy a burger and they didn't get a dessert three out of 12 of my friends are in that horrible horrible group where they don't eat burgers and they don't eat desserts all right okay so let's do some math here with our our script right here i pulled all the values off that chart and i started to drop them in here for branch one probability of burger knot burger was two out of three so two out of three one out of three probability of dessert not dessert four out of five one out of five one out of four three out of four and if i add up all of these it should turn out to be one and sure enough it does all right so i have a reasonable level of confidence that my numbers came out the way we expected all right and this is going to set us up for a situation in a little bit where we can now move beyond this and we can answer some really interesting questions all right but for now we'll take a little bit of a break you guys kind of turn through this um what time does this thing end i always forget 4 20 for something 4 40. sweet so we have a little bit of time all right so i'm going to turn it over to you folks all right i want you guys to take some of these pictures i produced for you and this is going to mirror exactly what we just went through you'll have some data i want you to maybe put on a piece of paper or whatever start to sketch this out fill in the things that you know start to fill in the things you don't and then we'll go from there meanwhile i'm going to go back and look at those those two functions and figure out why i suck at math okay why did this fail 52 sure supposed to be a 46. you are totally right i could have swore i changed this because i saw it and i could have swore i changed it yeah that's it i'm good thank you sir so everybody just fled the room but they left their laptops which means it's open season on unattended laptops pick the ones you want and i'll come back with your question turn this off two thirds the reasons um this is uh right okay oh uh um foreign um uh so the whole way down wouldn't i wouldn't give for microsoft paint all right so when i first started going down this road um i'm gonna be perfectly honest lots of swiggly lines lots of slashes parentheses crazy letters and numbers and things that mean absolutely nothing yeah my mind exploded um it took doing this multiple times over and over again reading the topic in book a rereading the same topic because they didn't understand it in book b and then maybe sometimes rereading the same topic in book c and going ah i see what you did there right um so having said all of that right if you're trying to go through things and maybe you're drawing little probability trees and you're like i don't know what number goes where you're in good hands half the people in this room might have been in that very same same thing and be willing to admit it there's a bunch of other people in the room who are in the same boat but we're not willing to admit it okay in some of our examples thus far right we were given things here's a probability here is a probability of something happened given that i have a precursor i have a condition and then we have the probability that two things happen this n is kind of like an intersection it means and probably the guy had a dessert burger and a dessert if we picture this and this just those two for right now single probability and a probability with this given symbol in the middle of it and we scroll back up here when i just have a probability it goes first when i have a given it goes second and so this given probability is up on this upper branch because it's telling me this probability of not getting an a only applies if i'm on the b branch this probability of getting an a only applies if i'm on the not b branch so this given statement helps you figure out where that particular value fits in any one of these four things and then the intersection of hey my friend adaberger andy also or she also ate a dessert that intersection is at the end of our chain if i know the probability ate a burger and i know the probability had a dessert given that they had a burger i can figure out that intersection so kind of mental model where these three things fit probability probability given that i'm on a particular branch and then the intersection and so hopefully that will help you start to flesh out where these things go but again i read book after book looked at it multiple ways some authors are really horrible at explaining stuff some authors are really good some authors are genius all right so yep right there this picture yeah yes the reason they would equal one is i have four possible options there's no other options that my friends could have went down they had a burger didn't have one they had dessert they didn't so four possible options i have to fit into one of those four categories and so the probability of getting any of them is going to be one all right and here when i solve for the probability of branch 1 branch 2 branch 3 and then i add up all four probabilities sure enough i get a 1. all right so that's that so let's wrap up this conversation here with this idea of the law of total probability and the law of bayes theorem our bayes theorem all right when we looked at those first probability trees it was fairly easy to kind of hop from one step to the next um hey my friend had a burger and you know 10 of my friends who ate burgers all ate desserts that's great but how do i reverse that question if i'm talking to a friend and my friend says to me you know what man i went to the restaurant i had this awesome dessert it was crazy good a little pecan tart how do i figure out whether my friend ate a burger or didn't how do i determine the probability of whether he ate a burger or didn't because if he says or she says i ate a dessert i may know this value like my friend is either on this branch or my friend is on this branch but i don't want to pry i would like to just kind of figure out the likelihood that they ate a burger how do we get back to that and that's where the law of total probability and bayes theorem come into play so let's start with looking at the law of total probability i'm going to apologize right there's lots of mathy symboly things so again you're going to have to go back review this look at this and kind of work through this i'll blow this up a little bit so the font is slightly larger okay so let us presume that i want to solve the following problem given that my friend said yep that dessert was tasty how do i determine the probability they ate a burger all right we know that to solve for this i need to know these two things it's a formula we had further up on the page what is the probability of the ada burger and dessert divided by the probability that they ate a dessert we may look at this and say well chalmer already gave us a formula to kind of figure this out if i want to know what that is i just need to figure out what's the probability ada dessert given the head of burger times burger that's exactly what we just did a few minutes ago so okay check we can we can solve this it's going to take a little math but we can solve that how do i figure out the probability they had a dessert so that's something we're going to have to kind of figure out if i take that little bit and replace whatever was in the numerator before okay if i replace this with this so we're going to make a little bigger formula but again we kind of know all of these values here we still don't know what dessert is quite yet um but we're getting there we're filling this in with things that we can answer i can look up the probability one of my friends normally eats burgers and i can figure out what the probability is that they had dessert if they had a burger to figure this part out i simply go out to the ends of each of the branches and i look at the two branches that say dessert on them and i say what's the probability that somebody had a burger and had a dessert what's probably they didn't have a burger and they had dessert and just add those two things together if i can add those two together i can get the overall probability that one of my friends ate a dessert now the magic becomes these break them out a little bit and we can solve for what the probabilities they desert and that is the law of total probability all right let's take a quick look at this for a sec so knowing what we know we can go through and do the same process and start to fill in the little blocks we can start to multiply things out we figure out the probabilities that i received spam or didn't receive spam probabilities that there were keywords in the email or there wasn't keywords in the email probability that something went all the way across a branch when you figure out these numbers at the end and with all of those things i can go back too big and i can start to fill in this part of this this equation and figure out what the probability is the guy had to desert okay once you know that we can take that value probability they had a dessert replace it with all this nonsense and now on this side of the equation i can essentially go and look at my chart that i sketched out and i can start to put a number in every single one of these spots hey he had a burger i know what is does how much a probability he had dessert i know the probability they had burgers these two guys are exactly the same i know he didn't have a burger and i know the probability they had dessert et cetera and so you can start filling all those things and if you can get those six values i can now tell precisely the odds that my friend says they had a dessert i know they had a burger it didn't right so let's put this to the test there's a lot of things going on there let's take a quick look given that a spamish style keyword was found inside of a message what is the probability that is classified as not really being spam right so given a keyword is present what is the probability that it's not classified as spam you say well that seems kind of weird if there are bad spanish words in there doesn't that automatically mean it's spanish not necessarily my friend says hey chalmer here's a great book on getting rich quickly right um he's not spamming me he's sharing something that he found whereas if i got an email from somebody you know in a foreign country hey you want to get rich quick maybe that's spam okay so you could have keywords but the email may not necessarily be spam all right so i start off i've got some values we know from some of the research we've done that seven tenths of the email that comes in is going to be nutspam so i have a number to go with not spam we know that if something is on the not spam branch the probability that a spammish keyword is there is onetenth and if we know that or we can also calculate that given something is spam and doesn't have any keywords is three out of a hundred things so let's start to fill in that a little bit all right so we start to put numbers down seven tenths of my emails not spam three tenths of spam uh something was classified as spam but it didn't have any keywords maybe they're starting a new spam trend to write only three out of ten things are spam but don't have any keywords um this one is keyword given the fact that it wasn't spam only one tenth of the things that aren't spam have those keywords so now we do all the things right make sure each of these branches is equal to one these branches are equal to one these are equal to one we back this number out from there and we start to fill this in all right and then we do the last bit of the math we multiply this times that so 3 times 9 gives me 27 10 times 10 gives me a hundred 7 times 1 gives me 7. 10 times 10 gives me 100. fill in all these all right with every one of these values filled out like this and it's as we practice and as we get used to it it becomes fairly straightforward to get to this point apologize for the small fun i can essentially pluck values right off this chart and start going boom boom boom boom boom boom boom and i can fill in all six values and now i can tell you if i got an email that had some really cool spammish keyword what's the likelihood that it really isn't spam all right so let's blow this up a little bit so on the top i say let's go find out if it isn't spam and there's a keyword present what is that so that is one out of ten so i put my event size is one i have 10 items uh if it is not spam that's a 7 out of 10. this is a 1 out of 10 7 out of 10 and i fill in all six of these and there we go if there is a spammish keyword in my email inbox get rich quick uh cialis viagra the odds that it is not spam in this made up example is 20 percent and so with bayes theorem this is a way to answer questions that might otherwise seem very difficult to get to my friend tells me they had a dessert what are the odds um another place where something like this might be used would be maybe like a b testing i give you one version of a website i give somebody else a different version of the website and we get a sense of if they picked something here what is the chance they were using this version of the website if they bought a thing or they clicked on an ad what is the probability that they were looking at a particular type of ad so here's an exercise for you folks i give you basically the same three types of data sketch out your little probability tree start to fill out the tree until you have all the values populated and then much like we did up here go ahead and work out those six items in the formula and answer the question after some of my friends played two different versions of a board game talking to my friend the friend said hey i really want to buy this game what is the probability that that tester played version b of the game versus version a i'll give you guys a few minutes to go through that give you about seven eight minutes all right oh my gosh you you you if you get this finished put your little questions okay all right okay the big sticking point here is figuring out what each of these things are just as i kind of walked around and talked to a couple people and listened to some of the comments right the process of getting from point a to point b is essentially the hard part and how this will normally play out in these types of examples you will potentially be given one of these two values on a branch so you have to do the math to get the other you'll be given two values here and you can get the third you'll be given two values here and you need to get the middle one those kinds of things and so as you get practice and you get practice by doing right you do this over and over again um you will grow accustomed to oh i've got these three facts or these four facts and i can start to fill in and then once you get this down and things are working out really well then you can start to apply this to real world problems okay but once this chart is filled in the next step becomes take each one of those things put them into the six spots and then the math should theoretically work out all right i'm going to let you guys read this section on independent events and we're going to move on to lesson 3 in the interest of time so you guys can go back and read that on your own we want to look really quickly at what we call discrete probability distributions and then we want to understand a little bit about factorials well permutations and combinations and what those are for and what they mean in the middle of this we're going to do a field trip i'm going to take you guys out onto the wild wild internets and we will look at some things that are out there that might be of interest and use to you and we'll talk a little bit about how this discrete probability distribution can apply to other things but let's get started with the discrete probability distribution one of the kind of the classic i guess examples of a discrete probability distribution is related to slot machines by discrete we mean it's broken up into individual components as opposed to like a nice curve right with this slot machine example i have three slot machine wheels every wheel has certain symbols on it it might have an apple it might have an orange it might have a quarter might have other random things depending on how the slot machine plays out if i were to get an a and a and a and apple and apple and apple on the three wheels i get four dollars i had to pay 20 cents to play so my gain is going to be 3.80 if i got an apple apple orange they give me three bucks but again i spent 20 cents to play so i really only gained two dollars and 80 cents orange orange orange i get two dollars i want to highlight this bit this apple apple orange is any order if i got an apple an orange and an apple that still qualifies i still get my three bucks woohoo all right they're still ripping me off okay now on any given wheel i have a certain number of oranges i have a certain number of apples a certain number of quarters and stuff on that wheel and the probability of getting an apple is one in ten the probability of getting an orange on a single wheel is going to be two out of ten probability getting quarters two out of ten and all the other symbols the cruft that's fifty percent probability of getting some other random symbol okay what i'm going to start doing here is i'm gonna start building out a table of details i'm going to go kind of step by step building out the table and it's going to take me to a point where i can figure out what is my average win at the casino air quoting the word win what is my average loss at the casino so here are my wheels here's how much they pay here's how much i get or how much i pay so normally when i screw up and i get nothing none of the wheels helps me i'm gonna immediately lose 20 cents if i get three quarters i get back 80 cents because i've spent 20 to get there um we know the probability of getting an orange so 2 percent or 20 probability of getting an orange 20 probably getting another one 20 probability getting a third the chances of me getting three oranges in a row is eight out of a thousand um similarly i can do the math to figure out what is the probability of getting all apples that's one in a thousand probability of getting all quarters is eight out of a thousand and the probability of being a sucker is 996 times out of a thousand i lose cash straight up all right if you are a gambling aficionado please don't be insulted when i say sucker that's a colloquialism all right so if i translate gains and losses um we can assign a probability of getting any specific gain and here i'm going to stop calling them gains and losses i'm going to say x so i have a capital x and a lowercase x x is this random variable um and the little x is any individual item and i've only got four or five options here so out of these five options that fall into this big random variable and so i know the probability of getting any of those five options and i know how much money i get and that's going to help me figure out my average win or loss all right in our previous discussions we talked about averages we use the word mean when we talk about these distributions we use the phrase expectation little mood lighting sweet is somebody leaning on a light switch all right it was getting crazy cozy in here all right so given any particular trial i might lose i might win is there a way to figure out my average and that is using expectation to figure out our expectation we use a formula much like we had before we say all right if i have a particular x what is the probability that i'll get that x and let me add up all of those and that will give me my mean e x is called expectation but we also often call it mean so you'll run into it as both and matter of fact we might use the symbol for mean which is this uh this greek mu all right so for starters i multiply the probability times the the value of the variable and i get these results a bunch of them come out positive and then we have this suckers category which comes out very negative and if i do all the math and i add all five of those results up my average loss every single time i play this game if i played it a lot of times my average loss will be 16 cents every time i play this game all right sure i might win four bucks once in a while but on average i'll lose 16 cents every time i play all right now knowing the mean is kind of cool but we also often want to know how broad that spectrum is is there a possibility i might have a really broad spectrum and maybe i'll get really lucky on one end of the spectrum to solve that we essentially solve for variance right so the variance of any given probability distribution is the expectation of the value minus the average squared right so let's get in here this is essentially the same chart we had before but i take the value minus the average remember the average was negative i'm losing money on this so i subtract a negative value and i get this um once i have taken the average and subtract it from all five values i'm gonna have to go back and square it so we jump in here we take each of those values we just calculated a second ago we go ahead and square them all and once we have a square we multiply it by the probability and we get all these things again you go back reread this kind of absorb it take your time but ultimately once i've multiplied the square value times the probability i can get a variance and i can tell with this particular data set it's wide it's narrow things are really close to the mean a lot of times things are far away from the mean a lot of times but again variance is such an ugly number nobody likes variance so we have standard deviation and that's just the square root of the variance all right so your first question might be holy cow how do we write code that does all of that well we're not going to we're going to skip that part right and we're going to go on a field trip we're going to look at some libraries these are your takeaways these are things you can go home and play with and explore and consider i'm going to look at a couple of libraries and figure out how the pros have put these things together for our use um the first place we're going to start is the stats field trip and for your reference don't try to like read out the the url because that's that's just going to like blind your eyes all of these are linked at the bottom and so i have all the urls to get to each of these down at the bottom okay so let's start with the scifi stats library load this up a bit okay the scifi library itself has some tutorials that'll kind of walk you through a series of things certain basic functions they might have or statistical functions that are present etc i'm going to dive into the scipy.stats library i'm basically going to kind of scroll through this and point out a few things the nuance here that i want you to walk away with is there's a heck of a lot of good work that's been put into solving some of these statistical problems that i should take advantage of instead of using chalmers crappy code all right we mentioned a minute ago discrete probability distributions where things take certain values a 3.80 return a 2.80 return well there's other distributions called continuous and so i'm going to kind of scroll through this right they're all alphabetical order a so we got alpha arcsin these are all continuous distributions and a lot of work has been done to try and create these objects in python that you can use to look at distributions of data in various ways and we'll dive in on one of these in a few moments but there's a lot right so when we talk about you starting your statistics journey this is step one this is the first three hours or something of a 40 hour college class on intro to stats and this is you know graduate level whatever right but there is a destination you can get to and in many cases you don't have to go all the way you don't know and memorize every one of these none of us have that memorized we build on the basics and then when we need something particular we go and try and hunt down the thing that will help us we have what's called multivariate distributions that look at various types of multiple variables that correlate with things we have some discrete distributions which is what we were looking at a moment ago there's various ways to handle particular types of discrete distributions and then of course they've got a whole slew of statistical functions like mode and calculating for skew and for variation and standard deviation etc so let's go dive in on one of these this is in the stats library and this is related to a particular discrete random variable it's called the binomial discrete random variable and the way to calculate certain values that come out of this they have this really funky formula we're not going to spell that out i'll let you guys figure it out but you provide it with a couple of values and it will allow you to build kind of this body of information that you can then go and explore and your exploration might lead you to making graphs that kind of show patterns in the behavior and if you want to know specific details about the data that you could use to make that graph they have a whole slew of additional kind of nested functions that allow you to dig right into that distribution and understand more about it etc right i'm not going to walk you through all these things but they're there so that's the first part of the field trip scifi stats the next part of the field trip we mentioned a library called numpy numpy's got much like the scipy library an incredible set of documentation where you can start to dive into particular things that interest you and we're not going to explore this one the way we did sci pi stats pandas also has again kind of this incredible wealth of information about how you can calculate information using data the python statistics library a couple of us were looking at this a few minutes ago there's really only about 10 or 12 different types of functions here this is more the uh the meat and potatoes kind of things that you're most regularly and frequently might use this does not get into any of the details like scifi stats and and numpy and stuff will allow you um but it's there and you don't have to import it you don't have the weight of importing a lot of things from thirdparty libraries so this is still useful for the things that show up most frequently all right so with that so that was our field trip i mentioned this idea of these discrete probability distributions you go home you start to wrap your head around that one of the really cool things that you can do once you have a good understanding of a discrete probability distribution is that you can apply what we call transforms in order to get to kind of this point i had to multiply certain things by hey this this is the probability that something's going to happen or this is the gains and the losses et cetera well what if my slot machine owner says hey we're going to upgrade your slot machine and it's no longer going to be four bucks if you win this but everything is going to be increased by a quarter you'll earn four dollars and a quarter three dollars and a quarter um instead of having to go back and redo this these transforms will allow me if you guys study up on this to very simply reevaluate my variances without having to do a lot of crazy math so that's pretty cool um so you'll want to research transforms on discrete probability functions so we've got 10 minutes i'm going to walk you through combinations and permutations with a sprinkling of factorials if you recall a few minutes ago i said hey look at this if i get an apple an apple and an orange i'm going to win something but i also illuminated the fact that it really really wasn't just apple apple orange it was any order of apple apple orange so i get orange and then an apple on the second wheel apple on the third wheel and when i calculated the probabilities for this i took that into account so i got apple apple orange plus apple orange apple plus orange apple apple say that three times quickly um this was easy because it was only three things i only had like kind of three combinations of this or three arrangements of it sorry it's probably a better term but what if i had lots of things and i had all sorts of arrangements is there a way to do that mathematically and do it easier that's where factorials combinations and permutations come into play all right we'll start off with factorials you might have seen this button on your calculator never known what it does there's often on calculators a button that will have something like x with an exclamation or an n with an exclamation that represents a factorial and what a factorial is is simply i will take whatever number you give me and multiply it by all the things that are decremented down by ones so a 2 factorial is 2 times 1 a 4 factorial is 4 times 3 times 2 times 1 10 factorial is spelled out it's a nice way of very simply creating very large numbers that are composed of things you might say well what kind of use would this be let's say that i have four books for example um and i want to put them on my bookshelf and i'm kind of particular about what order i put them in with the four books in my hand i could pick my first book i have four choices and i throw the first book down how many choices do i now have left in my hand i have four books to start with and i put one on the shelf how many choices do i have left how many books do i have left in my hand three so now i pick one out of the three and i put that on there how many choices do i have left in my hand two right so these factorials are often used in these kind of things we need to organize and arrange things if i have a bunch of horses and they're in a horse race by the way chalmers not a gambler but yes say i have horses and they're in horse race i have 20 horses which horse could come first have 20 options which horse could then come in second i only have 19 options which horse could come in third i only have 18 more options right so that's where factorials come into play a great thing about factorials is that if i have to do division of one factorial by another it's pretty easy because three times two times one over three times these cross out and i'm just left with five times four so it makes the math pretty pretty straightforward um i've got a little function here we'll calculate this calculate that and so i'll let you figure out the details of the function but i've got a function that will calculate factorials for us i want to highlight in vivid terms what i meant by chalmers code sucks and other code is better by looking at a realworld solution the calculation of factorials looks like it's pretty straightforward but there's a lot going on to the hood for example if you're on a 32bit piece of hardware the size of an integer maxes out at about 12 factorial if you're on 64bit hardware it maxes out around 20 factorial maybe your computer might want to build or calculate something larger than that so you might use floating point approximations or representations of those values and that will nudge you a little bit past those points or maybe in terms of speed you don't want to calculate 40 times 39 times 38 you might want to have a lookup table for certain low level factorials and then do the calculations on higher ones or you may not want to do the calculations at all so you might use an approximation like sterling's formula to figure this out so real world functions not chalmers will do things to help improve the speed or the reliability of it and i just want to show you what we mean by the speed of it so i created a factorial function we just looked at it a second ago but there is actually in python's math library a function called factorial and i'm going to import it as f so that the two names don't don't overwrite each other and if i calculate the factorial of four it's going to give me back some number and so let's go look at that make sure we get something back we get 24. returns 24 as expected there we go if you've never used jupiter to do this it's kind of fun there is the ability to time certain um statements or expressions etc in in python so i'm going to say use chalmers factorial function and calculate 40 factorial and time it and show us how long it takes to do this and then we'll use the library in or the function in the math library and we'll see how well it works so we'll run that the time it functions kind of cool it will run this multiple times and every time it runs it it will do it some number of times like a hundred thousand times so it took about seven micro seconds to do it with chalmers crappy homegrown code and it took 300 nanoseconds to do it with legit code that is really good at this and optimized for this right that is a massive difference like a thousand times difference right something like that or ten times difference whatever it is math is not my thing don't trust me for your maths all right three seconds or three minutes to go good grief we'll talk about permutations combinations and products um with permutations we will look at how we can arrange things for example how many ways can i arrange four out of five books on my shelf got five books i only have room for four let me figure out which four i want to pick or if i know that i care about three of the ten horses that win because i'm going to bet on three of them how many different options are there that three will cross the finish line right combinations on the other hand are things where we don't have to worry about the order of them with the horses right if if sally blue finishes in front of you know denver dan versus denver dan finishing first the order was crazy important with that permutation but with combinations order doesn't matter what did you have in your salad i had walnuts i had romaine lettuce maybe i didn't have iceberg had croutons the order doesn't matter if i said croutons and iceberg lettuce it doesn't matter products are a lot like permutations but you not only care about the order but you start to replace things so for example i pull a ball out of a lottery cage i read the ball i throw the ball back in and i have the chance of pulling that same ball out again but the order of the numbers matters and then combinations with replacements it's the same as combinations but i put stuff back in the pool so i got a handy little chart here do i replace stuff yes or no with those books i couldn't replace them because i only have one copy of each book um with the lottery balls i could put the lottery ball back in the in the in the bucket right order matters order doesn't matter right so we can calculate permutations combinations products and stuff one thing that i'll leave you guys with and then we're pretty much done again rolling your own not so good there is a library called intertools that has a function built in to do each of these and real quick we'll look i have three things i want to figure out kind of groupings or arrangements of them two at a time when order doesn't matter i only have three possible arrangements but if order does matter did one come before two or did two come in front of one et cetera all right i'll skip all of that there we go and those are the links to all the libraries you folks have been amazingly patient through the day brains are all fried by now i'm sure i'm glad you came i appreciate any feedback i will get a survey link up on the screen here i urge you to go to this particular location and give me feedback because feedback is something that i need so let's see www.surveymonkey.com and if i remember right i think surveymonkey's done in python all right and this is a capital hk 8 2 6 8. let me make sure i got this right surveymonkey.com r h g k 8 2 6 8. all right um if you guys need to get a hold of me i've sent you guys some emails and they have like my twitter handle in them you can reach out to me that way my email is there you can reach out to me if you want to ask questions please please fill out the survey that'll help me be better and i appreciate your time glad you came thank you
