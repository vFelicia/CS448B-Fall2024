With timestamps:

00:00 - this massive course about foundational
00:01 - generative AI was originally recorded
00:04 - live we've put it all together into this
00:06 - one video this course offers insights
00:09 - into generative models and different
00:12 - Frameworks investigating the production
00:14 - of text and visual material produced by
00:18 - AI the course is taught by three
00:20 - experienced instructors okay I think uh
00:23 - we can start with the session so hello
00:25 - everyone good afternoon to all uh this
00:27 - is the very first session for the uh
00:29 - generative AI uh from today onwards we
00:32 - are going to start with a community
00:34 - session of generative AI so uh yes in
00:38 - today's session we'll be talking about
00:40 - that what all thing we are going to
00:41 - discuss uh throughout the sessions and
00:44 - uh this session actually it will be
00:46 - happening for uh upcoming two weeks and
00:50 - uh it will be on the same time I'm going
00:52 - to take the session from uh 3:00 p.m.
00:54 - onwards uh maybe 3: to 5 so here in this
00:58 - uh committee session we'll try to to
01:00 - discuss many more thing regarding the
01:02 - generative AI so we'll start from very
01:05 - basic and we'll go to the advanc there
01:07 - we'll try to develop different different
01:10 - type of applications as well uh first of
01:12 - all I will start with the theory uh so
01:15 - there I will uh discuss about the
01:17 - theoretical uh uh like stuff and all
01:19 - that what is generative AI what is a llm
01:22 - and after that I will uh like go with
01:24 - the open a Lang and don't worry each and
01:27 - everything I will discuss in a very
01:28 - detailed way and and uh I will show you
01:31 - the dashboard as well where all the
01:33 - lectures and all will be uploaded and
01:35 - apart from that I will uh show you the
01:38 - uh like uh where you can find out all
01:40 - the videos quizzes and uh assignments
01:43 - and all because along with the session I
01:45 - will give you the different different
01:46 - assignment different different quizzes
01:48 - so at least you can practice with the
01:50 - concepts got it guys yes or no so are
01:53 - you excited please do let me know in the
01:55 - chat if you are excited
01:58 - then
02:11 - great so I think we going to start and
02:14 - uh so first of all guys what I will uh
02:16 - do I will give you the uh the detail
02:19 - introduction of the course that what all
02:21 - think we are going to discuss in this
02:23 - committee session and uh here basically
02:26 - this is our dashboard so let me share
02:29 - this link with all of you so uh don't
02:31 - worry my team will share the link of
02:33 - this dashboard in the chat so from there
02:36 - what you can do you can enroll it is
02:38 - completely free you no need to pay
02:40 - anything for this uh committee session
02:42 - and all the lectures and all the
02:44 - assignment and quizzes will be uploaded
02:46 - over here don't worry I will come to the
02:48 - curriculum also so here first of all let
02:51 - me show you the homepage uh this is the
02:53 - homepage guys uh this is the homepage of
02:55 - this dashboard and there uh uh like you
02:59 - can enroll in this particular dashboard
03:01 - and don't worry uh each and every video
03:03 - you will find out over the Inon YouTube
03:06 - channel as well so all the recorded
03:08 - video and all it will be available
03:10 - inside the Inon YouTube channel uh
03:12 - definitely this video is going to be
03:13 - record after the session so this video
03:16 - will be available inside the I YouTube
03:18 - channel as well as uh over the dashboard
03:21 - so here guys this is the dashboard I
03:22 - think you got a link of the dashboard so
03:26 - there you can enroll and then uh like
03:29 - you can start your journey of the
03:31 - generative AI so here guys uh me and buy
03:35 - both are going to take this particular
03:37 - session so there we are going to discuss
03:40 - in depth uh about the generative AI
03:43 - about the llm we'll try to discuss about
03:45 - a various application various recent
03:48 - model llm models and all uh we have so
03:50 - many things uh to discuss about the
03:52 - generative AI we have planned for the
03:54 - two weeks but uh maybe uh more than 2
03:57 - weeks uh we'll try to uh take if we are
04:00 - not able to cover and like all the
04:02 - curriculum whatever we have defined
04:04 - whatever we have thought uh so
04:06 - definitely we'll be extending the date
04:08 - as well but yeah we will make sure that
04:10 - within 2 week whatever curriculum we
04:12 - have defined we'll try to complete it so
04:14 - here guys are me and uh buy so if you
04:17 - don't know about me guys so my name is
04:19 - Sun my name is s Savita I'm working in
04:22 - Aon from past three year and I have I'm
04:25 - having an expertise in data science uh I
04:28 - have explored U every aspect of the data
04:31 - science like machine learning deep
04:33 - learning and advanced deep learning like
04:36 - computer vision NLP I have worked with
04:38 - the mlops as well uh there I have
04:40 - designed a various applications and all
04:43 - got it so yeah uh you can search me
04:45 - about more over the LinkedIn uh there
04:47 - you will get uh you will you will get
04:49 - got my profile and you will uh like uh
04:52 - get each and everything in a detailed
04:54 - way so here guys uh what you need to do
04:56 - so first of all you need to enroll to
04:58 - this particular dashboard uh you no need
05:00 - to pay anything over here and if you are
05:03 - going to login after login what you need
05:05 - to do uh so uh you will be redirect
05:08 - redirecting to this uh particular
05:10 - dashboard and uh so let me show you the
05:14 - dashboard first of all this is the
05:15 - dashboard guys as of now there is no
05:17 - such videos and all uh definitely after
05:19 - the session we'll uh upload the videos
05:22 - and assignment and quizzes so definitely
05:24 - along with the sessions and all you can
05:27 - practice so this thing is clear to all
05:29 - of you yes or no have you enroll uh
05:32 - through this dashboard did you get this
05:34 - Dashboard please do confirm in the chat
05:36 - I'm waiting for your reply please do it
05:57 - guys great so I can see uh uh many
06:00 - people are saying yes so definitely now
06:03 - uh we can discuss about the curriculums
06:05 - and all so whatever thing we are going
06:06 - to discuss throughout this committee
06:08 - session first of all I will give you the
06:10 - detail uh like uh detail introduction of
06:13 - the uh syllabus uh what all topics we
06:16 - have uh we'll try to more focus on the
06:19 - re recent Trends I'm not going into the
06:21 - uh classical uh machine learning and the
06:23 - Deep learning basically so I will focus
06:26 - more Focus basically on the open Ai
06:27 - langen and all so don't worry
06:29 - I will give you the detail introduction
06:31 - of the syllabus uh that whatever thing
06:33 - we are going to discuss inside this
06:35 - committee session so the first thing
06:37 - what you need to do guys you need to
06:38 - enroll inside this dashboard and uh
06:42 - whatever like videos and all you will
06:43 - get uh you will like go through and
06:46 - basically you can watch it over here
06:48 - itself directly now let's discuss about
06:50 - the curriculum and all that what all
06:52 - thing we are going to discuss and uh for
06:55 - that basically I have created one PPT so
06:57 - let me show you that particular p PPT uh
07:00 - just a
07:10 - second so here is a PPT guys can you see
07:13 - this PPT yes or no please do confirm in
07:15 - the chat if it is visible to all of
07:28 - you
07:39 - great I think uh this uh PP is visible
07:42 - to all of you now guys uh we can discuss
07:45 - uh that uh what will be our uh like
07:47 - topics and all uh that what all thing
07:49 - basically we have to discuss throughout
07:50 - this committee session so here uh first
07:53 - of all I will start from the generative
07:55 - AI so there I will give you the detail
07:57 - overview of the generative AI that what
07:59 - is a generative AI uh why uh we should
08:02 - use a generative AI uh what all type of
08:04 - like application we can create and uh
08:07 - each and everything each and every every
08:09 - theoretical stuff we try to discuss
08:11 - regarding the generative Ai and after
08:13 - that after the generative AI I will come
08:15 - to this uh large language model so just
08:18 - a second let me open my uh pen as well
08:22 - so I can write it down um each and
08:28 - everything
08:31 - yeah so here guys uh we can uh I can
08:34 - write it down as well now so here the
08:36 - first thing basically first I'm going to
08:38 - start from the generative AI there uh
08:41 - definitely I'll will be talking about
08:42 - each and everything each and every
08:43 - aspect of the generative AI then after
08:45 - that I will come to this large language
08:48 - model there I will try to discuss this
08:50 - llms large language model in a very
08:52 - detailed way we'll try to see the
08:54 - complete history of the large language
08:56 - model that what is a large language
08:58 - model what types of model we have what
09:00 - was the classical model and uh what is a
09:03 - recent model okay so each and everything
09:05 - we'll try to discuss regarding this llms
09:08 - and after that after completing this uh
09:10 - theoretical part theoretical of this uh
09:13 - stuff and all regarding the generative
09:14 - AI regarding this llms I will come to
09:17 - this open AI open Ai and this lenen so
09:21 - there uh we'll try to discuss in a very
09:23 - detailed way that what is the open AI
09:25 - what is the open AI API and inside the
09:28 - open AI API we have a different
09:30 - different them right so in OPI openi
09:33 - itself you will find out a various model
09:35 - that like openi open has created a
09:38 - various model uh that different
09:40 - different version of the gpts okay so it
09:42 - is having some uh like a old model as
09:45 - well some legacies and all and some
09:47 - upcoming models so each and every model
09:49 - will try to discuss I will give you the
09:50 - walk through regarding those particular
09:52 - model and I will discuss about the
09:54 - python API python uh API uh that uh how
09:58 - you can uh use utilize those particular
10:00 - model by using the python getting my
10:02 - point and apart from that apart from the
10:05 - python API and all will try to discuss
10:07 - that uh like if we are going to be uh if
10:10 - we are going to use the Lenin right so
10:12 - how it is different from the open AI so
10:14 - at the first place I will give you the
10:16 - uh detailed differences between this
10:18 - open Ai and this lenen that how it is
10:20 - different to each other that why this
10:22 - Lenin is required then I will come to
10:24 - the Lenin and then again we'll try to
10:26 - create uh again basically we'll try to
10:29 - Define the lenen and all uh by using the
10:31 - python we'll try to uh use the lenen or
10:33 - different different like a component of
10:35 - the Lenin like memory chain agents and
10:38 - all and yes after that I will try to
10:41 - create one
10:42 - application okay so here uh basically
10:45 - we'll try to create one application and
10:48 - with that uh definitely we'll be able to
10:50 - justify the knowledge whatever actually
10:52 - uh we are going to learn regarding this
10:54 - llm open lenion by using uh that by
10:57 - creating that particular project
10:59 - and after that I will uh come to the
11:02 - advanced part Advanced part like uh
11:04 - Vector databases uh we'll try to discuss
11:06 - about a different different Vector
11:08 - databases and first of all we'll try to
11:10 - discuss the need of the vector database
11:14 - that why it is required what is the
11:15 - meaning of the embedding uh how we can
11:18 - uh like uh save the embedding how we can
11:21 - retrieve that and how this a vector
11:23 - database this a vector database plays an
11:26 - important role whenever we are going to
11:28 - create any application related to this
11:31 - llms okay so there we'll try to discuss
11:34 - about the vector databases and then I
11:36 - will come to the some open source model
11:39 - so uh first of all I will come to this
11:41 - uh llama uh and I will discuss about the
11:44 - Llama indexes what is the Llama index
11:46 - and we have a like couple of Open Source
11:48 - model which is a very very famous so
11:50 - we'll try to talk about those model as
11:52 - well like we have a llama to itself we
11:55 - have a falcon we have a bloom there are
11:57 - various model and we'll show You by
11:59 - using those model how you can create uh
12:03 - like a how you can create your end to
12:04 - and application uh you can solve any
12:07 - sort of a task just take a name don't
12:08 - worry I will give you the detail
12:10 - overview about the NLP and all that what
12:12 - all task does exist what all task
12:14 - basically we have what all task we can
12:16 - solve by using this llm each and
12:18 - everything we'll talk about and then
12:20 - finally we'll create one more end to
12:22 - endend project there we'll try to uh use
12:25 - the entire knowledge uh whatever we are
12:27 - going to be learn uh like this Vector
12:30 - databases different different open
12:32 - source model and a length CH open a
12:35 - llama indexes and finally we'll try to
12:37 - deploy that model by using the amops
12:40 - concept so did you uh like this syllabus
12:44 - yes or no please do let me know guys
12:47 - please do let me know in the chat if you
12:49 - like the syllabus yes or
12:54 - no the agenda is clear to all of you if
12:58 - you can write it down the chat I think
12:59 - uh that would be
13:20 - great great so I can see many yes in the
13:24 - chat and many people are saying yes they
13:27 - are
13:29 - able to get yes don't worry we'll give
13:32 - you the PPT and all each and everything
13:33 - will be there in a uh resource section
13:36 - so from there you can download this PP
13:38 - you can download this entire thing
13:40 - whatever I'm uh like I will be using
13:42 - throughout the
13:43 - session yes uh so fine I got a
13:46 - confirmation now uh the first thing uh
13:49 - many people are asking the prerequisite
13:51 - what will be the prerequisite if you are
13:52 - starting with this committee session so
13:55 - prerequisite wise uh if you have a basic
13:58 - knowledge of the Python if you have a
14:01 - basic knowledge of the Python if you
14:02 - know about the core python uh in a core
14:05 - python actually we have uh uh like a
14:09 - ifls for Loop and uh different different
14:11 - type of data structure and the knowledge
14:15 - of the database exception handling if
14:17 - you are uh if you know about the basic
14:20 - python the basics of python then
14:21 - definitely you can proceed with this go
14:24 - along with that if you have a like some
14:26 - basic knowledge about machine learning
14:28 - and deep learning so you will understand
14:31 - uh the concept basically whatever uh
14:34 - like we are going to teach you in a
14:36 - better manner in a better way because
14:38 - here I'm not going to talk about the
14:39 - classical uh ml or the basics of the
14:42 - deep learning like uh artificial NE
14:45 - Network CNN and all definitely I will
14:47 - give you the overview about the transfer
14:48 - learning fine tuning and all but here uh
14:51 - uh I won't talk about the neural network
14:54 - and this recurr neural network lstms and
14:56 - all so uh if you have a basic
14:59 - understanding of machine learning and uh
15:02 - deep learning so definitely you will
15:04 - understand the concept in a very well
15:05 - manner otherwise basic python knowledge
15:08 - is fine for creating application basic
15:10 - python knowledge is uh like fine okay so
15:14 - you no need to worry about it uh
15:16 - whatever thing actually I need to
15:17 - explain you definitely I will do that uh
15:19 - in the class itself and uh we'll do the
15:22 - live implementation I'm not going to
15:24 - show you any uh pre-written code and all
15:26 - uh definitely I will write it down each
15:28 - and everything in front of you only got
15:30 - it so prerequisite is clear so
15:33 - prerequisite nothing just a python or uh
15:35 - I can write it down over here basic
15:37 - knowledge basic knowledge of ML and DL
15:41 - if you know this much then definitely uh
15:44 - like uh you will be able to understand
15:46 - each and everything in a well
15:50 - manner great so yes we'll talk about the
15:53 - RG approaches and all each and
15:54 - everything diffusion model is there
15:56 - there are some recent model in l each
15:59 - and everything will talk about and you
16:00 - will be capable so uh let's say if you
16:03 - are working in your company or maybe you
16:05 - are trying to switch into the generative
16:06 - AI or maybe you are fresher in every uh
16:10 - case right so this community course will
16:12 - help you definitely if you if you are
16:14 - going to attend every session if you are
16:16 - going to learn along with me definitely
16:18 - you can build anything after learning
16:21 - all sort of a thing got it great so I
16:25 - think uh this uh introduction is clear
16:27 - to all of you now I already discussed
16:29 - about uh about the dashboard and all so
16:32 - uh I given you the walk through of the
16:34 - dashboard so link you can find it out
16:36 - inside the chat inside the chat and from
16:39 - there itself you can enroll now the
16:41 - syllabus is clear dashboard is clear
16:44 - each and everything is fine so I think
16:47 - we can start with the introduction of
16:49 - generative AI generative Ai and llm
16:52 - because from today's on uh from
16:54 - tomorrow's onwards I I will be like move
16:56 - to the Practical part and there I will
16:58 - be talking about the open a how to
17:00 - generate a open key how to use the open
17:03 - API and uh we'll try to understand the
17:06 - chat completion API functional API and
17:09 - uh we'll try to understand the concept
17:11 - of the token also that what is a token
17:14 - uh like how many token should I use
17:17 - whenever we are giving any sort of a
17:19 - prompt what is a different different
17:20 - prompt template and all there are lots
17:22 - of thing which we need to understand so
17:23 - today's session actually it will be uh
17:26 - like completely introduction session and
17:29 - in this particular session uh we'll talk
17:31 - about the generative Ai and the history
17:33 - of the large language model so guys uh
17:35 - are you ready can I uh get a quick yes
17:37 - in the chat if you are ready
17:45 - then yeah definitely we'll talk about
17:47 - the uh like use cases of the generative
17:50 - and all u in today's session itself I
17:52 - will like give you that uh particular
17:54 - idea that where you can uh utilize this
17:57 - generative AI in a real time
18:01 - yes definitely this course content and
18:03 - all whatever you are seeing over here
18:05 - this one definitely it will be available
18:07 - over the dashboard as well so this is
18:08 - our dashboard we'll update it over here
18:11 - inside the course syllabus section so
18:13 - each and everything uh like uh we'll try
18:15 - to update in the dashboard
18:18 - itself here is a class timing and all
18:20 - and uh I will make sure that the uh the
18:23 - link also okay so uh we are not going to
18:26 - uh we are directly streaming over the
18:28 - YouTube so directly you can uh join
18:29 - through the YouTube so for that you just
18:31 - need to subscribe the channel and you
18:33 - will get a notification in that
18:36 - case great so people are saying yes sir
18:38 - we are ready ready ready
18:52 - great yeah definitely Wy we'll try to
18:54 - discuss the applications and all and uh
18:57 - I will explain you all the thing and
18:59 - that uh specific way only don't
19:06 - worry we are going to build AI
19:08 - application by using the AI
19:10 - tools AI based
19:18 - application great so I got uh many yes
19:22 - in the chat now I think uh we can start
19:25 - with
19:26 - a uh with the introduction of generative
19:29 - Ai and the LM so guys uh first of all
19:32 - tell me that how many of you you are uh
19:35 - you have started with the generative Ai
19:36 - and all already means uh you have
19:38 - learned something at least you have
19:40 - learned the basics in all uh so if you
19:42 - can write down the chat so that would be
19:45 - great means you are starting from very U
19:48 - like a scratch or you have some sort of
19:57 - idea
20:16 - great so many people are saying uh so
20:20 - some people are saying they know about
20:21 - the basics and some people are saying uh
20:24 - they're starting from the scratch don't
20:26 - worry so uh basically I will start from
20:28 - the scratch only now here guys uh you
20:31 - can see I have created One PP for all of
20:33 - you so let me uh first of all let me go
20:35 - through with this particular PP and
20:37 - later on what I will do I will again I
20:39 - will give you the revision by using this
20:40 - PP only and in between I will use my
20:43 - Blackboard also for explaining you some
20:45 - uh Concepts and all so here is my
20:47 - Blackboard so here I will be writing
20:49 - down uh the whatever basically thing I
20:53 - need to explain you and in between I
20:55 - will be using the ppds and all so first
20:57 - of all let me go through this particular
20:59 - PP and here you can see so uh I have
21:02 - written some sort of a name uh so in the
21:05 - generative AI whenever we are talking
21:06 - about the generative AI or a large
21:08 - language model so couple of name are
21:11 - very famous nowadays and in in those
21:14 - name actually this chat GPT is a uh like
21:16 - very very famous so here I have written
21:18 - this chat GPT it's a product of the open
21:21 - AI as we know about this Chad GPT
21:24 - everyone knows about the chat GPT yes or
21:26 - no I think yes now if we talking about
21:28 - this Google bar so it's a product of the
21:30 - Google and we talking about this meta
21:33 - llm 2 so this meta llm 2 it's a product
21:37 - of the Facebook got it guys yes or no so
21:41 - yes uh nowadays actually everyone using
21:44 - this chat GPT Google B meta lm2 is it
21:47 - it's also a platform similar to this
21:49 - chat GPT uh where you can uh chat or
21:52 - where you can ask a specific question
21:54 - which you uh which you do in a chat GPD
21:56 - itself So Meta lm2 it's a a model from
21:59 - the Facebook site now here guys if we
22:02 - are talking about the generative AI or
22:04 - we are talking about the large language
22:06 - model so in our mind the first image
22:08 - which comes into the picture that is a
22:10 - chat GPT Google B and meta llm 2 yes or
22:13 - no tell me guys yes because of that only
22:17 - uh because of this chat GPT Google B and
22:20 - like the other the different like
22:22 - whatever application you are seeing
22:24 - nowadays right so mid journey is one of
22:26 - the application or maybe Delhi uh or
22:29 - different different application because
22:30 - of that only I think you are learning
22:31 - this uh particular uh thing this
22:34 - particular course this generative AI
22:35 - course yes or
22:40 - no yes so but guys this generative AI is
22:44 - having their own Roots it's not all
22:46 - about the chat jpt Google B and some
22:48 - other uh application which you are
22:50 - seeing chat jpt is just a application of
22:53 - this generative AI chat GPT or this
22:55 - Google B is just a application of this
22:58 - uh like llm large language model
23:00 - basically we are using this large
23:02 - language model in a back end U like
23:04 - whatever application you are seeing like
23:05 - chat GPT and all in the back end but
23:08 - apart from this this generative Ai and
23:10 - this llm is having their own Roots so
23:13 - first of all what I will do I will
23:15 - explain you the concept of the uh like
23:17 - first of all I will uh start from the
23:20 - deep learning itself means I need to
23:22 - explain you few uh terms and terminology
23:24 - regarding this deep learning so let me
23:26 - uh back to the Blackboard so there I
23:29 - will be talking about the basics of the
23:31 - deep learning So within uh 5 to 10
23:33 - minutes I will be discussing the types
23:34 - of the neural network and all and then I
23:36 - will directly move to the uh like LMS
23:40 - and this uh genem so here guys uh you
23:44 - can see uh what I can do I can uh draw
23:47 - one box over here so this is the uh you
23:51 - can think this is what this is the
23:53 - neural uh uh basically if we are talking
23:55 - about the okay so first of all let me
23:57 - start from the deep learning itself so
24:00 - uh if we talking about a deep learning
24:01 - so uh we can uh divide this deep
24:05 - learning into three major segments so
24:07 - let me write it down over here this a
24:10 - deep
24:16 - learning so guys this deep learning
24:18 - actually we can divide into three major
24:20 - topic so the first topic actually which
24:22 - is called artificial neural
24:25 - network artificial neural network netork
24:28 - the second topic is called convolution
24:31 - neural network
24:33 - CNN the third one basically which is
24:36 - called recurrent neural network so we
24:39 - have a three types of the neural network
24:42 - and we can divide this a deep learning
24:44 - into this three major section apart from
24:47 - this you will find out other uh like
24:49 - topics as well so let me write down
24:51 - those uh thing over here so the fourth
24:53 - one uh which I can write it down over
24:55 - here that is a uh reinforcement learning
24:58 - and uh the fifth one we generally talk
25:01 - about it uh so that is what that is a
25:03 - gain so this gain also it comes under
25:06 - this generative AI I will talk about it
25:08 - I will talk about this game I will like
25:10 - give you the glimpse of this uh
25:12 - generative advisal Network that what is
25:14 - this and how the architectures look like
25:17 - of this gains and why I'm saying that
25:19 - this gains comes into the generative AI
25:22 - so if we talking about thisn so let me
25:25 - draw the box now so if we are talking
25:27 - about this n so here guys see we have an
25:30 - input layer inside this Ann actually
25:32 - what we have we have a input layer and
25:35 - uh you will find out the output layer
25:38 - and in between actually in between this
25:40 - input and output we have a hidden layers
25:42 - so just a wait now over here guys see we
25:45 - have a input layer and we have a output
25:48 - layer now in between actually you will
25:50 - find out a hidden layers various hidden
25:52 - layer so let me write it down over here
25:54 - input and here you'll find out the
25:56 - output now here in between this input
25:59 - and output you will find out of various
26:01 - hidden layers so let me write it down
26:03 - the hidden over here so this hidden
26:05 - layer actually it is nothing it's a
26:06 - hyper parameter so we can have as many
26:09 - as hid layer we can have as many as node
26:11 - inside the hidden layer we all know
26:13 - about the artificial neural network I'm
26:15 - assuming that thing now if we talking
26:18 - about this uh CNN actually so the CNN is
26:21 - nothing so in the CNN uh one more thing
26:23 - you will find out in terms of this CNN
26:26 - that is what that is a convolution we
26:28 - always perform the convolution in terms
26:31 - of this CNN so here if we are talking
26:33 - about this enn so uh we are using the uh
26:36 - like structure data where we have a like
26:39 - different different features numeric
26:41 - feature or categorical feature and uh we
26:43 - try to solve the regression and
26:45 - classification related problem but
26:47 - whenever we are talking about this CNN
26:49 - so here uh the CNN actually specifically
26:52 - we use for the image uh related data
26:55 - image or video related data you can say
26:57 - that uh we use the CNN and all for the
26:59 - grid type of data okay so we use the CNN
27:03 - for the grid type of data and there uh
27:06 - like you will find out one more
27:07 - component that is what that is a
27:09 - convolution so here uh let me write it
27:11 - down so the component name is what
27:14 - component name is a convolution so in
27:16 - the convolution actually you will find
27:18 - out a various step so uh we have a
27:20 - various step in the convolution itself
27:22 - so the very first step which we perform
27:24 - what we do guys tell me we perform the
27:26 - feature X section by using a different
27:29 - different filter after that what we do
27:31 - we perform the pooling and then we
27:34 - flatten the layer so there are different
27:36 - different like uh uh steps you will find
27:39 - out inside the convolution itself and
27:41 - after that what we do we apply the fully
27:43 - connected layer so that is nothing that
27:45 - is my Ann itself so over here I can
27:48 - write it down we have this convolution
27:50 - and we have a artificial neural network
27:52 - so this is my first architecture which
27:54 - is a like uh which is the Ann itself and
27:57 - and this is my second one that is what
27:59 - that is a CNN now if we talking about
28:01 - the third one which is a very very
28:03 - interesting that is called recurrent
28:05 - neural network that is called recurrent
28:07 - neural network so this enn we generally
28:10 - use for the structured data where we
28:12 - have a numerical column or categorical
28:15 - column and in the Target column like it
28:18 - will be a numeric or categorical one and
28:20 - based on that basically we are going to
28:22 - decide whether it will be a
28:24 - classification problem or a regression
28:25 - problem now if we talking about this CNN
28:27 - so already I told you if you're talking
28:29 - about this RNN so the name is what the
28:31 - full form what the full form is the
28:33 - recurrent neural network so this RNN
28:35 - actually we are using for the sequence
28:38 - related data so wherever we have a
28:39 - sequence wherever we have a sequence so
28:42 - this RNN we used for the sequence
28:44 - related data now let me do one thing let
28:47 - me draw the architecture of this RNN so
28:50 - over here guys in the RNN what you will
28:51 - find out so let's say this is my uh box
28:55 - and here is what here is my input so
28:57 - this is what guys tell me this is my
28:59 - input now here is what here is my output
29:02 - so let me draw the output one more time
29:05 - this is what this is my output got it
29:07 - now here guys see uh this is my input
29:10 - this is my output and this is what this
29:13 - is my hidden layer now in the hidden
29:15 - layer actually you will find out one
29:17 - thing one concept and the concept is
29:19 - nothing the concept is called a feedback
29:21 - loop okay so whatever output I'm getting
29:24 - from the hidden layer actually again we
29:26 - are passing that output to hidden layer
29:28 - until the entire time stem so that thing
29:31 - actually uh we learn or we learn in in
29:35 - the RN itself actually this RNN is
29:37 - nothing it's a special type of neural
29:39 - network and there you will find out the
29:42 - feedback loop feedback loop means what
29:44 - so whatever output we are getting from
29:46 - the hidden layer again we are passing
29:48 - the same output to the hidden layer
29:50 - until we are not going to complete the
29:52 - entire time stem that is what that is
29:54 - the RNN now uh you are uh we are talking
29:58 - about the llm so why we are uh why I'm
30:01 - discussing this RNN and all because this
30:04 - llm actually somehow it is connected to
30:06 - this RNN itself before starting with a
30:08 - llm a large language model we'll have to
30:11 - understand the concept of the RNN lstm
30:14 - attention uh like encoder decoder and
30:17 - then attention self attention and all so
30:19 - here I'm not going to discuss in a very
30:20 - detailed way I'm just giving you the
30:22 - glimpse of that that what is a like RNN
30:26 - what is the lstm what the Gru and then
30:28 - what was the sequence to sequence
30:30 - mapping and where this attention comes
30:32 - into a picture then how they have
30:34 - invented the self attention then how
30:36 - they started the using this transfer
30:37 - learning and this finetuning in terms of
30:41 - this uh in terms of this large language
30:44 - model why we are calling it is a large
30:45 - language model why we are not calling it
30:47 - a model okay so each and everything
30:49 - we'll try to discuss now uh you all know
30:52 - about this uh reinforcement learning and
30:54 - all so in the reinforcement learning uh
30:57 - you will find out one agent environment
30:59 - regarding that particular agent you will
31:01 - find out a different different state
31:03 - getting my point and then you will find
31:05 - out the feedback so that actually it
31:07 - comes inside the reinforcement learning
31:09 - and that is also part of the deep
31:11 - learning only now if we are talking
31:13 - about gain so gain is uh nothing
31:15 - actually so in the gain again you will
31:17 - find out a neural network uh which we
31:19 - are using for generating a data and that
31:21 - also comes in under inside the
31:23 - generative Ai and we have a different
31:25 - different types of game so first of all
31:28 - tell me guys uh this uh uh like types of
31:31 - the neural network this is clear to all
31:33 - of you please do let me know in the chat
31:35 - if uh this thing is clear then uh I will
31:37 - proceed with the next
31:40 - topic use cases wise I will come to the
31:43 - use case and I will uh try to discuss a
31:45 - different different use case I will come
31:46 - to the use case then I will tell you the
31:48 - applications of that and then I will
31:50 - come to the domains as well then in what
31:52 - all domains you can apply those use
31:54 - cases so don't worry each and everything
31:56 - we'll try to discuss over here
32:00 - yes I will directly come to the
32:02 - generative a itself but before that I
32:04 - will give you the timeline don't worry
32:06 - from Tomorrow onwards I'm going to be
32:07 - start uh I'm going to start from the uh
32:10 - like uh from the open ey itself uh like
32:13 - complete practical and all so no need to
32:15 - worry about it s Prasad I think you got
32:19 - your
32:26 - answer
32:28 - I think uh this basic introduction is
32:31 - clear
32:35 - now yes coming to the generative only
32:37 - don't
32:38 - worry yeah it's going to end to end uh
32:41 - we'll try to discuss end to end thing
32:42 - don't worry about
32:53 - it if you have any questions and all so
32:55 - you can directly ping into the chat
32:57 - uh so I will reply to you don't
33:21 - worry okay so I think now we can proceed
33:25 - so guys here uh in the uh PP itself I
33:28 - was talking about the generative AI then
33:30 - I given you the uh like uh uh the types
33:33 - of the neural network and I just explain
33:35 - you the uh like the regarding the
33:37 - artificial neural network and the CNN
33:39 - and this RNN so here in the generative
33:42 - AI uh you'll find out that I have like
33:44 - included a few slides and all so let's
33:47 - try to understand a few uh thing from
33:49 - here and then again we'll go back to the
33:52 - uh the Blackboard and then I will try to
33:54 - discuss few more concept so over here uh
33:57 - we have seen the chat GPT like I was
34:00 - talking about the different different
34:01 - application like chat GPT Google B and
34:03 - metm and all now let's talk about the
34:06 - generative AI that what is a generative
34:08 - AI now here you can see the definition
34:11 - of the generative AI uh which I have
34:13 - written over here uh that is what that a
34:15 - generative AI generate new data based on
34:17 - a training sample right so the name is
34:21 - uh the name is self-explanatory right so
34:24 - the name is explaining everything
34:25 - generative AI the AI which is generating
34:28 - something now what all thing we can
34:30 - generate so here if we are talking about
34:31 - the generative AI so you can generate
34:33 - images you can generate text you can
34:35 - generate audios you can generate videos
34:38 - as a output you can generate anything uh
34:40 - so uh this image text audio video it's
34:44 - nothing it's a type of the unstructured
34:46 - data and definitely it is possible by
34:48 - using the generated AI we can uh
34:50 - generate this type of data by using the
34:52 - generative AI now if we are talking
34:55 - about the generative AI so uh as I told
34:58 - you that it is having their own Roots
35:01 - okay so it is having their own roots and
35:03 - if we are going to divide this
35:04 - generative AI so we can divide into two
35:06 - segment so the first segment is called
35:09 - generative image model and the second
35:11 - segment is called generative language
35:13 - model and this llm actually it falls
35:16 - into this particular segment into this
35:19 - generative language
35:21 - model are you getting my point yes or no
35:24 - I think yes so if we talking about this
35:26 - generative image model so I told you
35:28 - when I I was talking about the Deep
35:30 - learning uh like Ann RNN and CNN
35:33 - reinforcement learning and there was a
35:35 - gain so initially we were using the gain
35:38 - for generating a data so let me show you
35:40 - the architecture of the gain so the how
35:42 - the architecture of the game looks like
35:45 - so with that you will get some sort of
35:46 - idea in the game we are using this uh
35:49 - neural network only so let me show you
35:52 - the architecture of the game so let me
35:54 - search it over here over the Google game
35:57 - architecture now uh here in the image uh
36:00 - let me open the architecture of the game
36:04 - so here guys uh just see so in the gain
36:07 - actually we have two main components so
36:10 - the first component is a generator this
36:12 - is what this is a generator okay so uh I
36:15 - think this is visible to all of you this
36:17 - is what this is a generator and here you
36:19 - will find out discriminator so this
36:21 - generator and discriminator is nothing
36:23 - it's a neural network so we are passing
36:26 - this real data so here basically what we
36:28 - are going to do we are going to pass a
36:30 - real data and here we have a generator
36:33 - which is generating some sort of a uh
36:34 - like synthetic data and here we have a
36:36 - discriminator based on that we are going
36:38 - to discriminate between real data and
36:41 - the synthetic data so this is the
36:43 - architecture of the game and inside this
36:45 - architecture you will find out we are
36:47 - using two main thing we are using two
36:49 - main component the first one is
36:51 - generator and the second component is a
36:54 - discriminator I think you're getting my
36:56 - point and this generator and
36:57 - discriminator is nothing it's a neural
37:00 - network got it so this is also comes
37:03 - under this generative AI so now let me
37:06 - show you this generative AI now over
37:08 - here I have written two points
37:09 - generative image model and generative
37:11 - language model so if you're talking
37:13 - about generative image model so in our
37:15 - previous days in our back back days
37:18 - actually in our old days in 2019 18 so
37:21 - this gain was very popular for
37:22 - generating a data again uh this gain is
37:25 - very uh like EXP uh like expensive in uh
37:28 - terms of computation power and all so it
37:30 - is very like very much expens uh like
37:33 - expensive in terms of like uh
37:34 - computation uh so over here you can see
37:37 - so we were using this gain uh we were
37:40 - using this gain for generating images
37:41 - and all in our back days in 2018 and in
37:44 - 2019 and it was very very popular and we
37:47 - have a different different uh variants
37:49 - of the Gams if you'll find out the type
37:52 - of the gain you will find out many types
37:54 - now uh recently actually you will you
37:56 - have find out the trend of the llm large
37:59 - language model now guys here uh we are
38:03 - uh we are talking about the game and
38:05 - then uh this gain basically it was the
38:07 - old concept it is a old concept
38:09 - basically and there are different
38:10 - different variants of the gain as well
38:13 - now over here if we are talking about
38:14 - this large language model so it become
38:16 - very famous from the Transformer I will
38:18 - come to the Transformer I will tell you
38:20 - the complete history of the Transformer
38:21 - as well now uh this image model and this
38:25 - language model
38:27 - but a recent days in a recent days what
38:29 - I have seen in terms of this llm and all
38:32 - even we can generate the images by using
38:34 - this llm we got those llm basically
38:37 - which is like that much powerful so by
38:39 - using those particular llm we can
38:41 - generate generat images as well okay so
38:45 - we I will show you couple of models and
38:47 - all uh regarding this uh like image
38:50 - generation and definitely you will get
38:53 - some sort of idea that how the uh those
38:56 - part particular alms is working in terms
38:58 - of image generation I can give you a
38:59 - couple of example uh like Delhi so Delhi
39:02 - is a example you can uh check over the
39:04 - open a which is a model which is like a
39:07 - uh like a famous for the image
39:09 - generation now here uh if we are talking
39:11 - about this image model so actually see
39:14 - this image model basically it was
39:16 - working for image to image Generation
39:18 - image to image generation now this
39:21 - generative model actually so if we are
39:23 - talking about this generative model it
39:25 - is working Tech uh it is working in
39:27 - terms of text to image generation text
39:30 - to image generation and text to text
39:32 - generation so this two tasks definitely
39:35 - we can perform by using this llm model
39:38 - and this image to image generation
39:40 - before we were doing it by using this
39:42 - gain model in 2018 and in 2019 now uh as
39:47 - I told you that we have those powerful
39:49 - model in our recent Days by using those
39:51 - particular model definitely we can
39:53 - Implement image to image generation as
39:55 - well that is also possible so uh
39:58 - regarding that uh definitely I will show
40:00 - you couple of model so we are having
40:03 - four tasks here I have written it now
40:05 - let me move to the next slide and let me
40:07 - show you that what I have so here guys
40:09 - you can see uh this cat is representing
40:12 - a genitive model where you are giving a
40:14 - prompt uh means where you are giving a
40:15 - question and uh as a response U again as
40:19 - a output basically you are getting a
40:20 - response so in terms of uh see here we
40:23 - are talking about generative model I'm
40:24 - not talking about specifically this El M
40:27 - okay so I told you this uh generative
40:30 - model actually uh you can think it's a
40:32 - super set this generative Ai and under
40:35 - this generative AI you will find out
40:36 - this llm and gang is also part of the
40:39 - generative AI getting my point I think
40:42 - this thing is getting clear so over here
40:44 - we are talking about the generative
40:45 - model so we are giving a input and we
40:47 - are getting a like output now
40:50 - specifically if I'm talking about
40:52 - regarding this llm regarding this large
40:54 - language model so this input actually
40:56 - this is called input prompt and the
40:58 - output actually it is called output
41:00 - prompt so this cat you can imagine as a
41:03 - generative model or as a llm model so
41:05 - what we are passing as a input we are
41:07 - passing input prompt and we are getting
41:09 - as a output output prompt so this prompt
41:11 - term is a very very important I think
41:14 - you have heard about this uh prompt
41:16 - engineering and all that uh uh like uh
41:19 - prompt engineer is getting this much
41:21 - that much and this prompt engineer plays
41:23 - a very important role if uh we have to
41:25 - design any sort of of a prompt now uh
41:27 - different different types of prompt of
41:29 - like zero short prompt few short prompt
41:31 - few short learning and all we'll talk
41:33 - about it as I will progress with the
41:35 - like implementation and all in between I
41:37 - will give you like idea regarding each
41:39 - and everything now over here guys you
41:42 - can see uh where this generative AI
41:44 - exist so if you will look into the uh
41:46 - look into through this particular slide
41:48 - so here you will find out this
41:49 - generative AI actually it lies inside
41:52 - the Deep learning getting my point so
41:55 - the generative AI actually it uh like
41:57 - reside inside the Deep learning uh
41:59 - initially only I have explained you that
42:01 - uh we have a different different types
42:02 - of neural network and it's a part of the
42:04 - deep learning only now whether we are
42:06 - going to generate an images by using the
42:08 - llm or by using the gains or whether I'm
42:10 - going to perform text to text generation
42:12 - text to image generation or image to
42:14 - text Generation by using the llm both
42:16 - lies inside this generative Ai and this
42:18 - generative AI is a part of the it's a
42:21 - part of the tell me it's a part of the
42:23 - deep learning now over here guys I have
42:26 - written a couple of more slid so I will
42:29 - try to explain you uh but first of all
42:31 - let me give you the timeline of the llm
42:34 - and then I specifically I will come to
42:36 - the llm and all and I will be talking
42:38 - about this discriminative Ai and the
42:40 - generative AI as well so tell me guys uh
42:43 - this part is clear are we going good are
42:46 - you able to understand whatever I'm
42:48 - explaining to all of you so if you are
42:51 - getting it so please write down the chat
42:52 - and you can ask me the questions as
42:55 - well
43:15 - if you have any uh type of Doubt or U
43:17 - like if you're getting it or not getting
43:19 - it whatever you can ask me in the chat
43:21 - uh like chat section uh I will reply to
43:24 - your questions
43:41 - no reinforcement learning is not
43:42 - required uh uh specifically we should
43:45 - not go for the reinforcement learning
43:47 - and
43:50 - all yes this is a part of the uh like
43:53 - this Genera way is a part of the deep
43:55 - learning right
44:03 - right yes llm model used in a generative
44:06 - AI correct you got it uh
44:10 - guys mathematical intuition so we will
44:13 - talk about the mathematical intuition
44:15 - and all but this uh more uh this course
44:18 - this comp session is it is more focusing
44:20 - on the applied side so I will create a
44:23 - various application in between whatever
44:25 - math iCal concept and all will be
44:27 - required I will let you know that don't
44:42 - worry great so I think uh people are
44:45 - getting it and uh they are trying to
44:48 - understand fine so whatever I have
44:49 - explained you let me explain you the
44:51 - like Blackboard uh and then again I will
44:54 - come to this PP and we'll try to uh wrap
44:57 - up the theoretical stuff and U then I
45:00 - will explain you the applications and
45:01 - all so over here guys see I was talking
45:04 - about this Uhn CNN RNN RL and G now I
45:10 - started from the generative AI itself so
45:14 - I have started from the generative Ai
45:16 - and I told you this generative AI is
45:18 - nothing you can consider it as a super
45:21 - set as a super set now inside this
45:26 - generative AI you will find out many uh
45:29 - like uh many uh concept many topics and
45:31 - all so here uh regarding the generative
45:33 - AI there is uh two main thing which you
45:35 - will find out the first one is
45:38 - gain gain that is a generative aders
45:42 - Network the second is what
45:44 - llms llms large language model now we
45:48 - have a various task so here let me write
45:51 - down the task as well so the task wise
45:53 - so here I told you the different
45:54 - different task basically so the first
45:56 - task which I can write it down over here
45:58 - that is a image to image Generation
46:02 - image to image
46:05 - generation now the second task was the
46:08 - uh image to text uh text to text
46:12 - generation text to text generation text
46:16 - to text generation now the third task
46:19 - was
46:21 - the uh image to text
46:24 - Generation image to text
46:28 - generation and the fourth one was
46:32 - the uh image to image generation sorry
46:36 - uh text to text Generation image to text
46:37 - and text to image generation so let me
46:39 - write it down over here text to image
46:44 - generation text to image
46:50 - generation now if we are talking about
46:52 - this image to image generation yes we
46:54 - were able to do this particular thing by
46:56 - using this
46:57 - gain we have seen the gains now we are
47:00 - talking about this text to text
47:02 - generation yes it was possible by using
47:04 - the lstm RNN and the uh different
47:07 - different by using the different
47:08 - different model as well but yeah this
47:10 - text to text generation actually
47:12 - nowadays you are seeing uh we are
47:14 - preferring this large language model for
47:16 - this text to text generation and you
47:18 - this chat GPT is a biggest application
47:20 - uh biggest like example for that the
47:22 - chat GPD which we are seeing image to
47:24 - text generation yes uh this is also
47:26 - possible by using a different different
47:28 - model like RNN lstm and Gru image
47:31 - captioning if you have if you uh if you
47:33 - have heard about this uh like image
47:35 - capturing task so that is also possible
47:38 - uh by using this uh like uh classical
47:40 - model but yeah by using this llm also we
47:43 - can perform it we can uh do it now if we
47:45 - are talking about this uh text to image
47:48 - generation so yes uh this type of task
47:51 - nowadays it is possible by using the uh
47:54 - llm so yes yes uh llm is able to do llm
47:59 - is able to perform a various amount of
48:00 - task uh whether it's a homogeneous or
48:03 - it's a hetrogeneous now uh I was talking
48:06 - about the uh llm uh sorry I was talking
48:08 - about this generative AI so where it
48:10 - exists so this generative AI actually it
48:12 - exists uh in a u like a deep learning
48:15 - itself so you can think that AI is a
48:17 - superet machine learning is a subset
48:20 - deep learning again is a subset of the
48:21 - machine learning and this generative AI
48:23 - is a subset of the deep learning because
48:25 - as I already told you we have a
48:27 - different different uh like other neural
48:29 - network also in a uh like a deep
48:32 - learning and this CNN is one of them
48:34 - this a convolution neural network okay
48:37 - so I think this part is clear to all of
48:39 - you now let me draw the architecture uh
48:42 - that where this uh generative AI exists
48:45 - so you can think this is what this is my
48:47 - AI this is one uh this is the like a
48:49 - super set now here this is what this is
48:51 - my machine learning this one now uh
48:54 - inside that you will find out the uh
48:56 - deep learning and inside the Deep
48:58 - learning you will find out this
49:00 - generative AI uh so let me take a
49:02 - different color over here uh let me take
49:05 - uh this color so here you will find out
49:08 - the generative AI so this is what this
49:10 - four circle is what this is the
49:11 - generative AI got it now here uh you can
49:15 - see why we are saying so why we are
49:17 - saying this is a like a subset so I
49:20 - think each and every explanation I have
49:21 - given you over here uh you can uh prefer
49:24 - this uh like a this particular slide
49:26 - that why I'm saying this generative AI
49:28 - is a subset of the deep learning so let
49:31 - me write it down over here this is what
49:33 - this is nothing this is a gen Ai and
49:35 - it's a subset of the deep learning now
49:37 - guys let me explain you the timeline of
49:39 - the uh this llm so uh now you got it
49:42 - that this uh llm is nothing it's a part
49:44 - of the generative a itself this large
49:47 - language model now let me talk about the
49:49 - complete timeline of this large language
49:52 - model so how it evaluate and uh uh I can
49:56 - like talk about the complete history of
49:58 - it and uh here guys you can see that
50:02 - first I was talking about the RNN so as
50:05 - you know that uh what is the RNN tell me
50:07 - RNN is nothing it's a type of the neural
50:10 - network it's a type of the neural
50:13 - network so uh there basically we have a
50:15 - feedback loop again we can pass the
50:17 - information to our H layer now you will
50:19 - find out a different different types of
50:21 - RNN or some Advanced architecture in
50:24 - terms of this RNN itself El the second
50:27 - uh like thing which is a type of the RN
50:30 - itself that is called lstm
50:33 - lstm right so in the lstm actually uh if
50:37 - we are talking about this lstm so here
50:39 - you will find out the concept of the
50:41 - cell state so in the RNN we just have a
50:43 - Time stem and it is for the shortterm
50:46 - memory it is for the shortterm
50:49 - memory we cannot retain a longer
50:52 - sentences by using this RNN it is not
50:55 - not possible if our sentence is a very
50:57 - very huge or it's a very very long so we
50:59 - cannot retain that particular sentence
51:01 - by using this RNN but if we are talking
51:04 - about this lstm yes we can do it by
51:06 - using this
51:08 - lstm so in this lstm you will find out
51:10 - the concept of the cell state so uh this
51:14 - uh lstm is nothing it is for the
51:16 - short-term dependency and it is for the
51:18 - long-term dependency also it is for the
51:20 - short like a memory short-term memory
51:23 - and is for the long-term memory as well
51:25 - if you look into the architecture of the
51:26 - lstm so you will find out along with
51:28 - this uh time stem so here we have the
51:31 - time stem U like it's a hidden State
51:35 - actually uh like on a different
51:38 - different time stem along with that
51:40 - you'll find out one cell state so it is
51:43 - going to retain it is going to retain
51:45 - the long-term dependency and in between
51:47 - in this a time stamp in this short-term
51:50 - memory and in this cell State you will
51:52 - find out a connection the connection in
51:54 - terms of gates so here you will find out
51:56 - one connection uh like uh one gate
51:59 - basically that is called forget gate so
52:02 - here I can write down the forget gate
52:03 - now here you will find out one more gate
52:05 - actually so that is called input gate
52:08 - here you are passing the input now here
52:10 - you will find out one more gate over
52:13 - here that is called output gate output
52:15 - gate okay so we have three gates inside
52:18 - the lstm for sustaining a long-term
52:21 - dependency or for reminding a longterm
52:23 - uh long sentences now uh you will find
52:26 - out one more updated version of the lstm
52:29 - so this RNN is a old thing this lstm is
52:31 - also old thing now you will find out one
52:33 - more updated version of the lstm that is
52:35 - what that is a GRU so this Gru actually
52:38 - they have invented in
52:40 - 2014 and they had they took the
52:42 - inspiration from the lstm itself now
52:45 - inside this Gru you won't find out the
52:47 - concept of the cell State everything is
52:50 - being done by the hidden State itself
52:53 - and here basically in the gru we just
52:55 - have two gate update gate sorry reset
52:59 - gate and update gate and it's a uh Advan
53:02 - or you can say it's a updation on top of
53:05 - this lstm it's a updated version of the
53:07 - uh like lstm itself now what is the full
53:09 - form of the gru G and recurrent unit now
53:12 - over here guys see this was the three
53:14 - architecture which was very very famous
53:16 - during 2018 and 19 in our old days now
53:20 - here see uh one concept comes into the
53:23 - picture if we are talking about this RNN
53:25 - lstm and Gru so by using this particular
53:28 - architecture what we are doing so by
53:30 - using this particular architecture we
53:32 - are going to process a sequence data yes
53:35 - or no we are going to process a sequence
53:38 - data now here one concept comes into a
53:41 - picture sequence to sequence mapping and
53:44 - for that only we are using this
53:46 - particular architecture so we have a
53:48 - different different type of uh like a
53:50 - mapping technique so let me write it
53:51 - down over here uh different different
53:53 - type of mapping technique
56:09 - uh now it is fine uh I think I'm audible
56:12 - to everyone
56:15 - now now I am audible guys please do
56:19 - confirm in the chat I think there were
56:22 - the issue from the mic side
56:29 - now I'm audible so please do confirm in
56:31 - the chat if I'm audible then and uh is
56:34 - there any Eco or uh what
56:37 - so guys are you facing any Eco in my
56:44 - voice now it is
56:53 - fine yeah it is perfect I
57:02 - think great fine fine fine uh it's
57:23 - clear great uh I think now I am audible
57:27 - to everyone sorry I think there was a
57:30 - issue from
57:40 - the do let me know in the chat uh from
57:43 - where I lost my
57:45 - voice so this concept is clear this one
57:48 - to many or one to one one to many many
57:51 - to one many to
57:53 - many
57:55 - [Music]
58:10 - yeah so I think uh I was there RNN lstm
58:14 - and Gru now I think it is fine I'm
58:16 - audible to everyone great so I was
58:18 - talking about RNN lstm Gru and then U I
58:22 - talked about the different different
58:23 - mapping sequen
58:25 - now uh this mapping sequences actually
58:28 - we can Implement by using this uh RNN
58:32 - lstm and
58:33 - Gru so over here uh yes so 1 to 1 one to
58:38 - many many to one many to many RN and LSM
58:41 - and Gru this was the sequences actually
58:43 - I was talking about now in 2014 actually
58:46 - see this was the sequences by uh we can
58:49 - Implement by using this different
58:50 - different models getting my point now
58:53 - over here uh if we talking about this
58:56 - particular sequences definitely we can
58:58 - uh like uh per we can uh create a
59:01 - various uh application by using this
59:03 - model but here basically we are having
59:07 - some sort of a restriction uh as I told
59:09 - you the different different application
59:11 - like one to many many to one so many to
59:14 - one means uh you can think that
59:16 - sentiment analysis one to one to many
59:18 - means what one to many you can say image
59:20 - capturing many to many image uh sorry uh
59:23 - language translation so there are
59:25 - various application of the sequences now
59:27 - see uh we are talking about the
59:30 - sequences uh the sequence to sequence
59:32 - mapping now uh we can definitely
59:34 - implement it by using this particular
59:37 - architecture so the problem we were
59:39 - having the problem was actually uh we
59:43 - cannot see let's say we are giving an
59:45 - input in the input actually we have a
59:48 - five words so whatever output we'll be
59:51 - getting in the output also we should
59:53 - have a five words
59:55 - so it's a fixed length input and
59:57 - output getting my point what I'm saying
60:00 - so by using this particular mapping 1 to
60:03 - one many to one or like many to many
60:06 - specifically we are talking about many
60:07 - to many so there was some problem there
60:09 - was some issue the issue was fixed
60:12 - length input and output so whatever
60:14 - number of inputs we are passing in terms
60:17 - of this many too many I'm talking about
60:19 - okay so whatever number of inputs we are
60:22 - passing so those many output on we can
60:25 - get it over here in the output itself so
60:28 - uh here actually one a research paper
60:31 - came into the picture in 2014 you can
60:34 - search about uh the research paper
60:36 - sequence to sequence learning so inside
60:40 - that uh paper they have introduced the
60:42 - concept of the encoder and decoder in
60:44 - the encoder and decoder actually the one
60:47 - segment the one segment was the encoder
60:50 - segment segment so let me uh draw it
60:52 - over here so the one segment was the
60:54 - encoder segment and the another segment
60:57 - was the decoder segment this another
60:59 - segment was the decoder segment and in
61:02 - between actually in between we were
61:05 - having in between actually we are having
61:08 - the context Vector so here uh in between
61:12 - this encoder so we are having the
61:14 - encoder and we are having the decoder
61:19 - decoder one part was the encoder and one
61:22 - part was the decoder and in between we
61:24 - having the context Vector means whatever
61:27 - information was there whatever
61:29 - information was there from encoder to
61:31 - decoder we are passing through this
61:34 - context Vector means we are wrapping all
61:36 - the information in this context vector
61:38 - and we are passing to the
61:40 - decoder that actually the paper uh has
61:43 - been published in 2014 you can search
61:45 - about it you can search over the Google
61:47 - sequence to sequence learning so let me
61:49 - uh search in front of you only now over
61:52 - here I can write it down sequence to to
61:55 - sequence
61:58 - learning research paper now uh over here
62:02 - guys you will find out this uh
62:03 - particular research paper now just try
62:05 - to read this paper now here in this
62:08 - particular paper they have clarify the
62:10 - issue that what was the issue with the
62:12 - classical mapping so that was restricted
62:15 - to the input and output now over here
62:18 - you if you will read this particular
62:19 - research paper so easily you can find it
62:22 - out the issue here itself in the
62:24 - like introduction itself they have
62:26 - mentioned they have mentioned this uh
62:28 - despite their flexibility and power can
62:30 - only be applied problem who inputs and
62:32 - targets can be sensibly encoded with the
62:34 - vector of fixed dimensionality it was
62:37 - just for the fixed dimensionality and
62:39 - basically there was we were having a
62:41 - limitations so for solving that
62:43 - particular limitation this a sequence to
62:45 - sequence learning paper came into the
62:47 - picture and there was three person Ilia
62:49 - sasar and orol and this there was one
62:53 - more person and this paper from the
62:55 - Google side now here guys uh let me open
62:58 - this uh Blackboard again so there was a
63:01 - context Vector but this uh encoder and
63:03 - decoder also was not able to uh perform
63:06 - well for the long uh longer sentences so
63:10 - here in the research basically they have
63:12 - proved if my sentence is going uh is
63:15 - going uh like above from 30 to 50 words
63:18 - right if it is longer than 30 to 50
63:20 - words so in that case it was not able to
63:23 - sustain the context it was not able to
63:26 - sustain the context if we are using this
63:29 - encoder decoder architecture now you
63:31 - will ask me sun what we were having
63:32 - inside the encoder and decoder so we are
63:35 - talking about the encoder so again here
63:36 - we were using the either RNN lstm or uh
63:42 - lstm and we were using this Gru and here
63:46 - also in the decoder also we are using
63:48 - this rnl we are using the lstm and we
63:51 - were using this
63:53 - Gru got
63:55 - it I think you got the problem now and
63:58 - you got to know about the encoder and
63:59 - decoder so we have started from the RNN
64:02 - then now we came to the lsdm Gru and
64:05 - then we have a different different
64:06 - mapping and for solving this particular
64:08 - issue which is related to this many to
64:10 - many uh like uh mapping many to many
64:13 - sequence mapping and this uh uh this
64:16 - language translation is one of the
64:17 - example if you will search over the
64:19 - Google translate uh just search over
64:22 - there anything let's say in the in H you
64:24 - are saying that or whatsoever so it will
64:28 - generate output so this input word and
64:30 - output word will would be a mismatch but
64:33 - that was a restriction with this uh like
64:35 - with the classical mapping so for using
64:38 - this encoder and decoder architecture we
64:40 - can solve that particular problem now
64:42 - here also we are having the issue that
64:44 - we cannot proceed a longer
64:47 - sentences we cannot proceed a longer
64:50 - sentences so here One More Concept comes
64:53 - into a picture inside this context
64:55 - itself and that was the
65:00 - attention that was the attention so uh
65:04 - here neural translation
65:10 - with just a second let me search about
65:14 - the neural trans TR a NS relation with
65:20 - attention yes this was the paper and uh
65:24 - this was the first paper let me search
65:27 - about the research paper yeah now guys
65:31 - uh this was the paper in this particular
65:33 - paper they have introduced the concept
65:34 - of the attention and just try to
65:37 - download it you need to download this
65:39 - particular paper and uh then you can see
65:44 - there so just a second let me show you
65:47 - this paper as well and this is the main
65:50 - uh like main papers uh basically which
65:52 - you will find out uh while you will be
65:54 - learning this deep learning and all so
65:56 - this paper actually this has been
65:58 - introduced in
65:59 - 2015 I think in 2015 or 16 now here they
66:02 - have introduced the concept of the uh
66:05 - attention actually so just try to read
66:07 - uh this particular paper at least try to
66:09 - read the introduction of it uh there we
66:12 - have uh there they have defined that uh
66:14 - what was a problem with the encoder and
66:16 - decoder and where this attention comes
66:18 - into the picture and what is the actual
66:20 - meaning of the attention they have
66:21 - introduced each and everything over here
66:24 - inside this particular paper inside this
66:26 - particular paper they have introduced
66:28 - each and everything regarding the
66:29 - attention see this is the architecture
66:31 - of the attention model and uh before
66:33 - going through with any blog any website
66:35 - or any tutorial try to uh go through
66:37 - with the research paper and try to
66:39 - understand the motive of that research
66:41 - paper now see guys uh here I'm not going
66:44 - into the detail of the attention because
66:47 - this attention itself uh is a longer
66:49 - topic but I can uh like give you the
66:51 - glimpse of that that uh uh what what
66:54 - they were doing in the attention so they
66:56 - were mapping so let's say we have a five
66:58 - words in the sentence so they were
66:59 - trying to map each word whatever word we
67:02 - have a input we were trying to match
67:04 - each each input word with the output
67:06 - word means this input and output this
67:10 - encoder and decoder if we are talking
67:11 - about this decoder actually so this is
67:13 - having the uh information each and every
67:15 - information of the Hidden State whatever
67:18 - like in the encoder like you will find
67:19 - out this RNN lstm or whether it's a GRU
67:23 - so uh we have a hidden State actually
67:25 - right so uh this decoder part is having
67:28 - the information regarding those
67:30 - particular hidden State all the hidden
67:32 - State and because of that it was able to
67:35 - uh it was able to predict so whatever
67:38 - like sentence and whatever words or
67:40 - longer sentences or like U like uh the
67:43 - longer sentences and all which uh
67:46 - whatever basically we were passing it
67:47 - was able to predict okay so this word is
67:49 - related to that particular sentence so
67:51 - what I will do I will create a like a
67:53 - one dedicated video on top of it there I
67:55 - will try to discuss uh this attention
67:57 - mechanism but yeah here I'm just giving
67:59 - you the timeline U and with that um you
68:02 - can clearly understand so uh here we
68:05 - were having the attention mechanism now
68:07 - guys by using this attention mechanism
68:10 - by using this attention mechanism in
68:12 - 2018 Google again Google published one
68:16 - research paper and the research paper
68:18 - name was
68:22 - attention about this encoder in the
68:25 - encoder and this decoder we were using
68:29 - what we were using guys tell me we were
68:30 - using this LSM either we are using the
68:33 - lstm RNN or maybe Gru now uh there also
68:39 - we are having the lstm maybe RNN or
68:42 - maybe you are having the Gru and uh if
68:45 - we are talking about the attention so
68:46 - whatever uh information we are passing
68:48 - from here to here so you are having the
68:50 - context Vector context Vector now on top
68:53 - of that we are having the attention
68:55 - layer attention layer and it was nothing
68:58 - it was just a mapping from input words
69:01 - to out output word now here actually
69:05 - they have published one paper in 2018
69:08 - and the paper name was attention all
69:11 - your need attention all your need now
69:16 - this paper actually it was a
69:17 - breakthrough in the NLP history this
69:20 - paper has been published in
69:22 - 2018 and here
69:27 - actually
69:29 - decoder but there is one uh there is one
69:32 - thing basically in terms of this encod
69:34 - and decoder you won't be able to find
69:36 - out this lstm RNN and Gru they are not
69:38 - using any RNN cell any lstm cell or any
69:41 - Gru cell so here actually they were
69:44 - using something else and here the what
69:47 - is a uh name of the research paper so
69:49 - they were saying that attention all your
69:51 - need only attention is required for
69:54 - generating us let's say we are passing
69:56 - any sort of an input means any longer
69:58 - input so from that particular input only
70:01 - attention is required for generating
70:03 - output now how let me show you
70:09 - that this Transformer architecture or
70:12 - let me show you the attention all your
70:14 - need research paper so attention all
70:17 - your need research paper so guys this is
70:22 - a very uh prestigious paper in our NLP
70:24 - history and uh this changed the complete
70:27 - history of the NLP and whatever llm and
70:29 - all whatever you are seeing like
70:31 - nowadays so they have used this
70:35 - Transformer architecture as a base model
70:37 - I will come to that and there I will try
70:39 - to uh discuss that uh what is the
70:41 - encoder and decoder again I'm not going
70:43 - into the depth of the mathematics but
70:45 - yeah definitely I will try to give you
70:47 - some sort of a glimpse so over here uh
70:49 - let me zoom in first of all this paper
70:53 - and and here guys the paper name was
70:55 - attention is all your need so this was
70:58 - the researcher asish Nome Nikki Jacob
71:01 - you can uh search about these particular
71:03 - people and here is the abstract uh you
71:06 - can see and this is the introduction at
71:08 - least try to read the introduction try
71:10 - to read this particular background and
71:12 - the model architecture so this was the
71:14 - model architecture which has been
71:16 - introduced by the uh by the Google
71:18 - researcher and the architecture
71:20 - basically which you will find out inside
71:22 - this research paper I think everywhere
71:24 - you will find out this uh this
71:26 - particular architecture in uh whatever
71:28 - NLP tutorial or if you are going to
71:30 - understand the attention mechanism and
71:32 - all so this is the architecture now in
71:34 - this particular architecture let's try
71:36 - to understand that what all things we
71:38 - have so see first of all we have a
71:41 - input okay try try to understand try to
71:44 - focus over here so we have a input over
71:46 - here then we have a input embedding so
71:48 - this is my first thing input and this is
71:50 - what this is the input embedding the
71:52 - third thing which we have that is a
71:53 - positional encoding getting my point and
71:56 - then after that you will find out the
71:58 - multi-headed attention then we have a
72:00 - normal uh normalization and all and then
72:02 - we have a feed forward Network now guys
72:06 - just tell me this is what this is a
72:07 - encoder part this is what this is a
72:09 - encoder part and this is what guys this
72:11 - is this is a decoder part this is the
72:14 - decoder part got it getting my point so
72:17 - here also we have a two segment first
72:19 - was the encoder and the second was the
72:21 - decoder but here we are not using any
72:23 - RNN cell lstm cell or maybe Gru cell
72:27 - here actually we are using something
72:28 - else some other concept and the concept
72:31 - actually I think this is not a new thing
72:32 - for you this embedding and all uh this
72:35 - embedding attention already I talked
72:37 - about the attention that what it is
72:39 - mathematically it is having a like uh
72:41 - like a some different explanation but
72:43 - yeah I think you got to know the idea
72:45 - now here we have a feed forward neural
72:47 - network you know like what is a like
72:49 - artificial neural network what is a feed
72:51 - forward neural network so it's not a
72:52 - like a new thing for all of you and by
72:55 - assembling all those thing they have
72:57 - created one cell one architecture and
73:00 - the name is called this uh Transformer
73:04 - so this architecture itself is called a
73:06 - Transformer what is this guys tell me
73:08 - this is a Transformer now here guys just
73:10 - see uh this uh Transformer if we are
73:13 - talking about this Transformer and all
73:16 - so let me uh tell you few things
73:18 - regarding this Transformer uh so first
73:20 - of all guys this is a uh fast compared
73:23 - to the classical architecture if we are
73:25 - talking about this RNN lstm and all so
73:28 - there we are passing the input based on
73:30 - a Time stem based on a Time stem but if
73:34 - we are talking about this Transformer
73:35 - guys so here what is the importance or
73:38 - what is the like plus point which we
73:40 - have inside the Transformer it is a
73:41 - faster why because we can pass the input
73:44 - in a parallel manner we can pass all the
73:47 - inputs all the tokens in a parallel
73:49 - manner in a parall actually we can pass
73:52 - the input now over here see we have a
73:54 - input embedding we are doing an
73:55 - embedding over here and then we have a
73:57 - positional encoding means we are
73:59 - arranging a sequence sequence of the
74:01 - sentence then we have a multi-headed
74:03 - attention again we are trying to uh
74:05 - figure out the uh meaning see let's say
74:08 - uh the sentence is what I am Sunny now
74:12 - uh here it is trying to find out the
74:14 - relation I with M and sunny is trying to
74:16 - find out the relation M with uh this I
74:19 - and sunny it's time to find out a
74:21 - relation this sunny uh and this m and
74:24 - this I so it is trying to find out a
74:26 - relation with each and every word so it
74:28 - is doing the same thing inside the
74:29 - multi-headed attention then you will
74:31 - find out this feed forward Network
74:33 - neural network actually and yes uh this
74:36 - is what this is my encoder part as I
74:38 - told you this is what this is my encoder
74:40 - part now if you will look into the
74:42 - decoder side so again we have a same
74:44 - thing so here we have a outputed output
74:46 - embedding means in uh uh like whatever
74:49 - uh like a sequence uh in whatever like U
74:52 - am format I want output so that is uh
74:56 - this particular thing this output Ting
74:58 - and then again we have a like
74:59 - multi-headed attention and we are
75:01 - passing this thing uh to the next one to
75:03 - the next layer and again we have a feed
75:05 - forward neural network over here on top
75:07 - of this you will find out the soft Max
75:09 - and finally we are getting a output
75:11 - output probability so don't worry I will
75:13 - try to discuss this Transformer
75:15 - architecture mathematically in a
75:17 - detailed way in some other video but as
75:19 - of now I'm just giving you the GL
75:20 - Glimpse because whatever llms we are
75:22 - going to discuss
75:25 - okay as a base architecture they are
75:27 - using this
75:29 - Transformer so guys until here
75:31 - everything is fine everything is clear
75:33 - please do let me know in the chat yes or
75:47 - no yes you can uh let me know in the
75:49 - chat uh then I will proceed with the pp
75:51 - and all and uh we'll try to wrap up the
75:54 - uh introduction of this llm and all and
75:57 - in tomorrow's session we'll try to talk
75:58 - about the open a and we'll discuss about
76:01 - the open API and all and a different
76:03 - different models of the
76:07 - openi any doubt anything so if you have
76:09 - any sort of a doubt please do let me
76:11 - know guys please do let me know in the
76:12 - chat uh I will try to clarify that uh
76:15 - those doubt and
76:22 - uh
76:24 - so did you get a timeline timeline of
76:26 - the llm I will come to the llm now the
76:28 - specific word and
76:32 - uh after deep learning an NLP what is
76:35 - the topic uh for generative AI please
76:38 - give up uh so after the Deep learning
76:42 - and see after the Transformer actually
76:44 - by using this particular Transformer
76:46 - people has created a different different
76:47 - llms and all large language model now I
76:49 - will come to that by using the slide I
76:51 - will try to show you that
76:53 - I think this
76:57 - is pry much clear now let me go back to
77:00 - this uh uh notes and here you can see so
77:05 - I started from the deep learning then
77:07 - generative VI and all then you got to
77:09 - know that where generative a lies then
77:11 - Alm Gru different different mapping
77:13 - encoder decoder attention and finally
77:16 - attention all your need now let's try to
77:19 - understand uh like rest of the thing by
77:20 - using the slide so here guys uh one more
77:23 - thing I think we were uh trying to
77:26 - understand this particular part where
77:28 - this generative AI exists and I hope you
77:30 - got a clearcut idea now let me go back
77:33 - to the uh let me like come to the next
77:35 - slide so in this slide you can see uh
77:37 - I'm talking about the generative versus
77:39 - discriminative model so what is the
77:41 - difference between this generative and
77:42 - discriminative model so we are talking
77:44 - about this discriminative model so
77:46 - whatever you have learned so far in a
77:48 - classical machine learning and deep
77:50 - learning so uh let's say uh I'm I'm
77:53 - talking about this uh any classification
77:55 - based model let's say I'm talking about
77:57 - this uh RNN so here actually see uh you
78:01 - are training your model on a specific
78:02 - data so this is your data this is your
78:04 - input and here is your output what you
78:06 - are doing guys tell me you are
78:07 - performing a supervised learning you are
78:10 - performing a supervised learning by
78:11 - using this recurrent neural network
78:14 - there is a classical model or we have
78:16 - like other classical model and all you
78:18 - can use any uh uh like a machine
78:20 - learning based model as well like na
78:22 - buers and uh different different
78:24 - variants of the nap bias or maybe some
78:26 - other model you can uh use that
78:28 - particular model also uh so over here we
78:31 - have a model and we are going to train
78:33 - this model by using the supervis machine
78:35 - learning there we are going to pass a
78:37 - specific type of data to this particular
78:39 - model and here we have a different
78:41 - different output like a rock this music
78:44 - is belong to the rock music classical
78:45 - music or maybe ranting so here we are
78:49 - passing this uh like music to my model
78:51 - and finally it is going to predict
78:53 - something like that this is a
78:54 - descriptive model now if we are talking
78:56 - about a generative model so this is a
78:59 - little different compared to this
79:01 - discriminative model how it is different
79:04 - uh compared to this discriminative model
79:05 - so here guys see we are training this
79:08 - see first of all the if we are talking
79:11 - about the generative model if we talking
79:13 - about the generative model so the
79:14 - training process is a little different
79:16 - if we are talking about the large
79:18 - language model if we are talking about
79:20 - the llms so uh the proc of training this
79:24 - llms is a little different compared to
79:27 - this discriminative model now over here
79:29 - we are talking this discri this
79:30 - generative model basically so we are
79:32 - passing the input to this generative
79:34 - model and we are getting an output how
79:37 - how so here basically we have a
79:39 - different different step for Gen for
79:41 - like training this generative models so
79:44 - gain wise I already told you that what
79:45 - is a like process if you want to like
79:47 - train uh any gain model if we are
79:49 - talking about llm large language model
79:52 - so at the first first place there will
79:53 - be unsupervised learning unsupervised
79:55 - learning then at the second place we'll
79:57 - be having a supervised fine-tuning and
80:00 - at the third place uh basically we have
80:02 - a reinforcement learning reinforcement
80:04 - learning they have recently used inside
80:06 - the chat uh in the GPD model itself uh
80:09 - which we are using for the chat GPD but
80:11 - before that whatever llm model they have
80:13 - created they have created they have
80:15 - trained on a large amount of data so for
80:17 - that first they have performed the
80:19 - unsupervised learning and then they have
80:20 - performed the supervised fine tuning
80:23 - so because of that that model were able
80:25 - to understand each and every pattern
80:27 - which was there inside the data and
80:29 - because of that it was able to generate
80:31 - the output so this generative model is
80:34 - nothing in that basically we have a data
80:37 - on top of that particular data we are
80:38 - training a model and for that we have a
80:41 - various step and uh basically then only
80:44 - we are going to do a prediction so what
80:46 - it is giving me as a prediction so
80:47 - whatever input we are passing so that
80:49 - input it is taking and finally it is
80:51 - generating uh the output related to that
80:54 - particular input means it is generating
80:56 - a new
80:58 - data getting my point I think this part
81:01 - is clear to all of you how this
81:03 - generative model is different from this
81:05 - discriminative model discrimin model is
81:07 - a classical model like supervised
81:08 - learning uh we are performing The
81:09 - supervis Learning now right so here we
81:12 - are having the RNN and we are passing a
81:14 - data and all and we are trying to train
81:15 - it generative model various step we have
81:19 - like for the training and all and it is
81:21 - responsible for generating a new new
81:22 - data that's it so I hope guys this uh
81:25 - thing is clear to all of you now I have
81:27 - kept couple of more slide regarding uh
81:30 - this particular concept just try to note
81:32 - down the uh the headings and all and try
81:34 - to remind uh this particular thing this
81:37 - discriminative versus generative model
81:38 - and all now here uh the same thing
81:41 - unsupervised supervised learning which
81:43 - is related to this uh discr model got it
81:46 - and here uh you can see uh this is the
81:49 - generative like model so in the
81:51 - generative model what we do first we
81:53 - perform the unsupervised learning we are
81:54 - doing a grouping and all and then we
81:56 - discri we perform the supervised
81:58 - finetuning supervised learning so that
82:00 - is a like process for training a uh like
82:04 - any sort of a llm model which comes
82:06 - under inside the generative AI itself
82:08 - and again wise I already talked about it
82:11 - now here actually uh we're going to talk
82:13 - about this uh llm so let me give you the
82:17 - quick idea about this llm and all that
82:19 - is what that is a large language model
82:21 - so for that all Al I have created one
82:23 - slide and there specifically I kept the
82:26 - thing related to this uh llms only so
82:30 - let me start from the very first slide
82:32 - uh let me give you the overview and uh
82:35 - from tomorrow uh actually in tomorrow
82:37 - session I will give you the detail uh
82:39 - like overview uh with respect to
82:41 - different different models and all
82:42 - whatever we have as of now just a quick
82:45 - introduction now what is the llm so llm
82:48 - is nothing it's a model it's a large
82:50 - language model which is trained uh like
82:52 - U it's a large deep uh it's a large
82:55 - language model which has been trained or
82:57 - a huge amount of data and it is behaving
83:00 - like it is generating something right so
83:03 - actually by using this uh llm we can
83:05 - generate any uh like a sort of a data
83:08 - like Text data or maybe image data and
83:11 - that is a like uh that is a advantage or
83:14 - that is a like uh uh one uh very uh like
83:18 - a very famous uh thing regarding this
83:20 - llm and all now if we are talking about
83:22 - this why this is called llm why this is
83:24 - called large language model so here guys
83:27 - if we are talking about this large
83:29 - language model so because of the size
83:31 - and the complexity so here specifically
83:34 - I have mentioned regarding this large
83:36 - language model regarding this llm why
83:39 - this is called this uh this large
83:40 - language model so here because of the
83:42 - size and because of the complexity of
83:45 - the neural network uh neural network
83:49 - neural network as well as the size of
83:50 - the data set uh which has has been uh
83:53 - which is trained on actually this is
83:55 - trained on the huge amounts of data
83:57 - because of that only actually it is
83:59 - called a large language model so here uh
84:02 - if we are talking about this uh L large
84:04 - language model so uh actually before we
84:08 - were not having the huge amount of data
84:11 - so uh recently actually uh you know uh
84:13 - this uh data generation and all uh Big
84:16 - Data actually came into the picture and
84:18 - this companies and all generated a huge
84:20 - amount of data and this Google also
84:22 - Google Facebook and the other companies
84:24 - is having a huge amount of data so uh
84:27 - they uh they are able to like find uh
84:30 - means uh actually they have uh gathered
84:33 - that particular data and on top of that
84:35 - data they have uh like as I told you
84:37 - they have performed the unsupervised
84:38 - learning and all and they have
84:40 - categorized a data and they have
84:41 - provided to a different different model
84:43 - which U like has been created like GPT B
84:45 - and all and because of that uh like they
84:49 - were able to predict the next next
84:51 - sentence and that is a like a main thing
84:53 - main advantage of this large language
84:55 - model now over here you will find out so
84:58 - in the next slide uh I have mentioned
85:00 - that what is the what makes llm so
85:03 - powerful so here by using one single
85:05 - model by using one single llm actually
85:08 - we can perform a different different
85:10 - type of task like text generation
85:12 - chatboard uh we can create a chatboard
85:14 - also we can uh do the summarization
85:16 - translation code Generation by using a
85:19 - single LM we can do that particular
85:22 - thing
85:22 - now here uh if you will find out so
85:25 - already I told you that what is the base
85:27 - architecture of the llm so here this
85:30 - Transformer is what it's a base
85:31 - architecture behind this llm behind this
85:34 - large language model and I have already
85:37 - explained you the concept of the uh
85:39 - Transformer that what we having inside
85:41 - the Transformer now here guys uh this is
85:43 - a few Milestone which we have in terms
85:46 - of the llm like bird is there I think
85:49 - you know about the bird if we are
85:51 - talking about the uh we are talking
85:53 - about the like a bad days right or old
85:55 - days in 2018 19 or 20 when uh chat GPD
86:00 - was not there just uh this uh GPT was
86:02 - not there GPT 3.5 and all the recent
86:05 - model which we are using inide of chat
86:07 - GPT so there were few Milestone and we
86:09 - were using this thing in our old days
86:11 - like B was there GPT uh actually GPT is
86:14 - having a different different variant it
86:15 - is having a complete family GPD 1 2 3
86:18 - and 3.5 and recently GPD 4 came into the
86:21 - picture and other variants as well so
86:24 - xlm is also there uh cross lingual
86:27 - language model pre-training by uh this
86:30 - particular guy now T5 was also there
86:32 - this a text to text
86:34 - transfer text to text transfer transform
86:37 - Transformer and it was created by the
86:39 - Google Now Megatron was also there so
86:41 - Megatron actually it was created by the
86:43 - Nvidia now M2M was there so it was the
86:46 - part of the Facebook research so there
86:48 - were many uh like uh there was the uh
86:51 - like many model actually actually okay
86:53 - and this was a milestone in uh this uh
86:56 - in terms of this large language model
86:58 - now over here guys see this bird GPT xlm
87:01 - T5 they are using a base architecture as
87:04 - a Transformer one only now if you will
87:06 - see in the next slide so I have
87:08 - categorize this thing so they are using
87:10 - a base architecture as a Transformer one
87:12 - only but in that you will find out some
87:14 - of the model are using a encoder and
87:17 - some of the model are using a decoder
87:20 - and some of the model are using both
87:22 - encoder and decoder now here I have
87:24 - categorized this particular thing that
87:26 - uh this is the model like B Roberta xlm
87:30 - Albert Electra DTA so these are the
87:34 - model they are just using the encoder
87:36 - only and if we are talking about this
87:38 - decoder uh if we are talking about the
87:40 - GPT GPT uh 2 gpt3 GPT new or like the
87:44 - entire family of the GPT so they are
87:46 - using this decoder so we have a two
87:49 - segment of the Transformer architecture
87:51 - few of models they are using an encoder
87:53 - side encoder part and few model
87:55 - basically they are using a decoder and
87:57 - uh here guys you will find out some
87:59 - model which is which are using both
88:01 - encoder as well as decoder so this T5
88:05 - Bart M2 m00 Big B so these are the model
88:08 - actually they are using both encoder and
88:10 - decoder in the Transformer architecture
88:13 - if you'll find out we have a two segment
88:15 - so this is a this segment basically this
88:17 - one is called an encoder segment and
88:19 - this particular segment this is called a
88:21 - decoder segment so here uh like I think
88:24 - you got to know uh you got to know the
88:26 - idea that uh this is what this is a like
88:29 - uh transform this is the encoder segment
88:32 - and this is what this is a decoder
88:33 - segment and this model this T5 B M2M and
88:37 - big but they are using both and we have
88:39 - other models as well I just written this
88:41 - uh couple of name over here now apart
88:44 - from this you will find out some openi
88:46 - based model open a based llm model so
88:48 - GPD 4 is there GPD 3.5 is there GPD
88:51 - based is there Delhi Biser iddings okay
88:55 - so these are the different different
88:56 - model which you will find out over the
88:58 - open website itself and uh here uh
89:01 - definitely GPT is uh one of the
89:03 - prestigious model or this is one of the
89:05 - very important model which uh people are
89:08 - using uh nowadays for creating their
89:10 - like applications and all and it is it
89:12 - can perform any sort of a task related
89:15 - to a generation okay now over here uh
89:19 - this is the openi based model which I
89:21 - have written now apart from this you
89:23 - will find out other open source model so
89:26 - this is the model from the openi side so
89:28 - if you are going to hit this model so
89:29 - definitely open is going to charge you
89:32 - regarding the tokens regarding the uh
89:34 - regarding like how many tokens and all
89:36 - whatever you are using according to that
89:38 - it is going to charge you but here we
89:40 - have some couple couple of Open Source
89:42 - model as well and I have written the
89:45 - name like Bloom Lama 2 Palm Falcon Cloud
89:49 - amp okay stable LM and so on we have a
89:52 - various model various open source model
89:55 - and uh yes but I I will show you that
89:58 - how you can use this particular model if
90:00 - you are going to create your application
90:02 - so definitely I will let you know I will
90:04 - show you that how you can utilize this
90:05 - model as well I will show you the use of
90:07 - the Falcon I will show you the use of
90:09 - the Llama 2 if you don't want to use
90:11 - this GPT uh GPT 3.5 GPT 3.5 turbo I will
90:15 - show you the use of this llama and this
90:17 - Falcon and some others open source model
90:19 - as well I think you are getting my point
90:22 - now here uh if we are talking about what
90:26 - can llm be used for so if we are talking
90:28 - about llm that what it can do so it can
90:32 - uh we can use this llm for any sort of a
90:34 - task like classification text generation
90:37 - summarization chat board question
90:39 - answering or maybe speech recognization
90:41 - speeech identification spelling
90:42 - character so this uh llm actually uh if
90:46 - we are talking about this L LM so first
90:48 - of all it's a model it's a large model U
90:51 - it's a language anguage model and it's a
90:52 - large model it's a large language model
90:55 - and what is a like what we can do by
90:58 - using this large language model we can
91:00 - generate the data okay it can identify
91:03 - the pattern of the data it is having
91:05 - that cap cap uh that uh that much of
91:08 - capacity so it can identify the pattern
91:10 - from the data and by using those pattern
91:14 - we are we can perform a various amount
91:16 - of
91:17 - task okay that's why this llm is too
91:20 - much powerful
91:22 - and here we can use this llm for any
91:24 - sort of a task and yes uh we know about
91:28 - this it and already I have uh like I
91:32 - explain you this thing I hope this
91:34 - introduction is clear to all of you now
91:36 - coming to this uh prompt design so
91:38 - prompt design and all uh definitely I
91:40 - will talk about it uh once I will come
91:42 - to this open a API there will try to hit
91:45 - the uh different different models of the
91:47 - open a and uh we have a different
91:50 - different type of prompts so as as of
91:52 - now you can think that the prompt is
91:53 - nothing whatever input we are passing to
91:55 - the model uh that is called input prompt
91:58 - and whatever output we are getting from
91:59 - the model itself that is called the
92:02 - output prompt and here how cat GPD was
92:05 - trained so generative of pre-training
92:08 - supervise fine tuning and this
92:10 - reinforcement learning there was three
92:12 - step which I have mentioned so I will be
92:14 - talking about this also and not in
92:17 - today's session in the like next session
92:20 - uh I'll be talking about this uh how CH
92:22 - GPT and all it was stained uh okay now
92:26 - what I can do so over here guys uh I
92:29 - think uh we should uh conclude the
92:32 - session so how was the session please uh
92:35 - do let me know in the chat it was good
92:37 - bad or what so did you uh understood
92:41 - everything did you understand everything
92:43 - whatever I have explained you uh
92:45 - regarding this uh regarding this llm and
92:47 - this generative AI the complete
92:49 - introduction because uh I want that
92:52 - before starting with any sort of a
92:54 - practical the basics should be
93:04 - clear everything did you
93:07 - understand amazing
93:10 - great to what is the
93:14 - topic
93:17 - yes fine uh if you have any doubt and
93:20 - all so you can ask me I will try to
93:22 - answer for that now before concluding
93:24 - with uh like uh before concluding the
93:28 - session let me show you few more things
93:30 - over here so see uh here first of all
93:33 - what you need to do uh first of all you
93:35 - need to like uh go through with the open
93:37 - a and you need to generate a open a API
93:40 - and all so that uh basically don't worry
93:43 - I will show you while I will be doing a
93:44 - practical and all so you need to like at
93:47 - least you need to create an account and
93:49 - uh and you need to login it over here so
93:51 - so once you will log in guys here you
93:53 - will get two option first is chat GPT
93:55 - and the second is API just go through
93:57 - with this API and generate this API key
94:00 - generate the API key from here don't
94:02 - worry in the next session in the next
94:04 - class again I will show you this thing
94:06 - and here I see we have a different
94:08 - different model so let me show you those
94:10 - model and whatever open source model and
94:13 - all is there so you will find out over
94:14 - the hugging phase so let me show you the
94:17 - hugging face models hugging face Hub and
94:21 - uh here you will find out the model Hub
94:24 - so guys uh here actually we have a model
94:27 - Hub just a second yeah models now you
94:31 - will find out a different different type
94:33 - of model see these are the models which
94:36 - is a open source and uh uh you'll find a
94:38 - complete description let's say this uh
94:40 - we are talking about this Orca 2 so this
94:43 - updated 12 days ago and it's a recent uh
94:45 - llm model uh which has been published uh
94:48 - by the Microsoft now over here you can
94:52 - see so it like you will find out the
94:54 - complete description or complete detail
94:56 - regarding this model and like uh how to
95:00 - use it and uh each and everything
95:02 - basically definitely we'll talk about it
95:04 - now for what all task basically we can
95:06 - use it okay so according to that also
95:09 - you can uh like select the models so
95:11 - just go through with the hugging phase
95:13 - models and there you will find out many
95:15 - uh like a different different models
95:18 - okay and yes for sure openi is also
95:20 - having uh different different llm model
95:22 - so we'll talk about that we'll try to
95:24 - understand the concept of this uh we'll
95:26 - try to understand this uh assistant
95:28 - actually and we'll try to talk we'll try
95:30 - to understand the chat U actually so
95:33 - what is this and how to use it how to
95:35 - use this chat option and this assistant
95:37 - option and here if you will go inside
95:39 - the documentation so you will find out
95:41 - of different different models over here
95:43 - this GPT GPT 3.5 Del TTS whisper
95:47 - embedding moderation GPT W gpt3 right
95:51 - right different different models we have
95:53 - and uh apart from that you can find out
95:55 - the different different task according
95:57 - to that also they have given you the
95:59 - model so text generation so they have
96:00 - given you the complete code and all so
96:02 - just try to visit it just try to go
96:03 - through it uh by yourself now uh we have
96:07 - other uh platform as well so if you are
96:10 - not going to use the uh maybe J uh if
96:14 - you don't want to use this uh GPT and
96:16 - all so here uh I can show you one more
96:19 - uh like option so
96:23 - AI 21 okay so AI 21 Labs AI 21 Labs so
96:27 - this is the Recently I figured it out
96:29 - actually this is the uh like alternative
96:32 - of the GPT so we'll talk about this also
96:34 - if you don't want to pay to this uh if
96:36 - you don't want to pay for the GPT so you
96:38 - can use this AI 21 lab uh and it will
96:42 - give you the uh like a uh one model one
96:45 - llm model so you can use it uh like
96:48 - freely actually it gives you the $90
96:50 - credit so so yes I will show you how you
96:53 - can use this AI 21 lab uh so let me show
96:56 - you the documentation and let me show
96:57 - you the models as well so here you will
97:00 - find out the uh model basically which is
97:03 - there so Jurassic 2 is a model and it's
97:05 - like a pretty amazing model and uh uh
97:09 - yes definitely I'll be talking about it
97:11 - and along with that uh the applications
97:13 - of it which is very much required that
97:15 - for what all task we can use it whether
97:17 - if you are going to create a chat board
97:19 - or maybe if you are going to do a
97:21 - question answering or text generation or
97:24 - like sentiment analysis for what type of
97:27 - task we should use it and how to design
97:28 - a prompt and all regarding the specific
97:31 - task got it so we'll talk about this
97:34 - also so uh yes many things is there and
97:37 - definitely uh uh like from Tomorrow
97:40 - onwards I'm going to start from the open
97:42 - a lure and step by step I will come to
97:44 - the uh different different models and
97:47 - all so I hope guys this is uh clear
97:53 - yes practical implementation will be
97:55 - there don't
97:58 - worry yes recording will be available
98:00 - over the
98:05 - YouTube yes all the uh all the topic
98:07 - will be covered in the upcoming session
98:09 - uh all the discussed topic and
98:15 - all yes definitely this will be
98:18 - available in the dashboard you can go
98:19 - and check uh your dashboard this uh
98:21 - video along with the video you will find
98:23 - out the assignment you will find out the
98:25 - quizzes and regarding the particular
98:42 - topic fine I think uh we can conclude
98:45 - the session
98:48 - now is gener andm are also used in
98:51 - computer vision based project so for
98:54 - computer vision based project we have a
98:56 - uh like others model we have a different
98:58 - models uh because uh the task is
99:00 - different over there so the task wise we
99:03 - are talking about the computer vision
99:04 - related task like object detection
99:06 - object segmentation tracking OCR object
99:09 - classification and for that we have a
99:11 - different model and definitely we can
99:13 - use a transfer learning of finding over
99:15 - there now uh by using this L llm um like
99:20 - this llm is for the like a different
99:22 - task it is related to the language
99:23 - related task it is not related to that
99:27 - detection or a segmentation or tracking
99:30 - it is not related to that particular
99:31 - task it is related to the language
99:34 - related task and uh here see let me show
99:37 - you one uh one more paper one more
99:39 - research paper so here I can show you
99:42 - this uh ULM fit now see uh so just try
99:46 - to go through with this particular paper
99:48 - universal language model find tuning for
99:51 - text classification now here in this
99:54 - particular paper you will find out that
99:56 - see uh this uh if you know the Deep
99:59 - learning so in the Deep learning we have
100:01 - uh two major concept so the one one
100:04 - concept is uh called transfer learning
100:07 - transfer learning the second concept is
100:09 - called fine tuning F transfer learning
100:11 - means what so you are transferring the
100:14 - information from uh from one state to
100:17 - another state okay or like you can I can
100:21 - give you very simple example for that
100:22 - let's say you know like how to how to
100:25 - write the cycle so for you like for if
100:29 - you know how to write the cycle
100:31 - definitely you can use that information
100:33 - and you can write the motorcycle also so
100:36 - that is the same thing basically which
100:37 - we uh do inside the transfer learning
100:40 - let's say we have trained the model uh
100:42 - like let's say we are talking about the
100:44 - computer vision so inside that uh you'll
100:47 - find out uh we have a various Tas like
100:49 - detection classification tracking and
100:51 - all so let's talk about the model let's
100:53 - say YOLO so or we have other model also
100:56 - like faster rcnn rcnn and all SSD SSD
100:59 - and all like a different different model
101:02 - related to a detection so the model
101:03 - already has been trained on some sort of
101:05 - a data some amount of data on some
101:07 - Benchmark data so by using that
101:09 - particular information we can uh like
101:11 - perform the detection and all for our
101:13 - specific task if we are not able to do
101:15 - it then definitely I will fine-tune my
101:17 - model but how we can use the same thing
101:21 - in NLP because in NLP actually we have a
101:25 - task uh the task is very specified we
101:27 - have a specific task let's say we are
101:29 - talking about um if we are talking about
101:33 - a task let's say uh ner name entity
101:36 - recognization or let's say we are
101:38 - talking about the task let's say a
101:40 - language gener language translation
101:43 - language
101:44 - translation language translation or
101:46 - maybe sentiment analysis so these are
101:48 - the specific task specific task ask
101:51 - means regarding to the specific uh
101:53 - regarding to the specific topic let's
101:55 - say if I want to do a sentiment analysis
101:57 - so not for the entire data whatever
102:00 - there in the world for the specific uh
102:02 - let's it for the Twitter data only means
102:04 - whatever TW tweets and all we are
102:06 - getting now if we are giving any other
102:08 - data un any other like a task related
102:11 - data so it won't be able to perform that
102:13 - so actually in this particular paper you
102:15 - will find out that how we can use this
102:18 - uh language model language model
102:21 - for uh like for the universal task and
102:24 - there only this llm comes into a picture
102:26 - L this llm actually it came from the
102:28 - language model itself okay because we
102:31 - are training this uh language model on a
102:33 - huge amount of data that is why it is
102:35 - called llm large language model because
102:37 - we have we have trained this data on a
102:39 - huge amount of we have trained this
102:40 - model on a huge amount of data got it so
102:43 - here in this particular paper they have
102:45 - like shown you that how to use this
102:48 - transfer learning because uh in before
102:51 - 2018 uh actually we were using this
102:53 - transfer learning in the computer vision
102:55 - only in the uh like in a different
102:58 - different tasks of the computer like
102:59 - object detection or segmentation you
103:01 - will find out the image data so on top
103:05 - of that data we have trade like a Ben
103:06 - model and directly like like vgg rset
103:10 - and all and directly we are using those
103:11 - particular model for our like a other
103:14 - task so here if we are talking about the
103:16 - NLP so we are not able to do it before
103:19 - this Transformer and all so actually see
103:21 - we got a Transformer we got this
103:23 - particular concept like how we can use
103:25 - this transfer learning and all in the
103:27 - like NLP field so this two concept came
103:30 - together transfer learning and the
103:32 - architecture like Transformer self
103:34 - attention and all and from there itself
103:36 - this uh llm came into the picture llm
103:38 - means large language model which has
103:40 - been train on a huge amount of data
103:42 - which is able to perform the transfer
103:43 - learning and we can do it uh we can find
103:46 - T it also and the main uh like uh
103:51 - the main cap or the main uh role of the
103:54 - llm is what it is able to generate a
103:56 - text text generation got it so fine I
104:00 - think we are done with the session now
104:02 - so rest of the thing we'll try to
104:05 - discuss in the uh tomorrow session and
104:07 - we'll try to more focus on the Practical
104:08 - side so all the recordings and all it
104:11 - will be updated on a dashboard and uh
104:14 - yeah that is it yes so I think uh we can
104:17 - start with the session now so yeah uh
104:20 - welcome again again uh so you all are
104:22 - welcome in this uh Community session
104:24 - generative AI Community session uh
104:26 - yesterday we have started this uh
104:28 - generative AI Community session where we
104:30 - have discussed about the generative AI
104:32 - so there I have given you the
104:34 - introduction related to the generative
104:35 - Ai and large language models and here
104:39 - you can find out the video so this is
104:40 - the dashboard uh it's a free dashboard
104:43 - actually uh which we have created for
104:45 - all of you the same video actually it is
104:47 - available over the Inon uh YouTube
104:49 - channel as well if you we will go in a
104:51 - live section so this uh same video you
104:53 - can find it out over there as well now
104:56 - uh let me show you uh that particular
104:59 - video so here is my YouTube now let me
105:03 - search over here I neon and here guys uh
105:07 - go inside this uh live section and this
105:10 - is the video so the same video same
105:13 - lecture you will be able to find out
105:15 - inside the live section apart from this
105:17 - uh the same uh thing basically we are
105:20 - uploading or the in neuron dashboard and
105:23 - here along with the video you will find
105:24 - out the resources so all the resources
105:27 - basically whatever I'm using throughout
105:29 - the session uh so whatever notes and all
105:32 - which I'm writing and whatever PPS and
105:34 - all or whatever code file I'm using
105:37 - throughout the session you will find out
105:39 - all the resources over here got it guys
105:42 - yes or no so do you have this dashboard
105:45 - do you have this dashboard tell me I
105:48 - think uh many people are androll
105:51 - yesterday uh for this free community
105:53 - session and yes all the videos and all
105:57 - basically we are going to upload over
105:58 - here not even video and resources along
106:01 - with the video and resources you will
106:03 - find out the uh live uh you will find
106:06 - out the quizzes and assignment as well
106:07 - so already uh I have prepared the
106:10 - quizzes and assignment so soon it will
106:12 - be uploaded over here so in this
106:14 - particular video you will find out one
106:16 - more section so the section will be
106:18 - quizzes and assignment so there you will
106:20 - find out a uh like uh a video related or
106:24 - a topic related quizzes and assignment
106:27 - got it yes or no so please uh give me a
106:30 - quick confirmation in the chat if this
106:32 - uh dashboard related thing and this uh
106:34 - video related thing is clear to all of
106:36 - you I'm waiting for your reply in the
106:38 - chat and if you have any sort of a doubt
106:41 - then you can ask me in the like chat
106:43 - section as well and don't worry my team
106:45 - will give you the link of the dashboard
106:47 - so if you haven't enrolled so far so uh
106:50 - by using that particular link definitely
106:52 - you can enroll it you can enroll U
106:55 - inside the
106:57 - dashboard great all clear all clear
107:12 - great fine so here I got a confirmation
107:16 - now uh so let's start with the session
107:19 - let's start with the uh second day so in
107:22 - the first day actually so what I
107:24 - discussed I discussed about the
107:25 - generative AI so where I have like told
107:28 - you that what is a generative AI so this
107:30 - is the slide basically which I was using
107:32 - and here actually this was the agenda
107:35 - the complete agenda which I going to
107:37 - discuss this uh throughout this
107:38 - committee session and uh today is the
107:41 - second day where I will start from this
107:43 - open AI so in the previous session I was
107:46 - talking about this generative Ai and I
107:48 - discussed each and everything related to
107:49 - this generative a and I hope you got a
107:52 - clear-cut idea that what is a generative
107:54 - Ai and in the generative AI actually
107:57 - what all things comes into the picture
107:59 - where llms lies so if we are talking
108:02 - about this large language model so
108:04 - regarding the large language model also
108:05 - I have clarify each and everything I
108:07 - have given you the complete timeline of
108:09 - this large language model where I have
108:11 - discussed about the uh the complete
108:14 - history of the large language model from
108:16 - the RNN so first I have started from the
108:18 - RNN then I came to the lstm then uh I
108:22 - discussed about the uh different
108:23 - different sequence to sequence mapping I
108:26 - talked about the encoder and decoder and
108:28 - after that I have explained you the me
108:30 - uh the concept of the attention and then
108:32 - I have discussed about the attention is
108:35 - all your need uh the Transformer
108:37 - architecture and I told you that
108:40 - whatever llms which you are seeing
108:42 - nowadays so those uh all the llms are
108:45 - using Transformer as a base architecture
108:48 - so I have explained you the
108:51 - the like whatever thing was there inside
108:53 - the Transformer architecture whatever
108:55 - component whatever segment was there
108:57 - each and everything I have discussed
108:58 - over there and apart from this
109:01 - generative AI I have talked about this
109:03 - llm also so there I have talked about
109:05 - that what is a llm why it is called
109:08 - large language model and uh why it is so
109:12 - powerful because this one uh because
109:15 - this one llm is able to perform lots of
109:18 - like task lots of uh one basically llm
109:22 - we can use for the different different
109:24 - type of application so here uh I have
109:27 - written the couple of name like text
109:29 - generation summarizer translation or
109:31 - code generation and so on we all know
109:33 - about the chat GPT uh chat GPT is are
109:36 - application and uh chat GPT is using
109:38 - gpt3 gpt3 is a a base model so GPD 3.5
109:43 - actually it's a base model so how it is
109:46 - how much it is powerful we all know
109:48 - about it and that is a example of the
109:50 - large language model which is capable to
109:53 - do so many things why because uh it is
109:55 - having a power so so that actually it
109:58 - can generate a it can generate a data
110:01 - based on a previous data it can
110:03 - understand the pattern and because of
110:05 - that only we are able to trans we are
110:07 - able to use this Transformer as a or
110:09 - whatever like Transformer based model we
110:11 - have we are able to use those transforma
110:14 - based model as a transfer learning I
110:17 - have explained you the concept of the
110:18 - transfer learning and the fine tuning as
110:21 - well so here I was talking about this
110:23 - llm and then I talked about the few
110:26 - milestone in a large language model so
110:29 - here I have written couple of name bird
110:31 - GPT xlm T5 Megatron M2M so these are the
110:35 - uh like a few milestone in a large
110:37 - language model now this model has been
110:40 - trained on a huge amount of data now
110:43 - specifically we are talking about GPT so
110:45 - in a GPT Family itself you will find out
110:47 - of various model I will talk about it it
110:50 - I will come to the open Ai and each and
110:52 - everything I will keep in front of you
110:54 - only and uh I will uh I will show you
110:56 - that how much it is powerful so we are
110:59 - talking about GPT so it's like really
111:01 - powerful and it it has been trained on a
111:04 - like huge amount of data and it is
111:06 - having a billions of parameter so here
111:08 - is few Milestone so in our back days in
111:11 - our history basically we are using this
111:13 - particular models now in a recent day we
111:15 - got so many uh architectures so many uh
111:18 - open source models and so I will talk
111:20 - about uh regarding those model as well
111:23 - so here in the next slide I have shown
111:25 - you so what all encoder based
111:27 - architecture we have what all decoder
111:29 - based architecture we have if we are
111:31 - talking about anod and decoder right so
111:34 - in which architecture you will find out
111:36 - both encoder and decoder if we are
111:38 - talking about B xlm Electra DTA so these
111:42 - all are these all the architecture
111:44 - actually it is based on an encoder we're
111:46 - talking about this GPT GPT family so
111:49 - it's a based on a decoder itself and the
111:51 - idea has been taken from the Transformer
111:53 - itself now here you can see this T5 Bart
111:56 - M2M big but so these are the model which
111:59 - are which is using this encoder and
112:02 - decoder both got it so now here uh then
112:07 - I talked about the openi based llm model
112:09 - so here uh the very first thing comes
112:12 - into the picture that is a GPD itself
112:14 - GPT 3.5 which is a like base model
112:17 - behind this chat GP chat GPT just a
112:20 - application it's not a model now here
112:22 - you will find out this Delhi whisper DCI
112:25 - there are many model I will be coming to
112:27 - that particular model and I will show
112:29 - you how you can get all the model from
112:32 - the opena itself and uh yes we'll try to
112:35 - use those model for our task for our
112:39 - like a uh for the for our like a like a
112:42 - requirements and all definitely will try
112:44 - to use this particular model like GPT
112:47 - GPT 3.5 I will show you how you can use
112:49 - GP 3.5 turbo viso da in or other model
112:53 - as well like aming and moderation so
112:55 - apart from that this apart from this uh
112:58 - like uh Milestone whatever Milestone I
113:00 - shown you and this openi based model
113:03 - here you will find out some other op
113:05 - Source model like Bloom llama 2 Palm is
113:08 - a model it's a very famous model from
113:10 - the Google side nowadays like most of
113:13 - the people are using this pal Falcon is
113:14 - a model cloud is there MP 30 uh MP is
113:19 - there uh this B actually it is showing a
113:21 - parameter right and here we have a
113:23 - stable Im so a stable LM so there are
113:26 - like so many open source model so I will
113:29 - come to that also and I will show you
113:31 - how you can utilize those particular
113:33 - model and apart from that I have like
113:35 - kept some more slight over here inside
113:38 - this particular PP so you can go through
113:40 - with that and you can understand some
113:42 - other uh like concept like how this chat
113:44 - GPD has been trained and all so I hope
113:47 - guys still here everything is fine
113:49 - everything is clear
113:50 - now we can move to the Practical part so
113:53 - please do let me know in the chat if
113:55 - everything is clear so far in terms of
113:57 - theory guys I'm waiting for your
114:06 - reply uh just a wait so let me give you
114:08 - the link of the website and
114:18 - uh
114:20 - yes guys I'm waiting for your reply so
114:22 - if you can confirm in the chat uh uh
114:24 - like everything is fine or not so that I
114:27 - can proceed with the Practical
114:30 - stuff yeah definitely this uh PP is
114:32 - already there so just try to enroll in
114:34 - this course the dashboard Bic basically
114:37 - which we have created this is our
114:38 - dashboard which you will find out over
114:40 - the Inon website so just try to log to
114:43 - your Inon website first of all if see if
114:45 - you are a new person so what you need to
114:47 - do you need to sign up after sign up uh
114:50 - you will login and after login you will
114:53 - search uh regarding this dashboard so
114:55 - here actually what is the name of the
114:57 - dashboard so the name of the dashboard
114:58 - is generative AI Community Edition so
115:01 - just click on this dashboard and here
115:04 - after clicking on this dashboard you it
115:05 - will ask to you whether you want to
115:07 - enroll or not so yes uh you will click
115:10 - on the enroll and it is completely free
115:12 - so it won't ask you any sort of a money
115:15 - and after enrolling into this particular
115:17 - course uh you can get the videos and you
115:20 - can get the resources as well so all the
115:22 - resources we have uploaded over here
115:24 - inside this resource section got it
115:32 - clear great so I think everything is
115:35 - fine everything is clear now let's start
115:38 - with the uh let's start with the
115:40 - Practical implementation so first of all
115:43 - guys uh let me clarify the agenda that
115:45 - what all thing we are going to discuss
115:47 - in today's session so for that what I'm
115:50 - going to do I'm going to open my
115:51 - Blackboard and here I will try to
115:53 - explain you each and everything uh like
115:56 - what what whatsoever we are going to
115:58 - like cover in this particular session so
116:01 - let's start uh let me write it down all
116:03 - the thing step by step now first of all
116:06 - I can write it down over here a day two
116:08 - Community session and then I will begin
116:12 - with the topic so here guys are day two
116:15 - of the community session now uh
116:18 - yesterday actually I I talked about the
116:20 - introduction part I talked about the
116:21 - introduction of the generative Ai and
116:23 - the llm now today I will be more
116:26 - focusing on the open a so here I will be
116:29 - discussing about the open AI so first I
116:32 - will give you the U like a complete walk
116:35 - through of the openai website of the
116:37 - openai documentation after that I will
116:40 - come to the openai API that how you can
116:43 - use this open API how you can use this
116:46 - open API and this API we are going to
116:49 - use by using this python so guys if you
116:53 - you know python so definitely uh like uh
116:56 - you will be able to write a code along
116:58 - with me uh and don't worry I will show
117:00 - you how to do the entire environment
117:02 - setup and all each and everything I will
117:04 - try to uh I will try to do in front of
117:06 - you uh from very scratch so uh you all
117:09 - can do along with me now over here I
117:12 - will come to this openi API and there
117:14 - I'm going to use Python and we have
117:16 - couple of more option like nodejs on all
117:19 - so if you are familiar with the
117:21 - JavaScript or maybe some with other
117:23 - language so in that case also you can
117:25 - use this openi API after that I will uh
117:29 - I will come to the openi playground so
117:31 - here uh they have given you very
117:33 - specific feature or very uh like uh very
117:37 - interesting feature that is what that is
117:38 - a openi playground so over here I will
117:41 - explain you that uh how you can use a
117:44 - different different model how you can uh
117:46 - like pass a different different prompts
117:49 - and how you can generate output how you
117:51 - can set up your uh like a different
117:53 - different uh sentiments and all
117:54 - regarding the system that okay so my
117:57 - system should behave like this or that
117:59 - so each and everything I will explain
118:01 - you over here and after that what I will
118:03 - do I will show you the chat completion
118:05 - API so I will use this chat completion
118:09 - chat completion and by using this chat
118:11 - completion actually uh we can call the
118:14 - GPT model so whatever uh like uh we can
118:18 - call the like openi API and uh with that
118:21 - definitely we can use any sort of a
118:23 - model like a GPT model or any other
118:25 - model so first I will uh start with the
118:28 - openi API we'll use we'll be using a
118:30 - python over here and I will show you how
118:32 - you can generate the openi key and after
118:35 - that I will come to the playground and
118:37 - assistant and then chat completion API
118:39 - and then I will explain you the concept
118:41 - of the function call function call now
118:46 - this is the agenda for today's session
118:48 - this is the agenda for today's Community
118:50 - class now before starting with the openi
118:53 - I will uh I will explain you that why
118:56 - openi is this much important why not
118:58 - other other like things or uh if we have
119:02 - like a other competitor of the openi
119:04 - that why we are not using that instead
119:06 - of this open ey and if we are going to
119:08 - use that then how we can do that okay
119:11 - and one more thing I would like to
119:12 - explain you over here so along with the
119:14 - open a I will uh talk about the hugging
119:17 - face so see over the hugging face
119:20 - actually hugging face is has provided
119:22 - you one uh hugging face hub for all the
119:25 - models so there you will find out all
119:28 - the open source model so directly you
119:30 - can generate a hugging face API key and
119:32 - you can utilize all sort of a model
119:34 - whatever is there over the hugging face
119:36 - Hub yesterday I have shown you that let
119:38 - me show you again uh that particular Hub
119:41 - so guys here once you will write it down
119:42 - so over the Google so once you will
119:45 - search uh once you will write it down
119:46 - hugging face model Hub so there uh you
119:49 - will get a link and you just need to
119:51 - click on that so here you will uh and
119:53 - then basically it will be redirecting to
119:55 - you to this particular model Hub now
119:58 - here you will find out all the open
120:00 - source model from a different different
120:02 - organization so yesterday I was talking
120:04 - about this Ora 2 now here you will find
120:07 - out other model as well like whisper
120:09 - large V3 now from the Facebook side
120:12 - there's a
120:13 - seamless okay now here you will find out
120:16 - other model as well so see from The Meta
120:18 - side there's a lamba Lama 2 so I will
120:20 - show you how you can utilize these
120:22 - particular model for the different
120:24 - different tasks according to your
120:26 - requirement getting my point so we will
120:29 - not restrict it uh we will not restrict
120:32 - to ourself to the till the open ey
120:34 - itself apart from that we'll try to
120:36 - explore few other model few other open
120:38 - source model and yesterday actually I
120:41 - have shown you one more platform and
120:43 - here's the platform AI 21 studio so it
120:46 - it gives you one model this Jurassic
120:48 - model so we can utilize that particular
120:51 - model also and this all are called large
120:54 - language
120:55 - model this IDE this thing is clear to
120:57 - all of you yes or no so uh what is the
121:00 - difference between hugging face and open
121:02 - AI so open AI is a different
121:04 - organization hugging face is a different
121:05 - organization and over the hugging face
121:07 - Hub see uh if you have heard about this
121:10 - Docker or this GitHub so first of all
121:12 - let me show you this GitHub so if I'm
121:14 - searching about this GitHub so here
121:16 - actually over the GitHub you will find
121:18 - out uh like see this is my GitHub and uh
121:22 - you all have the GitHub ID right you all
121:25 - have log to the GitHub and all and first
121:27 - you sign up and then you log in and
121:28 - whatever course and all you are having
121:30 - and definitely you are going to upload
121:32 - it over here uh in terms of repository
121:35 - now let's see if I if I have to find out
121:36 - something so what I will do here let's
121:38 - say if I'm going to write it down GitHub
121:40 - machine learning uh linear regression so
121:43 - GitHub machine
121:46 - learning machine learning linear
121:50 - regression so here if I will search uh
121:53 - like this then definitely I will get a
121:55 - link and here you can see so it has
121:57 - suggested me one repository and you will
122:00 - find out uh this uh code and all
122:02 - whatever code and all has been uh
122:04 - uploaded by this particular person and
122:07 - definitely you can download it and you
122:08 - can use it similarly we have a Docker
122:10 - Hub similarly we have a Docker Hub so
122:13 - let me show you the docker Hub so the
122:15 - docker Hub actually you will find out
122:17 - all the images and all so let's say uh
122:19 - like uh you downloaded Docker in your
122:21 - system you did setup and all now uh you
122:24 - don't want to install it from scratch
122:26 - you want to run it by a Docker so yes
122:28 - there is a Docker Hub and there you'll
122:30 - find out different different images and
122:31 - all so you can uh like uh you can pull
122:34 - that image and definitely you can run it
122:36 - inside your container so similarly we
122:38 - have a hugging face Hub there uh like it
122:41 - is uh it it is going to provide you a
122:43 - different different model actually on a
122:45 - single place so yes uh just uh you just
122:47 - need to log in over there and after that
122:49 - you need to generate a API key and
122:51 - directly you can use those particular
122:54 - model whatever is there like over the
122:56 - hugging face Hub now similarly we have
122:59 - openi it's other another organization so
123:01 - yes by using the openi API we can access
123:04 - the open a model as well so here uh okay
123:07 - so if you will find out if you will see
123:09 - to this open a this one this is the open
123:11 - a right now I will show you what all
123:13 - models this openi is having it is having
123:15 - a different different model various
123:16 - model I will come to that I will show
123:18 - you from very scatch so till here
123:20 - everything is fine guys everything is
123:22 - clear so uh just give me a quick quick
123:25 - confirmation so that I can show you the
123:27 - entire setup related to this opena API
123:30 - and we can run a couple of uh couple
123:33 - couple of line of code as well so please
123:35 - do let me know in the chat if uh
123:37 - everything is clear so
123:44 - far yes we'll talk about the fine tuning
123:47 - and all so how we can uh do the fine
123:49 - tuning regarding a different different
123:51 - model uh it's not a like easy task it's
123:54 - a a very expensive thing so we'll talk
123:58 - about
123:59 - it yes hugging pH model are
124:07 - free yes correct for building a model uh
124:10 - so for using uh if you want to use that
124:12 - particular model so either I can use
124:14 - open a so or else I can use hugging
124:16 - phase see whatever model is there over
124:17 - the hugging for definitely we can access
124:19 - that but let's say open a is having
124:21 - there uh like a uh it's a separate
124:23 - platform right so whatever model is
124:25 - there over the open a so we'll be able
124:26 - to access those model only from the open
124:28 - a not all the model which is there
124:30 - inside the hugging face also but hugging
124:32 - face actually is having all the models
124:35 - open source and all whatever model is
124:36 - there and some of the model from the
124:37 - openi side as well but openi actually
124:40 - it's a specific specific one specific
124:43 - organization clear yes or no so please
124:46 - do let me know if uh this thing is clear
124:48 - to to all of you so that I can proceed
124:50 - with the uh next part next
124:58 - section great so people are saying sir
125:01 - it is clear clear clear okay
125:10 - great yeah the model is already created
125:12 - over the hugging face and open ey they
125:14 - already trained the
125:17 - model
125:22 - we don't have all the models in the ging
125:24 - phase that's why we are learning this
125:31 - open great so I think uh all the thing
125:35 - uh like each and everything is clear to
125:37 - all of you now let's start with the uh
125:39 - like uh next part of this session so
125:42 - here I have uh discussed about this open
125:44 - Ai and this hugging phase and I clarify
125:46 - the agenda that what all think we are
125:49 - going to discuss but before starting
125:51 - with the open AI so let me give you the
125:53 - a brief introduction of the open AI that
125:56 - why this open AI is too much important
125:58 - so for that what I did I have created
126:00 - one small PP so with that actually you
126:02 - will get some U uh some basic idea uh
126:07 - regarding this open AI so here uh let me
126:10 - start uh let me start the slideshow so
126:13 - over here guys you can see about the
126:14 - open if we are talking about the openi
126:16 - so what is the openi open a is leading
126:19 - company in the field of AI it was
126:21 - founded in 2015 as a nonprofit
126:24 - organization by same Alman and Elon Musk
126:27 - as we know about the uh founder of the
126:30 - like open a so yes uh I think we are we
126:33 - are aware about uh with this particular
126:35 - names right same Alman and this Elon
126:37 - Musk and it has founded in 2015 as a
126:41 - nonprofit organization just for the
126:43 - research purpose now here in the next
126:46 - slide I have kept the name so he's a
126:48 - like
126:49 - he's a CEO of the open a Sam Alman and
126:54 - uh yes I think you know about the Sam
126:56 - Alman he was fired by the open board
126:58 - we'll talk about that also what what
127:00 - might be the reason behind that so we
127:03 - will discuss about that uh as well now
127:06 - over here you can see uh openi founded
127:08 - in uh 2015 and the company founded with
127:11 - the goal of developing and promoting
127:13 - friendly AI in a responsible way that
127:16 - was a logo of the open AI so with the
127:18 - focus on transparency and open research
127:21 - and he was the and they are the founder
127:23 - member of the like open a so Elon mus
127:27 - Sam Alman Greg Brockman okay this guy is
127:30 - a like great researcher and vak and zon
127:34 - so these are the founder founding member
127:36 - of the open AI now over here are open
127:39 - goals so there are some goals of the
127:40 - open related to the AI and all now openi
127:43 - Milestone so I was talking about that
127:45 - why this openi is too much important why
127:48 - not other does because if you will look
127:49 - into the market there are other uh there
127:52 - uh there are you will find out other
127:54 - organization as well uh so we have a
127:57 - Google and Google is having their
127:58 - separate Department Google uh AI
128:01 - research and all so Microsoft is also
128:03 - having their own department for the AI
128:05 - research even meta is having that even
128:08 - IVM so all the like big big giant so
128:12 - there they are having their own research
128:14 - uh like Department related to this Ai
128:16 - and all and they are working on that and
128:18 - they were working on that actually but
128:21 - why this openi is too much popular and
128:23 - why we should start from the openi
128:25 - itself so you know about the openi in
128:27 - 2020 actually they have launched the
128:30 - Chad GPT and guys believe me it was the
128:33 - Milestone and it was the major
128:35 - breakthrough in the history of the AI
128:37 - because before that also we are having
128:40 - so many llm model and it was able to do
128:43 - uh some sort of a thing but not like to
128:46 - not similar like to this GPT this GPT
128:50 - actually the GPT model which is a
128:52 - backbone of this Chad GPT application uh
128:55 - it was a a breakthrough in the history
128:57 - of the NLP and because of this this open
129:00 - AI came into the Limelight and uh apart
129:03 - from the GPT then uh uh like they have
129:06 - shown or they have released the other
129:08 - different different research so here
129:10 - here I have written couple of name
129:12 - basically so generative model is one of
129:15 - the Milestone of the open now apart from
129:18 - that you will see that they are going to
129:20 - uh they are going to participate in the
129:21 - robotic research and all and here uh
129:24 - like other uh like other few more thing
129:27 - basically so solving uh robic Q with a
129:30 - robot hand and here multimodel neurons
129:33 - and artificial neural network you can
129:35 - search about uh this particular things
129:37 - and yes uh this open ey actually it
129:40 - become uh very uh important uh basically
129:44 - because of this uh like GPT and all
129:46 - because of this uh chat GPT application
129:49 - and yes they were using a different
129:51 - technique for training this uh GPD model
129:54 - which we are using for the chat GPT and
129:57 - the idea from where they took the idea
129:59 - uh for training this GPT model there we
130:02 - have unsupervised learning we have a
130:03 - supervised learning and we have this
130:05 - reinforcement learning so they took from
130:08 - the ULM fit research paper yesterday I
130:10 - have shown you that which has been
130:11 - published in 2018 and in 2019 in 2020
130:15 - actually they have released this GPT GPT
130:19 - got it now here you can see buildin with
130:22 - open AI API so these are couple of name
130:24 - getup copilot keeper Tex Bible dingo so
130:28 - these are some application which is
130:29 - using this openi API and apart from that
130:32 - you will find out so what is the openi
130:34 - vision so the vision is like uh promote
130:37 - a friendly AI in a way that benefit all
130:40 - the humanity and all so this is a vision
130:42 - of the openi now feature so chat GPT
130:46 - Delhi whisper alignment so so these are
130:48 - the feature of the open AI Chad GPT is a
130:52 - a milestone Delhi is also there Delhi 2
130:54 - recently they have they have released
130:55 - the Delhi 2 whisper is uh one of them
130:58 - whisper actually it is a very good model
131:00 - for generating a transcript and all so
131:02 - whatever like text we are giving or
131:04 - whatever like videos we are giving to
131:05 - this particular model it is able to
131:07 - generate a transcript from that and here
131:10 - uh alignment is there startup fund so
131:12 - these are some feature of the open AI
131:14 - now guys uh before starting with the
131:16 - open AI API I think got enough amount of
131:19 - idea uh regarding this open AI yes or no
131:23 - please do let me know in the chat if uh
131:25 - this part is clear so I will proceed
131:27 - with a uh open a API so how you can
131:31 - generate a key and all and how you can
131:33 - utilize
131:37 - that
131:40 - yes are you getting guys whatever I'm
131:43 - explaining you over here uh if you have
131:46 - any sort of a doubt anything so you you
131:48 - can ask me in a chat section I will
131:50 - reply to all of your
131:52 - doubts so step by step we'll try to
131:54 - proceed uh and uh so each and everything
131:57 - will be
132:00 - clarified great so
132:04 - clear yes waiting for your reply uh if
132:07 - you can write it on the chat so then I
132:10 - will
132:16 - proceed what is the learn tool what is
132:18 - the aim to learn open AI so that I can
132:20 - utilize the same capability same AI
132:22 - capability in my
132:24 - application whatever model has been
132:26 - trained by the openi so that I can use
132:28 - the same model in my application for a
132:30 - different different
132:41 - task great so I think I have uh
132:45 - discussed each and everything related to
132:46 - the open a now this is the website of
132:48 - the openai so if you will search openai
132:51 - definitely you will get a website of
132:52 - that so in the website itself they have
132:54 - mentioned everything so latest update
132:57 - whatever uh latest update and all it is
132:59 - there so they are mentioning over here
133:01 - and Sam Alman return as a CEO of the
133:04 - open a I think you know about this
133:06 - controversy of the open a so let me uh
133:09 - give you some sort of a glimpse of that
133:11 - uh if you know about the open a so it
133:13 - was founded as a nonprofit
133:16 - organization but uh in 2019 actually
133:19 - they have uh started with their uh
133:22 - for-profit organization as well if you
133:24 - will search about the four profit
133:26 - organization
133:27 - of for profit organization of this open
133:30 - a so in 2019 actually they have started
133:33 - this a for profit organization and uh it
133:36 - was doing uh lots of work uh regarding
133:38 - this Ai and all and they collected uh
133:40 - like uh funds from different different
133:43 - companies and all from a big big giants
133:45 - and uh they were working on the G GPD
133:48 - model itself okay now after that uh this
133:51 - chat GPD has been released and in 2022
133:55 - actually 2022 or 23 basically so uh they
133:59 - started work on a uh like a different
134:01 - type of project so the project name was
134:03 - the
134:04 - qar the uh basically the project name
134:07 - was the qar and it was more specific to
134:11 - it was more specific to towards this AGI
134:14 - so may I know guys what is the full form
134:16 - of the AGI
134:19 - if if you know uh the full form of the
134:20 - AGI so please write it down in the chat
134:22 - what what do you uh understand with this
134:27 - AGI so the full form of the AGI is
134:31 - please write it down in the chat if you
134:32 - know about the full form of the AGI
134:34 - please do it yes artificial Journal
134:38 - intelligence correct so the full form of
134:40 - the AGI is artificial Journal
134:42 - intelligence actually see we talking
134:44 - about the chat GPD now this particular
134:46 - application it's not it is not
134:48 - representing a general artificial
134:51 - intelligence it is a restricted one it's
134:53 - a specific
134:55 - one getting my point so let's say there
134:58 - one side there is a Chad GPT and one
134:59 - side there is a human so definitely this
135:02 - Chad GPD can answer in a better way it
135:05 - can generate answer in a better way
135:07 - compared to this human but still it is
135:09 - not like a human so still we are not on
135:12 - that particular level where we can
135:14 - achieve a artificial intelligence like a
135:17 - human that is called artificial general
135:21 - intelligence and the project name was
135:23 - given by this openi the project name was
135:26 - the
135:26 - qar and that was happening in the
135:29 - for-profit organization this is the
135:31 - subsidiary of the open
135:33 - itself getting my point now because of
135:36 - that uh so there was a conflict in
135:38 - between the board member and uh this uh
135:41 - Sam Alman was fired and now again he
135:45 - joined the company uh there is a long
135:47 - story story but yeah I have given you
135:48 - the Glimpse you can search over the
135:50 - internet and you can uh read about it U
135:53 - okay so if you like to read the AI news
135:56 - and all AI related news news and all so
135:59 - definitely uh you should check it on a
136:01 - daily basis because on a daily basis
136:04 - there's something is happening on a teex
136:06 - side on a like organization side uh
136:09 - whatsoever so over here guys uh here you
136:12 - can see the open a website now if I will
136:15 - scroll down so you will find out each
136:17 - and everything over here itself that
136:19 - what all research is there uh what all
136:21 - upcoming models is there uh on whatever
136:24 - applications they are working so each
136:25 - and everything actually you will find
136:27 - out over here itself so here uh recently
136:29 - they have released this Delhi 3 so in
136:32 - October uh 20123 3rd of October 2023
136:36 - they have released this Delhi 3 there
136:38 - was a GPD 4 gp4 Vision where we can uh
136:42 - upload the images and we can do a lots
136:45 - of lots of task related to the images
136:47 - and all
136:48 - getting my point so here you will find
136:50 - out a research whatever latest research
136:52 - is there from the open a side no need to
136:54 - go anywhere everything you will find out
136:56 - over here itself if you want to start
136:57 - from the open a if you are using this
136:59 - open a in your organization if you want
137:02 - to use it and before that if you want to
137:05 - explore it so please go through the
137:07 - website and here you will find out each
137:09 - and everything now guys here is a
137:11 - question I told you that why uh what is
137:14 - the open a now why we are learning it I
137:17 - have to give you the specific answer of
137:19 - this particular question if you will ask
137:21 - me S why we are learning this open a
137:23 - what is the main Aim so now let me tell
137:26 - you that so first of all guys after
137:28 - opening this opena website what you need
137:30 - to do you need to log in it you need to
137:32 - log to this particular website and here
137:34 - you will get two option so the first
137:36 - option is a chat GPD and the second
137:38 - option is a API so we all know about
137:41 - this chat
137:41 - GPT I think uh we all have used this
137:44 - chat GPT and I think we are using it on
137:46 - a daily basis now we are not going with
137:49 - this chat GPT we are going with this API
137:51 - so I will click on this API option and
137:53 - once I will click on this API option so
137:55 - I will get this type of interface so I
137:58 - believe guys you all are getting this
138:00 - particular interface after clicking on
138:02 - this API please do let me know in the
138:04 - chat if uh everything is uh uh like
138:07 - going fine uh like me so please do let
138:10 - me know in the
138:16 - chat
138:24 - great so yes I think uh people are doing
138:28 - along with me now see guys here is what
138:31 - so here is a uh like open a API uh so
138:34 - once you will click on that you will get
138:36 - this particular interface now just uh
138:38 - overover your mouse left hand side and
138:40 - here you will get a different different
138:41 - option or various option now what you
138:43 - need to do guys for here first of all
138:45 - you need to click on this documentation
138:47 - so just click on this documentation and
138:49 - you will come to this particular page
138:51 - now here you will find out this overview
138:53 - so here they have given you the complete
138:54 - overview about the openi API that what
138:58 - all things they have and uh for what all
139:01 - applications we can use this openi API
139:03 - now here you will find out the
139:04 - introduction section as well so in the
139:06 - introduction section they have defined
139:08 - some sort of a thing related to a
139:10 - different different task like text
139:11 - generation aming assistant tokens and
139:14 - all now here you will find out the quick
139:16 - start so let's say uh you want to
139:18 - explore this open API so what you will
139:20 - do at the first place so after opening
139:22 - this open uh a openi API and after
139:26 - opening this after opening this
139:27 - particular documentation you just need
139:29 - to click on this quick start so after
139:31 - clicking on this quick start you will
139:32 - get all the code which initially you
139:35 - need to run inside your system getting
139:39 - my point if you want to use this open
139:40 - API if you want to use this openi API
139:44 - and you want to run the code if you want
139:47 - to start then for that what you need to
139:49 - do you just need to click on this quick
139:51 - start and over here you will find out uh
139:53 - different different option so let's say
139:55 - you know the nodejs so here you can
139:57 - click on this nodejs and you will find
139:59 - out entire setup related to this nodejs
140:03 - how to install the package how to uh set
140:05 - the key and all now here you'll find out
140:08 - the different different uh like Windows
140:10 - different different operating system
140:11 - related option and here you will find
140:13 - out the code snippet so directly you can
140:15 - run it and you can use it now if you are
140:18 - a python lover if you know the python
140:21 - only in that case yes they have given
140:23 - you the option so you just need to click
140:25 - on this uh Python and here you will find
140:27 - out the complete setup guide so how to
140:30 - install a python how to install how to
140:32 - create a virtual environment how to
140:34 - install this openi Library so and after
140:37 - that you will find out this uh setup
140:39 - openi key uh regarding this Mac OS and
140:42 - windows now here you'll find out how to
140:46 - uh request to your openi uh API how to
140:49 - request to the different different
140:51 - models so here is a code snippet so we
140:53 - are going to use this particular process
140:56 - uh if uh so yes you can use the same
140:59 - process don't worry I will show you how
141:01 - you can do the entire setup and all and
141:02 - how you can call the different different
141:04 - model now over here you will find out a
141:06 - model now guys this model actually this
141:08 - model is a uh like a very important part
141:11 - of the openi API now here they have
141:13 - given you the various model like GPD 4
141:15 - gp4 Turbo G PD 3.5 Delhi is there TTS is
141:20 - there whisper is there iding moderation
141:23 - GPD 5 is there GPD 3 which is a legacy
141:26 - now and here you will find out some
141:28 - deprecated model so here they have given
141:31 - you some a deprecated model like uh GP
141:33 - 3.5 Turbo with this much of tokens and
141:37 - here you will find out this text Ada Ada
141:40 - text weage text cury text DaVinci so
141:43 - these are the depricated model you can
141:45 - use it if it is required definitely you
141:47 - can use it so here you will get a
141:50 - complete list of the model whatever
141:52 - model you want to use for your task for
141:56 - your particular task now over here uh
141:59 - this is the uh like overview regarding
142:01 - the model now if I'm clicking on this
142:03 - GPD 3.5 so once I will click on this GPD
142:06 - 3.5 so here I will get a complete detail
142:09 - regarding this particular model now here
142:12 - is a what here is a model name so what
142:14 - is the name of the model GPT 3.5 turbo
142:19 - 1106 okay now over here you will find
142:22 - out two things so the first is what
142:24 - context window now in the context window
142:26 - you will find out the number of tokens
142:28 - now guys this tokens actually the number
142:30 - of tokens displays a very very important
142:33 - role if we are talking about this tokens
142:35 - so really it plays a very very important
142:37 - role and I told you if we are giving an
142:39 - input to our model to our LM model so
142:42 - we'll give in the form of prompts and
142:44 - prompt is nothing it's a collection of
142:46 - token so whatever input and output we
142:48 - are getting we are getting in the form
142:50 - of prompts right so we are giving a
142:52 - prompts to our model and we are getting
142:54 - a prompts from our model and this prompt
142:56 - is nothing it's a collection of tokens
143:00 - now we'll talk about this tokens and all
143:02 - then how much token is uh so as a return
143:05 - actually how much token you can get as a
143:08 - output as a free one actually this uh
143:10 - Chad this open a actually it stopped the
143:13 - free services now so before actually uh
143:16 - uh you would be getting this uh let me
143:19 - write it down over here so $20 of credit
143:22 - so earlier if you have used this uh open
143:25 - a so you must have seen that uh if you
143:28 - are uh like uh if you are going to
143:30 - create a open API key so in that case it
143:33 - was giving you this $20 free credit now
143:36 - they have stopped this particular
143:37 - service now they are not giving to you
143:39 - so first of all what you will have to do
143:42 - so first of all you will have to add the
143:44 - method a payment method actually so so
143:47 - you will have to add your credit card or
143:49 - debit card details and after that you
143:52 - will have to set your limit let's say
143:54 - $20 $50 $100 or whatever uh like limit
143:58 - um actually you find out it is fine so
144:01 - inside uh in that basically in that
144:03 - particular limit uh my work will be done
144:05 - so first of all uh you need to add the
144:06 - payment method and you need to set the
144:08 - limit and then only you can use this
144:10 - open API so recently they have updated
144:12 - this particular thing now we have
144:14 - alternative also so we have this AI 21
144:17 - lab so I will uh show you this uh thing
144:20 - as well where we have a Jurassic model
144:22 - and it gives you the $90 fre free credit
144:25 - $90 free credit but you won't be able to
144:27 - use this GPD 3.5 because it is only it
144:30 - is only available in this opena itself
144:32 - if you want to use this GPD 3.5 model
144:35 - GPD 3.5 turbo or gbd4 so it is only
144:38 - available in the opena itself and they
144:40 - haven't open source it and for this one
144:42 - you will have to pay if you want to use
144:45 - it in your organization in uh with
144:47 - respect to your task so definitely you
144:49 - will have to pay for that getting my
144:52 - point now over here guys see uh it
144:55 - return return a maximum of 4096 output
144:58 - token so regarding this particular model
145:01 - now here you can provide this much of
145:03 - tokens actually so this much of tokens
145:05 - as a uh input as a input basically and
145:08 - you will get this much of token as a
145:09 - output if you are going to use this
145:10 - particular model now here GPD 3.5 turbo
145:14 - So currently point to GPD 3.5 turbo 0
145:16 - 613 will Point GPD format turbo 11
145:19 - starting date this is this is the
145:20 - starting date and here this is the token
145:23 - size now here this is the token size
145:25 - basically they have given to you so you
145:27 - can uh provide this much of token and
145:29 - here you will be getting output in uh
145:32 - like as uh this is the maximum token
145:34 - size actually uh with respect to this
145:36 - particular model so you can go and read
145:38 - more about this model and all and here
145:41 - you will find out this training data so
145:43 - this uh model has been trained up to
145:45 - 2021 SE number 2021 and here uh these
145:49 - all are the model so I will uh use any
145:52 - sort of a model from here itself and I
145:54 - will show you how you can hit it by
145:56 - using this P openi python API now apart
146:00 - from that uh you will find out some
146:02 - other uh thing so let's say if I want to
146:04 - do a text generation so they have given
146:06 - you the complete detail regarding that
146:08 - and here they have given you the API
146:09 - endpoint as well so you can click on
146:11 - that and here in this particular way
146:13 - actually you need to write a prompt and
146:17 - all you need to define a prompts and all
146:19 - uh so actually this is the uh rate
146:21 - assistant uh as of now it is not working
146:23 - so you can click on that or you can use
146:25 - it this API endpoint inside your
146:27 - application so uh here they have given
146:29 - you the code that if you want to perform
146:31 - this particular task this text
146:33 - generation task so directly use this Uhn
146:36 - code snippet after setting up the
146:38 - environment and all after generating the
146:40 - openi key and you can perform this text
146:43 - generation over uh text generation if uh
146:45 - this is required according to your uh
146:48 - like application and all now over here
146:50 - you will find out the other option so
146:53 - embedding is there so embedding is
146:55 - nothing uh embedding actually you are
146:57 - just going to be uh convert your text
147:00 - into a uh some numeric uh numbers and
147:03 - here uh this ambing comes into a picture
147:05 - and this this is very robust model from
147:07 - the openi side and definitely you should
147:10 - use it uh I will show you how you can
147:12 - utilize this particular model and you
147:13 - find you will find out the complete code
147:15 - in s it and all and yes you can generate
147:18 - a Ming regarding your test Ming is
147:20 - nothing it's just a numeric
147:22 - representation of your text now here uh
147:26 - if you want to do a fine tuning so
147:27 - regarding that also you will find out a
147:29 - complete detail so how you can do a fine
147:31 - tuning and all now image generation is
147:33 - also there so if you want to do a image
147:35 - generation so which model you should use
147:37 - from here Vision related to The Vision
147:39 - also there is a GPT 4 now Vision related
147:42 - facilities it is there inside the gbd4
147:44 - itself text to speech speech to text
147:46 - moderation so no need to train your uh
147:49 - no need to train your model your uh NLP
147:53 - model from scratch now so they are
147:55 - giving you everything you just need to
147:56 - call the API and you can utilize it now
147:59 - many people are asking to me that sir
148:00 - what is the aim to learn behind this
148:03 - open ey and all so the aim is very very
148:05 - simple if you want to use this
148:07 - particular model for your uh uh
148:09 - different different task the task
148:11 - basically which they have mentioned over
148:12 - here you can directly use it you no need
148:15 - to like train it by your yourself
148:17 - because this model has been trained on a
148:19 - huge amount of data now that's why it is
148:20 - called llm I told you clearly right
148:23 - yesterday what is the meaning of the llm
148:25 - and yes uh in most of the cases in 99%
148:27 - of the cases it will work fine if let's
148:29 - say if you want to do a fine tune this
148:31 - particular model so definitely you
148:33 - required a higher resources and in that
148:35 - case you will have to pay to the openi
148:37 - as well getting my point so here you can
148:41 - read uh entire detail regarding this
148:43 - fine tuning and all so once I will come
148:44 - to this fine tuning part I will explain
148:46 - you this uh thing as well how to do the
148:49 - fine tuning and all regarding this model
148:51 - definitely I'm not going to do it uh in
148:53 - the live class but yeah I will give you
148:55 - the uh quick guidance regarding uh this
148:57 - fine tuning so I hope guys uh this model
149:02 - related thing model related part and
149:04 - this quick start and this introduction
149:06 - and what of capabilities is there so
149:10 - this thing is clear to all of you if it
149:12 - is clear then please do let me know in
149:13 - the
149:15 - chat yes or no so waiting for your reply
149:19 - please do let me know in the
149:22 - chat what what are the job opportunity
149:25 - after this particular course so after
149:27 - that you can apply as a NLP engineer uh
149:30 - you can work on a gentic way related
149:31 - project you can work uh as a uh gen VA
149:35 - engineer so if you are going to complete
149:37 - this particular course so after that you
149:40 - can join uh the company uh like whatever
149:43 - designation I told you on that
149:45 - particular designation
149:47 - and uh here in an interview do they ask
149:49 - from the scratch inside of using API no
149:51 - they won't ask you that you need to like
149:54 - uh you just show them like how to use
149:56 - the API and all no they won't ask you
149:58 - this particular thing uh they you just
150:00 - need to tell you what was your use case
150:02 - which model you have used and uh what
150:04 - was the cost regarding behind that
150:06 - particular model uh how you you have
150:09 - designed your prompt template how many
150:11 - tokens basically there uh you were uh
150:13 - defining inside your prompt in U
150:15 - basically inside the input input prompt
150:17 - and how much tokens basically you are
150:19 - getting inside the output
150:21 - prompt okay so these are the thing uh
150:24 - like uh they might they might ask you
150:26 - regarding this uh uh like openi API and
150:29 - all and open AI models uh they won't ask
150:32 - you that uh generate this key that key
150:34 - or
150:36 - whatever do we need to learn all the
150:39 - underlined math behind the model hugging
150:41 - pH and open ey yes the architecture
150:43 - should be clear so the architecture part
150:45 - should be clear uh architecture means
150:48 - what so uh the base architecture
150:50 - Transformer architecture they definitely
150:53 - they might ask you the or Transformer
150:55 - architecture in one of the interview
150:56 - they they have asked to me that uh can
150:59 - you uh explain me the Transformer
151:01 - architecture what is the meaning of the
151:02 - positional uncoding why we are using a
151:04 - skip connection over there and can you
151:06 - code it as well so if you want to use
151:08 - this Transformer in the python how you
151:10 - can do that which uh like which Library
151:13 - you will call or can you write it down
151:14 - the code from scratch so this type of
151:16 - question you might face if they are
151:18 - going on a architecture level they won't
151:21 - ask you the uh they won't ask you the
151:23 - architecture of the different different
151:25 - model which is there over the hugging
151:26 - face and all no they won't ask you
151:30 - that so can we proceed now if uh this
151:33 - part is clear tell me guys fast yes or
151:37 - no I given you the complete walk through
151:40 - of the open uh website openai API now I
151:45 - will show you how you can utilize it and
151:47 - don't worry guys I will uh show you the
151:50 - advanced thing as well I will show you
151:51 - the advanced part as well uh I will show
151:54 - you this function uh calling and all and
151:57 - uh first let me complete this uh uh chat
152:00 - completion and after that I will come to
152:02 - the function
152:06 - calling great so here uh I think this
152:09 - thing is clear now let's try to start
152:12 - with the Practical implementation so for
152:14 - the Practical implementation first of
152:16 - all uh what you need to do so let me uh
152:19 - write it down the step all the step so
152:22 - here uh the first thing what you need to
152:24 - do see uh you should have uh you should
152:27 - have this uh Anaconda inside your system
152:30 - I think you know about this Anaconda
152:32 - what is this Anaconda it's a package uh
152:34 - it's a package manager for the data
152:36 - science projects and all so you should
152:38 - have this uh Anaconda inside your system
152:40 - the second thing uh python must be
152:44 - installed python must be installed all
152:47 - now here whatever practical which I'm
152:49 - going to do so I'm going to do by using
152:51 - the Jupiter notebook so here let me
152:54 - write it down uh the Jupiter notebook
152:56 - now whatever practical and all whatever
152:58 - I'm going to do I'm going to use
153:00 - basically I'm going to do by using this
153:01 - jupyter notebook in the next class uh
153:04 - I'm going to uh create an end to end
153:05 - project first of all uh before starting
153:08 - with the end to end project I will come
153:09 - to the Len chain and there I will
153:11 - explain that each and every concept of
153:13 - the Len chain that how it is different
153:14 - from the openi and why should uh why we
153:17 - should use it and after that once I will
153:19 - come to the end to project then I I will
153:21 - start from the vs code itself vs code
153:24 - Visual Studio code so any ID you can use
153:27 - I'm not restricting you for the ID and
153:28 - all so if you are familiar with the py
153:31 - charm you can use that also if you are
153:33 - familiar with the like any other ID you
153:36 - can use that but yeah I love this vs
153:38 - code so uh for the project for the end
153:40 - project I will use this vs code as of
153:42 - now I going to use the Jupiter notebook
153:44 - uh just for the
153:46 - uh like open a uh python API uh so guys
153:51 - if you have this two thing this three
153:53 - thing actually inside your system so
153:54 - after that what you need to do you need
153:56 - to create one virtual environment so uh
153:59 - here by using this cond by using this
154:02 - cond you need to create one virtual
154:04 - environment I will show you all the step
154:06 - don't worry so here you need to create a
154:09 - virtual environment there inside after
154:11 - creating a virtual environment you need
154:13 - to activate it activate this virtual
154:15 - environment
154:16 - and here you need to install all the
154:18 - packages all the required packages
154:21 - inside this virtual environment so here
154:23 - you need to install all the required
154:25 - packages so let me write it down over
154:26 - here install all the required packages
154:29 - now uh required packages means what
154:31 - required packages means so you need to
154:34 - install this open a as of now and we
154:37 - have other packages also like pandas
154:39 - napai and all so if I will be uh if I
154:42 - will be having any sort of a requirement
154:44 - uh regarding the pandas numine uh or
154:47 - regarding any other packages so
154:48 - definitely I will install that also in
154:50 - my virtual environment now after
154:53 - installing all sort of a thing so after
154:55 - like creating a virtual environment
154:57 - after activating it and after installing
154:59 - all the packages then what I will do I
155:01 - will be starting with the Practical
155:03 - implementation so guys in my system I
155:06 - already having Anaconda so you can uh
155:08 - download it by searching this Anaconda
155:10 - so just go through with the Google and
155:13 - search over here Anaconda download so on
155:16 - once you will search this Anaconda
155:18 - download so here you will get the
155:20 - website uh here you will get a link so
155:22 - just click on that and here you will get
155:24 - a option for downloading this Anaconda
155:27 - now uh it is giving you the option based
155:29 - on your operating system so if you are
155:31 - using Windows if you using Mac or Linux
155:34 - according to that you can download this
155:36 - Anaconda now apart from that uh one more
155:39 - thing will be required so if you don't
155:41 - have python in your local system so you
155:44 - need to download that as well so
155:46 - python uh download so here I'm going to
155:49 - write down the python download and yes
155:52 - uh this is a website of the Python and
155:55 - uh here you need to uh here basically
155:57 - you can uh download the python by
155:59 - clicking on this particular website I
156:01 - would suggest you uh download this 3.10
156:03 - or 3.11 don't download the latest
156:05 - version this 3.12 or this 3.13 actually
156:09 - uh it is having some sort of a like
156:12 - issues so better uh okay don't download
156:15 - this 3.11 also either download the 3.10
156:18 - or 3.9 it will be working fine or you
156:20 - can download this 3.8 also this all
156:23 - three version is a stable version fine
156:27 - now after downloading this anaconda and
156:29 - this python inside your local system
156:31 - then what you need to do so once you are
156:34 - ready with the Anaconda and this python
156:36 - after downloading and installing and all
156:38 - you need to search Anaconda prompt so
156:40 - here uh you will find out the uh like
156:43 - Anaconda prompt so once you will search
156:45 - over here in the search search box
156:46 - Anaconda prompt so there itself you'll
156:48 - find out the Anaconda prompt now this is
156:50 - what this is my anaconda prompt guys
156:51 - this one now here actually this is what
156:53 - it is it is showing me a base
156:55 - environment as of now this base is a by
156:58 - default environment now here what I need
157:00 - to do I need to create a virtual
157:01 - environment how I can do that how I can
157:04 - create a virtual environment so for that
157:06 - we have a command now here the command
157:08 - is what cond create so cond create
157:11 - hyphen n and here I need to write it
157:14 - down my environment name so here my
157:16 - environment name is what testing open AI
157:19 - so testing open AI this is what this is
157:21 - my environment name you can give any XY
157:23 - Z name over here I don't have any issue
157:25 - now you need to mention the python
157:27 - version so here you need to write it
157:28 - down the python equal to 3.8 now guys
157:32 - here I'm going to use 3.8 you can use
157:34 - 3.9 3.10 don't use 3.11 12 and 13 3.8 7
157:39 - 9 10 these are the stable version and
157:41 - you can use it for your project now as
157:44 - soon as I will hit enter ENT so yes I
157:46 - will be able to create an environment so
157:49 - yes let me hit the enter and it is
157:51 - creating an environment so are you doing
157:53 - along with me if you are doing along
157:55 - with me then please do let me know in
157:57 - the chat
158:09 - guys yes I okay so people are saying yes
158:13 - we are doing
158:14 - it can we do sir using API as well as
158:19 - our make
158:20 - model if you have trained your own model
158:23 - then definitely you can do
158:27 - it great so many people are doing a lot
158:30 - with me I think now here you can see so
158:34 - uh this is what uh this is my base
158:35 - environment sorry this is my base
158:37 - environment and here I have created a
158:38 - virtual environment and this is my
158:40 - virtual environment if I want to
158:41 - activate it so for that this is the
158:43 - command so here you need to copy this
158:45 - command and just just paste it over here
158:47 - and so you will be able to find out that
158:48 - I have uh I'm able to activate my
158:51 - environment now you can clear the screen
158:53 - so for that you just need to write it
158:55 - down the CLS and here is what guys here
158:57 - is my virtual environment now here what
159:00 - you will do see uh first of all you need
159:02 - to check that what are libraries is
159:04 - available inside your virtual
159:05 - environment so for that you can write it
159:07 - down the command the command is what the
159:09 - command is PIP list so once you will
159:11 - write it down this pip list here you
159:13 - will find out all the library what ever
159:15 - is there as of now inside your virtual
159:18 - environment so these are the library
159:20 - which is there inside my environment and
159:22 - here I uh still I haven't uh downloaded
159:25 - this uh open open Package because by
159:29 - using the open by downloading the openi
159:30 - package only by using that open Package
159:32 - only I can hit the API getting my point
159:36 - yes or no so don't worry I will give you
159:39 - the entire step whatever step I'm
159:40 - following over here now here first of
159:43 - all you what you need to do see I took
159:45 - told you over my Blackboard that after
159:48 - creating a virtual environment you need
159:49 - to activate it and then you need to
159:51 - install the required package and before
159:53 - that I told you one thing that
159:54 - everything I'm going to do inside the
159:56 - jupyter notebook so guys here in this
159:58 - particular environment in this virtual
160:00 - environment you need to download or you
160:02 - need to install the Jupiter notebook and
160:04 - for that we have a command so let me
160:06 - write it on the command pip install
160:09 - Jupiter notebook so here I can write it
160:12 - down g u p y t e r n o t e b k so this
160:17 - is the command pip install jupyter
160:18 - notebook and with that you will be able
160:20 - to download the jupyter notebook and oot
160:23 - te so this is the correct spelling let
160:26 - me rewrite it
160:29 - again yeah so installing J notebook are
160:32 - you doing along with me tell
160:35 - me yeah so here let me write down the
160:37 - command in the chat section so cond
160:40 - create hyphone n and you can write it on
160:44 - environment name whatever you want to
160:46 - write it down so let's say testing open
160:48 - a and here python version is what
160:52 - 3.8 so this is the command uh you need
160:55 - to run this particular command for
160:56 - installing the sorry for creating a
160:59 - virtual environment now let me give you
161:01 - one more command so here you can check
161:03 - all the listed uh Library uh all the
161:07 - like Library whatever is there inside
161:08 - the virtual environment pip list is a
161:10 - command now let me give you one more
161:12 - command so here is one more command pip
161:15 - inst install Jupiter notebook so pip
161:19 - install Jupiter notebook so these are
161:22 - the three command did you get it uh
161:24 - please do uh confirm in the chat please
161:26 - give me a quick confirmation the
161:34 - chat see if you're not installing this
161:37 - Jupiter notebook in your current virtual
161:38 - environment in that case it will launch
161:41 - the jupyter notebook from your base
161:43 - environment so it is a better practice
161:46 - if you are creating a virtual
161:47 - environment then please install the
161:48 - jupyter notebook or please install the
161:51 - ipnb kernel over there so now if you
161:53 - will find out uh now if you will search
161:55 - pip list over here so just search pip
161:58 - list now once you will search pip list
162:00 - then you will find out lots of libraries
162:03 - or lots of
162:04 - packages which came along with the
162:07 - jupyter notebook now see here you can
162:10 - see all the packages and all after
162:13 - installing the jupter notebook now once
162:15 - I will write it down the Jupiter
162:16 - Notebook on my anaconda prompt so here
162:19 - let me write down the Jupiter notebook
162:22 - and it will open the notebook so once I
162:26 - will write it down the Jupiter notebook
162:28 - and you will see that yes it has open
162:32 - the Jupiter notebook so got it guys yes
162:36 - or no please do let me know in the chat
162:38 - if you are able to launch your Jupiter
162:43 - notebook if you are are able to launch
162:45 - the Jupiter notebook then please do let
162:47 - me know in the chat yes or no yes and
162:51 - after that you need to launch your file
162:53 - so you need to launch your notebook so
162:55 - click on this notebook and here is what
162:57 - guys here is your notebook so this is
163:00 - your notebook and each and everything we
163:02 - are going to do here itself inside this
163:05 - particular notebook now uh just make
163:08 - sure that you have this python uh Python
163:11 - 3 over here uh this uh ipynb kernel if
163:14 - you don't have that so so please try to
163:16 - select this Python 3 ipy
163:19 - kernel and I think now everything is
163:21 - ready so let's try to oh let's start
163:25 - with the open API so test open API and
163:30 - now let me rename it so here guys you
163:32 - can see this is my test openi
163:37 - API uh this is my file actually this is
163:39 - my notebook I hope you all have created
163:42 - this particular
163:44 - notebook
163:49 - if you have any doubt then please do let
163:51 - me know in the
164:07 - chat everything is clear everything is
164:10 - sorted please guys go ahead so just be a
164:13 - little interactive uh please write it
164:15 - down the chat if I'm asking something so
164:17 - if you if you can if you'll write it
164:18 - down the chat so definitely I will get U
164:34 - motivation great so now let's start with
164:37 - the uh like open AI API so first of all
164:42 - what you need to do so here is what here
164:43 - is my notebook so let me do one thing
164:45 - let me keep it uh keep this notebook
164:47 - over here
164:49 - itself and this is what this is my
164:51 - Jupiter notebook so first of all just go
164:54 - through with the openi website so here
164:57 - is your openi website guys this one now
164:59 - here you need to click on this quick
165:02 - start here what you need to do here you
165:04 - need to click on this quick start after
165:06 - clicking on this quick start so here
165:08 - they have given you the option the
165:09 - option is what python so here they have
165:11 - given you the three option Cur Python
165:13 - and node.js
165:15 - so click on this Python and here they
165:16 - have given you the complete instruction
165:19 - so first of all guys what you need to do
165:21 - you need to install a python so yes uh I
165:24 - think you already have installed this
165:25 - python you need to set up a virtual
165:27 - environment yes we set up the virtual
165:29 - environment and why this virtual
165:31 - environment is required so see uh for uh
165:33 - one particular project we have a lots of
165:36 - dependency if I want if I want to if I
165:40 - want to segregate all those dependency
165:42 - project to project okay so for that only
165:45 - we create a virtual environment so what
165:47 - is the requirement of the virtual
165:48 - environment because we have a several
165:51 - dependency on a single project if I want
165:53 - to keep it apart for that only we create
165:56 - this virtual environment got it so here
165:59 - they have created a virtual environment
166:01 - directly by using this python uh en and
166:04 - you can use this also for creating that
166:06 - but I'm using the Anaconda now here
166:09 - after that you need to install this open
166:11 - AI so here uh what you need to do guys
166:14 - so here you need to install this open a
166:16 - package and then only you can hit the
166:18 - open API getting my point so just copy
166:21 - this particular command and install this
166:24 - openi package in your virtual
166:27 - environment so here is what here is my
166:29 - virtual environment let me open that
166:31 - particular environment uh just a
166:36 - second what I can do here I can keep it
166:40 - this to
166:42 - my same TP fine now over here guys what
166:46 - you need to do you need to open your
166:48 - anaconda prompt see here actually I have
166:50 - launched this jupyter notebook so you
166:51 - cannot stop the server of this jupyter
166:53 - notebook so I'm opening a new Anaconda
166:56 - prompt so here you just need to write it
166:58 - down this Anaconda prompt and you will
167:00 - be able to launch a new Anaconda promt
167:03 - now guys just tell me what is my
167:04 - environment name testing open AI so here
167:08 - uh you just need to write it down uh
167:10 - cond EnV list so once you will write it
167:12 - down this K EnV list k EnV list so let
167:16 - me write it down this cond EnV
167:19 - list so you will get all the all the
167:23 - environment name so here guys you can
167:24 - see this is my all the environment which
167:26 - I have created in my system by using
167:28 - this Anaconda now uh here uh this is my
167:31 - environment testing open I want to
167:34 - activate this particular environment so
167:35 - I can write it down over here cond
167:38 - activate and here I can write it down my
167:40 - environment name testing open AI so once
167:44 - I will write down this and if I will hit
167:46 - hit enter so I will be able to activate
167:48 - my environment I'm going to uh I'm going
167:51 - to do a uh transition from base
167:53 - environment to this testing openi
167:56 - environment this is what this is my
167:57 - virtual environment this base
167:59 - environment is a default environment now
168:01 - over here what I will do I will I'm
168:02 - going to write down the CLS for clear
168:04 - the entire screen now over here I will
168:06 - just paste this particular command pip
168:08 - install hyphen iph upgrade open AI now
168:11 - once I will hit enter so yes uh I'm able
168:15 - to install this open AI inside my
168:18 - virtual environment so are you doing
168:20 - along with me are you able to install
168:22 - this open AI inside your virtual
168:23 - environment if yes then please do let me
168:25 - know in the
168:29 - chat in the virtual environment you need
168:31 - to install the jupyter notebook by using
168:33 - this pip install jupyter notebook
168:35 - command if you're not doing it in that
168:37 - case it will be taking a jupter notebook
168:39 - from the it will be launching a jupyter
168:41 - notebook from the base
168:43 - environment
168:46 - many people now people are saying yes we
168:48 - are doing it how many of you you are
168:51 - doing along with me please do let me
168:53 - know in the chat how many of you you are
168:54 - doing along with
169:04 - me yes yes
169:11 - yes okay great yes
169:15 - please write it down the chat if you are
169:17 - doing along with me
169:39 - then if you uh launching uh jupyter
169:42 - notebook from the base environment it
169:43 - will take a all the packages from there
169:46 - itself that's why I want a fresh one
169:48 - that's why I'm installing jupyter
169:51 - notebook in my current
169:54 - environment now over here I think I have
169:57 - already installed it so yes it is done
169:59 - now and if I want to check it so for
170:02 - that I'm uh I'm opening my jup notebook
170:04 - again and here you need to write it
170:07 - down uh import open AI so just write it
170:11 - down this import open Ai and here guys
170:14 - you can see
170:15 - we are able to import this open AI if
170:17 - you are done till here then I will
170:19 - proceed with the further python code so
170:22 - please give me a quick confirmation in
170:24 - the chat if you are able to import this
170:25 - open I'm just I'm waiting for 1 minute
170:28 - I'm waiting for uh 1 minute uh to okay
170:31 - so please uh give me a confirmation in
170:32 - the chat if you are able to import this
170:35 - open AI inside this jupyter
170:43 - notebook
171:01 - we are ready to go great now uh let's
171:04 - start with the uh open API that first of
171:08 - all guys we need to understand that what
171:10 - is what is this openi API so for that
171:14 - what I did I kep uh I return like uh
171:16 - some sort of a like
171:20 - uh um wait let me do one thing over here
171:24 - let me copy and
171:30 - paste yeah so here guys what I did I
171:32 - written some sort of questions and
171:34 - answers and here the first question is
171:36 - what the first question is what is open
171:38 - a API so by uh uh like uh so here by
171:42 - using this particular question so by
171:44 - reading this particular answer actually
171:46 - we can understand that what is this open
171:48 - API so this openi API has been designed
171:51 - to provide developer with seamless
171:53 - access to stateof Art pre-trained
171:56 - artificial intelligence model like GPD 3
171:59 - GPD 4 Delhi whisper ambing Etc so what
172:03 - is the meaning of it so if you want to
172:04 - use if you want to use the same model
172:07 - whatever model has been trained by the
172:09 - open AI so these are the different
172:10 - different model uh the name basically I
172:13 - have written over here GP 3 gbd4 Delhi
172:16 - is a model whisper is a model aming
172:18 - there are different different model
172:20 - right if you want to use this particular
172:22 - model inside your
172:24 - application so that uh so then basically
172:27 - you should use this open API now over
172:30 - here by using this openi API you can
172:32 - integrate Cutting Edge AI capabilities
172:35 - so this model actually it's a large
172:36 - language model and it is having a lots
172:38 - of capability in terms of a different
172:40 - different task as I explain you so by
172:43 - using this particular models you can uh
172:47 - like utilize uh that capability you can
172:50 - utilize the capability and uh you can
172:53 - utilize that particular capability and
172:55 - you can integrate inside your
172:57 - application getting my point and
172:59 - regardless the programming language so
173:01 - here they have they have given you two
173:02 - option so the first one is a Python and
173:04 - the second one is a nodejs so uh what is
173:07 - this open API so this open API is
173:09 - nothing it provide you the seamless
173:11 - exess of a pre-trained artificial
173:13 - intelligence based model uh for your uh
173:17 - like a different different application
173:18 - whatever application you are going to
173:20 - create and let's say if you are going to
173:22 - create any individual application which
173:23 - is based on NLP use case yes directly
173:26 - you can uh use this particular model
173:28 - instead of trading your model from very
173:30 - scratch now here so the conclusion is
173:33 - what so the conclusion is by using this
173:34 - openi API you can unlock the advanced
173:37 - functionality and you can enhance the
173:39 - intelligence and performance of your
173:41 - application so let's say there is Inon
173:44 - website and the Inon website you must
173:46 - have seen the chatbot
173:48 - option so in the chatboard actually uh
173:51 - you are doing uh you are connecting with
173:53 - our expert so let's say there there's a
173:56 - one person who is having a doubt so now
173:58 - this person what he is doing he is going
174:00 - to be connect with a uh like expert so
174:02 - here is the expert which is sitting
174:04 - behind this particular chat board now he
174:06 - is asking the question and he's getting
174:08 - a reply yes or no now guys just see over
174:12 - here so here uh like you have integrated
174:15 - this chatboard and this chat board is a
174:17 - uh it's not a like eii related chatboard
174:20 - so the person so here uh in the behind
174:23 - behind behind to this chatboard actually
174:25 - when expert is sitting he is giving you
174:27 - the answer now you want to uh like uh
174:31 - what you want to do guys over here so
174:33 - you want to use some sort of a AI now
174:35 - here you want that that type of model
174:38 - which will be able to answer all of the
174:40 - answer basically whatever the person is
174:43 - asking like chat GP so in that case you
174:45 - cannot train your own model if we are
174:48 - talking about if we are talking about
174:50 - like the llm model so in that CA in that
174:53 - case basically you cannot train your own
174:55 - model because it's a very very expensive
174:57 - let's say if you if you are just a
174:59 - startup okay or let's say if you are
175:01 - just a Learner in that case in that case
175:04 - you cannot invest this much of amount
175:06 - for training this particular model
175:09 - because it's a expensive process if you
175:10 - are going to set up the infrastructure
175:12 - if you're are going to uh like if are
175:14 - like hiring a developer ai ai developer
175:16 - and all amops engineer so in that case
175:19 - definitely the cost will be around 1 to
175:21 - 10
175:22 - CR because in that case you will have to
175:24 - create a distributed setup you will have
175:26 - to purchase a gpus there should be a
175:28 - team one proper team okay for the
175:31 - monitoring and all for each and
175:32 - everything there there will be a
175:33 - developers so the cost will be very very
175:35 - high in that case what you will do if
175:37 - you want to uh take advantage of this AI
175:41 - uh cap if you want to take a leverage of
175:43 - this model whatever model model has been
175:44 - created or trained by this open a what
175:47 - you will do you will use this openai API
175:49 - you will uh call this open API and by
175:53 - using this openi API you will be able to
175:55 - access this GPD model and directly you
175:57 - will be able to uh like append this
175:59 - model inside your chatboard so whatever
176:01 - person is asking definitely your GPT
176:03 - will be replying in that case and let's
176:05 - say any escalation is is happening in
176:07 - that case so definitely you can uh write
176:09 - it down your logic your code in uh in
176:11 - such a way that this request will be
176:13 - moved to the expert and now the it will
176:15 - be handled by the expert itself so like
176:18 - design you can like this basically you
176:19 - can design your system this is just a
176:21 - one example which I have given to you
176:24 - great I think uh everything is clear now
176:26 - over here so what is opena
176:29 - API this part is clear now the second
176:31 - question is what the second question is
176:33 - generate a open a API key so here what I
176:37 - have to do I have to generate a open API
176:39 - key what I need to do guys I need to
176:41 - generate open API key without this I
176:44 - cannot use the open API without this
176:47 - particular key so for that what I need
176:49 - to do what is the process let me tell
176:52 - you that so if I want to generate if I
176:54 - want to generate a open a API key so
176:57 - just go through with the open a website
176:59 - so here is your open a website and here
177:01 - just over your mouse uh on this
177:03 - particular side on the left hand side
177:06 - now here is the option this API key just
177:08 - click on that and here guys you will
177:10 - find out a option to generate or to
177:12 - create a new secret key are you getting
177:14 - this
177:17 - option are you getting this particular
177:19 - option please do let me know in the chat
177:21 - if you're getting it
177:26 - then after logging in to the openi
177:29 - website then only you will be able to
177:31 - find out this API key
177:33 - option and guys uh you cannot uh
177:36 - generate a openi key without adding any
177:38 - sort of a payment method so first of all
177:41 - you will have to add the payment method
177:43 - and don't worry in the next class I will
177:45 - show you how you can use hugging face
177:47 - API key for the same thing for the same
177:50 - task definitely we won't be able to
177:52 - access uh other uh models like gbd3 GPD
177:55 - 3.5 turbo or gbd4 and all but yes uh
177:59 - we'll be having access of a different
178:01 - model different open source model or
178:02 - whatever model is available over there
178:05 - in tomorrow's session I will show you
178:06 - how you can utilize the hugging face API
178:10 - [Music]
178:12 - key you you can finetune the model again
178:15 - it will be an expensive task
178:18 - Vishnu great so here you can see we have
178:21 - a uh like option to generate a like here
178:24 - basically what we can do we can generate
178:26 - a API key now for generating a API key
178:28 - you just need to click on this create a
178:30 - new secret key and here you need to give
178:32 - the name so let's say I'm going to write
178:34 - down the name uh my API key so this is
178:39 - the name of my API key once I will click
178:41 - on this create secret key so yes uh
178:45 - definitely I will be able to generate it
178:46 - now guys over here you can see this is
178:48 - my key uh definitely I will delete it
178:51 - right after the session otherwise you
178:52 - will exceed uh the limits and all all
178:55 - right so here I have generated my key
178:57 - and after the session I will delete it
178:59 - so no one will be able to use it so I
179:02 - have generated a key now what I will do
179:04 - I will paste it down in my Jupiter
179:06 - notebook over here so here is what guys
179:08 - here is my key so this is what this is
179:11 - my key basically which I have generated
179:14 - so here uh let me uh paste it down this
179:16 - particular key this is what this is my
179:18 - key now you have to generate your own
179:19 - key okay and don't share your key with
179:22 - anyone else so here this is what this is
179:24 - my key now what I need to do after
179:26 - generating this open a key I have
179:29 - generated the open a key and I kept it
179:30 - over here now after that I need to call
179:33 - the open AI API so how we can do that so
179:37 - for that we have a couple of couple a
179:39 - couple of line of code so let me paste
179:41 - it over here or let me write it down
179:42 - over here and then I will I will show
179:44 - you how we can hit any sort of a model
179:46 - now for that uh basically what I did so
179:49 - over
179:50 - here uh just a
179:53 - second yeah so first of all let me show
179:56 - you the list of the model as well now
179:58 - over here I can write it down uh one
180:00 - line of code so open a uh do API key API
180:06 - unor key and here I need to write it
180:08 - down my key here I need to write it down
180:11 - the variable basically where I have kept
180:13 - my key
180:14 - so once I will run it so here you can
180:16 - see open
180:19 - AI open AI API key yes I'm able to set
180:23 - my key now here I will call one method
180:26 - so my method name is what open AI dot
180:29 - model model underscore uh model. list so
180:35 - once I will call this particular uh
180:37 - method so here you will be able to find
180:39 - out your all the model see there is all
180:41 - the model basically which is available
180:43 - as of now now in the openi plateform now
180:47 - here you can see it is giving me some uh
180:50 - it is giving me output in a different
180:51 - way so what I can do I can convert it
180:54 - into a list so over here what I can do I
180:57 - can convert this uh particular output
180:59 - this particular response in a list so
181:02 - here uh this is my all the models so I
181:04 - can create a variable
181:06 - allore models and here I can pass this
181:09 - thing to my list method now see guys uh
181:13 - I will be getting all the model all the
181:15 - models uh whatever model is there inside
181:18 - the openi so the first one is a text
181:21 - search weage uh doc 001 and here is a
181:24 - date actually they have mentioned the
181:26 - date or maybe the version uh now the
181:29 - created when they have created and here
181:31 - is a object object is what model and
181:34 - owned by owned by open AI de now here
181:37 - what you can do you can create a uh data
181:40 - frame also so what you can do you can
181:42 - create a data frame so here uh let me
181:45 - write it down the code for the data
181:47 - frame so import pandas s PD now here I
181:51 - can write it on PD do data frame so here
181:56 - what I need to do you just need to pass
181:57 - this particular uh you just need to pass
182:01 - this
182:01 - particular value this one so let me keep
182:05 - it over here uh this uh list uh list of
182:09 - all the models so once I will run it so
182:11 - here you will be able to find out is
182:13 - giving me error the pandas is not there
182:16 - so for that uh just download the pandas
182:19 - or just install the pandas inside your
182:20 - virtual environment because in this
182:22 - virtual environment pandas is not
182:25 - available so let me write it down over
182:27 - here click install pandas and once I
182:30 - will hit the enter we will uh we will be
182:33 - able to install this
182:35 - pandas it will take some time so let it
182:41 - install yes I'm coming to the code I
182:43 - will show you the code just wait for
182:45 - some time just
182:58 - wait yeah so I'm done with the pandas I
183:00 - have installed it and uh now what I can
183:04 - do I can run it and you will be able to
183:06 - find out your data frame so here this is
183:08 - the model this is the like when it is
183:11 - created and object is what object is a
183:13 - model and owned by so now it is in a
183:16 - perfect format and you can read each and
183:18 - everything clearly and here I can
183:21 - provide the column name as well so let
183:23 - me give the column name let me write on
183:25 - the column name as well and here I
183:27 - already WR the code of for the column
183:30 - name so once I will run it so here you
183:32 - will find out the column name so here is
183:35 - my ID this is the like model ID and when
183:39 - it has created what is a uh like what is
183:42 - this actually so it's a object is a
183:44 - model now here owned by owned by this
183:47 - openi development team openi internal
183:50 - openi development or here you will find
183:52 - out some other name as well so I believe
183:55 - you are able to run this entire all like
183:58 - entire code whatever I have written over
184:00 - here now here uh this is what this is my
184:04 - code for uh seeing the model and all now
184:07 - the next thing uh here I got all the
184:09 - model now the third thing basically
184:11 - which I would like to uh explain you
184:13 - that is what that is a open AI
184:15 - Playground open a playground and after
184:17 - that I will come to the chat completion
184:19 - API now I will take uh more 15 minute
184:22 - and within that uh I will conclude this
184:24 - session and in tomorrow's session I will
184:26 - start with a chat completion a uh this
184:28 - function call and I will explain you the
184:31 - uh the hugging face API key as well so
184:33 - how you can utilize the hugging face API
184:35 - key for a open source model now let me
184:38 - copy and paste the entire uh thing
184:41 - whatever I have written for you so here
184:43 - here I have written some sort of a thing
184:45 - let me go through step by step so here
184:48 - I'm talking about this open AI
184:50 - Playground now what is this what is this
184:52 - open a playground now once you will uh
184:54 - search over the Google so open your
184:56 - Google guys and here search open AI open
185:00 - a playground now just search over here
185:02 - open playground and uh here you will
185:06 - find out this Playground now once you
185:08 - will click on this assistant so here you
185:11 - will find out a different different
185:12 - option so one is a assistant the second
185:14 - one is ched third one is a complete
185:16 - fourth is a edit I'm not going through
185:18 - with this complete and this edit because
185:20 - it's the Legacy now I will explain this
185:22 - chat first I will explain this chat and
185:24 - then I will come to this assistant now
185:27 - inside this chat uh so once I will click
185:29 - on this chat so here I can test uh my
185:33 - different uh I can test like different
185:34 - different prompts and all I can generate
185:37 - output I can test with a different
185:38 - different model and along with a model
185:40 - you will find out a various parameter so
185:43 - so first of all guys what you need to do
185:44 - you need to set you need to set your
185:47 - system right so here you will find out
185:49 - three options so the first one is what
185:51 - first one is a system the second one is
185:53 - a user and the third one is this one
185:56 - right so you can divide this entire
185:58 - interface into a three segment now let
186:00 - me give you step by step that what is
186:02 - the meaning of the system what is the
186:03 - meaning of this uh user and this
186:05 - assistant and what is the meaning of
186:07 - this model each and everything we'll try
186:09 - to understand over here so guys system
186:11 - is what so system is means system means
186:14 - uh how your model is going to behave
186:17 - here you are going to set the behavior
186:20 - of your system what you are doing tell
186:22 - me here you are going to set the
186:23 - behavior of your system so here if I'm
186:26 - going to write it down you are a
186:29 - helpful
186:31 - assistant now here if I'm going to write
186:33 - down you are a helpful assistant now
186:35 - what I will do I will write it down my
186:37 - message so see here here guys you will
186:38 - find out two thing uh two option so once
186:41 - you will click on this user now you will
186:42 - find out either user or assistant as of
186:44 - now what I am I am a user I'm asking a
186:47 - question now here I'm asking that uh uh
186:50 - what I can ask guys uh just tell me
186:53 - something different okay how I
186:57 - can make a
187:00 - money how I can make a money so I'm
187:02 - asking to my chat GPT how I can make a
187:04 - money and here is what here is my model
187:06 - so here once you will click on this
187:07 - model you will find out a different
187:08 - different model so uh there is GPD 4 GPD
187:12 - 3.5 GPD 3.5 turbo so all the model there
187:14 - is all the models right so here I'm
187:16 - using the gbd 3.5 now we have a various
187:19 - option so the first one is what first
187:21 - one is a temperature now what is the
187:23 - meaning of this temperature so we are
187:25 - talking about this temperature so just
187:26 - try to read about this temperature
187:28 - control Randomness lowering result in
187:31 - less random completion as the
187:33 - temperature approach zero the model will
187:35 - become deterministic and repeative so
187:38 - over here we are talking about this
187:39 - temperature if we are defining a higher
187:41 - value of the temperature means I'm uh
187:43 - I'm saying that just give me a more
187:45 - creative answer I'm adding a
187:48 - Randomness if I'm writing a zero I'm
187:51 - saying give the straightforward answer
187:53 - I'm asking to my chat GPD uh the
187:56 - straightforward answer I'm not going to
187:58 - add any sort of a creativity over here
188:01 - getting my point what is the meaning of
188:03 - this temperature I think yes now maximum
188:05 - length so here you can set the tokal
188:08 - length now here stop sequence is there
188:11 - so up to up to four sequence where the
188:13 - API will stop generating further tokens
188:15 - the return text will not be contain the
188:18 - like a stop sequence here you can
188:19 - mention the stop sequence now here is a
188:21 - top P parameter so this parameter
188:24 - actually this is again similar to this
188:25 - temperature it is controlling the
188:27 - diversity whatever like Pro whatever
188:29 - output you are going to be generate so
188:31 - control diversity via uh nucleus
188:33 - sampling 0 0.5 means half of likelihood
188:36 - weighted option are considered so you
188:38 - can just think about it that it is
188:39 - nothing just adding a diversity inside
188:41 - your output now frequency penalty if you
188:44 - don't want to repeat the tokens let's
188:47 - say you are generating some sort of
188:48 - output if you don't want to repeat the
188:49 - tokens inside your output so here you
188:53 - can mention the frequency penalty as of
188:55 - now it's zero so it's not going to be uh
188:58 - like put any sort of a penalty over here
189:00 - if you're going to increase the number
189:01 - definitely it will put the frequency
189:03 - penalty means it will give you the
189:05 - different different words it is not
189:06 - going to repeat the words now here
189:09 - present penalty so you can set this also
189:12 - so there is a different parameter just
189:13 - try to explore it now here I'm asking to
189:15 - my chat GPD how I can make a money so if
189:17 - I'm submitting this thing so here I will
189:19 - be getting my answer and there is the
189:21 - answer is there are many ways to come
189:24 - make a money and all so employment and
189:27 - all
189:28 - freelancing online selling rent or share
189:31 - sources and tutoring and teaching gig
189:34 - and economy gig economy affiliate
189:37 - marketing so it is giving me answer guys
189:40 - as you can see right now just uh do one
189:44 - thing so here guys see I've uh defined
189:47 - the behavior of the system Ive defined
189:49 - that I'm working as a user and here is
189:51 - my model all the different different the
189:53 - different different parameter I have
189:54 - like selected based on this model now
189:57 - just go over here and try to click on
190:00 - this view code so once you will click on
190:02 - this view code guys you will get the
190:04 - entire python code over here getting my
190:08 - point yes or no see over here you are
190:10 - getting the entire python code now you
190:13 - can utilize this python code if you have
190:15 - if you have done the complete setup in
190:17 - your system whatever setup basically
190:20 - which I which I uh which I have done
190:22 - right if you have done the complete
190:23 - setup in your system so directly you can
190:26 - hit uh directly you can hit the open a
190:28 - API and you can call the GPD 3.5 turbo
190:33 - model okay so that's why I've shown you
190:35 - this openi Playground now I think you
190:38 - are uh we are done with this open I
190:39 - Playground now let's try to do something
190:41 - amazing over here let's try to set set
190:43 - the different behavior of this chat uh
190:45 - GPT so here guys I have written couple
190:47 - of thing inside this particular like
190:49 - answer so how to open a playground so
190:51 - here I mentioned that here make sure
190:53 - that playground should have a credit yes
190:55 - if you don't have a credit if you
190:56 - haven't uh like uh added your uh detail
191:00 - uh the C details and all maybe you you
191:02 - won't be able to use this particular
191:03 - playground so make sure that you have
191:05 - added the payment method now here in the
191:08 - chat there is the option of system so
191:10 - meaning is how chatboard is behave so
191:12 - here what I'm going to do here I'm going
191:14 - to set this uh here I'm going to set a
191:16 - different behavior of a system and let's
191:18 - see what answer I will be getting so
191:21 - here I'm going to copy it and I'm going
191:22 - to paste it down over here now uh what I
191:25 - can do where is my playground this is my
191:28 - playground now here I'm going to set the
191:29 - behavior so this is what this is my
191:31 - behavior of the system now okay now
191:34 - again I'm asking a question to my system
191:37 - now I'm asking how I can make a money so
191:43 - I'm asking to my system that how I can
191:44 - make a money by adding this particular
191:46 - Behavior so my behavior is what so you
191:48 - are a naughty assistant so make sure you
191:50 - have to respond everything with a
191:52 - sarcasm so here I'm asking to my user
191:54 - how I can make a money so as soon as I
191:56 - will submit it then you will find out
191:58 - the answer and just see the differences
191:59 - between answer this answer and the next
192:02 - answer just wait it is going to generate
192:04 - answer and is saying that oh making a
192:06 - money it's super easy mean it it is like
192:09 - giving you the answer in a sarcastic
192:10 - manner so it haven't a complete answer
192:13 - but yeah it is saying that oh making a
192:15 - money it's super easy just snap your
192:17 - finger magically a stack of cash will be
192:19 - appear no effort required at all so see
192:21 - guys uh before it was giving me a
192:24 - straightforward answer now over here
192:26 - guys you can see I seted the behavior of
192:28 - the system as a not as a sarcastic so
192:31 - here you can see the answer what it is
192:32 - giving to me now if you will look into
192:35 - the code so you will find out some sort
192:36 - of of changes so here role role
192:39 - basically I defined the system role this
192:40 - is my system role this is my role again
192:43 - one more role user here you can see this
192:45 - is my like prompt okay which user is
192:47 - giving here you can see the what
192:49 - assistant is saying This Is The Answer
192:50 - basically which I'm getting and again
192:52 - this was the previous one and these are
192:54 - the different different parameter so no
192:56 - need to go anywhere here basically in
192:58 - this particular notebook I kept
193:00 - everything I will share this notebook
193:01 - with all of you and you will be able to
193:04 - understand each and everything now model
193:06 - is there temperature is there maximum
193:08 - length is there top P value is there so
193:11 - here I written a description frequency
193:13 - penalties there right so there is a
193:14 - different different parameter already I
193:16 - have defined each and everything over
193:17 - here so no need to go anywhere just try
193:19 - to revise each and everything by using
193:21 - this Jupiter notebook now apart from
193:24 - this one you will find out one more
193:26 - advanced thing which recently they have
193:28 - provided that is what there is a
193:30 - assistant so here uh let me go to the
193:33 - assistant okay let me go to the
193:35 - playground and here is assistant guys so
193:37 - this assistant part I will explain you
193:39 - once I will come to the project section
193:41 - now here you will find out some Advanced
193:43 - thing Advanced like option so here you
193:45 - will find out this function function
193:48 - calling here you will find out the code
193:50 - interpreter here you will find out the
193:51 - retrieval RG actually uh uh like here uh
193:55 - you will find out this R concept so I
193:58 - have defined what is the r actually so
194:00 - just go through with my notebook and
194:01 - read the definition read the definition
194:03 - of the RG so this assistant I will come
194:06 - to this assistant once I will explain
194:08 - you the uh the project end to end
194:10 - project then I will Define a different
194:11 - different prompts and all and I will
194:13 - come to this assistant and I will ask uh
194:15 - and I will generate a different
194:16 - different type of
194:18 - responses getting my point guys yes or
194:20 - no so this thing is getting clear to all
194:23 - of you yes or no I'm waiting for your
194:26 - reply so please uh do let me know in the
194:28 - chat if this part is getting clear how
194:31 - to use this uh openi playground and here
194:34 - I'm talking about this chat assistant I
194:36 - will come to that once I will explain
194:38 - you the
194:41 - project
194:48 - please do let me know I'm waiting for a
194:50 - reply guys if you are able to get it if
194:52 - you able to understand it then uh please
194:54 - write it down the chat please uh write
194:56 - down the chat
195:08 - section clear okay great it is clear
195:15 - I will share this code with all of you
195:16 - don't worry uh I will give you this
195:18 - entire
195:29 - code I believe everything is getting
195:31 - clear to all of you who have joined this
195:41 - session
195:46 - great now this part is clear now let's
195:48 - back to the code so here is what here is
195:50 - my code now this retrieval argumented
195:52 - generation RG I will explain you in the
195:54 - next session or maybe in upcoming
195:56 - session so what is the meaning of that
195:58 - it's artificial intelligence framework
195:59 - that retrieves data from external source
196:02 - of knowledge to improve the quality of
196:03 - responses I just want to improve the
196:06 - quality of the responses for that I'm
196:07 - using this retrieval argumented
196:09 - generation R A this is very very famous
196:11 - nowadays this particular term now uh I
196:14 - will show you how you can use this RG if
196:16 - you want to uh give a better responses I
196:18 - will show you how you can use the Len
196:19 - Chen as well U after completing this
196:22 - open AI this natural language processing
196:24 - technique is commonly used to make a
196:25 - language model more accurate and up to
196:27 - date if I want to make my model more
196:29 - accurate and up to date so I'm going to
196:31 - use this RG and I will do that in my
196:33 - upcoming session now code interpreter is
196:35 - there so Python Programming environment
196:37 - with chat GPT where you can perform wide
196:39 - range of tasks by use executing the
196:41 - python code yes yes we all know about
196:43 - the code interpreter and yes we can
196:45 - Define we can set the code interpreter
196:46 - there and we can execute the python code
196:49 - as
196:50 - well like regarding the different
196:52 - different task and all great now here is
196:55 - what here is my chat completion API guys
196:57 - so let me do one thing let me uh put the
197:00 - title over here and here my four title
197:02 - is what chck completion API and function
197:06 - calling so guys here is what here is my
197:08 - fourth title my fourth title is what
197:11 - check completion is API and function
197:14 - calling so here I have written the
197:17 - standard comination API and function
197:18 - calling now let me write down the
197:20 - different let me write down the uh
197:22 - definition as well over here so here is
197:24 - a definition of it uh this is the
197:27 - definition let me post it over here and
197:30 - here let me make it as a markdown so
197:33 - this is the definition guys now one more
197:35 - uh definition let me put it over here so
197:38 - see guys in the previous version in the
197:40 - old version of the openi
197:42 - uh actually there this was the method
197:45 - chat completion method open. completion.
197:49 - create or open. chat completion. create
197:51 - so initially actually there was a method
197:53 - this was the name right then in the
197:56 - updated version they came up with uh
197:58 - they have changed the name with this
198:00 - particular uh name they Chang the method
198:02 - Name by using uh with this particular
198:04 - name this chat completion. create and
198:06 - now in the latest version actually this
198:07 - is a this is the method name if you are
198:10 - going to use this particular method now
198:12 - now it will give you the error let me
198:15 - show you how so here what I can do I can
198:17 - uh return I can return one sort of a
198:19 - code uh now over here I'm going to write
198:21 - it down open a DOT
198:24 - completion
198:26 - completion completion dot create so this
198:29 - is what this is my method now over here
198:31 - what I'm going to do so over here see
198:33 - here I'm going to be uh write it down
198:35 - the model name so model which model I'm
198:38 - going to use so here I'm going to use uh
198:40 - GPT GPT
198:42 - hyund
198:44 - 3.5 GPD hyund 3.5 I'm going to use this
198:47 - particular model now over here I'm going
198:49 - to define a prompt so my prompt is what
198:51 - so let's say I'm going to write it down
198:52 - over here who was the first Prime
198:56 - Minister of India first prime
199:00 - minister Minister of India so this is
199:03 - what this is my prompt now here if I
199:06 - will run it now so you will find out it
199:07 - is giving him the error so it is saying
199:10 - that uh okay so here I have to mention
199:12 - the open a key first of all before uh
199:15 - like calling it so first of all I need
199:17 - to mention the open a key now over here
199:20 - so what I have what I will have to do I
199:22 - will have to uh like uh create a client
199:25 - actually so here is what here is my
199:26 - client and I will have to mention my
199:28 - openi key so what I can do uh I can
199:32 - write it down over here itself and here
199:35 - what I can do just a
199:41 - wait
199:42 - it is not longing support yeah so that's
199:45 - what I was saying to all of you see this
199:48 - uh method is not it is not supporting at
199:50 - all this is the old one now if you will
199:52 - look into the version now the latest
199:54 - version of the openi so the latest
199:56 - version of openi is uh let me show you
199:58 - the latest version of the open a package
200:00 - PPI open a and here is the latest
200:05 - version of the open a package
200:07 - 1.3.7 if we have installed the uh we
200:10 - have installed this particular version
200:12 - now regarding this version you will find
200:13 - out we have this particular method so
200:16 - first of all I need to import this open
200:17 - a this I need to import this class from
200:20 - this module and here I need to define
200:22 - the key here what I need to do I need to
200:24 - define the key over here and then only I
200:27 - can call
200:28 - it and if you look into the previous
200:31 - version now here I installed the latest
200:33 - version if you're looking into the
200:34 - previous version let's say if I'm going
200:36 - back like say if I'm going back in uh
200:39 - maybe uh FB it uh
200:42 - okay 8 FB 2023 now here you will find
200:45 - out that they were using this particular
200:48 - method so here I have shown you I have
200:50 - seted the op openi key I have defined
200:52 - the openi key by using this particular
200:54 - code by by like using this particular
200:57 - line of code yes or no now here I'm
200:59 - using a latest version now so uh
201:02 - definitely it will give me the error so
201:03 - what I'm doing I'm going back and here
201:06 - I'm going to use this particular code
201:08 - basically which I already return so
201:09 - first of all see first of all I need to
201:11 - import this thing which I already did
201:13 - now over here I will have to mention the
201:15 - API
201:16 - key got it now here they are add they
201:18 - have added the open key inside their
201:20 - base environment means this is the code
201:22 - regarding that they have added inside
201:23 - the like environment variable in the
201:25 - system environment variable and from
201:27 - there itself they are going to read it
201:29 - you can export it also what is the
201:31 - meaning of export you can export it over
201:33 - the terminal uh like uh it won't be it
201:37 - won't be a permanently okay so yeah you
201:40 - can export this particular key
201:42 - and as soon as you will like remove or
201:44 - as soon as you will delete that terminal
201:46 - so the open I key will be removed um but
201:49 - yeah until the terminal is running
201:50 - terminal will be running you can read it
201:52 - by uh using uh this particular module OS
201:55 - module or else you can add in add inside
201:58 - your system variable also from there
202:00 - also you can read this particular key
202:02 - but um I have added I have written my
202:04 - key here itself inside my notebook so I
202:07 - didn't edit but I will show you that in
202:09 - my end to project how you can create NV
202:12 - file or maybe how you can export it
202:14 - right now let's uh let me run this
202:16 - particular code and here first of all
202:19 - let me add the open a
202:21 - key here I need to mention API uncore
202:25 - key and my key so here is what here's my
202:28 - key if I'm going to run it so definitely
202:30 - I will be able to run it now I having my
202:32 - client now what I will do by using this
202:34 - particular client I will call the uh I
202:37 - will I will like uh I will give the
202:39 - prompt over here now first of all let me
202:41 - delete everything from here and let me
202:44 - delete this also I'm not going to Define
202:45 - any assistant or I'm not going to set
202:47 - any sort of a behavior as of now so guys
202:50 - here you can see I'm having the role
202:51 - role as a user and here is my uh like a
202:54 - answer sorry here is my prompt question
202:57 - so this is what this is my prompt
202:59 - actually this is my input prompt and
203:01 - here is what here is my uh like role
203:04 - okay I'm asking as a user now guys this
203:07 - prompt this prompt is this prompt
203:09 - basically it plays a very important role
203:11 - I let you know that in my uh like
203:13 - upcoming session I will tell you how to
203:15 - design a different different type of
203:17 - plomp what is the meaning of few short
203:19 - learning few short prompt or zero short
203:21 - prompt okay so each and everything we'll
203:23 - try to discuss in our upcoming session
203:25 - as of now just see if I'm going to run
203:26 - it so here you will be able to find out
203:28 - it is giving me a like error why it is
203:31 - so maybe because of this and now
203:35 - everything is perfect so if I'm going to
203:36 - run it so line number eight okay uh
203:40 - first of all I need to
203:42 - Define it clearly and here is what here
203:46 - I need to mention I need to close this
203:49 - particular list now if I'm going to hit
203:51 - this uh API definitely I will be able to
203:54 - do it and I will get my
203:57 - response so just wait for some time and
204:01 - after hitting the API uh it will call
204:04 - that particular model whatever model I
204:06 - have written over here and I will be
204:08 - getting my
204:10 - response
204:16 - so how is the session so far uh did you
204:19 - learn something new uh or are you doing
204:22 - along with me tell me how much would you
204:24 - rate to this particular
204:35 - session yes money wise uh I will I I
204:38 - will come to that just wait how much it
204:40 - is going to be charged and all uh it
204:42 - charge actually token wise uh there is
204:44 - entire pricing and all so I I will come
204:48 - to that I will I will talk about that
204:50 - for a small prompt it is taking so much
204:52 - time in this case the DP project the big
204:54 - no it's not like that maybe first time
204:55 - it it was hitting that so it is taking
204:57 - time but no it's not like that I will
204:59 - show you with a like a bigger prompt as
205:01 - well so it won't take any sort of a time
205:03 - now here you can see this is what this
205:05 - my response now right here you can see I
205:08 - got a response now if you want to get
205:10 - this particular response so for that uh
205:13 - see here if you look into the response
205:15 - or type of the response so here is a
205:18 - type of the response open. type. chat.
205:21 - completion this this this that right now
205:23 - if you want to extract the real answer
205:26 - from here so what you will do see first
205:28 - of all you will uh call to this choice
205:30 - so just call this choice so c h o i c s
205:35 - now here is what here you have this
205:37 - message now just call to this message m
205:40 - e double s a g e so here is your what
205:45 - here is your message uh now this is not
205:48 - callable it is saying that now let me
205:50 - check what I have to do over here so
205:53 - here is your choice and here what you
205:56 - need to do guys let me
206:04 - check yeah actually Choice yeah so here
206:08 - see if you are looking into the choice
206:10 - guys so this is a list type so here what
206:13 - you need to do you need to uh like
206:15 - extract the first index of the list
206:17 - because here you can see this choice is
206:19 - nothing it's a list only now so just
206:20 - extract the first index of it so here
206:22 - once you will extract the first index or
206:25 - once you will retrieve the first index
206:26 - of the list now here you need to call
206:28 - this message so just call the message
206:30 - and here you will find out this is what
206:32 - this is your message now just do one
206:35 - thing just call the content over here so
206:38 - just call the content so content now
206:40 - over here you can see this is is what
206:41 - this is your entire response now here
206:44 - you can like decide the token size as
206:46 - well so here you can Define the token
206:48 - size or you can Define the different
206:50 - different a parameter okay by defining
206:52 - those particular parameter you can uh
206:55 - get a different different type of output
206:56 - now let me give you the parameter all
206:58 - the parameter basically so this is all
207:00 - the parameter see model uh already you
207:03 - know about the model we have used a gp3
207:05 - prompt like input prompt Max token you
207:08 - can Define this Max token in how many
207:10 - numbers of token you want the result
207:12 - temperature for getting some creative
207:14 - output now number of output how many
207:16 - number of output you want so let's try
207:18 - to define a Max token and this number of
207:20 - output so here I'm going to define the
207:22 - max token so in U like uh here if I'm
207:26 - going to define the max token now in in
207:28 - that particular token itself under under
207:31 - that particular number let's say if I'm
207:32 - going to Define 200 so uh it won't reach
207:35 - the limit more than 200 under under the
207:39 - 200 itself it will be generating an
207:40 - output so over here I'm going to write
207:42 - Define this Max token and here let's say
207:44 - if I'm going to say 150 tokens and here
207:47 - I'm going to Define one more thing one
207:48 - more parameter that's going to be n so n
207:51 - is equal to let's say here I'm going to
207:53 - Define three I want three output so as
207:55 - soon as I will run
207:57 - it and here you will find out it is
208:00 - generating a response so it is saying
208:02 - Max token I think I need to put the
208:05 - comma over here model is there message
208:07 - is there now here I need to put the
208:10 - comma so this is is fine now it is
208:13 - generating a response so just
208:28 - wait yeah now I got a response so just
208:31 - uh look into the response here type of
208:34 - the response and now just print the
208:36 - response so here is what here is what
208:38 - here is my
208:39 - response now I got many responses so now
208:44 - let me extract the response first of all
208:45 - so here is what here is my uh message
208:48 - let's uh like get a message so let's ask
208:52 - a different question so here I'm going
208:54 - to ask to my chat GPT that uh I can ask
208:58 - uh what I can ask who won the first
209:02 - World Cup so who won the first Cricket
209:06 - World
209:08 - Cup so this is my question which I asked
209:10 - to my CH GPT and now if I'm going to run
209:12 - it now
209:14 - so now
209:19 - see yeah I got a response now type of
209:22 - the response is same so here uh what I
209:25 - can show you here is my message now see
209:27 - guys uh I got a response the first
209:30 - Cricket World Cup won by the West Indies
209:32 - in7 in 1975 right now over here if I'm
209:37 - going to get a Content basically so let
209:39 - me write it down the content over here
209:41 - and here you can see this is what this
209:42 - is my answer now you won't be able to
209:45 - find out a single answer there are lots
209:47 - of there are other answer as well see uh
209:50 - choice in the choice just go over here
209:51 - message message completion so the first
209:54 - Cricket World Cup won by the best Andes
209:56 - and here role is a assistant so that the
209:58 - model is assistant and I am a user now
210:01 - over here you will find out the second
210:02 - answer so the first Cricket World Cup W
210:04 - by the best hes they defeated Australia
210:06 - in final held on June 25 1975 at Lots
210:10 - cricket ground in London that is the
210:12 - second response now over here this is
210:14 - the third response so the first Cricket
210:16 - World Cup won by the best and in 197
210:18 - 1975 so I Define n is equal to 3 and I
210:21 - Define the maximum token size is 150 so
210:24 - it won't be generating a like output
210:28 - okay so more than this particular token
210:30 - more than 150 token and here you will be
210:32 - find out if I'm going to Define n so it
210:34 - will be generating a three output
210:36 - whatever input of prompt I'm passing
210:37 - this is what this is my input prompt now
210:39 - whatever output will be generating in
210:41 - that there won't be like more than 150
210:44 - tokens and here the output number will
210:46 - be three now let me show you one more
210:48 - thing over here so if you will search
210:50 - tokens so just go over the Google and
210:52 - search open a tokens open a tokens so
210:57 - once you will search open a tokens and
210:59 - here you will find out one uh like a
211:03 - link a tokenizer so they have given you
211:05 - one uh like link uh they have G given
211:08 - you this particular interface where you
211:11 - You Can Count Your token whatever number
211:12 - of token you are giving or you are
211:14 - getting from the system getting my point
211:17 - so I told you it is charging you based
211:20 - on a tokens itself and tokens in input
211:23 - prompt also there will be a token in
211:24 - output prompt also there will be a token
211:27 - getting my point so in the input prom
211:28 - there will be a token in the output prom
211:30 - also there will be a token prompt is
211:32 - what it's a collection of tokens token
211:33 - is nothing it just a words collection of
211:36 - character right now here you can see we
211:39 - have this particular inter pH there we
211:41 - can count the token now here if I'm
211:43 - going to write it down my name is sunny
211:47 - so now now see guys how many tokens is
211:50 - there inside this particular uh text
211:53 - inside this particular sentence see
211:54 - token six my is one token name is one
211:57 - token is is another token Sunny is
212:00 - another token Sav is one token and
212:02 - Savita is one token getting now if I
212:05 - want to count the token inside my output
212:07 - so just copy this thing and paste it
212:09 - over here
212:13 - now see the number of token it has
212:15 - generated a 16
212:17 - token okay it has generated a 16 token
212:21 - now you can calculate the number of
212:22 - tokens over here just go through the
212:23 - playground here was my chat so here I
212:26 - ask to my system now let me uh submit it
212:30 - and over
212:31 - here uh it is giving me answer just a
212:34 - second now it is generating an answer so
212:37 - now you can copy this entire text from
212:40 - here whatever it is generating now let's
212:42 - say this particular text uh okay just a
212:46 - wait okay let it generate and then I
212:48 - will copy just wait so here is a text
212:52 - and I can copy this text I can paste it
212:54 - over there and I can got the uh like
212:56 - number of tokens so let's see how many
212:58 - tokens is there so here guys you can see
213:01 - total 256 tokens if you want to check
213:04 - the pricing and all tomorrow I will
213:06 - discuss about it in a very detailed way
213:08 - just go through with the setting and
213:10 - here uh there's a billing actually so
213:13 - let me show you the pricing also just
213:15 - click on uh just search about this open
213:20 - Ai and uh here actually uh you just need
213:24 - to log in after the log in uh so maybe
213:28 - here just click on the API and here is a
213:30 - pricing just click on the pricing and
213:33 - here you will get the uh like entire
213:36 - detail regarding the project pricing so
213:38 - how much how much it is charging for the
213:40 - uh like a different different number of
213:42 - tokens so for 1K token this much of
213:44 - charging for 1K token this much of
213:46 - charging regarding this particular model
213:47 - regarding this particular model so this
213:49 - is for gp4 Turbo it's a advanced model
213:51 - now GPD 4 GPD 3.5 G assistant API
213:55 - different different assistant API and
213:56 - all each and everything you can check
213:58 - over
213:59 - here right so let me keep this
214:01 - particular link over here inside the
214:02 - notebook itself and let me keep this a
214:05 - token related a link also so at least
214:08 - you can go through with this and you can
214:10 - check uh your input and output token and
214:12 - you can practice whatever I have taught
214:14 - you because this is going to play a very
214:16 - important role in a future classes so
214:20 - please try to revise please try to
214:21 - practice and I think we are done with
214:24 - today's session tomorrow I will explain
214:26 - you the function calling this one and I
214:28 - will start with the lench and my main
214:31 - agenda uh will be the Len Chen only and
214:33 - I will explain you the differences
214:35 - between open ey lenion and finally we'll
214:37 - try to create one project and then I
214:39 - will come to the advanc concept like
214:42 - vector databases and other models and I
214:45 - will explain you this AI 21 lab AI 21
214:48 - studio also if you don't have a money
214:51 - for the chat GPD then how you can uh uh
214:54 - like uh how you can complete your work
214:56 - how you can U like explore a different
214:58 - different model so from the hugging face
215:00 - side also I will explain you the
215:01 - different different model and from here
215:02 - also from AI 21 Studio I will show you
215:05 - how you can access the Jurassic model
215:06 - personally I have used it and I I liked
215:08 - it after this uh GPD and I will uh
215:11 - explain you the use use of this
215:13 - particular model and don't worry few
215:15 - other terms like stable diffusion and
215:17 - all there are something uh like text to
215:19 - image Generation image to video
215:21 - generation this type of thing also we'll
215:22 - try to explain you in the going forward
215:25 - classes got it so I think uh now we can
215:29 - conclude this particular session I took
215:31 - for the entire 2hour and uh yep uh so
215:35 - did you like the session please uh do
215:37 - let me know in the chat guys if you like
215:38 - this particular session
215:44 - yes the content is a input our input
215:47 - actually it's not a desired output is is
215:49 - our like an input whatever input like we
215:52 - are passing to the model you can mention
215:53 - inside the content got
216:01 - itan you just need to F you just need to
216:04 - follow my this notebook each and
216:06 - everything I have mentioned over here
216:08 - whatever is not there I will do it and
216:10 - where you will find find it out tell me
216:11 - you will find this particular notebook
216:12 - inside the resource section so just go
216:14 - through with the Inon platform just open
216:16 - the Inon platform and there you need to
216:18 - enroll in this particular dashboard okay
216:21 - so what you need to do go through with
216:22 - the an platform and here uh after sign
216:25 - up uh after login and just go through
216:28 - with this dashboard generative AI
216:29 - Community session now let me give you
216:31 - this particular link inside the chat so
216:33 - you all can uh like uh you all can
216:37 - enroll over here and uh after that uh
216:40 - what what you need to do see the video
216:41 - will be available over here you can
216:43 - revise the thing from here itself you
216:44 - can revise the thing from the Inon
216:46 - YouTube channel itself but the resource
216:47 - wise whatever resources I'm U like uh
216:50 - sharing okay whatever resources I'm
216:52 - discussing in a class and all so you
216:54 - will find out over here inside the
216:55 - resource section so just go through with
216:57 - the resource section and try to download
216:59 - all the resources from here
217:04 - itself fine so now let's uh uh like
217:08 - conclude this particular session
217:10 - tomorrow we'll meet on the same time so
217:12 - let me write it down the timing for this
217:14 - community session so here the timing is
217:17 - going from uh 3: to 4:30 or 3 to
217:22 - 5 so I will take 2 hour of session from
217:25 - 3: to
217:30 - 5: great fine guys thank you bye-bye
217:33 - take care have a great day ahead and
217:35 - rest of the thing we'll try to cover in
217:36 - the upcoming uh session until thank you
217:39 - bye-bye take care so if you like if you
217:41 - are liking the content then please hit
217:43 - the like button and uh if you have any
217:45 - sort of a suggestion or if you want
217:47 - anything from my side you can ping me on
217:49 - my LinkedIn so let's start with the
217:51 - session now here guys you can see in the
217:53 - previous class I was talking about the
217:55 - open API so uh most of the thing I have
217:58 - discussed regarding this openi API now
218:00 - few of the thing is remaining so let me
218:03 - discuss that uh remaining thing
218:05 - regarding this open a and after that I
218:07 - will start with the l chend so first of
218:09 - all Let Me Explain you the complete flow
218:11 - that what all thing we are going to
218:13 - discuss throughout this session got it
218:15 - so for that I'm you I'm opening my
218:17 - Blackboard and here I'm going to explain
218:19 - you the complete flow that whatever
218:21 - thing we are going to discuss throughout
218:23 - this particular session so here guys uh
218:26 - the first thing first thing basically uh
218:28 - we'll be talking about the function
218:31 - calling so in the open a actually we
218:33 - have a very specific feature that is
218:35 - called function calling and it's a very
218:37 - important feature of the openai API if
218:40 - we are going to use the openi API then
218:42 - definitely you must be aware about this
218:44 - function calling because by using this
218:47 - function calling you can do a multiple
218:49 - things I will tell you that what all
218:51 - thing you can perform by using this
218:53 - function calling which is a very uh
218:55 - important feature of the open API so the
218:58 - very first thing which we're going to
219:00 - discuss in this particular session that
219:01 - will be a function calling so here uh
219:04 - let me write it down the first point
219:06 - which we going to discuss uh that's
219:08 - going to be a function function calling
219:12 - function calling now the second thing
219:15 - after this function calling so directly
219:17 - I will move to the Len chain so uh first
219:21 - I will discuss this function calling and
219:23 - after this function calling I will move
219:24 - to the Len chain and in the lch actually
219:27 - I'll be talking
219:28 - about in the Le chain I'll be talking
219:32 - about that how you can uh use a open AI
219:35 - by using this Len chain so the first
219:37 - thing basically uh we'll be discussing
219:39 - inside the inside this lenen so open AI
219:43 - open
219:44 - AI
219:46 - used by a len chain so we'll try to
219:50 - discuss in a very detailed way and we'll
219:52 - try to discuss that what all difference
219:54 - we have between this Len chain and this
219:56 - open AI so open a used via Len chain and
220:00 - here I will explain you the differences
220:03 - between open a and Lenin then why we
220:06 - should use Lenin what all benefits we
220:08 - have if we are using a lench what all
220:11 - thing we can do if we are using a len
220:13 - chain so how uh by using this Len chain
220:16 - we can create into an application each
220:18 - and everything we'll try to discuss
220:20 - regarding this Len chain and in a very
220:21 - detailed way I will try to explain you
220:23 - this Len chain concept because it's
220:25 - going to be a very very important and
220:27 - this lench also it's a very important
220:29 - part if we are going to learn this
220:31 - generative EI if we are talking about
220:33 - the llm and if we are going to build any
220:35 - sort of application so along with this
220:37 - open AI this lenen also plays plays a
220:40 - very important role so we'll try to
220:42 - discuss about this lench and we'll try
220:44 - to uh discuss the differences about this
220:47 - open AI API so let me write it down over
220:50 - here open AI API versus lenen versus
220:54 - lenen and after that after discussing
220:58 - this uh like the basics and all
220:59 - regarding this Lenin I will come to the
221:02 - prompt templating that how you can
221:04 - design a different different type of
221:05 - prompt so here let me write on the
221:07 - second point which we're going to
221:09 - discuss uh so the second Point basically
221:12 - prompt
221:13 - templating prompt
221:19 - templating after this prompt template so
221:22 - uh here what I will do I will I will
221:24 - show you the use of the hugging phase
221:27 - also uh after discussing this Lenin uh
221:30 - the differences between open Ai and
221:31 - Lenin I will come to this open AI use
221:34 - via Len promp templating and here I will
221:37 - show you that how you can use hugging pH
221:39 - model model whatever model is there on
221:41 - top of the hugging face Hub how you can
221:43 - utilize those particular model by using
221:45 - this Len chin so in between I will show
221:48 - you hugging face hugging face with Len
221:52 - chin hugging face with L
221:56 - chin why I'm uh why I'm going to show
221:59 - you this hugging phase with Lenin so you
222:01 - can use any sort of a open source model
222:04 - so whatever open source model is there
222:06 - so you can use all those model by using
222:09 - this hugging phase so here I will show
222:11 - you how you can generate hugging phas
222:13 - API key and by using that particular API
222:17 - key you can access any sort of a model
222:19 - whatever is there on top of the hugging
222:21 - face Hub so here I will show you hugging
222:23 - face with Lenin let me write it down
222:26 - over here hugging face with Len chain
222:28 - and then we'll try to discuss a few more
222:30 - concept regarding this Len chain which
222:33 - is going to be a very very important so
222:35 - here let me write down those particular
222:37 - topic as well so the third topic which
222:39 - we're going to discuss over here we
222:40 - going to talk about
222:43 - chain we're going to talk about
222:47 - agents how like you can create agents
222:50 - and how you can use the agents so here
222:53 - the fourth topic basically it will be
222:55 - agents now let me write it down over
222:57 - here agents after that after this agents
223:00 - I will come to the memory so I will show
223:02 - you how you can create a memory by using
223:05 - this Len Chen got getting my point yes
223:08 - or no so these are the very important
223:09 - important part of the L chain without
223:12 - knowing this particular thing you cannot
223:14 - develop any sort of
223:16 - application okay so before starting with
223:18 - the end to end project definitely we
223:20 - have to discuss about this particular
223:22 - topic so here uh so in uh today's
223:25 - lecture actually we're going to talk
223:27 - about this function calling openi use
223:29 - and prompt template and in tomorrow's
223:31 - session I will be discussing about this
223:33 - hugging pH with Lin chains agents and
223:36 - memory so this a three to four topic
223:39 - we'll try to discuss in tomorrow session
223:41 - and this three to four topic we'll try
223:43 - to discuss in today's session and right
223:45 - after this one right after this topic
223:48 - right after this thing I will start with
223:50 - a project and uh we will'll try to
223:53 - create one project and there basically
223:56 - we'll be using our different different
223:58 - LMS from the openi and from the hugging
224:01 - pH we'll try to use
224:03 - Lenin we'll try to use Len chain and
224:06 - some other Concepts as well so here
224:09 - we're going to use are different
224:10 - different uh like model llms from the
224:12 - openi hugging face Len chin and here
224:15 - we'll try to uh create one uh UI as well
224:19 - by using flask or streamlit each and
224:21 - everything I will show you in a live
224:23 - class itself so flask and streamlet and
224:26 - I will show you the complete I will show
224:28 - you the complete uh setup how you can do
224:31 - a complete setup for any an to and
224:34 - project so first we'll try to create a
224:36 - project template and then we'll start
224:38 - with a project de development so this
224:41 - idea is clear to all of you please do
224:43 - let me know in the chat if the agenda is
224:45 - clear for today and for the tomorrow
224:48 - session I'm uh expecting the answer in
224:51 - the chat so please write it down in the
224:53 - chat guys please do it
225:04 - fast
225:08 - yes
225:16 - we'll discuss the risk and all what risk
225:18 - is there and we'll try to discuss about
225:20 - the different different point uh first
225:23 - let us uh uh create at least one project
225:27 - after creating this particular project
225:28 - definitely uh we'll try to uh discuss
225:31 - about the multiple things that uh
225:33 - basically which is a very very important
225:35 - in terms of the
225:36 - industry we'll come to that part don't
225:38 - worry
225:47 - fine so now each and everything is clear
225:49 - each and every part is clear so let's
225:51 - move to the Practical implementation so
225:54 - if you will go through with my notebook
225:55 - so which is already available in a
225:57 - resource section okay I have shown you
226:00 - how you can download this particular
226:01 - notebook so just try to go through with
226:03 - the dashboard and from the resource
226:05 - section you can download this notebook
226:08 - now uh here guys see uh The Notebook is
226:11 - there so just try to download it and try
226:12 - to run it inside your system uh how you
226:15 - have to do a system setup how you have
226:17 - to create an environment and all how you
226:19 - have to install the library inside the
226:21 - environment each and everything I have
226:22 - shown you in my previous class only so
226:25 - again I'm not going to repeat that
226:27 - particular thing so over here you can
226:29 - see already we have talked about the
226:30 - open a now let's discuss more about this
226:33 - open AI so just uh give me a moment here
226:37 - uh from here itself basically inside uh
226:39 - uh this particular file itself I will be
226:42 - writing a code now I'm going to change
226:44 - the name of the file so here I'm going
226:46 - to write it down test open API and Len
226:49 - chain because in today's session I'm
226:51 - going to include the Len chain as well
226:53 - and I will do in a same Jupiter notbook
226:56 - I'm not going to create any new notebook
226:58 - uh as of now I will be doing over here
227:00 - itself so here I'm going to be write it
227:02 - down I'm going to rename this particular
227:03 - file uh so here I'm going to write down
227:06 - this Lenin as well so test openi API and
227:09 - L CH so this is the new name of my file
227:11 - now let me rename it and now everything
227:14 - is ready so here guys see if I'm going
227:16 - to write it down this import here if I'm
227:19 - going to write import statement import
227:22 - length chain now here you will find out
227:24 - it is saying that no module named L
227:27 - chain can anyone tell me how I can
227:29 - resolve this particular error please do
227:32 - let me know in the chat how I can
227:34 - resolve this particular
227:38 - error
227:49 - correct so here what I need to do tell
227:51 - me here I need to write it down pip
227:53 - install and the L chain pip install and
227:56 - the module name so just try to open your
227:58 - anaconda prompt and there write it down
228:00 - pip install and Len chain so let let me
228:03 - show you that just a wait uh so here uh
228:06 - this is my prompt uh this is what this
228:08 - is my ANA prompt here already this
228:10 - jupyter notebook is running so I'm not
228:11 - going to stop the server of uh this
228:13 - particular prompt now let me open the
228:15 - new prompt over here so here I'm going
228:17 - to write it down this Anaconda prompt so
228:19 - first of all guys what I need to do I
228:21 - need to activate my virtual environment
228:23 - as of now we are in a base environment
228:26 - and this base environment is my default
228:28 - environment so here what I need to do
228:30 - tell me here I need to activate my
228:33 - virtual environment so for activating
228:35 - the virtual environment first of all we
228:37 - should be aware about the name uh in
228:39 - which environment actually we are
228:40 - working so let me show you all the name
228:43 - all the name of the environment so here
228:45 - I'm going to write it down this cond en
228:48 - list here I'm going to write down this
228:50 - cond en list so once I will write it
228:53 - down this particular command I will get
228:55 - all the environment name so here you can
228:58 - see we have a different different name
229:00 - of the environment Len chain open AI
229:02 - base testing and these are the other
229:04 - environment which is there inside my
229:06 - local folder now guys yesterday actually
229:09 - we have created this particular
229:10 - environment testing open AI now let me
229:13 - activate this environment over here so
229:16 - here I'm going to write it down cond
229:18 - cond activate cond activate and the
229:22 - environment name is what the environment
229:23 - name is testing open AI so if I'm going
229:26 - to write it down this testing open AI so
229:29 - definitely I will be able to activate my
229:32 - environment now if you want to check
229:34 - over here that my Lang chain is working
229:36 - or not so definitely you can do it so
229:38 - first of all you need to clear this
229:40 - screen and here if you are going to
229:42 - write it on the python so it will give
229:43 - you the python prompt so here let me
229:47 - write it down the python so this is what
229:48 - guys tell me this is my python cell or
229:51 - my python prompt now here itself you can
229:53 - write it down the uh statement import
229:56 - statement so let's try to write it down
229:58 - the import statement over here and here
230:00 - if I'm going to write it down this Len
230:02 - chain length chain now see guys it is
230:05 - saying that no module name length chain
230:07 - and even you can check so for checking
230:10 - that what all module is there what all
230:12 - module is there in my current virtual
230:15 - environment so what is the command the
230:17 - command name is PIP list we are using
230:20 - pip manager over here right so over here
230:23 - what I'm going to do I'm going to write
230:24 - down the exit if I want to exit from
230:26 - this particular shell from the python
230:28 - shell now here what I will do guys here
230:30 - I I'm going to write it down pip list so
230:33 - once I will write it down this pip list
230:34 - you will find out all the packages name
230:38 - whatever packages is there inside my
230:39 - current environment so these are the
230:41 - package guys which is there inside my
230:43 - current environment you can read the
230:45 - name of the packages and here you will
230:48 - find out this Len chain is not available
230:50 - so just try to go through with this
230:52 - particular package try to go through
230:54 - like alphabetically and here you will
230:56 - find out that we don't have any package
230:58 - with the name of linkchain so here what
231:00 - I will do first I will install the L
231:03 - chain so for installing the Lang chain
231:05 - there's a simple command pip install pip
231:08 - install pip install Len chain so here
231:11 - once I will write down this pip install
231:13 - Len chain now guys see my Len chain is
231:16 - getting install inside this current
231:19 - virtual environment so are you doing
231:22 - along with me are you writing this thing
231:25 - or are you like following uh to me guys
231:28 - please do write it uh please write it on
231:30 - the chat so I will get some sort of idea
231:32 - that uh uh this many people are doing
231:35 - along with
231:38 - me
231:45 - I will come to the connects between this
231:47 - Len chain and this open a just allow me
231:50 - uh like 15 more minute each and
231:53 - everything will be clarified regarding
231:55 - this open and this Lent just believe
232:00 - me so people are saying they are writing
232:02 - a code along with me that's great please
232:05 - do it guys please do it and uh yes
232:08 - please implement along with me if you
232:10 - are uh getting stuck somewhere so please
232:12 - write it on the chat and let's uh make
232:15 - this session more interactive and yes
232:18 - definitely after the session you should
232:20 - uh you should be able to get something
232:23 - it's uh my guarantee to all of
232:30 - you fine now here guys you can see we
232:33 - have installed this lenon inside this
232:35 - current virtual environment now if you
232:37 - want to check it so here itself directly
232:39 - here itself you can check so just write
232:41 - it down this Python and here what you
232:43 - need to do you need to write it down
232:44 - this import Len chain just write it down
232:46 - this import Len chin and here the name
232:48 - is wrong so let me write down the
232:50 - correct name now see guys we are able to
232:52 - import this Len chain means L chain is
232:54 - there in my current virtual environment
232:57 - okay fine so I think till here
232:59 - everything is fine everything is clear
233:01 - now here again I'm going to import it so
233:03 - definitely I will be able to import but
233:05 - before starting with this length chain I
233:07 - would like to explain you the function
233:09 - calling so what is a function calling
233:11 - why I'm saying this function calling is
233:13 - very important uh definitely we should
233:15 - learn it actually it's a new feature
233:17 - inside this open AI so let's try to open
233:19 - this open a website and here okay so
233:21 - here already I opened it now guys once
233:24 - you will open the documentation of the
233:26 - open AI so there itself you will find
233:28 - out this function calling so it's a new
233:31 - feature uh recently they have added
233:33 - maybe uh four to 5 months back and uh
233:36 - what we can do by using this particular
233:38 - function calling so by using this
233:40 - function calling there is a there is a
233:41 - many use of this function calling so the
233:44 - first use basically uh the very basic
233:47 - use which I would like to tell you we
233:48 - can formate our
233:50 - output okay we can we can formate our
233:53 - output in a we we can formate the output
233:55 - in our desire desire format so whatever
233:57 - output we are getting now from the open
234:00 - uh let's say we are using openi API and
234:03 - we have a model open API what it is
234:05 - doing tell me it is calling the llm
234:07 - model agree now whatever output we are
234:10 - getting now we can format that
234:12 - particular output in a desired format in
234:15 - our required format that is the first
234:17 - use of this function colleag now we have
234:21 - other use of this function colag some
234:23 - Advanced use of this function colag
234:25 - let's say uh we are uh calling any sort
234:28 - of a API means let's say we are asking
234:30 - something to my CH GPT and it is not
234:33 - able to answer for that particular
234:34 - question so for that what we are doing
234:37 - we are calling any third party API any
234:39 - any sort of a plugins and whatever
234:41 - output we are getting whatever output we
234:44 - are getting right so we can format that
234:46 - particular output and we can append that
234:48 - output in our conversation
234:51 - chain that is really powerful and
234:53 - somehow L chain is also doing the same
234:55 - thing but yeah so recently they have
234:58 - added this function colleag this one
235:00 - feature actually inside this open a and
235:03 - here uh like it's really uh like a
235:06 - important one and it's like really uh
235:08 - very very useful and in the lenon also
235:10 - we can do the same thing right but apart
235:13 - from this thing lenon is having so many
235:16 - functionality in the lch actually we can
235:18 - perform so many things I will come to
235:20 - that I will I will show you the
235:21 - differences between this open and this
235:23 - lench why we are using this openi why uh
235:26 - why we are why we are going to use this
235:28 - Len chin why uh we are not going to use
235:30 - this openi API itself because see in a
235:33 - back end if we are going to talk about
235:34 - this Len chain so in a back end this Len
235:36 - chain this Len chain actually it's
235:38 - calling open API it's a wrap up on top
235:40 - of the open API come I I will come to
235:43 - that first of all let me clarify this
235:44 - function calling so guys to understand
235:47 - this function calling I will I draw the
235:49 - architecture and all I will I will try
235:51 - to uh explain you each and everything
235:53 - okay but before that let me write it
235:55 - down some sort of a code over here so
235:57 - here what I'm going to do here I'm going
235:59 - to open my IP NV file and here I'm going
236:02 - to write it down some sort of a code to
236:04 - understand this function calling so step
236:06 - by step I will try to explain you and
236:08 - please do along with me I think uh that
236:11 - would be great so for that guys what I
236:13 - did so here uh just a wait I have
236:16 - written one
236:21 - text great so here guys see uh I have
236:24 - written one text so let me copy and
236:26 - paste this particular
236:27 - text now here I'm going to run this
236:30 - particular uh cell and once I will print
236:33 - this student description so here you
236:35 - will get the entire description so I I
236:38 - just written a very basic description so
236:41 - uh s saita is a Str of the computer size
236:43 - it Delhi he's a Indian and he's having a
236:46 - 8.5 cgpa something something about me or
236:48 - something about like U any person you
236:51 - you can write it down this uh particular
236:53 - description so here is a short
236:55 - description now guys what I will do see
236:57 - so here is what here is my short
236:59 - description now here I have designed one
237:02 - prompt and that prompt I would like to
237:05 - pass to my chat GPT means I would like
237:08 - to pass to my GPT model so here see uh
237:12 - whenever we are talking about a prompt
237:14 - so I told you that what is a prompt so
237:16 - let's say this is my llm
237:20 - model this is what this is my llm model
237:23 - now we are passing input to this llm
237:25 - model and we are getting response we are
237:28 - getting a output so this respon this
237:30 - input actually so this input is called
237:32 - input prompt and this prompt is nothing
237:35 - it's a collection of
237:37 - tokens
237:39 - so you can understand in such a way that
237:40 - this prompt is nothing it's a
237:42 - sentence and this token is nothing it's
237:44 - a words what is this tell me it's a
237:47 - words so this uh sentence is nothing
237:50 - it's a token and sorry sentence is a
237:53 - prompt is nothing it's a sentence and
237:55 - token is nothing it's a words right so
237:57 - here we will be having input prompt and
237:58 - here we have a output
238:00 - prompt getting my point so here see I
238:04 - have written one description now I will
238:05 - write it down my prompt I will I have
238:07 - designed one prompt so let me uh copy
238:09 - and paste that particular prompt and
238:12 - let's see uh what will happen if we are
238:14 - going to paste uh if we are passing this
238:17 - particular prompt to my llm so here is
238:19 - my prompt guys so just try to read this
238:21 - thing over here and so this prompt is
238:23 - saying so let me run it first of all so
238:26 - this prompt is saying please extract the
238:28 - following information from the given
238:29 - text whatever text we are passing let's
238:32 - say this is a description so uh we are
238:34 - passing this particular description so
238:35 - from that particular description I have
238:37 - to extract a few useful information so
238:42 - here the information is what name
238:44 - College grade and Club so these are the
238:48 - information just just try to read this
238:49 - particular uh description and based on
238:52 - this definitely uh you can extract this
238:55 - particular information like name College
238:57 - grade and
238:58 - club now chat GPT or this GPT model will
239:02 - do it uh will do it for me uh something
239:05 - like this I have designed this
239:07 - particular prompt so here I'm saying
239:09 - please extract this particular
239:10 - information and this these are name and
239:13 - here this is the body of the text and
239:15 - here I'm passing my text you can see so
239:17 - here I'm writing I have a string so I
239:18 - have defined one prompt and here I'm
239:20 - passing my description now see once I
239:23 - will run it so definitely I will be
239:25 - getting my prompt so here is what guys
239:27 - tell me here is what here is my prompt
239:29 - this is what this is my prompt okay it
239:31 - is fine not an issue now guys what I
239:33 - will do I'm going to pass this
239:35 - particular prompt to my chat GPT all
239:38 - right now what I can do I can pass this
239:40 - particular promt to my chat GPT and over
239:43 - here uh first of all let me copy and
239:46 - paste this particular code or let me
239:48 - write it down that so here I'm going to
239:50 - write it down from open a
239:52 - import open AI so this is what this is a
239:55 - class now here what I'm going to do I'm
239:57 - going to create object of this
240:00 - particular class so here I'm going to
240:02 - create a object of this particular class
240:04 - so here I will write it down open Ai and
240:07 - here uh what I'm going to do so here is
240:09 - what here is my object now I can keep
240:12 - this object inside one variable now here
240:15 - I'm going to say my variable name is
240:17 - what my variable name is client now if I
240:19 - want to make a connectivity so for
240:21 - making a connectivity what I need to do
240:23 - tell me so here I need to pass my API
240:26 - key so how I can do that so here is a a
240:29 - parameter uh we need to pass one
240:31 - parameter over here so the parameter
240:33 - name is what parameter name is API unor
240:36 - key so here I'm going to write it down
240:38 - AP apore key and here I will pass my key
240:41 - so my key is what my key is my key so
240:44 - once I will uh run it so here you will
240:46 - be able to find out this is what this is
240:48 - my client so let me contrl Zed and here
240:52 - is what here is my client so this is
240:54 - what guys tell me this is my client now
240:56 - by using this particular client
240:58 - definitely I can call my chat completion
241:01 - API so let's try to call this chat
241:03 - completion API and here I have already
241:06 - written the code for that so let me copy
241:08 - paste uh I have written some sort of a
241:10 - code already I kept in my notepad so
241:13 - from there sometimes I will copy it uh
241:16 - because I want to save my time otherwise
241:19 - uh if I'm going to write each and every
241:20 - line so definitely it's going to take
241:22 - more time now here uh you can see so we
241:25 - are going to call this chat completion
241:28 - API now chat completion this is the
241:30 - particular method that's it now here is
241:32 - what here is my prompt now once I will
241:34 - run it so you will be able to find out I
241:36 - will be getting one response so here is
241:39 - my response let me show you this
241:41 - particular response and here is what
241:43 - guys here is my response definitely I
241:46 - can extract this response uh for that uh
241:49 - what I need to do so here I just need to
241:51 - write it down this
241:52 - response uh response and this response
241:55 - actually uh inside this response there
241:57 - you will find out this choices so I will
242:00 - write it down this dot choices dot
242:03 - choices now I will run it so here you
242:05 - will get this choices now from here what
242:07 - I need to do
242:08 - from here this is the list actually so
242:10 - here I will write it on this zero zero
242:12 - index whatever information is there on
242:15 - this zero index now from here I'm going
242:17 - to extract uh this particular
242:19 - information now here I will write it
242:21 - down this message message now here is
242:24 - what this is my message actually and
242:26 - from this message I'm going to write it
242:28 - down I'm going to except this content so
242:30 - here I'm going to write it down this dot
242:33 - content now guys see this is what this
242:35 - is my entire information now if I want
242:38 - to convert this particular
242:40 - information now if I want to convert
242:42 - this particular information in Json
242:44 - format so for that what I will have to
242:46 - do so here actually what I'm going to do
242:48 - I'm going to collect this thing in one
242:51 - variable that is what that is my output
242:53 - now here what I will do guys here I'm
242:55 - going to import Json so here I'm going
242:57 - to write it down import Json and here
242:59 - I'm going to write down json. load now
243:02 - to this load function I will uh provide
243:05 - my variable my variable name is what my
243:07 - variable name this output now here you
243:09 - will find out uh is saying this json.
243:13 - load it is giving me Str Str object has
243:16 - no attribute read okay it's not going to
243:19 - read let me check what is the correct
243:21 - function just a
243:25 - second so the function name is loads
243:29 - here guys you can see so the uh the
243:31 - method basically which I was calling so
243:33 - the method name was loads so Json do
243:36 - loads and here we are are passing this
243:38 - output now you can see this is what this
243:40 - is my output are you getting my point
243:43 - guys are you able to see what I did I I
243:46 - given this uh I given this prompt I
243:49 - given this basically I given this
243:51 - description to my model and I asked that
243:55 - okay just give me this particular
243:57 - information just give me this particular
243:59 - information from this description and
244:01 - here what I did I passed this particular
244:03 - prompt to my tell me to my chat
244:07 - completion API actually this chat
244:09 - completion API is calling this GPD 3.5
244:12 - turbo model and here guys you can see we
244:14 - are able to get a response whatever
244:16 - description we have given according to
244:18 - that whatever prompt we have designed
244:20 - and it is giving me that particular
244:22 - response we have given a description we
244:25 - have designed a prompt and according to
244:27 - that only we are getting a response here
244:30 - you can see this is a response actually
244:32 - I have converted it into a Json format
244:34 - so this is the first thing which I want
244:36 - to show you now here guys see this type
244:40 - of prompt it is called few short prompt
244:43 - it is called few short prompt where I'm
244:46 - giving my description and I'm saying
244:48 - that okay so uh you need to behave like
244:51 - this means whatever description I'm
244:52 - giving to my model and here uh regarding
244:55 - that particular description I want to
244:57 - extract some sort of a
244:59 - information so here actually this type
245:02 - of prompt is called fuse short prompt
245:04 - now directly I was asking something to
245:06 - my model in my previous one in my
245:08 - previous uh session so here actually
245:12 - directly I was asking uh the question to
245:14 - my uh model to my llm model so this is
245:17 - called actually zero short prompt this
245:19 - is what zero short prompt now here this
245:22 - type of prompt actually is called few
245:24 - short
245:25 - promp getting my point this idea is
245:29 - getting clear to all of you please do
245:31 - let me know in the chat if you are able
245:33 - to follow me till here please write it
245:35 - down in the chat I'm waiting for your
245:37 - reply
245:43 - I'm sharing the text uh don't worry I
245:45 - can share everything in the chat so just
245:47 - a
245:49 - second um here is a
246:05 - text so here is a text guys
246:08 - I
246:09 - think it's
246:11 - a it's a half text let me give you the
246:15 - full so college and here is the full
246:21 - text because it is having a word limit I
246:23 - cannot uh like give more than 80 words I
246:27 - think I cannot uh like paste more more
246:30 - than 80 words in the inside the
246:36 - chat
246:39 - yes is it is it because we are asking
246:41 - for a number of variable in a second
246:42 - prompt correct your understanding is
246:45 - correct
246:48 - Goldie so zero short means we are not
246:51 - defining anything over here directly we
246:52 - are asking a question to my model now
246:56 - what is a few shot so here we are giving
246:58 - some sort of a description and based on
247:00 - that particular description we are
247:02 - asking regarding some information we are
247:05 - asking some information okay so this is
247:08 - called few shot and here is a zero shot
247:11 - don't worry uh we have a many example
247:13 - here I just given you the glimpse of
247:14 - that just wait for some time one or two
247:16 - more classes you will get more about it
247:19 - because uh now we just we are going to
247:20 - design The Prompt and all and in the
247:23 - next session specifically I will I will
247:25 - be working on the prompt on a different
247:27 - different prompt and even uh for the uh
247:30 - inside the project also we are going to
247:31 - design a different different prompts got
247:33 - it now see uh definitely we are able to
247:37 - call our l m we are able to call our
247:39 - like open a API and definitely we are
247:41 - able to get our output also from the llm
247:45 - models now here guys what is the use of
247:48 - the function calling so first of all let
247:49 - me uh Define one very basic function and
247:52 - then I will Define one Advanced function
247:54 - also so here what I'm going to do see
247:57 - here I did this particular thing by
247:59 - using this uh chat jpt Itself by using
248:02 - this completion API now let me show you
248:04 - the same thing by defining the function
248:06 - so here what I'm going to do so here I'm
248:08 - going to Define one function so let me
248:12 - do one thing let me Define one function
248:14 - and here this is my function guys see
248:17 - I'm going to define the function this is
248:18 - my function now from where I got this
248:21 - particular format so you must be
248:23 - thinking sir okay so sir you define this
248:25 - function now from where you got this
248:27 - particular format so just try to go
248:29 - through with the open API and here uh
248:32 - sorry open a documentation and here just
248:34 - click on this function calling and once
248:36 - you will scroll down over here so here
248:39 - you will get the code s snippet so and
248:42 - inside this code s snippet you will find
248:44 - out this function definition that how to
248:46 - decide or how to define this particular
248:49 - function getting my point I will come to
248:52 - this particular example I have designed
248:54 - one example for all of you but first of
248:56 - all let's try to understand a function
248:58 - calling from uh like very basic example
249:02 - and then I will come to the advanced
249:04 - part so here you can see we have a
249:06 - function
249:08 - and from here itself I took this
249:09 - function definition and how to decide
249:12 - how to define this function and all now
249:13 - let me tell you what I written over
249:15 - there so here I have opened this uh
249:17 - notebook now see uh what is the name of
249:20 - this function actually student custom
249:22 - function it's not a function like python
249:25 - we write it down that Def and all it's a
249:28 - like function basically which we are
249:29 - writing down for the open AI U actually
249:32 - we have to uh like pass this thing to
249:34 - the uh to inside the chat complete API
249:38 - itself I will come to that first of all
249:39 - let's try to understand this uh
249:41 - structure so first of all I I need to
249:44 - write it on the name so here I have
249:45 - written the name name is equal to
249:47 - extract student information then we have
249:50 - to write it on the description so here
249:52 - you can see this is the description of
249:54 - the function that why we are going to
249:56 - Define it now here you will find out
249:58 - some sort of a pairs so key and value
250:00 - pairs so first we have a parameter so
250:02 - here you can see we have a parameter now
250:04 - uh we have a type so which type of uh
250:07 - like object object we are going to be
250:08 - defined over here and then we have a
250:10 - properties now here you will find out
250:12 - inside this parameter you will find out
250:14 - a different different values like name
250:17 - school grade and Club whatever actually
250:20 - I Define over there inside my prompt the
250:22 - same thing the same thing over here
250:25 - right so first we have a name the second
250:27 - thing we have a description the third
250:29 - one we have a parameter inside the
250:31 - parameter we have a different different
250:32 - values like names school grade and Club
250:38 - getting my point now here just see the
250:41 - type of this name it's a string just see
250:44 - the type of this school it's a string a
250:47 - college you can write down the college
250:49 - here is a college so let me write down
250:50 - the college instead of this school so
250:53 - here is what here is college so instead
250:55 - of this is school I can write down this
250:57 - college now here is college the type of
251:00 - college is string right now here is a
251:03 - grade now grade type is integer now here
251:05 - is a club so Club type is integer again
251:09 - I think you getting my point that how to
251:10 - define this function it's a predefined
251:13 - format or the Inon platform itself
251:15 - you'll get this particular form format
251:17 - now just run it okay now just run it and
251:21 - after that what you need to do so here
251:23 - see you need to uh call the chat
251:26 - completion API so here is your chat
251:28 - completion API let me copy this chat
251:30 - completion API from here and let me
251:33 - paste it down now here you need to
251:35 - Define some sort of a parameter now let
251:38 - me write it down those particular
251:39 - parameter and then I will run it so here
251:42 - guys you can see we have this message so
251:45 - let me keep this message in a single
251:47 - line so here I'm going to keep this
251:49 - particular message in a single line so
251:52 - here is what guys here is what here is
251:54 - my message it is fine now after the
251:57 - message what you need to do you need to
251:59 - write it down one more parameter and the
252:01 - parameter will be what the parameter
252:03 - will be a function so here I'm going to
252:05 - write it on the parameter the parameter
252:07 - name is what function so here is my
252:10 - parameter function now tell me what is
252:11 - the name of the function so here the
252:14 - name of the function is nothing it's a
252:16 - student custom function so let try to
252:19 - copy it and try to paste it over here
252:22 - that's it you just need to copy the
252:24 - function name from here and you need to
252:27 - paste it over
252:29 - here okay as a value of this particular
252:32 - parameter now guys I can keep this
252:35 - particular response in response two so
252:37 - so here I'm going to write it down this
252:39 - response to so here is what here is my
252:41 - response to now let me run it and let's
252:43 - see what I will be getting so here is
252:45 - saying okay it is giving me error so I
252:47 - think uh chat
252:50 - completion role is fine I'm using client
252:53 - only let me check with the
252:56 - client yeah client uh now everything is
253:00 - fine what is the issue I you code
253:03 - incorrect API
253:05 - provided okay okay just a second let me
253:11 - use the correct client this is
253:15 - fine and here I can keep the Cent c l i
253:20 - e n t now
253:26 - see uh it is saying that
253:29 - incorrect invalid key uh why it is
253:36 - so um just to check let me check this
253:39 - key over here student custom information
253:43 - prompt is fine U but before it was
253:45 - giving me output now why it is saying
253:48 - like that let me check with a key over
253:51 - here so my key and here is what here is
253:56 - my key just a second guys let me take a
253:58 - correct
254:00 - key
254:06 - uh
254:08 - okay don't worry I will delete this
254:10 - particular key uh I'm running in front
254:13 - of you everyone but after the session I
254:16 - will delete it fine so now I am having
254:19 - my key and here what I can
254:23 - do again I can run
254:26 - it
254:28 - great now let's
254:33 - see yeah now everything is working fine
254:35 - so this is what this is my response to
254:37 - two and here guys you you will find out
254:40 - that we are getting a output so we are
254:43 - getting output in whatever format we
254:45 - have defined this thing so we have
254:47 - defined this thing like uh name College
254:49 - grade and club now here you will find
254:51 - out the same thing so name is there
254:54 - college is there grade is there and Club
254:56 - is there if you don't if you want to
254:58 - change any sort of a description you can
254:59 - change it and you again you can check it
255:02 - and now actually we are
255:03 - not we we are not uh doing directly this
255:06 - thing we are using a function over here
255:09 - and this is a very basic use of the
255:11 - function as of now which I have shown
255:13 - you getting my point so directly also
255:16 - you can do that you can call it but here
255:18 - they have given the function by using
255:20 - this function also you can call
255:23 - it okay so here actually this is the
255:26 - basic use of the function and at this
255:28 - point of time you you won't be able to
255:30 - find out any differences in a direct
255:33 - call and in a function call both is
255:36 - looking same but now the difference will
255:39 - start once I will explain you the second
255:42 - example now over here you can see so
255:44 - this is the response which I'm getting
255:46 - now let's try to extract the response so
255:48 - over here what I can do I can write it
255:50 - down this a contain and let's see what I
255:52 - will be getting over here so here is
255:55 - what here is my uh content which I want
255:58 - okay which I want to extract from here
256:00 - so let me copy it and let me paste it
256:02 - over here actually I want to extract the
256:04 - content so that's why I'm going to be
256:05 - write down response to Choice message
256:07 - and content so once I will done it and
256:10 - over here I will be getting this content
256:13 - so here I am getting this content now
256:16 - let me check over here okay actually see
256:20 - here actually we have to get the content
256:22 - from the function call so till message
256:24 - it's fine so let me check with the
256:26 - message till message I think it is fine
256:28 - now if I want to extract the content now
256:30 - so over here I will have to call this uh
256:32 - I will have to write it down this
256:33 - function call because before I was
256:35 - extracting the message because directly
256:37 - I did it directly I I called my llm
256:40 - model now here I'm calling it but by us
256:43 - using function so here I've defined the
256:45 - format in a function I have defined the
256:47 - format of the function and now by using
256:49 - this function I'm calling my API so the
256:52 - the API is hitting the model and
256:54 - whatever output desired output I want
256:57 - I'm getting it now over here what I will
256:59 - do so here I'm going to write it down
257:01 - this uh dot function call so let me copy
257:04 - and paste it over here function
257:07 - underscore call now over here guys you
257:09 - can see we are getting this particular
257:11 - value now let me write it the argument
257:13 - over here arguments and this is what
257:15 - this is my output now yes same thing we
257:18 - can do over here as well so here I can
257:20 - write it down this uh Json Json do loads
257:25 - and here what I can do I can write down
257:27 - the json. loads and now see I'm getting
257:30 - a same output but see guys here at this
257:34 - point of time definitely you are not
257:36 - able to find out a difference between
257:38 - the direct function call and between
257:40 - this uh direct call and this function
257:42 - call right now I will show you one
257:45 - Advanced example and by seeing that
257:47 - particular example definitely you will
257:49 - be able to discriminate getting my point
257:52 - so till here everything is fine are you
257:54 - able to do it don't worry I will give
257:56 - you the code and I will give you each
257:58 - and everything whatever I'm writing over
258:00 - here and uh this file and all it will be
258:03 - available inside my resource section so
258:05 - here is the resource section guys uh so
258:07 - just try to enroll into the course and
258:09 - uh yes definitely you will be able to
258:11 - get this particular file inside this
258:12 - resource section and this is completely
258:14 - free you no need to pay anything you no
258:17 - need to P you don't need to pay actually
258:19 - a single rupees for this for this
258:21 - particular dashboard so please try to
258:23 - enroll and try to download the resource
258:25 - from there so till here everything is
258:28 - fine please give me a quick yes then I
258:30 - will proceed with a further
258:35 - topic
258:42 - what is the difference between Json and
258:43 - function call so here you will find out
258:45 - so just check the type of this output so
258:48 - here you will find out the type of this
258:50 - output is nothing let me show you it's a
258:54 - string now here I have converted into a
258:56 - Json that's it okay I don't I I don't
258:59 - want to keep it in a a string because uh
259:01 - it's not looking good to me if you will
259:03 - print it now if you will print it guys
259:07 - see it's not looking good to me that's
259:09 - why I converted into ajason now if you
259:11 - will check the type of this particular
259:13 - output so here you will find out a Json
259:16 - let me write it down the type over here
259:18 - and let me print it now so here is what
259:21 - guys tell me here is nothing it's a Jon
259:23 - not dictionary got it so this is fine to
259:26 - everyone I think till here everything is
259:35 - clear
259:41 - great now let's start with the second
259:43 - concept so over here uh the first
259:46 - concept actually I shown you the basic
259:48 - use of the function and all now let's
259:49 - try to understand the advanced use of
259:52 - this function calling so over here guys
259:54 - see uh we have few more thing regarding
259:56 - these functions and all so first of all
259:58 - let me tell you that now let's say if
260:00 - you want if we are passing a description
260:02 - of two student all together so it can
260:06 - handle that thing also it can handle
260:08 - that thing also now over here let me
260:10 - show you that particular uh that
260:12 - particular thing also just a wait uh I
260:14 - have I have a code for that and I'm
260:16 - going to copy and paste see guys so what
260:18 - you need to do so over here I just
260:20 - written one for Loop and let me show you
260:23 - that particular for Loop and here see
260:25 - inside this for Loop what I have written
260:28 - so first of all I Define one uh list and
260:32 - inside this list we have a two
260:34 - description so the first one you know uh
260:36 - already I written this particular
260:37 - description now let me uh let me run it
260:41 - okay so what was the name of that so
260:44 - just a wait let me check
260:51 - um okay where I have written this
260:53 - student I think this one so that name
260:56 - the name of the variable is student
260:58 - description so let me copy and paste
261:00 - over here let me copy and paste this
261:02 - student description so this is what this
261:04 - is the student description this is the
261:05 - first one so let me
261:07 - write it down student description over
261:08 - here now let me keep it over here now
261:11 - student description now I'm going to
261:13 - Define one more so here I'm going to
261:14 - create one more variable and here
261:17 - student description
261:18 - two and here guys what I will do again
261:21 - I'm going to copy and paste a same thing
261:24 - so this is the value which I'm going to
261:25 - copy and paste and I'm going to do some
261:26 - sort of a changes over here so instead
261:29 - of this s Savita I'm going to write down
261:30 - something else so let's say I'm going to
261:32 - write it down Krish n so and here
261:35 - Krishna is a student of a compter
261:36 - computer science I uh maybe instead of
261:38 - this delh let me change the name so here
261:41 - is what here is Mumbai now here he is a
261:43 - cgpn so he's having more than 9.5 cgpa
261:47 - so let me write down this like cgpa as
261:50 - well and here let me change the name so
261:52 - instead of Sunny what I'm saying I'm
261:54 - saying Krish is known for his
261:56 - programming skill and he's a member of
261:59 - here I can write down DS Club data
262:01 - science club data science club so here I
262:04 - am giving an information regarding
262:07 - two student now here see he hopes to
262:10 - pursue in a career in artificial
262:11 - intelligence after graduating something
262:13 - else right so now what I will do let me
262:15 - run it and let me keep this particular
262:18 - description over here so here what I'm
262:20 - going to do I'm going to keep this
262:21 - particular description now what I will
262:23 - do so over here uh I I'm just going to
262:26 - run the for Loop and here you can see
262:29 - one by one the description is coming and
262:31 - it is going through this particular uh
262:34 - completion API this Chad completion API
262:36 - and I will be getting a response so
262:38 - let's try to make some changes over here
262:40 - because it's a like old code let me give
262:43 - the latest one over here so this is the
262:45 - latest let me copy and paste the latest
262:49 - function so here is what here is a
262:51 - client chat completion. create now over
262:55 - here the model name is what model name
262:57 - is same now here message uh it's the
263:00 - same this one now let me write down the
263:02 - student so it will be more uh like clear
263:04 - to all of you so here here uh you can
263:07 - see we are calling a function now here
263:09 - guys see we are calling which function
263:11 - this particular function let me copy the
263:13 - same name so here the function name is
263:15 - what student custom function so here I'm
263:17 - going to copy the name of the function
263:19 - and let me paste it over here so this is
263:22 - what guys tell me this is my function
263:23 - name and here is function call is auto
263:25 - right automatically the function is
263:27 - going to be called now what I want tell
263:29 - me I want a response so over here I'm
263:31 - going to print this particular response
263:33 - and let's see we'll be able to get a
263:35 - correct response or not so if I'm going
263:38 - to run it guys so you will be able to
263:40 - find out a response regarding two
263:41 - description so it is saying that check
263:44 - completion is not a subscribable okay so
263:47 - over here I think I will have to paste
263:49 - this thing now let me copy it and let me
263:55 - paste it over here
263:57 - so this is the one I think it is fine
264:01 - now and this is going to be a response
264:05 - so response whatever response we are
264:06 - getting there is a choice and inside
264:08 - that we have a message and finally
264:10 - function call and from there we are
264:12 - going to collect a argument so once I
264:15 - will this argument actually this
264:16 - arguments you can map this argument with
264:18 - this thing this uh thing basically which
264:20 - I have written over here inside the
264:21 - function name College grade and
264:25 - Club getting my point so here what I'm
264:27 - going to do now here I'm going to run it
264:29 - and let's see what I will be getting
264:32 - so once I will run it definitely I will
264:35 - get a response great so here it is
264:37 - giving it has given me a response
264:39 - regarding the first uh description and
264:41 - now guys you can see it has given me a
264:43 - response regarding the second
264:44 - description so the first one is s sabida
264:47 - and the second is kishna you can give as
264:49 - many as uh like description in all so
264:51 - over here let me take the third one and
264:54 - let me keep it over here and here I can
264:56 - say so here student description three
265:00 - three now over here instead of this
265:02 - krishak let's say I'm going to write
265:04 - down one more name let's say sudhansu
265:06 - Kumar and here I can say that he's a
265:09 - student of
265:10 - IIT Hyderabad or I let's say uh
265:16 - Bangalore now over here he's a Indian
265:19 - he's having a cgp around let's say 9.2
265:22 - and he's programming skill and he's a
265:24 - active member of mlops club now let me
265:27 - write it down over here mlops Club so
265:30 - now yes I have given this particular
265:32 - description over here and if I'm going
265:34 - to copy it and let me paste sit over
265:36 - here so regarding this description also
265:39 - definitely we'll be able to call our
265:40 - model we'll be call our API and finally
265:43 - we'll be getting a output it's doing the
265:45 - same thing which our chat completion API
265:47 - is doing directly without function right
265:50 - now we are doing along with a function
265:53 - along with a multiple description
265:55 - getting my point so here this is the
265:57 - basic use actually basic use of the
265:59 - function after this one I will come to
266:01 - the advanc use just wait now over here
266:03 - see if I'm going to run it so let's see
266:05 - what I will be getting uh so here I will
266:08 - be getting a First Response yes this is
266:11 - my first response now this is the second
266:14 - response and here you can see there is
266:18 - the third response getting my point guys
266:21 - yes or no we can call our llm model we
266:24 - can we can call our API we can hit the
266:26 - model and we can summarize the result
266:29 - according to the prompt if this thing is
266:32 - clear to all of you then please write it
266:34 - down yes in the chat please do let me
266:36 - know in the chat guys if this part is
266:38 - clear to all of
266:41 - you yes it's a case sensitive whatever
266:44 - variable you are going to Define in the
266:45 - function col it's a k so please make
266:47 - sure that you are going to write it down
266:49 - the correct
266:59 - name after this one the use of the
267:01 - function call will be clear just wait
267:04 - okay fine now this thing is clear to all
267:06 - of you now let me come to the next point
267:08 - so here actually what we are going to do
267:10 - see uh we are going to call a single
267:13 - function right regarding this particular
267:15 - description uh this is my function but
267:19 - we can call a multiple function also we
267:22 - can call a multiple function also so
267:25 - here guys let's say if we are going to
267:26 - define a one more function here let's
267:29 - say if we going to define a one more
267:31 - function so you can Define any sort of a
267:33 - function over here let's say function
267:35 - two let me write it down over here
267:37 - function 2 function _ 2 you can define a
267:41 - second function and after defining see
267:44 - you will Define in a same format
267:45 - whatever format is there this one in
267:48 - this format itself so in this format
267:51 - whatever format I have written now the
267:53 - variable and the parameter and the
267:54 - description U and those thing will be
267:57 - changed but the format will be a same
267:59 - because the same format which you will
268:01 - be find out over the tell me over the
268:04 - open a API s they already have given you
268:07 - that so this is what this is my function
268:08 - two now you can like Define a function
268:11 - two whatever information you want so
268:13 - let's say I just want this grade and
268:14 - club or whatever so right so if I'm
268:17 - going to remove it you can remove it or
268:18 - maybe you can Define one more function
268:20 - for some other information right and now
268:22 - if you want to call it so how you will
268:25 - do that tell me so for that actually uh
268:28 - here I have created this uh list right
268:31 - here we have created a list of the
268:33 - student information regarding a
268:34 - different different description
268:36 - now here again I can create one more
268:38 - list the list basically the list
268:41 - regarding this function so here what I
268:43 - can do I can copy this code and I can
268:45 - paste it over here this particular code
268:47 - and here what I can do I can create one
268:49 - more list and inside this list what I
268:51 - can do I can write it down the function
268:53 - so here is what let me a copy and paste
268:56 - so this see this is what this is my
268:57 - function parameter now here we have a
269:00 - first function and we have a second
269:01 - function so this is this is my first
269:03 - function which I defined already this
269:05 - one so let me copy this particular name
269:07 - and let me paste it over here this one
269:09 - so this is what tell me guys this is my
269:11 - first function which I'm going to write
269:12 - down over here and this is my second
269:14 - function already I given the same name
269:16 - so like this you can call a multiple
269:18 - function
269:20 - also getting my point so here I have
269:22 - defined this function and according to
269:24 - that I'm getting my desired output
269:26 - desired parameter you can create one
269:28 - more function on top of a same
269:30 - description and here you just need to do
269:33 - one thing instead of this specific
269:35 - function you just need to write it down
269:36 - this function you just need to provide
269:38 - this list and you are done according to
269:41 - the definition you will get output so
269:44 - this is your assignment you have to do
269:46 - by yourself I have given you the way I
269:48 - have given you the path now just Define
269:50 - a second function regarding whatever
269:52 - information is there inside the
269:54 - description whatever you want to extract
269:56 - just Define a function and call it over
269:59 - here so here I can mention this thing as
270:01 - assignment don't worry each and
270:03 - everything I will provide you uh this
270:05 - notebook will be available in the
270:06 - resource section you can download from
270:10 - there this is what this is your
270:12 - assignment guys now here this part is
270:15 - clear that uh we are calling up llm so
270:19 - here directly we are calling llm then
270:21 - what we are going to do see we have
270:22 - designed a prompt directly we are
270:23 - calling llm then what we are going to do
270:25 - we have Define a function then uh like
270:28 - we are getting that particular output
270:29 - that is also fine now we are going to
270:31 - call our llm by using openi with respect
270:34 - to different different description that
270:35 - is also fine means regarding a like
270:38 - different different description on the
270:39 - same time now we can Define two function
270:41 - as well more on more than two function
270:43 - that is also fine now what is the actual
270:46 - use of it still we are not able to find
270:48 - out the actual use of this function
270:50 - everything is looking same now let me uh
270:54 - explain you that particular part I'm
270:56 - coming to the advanced example now so
270:59 - over here what I'm going to do I have
271:00 - written one Advanced example and uh let
271:04 - me copy and paste uh the code basically
271:06 - which I have written step by step I will
271:09 - copy and paste don't
271:20 - worry okay so here guys see again I'm
271:24 - going to start from
271:25 - scratch now Advanced example of function
271:34 - call
271:36 - Advanced example of function calling
271:42 - okay now over here guys see uh what I'm
271:45 - going to do I'm going to call my chat
271:47 - GPT so here I'm going to copy and paste
271:51 - one code now this code actually we have
271:54 - defined something over here so here I'm
271:57 - saying uh what I'm asking I'm asking to
271:59 - my llm that what is the next flight from
272:03 - so here I let me change the name let me
272:05 - write it down Delhi to Mumbai so here
272:08 - I'm going to write it down what would be
272:10 - the next flight from Delhi to Mumbai
272:13 - this is my prank now just tell me guys
272:16 - will my Chad GPT able to answer for this
272:19 - particular
272:21 - question my CH chat G is able to answer
272:23 - for this particular question the
272:25 - question which I'm asking over here I
272:27 - want your uh like p uh like I want your
272:31 - opinion on that please write down the
272:32 - chat I'm asking to all of you can my
272:36 - chat GP answer for this particular
272:41 - question no why why it cannot be answer
272:46 - because like this chat GPT has stayed on
272:49 - the limited amount of data right so not
272:51 - a limited amount of data it has stay on
272:54 - uh the data basically which is available
272:55 - till September
272:57 - 2021 getting my point if you look into
273:00 - the chat GPT if you look into the open a
273:02 - just just go with the open AI uh not
273:04 - this one so where it is this one so here
273:07 - guys just just uh go over here and uh
273:10 - what you can do you can go into the
273:13 - models now over here just click on this
273:15 - GPD 3.5 and uh just look over here
273:19 - training data so it has trained up to
273:21 - September 2021 data up to this
273:25 - particular data that's why it won't be
273:28 - able to answer for this particular
273:30 - question whatever I'm going to write it
273:31 - down here now let me run it and let's
273:34 - see the response that what response I
273:36 - will be getting so over here uh yes it
273:39 - is giving me a response let's wait for
273:41 - some time I got a response now and here
273:44 - I'm going to run it so see what it is
273:46 - saying that it is saying that as an AI
273:49 - language model I don't have a realtime
273:52 - information however you can easily find
273:54 - out next flight from Delhi to Mumbai by
273:57 - checking the website or mobile apps of
273:59 - Airlines so that operate the route such
274:02 - as air india indigo spice jet vistara go
274:05 - Additionally you can contact travel
274:07 - agency or use online flight scratch
274:10 - engine for up to date now just tell me
274:12 - if you are going to create if you're
274:14 - going to create any chatbot by using
274:16 - this open API so will you give this type
274:19 - of answer to your user if your user is
274:22 - going to ask you that what is the next
274:24 - flight from Delhi to Mumbai definitely
274:26 - you will have to do some sort of a jugar
274:28 - right you will have to extract the
274:30 - information from
274:32 - somewhere you you cannot give this type
274:35 - of answer right so you will have to make
274:37 - your chatboard that much of that much
274:39 - capable you you have to make your
274:42 - application that much capable so it can
274:43 - answer for this type of question as
274:46 - well okay now let me tell you uh the use
274:49 - of the function calling over here that
274:51 - how function calling can help to us so
274:54 - over here what I'm going to do here I'm
274:56 - going to Define one
274:57 - function what I'm going to do guys here
275:00 - I'm going to Define one function so this
275:02 - is what this is my function just like
275:05 - observe step by step don't run anything
275:07 - don't write it down any sort of a code
275:09 - just observe whatever I'm explaining to
275:11 - you that's it so here is what here is my
275:14 - function function description now we
275:16 - have a name of the function get flight
275:18 - info we have a description get flight
275:21 - information between two location now
275:24 - here we have a parameter and inside
275:25 - parameter we have two things so the
275:28 - first one you will find out that is what
275:30 - that is a location origin and location
275:32 - destination so in my case what is the
275:35 - origin
275:37 - delhi now here in my case like whatever
275:41 - prompt or whatever question I'm asking
275:42 - in that case the destination is what
275:44 - destination is tell me
275:47 - Mumbai so there is two parameter I have
275:51 - here is a type here is a description
275:53 - here is a type here is a description
275:55 - that's it so let me let me change
275:57 - something inside the description also so
275:59 - here I'm I can write it down Delhi d e l
276:02 - and here let me write it down the Mumbai
276:04 - mu M mu M so this thing is fine now here
276:09 - if you will observe so I have mentioned
276:11 - one more thing I have mentioned one more
276:14 - parameter over here the parameter name
276:16 - is what the parameter name is required
276:18 - now what is required location required
276:22 - origin location required and destination
276:24 - is required two things is required over
276:27 - here okay that is fine till here
276:29 - everything is fine we are able to
276:30 - understand but still we didn't get a
276:32 - complete idea how you will get it first
276:34 - of all let me run the entire code right
276:37 - so here you can see we have a
276:39 - description so let me run it and this is
276:41 - fine this is like perfectly fine now
276:44 - here I have a prompt so let me copy The
276:47 - Prompt over here I'm not writing from
276:49 - scratch because it might takes time so I
276:52 - already return in my notepad and all
276:53 - somewhere so I'm just going to copy and
276:55 - paste that's it so here guys um I'm
276:58 - asking to my chat GPD or sorry I'm
277:00 - asking to my GPD model when is the next
277:03 - flight from New Delhi to Mumbai this is
277:06 - my question now over here if I'm going
277:08 - to run it so here guys you will see that
277:10 - okay so this is my this is my user Prem
277:12 - now what I'm going to do now I'm going
277:14 - to copy it now I'm again I'm going to
277:16 - copy the same thing this one and I'm
277:18 - hitting this particular prompt so here
277:20 - is what here is my model here is my role
277:23 - role is what role is a user and here is
277:25 - my prompt getting my point now here now
277:29 - I'm passing my function just focus over
277:32 - here just focus now over here I'm
277:34 - passing passing my function function
277:36 - underscore description this is what this
277:38 - is my function description now see over
277:40 - here uh this is my prompt and if I'm
277:43 - going to run it now if I'm going to run
277:45 - it now now you will see the response
277:47 - that what response I will be getting
277:49 - before actually I was getting this
277:50 - particular
277:51 - response before I was getting this
277:54 - response now just look into the response
277:56 - that what will be the response over here
277:57 - so here what I'm going to do I'm going
277:59 - to copy the same thing uh this
278:02 - particular thing and here I'm going to
278:05 - write it down response to response to
278:07 - choice choice message and contain so
278:10 - once I will run it so here you can see
278:12 - it's not giving me anything okay so why
278:14 - it is not giving me let me show you
278:16 - because there is no such content there
278:18 - is no such content that's why it is not
278:20 - giving me anything now let me print till
278:22 - message only and you will find out the
278:25 - uh the like values over here so over
278:27 - here guys see if I'm going to print till
278:30 - message so it is giving me a message
278:31 - whatever message I'm getting step by
278:33 - step we'll try to understand it don't
278:34 - worry now here let me copy this thing
278:36 - and let me check with this particular
278:39 - argument so here I'm going to copy this
278:40 - argument and let's see what argument we
278:43 - have uh so over here it is saying okay
278:45 - first of all I need to call this
278:47 - function call and then only I can call
278:49 - this argument uh not an issue fine now
278:52 - over here we have a argument see we have
278:54 - two argument first is loc uh location
278:57 - origin that's a Delhi and location
278:59 - destination that's a
279:00 - vom getting my point guys see it is
279:03 - going to extract from here location
279:05 - origin and location destination and here
279:07 - is Delhi here is Mumbai this is a
279:09 - location origin location destination now
279:11 - it is not giving me answer but it is
279:13 - going to it is it is it is able to
279:15 - extract something right from this
279:17 - function call and here you can see these
279:20 - are this is two argument right there you
279:23 - will find out two argument this is the
279:24 - argument basically which we are able to
279:26 - get it from here because we have already
279:28 - defined it over here this thing okay
279:30 - that is fine this is clear to all of you
279:31 - now guys see how you will uh give this
279:35 - uh like flight actually so for that you
279:38 - will have to call any third party API
279:40 - then only you will be able to provide
279:42 - the information now right so let's say
279:45 - if I'm talking about the make my trip so
279:47 - what it does it is having access of a
279:49 - different different API if I'm going to
279:50 - book any train ticket so is calling the
279:52 - IR CZ API and is giving me the entire
279:55 - detail make my trip is not a owner of
279:58 - the Railway where it is having the
280:00 - entire data entire information of the
280:03 - Railway Indian Railway no
280:05 - IRCTC actually it's a organization
280:08 - actually that is a portal which is like
280:10 - governed by the uh Indian government and
280:13 - like it it is having some sort of apis
280:15 - and all which is being called by the
280:17 - make my trip or any other website and
280:19 - because of that only you are able to get
280:20 - an information whatever rails and all
280:23 - whatever flights and all you are going
280:24 - to find out over there or maybe some
280:27 - other website right so here what you
280:29 - will do for getting this information you
280:30 - will call the API any third party API
280:33 - now here see I'm not going to call any
280:35 - sort of API I'm giving you as assignment
280:37 - this thing so you can call any sort of
280:40 - API you can explore a different
280:41 - different API and you can accept the
280:43 - information from there I'm uh I can uh
280:46 - give you the very basic name rapid API
280:48 - just go through go and check with the
280:49 - rapid API there you will get the each
280:51 - and every API related to the weather
280:53 - related to the different different thing
280:54 - as of now what I did actually I created
280:56 - my own function which is working as a
280:58 - API I created my own function which is
281:00 - working as a API now let me give you
281:02 - that uh let me show you that particular
281:04 - function so here what I did I have
281:06 - created my own function which is working
281:08 - as a API you can think this working as a
281:11 - API but you can call your real time API
281:14 - for extracting a real data don't worry I
281:17 - will show you that thing I will uh show
281:18 - you how you can call the Sur API in my
281:20 - next class when I will discuss about the
281:22 - agents in a lang chain there I will
281:24 - discuss about the Sur API and all so
281:26 - over here you can see guys we have a uh
281:28 - I have created one function get flight
281:30 - info location origin location
281:32 - destination now here I'm going to be uh
281:34 - like here I written some sort of a code
281:36 - that is what that is nothing as a flight
281:37 - information and it is in a dictionary
281:39 - format so here we have a location origin
281:41 - destination date time Airlines and
281:43 - flight this is the airlines time and
281:45 - this is the flight number and all now
281:47 - here this function is working as a API
281:50 - you can think like that now if I'm going
281:52 - to run it so over here uh it is working
281:55 - fine now guys see what I'm going to do
281:58 - here so this function is working fine
282:00 - now here uh I'm going to collect this
282:03 - origin and this destination so first of
282:06 - all let me show you this particular
282:07 - thing uh argument I already shown you
282:10 - this one this is my
282:13 - argument and over here uh what I'm going
282:16 - to do I'm going to be convert this
282:19 - argument into a Json so
282:21 - json. loads now over here what I'm going
282:25 - to do so let me run it and here I am I
282:28 - having two argument uh first is Delhi
282:30 - and the second is Bombay this is my
282:32 - origin and this is my destination so
282:34 - this thing this information I'm going to
282:35 - collect in my like a variable that is
282:38 - perams now over here we have a variable
282:40 - that is perams now from here I'm going
282:42 - to extract few more information I want
282:44 - to extract the origin and the
282:46 - destination so for that I already
282:47 - written the code let me copy and paste
282:49 - so this is my origin so I'm calling this
282:52 - get uh method on top of this uh
282:54 - dictionary actually this is my
282:55 - dictionary and I'm extracting a value of
282:57 - this particular key as like this I'm
283:00 - extracting a value of this particular
283:01 - key you you can see over here let me
283:03 - show you so this is what this is my
283:05 - dictionary now on top of this dictionary
283:07 - if I will call this get method now uh by
283:10 - using this uh key so get and over here
283:14 - what I will do I'm going to write it on
283:15 - the key so the key name is what location
283:18 - uncore origin now over here see if I'm
283:22 - going to run it now you will find out
283:23 - this Delhi so this is my origin and here
283:26 - you will find out the destination
283:28 - similarly I can get the destination also
283:29 - now it's not a big deal see now over
283:32 - here I can call this a destination why
283:35 - I'm doing it entire thing will be clear
283:37 - and I will give you the quick revision
283:38 - also just wait for some time just wait
283:40 - for more 5 minute everything will be
283:42 - fine so Delhi is there Delhi and Bombay
283:44 - is there so here we have origin and
283:46 - destination now we got both origin and
283:49 - destination right so parameter is uh we
283:51 - are able to get a parameter we are able
283:53 - to get origin and destination now let's
283:55 - try to find out the flight detail right
283:57 - so let's try to fly find out the F
283:59 - flight detail so for that basically what
284:01 - I'm going to do here I'm going to call
284:05 - one uh so here I'm going to call one
284:07 - method that is a a right so what this a
284:10 - will do so here actually I'm going to
284:11 - pass the name so let me show you this
284:13 - particular value what is happening over
284:15 - here so just a wait let me copy and
284:17 - paste over here so this is what this is
284:19 - the name this name is what this is the
284:21 - function name get flight information
284:23 - right now I'm giving this uh function
284:26 - name uh this uh function name this GL
284:28 - get flight info which is a string as of
284:30 - now let me show you the type of this
284:32 - function over here so over here what I'm
284:33 - going to do here I'm going to write it
284:35 - down type of this function so this type
284:37 - of the function is nothing it's a string
284:40 - only so let me uh keep it inside the
284:43 - bracket so this is what this is a string
284:44 - now if I'm passing this thing to my eval
284:46 - function eval method so you will get the
284:49 - actual function this eval is doing
284:50 - nothing this EV is giving you the actual
284:52 - value that's it this is what this is the
284:54 - function now we have defined get flight
284:56 - information it will give you the actual
284:58 - value that's it so here you can see it
285:00 - is giving me the function only this is
285:02 - what this is my function this get flight
285:04 - info is what it's a function now it's
285:05 - not a string we have already defined it
285:07 - over here see this one so this is doing
285:09 - nothing it is just giving me actual
285:11 - value okay now let me show you one
285:13 - example very basic example let's say if
285:15 - I'm going to write down and here if I'm
285:17 - going to write down two now tell me what
285:19 - is this two if I'm going to write down
285:21 - like this uh type and here I'm going to
285:25 - write it down two just tell me what is
285:27 - this it's a string but two is a string
285:30 - no it's an
285:31 - integer right it's a integer so if I'm
285:34 - I'm going to write it down like this now
285:35 - if I'm passing to my so it will provide
285:37 - an integer see this is what this is an
285:38 - integer if you check with the type so
285:40 - type the type will be an integer only so
285:43 - it is converting whatever value we are
285:46 - passing into the well method now it is
285:47 - converting into a original format into a
285:49 - original form so here we are getting a
285:51 - function so this is what this is my
285:52 - function which I collected over here now
285:54 - I just need to call this particular
285:56 - function so here I'm going to call this
285:58 - function now after calling this
286:00 - particular function I will be get see
286:02 - here I'm going to pass the parameter
286:04 - keyword argument keyword par like this
286:06 - this particular parameter params this
286:07 - one okay location origin and location
286:10 - destination this two thing we want over
286:12 - here this one right now once I will run
286:15 - it so here I will be getting my details
286:18 - so let me run it first of all uh where
286:20 - is a perms here is a perms and here is
286:22 - what here is my flight details so name
286:25 - date time is not defined let me Define
286:29 - the date time over
286:31 - here so from date time on of date time
286:37 - import date time and it is done I think
286:42 - now let me run
286:44 - it time Delta is not defined let me
286:48 - check what all import statement is there
286:52 - just a
286:54 - wait time Delta also we can import from
286:57 - here itself so this is going to be a
287:00 - time Delta great now let me run it and
287:04 - over here you will find out a detail see
287:07 - so actually what we are going to do uh
287:10 - this function actually uh you can think
287:13 - it's a it is working as a API got it now
287:17 - here what we are going to do so we are
287:18 - extracting a information from the uh
287:21 - like whatever prompt and all we are
287:22 - passing now so from there basically we
287:24 - are extracting an information and we are
287:26 - collecting a detail of the flight okay
287:28 - from U like this is the response
287:30 - actually see first what I did I defined
287:32 - a function this is what this is my
287:33 - function
287:35 - this is what this is my function right
287:36 - after that we are calling the uh after
287:39 - that we are hitting to the uh like model
287:41 - by by using this open API now after
287:44 - hitting it so actually whenever we are
287:47 - checking with a response so in argument
287:49 - actually in a function argument we have
287:50 - this two thing now by using this two
287:52 - thing now what we are going to do so we
287:54 - are uh like extrating the information
287:57 - from here so as of now this is this
287:59 - function actually you can think it's my
288:01 - API but you can call actual API by using
288:04 - this particular information that is what
288:06 - I'm doing over here just just think over
288:07 - here that is what I'm doing so now what
288:09 - I did what I got tell me guys so I I
288:13 - collected the information whatever see I
288:15 - Define the thing inside my function
288:18 - inside this particular function okay
288:19 - this one this is the value this is the
288:21 - like parameter which I defined now I uh
288:24 - I like called my model I called my open
288:26 - API and it is hitting the model right so
288:29 - whatever response I'm getting now from
288:31 - that particular responses I'm getting
288:33 - this particular argument because my chat
288:36 - GPT is not able to answer for this
288:37 - particular question and by using this
288:39 - argument I'm hitting my API I'm hitting
288:42 - my API and after hitting the API guys
288:45 - you can see this is the detail this is
288:47 - the information I'm
288:49 - getting okay by using those particular
288:51 - argument now let me show you the
288:53 - complete one so once we are getting this
288:55 - particular information the flight
288:56 - information regarding those particular
288:58 - argument okay you can create an end
289:00 - application here I'm showing you in a
289:01 - notebook itself so here see guys what
289:04 - I'm getting now give you the final code
289:06 - so we are getting this particular
289:07 - information and is done now let me uh go
289:12 - for the final call so here you can see
289:16 - uh I can keep it as a uh response three
289:18 - client chat completion create now here
289:21 - is what here is my model and here is
289:23 - what here is my user prompt whatever
289:24 - prompt I I'm passing now see guys over
289:26 - here see role is what role is a function
289:29 - now I have changed the role okay uh here
289:31 - is a role role is a user now role is a
289:33 - function function now this is the value
289:35 - I'm extracting from the function
289:37 - whatever function I'm defined and here
289:39 - is what here is a like content basically
289:41 - which I'm passing this is what this is a
289:42 - flight right so this is the argument
289:44 - which we are extracting from the
289:46 - function whatever function I have
289:47 - defined right and then this is what this
289:50 - is my function description that's it
289:51 - right so here see guys uh my role role
289:54 - as a user as a role as a user basically
289:56 - what I'm asking to my uh chat GPT or
289:58 - sorry to my GPT model let me show you
290:01 - that so over here what I'm going to do
290:03 - I'm going to print it this user prompt
290:05 - this is my question this is my prompt
290:07 - this is what basically which I'm going
290:08 - to ask right now over here roll again I
290:11 - Define one more role that is what that
290:13 - is a function right now over here I'm
290:15 - going to pass the name and here I'm
290:17 - going to extract the like function the
290:20 - the ex exact function over here you can
290:22 - check over here you can like copy it and
290:25 - you can paste it over here this one so
290:28 - just just paste and you will get this
290:30 - function called now just collect the
290:32 - name name of the function do name so
290:34 - what is the name of the function get
290:36 - flight info right now here is what
290:38 - content is nothing content is a flight
290:40 - now as soon as I will run it so here you
290:42 - will be able to find out that we are
290:44 - able to extract the information now let
290:47 - me show you this response three so here
290:49 - is what here is my response three and
290:51 - guys see what I'm getting over here so
290:54 - let me print the final one and here you
290:58 - will be able to find out a detail so let
291:01 - me run it see guys so now let me call
291:05 - the uh this uh function call just a
291:09 - second function uncore
291:13 - call function _ call and over here guys
291:16 - you can see we have argument and
291:19 - actually we have a message over there
291:20 - just a wait let me show you that
291:23 - also uh function call and
291:26 - argument okay just a
291:31 - wait oh message inside the message
291:33 - message itself I will be able to get it
291:36 - uh where my message is coming inside a
291:40 - choice and
291:42 - here okay I need to call a Content
291:44 - actually just a
291:49 - second message function call this is my
291:52 - function call that is fine now here
291:55 - Choice uh just a second choice what we
291:58 - have inside a
292:00 - choice okay it is a response three fine
292:03 - fine fine I was checking with a response
292:05 - two uh yeah this was a response now it
292:08 - is fine it was a response three I was
292:10 - checking with a response two it's my bad
292:12 - it's my bad uh okay now let me collect
292:16 - the message from here so here is what
292:19 - here is a zero and
292:22 - uh now let me call this
292:28 - message so here is my message and let me
292:31 - collect the content
292:35 - tent and here is what here is my content
292:39 - guys so did you get it what is the use
292:41 - of this function calling now let me give
292:43 - you the definition of this function
292:45 - calling in a single line so just a wait
292:48 - I'm giving you the definition definitely
292:50 - you will be able to relate now so if we
292:52 - are talking about this function calling
292:54 - now so here is a definition of it let me
292:58 - copy and paste so what is our definition
293:00 - of the function calling so function
293:02 - calling is nothing learn how to connect
293:05 - large language model to the external
293:07 - tool that's it we can define a function
293:10 - we can Define the parameters we can
293:13 - Define the values and according to that
293:15 - we can get our responses from the third
293:17 - party API and here I have defined this
293:20 - particular function M function is a
293:22 - third party API but you can call the
293:24 - realtime API and you can get the
293:28 - information you can get the exact
293:31 - information this thing is clear to all
293:34 - of
293:35 - you yes or
293:38 - no how many of you you are able to get
293:41 - it how many of you you are able to
293:43 - understand this thing if you can let me
293:45 - know in the chat so I think that would
293:47 - be great again I will try to revise it
293:49 - uh I will give you the quick revision of
293:51 - it and then I will move to the link
293:56 - chain will you revise it please do let
293:59 - me know in the chat will you revise this
294:02 - concept
294:08 - I'm waiting for a reply if you can
294:09 - answer me in the chat I think that would
294:11 - be
294:32 - great
294:35 - yes I'm going to revise it just wait
294:37 - just give me a second first of all uh do
294:39 - let me know how much person you got so
294:42 - if you can tell me uh in a percentage
294:43 - also so that would be great I will get
294:45 - some sort of idea that okay you are
294:47 - getting something from here whatever
294:49 - code I'm writing you're getting from
294:50 - here so please uh do let me
295:02 - know 80%
295:11 - great 70 70
295:16 - 80 yeah if you're getting 70 or 80% now
295:19 - so I think rest of the thing like you
295:21 - just need to revise Sor is saying sir
295:23 - I'm just getting 10% so Sor in that case
295:26 - you need to follow from a very first
295:28 - session just check with the very first
295:30 - session and then come to the second one
295:32 - and then come come to this third
295:39 - one if you are near to 70 to 80% now
295:43 - then you just need to revise it once
295:44 - that's
295:48 - it yes correct uh your understanding is
295:52 - correct here we are extracting value
295:54 - from given prompt using function
296:02 - call
296:11 - what is the meaning of the role is equal
296:12 - to function which
296:15 - one here we are defining now see we have
296:18 - a user so user is asking a question and
296:20 - rest of the information we are going to
296:22 - collect from here we are defining one
296:24 - more role we have we can Define many
296:25 - roles over here um we can Define uh like
296:29 - uh we can Define the system we can
296:30 - Define role as assistant we can Define
296:32 - role as a user user we can Define role
296:34 - as a
296:35 - function user is asking something and uh
296:38 - and uh from wherever basically we are
296:41 - going to be get output or we are getting
296:43 - a uh we are we trying to exct the
296:45 - information regarding this particular
296:47 - prompt so we are defining as a rle over
296:49 - here that's
297:00 - it great so let's revise it now and then
297:03 - I will go for the Len chain so we'll try
297:05 - to understand the langen chain and all
297:06 - already I have installed this L chain
297:08 - and try to hit the open API and tomorrow
297:11 - we'll understand the lch in a very
297:13 - detailed way uh today uh just a quick uh
297:17 - understanding quick uh uh first of all I
297:19 - will give you the quick recap of all
297:21 - those all this thing and then I will
297:23 - come to the lon part so let's understand
297:27 - this function calling one more time from
297:32 - scratch
297:39 - great so over here see we are talking
297:42 - about this uh we are talking about this
297:43 - chat completion API and I think you know
297:46 - about it how many time we have discussed
297:48 - so we're passing the prompt here is my
297:50 - prompt and we are getting the output now
297:52 - Today I Started from the like a
297:55 - different type of prompt so uh today I
297:57 - have started from the function calling
297:59 - so here I have defined one description
298:01 - and here I'm writing uh the prompts my
298:04 - prompt is saying that uh here you need
298:06 - to extract this information from the
298:09 - given description that's it now here you
298:12 - can see uh this is my client this is
298:15 - what this is my client now here I'm
298:17 - going to call my chat GPT and sorry I'm
298:21 - going to call my GPT model so after that
298:23 - what I'm getting I'm getting my response
298:25 - I'm going to convert into a Json and
298:26 - this is fine right this is fine anything
298:28 - you can ask to your model and you can
298:30 - print as a response you just need to
298:32 - define a prompt that that's it now here
298:35 - the same thing I'm going to do by using
298:36 - this function so here I'm going to do uh
298:39 - the same thing by using this function
298:41 - now here I'm going to define a several
298:43 - parameter so this is my parameter name
298:45 - College grade and Club it should be a
298:47 - same similar to this prompt itself
298:49 - whatever prompt I have defined I have
298:50 - written right so just look into the
298:52 - prompt I will share this notebook then
298:54 - you can check it should be similar to
298:55 - that only this particular properties
298:58 - this particular values now over here uh
299:01 - you will find out that okay I again I'm
299:03 - going to call it again I'm working I'm
299:06 - like role I've defined as a user there's
299:07 - a Content prompt and you are getting a
299:10 - response and here you are getting a
299:12 - response now guys here you can see we
299:15 - are going to print a message and finally
299:16 - we are getting a same thing by calling
299:18 - this uh by using this function call as
299:21 - well now here actually once you will
299:22 - look into the prompt we have defined one
299:24 - thing over here we we are saying that uh
299:27 - return it as a Json object return it as
299:30 - a Json object so whatever response you
299:32 - are getting now from from the openi side
299:34 - also I tested the same thing of the CH
299:36 - GPT see I given the description this was
299:39 - my description and CH GPD has given me
299:41 - output is a Json format so if you are
299:44 - calling it now uh this uh like a GPD
299:47 - model so it will give you the output in
299:48 - a Json format this one so here it is
299:51 - giving you the output this particular
299:52 - output in a Json format this one
299:54 - actually it's a string but yeah we can
299:56 - convert into a Json and that is what I
299:57 - did now the same thing why we are doing
299:59 - by using this function now over here H
300:01 - it's fine it's clear now here I've given
300:03 - you a few more uh like functionality
300:05 - regarding this function I can call it
300:07 - for the several description in a single
300:10 - sort I just need to keep the for I just
300:11 - need to write down the for Loop over
300:13 - here so I'm getting a multiple responses
300:15 - for sun for Chris for sansu right so
300:18 - here I'm getting a multiple responses
300:20 - now here I given you an assignment so
300:23 - here I told you that you can call a
300:25 - multiple function also don't call a
300:27 - single function here I'm getting an
300:28 - information from the single
300:30 - function but you can call a multiple
300:32 - function and here I shown you the way
300:34 - you just need to define a function in a
300:36 - list and that's it so here is a function
300:39 - you just need to define a function in
300:40 - the list and just pass it over here and
300:42 - according to that only you will get a
300:44 - response getting my point now here I've
300:47 - shown you the advanced example of
300:49 - function calling and that's a real use
300:50 - of the function and here if you want to
300:52 - Define this function in a single word in
300:54 - a single line if you want to understand
300:56 - this function in a single line so here
300:58 - you can see this is the definition learn
300:59 - how to connect large language model to
301:02 - the external tool
301:03 - so here what I want to do so here let's
301:05 - say uh this is my model and here I'm
301:10 - going to write down some sort of a
301:12 - prompt where uh like it is going to be a
301:15 - request and here I'm getting a response
301:18 - now this prompt actually it's something
301:20 - uh related to a real time I'm asking a
301:23 - real time question that just give me the
301:25 - flight just tell me like what all
301:27 - matches uh we have in upcoming days or
301:31 - uh just tell me the weather okay
301:33 - something like that so I'm asking a real
301:35 - time information it won't be able to
301:36 - provide it to me in that case what you
301:39 - will do so you are not going to call
301:41 - your llm now because it is not trained
301:45 - on that uh on it it has not been trained
301:48 - on top of that data actually if you are
301:51 - talking about this GPT so this GPT
301:53 - actually train on this uh till actually
301:55 - till September 2021 so this GPD train
301:59 - till uh 2021 only now in that case
302:02 - whatever prompt you are going to be
302:03 - write it down you won't be able to get a
302:05 - response right so here this function
302:08 - calling comes into a picture so once you
302:10 - will Define the function now so here
302:13 - what you will do you are going to define
302:14 - a function you are going to different
302:15 - Define a different different arguments
302:17 - and all each and every information you
302:18 - are passing to this function that's it
302:21 - now you just need see here this argument
302:24 - what you will do by using this
302:26 - particular argument you will call a
302:27 - third party API third party API
302:34 - third party API now you will call this
302:36 - third party API here or whatever
302:39 - function you are going to Define and
302:41 - whatever prompt you are writing
302:42 - according to that you will get a
302:43 - response because this llm is not able to
302:45 - provide you the response right and the
302:48 - same thing the each and everything you
302:49 - can do by using the chat completion API
302:51 - only chat completion method you can say
302:54 - chat completion API or chat completion
302:55 - method both are fine by using this chat
302:57 - completion method now let me show you in
302:59 - terms of coding so over here if you look
303:03 - into the code so I'm doing the same
303:04 - thing here I have defined a function see
303:07 - this is what
303:08 - uh first of all I'm asking to my first
303:11 - of all I'm asking to my uh llm model it
303:14 - is not able to answer now after that
303:17 - what I did I defined the function got it
303:20 - after that I defined a prompt I'm
303:21 - passing to my model I'm passing to my
303:25 - actually uh this uh like chat completion
303:27 - method so here is my user here is my
303:29 - prompt and here is my function
303:30 - description by doing that what I'm able
303:32 - to do I able to extract few of the uh
303:35 - few value whatever is there inside this
303:37 - function whatever I have defined over
303:39 - here because here I'm writing in this
303:40 - function description now after that this
303:43 - value I'm using and this is what this is
303:45 - my API okay this this is my like it's
303:47 - not a real API it's like a virtual API
303:50 - whatever you can say now whatever value
303:52 - I'm passing whatever uh thing I'm
303:54 - collecting from here I'm passing to this
303:55 - API and I'm getting a response over here
303:58 - this is the response this is my
304:01 - response got it now what I will do here
304:04 - now I compiled each and everything over
304:05 - here inside this chat chat completion
304:07 - method so how I compile this is my model
304:10 - this is my prompt this is my user this
304:12 - is my prompt this is my function call
304:14 - this is my function call along with the
304:17 - argument and over here this is my
304:19 - function that's it if I'm going to run
304:21 - it now it is going to extract the
304:23 - information from the third party API
304:25 - which is my function as of now now you
304:27 - can take as assignment you can call the
304:29 - real time API you can use the rapid API
304:31 - you can do that you can call a real time
304:33 - API so now this function calling is
304:36 - clear to all of you yes or
304:42 - no correct ran your understanding is
304:44 - correct
304:48 - now your understanding is correct and I
304:51 - think you are able to get
305:00 - it now let's start with the length chain
305:03 - so we have a a 10 minute uh now we can
305:06 - understand the concept of the length
305:08 - chain and then from Tomorrow onwards I'm
305:11 - going to start with the Len chain now
305:13 - first of all let me write it down the uh
305:16 - code for the Len chain so here I'm going
305:18 - to write it down Len CH and here uh you
305:23 - can I can mark down it and uh so first
305:27 - of all guys what I need to do so I'm
305:28 - going to start from the Len chain uh so
305:31 - the first thing very first thing uh I
305:33 - need to import it so let me give you the
305:35 - entire code okay so step by step let me
305:38 - write down each and everything so first
305:39 - of all I have to import the Len chain so
305:42 - here I'm going to write it down import
305:44 - length
305:45 - chain now here I have imported the Len
305:48 - chain now from this like in this lure
305:50 - actually we have a different different
305:51 - modules we have a different different
305:53 - module and inside that we have a
305:54 - different different classes so as of now
305:56 - we are going to use the open AI so here
305:59 - I'm going to write it down from Len chin
306:01 - from Len
306:03 - we are going to import this open AI so
306:07 - lenin. llms and here I'm going to write
306:09 - down this open AI okay so we are able to
306:12 - import this open AI now what I will do
306:16 - so initially I told you that this lenon
306:19 - is nothing it's a wrapper on top of this
306:21 - open AI so you can think that this is my
306:24 - open AI right this is what this is my
306:27 - open AI now on top of this open a on top
306:30 - of this open API this lench is nothing
306:32 - it's a
306:35 - wrapper okay so this is what length
306:37 - chain now here whatever request we are
306:40 - making whatever request we are making
306:43 - right so now we are not directly using
306:45 - this open a now we are not directly
306:48 - using this open API instead of that we
306:52 - are using this L chain so our request is
306:54 - going through to this a len chain and
306:57 - then it is hitting this open AI but this
307:01 - Len chain it is not restricted to till
307:03 - here itself we have a many uses of the
307:06 - Len
307:07 - chain getting my point this Len chain is
307:10 - not restricted to this one only we have
307:12 - a many uses of the link chain I will
307:15 - talk about those uses and this Len chain
307:17 - actually it's a very powerful uh it's a
307:20 - very powerful application it's a open
307:22 - source I will show you the source code
307:23 - as well uh even we can search about it
307:25 - so let me show you that uh let me show
307:27 - you the source code of the Lenin so here
307:31 - I'm going to write it down Len Chen Len
307:34 - Chen GitHub so here is what guys here is
307:37 - a len Chen GitHub uh just a second yeah
307:42 - so this is a lenion GitHub now you will
307:44 - see the number of folks the number of
307:46 - star number of folks number of start
307:49 - number of watching right so number of
307:51 - watching in a real time and this length
307:53 - chain is really amazing let me give you
307:55 - this link inside your chat please try to
307:58 - uh explore it by yourself and it's a
308:01 - very uh Power powerful and very
308:03 - important as well if you want to build
308:04 - any llm based application so you can use
308:08 - this length chain it's a it's completely
308:10 - op source and here you can see used by
308:12 - 40,000 people and here is a number of
308:15 - contributor you can also become a
308:16 - contributor if you like to contribute in
308:19 - a open source now here you can see the
308:20 - commits 7 hour ago they committed
308:22 - something just just go through with this
308:24 - commits and check what thing they have
308:26 - committed what what changes they have
308:28 - made over here try to understand it and
308:30 - this package actually it is available on
308:32 - the pii repository so just go over the
308:35 - pii repository pii Len chain and search
308:38 - about the Len chain and here you will
308:40 - find out this Len chain this is what
308:42 - this is a len chain guys this is a like
308:44 - they have hosted the package on pii
308:46 - repository and it is a latest version of
308:49 - The Lang chain now here also just just
308:51 - uh scroll down here also you will find
308:54 - out the same thing
308:55 - uh deployment so they are doing a deploy
309:00 - here is a package package see this is
309:02 - the release so 0.0.3 46 0.0.3 46 this is
309:07 - the latest uh version which you can see
309:10 - over here as well this one is uh so far
309:13 - they did 297 release total 297 release
309:18 - see this is the total release actually
309:19 - total number of release now you can see
309:21 - over here as well just go inside the
309:23 - real uh just go just click on this
309:25 - release history and check the uh entire
309:28 - uh like release related to the length CH
309:31 - got it right so here is a latest version
309:34 - of the Len chain similarly we have a
309:36 - llama index two also and this Len chain
309:39 - is a open source and the Llama index 2
309:41 - it's a framework from The Meta we can do
309:44 - a same thing by using this llama index 2
309:46 - also I will come to that I will come to
309:48 - the Llama Index right now over here see
309:51 - we have this Len chain we have this
309:52 - openi now let's try to create now let's
309:54 - try to create object of this open Ai and
309:57 - here what I need to do guys tell me here
309:59 - I'm going to here I'm going to pass pass
310:02 - my open a key so first of all uh I will
310:05 - have to pass the parameter now let me um
310:08 - give the parameter over here and here I
310:10 - need to write it down this my key and
310:13 - here is what here is my client right now
310:16 - I just need to call one method and my
310:18 - method is going to be a predict right so
310:21 - my the method name is going to be a
310:22 - predict so let me write it down over
310:24 - here Cent c l i n t dot predict now here
310:27 - what I need to do here I just need to
310:29 - pass the prompt prompt is what prompt is
310:32 - a input whatever input we are passing to
310:34 - the model that's it so let me Define The
310:36 - Prompt so here I'm going to write it
310:38 - down the prompt and this prompt let's
310:40 - say I'm going to ask to my model what I
310:42 - can ask so I can ask can you tell
310:46 - me
310:48 - total number of country total number of
310:53 - country in Asia so here is my question
310:56 - so I just asked a little tricky question
310:59 - not a tricky actually it's a
311:00 - straightforward so uh here is my
311:02 - question my question is what my question
311:03 - is can you tell me total number of
311:05 - country inia now this is called guys
311:07 - zero short prompting what is this tell
311:09 - me this is called zero short
311:13 - prompting this is what guys tell me this
311:15 - is a zero short prompting now here if I
311:17 - will run it and here if I will pass my
311:19 - prompt to My Method client don't predict
311:22 - so here you will get output so here it
311:24 - is saying that there are 48 country in
311:27 - Asia if you would like to uh if you want
311:30 - to name then here you can mention
311:32 - can you give me can you give
311:37 - me top
311:40 - 10
311:42 - country name so here uh I have extended
311:46 - the question now and now see over here I
311:49 - will be getting a name of the country so
311:51 - it is giving me the sash slash sash is
311:54 - nothing it means it means that if I'm
311:56 - going to print it now so it will print
311:57 - after two line so for that what you can
312:00 - do you can just call this a strip
312:02 - SD and it will strip your output so here
312:05 - you will find out the correct output so
312:08 - there are 48 continer isia the top 10
312:11 - country by population in Asia these are
312:13 - the country now here if I'm going to
312:15 - write it on print so you will get a
312:17 - output in a correct format so here guys
312:19 - you can see you will get output in a
312:22 - correct format so there are total 48
312:24 - country in Asia and these are the top 10
312:26 - countries China India Indonesia Pakistan
312:28 - Bangladesh Japan Philippines Vietnam
312:31 - Iran and turkey got it guys how to use
312:34 - lch I just given you the introduction of
312:36 - that but there are many more things so
312:39 - all the things uh uh the remaining thing
312:41 - definitely we are going to discuss in
312:43 - next session as of now just think that
312:45 - this uh lench is nothing it's a rapper
312:48 - on top of the open AI but it is having a
312:50 - lots of uses it can call any third party
312:53 - API it can call any sort of a data
312:55 - resource it can uh like uh it it it is
312:58 - having a power to read a different
313:00 - different documents it's a having a
313:02 - power to making a change to making a
313:05 - memory it is having a power it is uh it
313:08 - is not only for the open AI we can use
313:12 - this lenen for any open source model any
313:15 - open source llm model and tomorrow I
313:18 - will show you here I have used so let me
313:21 - write down tomorrow's agenda what all
313:22 - thing we are going to discuss tomorrow
313:26 - tomorrow uh tomorrow's
313:29 - agenda so we are going to uh cover
313:33 - hugging phase hugging phase API with Len
313:38 - chain uh and we'll try to understand the
313:41 - use of the Len chain use of the length
313:43 - chain so we'll try to understand this
313:45 - use of the Len chain in very
313:48 - detailed way so this will be the agenda
313:52 - for tomorrow's uh like this this is the
313:54 - agenda for tomorrow's class and after
313:56 - that I will directly jump to the project
313:59 - we try to create one project and with
314:01 - that your understanding will be clear
314:03 - and rest of the topic we'll cover after
314:06 - uh after the project and all so tell me
314:09 - guys how was the session did you like
314:11 - this session uh did you uh did you got
314:14 - everything yes or no whatever I have
314:18 - explained yeah meanwhile you can explore
314:20 - it by yourself that is a good
314:22 - idea tell me guys fast uh did you like
314:25 - the session please do let me know in the
314:27 - chat if you are liking the session if
314:29 - you're liking my content I have WR and I
314:32 - I created each and everything from
314:33 - scratch by myself only and believe me if
314:35 - you are following this notebook if you
314:37 - are following my content you won't face
314:39 - any
314:40 - issue and even in our interview also you
314:42 - can answer in a better
315:00 - way
315:04 - okay so I think uh now uh we have
315:08 - covered all the thing whatever I told
315:11 - you and uh yeah all the resources and
315:14 - all you can find it out over the
315:16 - dashboard so we are uploading each and
315:18 - every resources in a resource section so
315:21 - just visit the dashboard and here uh we
315:24 - have all the videos videos and quizzes
315:27 - assignment each and everything we are
315:28 - going to update over here so along with
315:30 - the session you can and practice now
315:33 - here uh we have our resources regarding
315:36 - the first session so all the all the PDF
315:39 - and all all the PPT so at least you can
315:42 - revise the thing you no need to go
315:43 - through with the video again and again
315:45 - you can directly uh download the
315:46 - resource and you can look into that if
315:48 - you have attended my live session and
315:51 - here we have a IPO NV file also so just
315:55 - visit this uh resource section and this
315:58 - is the IP VB file now I will update this
316:00 - IP VB file in my day three video and
316:03 - along with that we'll be having some
316:05 - quizzes assignment and don't worry I
316:06 - will give you more assignment more
316:08 - quizzes and see in between whatever I'm
316:10 - leaving so here I told you that you need
316:13 - to create your own API this one uh in an
316:15 - advanced example of function calling so
316:18 - just use any API okay just search over
316:20 - the internet I told you you can use
316:22 - Rapid API and try to get a realtime data
316:25 - instead of this uh dummy function which
316:27 - I created over here you can take it as
316:29 - assignment here I told you that you need
316:32 - to you can use multiple function right
316:34 - in a single shot just try to create one
316:36 - more function define it in your in your
316:38 - own way and then uh run it and uh get an
316:41 - information so here I'm getting an
316:43 - information regarding three user you can
316:45 - add more user and you can add multiple
316:48 - function over there so now let's start
316:50 - let's begin so in the previous classes
316:53 - uh in the uh previous three classes
316:55 - actually I have talked about the
316:56 - generative Ai llm and then I came to
316:59 - this open Ai and yesterday I have I did
317:01 - the detailed discussion on top of this
317:03 - open Ai and I have introduced the Len
317:06 - chain to all of you uh so guys this is
317:08 - the notebook inside this notebook I have
317:10 - kept each and everything whatever notes
317:12 - whatever code and all whatever thing I
317:14 - was doing all right so uh in terms of
317:17 - code and all so each and everything I
317:18 - have kept inside this particular
317:20 - notebook and this notebook is available
317:22 - inside your resource section so from
317:24 - where you will get a resource guys so
317:26 - for for that uh you need to go through
317:28 - with the dashboard so here is your
317:29 - dashboard here you will find out uh here
317:32 - you will find out all the recordings U
317:35 - Day One recording day two recording day
317:36 - three recording so just try to go
317:38 - through with the day three you just need
317:40 - to click on the uh day three and here uh
317:44 - check with the resource so go inside
317:46 - your resource section and this is the
317:48 - dashboard guys generative AI Community
317:51 - Edition English so here you will find
317:53 - out uh two dashboard uh the two
317:55 - Community dashboard one for Hindi and
317:57 - one for English so this is for the Hindi
317:59 - one U actually I'm taking a same classes
318:01 - on a Hindi uh Channel as well I on Hindi
318:05 - I on teag Hindi you can search over the
318:07 - uh YouTube and the uh it's it is your
318:10 - one this English one so just go and
318:12 - check with your dashboard you will find
318:14 - out all the recordings and all so click
318:17 - on this day three and here check with
318:19 - your resource section so okay so
318:21 - resources is not there I have already
318:24 - given to my team but don't worry I will
318:27 - check and here is what guys here is a a
318:29 - notebook so uh definitely I will provide
318:32 - you this particular notebook inside the
318:34 - resource section so you all can run it
318:37 - you all can run it and by running it you
318:39 - can uh revise the thing and all and
318:41 - apart from uh this notebook apart from
318:44 - this resources you will find out the
318:45 - quizzes and assignment also so please
318:47 - try to enroll to this dashboard try to
318:50 - visit the Inon website sign up over
318:51 - there login and then uh enroll into this
318:54 - community session for this commun
318:56 - session you no need to pay anything it's
318:59 - just it's a free one okay so just just
319:02 - go through with the Inon website and
319:03 - login um after sign up do the login and
319:06 - you can access this particular dashboard
319:08 - and you will find out the same dashboard
319:10 - in a description also so just just try
319:12 - to check the description of this video
319:14 - of this live section you will find out
319:15 - the dashboard or else you can check with
319:17 - the previous Live recorded session also
319:19 - which is already available on the over
319:21 - the Inon YouTube channel got it so this
319:24 - uh resource uh part is clear to all of
319:26 - you now in today's session what all
319:29 - thing we going to discuss so guys first
319:30 - I will will start from the Len chain
319:33 - first I will explain you the complete
319:34 - Len chain that what is a len chain what
319:36 - all things we have inside the Len chain
319:39 - why we should use it why it is too much
319:41 - powerful each and everything we'll try
319:43 - to discuss regarding the Len chain and
319:46 - after that I will come to this hugging
319:47 - phase I will explain you that how you
319:50 - can uh how you can use any any like open
319:53 - source model from the hugging face Hub
319:56 - got it yes or no so in the previous
319:58 - class I told you that whatever model
320:00 - whatever model is there over the open AI
320:02 - platform how you can use that by after
320:04 - generating a API key now in today's
320:06 - session after discussing this lench I
320:09 - will come to the hugging phas and I will
320:10 - show you I will show you that after
320:12 - generating a API key hugging face API
320:15 - key how you can utilize that particular
320:17 - model so each and everything uh we'll
320:20 - talk about in today's session uh
320:22 - whatever I have told you and after that
320:24 - we'll start with the project so in
320:25 - tomorrow's session or maybe day after
320:27 - tomorrow so I will start with the
320:29 - project end to end project I will use
320:31 - this openi concept hugging face concept
320:33 - linkchain concept and I will uh show you
320:36 - that how you can create a web
320:38 - application end to end web application
320:41 - and then we'll come to the advanced part
320:43 - like vector databases and some other
320:45 - topic so I think uh everything is fine
320:48 - uh the agenda is all clear uh so please
320:51 - give me a quick confirmation in the chat
320:52 - if we can start then and whatever I have
320:54 - explain you whatever I have explained
320:57 - you so far so it is clear or not so
320:59 - please do let me know in the chat uh if
321:01 - it is clear and if we can start then I'm
321:04 - waiting for your
321:30 - reply
321:35 - fine so I got the answer now great so
321:39 - let's start uh let's start with the
321:41 - topic so in this uh uh notebook itself
321:44 - I'm going to write it down the entire
321:46 - code uh of the Len chain so whatever
321:48 - thing is there regarding the Len chin I
321:50 - will try to do here itself and whatever
321:52 - thing uh things will come into the
321:54 - picture uh whatever other libraries and
321:56 - all so definitely we'll try to install
321:58 - all those library in the current virtual
322:01 - environment now here guys uh I told you
322:04 - that how to create an environment how to
322:06 - uh launch the Jupiter notebook how to
322:08 - install the openi over there how to uh
322:10 - like install the langen each and
322:12 - everything I have discussed in my
322:14 - previous session so if you don't know
322:15 - about it so please go and check with my
322:17 - previous session there I did a detailed
322:19 - discussion regarding the environment
322:21 - setup got it now here guys um already I
322:24 - have written some sort of a line some U
322:26 - like sort of a quotee for the L chain
322:28 - yesterday actually I I like uh I was uh
322:31 - I I have imported the Lenin and I have
322:33 - used the key the openi key and basically
322:36 - I have imported this openi class and I
322:39 - created a object then I uh written a
322:41 - prompt over here and here I was uh like
322:45 - giving this prompt to my open API and in
322:48 - the back end it was running the llm
322:50 - model and here you can see this is what
322:52 - this is my output got it now here I I
322:56 - had written actually this this this is
322:58 - the today's agenda whatever thing we are
322:59 - going to discuss in today's session so
323:01 - hugging face API use of Lang CH and all
323:04 - so each and everything we'll try to do
323:06 - here itself in the uh in today's class
323:08 - itself so first of all let me write it
323:10 - down each and everything over the
323:12 - Blackboard so with that you will get a
323:14 - clear-cut understanding regarding the
323:16 - agenda and all that whatever the thing I
323:18 - am going to discuss and after that I
323:20 - will come to the code part code section
323:23 - so let's start uh with the agenda now in
323:25 - today's class guys we'll be talking
323:27 - about the Len chain so let me write it
323:30 - down over here in today's session we're
323:32 - going to start with the Len chain now
323:35 - what is a len chain why we use Len chain
323:38 - and what is a difference between this
323:40 - open a and this Lenin so each and
323:42 - everything we'll be discussing over here
323:43 - itself now the first thing the first
323:45 - thing which we going to discuss in the
323:47 - Len Chen the first thing how to use Len
323:49 - Chen or how to use open a uh how to use
323:56 - how to use open AI by a lang chin so how
324:00 - to use open AI via Len chain that's the
324:04 - first thing we'll try to discuss got it
324:07 - after that I will come to the prompt
324:08 - template prompt uh templating so how you
324:11 - can do a prompt templating by using this
324:13 - Len chin so the second thing the second
324:15 - topic which we're going to talk about
324:17 - that will be a prompt
324:19 - templating promp templating the third
324:22 - thing which we're going to discuss
324:23 - inside the Len chain that will be chains
324:26 - we'll talk about the chains that what is
324:28 - a chains uh how we can utilize this
324:30 - chains what is the meaning of the chain
324:32 - how uh what all the different different
324:34 - type of chains is there each and
324:36 - everything we talk about over here then
324:38 - we'll talk about the agents that what is
324:40 - the
324:43 - agents okay so we'll talk about the
324:45 - agent that what is the agent and what we
324:47 - can do by using this agent so each and
324:50 - everything we'll try to discuss
324:51 - regarding this agent and here if uh so
324:54 - here I will show you that how you can
324:56 - use the Google API so by using the Sur
324:59 - API so what I will do so by using the
325:02 - surp
325:03 - API I will try to I will try to use the
325:07 - Google API Google API Google search
325:12 - API so in the agent section I will
325:15 - explain you this particular thing and
325:17 - after the agent the fifth one the fifth
325:19 - topic which we're going to discuss
325:21 - that's going to be a memory so we'll let
325:24 - you know that how we can retain the
325:26 - memory how we can retain the memory like
325:29 - chat GPD is doing how we can do the same
325:31 - thing if we are using this open API so
325:35 - we will try to discuss this memory uh
325:37 - memory part as well and which is a uh
325:40 - like which is available over here inside
325:41 - the lench and by using this Len Chen we
325:43 - can implement this particular feature
325:46 - after this memory I would come to that
325:48 - uh document loader so uh how we can load
325:51 - our different different type of
325:52 - documents so document is nothing
325:54 - documented just a file like PDF file CSV
325:57 - file tsv file or any other file how you
326:00 - and load that particular document so
326:02 - we'll talk about a document loader as
326:05 - well so here let me write it down
326:07 - document
326:11 - loader after completing all these thing
326:15 - then I will come to this hugging
326:16 - phase hugging phase I will show you how
326:20 - you can I will show you that how you can
326:23 - uh generate a hugging face API key
326:25 - hugging face API token and how you can
326:27 - utilize any sort of a model whatever
326:30 - model is is there over the hugging face
326:32 - Hub so how you can use that particular
326:34 - model so I will talk about the hugging
326:36 - face after that and finally we'll move
326:38 - to the project section so uh this is the
326:40 - agenda for today's session for today's
326:42 - class and apart from this each and
326:45 - everything I have explain you how to
326:47 - generate a open key how to uh like use a
326:50 - open a what is chat completion what is a
326:52 - function calling and all even I have
326:54 - talked about the basics of the langen as
326:56 - well so if this part is clear to all of
326:59 - you so please do let let me know in the
327:01 - chat if till uh like if the agenda is
327:04 - clear so I just want quick yes in the
327:06 - chat and please do let me know how many
327:09 - of you you are writing a code along with
327:11 - me because today I will go a little slow
327:13 - so you also can write it down the code
327:15 - along with me please do let me know guys
327:18 - please write down the
327:29 - chat
327:43 - good I think many of you you are writing
327:46 - a code
327:51 - mhm uh just a wait just uh give me a
327:59 - second
328:04 - fine so let's start with the uh agenda
328:07 - now so here guys you can see I have
328:09 - written a agenda and first of all uh let
328:12 - me explain you that what is a len chain
328:14 - why we are not using this openi API why
328:17 - we are using this Len chain and uh why
328:20 - it is too much important this Len chain
328:22 - and this llama index to so first of all
328:24 - let me talk about uh the differences
328:26 - between this open Ai and this Len chain
328:29 - and then I will come to the
328:30 - implementation part so here uh first of
328:33 - all let me write it down the limitations
328:35 - of the chat
328:36 - GPT sorry limitations of the open a
328:40 - API uh limitations of open AI
328:49 - API now here guys see uh if we are
328:51 - talking about this open API so here you
328:54 - won't be able to find out a free model
328:57 - so the first thing actually the first
328:58 - thing uh in the limitation uh like which
329:01 - we are going to talk about so here open
329:03 - a model is not a free one so here let me
329:06 - write it down open AI model open AI
329:10 - model open AI model is not a
329:13 - free now let's see uh let's assume that
329:17 - okay so the model is not a free one and
329:20 - if I want to use the llm uh like if if I
329:23 - want to use the llm capability or that
329:25 - AI capability in my application I if I
329:28 - don't have a budget so what I will do I
329:30 - will go with the other option other free
329:33 - option open source
329:34 - option okay so let's say some XYZ
329:37 - organization some XYZ organization
329:40 - created one llm now I want to use this
329:44 - particular llm so yeah definitely what
329:47 - you can do you can use the uh API
329:49 - whatever API this XYZ company has given
329:51 - to you and by using that particular API
329:54 - you can use this particular llm right
329:56 - now let's say you don't want to use this
329:58 - llm you want to use some other llm
330:01 - now how you will access it by using the
330:04 - different API now let's say if you want
330:05 - to use some other llm whatever llm is
330:07 - there let's say uh one LM is over the
330:10 - hugging phas Hub right if you want to
330:12 - use that particular llm large language
330:14 - model from the hugging phase right if
330:16 - you want to use it then definitely you
330:17 - can use it by generating that particular
330:19 - API key but guys just think over here uh
330:22 - yes we are using a different different
330:24 - API over here first of all uh we were
330:26 - using this openi API but as you know
330:29 - that openi model is not a free one for
330:32 - uh uh like if you want to use it so
330:34 - definitely we'll have to pay something
330:36 - and how we're going to pay it so based
330:38 - on tokens yesterday actually uh day
330:41 - before yesterday I shown you the uh the
330:43 - token price and all that how much you
330:45 - will be a charge if you are going to use
330:47 - this openi API if you are going to use a
330:50 - different different model over there I
330:51 - told you regarding the input tokens
330:53 - output tokens each and everything I have
330:55 - discussed so just go through and check
330:57 - with the previous session okay so if you
331:00 - are not aware about it now let's say if
331:01 - I want to use any XYZ llm or any other
331:04 - llm so how you can use it by using their
331:07 - API key but just think that uh just
331:10 - think on top of it if why not like if we
331:13 - have any one solution so the one
331:16 - solution actually it can interact with
331:19 - several
331:20 - apis right so here I'm using this open
331:23 - API I if I want to access this
331:25 - particular model definitely I'm using
331:26 - this XYZ API or let's say some other
331:28 - model for that I'm using this XYZ API or
331:31 - maybe I'm downloading it but just think
331:33 - on top of it if we have any single
331:36 - solution for all the llms with that
331:40 - particular solution if we can access all
331:41 - the llms to that will be well and good
331:44 - now so lenen provide you that capability
331:47 - Len chain provide you that capability so
331:49 - by using this Len chain you can access
331:52 - any sort of a llm right I will let you
331:56 - know that uh what all llm and let's say
331:58 - this openi is not a free one now let's
332:00 - say if you want to access a model from
332:02 - this hugging phase let's say you want to
332:04 - access one model from the hugging phase
332:06 - so this length chain gives you that
332:08 - particular capability by using the Lang
332:10 - chain you can access the model from the
332:12 - hugging face also and from a different
332:15 - different apis I will show you what all
332:17 - apis this Lang Chen is having I will
332:19 - come to the documentation so Lang Chen
332:22 - is not
332:23 - restricted till this open AI it is
332:26 - having an access of a multiple API that
332:29 - is the first thing
332:30 - here is a limitation and here I told you
332:32 - the advantage of the Len chain I think
332:35 - you got my point now the second thing if
332:38 - we talking about this GPD model uh if we
332:42 - are talking about the GPD
332:44 - model you know this have been trained
332:47 - till September 2021 data this train till
332:51 - September 2021 data if I'm going to ask
332:54 - anything to my chat GPT or if I'm going
332:57 - to ask anything to my GPD model
332:59 - definitely it won't be able to reply me
333:02 - and you all agree with this thing
333:04 - getting my point so if you will ask to
333:06 - the chat GPT that uh just tell me who
333:09 - won the recent Cricket World Cup will
333:12 - the chat GPT uh able to answer this
333:14 - particular
333:15 - question no it cannot answer to this
333:17 - particular question because this have
333:19 - been trained till September 2021 data so
333:23 - for that what I will have to do I will
333:26 - have to call any third party API for
333:29 - extracting the information yesterday I
333:32 - was doing by using the function C in op
333:34 - open a right but here by using this
333:37 - length chain we can do in a more
333:39 - efficient
333:40 - way getting my point why we use this
333:43 - length chain because here if we are
333:45 - talking about if we are talking about
333:47 - this uh like if we are talking about the
333:49 - limitation of the GPT so I can write it
333:51 - down over here uh it is uh it is having
333:54 - limited knowledge so let me write it
333:56 - down over here it is having it is having
334:01 - it is having a limited knowledge a
334:04 - limited
334:09 - knowledge
334:11 - till 2021 so if I want to extract
334:14 - something if I want to extract something
334:17 - if I want to exess some extra if I want
334:19 - to exess something which is which
334:20 - happened uh recently or uh any like real
334:23 - time information so for that also like
334:26 - we use this length chain and apart from
334:28 - this you will find out
334:31 - uh like different different like
334:34 - function or different different
334:35 - functionality inside the Len chain this
334:36 - Len chain actually it's a more powerful
334:38 - so here there I have given you two main
334:40 - reason that why you should use the
334:42 - length chain now here by using this
334:44 - length chain so let me write it down
334:45 - over here by using the different color
334:47 - so we are talking about this length
334:48 - chain so by using this length chain what
334:50 - you can do you know so you can access
334:53 - any model okay so you can
334:58 - access
335:00 - different llm
335:03 - model different llm
335:05 - model by using by using different
335:10 - API whatever API this lenion support by
335:13 - using different
335:16 - API second
335:20 - thing you can
335:23 - access you can
335:27 - access you can access uh uh private data
335:31 - resources private data
335:37 - sources you can access uh any third
335:41 - party API so here let me write on the
335:42 - third point you can access you can
335:48 - access any third party
335:57 - API got it so this is the
336:00 - uh like some features of the length
336:01 - chain now if we are talking about this
336:03 - length chain so let me do one thing let
336:05 - me create one Circle here what I'm going
336:08 - to do so here I'm going to create a
336:10 - circle now here I can write it down
336:12 - inside this particular Circle I can WR
336:14 - write it down this length CH so what I'm
336:17 - doing here I'm writing
336:19 - down uh just a
336:22 - second so here I'm writing down length
336:26 - chain now what this length chain can do
336:30 - so this lench actually it is having a
336:33 - chain so it can create a chain I will
336:35 - tell you what is a
336:37 - chain it can read the documents okay so
336:42 - document loader it is having a document
336:48 - loader now here I can write it on the
336:50 - third one so it is having a concept of
336:53 - agent for accessing any third party API
336:57 - agent now this can access any sort of
337:00 - llm so let me create Arrow over here so
337:04 - here I can do one thing I can uh give
337:07 - the arrow so what it can do so here uh
337:10 - let me keep the arrow so it can access
337:13 - any sort of a
337:14 - llm large language model from a
337:16 - different different API whether it's a
337:18 - open AI or any other API I can give you
337:20 - the example of two as of over here
337:22 - hugging face hugging
337:25 - face and open Ai and open AI
337:30 - and it it is having a access of a
337:32 - different different apis as well so it
337:34 - is having agent it is having a chains it
337:36 - is having a document loader and it can
337:38 - retain the memory as well so we are
337:40 - talking about the fifth one so it it it
337:43 - can retain the memory so let me write it
337:44 - down over here what it can do guys tell
337:46 - me so it can retain the
337:51 - memory it can retain the memory I will
337:53 - uh come to that memory part so this one
337:56 - langin actually it can do a multiple
337:58 - things it can perform of multiple things
338:01 - and here I have written a couple of
338:03 - limitations of the openi API and this is
338:07 - a limitation which you will find out
338:08 - inside the openi API openi model is not
338:10 - a free one and it is having a limited
338:13 - knowledge so here guys you will uh so
338:16 - what is this what is this Lang chain so
338:18 - here this Lang chain actually it's a
338:19 - open source framework which provide you
338:21 - a multiple
338:23 - functionality with that you can create a
338:25 - agent you can connect with any third
338:27 - partyy API you can create a memory you
338:28 - can retain a memory you can uh read a
338:31 - different different kind of documents
338:32 - like CSV tsv PDF or whatever and here
338:36 - you can create a chain you can create a
338:39 - prompt template also I forgot one thing
338:42 - so here I can write it down you can
338:44 - create a different different a prompt
338:46 - template so let me write it down over
338:48 - here different different prompt
338:54 - templates got it are you getting my
338:56 - point so if we are talking about so see
338:58 - if we are talking about in terms of
339:00 - openi the code basically which I have
339:02 - written inside uh my previous class this
339:05 - one so what is this it's nothing now
339:07 - instead of using open API directly I'm
339:10 - using one wrapper on top of that that is
339:12 - what that is a len chain so over here
339:14 - let me write it down one more thing one
339:16 - more point so just just think over here
339:18 - that this is what this is my open API
339:21 - let me let me draw it over here so here
339:23 - is what guys tell me so here is my open
339:26 - AI API this one now here we have a
339:29 - L
339:31 - chain sorry uh here actually see this is
339:34 - open a API and how we are making a
339:36 - request to this open API so this is what
339:38 - this my Lang
339:42 - chain now if we are going to run any
339:44 - sort of if if we are passing any sort of
339:46 - a prompt right so just just think over
339:48 - here if we are passing any sort of a
339:50 - prompt so we are running it we are
339:52 - running it through this Len
339:55 - chain okay so we are passing a input
339:58 - this is what this is my l Len chin
340:01 - Lenin and here this prom is going
340:03 - through now to this open
340:05 - API open AI
340:10 - API and here is what here is my
340:12 - llm if we are talking about with respect
340:15 - to this openi API so like this it is
340:17 - working it's nothing it's just a
340:19 - wrapper it's just a
340:22 - wrapper on top of on top of open
340:28 - API
340:31 - on top of open a API it is what guys
340:33 - tell me it's just a wrapper on top of
340:35 - this open AI API and not this open a API
340:39 - actually it can do a multiple thing so
340:42 - it can do a multiple thing right so let
340:44 - let me tell you what thing it can do
340:46 - let's say this is your application so
340:48 - here what I can do so let's say this is
340:49 - what this is my application and here is
340:51 - what here let's say I have used this Len
340:53 - chain this is what guys tell me let me
340:55 - change a color so this is what this is
340:56 - my Len chain now if I'm us using this SL
340:59 - CH so it can interact with many it can
341:03 - interact to a many uh like apis like
341:06 - hugging face open or with any third
341:08 - party like API so let me draw it over
341:10 - here this one this one okay now let me
341:13 - do one more thing so over here let me
341:15 - draw uh one more Circle and with that
341:18 - maybe the thing will be more clear now
341:20 - here what I can write it down let's say
341:22 - this is what this is your application
341:24 - okay so over here I can write it down
341:26 - this is what this is your application so
341:28 - this is this is
341:30 - your app now it's making a request so
341:33 - this request is going through this Len
341:36 - you can uh think that it just it is
341:38 - nothing just a prompt is we are passing
341:40 - we want to interact with llm actually
341:42 - large language model so here we are
341:43 - passing a prompt so first it is going
341:45 - through this Len chain this is what this
341:47 - nothing this is my Len
341:49 - chain now this Len chain actually it can
341:52 - it can interact in a many ways so over
341:54 - here I can write it down some sort of
341:56 - API so here I can connect with the open
341:58 - AI
341:59 - open API I can connect with the hugging
342:04 - face hugging face API I can connect with
342:07 - a bloom
342:08 - API and I can access a different
342:11 - different
342:12 - llm I can access what I can do I can
342:15 - access a different different large
342:16 - language
342:18 - models getting my point yes or no and
342:20 - apart from this this Len can connect
342:22 - with a other data resources also with
342:25 - some third party API like
342:27 - Google like we
342:30 - Wikipedia and some other data
342:35 - sources now tell me guys this length
342:38 - chain is clear to all of you what is the
342:40 - length chain here I have uh here here I
342:43 - created like each and every diagram and
342:44 - with that particular diagram I have I I
342:46 - try to explain you each and everything
342:49 - regarding this Len chain so please do
342:51 - let me know in the chat if this thing is
342:53 - clear or
342:58 - not
343:03 - I'm waiting for your reply please do let
343:04 - me
343:14 - know yes I will share this PDF note with
343:16 - all of you don't worry uh I will keep
343:19 - inside the resource
343:28 - section please do let me know in the
343:30 - chat guys if this thing is clear then I
343:32 - will proceed further I will proceed with
343:34 - the
343:52 - Practical great so if you are liking the
343:54 - content then please hit the like button
343:56 - also so I will get some more motivation
343:59 - so yeah guys please hit the like button
344:02 - and please be interactive if I'm asking
344:03 - something then please try to answer
344:05 - please please write down the answer in
344:07 - the chat uh that will be a great
344:09 - motivation for
344:23 - me okay now let's start with the
344:25 - Practical implementation so over here
344:28 - you can see I uh started with a len
344:30 - chain so let me uh run it first of all
344:32 - so here is what here is what here is my
344:34 - Len chain now uh here I'm going to be
344:37 - import my open a uh this uh each and
344:40 - everything I have explained in my
344:41 - previous class itself now let me uh
344:44 - import first of all let me check with my
344:46 - key this uh I will have to generate a
344:48 - openi key if I want to access the open
344:51 - API now now I'm not directly going to
344:54 - hit this open openi API I am hitting by
344:57 - using this length chain
344:59 - getting my point so here I will have to
345:01 - mention the open API key so let me take
345:04 - my open API key just a second
345:10 - uh so here I can keep it somewhere just
345:17 - wait uh so here is my openi key now let
345:21 - me paste it over here this
345:24 - one so yes I have created my client
345:27 - means I have created my object now here
345:29 - is what here is my prompt here is what
345:31 - guys tell me here is my prompt now what
345:33 - is the prompt guys tell me the prompt is
345:34 - nothing in whatever see prompt is
345:37 - nothing it's just a sentence which we
345:39 - are passing to to our llm as a input
345:42 - it's nothing just a collection of words
345:43 - collection of tokens so word itself is
345:46 - called a token that's it that's is a
345:48 - prompt now over here if I'm going to run
345:50 - it so let me run this particular prompt
345:54 - and here you can see I'm asking to my
345:56 - chat GPT sorry I'm asking to my GPT
345:58 - model can you tell me total number of
346:00 - country in the Asia can you give me top
346:01 - 10 country name yes it is able to give
346:03 - it it is it is able to like provide a
346:06 - name basically now let's start from here
346:08 - because still here I've explained you
346:10 - each and everything in the previous
346:11 - class now let me give the next prompt
346:13 - the second prompt so over here I can ask
346:15 - something else to my uh GPD model now
346:18 - tell me guys what should I ask any uh
346:21 - any question anything which uh you would
346:24 - like to highlight uh which should I
346:26 - return return over
346:27 - here
346:51 - good so over here I didn't get
346:55 - any okay so let's uh ask like any uh
346:58 - basic question so can you tell me can
347:01 - you tell me a
347:03 - capital of
347:06 - India so let's uh search about this
347:09 - capital of India and here what I can do
347:13 - I can run it and uh let me uh give this
347:16 - particular input uh let me give this
347:19 - particular prompt to my uh uh to my
347:23 - model and I just need to call this
347:25 - client. predict and here I need to
347:27 - provide the prompt so client. predict
347:31 - and here I just need to provide the
347:32 - prompt so it is giving me answer it is
347:34 - saying that the capital of India is New
347:37 - Delhi now here let's try to strip this
347:39 - uh particular output strip means it it
347:41 - will remove the slend from here so I'm
347:44 - going to strip it and here you can see
347:46 - it is giving me an answer so I am
347:48 - getting answer without this selection
347:50 - now I think it is clear to all of you
347:52 - now one person is asking that what
347:54 - exactly tokens and Vector uh so here
347:58 - let's Ty to ask this same question uh to
348:00 - the GP or uh to the jpt model so what
348:04 - I'm going to do here I'm going to uh
348:06 - keep same question from the chat itself
348:09 - and the question is what is a token and
348:12 - a vector you can ask anything to your
348:14 - chat GPT and behind the chat GPT
348:16 - actually this uh behind the chat GPT the
348:19 - GPD model is working so let's uh ask
348:21 - about the tokens and the vectors and
348:24 - let's see uh what will be the answer uh
348:27 - which I will get from the GPD side so
348:30 - let me predict this a prompt three and
348:33 - here the answer is client. predict prom
348:37 - three and see the answer tokens are
348:39 - individual unit that a computer program
348:41 - used to perform operation they can be
348:43 - words symbol or numbers so the same
348:46 - thing I told you now this tokens is
348:47 - nothing just a words right that are used
348:50 - in programming language to represent a
348:51 - specific intersection Vector is data
348:53 - structure that is store a elements of
348:56 - the same time it is used to store
348:57 - sequence of el such as number of
348:59 - character so a vector is nothing what is
349:02 - a vector vector is having two unit now
349:03 - magnitude and the direction so how we
349:06 - represent the vector in our algebra in
349:08 - our algebra if you are like little
349:10 - familiar with the algebric uh algebra
349:12 - concept um algebra Concept in the
349:14 - mathematics so we open the square
349:17 - bracket we write it down some sort of a
349:18 - number and we close the square bracket
349:20 - that is the representation of the vector
349:22 - and along with that maybe the direction
349:24 - uh might be involved that's it so here
349:28 - uh you you can see definitely we are
349:29 - able to call the openi API now let's try
349:32 - to understand few more thing related to
349:34 - this length chain now here let's start
349:38 - to talk about the prompt template the
349:40 - very first topic which we're going to
349:42 - talk about uh we want to talk about
349:45 - related to this prompt template so first
349:47 - I will show you the example of this
349:48 - prompt template that how you can create
349:51 - a prompt template and after that I will
349:53 - um I will try to explain you that what
349:55 - is a prompt template first let me run
349:57 - the code so here is here is what uh we
349:59 - are going to discuss about this prompt
350:01 - template now I'm going to write it down
350:04 - from length chain from length chain and
350:08 - from here I'm going to import
350:10 - prompts prompts and let me import this
350:13 - prompt template class so
350:16 - prompt prompt uh p r o m PT prompt
350:22 - templates so I'm going to import this
350:24 - particular class what is the name of the
350:26 - class prom template okay it's not a temp
350:28 - templ actually a template so prom
350:30 - template now if I will run it so
350:32 - definitely I will be able to import it
350:34 - so here my spelling is wrong so let me
350:36 - correct it first of all and here you can
350:38 - see we are able to import this
350:40 - particular class now after that what I
350:42 - will do so here actually I want to
350:45 - create my prompt right I want to create
350:48 - my prompt now let me do it first of all
350:50 - and then I will come to the explanation
350:52 - so here what I'm going to do so I'm
350:54 - going to create an object of this prompt
350:56 - class so here is what here is my object
350:58 - so I'm saying that it is nothing it is
351:00 - my prompt template name so here I'm
351:03 - going to write it down prompt template
351:05 - this is what this nothing this is my
351:06 - variable prom template name got it I
351:10 - have created my object now inside this
351:13 - object I have to pass some parameter so
351:15 - let's try to pass few parameters over
351:17 - here the first parameter which I'm going
351:19 - to pass over here the parameter is going
351:21 - to be input variable so here the
351:23 - parameter which I'm going to pass over
351:25 - here that's going to be an input
351:27 - variable in input variable and the
351:29 - second parameter which we're going to
351:30 - pass over here that's going to be a
351:32 - template so how my prompt will be
351:35 - looking like so here I'm going to write
351:37 - it down template and is equal to right
351:40 - now in the variable actually I'm going
351:41 - to write it down the name what will be
351:43 - my variable so here I'm saying city city
351:47 - will be my variable and here I'm going
351:48 - to write it down my template now in the
351:51 - template actually I'm going to write
351:53 - down that uh can you tell me the capital
351:55 - of so here I'm just saying that can you
351:58 - tell me the capital of and here on a in
352:03 - a curly braces I'm going to write it
352:05 - down the city right City so c i t by so
352:09 - here whatever uh this is what this city
352:11 - is nothing it's my input variable so
352:13 - here I'm going to write down the city so
352:15 - this is what this is my object this is
352:17 - what this is my object for the plum so
352:19 - here I can put the question mark as well
352:21 - and if I'm going to run it now here you
352:23 - will be able to find out it is giving me
352:25 - an error why because I didn't put the
352:27 - comma over here now here you will you
352:29 - can see this is what this is my prompt
352:31 - template now what is the issue over here
352:33 - input variable okay so the so the
352:37 - parameter name is what input variable
352:39 - now I think everything is fine
352:40 - everything is clear now here what I will
352:42 - do I will call one method I will call
352:45 - one method just just be careful over
352:47 - here right so here I will call one
352:49 - method now here I'm going to write it
352:51 - down format and here what was my
352:54 - variable what was my input variable
352:56 - input variable was City now if I'm going
352:58 - to write down City so here let me write
353:00 - it down this uh Delhi so here once I've
353:04 - have done it now so it is giving me a
353:06 - specific prompt that can you tell me a
353:08 - capital of Delhi automatically right now
353:11 - here see again I'm going to ask the here
353:14 - again I want to create a prompt for uh
353:16 - for a different country let's say I want
353:18 - to ask a capital of China c i n now here
353:22 - you can see it is saying uh it is uh
353:24 - giving me a prompt that can you tell me
353:26 - a capital of China can you tell me a
353:29 - capital of China so what is the meaning
353:31 - of this prompt template what what what
353:33 - is the use of it now I think you can
353:35 - understand so by using this prompt
353:37 - template we can construct The Prompt
353:39 - based on a input variable now let's say
353:42 - you are going to create an application I
353:45 - can give you very uh good scenario now
353:47 - here is your
353:49 - application right here is what here is
353:51 - your application now you you have
353:53 - created this application by using the
353:56 - flas now here you are ask asking to the
353:58 - user just a city
354:00 - name just a city name or just a country
354:03 - name actually and based on that city of
354:06 - based on that country you want to
354:07 - provide a specific information and here
354:10 - you are using any sort of a
354:13 - llm whether it's from hugging face or
354:15 - open AI now guys over here uh you don't
354:20 - want to be here actually you don't want
354:23 - that that your user is giving a entire
354:26 - prompt you just want to take take a you
354:29 - just want to take a city name you just
354:31 - want to take a variable like we do in a
354:34 - python you know in a python we we have
354:36 - an input function yes or no but and by
354:40 - using this input function we take a like
354:42 - input from the user and let's say we
354:44 - have to uh showcase the addition uh
354:46 - divide or maybe uh multiplication
354:49 - whatever on top of those input variable
354:51 - we can do it similarly over here let's
354:53 - say we are taking just a city name so by
354:56 - using this city name we can construct
354:58 - our prompt and that particular prompt we
355:00 - can pass to the
355:02 - llm and Leng chain gives you this
355:05 - particular functionality we don't have
355:06 - this thing inside open AI API getting my
355:11 - point now so here I have created my prom
355:13 - now let's try to pass this prompt to the
355:15 - length chain so what I can do here I can
355:18 - write it down this is what this is my
355:19 - prompt
355:20 - first p o p
355:23 - Mt prompt first this is what this is my
355:26 - prompt first and here I can write it
355:28 - down prompt second this is what this is
355:30 - my prompt second and here is prompt
355:34 - second now let's try to pass this
355:36 - particular prom to
355:37 - my to my llm or let's let's try to call
355:41 - the API open API for that already we
355:43 - have a method client predict so let's
355:45 - try to call this particular prompt now
355:47 - here I'm going to call the prompt first
355:50 - this is the prompt which I'm going to
355:52 - call and here uh I'm going to call I'm
355:54 - going to write down this strip function
355:56 - also so I won't get any sort of slash or
355:58 - whatsoever right now here you can see
356:00 - the capital of Delhi is India the
356:03 - capital of New Delhi is India okay so
356:05 - here I need to write it down just just
356:08 - let me redefine it instead of the city
356:09 - what I can do I can write down the
356:11 - country right now uh this is what this
356:15 - is my country and here instead of the
356:18 - city let me write it down the country
356:20 - one more time and here I can write it on
356:22 - the India I think now it is it is a
356:25 - meaningful now here I can write it on
356:27 - the country one more time uh country c u
356:32 - okay c u n c
356:35 - o un n and here the
356:39 - same here is a same and here is also
356:43 - same now it's a meaningful and let me
356:46 - run it and see what I will be getting
356:48 - over here so prompt one prompt second
356:50 - and here is uh like a it's a New Delhi
356:53 - and let me check with a prompt two so
356:56 - guys here what I can do I can pass the
356:58 - prompt two and let's see the output it
357:00 - is saying the capital of China is a
357:03 - Bing so this prompt basically this
357:06 - prompt template will help you a lot
357:09 - whenever you are going to create any
357:10 - sort of application where you just
357:13 - required a single word from the
357:15 - user this thing is clear to all of you
357:18 - if yes then please do let me know in the
357:26 - chat
357:29 - please do let me know in the chat if
357:31 - this part is clear to all of you please
357:32 - write it on the chat I'm waiting for
357:34 - your
357:39 - reply are you liking the session are you
357:42 - liking the content so please hit the
357:44 - like button as well if you are getting
357:45 - everything if you are able to understand
357:47 - whatever I'm explaining to all of you
357:49 - please do let me know in the chat and
357:53 - yeah and whatever questions you have you
357:55 - can write it down the chat I I I'm
357:56 - monitoring the chat don't
358:04 - worry wait S I will come to that again I
358:07 - will try to explain the L and Advantage
358:09 - first of all let me uh complete the code
358:11 - part otherwise we won't be able to
358:12 - complete all the thing within
358:23 - R yes correct Vishnu your understanding
358:26 - is pretty much clear now
358:28 - since open AI model is not free uh so we
358:32 - Len access all
358:35 - API all other API as well like uh uh
358:38 - hugging face API it can access the
358:39 - hugging face API it can access the bloom
358:41 - API or different different API I will
358:43 - come to the documentation let me uh
358:45 - clarify the basic basic thing uh
358:47 - whatever is there inside the Lang chain
358:49 - I will come to the uh
358:56 - documentation great now here everything
358:58 - is clear everything is fine so here we
359:00 - have this uh here we have this object
359:03 - name prom template uh name and here is
359:06 - what here is my method that is what that
359:08 - is a format now what I'm going to do
359:10 - here H so here actually we have a second
359:12 - method also which is doing the same
359:13 - thing let me show you that at many
359:15 - places you will find out that particular
359:17 - method also I written it somewhere uh
359:20 - just give me a second yeah this one so
359:22 - it is working in a similar way langen
359:25 - has given you the two ways actually for
359:26 - creating this prompt so first of all see
359:29 - we have this promp template
359:31 - class we can create
359:34 - object and we can call this method
359:36 - format method got it now we have a
359:40 - second way here you can see this one
359:43 - prompt template. from template you can
359:46 - call this particular method also and it
359:47 - will work in a similar way both are same
359:49 - don't ask me sir why we are using this
359:51 - that Lenin is giving you the two option
359:53 - for creating a prompt template right now
359:55 - here you can see prompt template prom
359:56 - template what is the good name of the
359:58 - company that makes product I can write
359:59 - it on any like name uh any uh product
360:02 - name so here uh what I can say I can
360:05 - give this particular uh okay first of
360:08 - all let me run it and here is what I'm
360:10 - going to call this format method over
360:11 - here so from template do from temp prom
360:15 - template. frommore template and here is
360:17 - what here is my template template and
360:20 - here is what here is my tell me what is
360:23 - this this is my key now input variable
360:26 - now right now now let me show you what I
360:28 - will get over here so I will be able to
360:30 - construct my prompt what is a good name
360:32 - of the company that make a
360:34 - toys here is my key and here is my
360:36 - template it's going to combine both and
360:39 - finally I'm getting my prompt so over
360:42 - here what I can do so over here I can
360:43 - write it down my prompt so this is what
360:46 - this is my prompt number three and see
360:48 - guys if I'm going to run it so what I
360:51 - will get so here I'm if I'm going to run
360:52 - it this promt three ah it will give me a
360:55 - name it's not a 23 basically it's just a
360:58 - three so let me run it and let's see
361:00 - what would be the output so p r o p Mt p
361:04 - r o MPT uh it's a spelling
361:08 - mistake and now let me check it is
361:11 - working or not so toy makers unlimited
361:14 - so this is the company name actually
361:15 - which I'm getting if I'm giving this
361:18 - particular prompt to my GPT model you
361:21 - can test over the chat GPD as well so uh
361:24 - you will get this type of nam in the
361:26 - back end we are calling the GPD model
361:27 - don't forget over here don't forget okay
361:30 - so we are getting a uh GPT we are
361:33 - basically calling a GPT model over here
361:36 - so this part is clear to all of you and
361:38 - uh I think now this uh prompt part
361:41 - prompt section is pretty much clear I
361:43 - believe that it is clear yes or no this
361:46 - uh prompt template if it is then uh
361:49 - please confirm in the chat then I will
361:51 - uh explain you the second topic that is
361:53 - a agent agent in a lang chain and after
361:57 - that I will come to the uh chain and
361:59 - memory and document loader and finally
362:01 - we start with the hanging phase so tell
362:04 - me guys it is clear this uh prompt
362:06 - templating how we can create a prompt
362:08 - template great it is clear to all of you
362:10 - now let's understand the agent so what
362:13 - is an agent guys tell me so agent is
362:16 - nothing we use this agent in the L chain
362:20 - for calling any third party tool that's
362:24 - a simple definition of the agent if
362:26 - someone is going to ask okay just tell
362:28 - me who is a
362:30 - agent who is a agent in a real time
362:32 - let's say if I'm saying uh there is one
362:34 - agent uh let's say you uh went to the uh
362:37 - any uh you want to purchase any property
362:41 - you want to purchase any property and
362:42 - you went to the Builder and you are uh
362:45 - and uh once you visited the property and
362:48 - you have visited the Builder office or
362:50 - whatsoever there you will find out agent
362:52 - so who is the agent actually so it's a
362:55 - it will so let's say you are a main
362:57 - person and uh you want the information
362:59 - of the property so that you want a like
363:02 - the main person and you want the
363:03 - information from the of the property
363:05 - basically so this agent will help you
363:07 - this agent will collect the information
363:09 - of that particular property and it will
363:11 - provide you in a similar way the agent
363:14 - is working over here getting my point
363:17 - yes or no I think yes now let me run it
363:20 - and let's try to understand the agent so
363:23 - guys over here I will start the thing uh
363:26 - I will ask ask one question to my chat
363:30 - GPT so here I'm going to ask one
363:33 - question to my chat
363:35 - GPT just a
363:39 - wait great so let me open my chat GPT
363:42 - and here let me ask one question the
363:45 - question is very very simple so here I
363:47 - want to know that uh can you tell
363:53 - me
363:55 - current GDP
363:58 - of
364:00 - India so here uh I'm asking to my CH GPD
364:04 - can you tell me the current
364:05 - GDP of India now if I will uh run it so
364:09 - here it is saying to me I'm sorry I
364:11 - don't know in a real time as my training
364:14 - only include information up to the
364:16 - January 22 this that whatever getting my
364:19 - point yes or no tell me so it is not
364:21 - having uh this particular information if
364:23 - I'm asking to my CH gbt can you tell me
364:28 - who won the
364:32 - Cricket World
364:35 - Cup
364:39 - recently now here see what I will
364:44 - get so here it is saying guys I don't
364:47 - have a real time
364:50 - information only includes data up to
364:53 - January
364:54 - 2022 or 20 202 20 okay as my latest
364:59 - updated the most recent information
365:01 - World Cup was held in 2019 emerged as a
365:08 - champion defeating New Zealand in a
365:10 - thrilling final so is giving me an
365:12 - information from the 2019 match I think
365:15 - India again uh uh like uh they out uh I
365:20 - think uh they uh they they got defe from
365:23 - the New Zealand itself right in a
365:25 - knockout match in a semi-final itself
365:27 - uh yes I'm able to remember it so here
365:30 - uh it is not able to give me an answer
365:32 - now let's ask the same thing uh through
365:34 - the open so through the lench itself in
365:37 - my code I'm going to write down the same
365:39 - thing over here so here I'm going to
365:41 - create a prompt for so I'm asking to my
365:43 - model prompt 4 so here I'm asking to my
365:46 - model can you tell
365:53 - me who W the
365:56 - recent
365:58 - Cricket World
366:00 - Cup so this is the question and now let
366:02 - me ask it let me run it so what I can do
366:05 - I can write it down this client predict
366:07 - and here I can pass my prompt prompt
366:11 - four now see uh okay first of all I will
366:15 - have to run it p r o m PT p r o m PT now
366:21 - see guys uh it is saying that uh the 201
366:25 - won by the England I'm asking about the
366:27 - recent World Cup but it is saying that
366:29 - uh the 2019 Cricket World Cup won by the
366:33 - England only it's completely wrong right
366:35 - now here what I can do I can ask one
366:37 - more thing can you tell me the current
366:39 - GDP of can you tell me a current GDP of
366:42 - India can you tell me current
366:47 - GDP current GDP of India so let's see
366:52 - what will be the answer so here is what
366:54 - here is my prompt five let me copy it
366:56 - let me paste it over here and here I can
366:59 - write it down this prom
367:01 - five so as of 2039 India GDP was
367:04 - estimated to be around
367:06 - 2.94 trillion actually it has been
367:09 - trained till 20 uh 22 data 2022 data
367:13 - right so till January 2022 data right so
367:17 - here it is not able to give me a proper
367:18 - answer uh it is not able to give me a
367:21 - real time answer so for that what I will
367:23 - do guys tell me so here I will use the
367:26 - agent I will use the concept of the
367:28 - agent which will extract the information
367:31 - from the third party API now here I'm
367:34 - going to use Sur API now here so for for
367:42 - extracting extracting or real time info
367:45 - real time info I'm going to use I'm
367:49 - going to
367:50 - use Sur API Sur API Now by using the Sur
367:55 - API
367:57 - Now by using now by using this Ser
368:02 - API I will now by using the Ser API I
368:05 - will
368:06 - call Google search
368:11 - engine
368:13 - and I will
368:16 - extract the
368:19 - information in a real time so here I
368:22 - have written this particular uh like a
368:24 - statement so I hope it is clearly
368:26 - visible to all of you now let me keep it
368:29 - in a mark down and it is clear so for
368:32 - extracting a real time info I'm going to
368:33 - use Sur API Now by using the Sur API I
368:36 - will call Google search engine and I
368:38 - will extract the information in a real
368:41 - time let's see how you can do it so here
368:44 - what I'm going to do so first of all I
368:45 - will have to install this particular
368:47 - Library pip install Google search result
368:52 - that is the first thing now install this
368:54 - library inside your current virtual
368:57 - environment so here what I'm going to do
369:00 - here I'm going to install this
369:02 - particular here I'm going to install
369:04 - this particular liity in my current
369:06 - virtual environment where guys tell me
369:08 - in a current virtual environment clear
369:11 - fine now after that what I will do so
369:13 - after that I will create my Sur API key
369:16 - Sur API key because uh with that only I
369:19 - can access I can access a different
369:21 - different API now let me show you the
369:23 - surp API so just open the Google so here
369:27 - just open the Google let me show you
369:28 - from scratch so over the Google what you
369:31 - need to do you just need to uh okay so
369:33 - here what I'm going to do I'm going to
369:34 - write down the surp API so let me write
369:36 - down this Sur
369:38 - API so once I will write down surp API
369:40 - now now here you will get this very
369:42 - first link so what is a Sur API like uh
369:46 - we have a rapid API now in a similar way
369:48 - we have a Sur API so Sur API is a
369:50 - realtime API to access Google search
369:52 - result not from the Google actually and
369:56 - from any search engine Bing or maybe
369:58 - some other search engine even we can
370:00 - access the Wikipedia also right I will
370:03 - show you how so here uh if I will open
370:06 - it now so you just need to do sign in
370:08 - first you need to do register and then
370:10 - you need to do the sign in I already
370:11 - registered so that's why it is giving me
370:13 - this particular page now just scroll
370:15 - down over here just see over here API
370:18 - documentation now in a over here you
370:20 - will find out a different different
370:21 - documentation related to Google search
370:23 - API Google Map API Google job API Google
370:26 - shopping API Google image API now apart
370:29 - from the Google you will find out the
370:30 - Bing Bing search API also by do
370:34 - also BYU also it's a Chinese search
370:36 - engine now Doug du go search API Yahoo
370:38 - search API yendex search API eBay search
370:41 - API YouTube search API any API you can
370:43 - call by using this Sur API now just
370:46 - click over here API key and here is what
370:49 - guys here is my API key now you have to
370:52 - generate your own API key this is my API
370:55 - key now let me copy this API key from
370:58 - here and it is having some sort of a
371:00 - limitation actually you can just do a
371:01 - 100 search in a free version but in a
371:03 - paid version I think uh you can uh like
371:06 - increase the number of search so just
371:08 - see over here just open it and you will
371:11 - be able to find out entire
371:12 - detail so plan is a free plan price per
371:16 - mon
371:17 - zero uh total plan s 100 plan search
371:21 - left 995 5 I already did it and yeah
371:24 - this is it in a free version you can
371:26 - check check with the plan so just go in
371:27 - the change plan and here you will find
371:30 - out the entire detail so production plan
371:33 - developer plan big data plan all the
371:36 - plans you'll find out over here and by
371:38 - using this API you can access the Google
371:41 - search engine you can access the Google
371:43 - search API inside your application right
371:47 - now here what I need to do I just need
371:49 - to paste this API key in my I just need
371:52 - to keep this APK in my variable till
371:54 - here everything is fine everything is
371:56 - clear now what I will do guys so over
371:59 - here I will I I have to like import few
372:03 - uh I have to import few uh like import
372:05 - uh statement basically uh I have to
372:07 - import few packages so agent type load
372:10 - tools and initialize agent so these are
372:13 - the these are the like these are the
372:16 - packages basically which I need to
372:17 - import agent type load tool and
372:19 - initialize agent so see guys uh let me
372:22 - import this particular thing first of
372:24 - all and yeah it is working F now first
372:27 - of all what I will do first of all I
372:29 - will create a ag first of all I will
372:31 - create a client means here I've created
372:33 - now this open a uh client this
372:36 - one this one okay let me use this one or
372:39 - I can create one more time not an issue
372:41 - as many as time you can do it so here
372:43 - what I'm going to do so here I'm going
372:44 - to uh paste this particular code here
372:46 - I'm going to create my client so this is
372:48 - what this is my client now after that I
372:51 - have to load the tools which tool tell
372:54 - me which
372:55 - tool which tool like we are going to
372:57 - load Sur API now we are going to use the
372:59 - Sur API now so that that's the only tool
373:01 - right so here what I'm going to do I'm
373:03 - going to create a object of this
373:04 - particular method sorry this particular
373:07 - class so here is what here is my object
373:10 - now this is what this is my tool now
373:12 - here I will mention something inside
373:14 - this tool now let me do it over here so
373:16 - let me uh mention this particular thing
373:19 - so here I'm going to mention it so this
373:21 - is a thing basically which I need to
373:23 - keep Sur API uh first of all I need to P
373:26 - The Sur API key and llm so here is what
373:29 - here is my llm already I've created this
373:31 - client I'm using open still I'm using
373:34 - open okay I didn't uh explain you the
373:36 - hugging face so far so this is my Sur
373:38 - API key and here is the name which tool
373:40 - you are using that's it in our square
373:42 - bracket you need to write it down the
373:43 - name you can find out each and
373:45 - everything with the alen tuto lenion
373:47 - documentation everything is there
373:50 - everything is there I will come to that
373:51 - just wait so here is what here is my
373:53 - tool I created my tool now I have to
373:56 - inal I have to create my agent type so
373:59 - here what I want to do uh so here
374:02 - basically what I want to do guys tell me
374:04 - so here I want to create my agent type
374:07 - so U here what I will do I will uh
374:10 - create an object of this initialized
374:12 - agent let me create the object of this
374:14 - initialize agent and here is what guys
374:16 - tell me here is my agent this is what
374:18 - this is my agent now inside this
374:19 - initialize agent again I will keep
374:21 - something so first of all the first
374:22 - thing which I will keep that is going to
374:24 - be a tool so the tool basically which
374:26 - which I've created the second type will
374:28 - be a client means my model the third
374:30 - type will be a agent this agent this
374:32 - agent uh basically agent type actually
374:35 - and here we are going to talk about this
374:36 - zero short react description we are
374:38 - going to mention this zero short react
374:40 - description and verbos to means whatever
374:42 - information um what if I will run it now
374:44 - so whatever information will be in a
374:46 - back end I will be able to see not over
374:47 - the display there's the meaning of the
374:49 - bbos right so here I mentioned three
374:51 - parameters the first is tool the second
374:53 - is client the third is Agent
374:56 - and the first fourth is barbos great now
374:59 - let me run it so this is what this is my
375:01 - agent now what I will do so here I will
375:04 - write it down agent and I will run so
375:07 - run now here I will ask the same
375:10 - question so my question was let me take
375:13 - this particular question from the chat
375:15 - jpt can you tell me the okay so can you
375:18 - tell me who won the recent World Cup so
375:20 - if I'm going to ask the same question
375:22 - now to my
375:24 - agent so here what I'm going to do I
375:26 - going to ask it and let's see what I
375:28 - will be what I will be getting so it is
375:30 - executing the agent and here is search
375:32 - here is action who won the Cricket World
375:34 - Cup and here you can see Australia won
375:37 - the Cricket World Cup it's a recent
375:41 - information it's a real time information
375:42 - which I'm getting now it is giving me
375:44 - many given me some other thing as well
375:46 - links and all because it is calling the
375:48 - Google API Google search engine actually
375:50 - in a back end and here you can see it is
375:52 - giving me answer a on the recent World
375:54 - Cup you can ask anything
375:56 - you can ask anything guys just just uh
375:58 - write it down over here so you can say
376:01 - that
376:03 - uh can
376:06 - you tell me five
376:10 - current can you tell me five top current
376:19 - affairs a f i i RS so if I will learn it
376:23 - now it will hit the Google search enger
376:26 - and here it is saying that see uh so it
376:31 - is saying that top five current affairs
376:34 - and still it is running so read is not
376:37 - available tool try to open I should
376:40 - search engine to find out observations
376:42 - see here it is giving me
376:44 - some like top five current affairs
376:47 - International breaking news uh affairs
376:50 - from us Europe this is the second one a
376:53 - current affairs Subs is one of the best
376:55 - known as a improved life
376:56 - jagaran Jo affairs.com okay it has given
377:01 - me a different different website maybe
377:03 - or uh it here is a news Okay so actually
377:07 - it is giving me a different different
377:08 - name it it is not giving me a proper
377:11 - current affairs I will have to mention
377:13 - that I will have to write uh that
377:14 - particular prompt basically so let's do
377:17 - one thing now let's understand the
377:18 - Wikipedia also so how we can uh like
377:20 - call the Wikipedia so here what I will
377:23 - do I will be writing down pip install
377:25 - pip P install
377:28 - Wikipedia now I will have to install it
377:31 - in a current virtual environment now if
377:32 - I will run it now pip install Wikipedia
377:34 - so let it run uh so here you can see
377:37 - I've installed the Wikipedia now what I
377:38 - will do first of all guys see tell me
377:41 - what is the first thing I have to load
377:42 - the tool so let me load the Tool uh so
377:46 - here is what guys see here is my tool
377:49 - and here is my LM means my client open a
377:51 - client that's it now my tool now what I
377:53 - have to do I have to create an agent so
377:56 - here is what here is my agent this is
377:58 - what my agent I have initialized the
377:59 - agent here is my tool here is my like
378:01 - model and here is my agent type zero
378:04 - short react I will come to that what is
378:06 - this react description and BOS equal to
378:08 - two once I will run it and here whatever
378:11 - I will run now see I'm going to write
378:14 - down uh agent dot run and here I'm
378:19 - asking can
378:21 - you tell
378:23 - me more can you tell me about this re uh
378:28 - okay can you tell me more about this
378:32 - recent
378:34 - Cricket c i c k e Cricket World
378:39 - Cup so if I will run it now it is going
378:42 - to extract the entire information from
378:44 - the
378:47 - Wikipedia okay it is it is taking from
378:49 - the 2019 World
378:51 - Cup okay it is taking from the 2023
378:54 - World Cup itself the World Cup for the
378:56 - 39 Cricket World Cup which was H in
378:58 - India 5th October November 23 Australia
379:01 - won the
379:01 - tournament great so it is excting a
379:04 - information from the uh recent one
379:07 - itself now here I can ask one more
379:10 - question to my just a second what I can
379:13 - do I can copy it first of all let me
379:15 - copy this particular thing and here what
379:18 - I'm going to do here I'm going to pass a
379:20 - next question so the next question is so
379:23 - let me keep the question over here
379:26 - uh let me run
379:28 - it it is taking the information from the
379:30 - Wikipedia itself are you getting it guys
379:33 - yes or no yes surf I explain you
379:35 - everything regarding the surf API s if
379:38 - you are here if you look into the surf
379:40 - API right so each and every plan I have
379:43 - shown you and it give you the free uh
379:45 - access also but up to uh like it is
379:48 - having some limitation over there you
379:50 - can just hit 100 search you can just hit
379:53 - the 100 100 search in a free version if
379:55 - you're going to take a plan so in that
379:57 - case uh there will be a different uh
379:59 - number of search actually search plan is
380:02 - there different different plan is there
380:03 - see Di okay
380:06 - $2,500 per month $8,000 per month Cloud
380:09 - for plan many plans is there see guys
380:12 - how much plans is
380:14 - there uh which you will find out just go
380:17 - through with it I let me give you this
380:18 - particular link inside the chat and
380:20 - don't worry each and everything will be
380:22 - available inside the resource section at
380:23 - the single place uh at the single place
380:26 - I will keep all the thing and I will
380:28 - give you that don't worry so now see it
380:30 - is extracting the entire information
380:32 - from the uh like uh it is going to
380:35 - extract the entire information from the
380:37 - vikkipedia so final answer the total
380:39 - National dep of the this one and here
380:42 - you can see this is the GDP of the uh
380:45 - USA and here observation and all
380:49 - everything everything now see action
380:52 - Wikipedia input GDP of United State
380:54 - observation p economy of United States
380:57 - summary this is the complete information
381:00 - complete information which is going to
381:01 - fetch which it is fetching from the
381:03 - Wikipedia itself now tell me guys how
381:06 - many of you you are able to understand
381:08 - the concept of the agent so please let
381:11 - do let me know in the chat and then
381:12 - again I will revise it and I will
381:14 - explain you uh through the lench and
381:16 - documentation please do let me know in
381:18 - the chat first if you are how many of
381:20 - you are able to understand the concept
381:22 - of this
381:23 - agent here from here I have started this
381:26 - agent tell me guys
381:34 - fast by using the Sur API we can uh
381:37 - access uh we can access a real time
381:41 - information and it is possible in a is
381:44 - possible in a len
381:47 - chain please do write it down in the
381:49 - chat if you're liking the uh session so
381:51 - please hit the like button also and I'm
381:54 - waiting for your response guys please
381:55 - please do let me
381:57 - know sir please explain the logs which
382:00 - is coming from the agent so here I can
382:02 - explain the log so here is what here is
382:04 - my logs what is this uh what is it uh
382:07 - just check over here so it is saying
382:09 - entering new agent executor chain so
382:12 - after this I'm coming to the chain
382:14 - concept chain and memory two thing is
382:16 - remaining and the document loader three
382:18 - is remaining uh uh then uh you will be
382:21 - able to understand this chaining and all
382:22 - in a better way now here entering a new
382:25 - you execute a chain so action is what it
382:29 - just want to search now action input top
382:31 - current affairs so it is making
382:33 - observation it is searching everything
382:34 - from the Google then it is thinking
382:36 - something I need a narrow down the list
382:38 - of top five internally it is doing
382:40 - everything internally it is doing
382:41 - everything and it is giving you the
382:43 - final answer this one finished chain
382:45 - actually each and everything has been
382:47 - coded in the form of chain llm chain I'm
382:50 - coming to that chain and once you will
382:53 - understand that particular chain now
382:54 - this thing will be are like pretty much
382:56 - clear to all of you believe me just just
382:59 - read it by yourself as
383:05 - well what is the use of client in this
383:07 - what is a just it's just a name now what
383:09 - is a client see I told you please learn
383:12 - the python first if your python uh topic
383:15 - is clear then definitely you will be
383:17 - able to understand this line of code see
383:20 - someone has created openi class
383:22 - somewhere in openi P you just downloaded
383:24 - that you just downloaded that particular
383:27 - package by using pip install openi and
383:29 - now you are creating a object of that it
383:31 - is just is just a class and here is a
383:33 - object this is the object name you can
383:35 - keep it anything here you can give your
383:37 - name like whatever name your name just
383:39 - write it down your name this is what
383:41 - this is nothing this is the object of
383:42 - the openi class and here you are passing
383:44 - a different different
383:46 - parameter someone has created a class
383:48 - and you are just using it that's it
383:51 - nothing else so this is what this is my
383:54 - client and I think this is clear to all
383:56 - of you now coming to the next part so
383:59 - here first of all let me show you the
384:01 - Lenin documentation so I'm going to
384:03 - write it down over here Lenin
384:05 - documentation now over here uh like uh
384:09 - you can see this is what there is
384:10 - nothing there's a Lenin documentation
384:12 - and here is an introduction so they have
384:14 - given you the complete introduction of
384:16 - the lenen over here Lenin Library lenen
384:18 - template Lang server Lang Smith
384:21 - everything you will find out over here
384:23 - and this document is a
384:25 - amazing one similar to this open a uh so
384:29 - yesterday we have seen the open a
384:30 - documentation right so this length chain
384:32 - documentation is similar to that openi
384:35 - documentation it's a pretty amazing each
384:37 - and everything you will find out over
384:38 - here itself each and everything you will
384:41 - find out over here itself now let's
384:43 - start with the installation so how you
384:45 - can do that it is very very easy pip
384:47 - install length chain and pip install and
384:49 - all what is the meaning of this pip
384:50 - install hyphen e dot so this thing we'll
384:52 - try to understand in our upcoming
384:54 - session once I will start with the end
384:56 - to end project now L server we try to
384:59 - understand this also what is the Lang
385:00 - server all L CLI so many like they have
385:02 - given you over here as of now this lch
385:05 - package is required that's why we are
385:07 - going to download it now over here we
385:09 - have a quick start so here you will find
385:11 - out the quick start so you can go
385:12 - through with this quick start and you
385:14 - can uh like you can take a glimpse of
385:17 - this Len CH so everything you will find
385:19 - out over here in a quick start itself
385:21 - pip install lch pip install open a you
385:24 - can export the open a key key and then
385:25 - you can use it and here is a different
385:27 - different thing which you will be able
385:29 - to find out whatever thing we are
385:31 - running so open a you can uh create
385:34 - object of this chat openi also now here
385:37 - is llm model here is U you can use this
385:39 - particular class also chat open AI now
385:42 - human messages lch schema human message
385:45 - there you can check with this what is
385:46 - this now you can create a prompt
385:47 - templates already we have created now
385:50 - just see over here what is a what is a
385:52 - PR prom template most llm application do
385:54 - not do not pass user input directly into
385:57 - llm most of the application you will
386:00 - find out you just require a single word
386:02 - I given you the example yes by using
386:04 - this prompt template you can achieve
386:06 - that particular functionality and here
386:08 - is example for that got it now here is a
386:11 - chat comprom template so each and
386:13 - everything you'll find out over here and
386:17 - uh as uh like you will find out the
386:19 - latest version so there might be some
386:21 - sort of a changes in a code and all but
386:24 - don't worry the concept ccept will
386:25 - remain same we'll find out some changes
386:28 - in a code in a classes the name of the
386:30 - classes but the core concept will same
386:33 - if you're getting any error in a new
386:35 - version then check with the like
386:37 - documentation and try to rectify it
386:39 - that's it so here is a quick start and
386:41 - you can go through with this quick start
386:43 - and you can understand a different
386:44 - different things now security wise they
386:45 - have given you the different different
386:46 - thing now let me come to the next part
386:48 - so over here just click on this G to
386:50 - started again they have given you the
386:52 - different different uh thing prompt is
386:54 - there model is there which model you
386:56 - going to use output parser entire
386:57 - pipeline okay R they have included their
387:00 - R also now okay so retrieve augumented
387:03 - generation so you can go through with
387:05 - this and you can understand what is this
387:06 - R but don't worry I will cover this in
387:08 - my uh next class this RG it is I'm
387:12 - having this R in my pipeline so I will
387:13 - try to cover it this U uh in a live
387:15 - class itself in a Jupiter notebook
387:17 - itself I will write it on the code now
387:19 - over here you can understand about a
387:21 - different different thing different
387:22 - different concept just just go through
387:23 - with this document it's amazing one now
387:25 - interface is there so prompt chat model
387:28 - llm out part are retriever tool these
387:30 - are the things just just go through with
387:32 - this try to understand it now how to so
387:34 - here is a different different thing
387:36 - which they have mentioned Right add
387:38 - fallbacks bind R time runable Lambda
387:41 - many things right so here you will find
387:43 - out the cookbook so inside the cookbook
387:44 - everything they have given you
387:46 - everything prompt plus LM so the thing
387:48 - basically which we are going to do over
387:50 - here uh which we are going to do as of
387:51 - now they have mentioned it over here R
387:54 - RG this was this was not there
387:57 - previously when I had checked recently
387:59 - they have added in a new version so R is
388:01 - there so here you will find out the code
388:03 - related to the r see this one now here
388:05 - multiple chains chains I will come to
388:07 - this chains after this one I will
388:08 - explain this chains right so here you
388:10 - can see the change and all so each and
388:12 - everything they have given you but as of
388:14 - now we are trying to understand this
388:15 - particular part we are trying to
388:17 - understand this agent and we are trying
388:18 - to understand this model input output so
388:21 - prompt already we talked about chat
388:23 - model already I shown you by using the
388:24 - open
388:25 - so this is like pretty amazing document
388:27 - guys so once you will go through with
388:29 - this document now you will find out uh
388:31 - it is having so many things and they
388:33 - have given you the code and all each and
388:34 - everything they have provided you
388:36 - believe me guys so just go through with
388:37 - this one and try to understand uh
388:40 - different different thing or whatever
388:41 - thing basically is there so we going to
388:43 - understand this chains now and we'll be
388:45 - try we'll try to understand this memory
388:47 - but apart from this chains and memory it
388:49 - is having lots of thing which uh we
388:51 - might uh we might use in our application
388:55 - if if you are creating application now
388:57 - so this concept uh like might come into
388:59 - the picture regarding the RG or
389:01 - regarding a different different one
389:02 - different different topic basically
389:04 - which they have included but over here I
389:06 - would like to tell you one thing
389:07 - whatever I'm explaining you in a Jupiter
389:09 - notebook U if you are a beginner that
389:12 - definitely it's a more than uh it's more
389:13 - than enough for all of you and uh in the
389:16 - next class once uh when I once I will
389:18 - implement the project now then uh you
389:20 - will find out the importance of it and
389:22 - don't worry I will uh keep some latest
389:25 - thing also like R and all inside my
389:27 - project and inside my uh future classes
389:29 - and you will get to know that so here uh
389:32 - I have given the overview now let me
389:35 - talk about this uh agent type so there
389:37 - basically you have seen one thing that
389:39 - was the agent type now let me talk about
389:42 - this agent type what is this so here you
389:45 - can see guys in a agent itself you'll
389:47 - find out the agent type see agent type
389:49 - just just click on this agents and here
389:51 - you will find out the agent type now we
389:53 - have a different different type of agent
389:54 - zero short Agent Zero short react agent
389:57 - structure input react
389:59 - agent openi function yesterday I have
390:02 - talked about this openi function and now
390:05 - it's a legacy people are not using it
390:08 - people are using this agent concept from
390:11 - the lench and directory people are not
390:13 - using this open function uh but still I
390:16 - have explained you that so here you will
390:18 - find out the conversation self ass react
390:20 - documentation and all and this zero
390:21 - short is nothing it's a basic one so if
390:23 - you're going to ask something to your LM
390:25 - model to your GPT model so you will use
390:27 - the zero shot react now here you will
390:30 - find out this this agent use a react
390:31 - framework to determine which tool to use
390:33 - based on a solar on the tools
390:35 - description so whatever tool description
390:37 - you are giving based on that it will
390:38 - search the uh like compatible tool and
390:41 - it will provide the prompt to that
390:42 - particular search engine or to that
390:45 - particular tool and it will give you the
390:46 - out that's it zero short
390:48 - react now here this is the most general
390:51 - purpose action agent you can see the
390:54 - node so this thing is clear to all of
390:56 - you now let's start with the
390:58 - chains so are you comfortable till here
391:01 - and if you're not able to write it on
391:02 - the code along with me sometimes it
391:05 - happens in the live session don't worry
391:07 - just listen to me just listen to my
391:09 - words whatever I'm saying and practice
391:11 - after the class practice after the live
391:14 - session recording will be there and
391:16 - resources also will be there so let me
391:18 - write it the chain over here and let's
391:20 - start with the chain
391:23 - now
391:25 - so first of all tell me guys this part
391:27 - is getting
391:30 - clear how many days you will take to
391:33 - come up with an end to end project one
391:35 - day only one day I will take to come up
391:36 - with an end to end
391:39 - project so lench is only made for the
391:41 - NLP use case or any other compete
391:43 - capabilities also it is having as of now
391:45 - I have used this for the NLP use cases I
391:47 - will have to explore the recent uh thing
391:49 - whatever is there inside the Lenin maybe
391:52 - uh we can use it for the other uh like
391:54 - for the other task also but I haven't
391:56 - explored it for the other task I just
391:57 - use for the NLP once I will explore it I
392:00 - will let you know that whatever recent
392:01 - update is there but if you want to know
392:03 - about it just go through with the recent
392:12 - documentation all the llm has only text
392:14 - or code generation capability yes but
392:16 - you can do many whatever NLP task is
392:19 - there now you can do by using the llm
392:20 - because it is having the code generation
392:22 - capability with that it can understand
392:24 - the pattern inside the data so you can
392:27 - fine tune it it is uh possible you can
392:29 - fine tune inside your CPU Itself by
392:31 - using your CPU I will let you know uh
392:34 - otherwise I will share the resources
392:36 - with all of you uh don't worry we we'll
392:39 - come to that and uh we'll try to talk
392:41 - about it uh not as of now later on but
392:44 - yeah uh I will give you the glimpse of
392:53 - that
392:58 - great uh I think uh now people are
393:02 - getting many
393:06 - things we are using uh not completely
393:10 - actually if you don't know about those
393:12 - thing you won't be able to understand
393:14 - this particular part that's why first I
393:16 - started from the basic from the open
393:18 - itself otherwise directly I can start
393:20 - from the lch and then uh again you will
393:22 - ask to me sun what is this uh
393:25 - what is this open Ai and what is this
393:28 - llm what is this genitive AI I can even
393:32 - I can start from here itself from the
393:34 - Leng chain so but I started from the
393:36 - very
393:53 - basic
394:09 - okay so let's start with a a new topic
394:13 - uh that's a chain so what is a chain so
394:15 - let's understand the
394:17 - chain so first of all I can uh show you
394:20 - the documentation and
394:23 - uh
394:25 - just a
394:31 - wait great so here actually what I did I
394:33 - kept one a simple definition of the
394:35 - chain and let me copy and paste
394:53 - it
394:58 - so here is a definition just try to read
395:00 - this particular definition and try to
395:02 - understand the meaning of chain and it
395:04 - will be more clear once I will write it
395:06 - on the code so Central to length chain
395:08 - is a vital component uh known as a lang
395:10 - chain chains forming the core connection
395:12 - among one or several large language
395:15 - model in certain sophisticated
395:17 - application it become necessary to chain
395:19 - llm together either with each other each
395:23 - other or with other element so if you're
395:26 - not able to understand by this
395:28 - particular definition so let me open the
395:30 - documentation for all of you so here in
395:33 - the go inside this more uh just click on
395:35 - this more and here is a chain just uh
395:38 - read about this chain so using an llm in
395:42 - isolation is fine for a simple
395:44 - application but more complex application
395:47 - require chaining llm either with each
395:50 - other or with other component now what
395:53 - is the meaning of it
395:54 - so just uh okay so I have uh explained
395:58 - you the agent that's why I explain you
396:00 - the agent at the first place and then I
396:01 - came to this chain now tell me guys this
396:06 - llm was not working over there so I
396:10 - changed what I did now I Chang I changed
396:13 - the terminology so what I did guys now I
396:16 - so this LM was not working for that
396:18 - particular prompt so after coming to
396:20 - this llm means let's say if I'm not
396:22 - getting any sort of output so I came to
396:24 - to this
396:25 - chain and this chain actually it was
396:28 - connecting to me it was connecting to me
396:31 - to The Sur API through the surp API
396:35 - basically it was connected to me Google
396:37 - search engine getting my point so here
396:41 - what is the meaning of chain so chain is
396:43 - nothing okay if if you're talking about
396:45 - chain in journal so let's say this is a
396:49 - chain so something like this you will
396:51 - find
396:52 - out so what is this what do this guys
396:54 - tell me so chain is nothing which is uh
396:58 - like connecting a several
397:01 - components which is connecting a several
397:04 - component getting my point yes or no I
397:07 - think you are getting try to understand
397:08 - it what is a chain so chain is nothing
397:10 - it is just connecting a several
397:12 - component so here they are
397:15 - saying using llm in isolation it's fine
397:20 - but in complex application require
397:23 - chaining that the example I shown you by
397:25 - using the agent if you will read it if
397:28 - you will read the answer of the if
397:31 - you'll read the answer of the agent
397:33 - agent I'm running agent don't run and
397:34 - you are getting an answer so if we'll
397:36 - read that you'll find out it is chaining
397:38 - means for is trying to find out
397:40 - somewhere else it's not able to get then
397:42 - again it is going to somewhere else and
397:44 - it's going to take a information then
397:45 - again it is going to call some other
397:47 - prompt and it's going to take a
397:50 - information so what is a chain so chain
397:52 - is nothing it's a collection of
397:54 - component now which component what
397:56 - component whatever component maybe
397:59 - inside the uh like uh uh like whatever
398:02 - let's say we are using length chain and
398:04 - inside that we have a different
398:05 - different component I'm going to chain
398:07 - to those particular component and maybe
398:09 - I'm going to uh like connect with other
398:11 - llm so I can do that as well or maybe
398:13 - I'm going to connect any third party API
398:16 - I can connect that as well so I'm doing
398:18 - a chaining if I'm running chat agent.
398:21 - run now internally it is doing a
398:23 - chaining
398:24 - getting my point I think you're getting
398:26 - now let's try to understand in terms of
398:28 - python code so here first I will start
398:31 - with a very basic example so what I can
398:35 - do here so here uh first of all I can
398:38 - write it on my
398:39 - client so here is my client guys c r i e
398:42 - n t this is what this is my client now
398:44 - what I will do guys so here I'm going to
398:47 - import The Prompt template so this is
398:49 - what this is my prompt template and by
398:51 - using this prompt template I'm going to
398:53 - create I'm going to
398:55 - create uh I'm going to create one prompt
398:59 - so here is what here is my prompt so
399:01 - what is a good name for a company that
399:03 - makes a product so here I can run it and
399:05 - let's say uh I'm going to write it down
399:08 - any company name so okay I'm going to
399:10 - write down the uh actually I want a
399:12 - company name what is a good name for a
399:14 - company that makes a product so I'm just
399:18 - asking to my chat GP okay I I'm making
399:20 - this particular product just give me a
399:21 - good name for this particular company so
399:23 - here I'm going to write down let's say
399:24 - wine so wi so here I uh I'm uh just just
399:28 - think that uh just think like that that
399:30 - I'm going to open a company uh and here
399:33 - I'm going to produce a wine and all uh
399:35 - okay so I want a name any creative name
399:39 - okay that I'm asking to my LM model now
399:42 - here if I will uh like close it so what
399:45 - I'm going to do so here I'm going to run
399:46 - it so uh prompt. format so this is what
399:50 - this is my prompt what is a good company
399:52 - name for a what is a good name for a
399:54 - company that makes a wine so that's
399:56 - going to be my
399:57 - prompt p r o p Mt so this is what guys
400:01 - this is my prompt now what I will do so
400:03 - here actually I'm going to import the
400:06 - chain here I'm going to import this llm
400:09 - chain here I'm going to import the llm
400:11 - chain just just be with me just for uh
400:14 - next 5 minute everything you will get
400:18 - it's my promise to all of you I have
400:20 - simplified every thing every uh like uh
400:23 - every line of code just be with me next
400:25 - for 5 minute so here you can see we have
400:27 - a llm chain now what I'm going to do I'm
400:29 - going to create a object of this llm
400:33 - chain now guys uh here I'm not going to
400:36 - call a predict method I'm not going to
400:40 - call a predict method what I'm going to
400:41 - do so here in this llm CH what I'm going
400:44 - to pass guys I'm going to pass client
400:46 - right and I'm going to pass my prompt
400:49 - that's it this two thing I'm going to
400:50 - pass so llm llm is what c l i n t and
400:54 - here I'm going to pass my prompt so p r
400:56 - o p Mt prompt is equal to
401:00 - prompt so I passed the client and I
401:03 - passed the prompt here now this is what
401:05 - this is my llm Chen right I'm going to
401:07 - connect both component LM and my prompt
401:11 - now over here what I'm going to do so
401:13 - this is what this is my chain this is
401:14 - the object basically which I have
401:15 - created now here you can see it is
401:18 - saying that uh it is giving me
401:21 - a why I'm getting it let me check with
401:24 - the
401:28 - prompt so here uh let me run it first of
401:32 - all what is a good company that makes a
401:38 - wine okay from template uh I think I
401:42 - will have to
401:43 - use format uh I think I will have to use
401:48 - this particular prompt only uh this one
401:50 - this only uh let me delete it because it
401:52 - is asking
401:54 - I need to provide in the form of
401:56 - dictionary so I cannot pass a direct
401:58 - prompt over here what is a uh because uh
402:01 - here whenever I'm running this uh
402:03 - whenever I'm calling uh the run method
402:05 - Now by using this chain then
402:06 - automatically it will uh like take the
402:08 - name from here itself so let me delete
402:10 - it let me delete this particular line
402:12 - I'm going to delete it guys this one so
402:15 - here is what here is my prompt now Len
402:17 - chin llm chain and here now it is fine
402:20 - now what I will do here I'm going to
402:22 - write down chain and chain. run and here
402:26 - actually I need to pass the value so
402:28 - here I'm going to pass y now if I will
402:31 - run it now see it is giving me answer
402:34 - the name of the company is what it's a
402:37 - uh sdip strip and is the name of the
402:41 - company is what Vintage Wines Winery so
402:44 - it it has given me a name of the company
402:47 - like I want to create this particular
402:48 - product and here it has generated answer
402:52 - now I'm going to change
402:54 - I I'm making a chain by using two
402:57 - components the first one is llm model
402:59 - that is that I'm getting from the openi
403:02 - and which is available inside my client
403:04 - and the second is what second is a
403:06 - prompt which I'm passing over here so
403:08 - now I can directly run it by giving the
403:10 - keyword and here you can see I'm getting
403:12 - answer so I'm changing this two thing
403:14 - this is the simple this is the simplest
403:16 - uh like uh there simplest example I've
403:18 - given you now let come to the second
403:20 - example so over here what I'm going to
403:22 - do so here I'm giving the the second
403:24 - example example
403:27 - two example two so I took one more
403:31 - example to for explaining uh this
403:33 - chaining part actually so here uh let me
403:36 - copy and paste so here is what guys here
403:38 - is my prompt template this is what this
403:40 - is my prompt template now here I'm
403:42 - asking uh this is what this is my
403:44 - template I want uh to open a restaurant
403:47 - for cuisin Indian cuine Chinese cuisine
403:49 - Mexican Cuisine Japanese cuisin American
403:51 - Cuisine whatever for that I want a f see
403:54 - name this is my prompt template let me
403:56 - run it here I'm running it now if you
403:59 - will find out the prompt template so
404:01 - here you will find out the prompt
404:02 - template so this is what this is my
404:03 - prompt template got it now what I will
404:07 - do guys here I will make a chain so what
404:09 - I'm going to do so here I'm going to
404:11 - make a chain so let's say uh this is
404:13 - what this is my chain so llm chain and
404:16 - I'm going to combine two thing first is
404:18 - client and the second is what the second
404:20 - is promt template now if I will uh run
404:23 - it so so here I'm getting my chain then
404:25 - I will write it down chain do run now
404:28 - I'm uh let's say I'm giving something
404:31 - over here let's say I'm giving uh
404:34 - Chinese so according to that it will
404:37 - give me answer so the answer which I'm
404:39 - getting the golden dragon dragon place
404:42 - so here what I'm getting guys I'm
404:43 - getting this Golden Dragon place so the
404:47 - emperor's kitchen that's the name okay
404:50 - if I'm writing over here uh Indian let's
404:52 - say what I will be getting so Indian so
404:55 - here actually I'm getting Maharaja
404:56 - Delight so just the name it is
404:58 - suggesting me one name which I'm asking
405:01 - to my llm model that's it now let me
405:04 - show you few more thing over here now so
405:07 - here I'm getting a a response and the
405:09 - response is fine now let me uh come to
405:13 - the second thing second example so here
405:16 - what I'm going to do so here let me show
405:19 - you something so now over here if you
405:22 - want to see the detail actually so for
405:24 - that I have mentioned one more thing
405:25 - that is a verbos parameter as I told you
405:28 - earlier if I want to check all the
405:29 - detail whatever is happening in back end
405:31 - so for that there is a parameter verbos
405:33 - is equal to true now if I will run it
405:35 - now see what I will find out uh let me
405:38 - predict with some name so let me uh
405:41 - check uh chain. run and here I can write
405:44 - it down let's say America so here it is
405:48 - saying that entering new llm chain
405:51 - prompt after formatting I want to open a
405:54 - restaurant for American food suggested a
405:56 - fancy name for this and here is a name
405:58 - American spice Visto so you can see the
406:01 - complete detail over here what is
406:03 - happening by using the barbos true until
406:06 - here everything is fine everything is
406:08 - clear now guys here uh this is the
406:11 - simple chain basically which I have
406:13 - created by using this two component now
406:15 - let me explain you One More Concept over
406:17 - here so here actually I have written one
406:19 - definition or I have written one text uh
406:22 - just let me explain you the this
406:23 - particular part and then uh again I will
406:25 - try to revise you so here I'm going to
406:28 - mark down it and here guys see what I'm
406:31 - saying if you want to combine multiple
406:33 - change and set a sequence for that we
406:36 - use Simple sequential chain simple as
406:40 - simple as that right so if you want to
406:42 - combine a multiple chain if you want to
406:44 - combine a multiple chain and set a
406:46 - sequence for that we use a simple
406:49 - sequential chain so let's try to use the
406:51 - simple sequential chain and let's
406:54 - understand what is it so for that
406:55 - basically I have designed one prompt
406:58 - okay just just understand over here so
407:00 - step by step we'll try to understand see
407:02 - Ive already written a code in my doc I'm
407:04 - just copy and pasting so that I can save
407:06 - my time that's it everything is same see
407:08 - I can write it now the code in front of
407:09 - you also but it will take some time for
407:12 - writing this particular uh statement on
407:14 - all it's the same thing okay wherever I
407:16 - have to write from scratch I will do
407:17 - that now over here see uh let's try to
407:22 - understand step by step
407:37 - now over here this is what this is my uh
407:41 - second prompt so in the first prompt see
407:44 - in the first prompt The Prompt template
407:46 - which I have defined what I'm saying
407:47 - over here I'm saying uh I want start a
407:51 - startup right I want want a start a
407:54 - startup and suggest me a good name so
407:57 - here is my prompt now here you can see
407:59 - this is my input variable that is what
408:00 - that is a startup name yeah it's fine
408:03 - it's clear to all of you now here I've
408:05 - created a chain by using this a model
408:07 - this is my model and this is my prompt
408:11 - template okay this is the first shap now
408:14 - here I have created one
408:16 - more prompt now here I'm saying uh
408:20 - suggest some strategy for the name so
408:22 - whatever name name whatever name I will
408:25 - get from here startup name for that what
408:29 - I want I want some sort of a strategy
408:32 - let's say I'm going to open or I'm going
408:34 - to start my atte startup so for that
408:36 - what I require tell me so I for that
408:38 - basically I require audience I required
408:39 - my team I required my Marketing sales
408:41 - team if I want to open any fintech
408:43 - startup or if I want to start any
408:45 - consultancy or whatever right whatever
408:47 - uh like company which I want to start so
408:50 - regarding that what I want I want some
408:51 - sort of a strategy
408:54 - getting my point here yes or no so now
408:57 - what I will do I will combine this two
408:58 - change see here this this is my first
409:01 - change this this this is what this is my
409:02 - first chain this one and this is my
409:05 - second
409:06 - chain now I will combine this both Thing
409:09 - by using simple sequential chain I will
409:11 - making I'm making a
409:13 - sequence I'm trying to make a sequence
409:15 - between these two
409:17 - chain okay before I I was just running
409:20 - with a single uh like uh with a single
409:22 - chain only and we we are having only two
409:24 - component llm and my prompt now here I'm
409:27 - going to come my true chain now just
409:29 - tell me guys here I'm using this
409:31 - particular llm can I use a different llm
409:34 - over
409:35 - here I can try with that I can check
409:38 - right so here I'm using a same model now
409:42 - I can check with a different LM also in
409:44 - this particular case so this chain is a
409:46 - pretty amazing thing it is connecting a
409:49 - homogeneous component or it is it can uh
409:52 - we can connect a hetrogeneous component
409:54 - also means some other model as well you
409:57 - can test it with the other model uh so
410:00 - here you can see we are able to do it
410:02 - now guys here what I will do so here is
410:04 - my first template this is my first chain
410:07 - this is my second template this is my
410:08 - second chain now what I will do over
410:10 - here so here I'm going to import a
410:12 - sequence uh so here I'm going to import
410:15 - a simple sequential chain here I'm going
410:17 - to import this simple sequential chain
410:20 - now once I will run it so here I
410:21 - imported now let me create
410:23 - a now let me create a object of it so
410:27 - here guys here is a object now inside
410:29 - this object inside while I'm creating
410:31 - object I will pass some sort of a
410:33 - parameter so it will call my init method
410:35 - okay in a back end now here I'm going to
410:37 - pass some sort of a parameter and that's
410:39 - going to be a very very easy and here is
410:41 - the parameter name so chains first is
410:44 - name chain and the second is stategy so
410:46 - automatically see what will happen
410:48 - actually first it will call to this one
410:51 - it will uh generator startup name
410:53 - automatically it will give uh it it will
410:55 - give name to this particular uh like a
410:58 - to this particular template
411:00 - automatically it will fetch from there
411:01 - itself and I will be getting this
411:04 - strategies I will be getting this
411:06 - particular strategies automatically
411:08 - chaining automatically chaining is
411:10 - happening okay this one now let me show
411:13 - you how so over here uh what I will do
411:16 - so let me uh create object and here I
411:18 - just need to call a method so here I'm
411:21 - going to call uh method that's going to
411:25 - be a chain. run now here I want to open
411:28 - a startup let's say the startup related
411:30 - to the artificial intelligence so here
411:32 - I'm going to write it down
411:33 - artificial
411:35 - intelligence now here once I will call
411:38 - it so let me run it and let's see what I
411:41 - will be getting over here so I'm making
411:44 - a sequence guys between a
411:47 - prompts so it is saying that uh develop
411:50 - a strong marketing strategy and and some
411:53 - sort of a information let's let me print
411:56 - it uh so that I won't get this
411:59 - lesson so here is my
412:04 - strategies stay informed and up toate on
412:07 - a latest AI train develop a
412:10 - comprehensive uh AI strategy utilize AI
412:13 - tools utilize data driver inside so
412:16 - these are some sort of a strategy
412:17 - actually see automatically I'm getting
412:19 - see this name now which which we have
412:21 - defined see startup name which is coming
412:23 - over here okay then whatever name is
412:25 - coming from there automatically is going
412:27 - over here this inside this name and we
412:29 - are getting a strategies we are chining
412:31 - we are chining right now this is a
412:34 - simple sequential chain now here uh here
412:38 - we have one drawback actually uh we it
412:41 - is giving me a final answer it is not
412:43 - giving me a answer uh it is not giving
412:46 - me answer related to the first prom it
412:48 - is not giving me it is not giving me
412:50 - that particular answer it giving me a
412:52 - direct uh the last one answer from the
412:54 - last uh like a prompt itself if you want
412:58 - answer like from the entire prompt so
413:02 - for that also we have one method okay uh
413:05 - sorry we have one more class let me show
413:06 - you that particular class now so here uh
413:09 - what we can do so I already written the
413:11 - name so let me give you that particular
413:14 - uh name and here is what here is a name
413:18 - guys so the name is what now let's try
413:20 - to understand the sequential chain so so
413:22 - far actually we have understand the
413:24 - simple sequential chain now we are going
413:26 - to understand the sequential chain and
413:29 - it is having a more power compared to
413:30 - this SE uh simple sequential chain where
413:33 - we can uh keep uh the sequence sequence
413:36 - of the different different prompts and
413:38 - the different different chains now uh
413:41 - let's try to understand this sequential
413:42 - chain and here what I'm going to do here
413:45 - I'm going to copy one more code now let
413:47 - me paste it over here so again I'm going
413:50 - to create okay already I have a client
413:52 - so let me move it it is not required at
413:54 - all so here is my prompt template and
413:57 - what I'm saying here I want to open a
413:58 - restaurant suggest me a fancy name now
414:00 - just see over here what I'm going to do
414:02 - I'm going to mention one key over here
414:04 - that is what there is my output key and
414:06 - what is my output key output key is
414:07 - nothing it's a Resturant name right now
414:10 - now just see over here where I'm going
414:11 - to use this output key so here I'm going
414:13 - to Define one more parameter one more
414:15 - prompt template and here guys you can
414:17 - see so in this particular prompt
414:19 - template prompt template name we have a
414:21 - prompt template and and here input
414:23 - variable kin and this is a template now
414:25 - here is my chain llm chain this is my
414:27 - model this is my prompt template and
414:29 - here we have a output key output key is
414:32 - what restaurant name so whatever name
414:35 - basically whatever name I will get from
414:38 - here I will keep inside this restaurant
414:41 - name and this restaurant name I'm
414:44 - passing over here this restaurant name
414:47 - I'm passing over here and here whatever
414:50 - thing I will get from here from this
414:53 - particular prompt I'm keeping inside the
414:55 - menu item and if you are going to create
414:57 - a next
414:59 - prompt you can mention over there now
415:03 - let me run it and let me show you what
415:04 - will be the final answer over here so
415:07 - here I'm going to import the sequential
415:09 - chain and here you can see so this is
415:11 - what this is my sequential chain and now
415:13 - let me copy it and let me paste the
415:16 - final code and here is my uh object of
415:20 - the sequential chain so let let me keep
415:23 - it in a single line so here sequential
415:25 - chain this is the object which I have
415:27 - created now change what I want to chain
415:29 - means like in terms of what I want to
415:31 - make a chain so this is the first name
415:33 - name chain this is the one now second
415:35 - chain is what food item chain means I
415:37 - want a food item regarding that
415:40 - particular restaurant now over here this
415:42 - is my input variable and here is my
415:44 - output variable restaurant name and menu
415:46 - items this
415:48 - one Whatever output I'm getting from
415:50 - here I'm keeping over here inside this
415:52 - variable whatever output I'm getting
415:54 - from here I'm keeping over here inside
415:55 - this variable and I'm going to mention
415:58 - inside the output variable if you want
415:59 - to make a further chain you can do it
416:02 - according to your problem statement now
416:04 - let me run it and let me show you the
416:06 - final answer and the final response so
416:09 - here I am going to call this method
416:13 - chain okay so this is about this is my
416:15 - chain and here let me run it and see
416:18 - what I will be getting so chain and I'm
416:22 - I'm passing cuisin Indian so it is
416:24 - giving me cuin is what cuin is Indian
416:26 - and here is a restaurant name there's
416:28 - going to be a Taj Mahal Palace Taj
416:31 - Maharaja Palace and here is a menu item
416:34 - now so guys this is the response which
416:36 - I'm getting over here can you see over
416:39 - here the response which I'm getting all
416:41 - the thing all the thing in a sequence
416:43 - now let me revise this particular thing
416:46 - revise me this particular concept so
416:48 - chain what is a chain which is going to
416:50 - connect two components so here what I
416:52 - did see here I have connected two
416:54 - component first is model second is
416:57 - prompt now in example two you can see
416:59 - what I'm going to do so same thing I'm
417:00 - going to perform now in the third one uh
417:02 - with the entire detail actually with our
417:04 - entire detail now in the third one I'm
417:06 - calling simple sequential chain in that
417:09 - I'm getting a output from the last
417:12 - prompt but if we are talking about a
417:14 - sequential
417:15 - chain instead of the simple sequential
417:17 - chain I'm using sequential chain so I'm
417:20 - getting a entire output over here means
417:23 - from first template uh from first prompt
417:25 - template to last prompt template and
417:28 - here you can see we are mentioning this
417:29 - output key so whatever answers I'm
417:32 - getting over here whatever answers I'm
417:34 - getting from this particular uh prompt
417:37 - right we are able to store it over here
417:39 - and we are passing to the we are passing
417:42 - to the next prom we are passing to the
417:44 - next uh like a prompt basically over
417:47 - here you can see this one same
417:48 - restaurant name and we are going to
417:51 - combine it finally
417:52 - so guys tell me do you like it did you
417:55 - understand
417:57 - it I will come to that the purpose and
418:00 - all everything will be clarified right
418:02 - so uh we will talk about because
418:04 - everything should be connected now to
418:05 - each see whenever uh like if you are
418:08 - going to ask to anything uh to your chat
418:11 - GP what do you think tell me so how this
418:14 - application is working we are are we are
418:17 - like uh what we are going to do guys so
418:20 - we are reaching step by step actually we
418:22 - are trying to reaching to our final
418:24 - application understand guys so here if
418:26 - someone has created this chat GPT it
418:29 - they have implemented everything
418:31 - whatever we are going to run by using
418:33 - this Len chain here you will find out
418:35 - the memory concept okay let me ask one
418:37 - question to my CH gbt so here here I'm
418:40 - asking can you tell
418:42 - me can you tell me about something Taj
418:47 - okay so here uh I'm asking this question
418:49 - to my chat jpd now here you can see
418:52 - uh uh like uh here is the answer now I'm
418:56 - asking to my chat GPT 2 + 2 how much so
419:01 - it is saying to me let me run it so here
419:03 - it is saying to me 2 + 2 is nothing it's
419:05 - a five okay sorry uh it's a four right
419:09 - now here if I will ask to my chat GPT
419:11 - how much 100 uh
419:14 - multiply by 1,000 now if I will run it
419:17 - so here you will get the answer now here
419:20 - if I will ask to my CH GPT
419:24 - who
419:26 - uh build the Taj Mahal can you who built
419:32 - the Taj Mahal so here if I'm going to
419:35 - ask this particular question so here you
419:37 - can see the Taj m b by the mul Emperor
419:40 - so actually it is not going to forget
419:42 - the context whatever you are asking now
419:44 - previously it is able to sustain the
419:47 - that particular memory it's a biggest
419:50 - power of the CH GPT so we are trying to
419:53 - reach uh like step by step we are going
419:55 - to we are trying to understand all sort
419:57 - of a thing by using this Len CH and then
419:59 - finally we will move to the uh the end
420:02 - uh like a goal the our end application
420:04 - now over here this chain actually is
420:05 - very important if you want to uh like a
420:08 - retain the information from the first
420:09 - prompt to the last prompt for that you
420:11 - can use this uh you can use this uh
420:14 - sequence chain I can understand you are
420:16 - uh trying to understand that where we
420:18 - are using in a real time in a
420:19 - application and all I will come to that
420:21 - part okay but just understand over here
420:24 - so I was running the Sur API so here
420:27 - actually once you will read the entire
420:29 - detail of the Sur API of this agent so
420:31 - you will find out that in like uh uh
420:34 - internally it is using the chaining it
420:36 - is trying to chain each and every thing
420:39 - back in a back end basically they have
420:40 - implement the chaining complete chaining
420:42 - so just just try to read it and finally
420:44 - it is giving me a the the like
420:46 - conclusion over here so in a similar way
420:49 - here I just shown you the example a very
420:51 - basic example but by yourself what you
420:54 - can do guys so by yourself uh like you
420:57 - can uh like create a different different
420:58 - prompts and you can implement this
421:00 - chaining concept over there and you can
421:03 - understand in a better way you can
421:05 - search about the applications and
421:08 - all getting my point yes or
421:14 - no tell me guys this thing is getting
421:16 - clear to all of you if it is getting
421:18 - clear then please do let me know in the
421:21 - chat
421:38 - so are you able to get it uh please do
421:41 - let me know in the chat guys if uh this
421:44 - thing is fine to all of
421:50 - you
422:05 - I'm waiting for a reply guys if you can
422:07 - write it down the chat and if you're
422:08 - liking the session so please hit the
422:10 - like as
422:20 - well great now let's try to understand
422:23 - uh One More Concept and then I will uh
422:25 - stop the session uh today I couldn't
422:28 - reach to the hugging phase but don't
422:30 - worry tomorrow I will show you that and
422:33 - memory also so One More Concept is there
422:36 - memory now let me show you the basic
422:37 - concept now the uh the very basic
422:40 - concept of the Leng chain which we are
422:42 - going to use in a future that is going
422:43 - to be a document loader so let me
422:45 - explain this document loader also so
422:48 - here uh what I'm going to do I'm going
422:50 - to uh show you that how you can read any
422:53 - sort of a document by using this uh by
422:56 - using this length chain now once you
422:58 - will search uh let me search over the
423:01 - Google
423:03 - Document
423:06 - loader document loader Lang chain
423:10 - documentation so simply I'm searching
423:12 - about this uh document loader on top of
423:14 - the documentation so here uh let me open
423:19 - this document loader so once you will
423:21 - come inside this module now and here is
423:23 - a uh here is a like option retrieval now
423:27 - inside that you will find out a document
423:28 - loader so CSV file directory HTML Json
423:31 - markdown PDF or different different
423:33 - document you can load and it is required
423:37 - it is required I will show you where it
423:38 - is required and once I will reach to the
423:40 - Practical implementation once I will
423:42 - create any sort of a project okay so
423:44 - there I will show you how you can read a
423:46 - different different files and how you
423:47 - can utilize let's say uh you have one
423:50 - information so some information inside
423:52 - the uh txt file or maybe in the format
423:55 - of HTML or Json or maybe CSV now you
423:58 - want to read it from there and you want
424:00 - to give it to you uh you want to give uh
424:02 - that particular information to your uh
424:05 - chat GPT or maybe GPD model so in that
424:07 - case you will have to use this document
424:09 - loader so let me show you how you can
424:11 - use this uh PDF loader so here is what
424:14 - here is a PDF loader so for that first
424:16 - the first thing what you need to do you
424:18 - need to install this P PDF so just open
424:21 - your notebook and here write it down
424:23 - this pip install pip install P PDF so
424:28 - once you will write it down this pip
424:30 - install P PDF you will be able to
424:32 - install this Pi PDF inside your virtual
424:35 - current virtual environment now after
424:36 - that you need to lo you need to write it
424:38 - down this particular command uh you need
424:40 - to write it down this particular import
424:41 - statement from lench do document loader
424:44 - import Pi PDF loader right from the
424:47 - documentary itself I'm going to take it
424:50 - I I'm I'm I'm not going to write down by
424:52 - myself here I'm showing you the power of
424:54 - the documentation so once you will
424:56 - explore it you will get a many more
424:58 - thing from here itself right whatever
425:01 - like you want so here I'm going to uh
425:04 - what I'm going to do guys so here I'm
425:05 - going to mention this import statement
425:08 - now we have one uh ex uh now here
425:12 - actually we have to call this particular
425:14 - method sorry we have to create a object
425:16 - of this particular uh class and here let
425:18 - me paste it down so this is the pi PDF
425:21 - Lo now I have to pass my PDF I have to
425:24 - give the uh I have to like write it down
425:27 - the my path whatever is there uh in my
425:29 - local system so inside my download let
425:32 - me check any PDF is there or not so let
425:35 - me check with the
425:39 - PDF LM here is a PDF machine translation
425:44 - attention so let me copy the path uh let
425:47 - me paste it down over there let's see it
425:49 - is able to read it or not
425:52 - so where is a path guys here is a
425:58 - path let me copy the path and I have
426:01 - copied the absolute path now where it is
426:04 - here is my code so here I pasted my path
426:08 - and let's see it is going to load or not
426:10 - it's showing a uni code error so let me
426:12 - put the r over here and it is done now
426:15 - let me check inside the loader that what
426:17 - I have so here it is created the object
426:20 - now let me I write it down the loader
426:24 - over here loader do loader so once I
426:27 - will write down this thing so here you
426:29 - will see that uh okay l a d r loader do
426:35 - loader P object no attribute
426:37 - loader uh what is this let me check the
426:40 - documentation here they are calling
426:42 - loader and split and that will give you
426:45 - the
426:45 - pages great so let me call this uh
426:50 - loader and split
426:52 - and here I have a Pages now let's see we
426:54 - have a Pages yes I got the entire detail
426:58 - so see I able to read the PDF by using
427:02 - this document reader why I've shown you
427:04 - this thing because uh it will be
427:06 - required we use now pandas do read CSV
427:11 - for uh like collecting any any sort of a
427:14 - data in the form of data frame right so
427:16 - if I want to uh take any data if I want
427:19 - to format any data in the form of data
427:20 - frame so so we use this pd. read CSV or
427:23 - we use np. aray similarly if you want to
427:25 - read any a document by using this L
427:28 - chain you can do it you can do it guys
427:31 - so here there is another one and uh you
427:34 - can take it as assignment you can read
427:36 - the CSV there is a complete code here is
427:38 - a uh code for the file directory here is
427:40 - a like HTML here is a Json markdown is
427:44 - there there's a different different uh
427:45 - like a uh different different document
427:48 - loaders you will find out now guys uh
427:50 - let's try to revise the thing let's
427:52 - revise the session what all thing we
427:53 - have learned in today's class in today's
427:55 - session and then I will conclude it and
427:58 - in tomorrow's session I will start from
427:59 - the memory memory and finally hugging
428:02 - face sorry actually I went uh into some
428:05 - depth Okay I uh I try to explain New
428:08 - Concept in a detail way that's why I
428:10 - couldn't start with a hugging face API
428:12 - but don't worry in tomorrow's session I
428:14 - will show you how you can uh how you can
428:17 - uh download any open source model how
428:20 - you can use any open source model model
428:21 - by using the hugging pH API and then uh
428:25 - right after that we'll try to create our
428:27 - application that is going to be a McQ
428:29 - generator we'll see that how you can
428:31 - generate McQ by giving any sort of a
428:34 - text and where this document loader
428:36 - where this chaining memory each and
428:37 - everything will come into the picture
428:39 - and even the prompt also prompt template
428:41 - right now let's revise the thing what
428:44 - all thing we have learned so let me
428:45 - revise it over here so in today's class
428:48 - uh we have talked about so where is my
428:50 - pen
428:52 - yeah so in today's class we have talked
428:54 - about this agent I have shown you that
428:56 - how to call a third party API so here we
428:59 - have seen how to call a Google search
429:02 - engine Google search engine API Google
429:05 - search engine API so let's say uh your
429:10 - chat GPT actually has been trained till
429:12 - uh September 2021 data so if it is not
429:15 - able to give the information in a real
429:17 - time in that case you can use this agent
429:20 - you can call you can can use the concept
429:22 - of
429:23 - chain right you can use the concept of
429:26 - chain in which scenario so where you
429:28 - have a multiple prompt which is
429:29 - connected to each
429:31 - other not a simple application not a
429:33 - simple prompt just for the testing I'm
429:36 - talking in a real
429:39 - time so I'm talking in a real time uh
429:43 - just a
429:50 - wait
430:12 - uh now it is fine so here I was talking
430:14 - about this uh Google search engine and
430:18 - uh yep and then we have talked about the
430:20 - change prompt template also document
430:22 - loader now this uh two thing is
430:24 - remaining so in uh tomorrow's session I
430:27 - will start from the memory uh in
430:29 - tomorrow session actually I will try to
430:30 - explain the memory concept and then I
430:31 - will come to this hugging phas API got
430:34 - it guys yes or no so how was the session
430:37 - uh did you learn something new so please
430:39 - do let me know guys uh did you learn
430:42 - something new from here whatever I have
430:44 - explained and uh how was the session how
430:46 - was the content uh please do write it
430:48 - down the
430:50 - chat
430:54 - should I add a few more things if you
430:56 - want then uh please do let me know
430:58 - please uh write it on the chat I I'm
431:01 - like waiting for your replies and you
431:04 - you can comment also so if you are
431:06 - watching re-watching the video and if
431:07 - you want something from my side you can
431:09 - write it on the comment section you can
431:11 - tell me over the LinkedIn and yeah
431:14 - that's it so I hope you are liking my
431:16 - session so please hit the like button if
431:19 - you liking the content if you're liking
431:20 - the
431:37 - session GB 3.5 get updated till yeah ah
431:41 - recently we have seen that today
431:50 - itself
431:58 - so why we are using Len chain and
431:59 - advantages over other API you will get
432:02 - to know more about it in tomorrow's
432:04 - session otherwise just try to revisit
432:07 - the session in a starting itself I have
432:09 - talked about the limitations of the
432:11 - openai and I talked about the advantage
432:14 - of the open a clearly I have written it
432:16 - over here so just try to revisit the
432:17 - session you will get it and here I have
432:20 - tried to explain you everything what is
432:22 - a lenen it's a rapper or the open Ai and
432:25 - uh your app here is a lenen which is a
432:28 - rapper now you can hit a multiple Thing
432:31 - by using this Len
432:35 - chain yes day three not day three
432:38 - notebook will be available in your
432:40 - resource section soon it will be
432:41 - available don't worry uh yeah so this is
432:44 - it guys from my side I hope uh like uh I
432:49 - already told you the tomorrow's agenda
432:51 - uh memory and the uh hugging phas right
432:55 - so thank you guys thank you bye-bye for
432:56 - joining the session if you have anything
432:58 - any doubt or any concern or anything in
433:01 - your mind so just uh do let me know
433:03 - please uh write down the uh please write
433:06 - down your thoughts in a comment section
433:08 - and you can ping me over my LinkedIn as
433:09 - well okay so let's start with the
433:11 - session and today is a today is the day
433:14 - five day five of this community session
433:16 - Community session of generative AI so uh
433:20 - I already uh covered um most of the
433:22 - thing actually in a in with respect to
433:25 - this open a and this Lin and uh in total
433:28 - I took four session uh here you can see
433:31 - all all these four session uh where I
433:34 - have started from the introduction of
433:36 - the generative AI then I came to the
433:39 - introduction of the open Ai and we we
433:41 - have understood we have understood the
433:43 - concept of the open API then I have
433:45 - discussed about the Len chain and
433:47 - yesterday also I was talking about the
433:49 - Len chain in today this class uh I will
433:51 - be talking about the memory Concept in
433:54 - the Lang chain which was the remaining
433:55 - one and after that I will start with the
433:59 - hugging face API and then uh from next
434:02 - class onwards we'll try to uh Implement
434:05 - our first end to end project by using
434:07 - this linkchain and this open AI so uh
434:10 - guys here we have uploaded all the
434:12 - sessions all the lecture you can go
434:15 - through with this dashboard which is
434:16 - already there over the Inon platform you
434:18 - just need to sign up and after the sign
434:21 - up you need to login over there and you
434:23 - will get this particular dashboard uh
434:25 - over the in youron platform so already
434:27 - we have given you the link uh in the
434:29 - chat so please try to uh enroll yourself
434:33 - if you are new in this particular
434:34 - session uh this enrollment is completely
434:37 - free you no need to pay anything for
434:39 - this uh for this en for this particular
434:41 - session uh so you can down uh you can
434:44 - enroll inside the course and you can
434:46 - access all the uh lectures and here you
434:49 - will find out the resource section
434:51 - inside that all the resources uh is up
434:54 - to date whatever thing I have discussed
434:56 - in the live classes each and everything
434:58 - you will find out over here so let me
435:00 - show you yesterday I have discussed
435:01 - about the lure so this file is already
435:04 - there you just need to download it and
435:06 - you can uh run inside your system you
435:10 - can run inside your system you can run
435:11 - over the Google collab anywhere you want
435:14 - so I shown you the setup in in the local
435:16 - system itself you can go through with my
435:18 - previous session and there you can
435:20 - understand how to to do a local setup
435:21 - how to do a h setup with respect to open
435:24 - Ai and Linkin how to run a code
435:26 - regarding this open Ai and Lenin each
435:28 - and everything I have explained you in
435:30 - the previous classes so please go
435:31 - through with my session and uh like uh
435:34 - try to understand at least till here
435:37 - till this L and this open I so uh you
435:39 - can implement the project along with me
435:41 - whatever thing I'm going to explain from
435:43 - next class onwards uh because in today's
435:45 - class I will cover this lure memory and
435:47 - then I will come to this hugging face
435:49 - API and from Monday on onwards Monday
435:51 - onwards Monday to Friday so Monday
435:53 - onwards I'm going to start with the
435:55 - project Tuesday also I will take a
435:56 - project and then I will come to the
435:58 - vector database and then few more
436:00 - concept few uh like different different
436:02 - models uh some open source model and I
436:04 - will try to explain you this uh ai2 lab
436:07 - also that uh how you can uh access that
436:09 - Jurassic model uh which I told you in my
436:12 - initial uh like introduction so yeah I
436:15 - think everything is clear everything is
436:17 - fine to all of you so please do confirm
436:19 - in the chat if uh everything is fine
436:21 - everything is clear till here then we'll
436:23 - start with today's concept so I'm
436:25 - waiting uh for your reply please write
436:28 - it on the chat
436:35 - guys and you can find out the same
436:37 - session over the Inon YouTube channel as
436:39 - well so just try to visit the Inon
436:41 - YouTube channel and go inside the live
436:43 - section there you will find out this
436:45 - committee session already uh the
436:48 - recording is uh already we have upd the
436:51 - recording in the live uh section itself
436:53 - and in the description you will find out
436:55 - the uh you will find out this dashboard
436:57 - link as
436:59 - well uh let me show you that just a
437:09 - second yeah so here is Ion YouTube
437:12 - channel so just uh uh over the click
437:15 - over the channel and here go inside this
437:18 - live section click on this live section
437:20 - there you will find out all the
437:21 - recordings so uh this is the very first
437:24 - recording where I have discussed uh each
437:26 - and everything regarding the generative
437:27 - Ai and the second recording is this one
437:30 - the third one this is the third
437:31 - recording and here you will find out the
437:33 - fourth recording now just click uh any
437:35 - of them so after clicking just try to go
437:38 - through with the description and here
437:40 - you will find out the uh dashboard link
437:43 - and other details so each and everything
437:45 - you can find out uh over the Inon
437:48 - YouTube channel as well you you can find
437:50 - out this uh dashboard link over there
437:52 - just click on that and enroll yourself
437:55 - it is completely free now let's start
437:57 - with today's session so here I will be
438:00 - talking about the Len chain L memory in
438:03 - Len chain so how you can uh like uh how
438:07 - you can use this memory con concept by
438:09 - using this Len Chen but before starting
438:11 - with the Practical let me give you some
438:13 - theoretical explanation so what I'm
438:15 - doing here I'm going to open my
438:17 - Blackboard and here I will try to
438:18 - explain you the concept of the memory
438:21 - right and a what thing we are going to
438:23 - discuss that also I will be talking
438:25 - about here I will be writing in front of
438:28 - you and then finally we'll Implement uh
438:30 - those particular thing in a python now
438:33 - uh in the previous class I was talking
438:35 - about the Len chain and I given you the
438:37 - complete detail introduction regarding
438:40 - the Lenin that what is Lenin why we
438:42 - should use it what is the advantage on
438:45 - top of this openi API why we should not
438:47 - use openi API why we should use lenen
438:50 - each and everything we have discussed
438:53 - now in future session uh I will explain
438:56 - about the Llama index 2 so it is similar
438:59 - to Lenin and I will come to the Llama
439:00 - index 2 and it's a framework from the
439:02 - Facebook site so we'll try to discuss
439:04 - each and everything related to L related
439:07 - to this llama index 2 as well and I will
439:09 - give you the differences between Len
439:10 - Chen and Lama index 2 but as of now here
439:12 - I'm going to explain you the Len chain
439:14 - only and most of the concept I already
439:16 - discussed so if we talking about the Len
439:19 - chain so what all thing we have
439:21 - discussed so far let me tell you that so
439:25 - in the Len chain first I discussed that
439:27 - how to uh call the open a API by using
439:30 - this Len chain you can think that this
439:32 - Len chain is nothing it's a wrapper on
439:34 - top of this open a API and not only
439:36 - openi API we can access a various API by
439:40 - using this Len shed so here we have
439:42 - openi API we have seen that how to
439:44 - access and how to uh how to access or
439:47 - how to use the open API by using the
439:50 - there is just a simple import statement
439:53 - which I which we have to write it down
439:55 - inside the notebook or inside the code
439:58 - and we will be able to import it that's
440:00 - it now apart from that we have seen the
440:02 - concept of the agent I have explained
440:04 - you that what is the agent then uh I
440:06 - have explained you the prompt template
440:08 - that what is a prompt
440:10 - template prompt template how you can
440:13 - create a prompt template and all so we
440:15 - have seen each and everything regarding
440:17 - that now we have understood the concept
440:19 - of the chains that what is chains and
440:21 - what we can do by using the chains if we
440:24 - are going to define a chain right so uh
440:27 - what all thing we need to import what
440:29 - component is required what is the
440:31 - meaning of the simple uh sequential
440:32 - chain what is the meaning of the
440:34 - sequential chain each and everything I
440:36 - have discussed regarding the chains
440:38 - after that I came to the document loader
440:41 - I have discussed about the document
440:42 - loader if you want to uh load any sort
440:46 - of a document document is nothing it's
440:48 - just a like a files and all right so if
440:50 - you want to read the PDF PDF file if you
440:53 - want to read the Excel file CSV file
440:55 - HTML file or maybe any other file so you
440:59 - can um you can load that particular file
441:02 - by using this link chain it is possible
441:04 - now the fifth one now the sixth one
441:06 - which we're going to talk about that is
441:07 - going to be a memory so we'll uh discuss
441:10 - the concept of the memory first I will
441:12 - write it on the code and then again I
441:14 - will come to this memory part and try
441:16 - will try to explain you but before that
441:18 - uh I would uh I will explain this memory
441:20 - memory concept by using the chat GPD
441:22 - also before writing a code now this is
441:24 - all about the L CH these all are the
441:26 - thing basically which we need to discuss
441:28 - regarding the L chain and that's going
441:29 - to be a very important if you are going
441:31 - to implement the project end to end
441:33 - project now after that what I will
441:36 - discuss so here let me write down the
441:37 - topic name which we're going to discuss
441:39 - after this Lon so I will talk about the
441:41 - hugging phase hugging phas API how you
441:46 - can generate a token how you can
441:47 - generate a hugging phas API token and
441:50 - after that we'll try to access a open
441:53 - source model whatever model is there on
441:55 - top of the hugging phase so we'll try to
441:57 - access those particular model by using
441:59 - this hugging phase and we'll try to do a
442:01 - same thing we'll try to do a same thing
442:03 - basically which we are doing uh by using
442:06 - this open API but at this uh now at that
442:10 - time I'll will be using the open source
442:12 - model not this U uh like not this GPD
442:15 - model basically which is a uh which is a
442:17 - like model of the open a now will try
442:20 - try to access those open source model
442:22 - and then we'll try to understand that
442:24 - how uh we'll try to understand that how
442:26 - you can create a pipeline by using the
442:28 - hugging face so we'll try to understand
442:30 - the concept hugging face pipeline
442:32 - hugging face pipeline I told you this uh
442:35 - Lenin is nothing this lenen is a wrapper
442:39 - okay this lench is a wrapper on top of
442:40 - this uh open ey this lench is a wrapper
442:43 - on top of the hugging face so not only
442:45 - open AI we can interact with hugging
442:48 - face also uh by using this L chain and
442:50 - not even with hugging phase we can
442:52 - interact with many API in future I will
442:55 - explain you that I will come to that and
442:57 - if you if you want to know about it so
442:59 - you can visit the documentation
443:01 - yesterday I shown you the documentation
443:02 - of the Len chain and you can see over
443:04 - there not even open AI not even hugging
443:06 - pH we can access a multiple API by using
443:09 - Lang chain so Lang chain is nothing just
443:10 - a rapper on a different different uh on
443:14 - top of a different on top of different
443:15 - different
443:16 - API got it yes or no I think this thing
443:19 - is clear to all of you then we'll see
443:20 - how we can create a hugging face
443:22 - pipeline which we used to do by using
443:23 - the hugging pH Transformer now here also
443:26 - we can import the same thing we can
443:27 - import the hugging face pipeline by
443:29 - using the Len chain and we can create
443:31 - the pipeline and we I will show you so
443:33 - here uh by using the hugging phas API
443:36 - you can access the model by using the
443:38 - hugging face API you can access the
443:39 - model but you can install this model
443:41 - inside your local environment also
443:44 - inside a local environment also inside
443:45 - your local memory also so I will show
443:47 - you how you can perform the same thing
443:50 - by
443:51 - local llm local LM means what nothing
443:54 - I'm just going to be uh I'm just going
443:56 - to be download the model I'm just going
443:58 - to be download the model from the huging
443:59 - phase and that model itself I'm going to
444:02 - use similar to this uh GPT and all which
444:06 - I which I'm like accessing by using the
444:07 - open API or by using the Len Chen Len
444:10 - Chen and openi right so same thing I can
444:12 - do over here as well uh okay by using
444:14 - the hugging face API but if you want to
444:16 - download the model in your local memory
444:18 - in your local system that that also you
444:20 - can do that also uh you can do and that
444:23 - is also possible so I will explain you
444:26 - that part as well and finally we'll
444:27 - create a hugging phas Pipeline and from
444:30 - next class onwards we'll start the
444:32 - project implementation so uh if uh
444:35 - everything is fine until here then
444:38 - please do let me know if the agenda is
444:40 - clear to all of
444:41 - you and if you are liking the session
444:44 - then please hit the like button
444:46 - guys please hit the like button if you
444:48 - are liking the session
444:54 - I just started I I just given you the
444:56 - overview that what all thing we are
444:57 - going to discuss that's it I haven't
445:00 - started with the coding and
445:08 - all no we don't have a session on
445:10 - Saturday and Sunday uh we have a session
445:12 - from Monday to
445:18 - Friday
445:28 - great so let's start with the
445:30 - implementation so first I'm going to
445:33 - start from the memory that what is a
445:35 - memory inside the L chain and how we can
445:39 - use that so see first of all let me uh
445:42 - explain you the same thing by using the
445:44 - chat GPD so what I'm going to do here
445:47 - I'm going to open my chat GPD and let me
445:50 - write it down something over here so
445:52 - here I'm going to write it down that uh
445:55 - can you tell me uh can you can you tell
445:59 - me who won the first World Cup first
446:05 - Cricket World Cup so I'm going to ask to
446:07 - my Chad GPD that can you tell me who won
446:10 - the first Cricket World Cup so that this
446:12 - is my question which I'm going to ask to
446:14 - much chbd now let me hit the enter and
446:17 - let's see the reply so is saying that
446:20 - the first Cricket World Cup was held in
446:22 - 1975 and uh the Western de emerged as
446:25 - the champion they defeated Australia in
446:27 - the final which took place as a l uh
446:30 - Lords cricket ground in London on uh
446:32 - June 21
446:34 - 1975 so Western was the uh winner at
446:38 - that particular time now let's try to
446:39 - ask something to my chat gbt so here I'm
446:42 - asking to my chat GPT can you tell me
446:45 - can you tell me 2 + 10 so here it is
446:50 - giving me answer 2 + 10 is 12 now let me
446:53 - ask something else to my CH gbd can you
446:55 - tell me
446:57 - about the Indian GDP so here I'm going
447:02 - to ask my chat GPD can you tell me about
447:04 - the Indian GDP so it is uh saying that
447:07 - uh my knowledge up to date till uh U
447:10 - till January 2022 so I don't have a most
447:13 - recent data now it is giving up some
447:15 - more detail now you can ask the GDP you
447:18 - can ask like GDP the that what was the
447:20 - GDP in 2021 in 2022 something like that
447:23 - or whatsoever now here see what was my
447:25 - first question so here I asked the first
447:27 - question can you tell me who won the
447:29 - first World Cup who won the first
447:31 - Cricket World Cup now here see after
447:34 - writing this many of after writing a
447:36 - different different like a question now
447:38 - is still my Chad GP is able to remember
447:41 - this particular sentence this particular
447:44 - sentence because in back end actually it
447:46 - is using the memory concept it's able to
447:48 - remember the it is able to remember the
447:50 - conversation that whatever conversation
447:52 - is happening over here so here if I will
447:54 - ask to my chat GPT can you tell me can
447:58 - you tell me can you tell me the winning
448:03 - team captain so here I didn't mention
448:06 - anything and I'm just asking to my chat
448:08 - GPT can you tell me the winning team
448:10 - captain so if I will if I will hit the
448:12 - enter and here guys you can see the
448:14 - reply
448:16 - so it is saying okay captain as of my
448:20 - knowledge and I don't have information
448:21 - wining team captain uh can you tell me
448:24 - the winning
448:25 - team okay let me ask one more time is
448:29 - saying that uh can you tell me who won
448:31 - the first Cricket World Cup and here I'm
448:33 - asking can you tell me
448:37 - winning
448:40 - Captain uh winning
448:43 - team
448:45 - captain name so if I'm asking to my gp2
448:50 - so it is saying that uh it seems like
448:53 - might be a slight
448:55 - spelling about the okay cap it's a
448:58 - captain I am writing a wrong spelling
449:00 - let me correct the spelling first of all
449:02 - so here uh the spelling will be a
449:04 - captain just a second let me copy the
449:07 - correct uh correct spelling and let me
449:09 - paste it over here and let's see I'm
449:11 - getting answer or not so here it is
449:14 - saying information the
449:16 - tournament okay so it is saying that uh
449:19 - uh just a second guys what I can do uh
449:22 - let me delete this chat or let me open
449:24 - the new chat and let me show you this
449:26 - particular thing oh yeah just a wait so
449:29 - it is able to remember the thing uh let
449:32 - me start from the new one uh first of
449:34 - all let me delete it don't know why it
449:36 - is doing like this just a second let me
449:39 - delete the chat okay now here is what
449:42 - here is my new chat now here uh let's
449:45 - start from the beginning so here I'm
449:46 - asking to my chat GPT can you tell me
449:50 - who won the first
449:54 - Cricket World Cup this is a SE uh like
449:57 - simple question which I'm going to ask
449:59 - my chat GPT so here uh you can see it is
450:03 - giving me answer okay no doubt no issue
450:06 - now here if I'm going to ask my chat GPD
450:08 - that what will be uh what will be 2 + 2
450:13 - 2 + 2 right so now let's see what I will
450:16 - be getting over here so here is saying
450:18 - that 2 + 2 will be four now let me ask
450:21 - my chat GPT what will be 2 * 5 now here
450:26 - it is saying that uh the multiplication
450:29 - will be 10 now I'm asking to my chat GPT
450:32 - can you tell me can you tell me about
450:36 - can you tell me who was the winning who
450:41 - was the captain d a i in captain of a
450:46 - captain of the winning team now let's
450:50 - see uh will it be able to answer or
450:56 - not it's taking time and let's see what
451:00 - will be the
451:01 - answer yes it is able to answer now see
451:04 - so here I asked to my C GPT who won the
451:07 - first Cricket World Cup so here is my
451:09 - like answer now I asked to my CH GPT
451:11 - what is 2 + 2 and the answer is this one
451:15 - now I asked to my CH GP 2 into 5 so this
451:18 - is the answer now again I asked to my
451:20 - chat GPT without giving any sort of an
451:22 - information regarding this Cricket World
451:23 - Cup and all and you can see the answer
451:26 - it is saying that Clive Lord was a
451:28 - captain uh clyve Lord was a captain of
451:30 - the West Indies cricket team that was
451:32 - was the Cricket World Cup in 1975 so
451:36 - here guys in a back end this chat GPT is
451:39 - implementing this memory concept now if
451:41 - you are accessing if you are accessing
451:43 - your uh if you are accessing llm uh this
451:45 - GPD and all by using the open AI or
451:48 - maybe by using the huging phase so how
451:50 - you can retain the memory because chat
451:53 - GPT chat GPT is application in backend
451:56 - uh this GPD model is running getting my
451:58 - point now if you want to implement a
452:00 - same thing let's say if you are
452:02 - accessing the model llm model by using
452:04 - the open API or maybe by using the Len
452:07 - Chen basically Len Chen is hitting the
452:08 - open API only so how you can retain this
452:11 - particular memory how you can do that so
452:13 - now let's try to understand that
452:15 - particular part that particular concept
452:17 - so if I'm using uh the open API that how
452:20 - I will be able to retain the memory and
452:23 - Len chain gives you this particular
452:24 - facility so by using the memory concept
452:27 - you can retain the memory like chat GPT
452:30 - so the problem statement is clear to all
452:32 - of you please do let me know in the chat
452:34 - if uh the problem statement is
452:38 - clear I'm waiting for your reply guys
452:40 - please do let me
452:48 - know
452:49 - what's the purpose of the Len chain so
452:51 - in the previous class I have clearly
452:53 - defined the purpose of the Len chain if
452:55 - you don't know about it so you must
452:57 - visit the previous class where I have um
452:59 - I did the detailed discussion about the
453:01 - Len
453:10 - chain great so everything is fine
453:12 - everything is clear now let's uh begin
453:15 - with the implementation so first of all
453:17 - guys what I need to do so first of all I
453:20 - need to import a different different uh
453:23 - first of all let me import the different
453:25 - different uh like a uh import a
453:28 - statement okay so here is my open Ai and
453:32 - okay it is fine now let me do one thing
453:34 - over here let me
453:37 - [Music]
453:42 - import the same file I already given to
453:45 - you you can check in a resource section
453:47 - from there you can download it's a same
453:49 - file which I'm using over
453:51 - here so it is for the asent type
453:56 - uh okay everything is fine now let me
453:59 - take a prompt template from
454:01 - here great so here what I'm going to do
454:04 - here I'm going to write it down the
454:07 - memory so just a
454:09 - second yeah so first of all let me write
454:12 - it on the memory over here
454:18 - and
454:21 - memory now let's begin let's start so
454:24 - here I'm going to import The Prompt
454:26 - template the first thing which I'm going
454:28 - to do over here so first of all I will
454:31 - have to uh create my a client right so
454:34 - for creating a client actually uh let me
454:37 - write another the code so here actually
454:39 - let me import one more thing I'm going
454:41 - to import llm Chen actually I restarted
454:44 - my kernel that's why I need to import it
454:45 - again and here uh let me do one thing so
454:49 - LM chain I already imported let me
454:51 - create a client first of all so for
454:53 - creating a client what I can
454:56 - do already written a code inside my
455:01 - file yeah so this is the code for
455:03 - creating a client so here uh what I'm
455:06 - going to do guys see here I'm going to
455:08 - create a
455:10 - client so this is what this is my client
455:13 - now open AI key is not defined okay
455:16 - first of all I will have to import the
455:17 - open a so from length chain Len
455:20 - chain do open and here I'm going to
455:25 - import this open AI now let's run it
455:30 - again and it is saying open AI is not
455:34 - there so let me change the spelling of
455:36 - the
455:37 - openi I think it is
455:40 - capital no it is not like that so let me
455:43 - check with the correct import statement
455:45 - what is
455:47 - that
455:53 - yeah this is
455:56 - the okay I'm using the length chain just
455:58 - a wait so by using the Len
456:04 - chain okay from llm actually we have to
456:06 - import this open a uh it's my bad so now
456:11 - it is done yeah it is fine I created a
456:14 - CLI yep now everything is set so here I
456:17 - have imported three state M first is
456:19 - prom template second is llm chain and
456:22 - third is open AI I restarted my kernel
456:24 - that's why I uh got a a requirement to
456:27 - reimport it uh this particular statement
456:30 - now here I created a client now let's
456:32 - try to understand the concept of the
456:34 - memory so first of all guys what I will
456:36 - have to do I will have to create a
456:37 - prompt template and I will have to hit
456:39 - my model right so for that uh what I did
456:43 - I already written a code so let me uh
456:45 - keep the prompt template over here so
456:48 - this is what guys this is my prompt
456:49 - template I told you that what is the
456:51 - meaning of the prompt template and how
456:53 - to create a prompt template each and
456:55 - everything I have discussed in my
456:56 - previous classes if you don't know about
456:58 - it so please go and check with my
457:00 - previous s so this is what guys tell me
457:02 - this is my prompt template now here I'm
457:04 - uh not going to hit my model U like
457:08 - directly uh instead of that I'm going to
457:11 - use llm chain I clearly told you in my
457:14 - previous class that what is llm chain
457:16 - llm CH LM chain is nothing l l m chain
457:19 - uh is a like concept where we are going
457:21 - to connect two components right so what
457:24 - is the meaning of the chain so inside
457:26 - chain you will find out that we are
457:28 - going to connect a multiple component so
457:30 - here we have llm chain where we are
457:33 - going to connect a multiple component my
457:35 - first component is a client uh which is
457:37 - my object of the open a which I have
457:40 - created and the second uh the second
457:42 - component is prompt template let's try
457:44 - to use llm chain over here and let's see
457:47 - what I will be getting so for that first
457:49 - of all I'm going to create a object of
457:51 - this llm chain now let me create a
457:53 - object of this llm chain and I can keep
457:56 - it over here I can keep this particular
457:58 - object inside this chain variable now
458:00 - let me pass my llm llm is nothing it's a
458:03 - client itself because by using this
458:06 - client only uh we are getting a model we
458:09 - are getting a model from the open Ai and
458:11 - by default I think we are using text D
458:13 - Vinci uh and if you are going to mention
458:16 - the model parameter you can use your
458:18 - desired model as well so that is also
458:20 - possible now over here I'm going to
458:21 - write down this client and then what I
458:23 - will do guys so here I will mention my
458:25 - prom template so let me mention my
458:28 - prompt template let me write down the
458:30 - parameter prompt p r o m PT and here let
458:34 - me copy this name prompt template name
458:36 - and here I have this prompt template
458:39 - name so once I will run it so here you
458:42 - can see we are able to create a chain so
458:44 - this is what this is my chain now what I
458:46 - will do I will run uh uh I will I will
458:49 - like uh I will call the run method and
458:53 - here I will mention the name so I'm I'm
458:56 - asking over here what is a good name for
458:58 - the company that makes so I can uh so
459:00 - this product actually uh I can I can
459:02 - give any sort of a product name over
459:04 - here so let's say here if I'm saying uh
459:07 - if I'm uh asking to my uh like model so
459:11 - colorful
459:13 - colorful colorful uh cup so here I'm
459:16 - asking to my model colorful cup so if I
459:19 - will uh run it so here you can see so it
459:22 - is giving me answer so for if I want to
459:24 - like uh check that what is the answer
459:26 - which I'm getting over here so I can
459:28 - give it to my print statement and let's
459:30 - see what will be the final answer so
459:32 - here it is saying holder color cup
459:34 - Corporation something like that it is
459:36 - giving me a name so let me call the
459:39 - strip over here strip will remove
459:40 - unnecessary thing from here so it is
459:43 - saying cakes uh Sugarland sprinkle so
459:47 - this is the name basically which I'm
459:49 - getting uh if I'm asking this particular
459:51 - question to my to my model right to my
459:55 - llm model to my uh GPT model now uh till
459:59 - here I think everything is fine already
460:01 - we did uh uh like uh we did it so many
460:04 - times in our previous classes in our
460:06 - previous session now let's try to
460:08 - understand few more thing over here
460:09 - let's try to understand the memory
460:11 - concept that how the memory how this
460:13 - memory is working in terms of this uh
460:15 - Len chain okay and how we can uh sustain
460:18 - the memory basically the uh conversation
460:20 - whatever conversation we are going to do
460:22 - now here see guys uh I'm going to write
460:24 - it down uh one more time so let me
460:27 - create one more prompt over here so
460:29 - let's say uh there the same prompt uh
460:31 - same prompt template I have used now
460:33 - here what I'm going to do um here I'm
460:35 - going to ask to my uh here I'm going to
460:38 - ask uh again one thing so let me do one
460:41 - thing let me again create this chain
460:43 - over here and I'm going to copy and
460:45 - paste the same thing and let me run it
460:47 - so chain do run I'm going to call this
460:49 - chain. run and instead of this colorful
460:52 - cup I'm giving a different name so here
460:55 - I'm giving name let's say drone so
460:57 - drones I I want to ask a I want to ask a
461:00 - company name so which make a drones so
461:03 - here the product name is what the
461:04 - product name is drones I'm passing the
461:06 - product name inside this method inside
461:09 - this run method so chain. run and here
461:11 - I'm passing this drone let's see what
461:12 - will be the name so here it is giving me
461:14 - a name drone X technology so uh it is
461:17 - giving me a name that that uh don't ask
461:20 - technology okay so here I can call this
461:22 - a strip so it will remove the
461:24 - unnecessary thing uh from the a
461:27 - beginning so skyron technology so this
461:30 - is the name basically which is giving to
461:31 - me and I hope till here everything is
461:34 - fine everything is clear already we have
461:36 - learned these many things right now let
461:38 - me uh explain you the uh like memory
461:41 - concept so here uh if I'm going to call
461:44 - one parameter so let me write it down
461:46 - this chain do memory
461:49 - so here if I'm going to call this
461:50 - parameter chain. memory so here I'm not
461:53 - getting anything here I'm not getting
461:55 - anything so let's try to see the type of
461:57 - this chain do memory that what is the
461:59 - type of this chain do memory so chain do
462:03 - memory now let me show you the type of
462:06 - this chain do memory so here you can see
462:08 - it is giving me a non type means it is
462:10 - not going to return anything to me
462:12 - because here we are not going to sustain
462:14 - any sort of a memory whatever
462:16 - conversation we are doing to my model
462:18 - what whatever conversation is happening
462:20 - right so we are not going to sustain
462:22 - anything over here we are not going to
462:25 - sustain anything over here in terms of
462:27 - the conversation now let's try to
462:29 - understand how we can do it how we'll be
462:31 - able to sustain the conversation
462:33 - whatever conversation we are making uh
462:36 - like by using the API and whatever
462:38 - conversation we are making with respect
462:41 - to that particular model so here for
462:43 - that we just need to write it down one
462:46 - parameter so uh first of all let me
462:48 - write down the heading over here so the
462:50 - heading uh let me write down the heading
462:52 - The Heading is nothing heading is
462:54 - convers conversion buffer memory so here
462:57 - uh we want to save a memory we want to
463:01 - save a like conversation memory so here
463:04 - I return this conversation buffer memory
463:06 - we have three to four topic inside this
463:08 - memory so step by step I will try to
463:10 - explain you each and everything now
463:12 - first let's try to understand what is
463:14 - this conversation buffer memory so uh
463:16 - you can just think about uh this
463:18 - conversation perform memory uh just like
463:20 - a memory whatever conversation we are
463:22 - going to do with respect to our model
463:24 - right so is going to store all those
463:26 - thing right it it is going to sustain
463:28 - all those thing it's going to sustain
463:30 - the entire memory throughout the
463:32 - conversation that's it now here what I'm
463:34 - going to do so here let me uh copy and
463:38 - paste one more statement and let's see
463:41 - uh what I have written over here so here
463:42 - why we have I have written that uh we
463:45 - can attach memory we can attach memory
463:47 - to remember on the previous conversation
463:49 - I just need to uh mention one parameter
463:52 - the parameter name is what the parameter
463:54 - name is a memory so I just need to
463:56 - attach one parameter and we'll be able
463:58 - to remember all the previous
464:00 - conversation regarding this model now
464:02 - how I can do it so here uh let me first
464:05 - of all let me import this conversation
464:07 - buffer memory from the lenon itself and
464:10 - the uh and then I will show you the same
464:12 - thing by uh from the documentation also
464:15 - so each and everything I uh pick up from
464:17 - the doc documentation itself and again I
464:19 - will go through with the document again
464:22 - I will go through the documentation and
464:24 - I will show you the same thing over
464:25 - there as well so just wait for few
464:27 - minutes and each and everything uh each
464:29 - and every part will be clear to all of
464:31 - you now here uh you can see I'm going to
464:34 - import this conversation buffer memory
464:36 - now what I need to do here so this is
464:38 - the class so I need to create a object
464:41 - of this class so here I'm going to
464:42 - create a object of this class and I'm
464:44 - going to keep uh this object inside the
464:47 - variable so I've created a variable by
464:49 - name Memory so this is what this is my
464:52 - uh like variable where I'm going to keep
464:54 - a object of this conversation buffer
464:55 - memory now let me run it so here is what
464:58 - here is my memory now I just need to
465:01 - mention this particular parameter inside
465:02 - my chain that's it and my work will be
465:05 - done let me show you how so here what
465:07 - I'm going to do again I'm going to
465:09 - create a prom template so here is what
465:11 - here is my prom template as you can see
465:14 - this is what this is my prom template
465:16 - now here what I'm going to do here I'm
465:18 - I'm going to create uh here I'm going to
465:19 - write it down llm chain so let me write
465:22 - it down this llm chain and the first
465:24 - parameter which I need to mention over
465:26 - here that's going to be a llm and my llm
465:29 - is nothing it's a client itself so in
465:31 - the client variable I'm going to keep my
465:33 - llm so here you can write it down this
465:35 - CLI c l i n t and here you need to
465:38 - mention the prompt so here is what here
465:40 - is my prompt and to this particular
465:42 - parameter to this prompt parameter you
465:43 - just need to pass uh this particular
465:45 - value this prompt template name so once
465:48 - you will pass this prom template name
465:50 - and you will what you can do you can
465:51 - create a object of this Ln chain and
465:54 - then you can call chain do run getting
465:57 - my point chain is nothing it's a
465:59 - collection of
466:01 - component getting my point yes or no in
466:04 - a uh like uh in a sequence in a
466:06 - particular chronology so here you can
466:09 - see we have llm client prom template now
466:12 - if I want to retain all the conversation
466:14 - if I want to retain all the memory which
466:17 - I'm able to retain in a chat GPT here
466:19 - you can see so if I'm asking to my chat
466:21 - GPT can you tell me who won the first
466:23 - Cricket World Cup so it is answer like
466:25 - it is generating answer now if I'm
466:27 - asking to my chat GPD what will be 2 + 2
466:30 - so here what will be 2 into 5 now again
466:33 - I'm asking to my chat GPD that can you
466:35 - tell me who was the camp of the winning
466:37 - team I'm not giving any such information
466:40 - in inside my prompt as you can see but
466:41 - is still it is able to give me an answer
466:44 - based on a previous conversation so if I
466:46 - want to do a same thing with my API how
466:49 - we can do it so that's a thing which I'm
466:51 - explaining you now let me mention one
466:54 - parameter over here that's going to be a
466:55 - memory so m m o r by and here let me
466:59 - mention me m o r by so once I will run
467:02 - it so first of all let me uh uh keep all
467:05 - the thing in a variable variable name is
467:07 - going to be a chain so here Ive created
467:09 - a object of this llm chain now here if I
467:12 - will run so let me run something over
467:14 - here chain do run so here I'm going to
467:17 - ask that uh I'm going to ask regarding
467:19 - the product so what be the good name for
467:21 - the company that makes a product let's
467:23 - say I'm asking about the wines so if I
467:26 - will run it so it is giving me a name so
467:28 - it is giving me a name it is generating
467:29 - a name over here now again what I'm
467:32 - going to do so again uh I'm going to ask
467:34 - to my uh again I'm going to ask to my
467:37 - model so here I'm asking to my model so
467:40 - what would be the good name for the
467:42 - company that makes let's say here I'm
467:43 - saying camera so here I'm asking a c
467:47 - like regarding a camera I just want a
467:48 - name so it is saying that camera Lum
467:50 - technology so it is giving me a name it
467:52 - is suggesting me a name now uh here is
467:55 - what here is my name now uh let me ask
467:58 - to something else over here let's say uh
468:00 - I want a company I want to create a
468:02 - company so the company related to a
468:04 - drone so I want a company name which
468:07 - create a drones so here if I'm saying
468:09 - that drones now here you can see is
468:11 - giving me answer drone craft so here I
468:14 - asked three question to my to my model
468:17 - by by hitting the API I asked three
468:19 - question to my model to my LF model now
468:22 - uh let's see it is able to sustain the
468:24 - memory or not so now if I will run this
468:26 - chain. memory now you will be able to
468:29 - find out yes it is able to retain all
468:31 - the conversation whatever conversation
468:33 - is happening because because of what
468:35 - because of this conversation buffer
468:37 - memory so whatever conversation we are
468:39 - doing right whatever previous
468:41 - conversation is there so each and every
468:43 - conversation we are able to sustain but
468:45 - previously we were not able to do it so
468:47 - here it was was giving me none type here
468:49 - it was not giving me anything but now
468:51 - you can see we are able to sustain the
468:53 - information and if I'm calling chain.
468:56 - memory it is giving me the entire detail
468:58 - over here now let's try to understand
469:00 - let's let's try to like uh uh let's try
469:03 - to understand a few more thing over here
469:04 - now here if I will run this chain do
469:07 - memory chain. memory and here if I will
469:11 - call this chain do memory. buffer so now
469:14 - you will find out that this is the
469:16 - entire conversation now let me uh print
469:19 - uh let me keep this thing uh in my print
469:21 - method so I won't get this selection
469:23 - over here instead of that I will get the
469:25 - new line because slash and me is what SL
469:27 - and me is nothing it's a new line now
469:29 - over here you will find out the entire
469:31 - conversation that whatever conversation
469:32 - is happening between me and model so
469:35 - here human is asking about wines so e is
469:37 - giving me answer now human is asking
469:39 - about the camera is giving me answer
469:41 - human is asking about the drones it is
469:42 - giving me answ so like this you can draw
469:45 - uh you can create your prompt template
469:47 - and you can ask to anything to your
469:49 - model and you can sustain the entire
469:51 - memory you can sustain or you can uh
469:53 - keep the en entire conversation with you
469:56 - getting my point guys yes or no are you
469:58 - able to understand it is getting clear
470:00 - so please do let me know if you are able
470:02 - to understand this particular concept
470:04 - I'm waiting for your reply in the chat
470:07 - please do let me know guys please write
470:08 - down the chat if you are getting it and
470:10 - please hit the like button so yeah I
470:13 - will get some sort of a
470:16 - motivation I are you able to understand
470:18 - the concept of the memory how to retain
470:20 - see here actually we are going to uh
470:22 - like retain the conversation and uh I
470:25 - will explain you the further use so uh I
470:28 - will I will explain you a few more
470:30 - concept over here just just wait step by
470:32 - step we'll try to understand each and
470:34 - everything so don't be in a hurry and
470:37 - try to understand the entire thing if
470:39 - you have started something then
470:40 - definitely I will end it okay so here
470:44 - people are saying that it is clear and
470:46 - you are able to they are able to
470:48 - understand the concept of the memory
470:50 - that how to sustain the conversation
470:52 - whatever conversation we are doing all
470:55 - the previous conversation now let's try
470:58 - to understand few more thing over here
471:01 - so uh yes we are able to uh maintain the
471:04 - previous conversation by using this
471:06 - conversation buffer memory we just
471:09 - created a object and we are just going
471:11 - to keep it over here in our chain that's
471:14 - it now guys here let me show you one
471:16 - more thing so here here what I'm going
471:18 - to do so here uh I'm going to introduce
471:20 - you with the New Concept that's going to
471:22 - be a conversation chain now let's try to
471:24 - understand what is this conversation
471:26 - chain each and everything we'll try to
471:28 - understand by using this conversation
471:29 - chain so here uh I'm saying that here
471:33 - I'm going to uh like write it down some
471:36 - sort of a statement and the statement is
471:38 - something like this so here uh let me
471:40 - mark down it and let me show you so
471:42 - conversation buffer memory goes growing
471:45 - endlessly means uh whatever conversation
471:47 - you are doing uh so you will be able to
471:49 - sustain all the conversation by using
471:52 - conversation buffer memory No Doubt with
471:55 - that but just remember last five
471:57 - conversation chain or if you want to
471:59 - remember just last 10 to 20 conversation
472:01 - chain in that case what I can
472:03 - do what should I do over here so here L
472:07 - chain has given you few more method now
472:09 - let's try to understand regarding uh
472:11 - let's try to understand those particular
472:13 - method that what is the use of this
472:14 - conversation chain and we have one more
472:17 - me method now let me uh give you that
472:20 - particular method also try to understand
472:22 - about it so here is my second method see
472:24 - each and everything I kept it somewhere
472:26 - in my notepad I'm just going to copy and
472:27 - paste so try to understand please
472:29 - because I'm doing it uh because I want
472:31 - to save my time and uh in a short uh
472:35 - amount of time I want to deliver uh like
472:37 - uh more and more thing so here you can
472:40 - see uh there is one more concept that is
472:42 - conversation buffer window memory so
472:45 - there is two concept which we need to
472:47 - understand now here first let's try to
472:49 - understand this conversation chain that
472:50 - what is the meaning of it so here uh
472:53 - what I'm going to say that uh let me
472:55 - keep it in a single line and if I uh if
473:00 - just remember let's just remember 10 to
473:02 - 15 convers and that would be great now
473:05 - what I can do here I can write down some
473:06 - sort of a code regarding this
473:08 - conversation chain so first of all guys
473:10 - what I need to do here first of all I
473:12 - need to import it so let me import this
473:15 - conversation chain over here so from uh
473:18 - the link chain itself from the link
473:19 - chain do chains I am going to import
473:21 - this conversation chain now let me run
473:24 - it and yes we are able to do it now here
473:26 - what I'm going to do I'm going to create
473:28 - object of this conversation chain now if
473:31 - you look into the if you look into the
473:33 - object so here I'm going to keep a
473:35 - couple of thing here I'm going to write
473:37 - down a couple of things so here the
473:39 - first thing see uh this is what this is
473:41 - the object this is the object and inside
473:43 - this object I'm going to mention few
473:45 - parameter the parameter nothing here I'm
473:47 - just is going to mention this model LM
473:49 - model and here I mention open a I can
473:51 - write it down the client directly or
473:52 - else I can write it down like this open
473:54 - a and here is my open a key and this is
473:56 - the temperature you already know what is
473:58 - the temperature in the previous session
474:00 - in my uh day two actually I have uh
474:02 - explained you the concept of the I have
474:04 - explained the concept of this
474:06 - temperature what is the meaning of the
474:07 - temperature and the value you will find
474:09 - out of this temperature between 0 to 2
474:11 - if you are keeping it zero so you will
474:13 - get a straightforward answer but you
474:14 - have like increasing the value of this
474:17 - temperature so it's going to be this
474:19 - model is going to be a more creative it
474:20 - will give you the creative answer so
474:22 - here you can U maintain the temperature
474:25 - of the answer whatever answer basically
474:27 - you want whatever output basically you
474:29 - want you can maintain a temperature you
474:31 - can maintain the creativity of that
474:33 - particular answer now here uh to this
474:36 - particular method to this conversation
474:37 - chain I'm just going to pass this llm
474:40 - and here is what here is my object open
474:42 - Ai and there's couple of parameter which
474:45 - uh with that you are already familiar
474:47 - now let me run it so let me create a
474:50 - object of this conversation chain so
474:53 - here I created object of this
474:54 - conversation chain and the uh object
474:57 - name is what the object name is convo
474:59 - now I just need to run something over
475:01 - here so uh here what basically what I'm
475:03 - going to do here I'm going to write down
475:05 - convo convo do prompt so here if I will
475:09 - write convo do prompt so you will find
475:10 - out that this is nothing it is giving me
475:12 - a prompt template so here we have a
475:14 - input variable which is history and
475:16 - input template so it is a there is a
475:18 - template the following is a friendly
475:20 - conversation between a human and AI the
475:22 - AI is a tative uh provides lots of a
475:25 - specific detail from its context if AI
475:28 - does not know the answer to the question
475:29 - it truthfully say it does not know so
475:32 - here uh they have written by one by
475:34 - default message one by default prompt
475:36 - actually now let's try to see uh
475:38 - something else over here so here I'm
475:39 - going to write down con. prom. templates
475:43 - now uh let me extract this template and
475:46 - here you will see that uh here basically
475:49 - we have a template the same message
475:50 - which I was trying to read from there
475:52 - from here itself so now you can see the
475:55 - same message over here now if you will
475:57 - write it on the print so here you will
475:59 - get the clear cut message uh without the
476:01 - selection and all so just write down
476:03 - inside the print so this is the uh thing
476:06 - uh this is the message basically which
476:07 - I'm getting it's a by default message uh
476:09 - which I'm getting if I'm calling this
476:10 - con. prompt so here in the template it's
476:13 - a by default message now uh now let's
476:16 - try to understand that what is the use
476:18 - of this uh convo what is the use of this
476:20 - particular object now here what I'm
476:22 - going to do here I'm going to ask the
476:24 - same question to my chat GPD uh to my
476:26 - GPD model now here I'm saying that convo
476:30 - convo do run and here I'm asking to my
476:34 - uh model uh who won the first Cricket
476:41 - World Cup who won the first Cricket
476:43 - World Cup who won the first Cricket
476:46 - World Cup this is the question now if
476:48 - I'm going to run it so here you will
476:49 - find out it is giving me answer that the
476:51 - first Cricket World Cup won by the
476:53 - Western be in 1975 they beat Australia
476:56 - by 179 in the final so this is the
476:59 - information which I'm getting from the
477:00 - from my model now here what I'm going to
477:02 - do here I'm going to run uh convo convo
477:06 - do run now here I'm asking to my model
477:09 - that uh can you tell me can you tell me
477:13 - uh can you tell me how
477:15 - much will be 5 + 5 so it's a simple
477:19 - question which I'm asking to my model
477:21 - now let's see the answer the answer is
477:23 - 10 now let's try to ask one more
477:25 - question over here so let's try to ask
477:27 - one more question to my uh model so here
477:30 - what I'm going to do here I'm asking con
477:33 - can you tell me how much will be 5 * 5
477:37 - so that's a question or let me keep
477:39 - something else over here let's say 5 + 1
477:42 - and here and this is the expression this
477:44 - is the mathematical explation which I'm
477:46 - passing now let's see what will be the
477:47 - answer so it is able to answer me that
477:49 - the answer is 30 now let's try to ask uh
477:53 - uh the question to my model that uh who
477:56 - was the captain of the winning team the
477:59 - same question which I was asking to my
478:01 - chat GPT and it was able to answer now
478:03 - let's see uh will it be able to answer
478:06 - the same question or not over here if
478:08 - I'm hitting my API let's see now so here
478:11 - what I'm going to do so here I'm going
478:13 - to uh copy it conversion uh convo do run
478:17 - and I'm going to ask the question the
478:18 - question is nothing the question is uh
478:20 - very simple so who was the captain who
478:25 - was the captain of the
478:29 - winning team so I didn't give any sort
478:32 - of information what winning team which
478:34 - winning team I just like going I'm just
478:36 - going to follow the conversation now if
478:38 - I will hit the enter so here you will
478:40 - find out it is able to give me a reply
478:43 - the captain of the winning team in the
478:45 - first Cricket World Cup was the live lck
478:48 - so it is able to sustain it is able to
478:50 - sustain the conversation now how we can
478:54 - do it by using this conversation chain
478:56 - so first we have understood that if you
478:58 - want to get the if you if you want to
479:00 - get all the previous conversation so you
479:03 - can get it you just need to mention the
479:05 - memory parameter over here if you're not
479:07 - going to do it so in that case it will
479:09 - give you the none but if you're going to
479:11 - mention it conversation buffer memory so
479:13 - it will be able to retain all the
479:15 - previous conversation
479:18 - now here we are talking about this
479:19 - conversation chain so by using this
479:22 - conversation chain I will be able to
479:24 - retain the I will be able to retain the
479:27 - tell me I will be able to retain the
479:29 - memory and uh yes uh like you can ask
479:32 - anything let's try to uh again check
479:34 - with a different uh like uh let's try to
479:37 - check again with a different prompt so
479:39 - here I'm uh saying to my model
479:42 - so can you divide can you divide
479:47 - those uh can you
479:49 - divide uh the
479:51 - number numbers and can you give me
479:55 - answer can you give me a final answer so
480:00 - here I'm asking through my model that
480:01 - can you divide the number whatever
480:03 - number basically is using before
480:06 - actually it is using so can you divide
480:08 - those particular number and can you give
480:10 - me the final answer now let's see what
480:12 - what I will be getting over here so it
480:13 - is giving me the five okay so it is
480:15 - giving me a five uh which uh number is
480:18 - going to divide I uh so the answer is
480:22 - five which number it is going to divide
480:25 - I think uh 5 is six 5 / by uh five if it
480:32 - is saying like that maybe is going to
480:34 - divide this uh 30 by six so that's why
480:38 - I'm getting this five but yeah it is
480:39 - able to retain the memory it is able to
480:42 - retain the memory and it is working so
480:44 - uh I think uh you got to know that how
480:47 - to uh get all the previous conversation
480:50 - that is the first thing and how to
480:51 - retain the memory if you are using the
480:53 - API now guys see we have one more method
480:56 - over here the method name is what
480:58 - conversation buffer window memory now
481:01 - what's the meaning of that first of all
481:03 - let me show you first of all let me
481:04 - write it on the code actually and then I
481:06 - will explain you the meaning of this
481:08 - conversation buffer window memory so uh
481:11 - tell me guys still here everything is
481:13 - fine everything is clear that whatever
481:15 - thing my chat GPD is doing I able ble to
481:16 - do the same thing by using this Len
481:18 - chain this Len chain is too much
481:20 - powerful if you if I'm using my API so
481:24 - in that case how I can sustain the
481:26 - conversation how I can remember all
481:28 - those thing so here is a way you just
481:31 - need to import the classes and all in a
481:33 - back end already the code has been
481:35 - written by someone you just you are just
481:37 - going to use it and uh definitely you
481:40 - can uh create a application in that you
481:42 - can use the same concept got it so if
481:45 - this part is getting clear then and
481:46 - please do let me know in the
481:53 - chat no buffer this is a different
481:55 - object now we are just going to remember
481:58 - all the previous conversation here see
482:00 - we are able to retain the previous
482:02 - conversation this one is giving me all
482:04 - the conversation but here actually by
482:06 - using this conversation chain what I'm
482:08 - doing tell me so here by using this one
482:11 - I'm able to do like same this chat
482:15 - GPT okay okay so where we are able to
482:17 - retain the uh like where we are able to
482:20 - retain the memory so here I was asking
482:23 - this thing to my CH to my model to my
482:25 - API and then I I written this particular
482:28 - um like me I I written this particular
482:30 - prompt and then again I asked this
482:32 - question related to this one and it is
482:34 - able to give me
482:35 - answer so that's a difference try to
482:38 - understand try to observe it here
482:40 - conversation buffer memory this a
482:41 - different method by sustaining the
482:43 - conversation here you can see and
482:45 - conversation chain is doing a same
482:47 - Behavior Uh like which we are able to
482:49 - achieve in a chat GPT so somewhere in a
482:52 - in the chat GPT application also they
482:54 - implemented the same concept for
482:55 - sustaining the memory that's why it is
482:57 - able to do it we don't know uh uh What
483:01 - uh what type of code they have written a
483:03 - backend if you want to check you can
483:04 - check it you can go through with the Len
483:06 - chain so here uh you can search a len
483:08 - chain l a n
483:11 - g and uh just check with the Lenin
483:14 - GitHub so here you will get the source
483:16 - code code of the Lang chain and now you
483:18 - can uh check that what code they have
483:20 - written regarding a different different
483:21 - thing so here go inside the cookbook and
483:24 - there is like all the code regarding a
483:26 - different different thing and just try
483:28 - to read the lowlevel code that what
483:32 - all what Logics and all they are going
483:34 - to uh they have written over here
483:36 - actually so you just need to go through
483:38 - with the Len and uh GitHub and there
483:41 - you'll find out all the codes and
483:44 - all tell me guys now this part is
483:46 - getting clear to all of you please or do
483:49 - let me know in the chat if the part is
483:51 - getting if this part is if this part is
483:53 - getting clear or not this uh
483:55 - conversation chain and this uh
483:57 - conversation buffer memory now let's try
483:59 - to understand this conversation buffer
484:00 - window memory but that what is a meaning
484:02 - of it and then again I will uh I will
484:06 - try to revise it and I will uh I will be
484:08 - showing you the same thing by using the
484:10 - uh documentation so all the thing uh
484:12 - they have mentioned over there already
484:14 - uh each and every theoretical is stuff
484:16 - then uh I will try to explain you that
484:19 - uh from there itself now here we are
484:21 - talking about this conversation buffer
484:23 - window memory then what is a use of this
484:25 - particular method now let's try to
484:27 - understand it so here the first thing
484:29 - which I have to do so first of all I
484:31 - have to create a object of it now uh
484:34 - here let me create a object so I'm going
484:36 - to import it conversation buffer window
484:39 - memory now if I'm going to run it so yes
484:41 - I'm able to run it and I'm able to uh
484:44 - I'm able to like import this particular
484:46 - statement so here I'm going to create a
484:48 - object of it so this is what this is my
484:50 - like object and here I'm going to write
484:53 - down my object name is nothing it's a
484:54 - memory now inside this uh uh like object
484:59 - actually uh there is one parameter so
485:01 - let me write it on the parameter name so
485:03 - the parameter name will be a key right
485:06 - which I represent with which they
485:07 - represent with K so here I I'm going to
485:10 - pass one parameter the parameter name is
485:12 - what the parameter name is K now here I
485:14 - can pass any sort of a value regarding
485:17 - this K 1 2 3 4 5 6 7 8 9 10 11 12
485:20 - whatever now what is the meaning of that
485:22 - so first of all let me write down that
485:24 - and let me run it in front of you and
485:26 - then I will try to explain you this
485:28 - thing so here I'm going to write it down
485:29 - K is equal to 1 now here I created a
485:32 - object so here I've created a memory now
485:35 - what I'm going to do I'm going to create
485:37 - a conversation chain again so the
485:38 - conversation chain which I uh uh which I
485:42 - imported over here now let me paste it
485:44 - over here this conversation chain
485:46 - conversation chain and now what I need
485:48 - to do I I'm just going to be mention one
485:50 - parameter over here so I'm going to
485:52 - mention memory parameter inside this
485:54 - conversation chain see this is my main U
485:57 - this is my main class this conversation
485:58 - chain which I'm using over here though
486:01 - uh along with that you'll find out two
486:03 - more so conversation buffer window
486:05 - memory and conversation uh conversation
486:07 - buffer memory so buffer window memory
486:10 - what is the meaning of that after this
486:13 - uh particular example you will get to
486:15 - know by yourself on only so here I'm
486:17 - going to keep it and let me uh write it
486:21 - on this memory over here and here what
486:23 - I'm going to do here I'm going to create
486:24 - a object so convo object so this is what
486:27 - this is my convo object now uh what I'm
486:29 - going to do I'm going to run it so here
486:31 - I'm going to run the same thing so now
486:34 - let me uh copy it and let me paste it
486:37 - over here so let me paste it over here
486:40 - uh this particular thing uh this
486:42 - particular sentence and here let's see
486:45 - what will be the answer so here if I'm
486:46 - going to run it so you can see that it
486:48 - is saying that the first Cricket World
486:50 - Cup uh was held in 1975 and it w won by
486:53 - the wested that is perfectly fine now
486:56 - again I'm going to ask to my model that
486:58 - convo. run convo do run and here I'm
487:02 - asking that what will be 5 + 5 now it is
487:05 - saying that 5 + 5 will be 10 now I'm
487:07 - asking to my uh now I'm asking to my
487:10 - model that who was the captain of the
487:12 - winning team so if I'm uh giving this
487:15 - particular code question now let's see
487:17 - what will be the answer so it is saying
487:19 - that I sorry I don't know I'm sorry I
487:22 - don't know because see uh if I didn't
487:24 - mention anything it is able to uh by
487:28 - default actually see there is a uh
487:29 - memory parameter see in a you can create
487:32 - this conversation buffer memory and if
487:34 - you are going to create a chain now if
487:36 - you're going to create a chain now there
487:37 - you can mention this memory and you can
487:39 - track the entire conversation that is
487:43 - perfectly fine now here uh if I want a
487:46 - same behavior like this chat GPT for
487:48 - that there is a main method conversation
487:50 - chain there's a main method so here
487:53 - conver here I created a object of the
487:54 - conversation chain and here is what here
487:57 - I'm going to call this run method now
487:59 - you can see it is able to sustain the
488:01 - memory it is able to sustain the memory
488:04 - now here you will find out one more
488:06 - thing uh like one more class
488:08 - conversation buffer window memory now
488:10 - here Ive created a object of this
488:12 - conversation buffer buffer window memory
488:14 - and I passed the key value key equal to
488:16 - 1 so key equal to 1 means what is the
488:18 - meaning of this key equal to 1 so it is
488:21 - just able to sustain or it is just able
488:24 - to remember all the thing uh like till
488:27 - the one prompt till the first prompt
488:29 - only after that it won't be able to
488:32 - remember anything if I'm writing over
488:34 - here K is equal to 4 now in that case
488:37 - just see the effect so here if I'm going
488:39 - to create K is equal to 4 so see uh
488:41 - convo is there now I'm going to run it
488:43 - okay great now I'm going to ask to my
488:45 - model okay
488:46 - now see see now it is giving me answer
488:49 - so I can Define the window size I can
488:51 - Define the number of prompt here if I'm
488:53 - saying uh K is equal to 2 so now let's
488:57 - see what it is giving to me so here I'm
488:59 - saying K is equal to 2 that's great this
489:01 - one is fine this one is fine now it is
489:03 - saying the first Cricket World Cup was
489:05 - held in 1975 now it will stop over here
489:09 - now if I'm going to ask to my uh like
489:11 - this one so here it is giving me answer
489:13 - because now I'm going to sustain this
489:15 - both both conversation see K is equal to
489:18 - 1 means what let me tell you that K is
489:21 - equal to 1 means what see k equal to 1
489:24 - means what this one only the first one k
489:27 - is equal to 2 means what this both this
489:29 - both K is equal to 2 so if I'm writing
489:31 - over here K is equal to 2 so it is going
489:33 - through with this particular sentence
489:34 - and it's going through with this
489:35 - particular sentence and if it is seeing
489:37 - this sentence now so it is able to
489:38 - remember it is able to see this one now
489:40 - this one and this one so in that case it
489:43 - a it is able to generate answer but if I
489:45 - mention k equ Al to one so after this
489:47 - one is not able to remember anything
489:49 - that's the last one okay so I can select
489:52 - the window size over here you can select
489:54 - the window size if you're not going to
489:56 - select it will be tracking the entire
489:58 - conversation by default it will be
490:00 - tracking the entire conversation now
490:02 - let's try to see the same thing by using
490:04 - uh like on top of the documentation also
490:07 - so they have mentioned the same thing so
490:09 - let me open the Len chain documentation
490:11 - l n Len chain documentation and over
490:16 - here uh let me open it first of all so
490:19 - Lin memory where you will find out go
490:22 - inside more and here is a memory so
490:24 - let's try to understand uh about the
490:26 - memory that uh what all typee of
490:29 - memories we have and what all thing
490:33 - basically they have written over here
490:34 - let's try to understand that thing so
490:36 - most llm application have a
490:38 - conversational interface so an essential
490:40 - component of the conversation is begin a
490:42 - it's conversation uh is being able to
490:45 - refer to information introduced earlier
490:47 - in the conversation means uh whatever
490:49 - conversation we are making so it should
490:50 - be like uh like it should have a
490:52 - connectivity in between so at bare
490:54 - minimum a conversational system should
490:56 - be able to access some window of past
490:58 - message directly so a comp more complex
491:01 - system will need to have a world model
491:03 - that is constantly updating which allow
491:05 - us to do thing like Mentor information
491:07 - about the entities and their
491:09 - relationship so here they have given you
491:11 - the complete detail now building memory
491:13 - into a system how how state is stored
491:15 - how state is queried so there are like
491:18 - some sort of a theory they have given
491:20 - over here now here they have given that
491:23 - this get is started so let's try to read
491:24 - it from here so let's look at what
491:27 - memory actually looks like in L chain
491:29 - here we will cover the basics of
491:30 - interacting with the arbit memory class
491:32 - so here the same memory class uh which
491:35 - we were using so here I have created a
491:37 - like object of the memory class now here
491:39 - I'm asking so memory. chat. memory add
491:42 - user and what is up so something like
491:45 - that uh there calling basically this
491:46 - particular method over here which is
491:49 - there inside this conversational buffer
491:51 - memory itself now what variable get
491:54 - written from memory so here if you will
491:56 - load the memory you are getting this
491:57 - particular thing the same thing I was
491:59 - able to get by calling this parameter
492:01 - the parameter which I was calling chain.
492:03 - memory actually I'm not directly using
492:05 - this thing I'm not directly using a
492:07 - method from this particular class from
492:09 - this conversation buffer memory instead
492:11 - of that what I'm doing instead of that
492:13 - I've have created a object of this llm
492:16 - chain and here I'm passing my all the
492:18 - component I'm making a chain okay I'm
492:21 - stacking all the component and then
492:23 - basically I'm calling this chain. memory
492:26 - and I'm getting here I'm getting this
492:27 - particular output and the same output
492:30 - you can see over here as well you you
492:32 - you are getting the same output over
492:34 - here as well right so yes I'm able to
492:36 - get the same output by using that
492:38 - particular parameter chain. memory.
492:40 - buffer or chain. memory now here uh we
492:43 - have other one also so like you can give
492:46 - the key and all you can explore about it
492:48 - now there are few more parameter like
492:50 - return return message and all each and
492:51 - everything you will find out over here
492:54 - now end to an example so they have given
492:55 - you the endend example over here so open
492:57 - a prompt
492:58 - template conversation buffer memory now
493:01 - see I'm using the same thing I'm using a
493:03 - same thing over here I'm using the llm
493:06 - chain I'm I'm running the same example
493:08 - in my jupyter notebook so you can go
493:10 - through with the documentation and you
493:12 - can copy from there also and you can
493:13 - test it they have given you like a small
493:15 - small code is snipp it just for the
493:17 - testing just for the learning and
493:18 - directly you can integrate this thing
493:20 - inside your application got it now here
493:23 - uh you can see using a chat model so one
493:26 - more example they have given you and
493:28 - then next step inside that you will find
493:30 - out few more thing uh memory in llm
493:32 - chain memory types okay now customized
493:35 - conversation custom memory multi uh
493:37 - multiple memory classes there are so
493:39 - many thing you will find out so if
493:41 - you'll go inside this memory type so
493:43 - just just see uh with the memory types
493:45 - and and then conversation buffer
493:47 - conversation buffer the same thing um
493:49 - the entire code you will find out then
493:51 - conversation buffer window now let's see
493:53 - what is the meaning of the conversation
493:54 - buffer window so conversation buffer
493:57 - window memory keep a list of interaction
493:59 - of the conversation over the time it
494:01 - only uses the K interaction the number
494:04 - of interaction so this can be useful for
494:06 - keeping a sliding window of of most
494:09 - recent interaction so the buffer does
494:11 - not go too large so if we are talking
494:14 - about buffer so it is having a complete
494:18 - uh like a complete uh conversation
494:21 - whatever conversation we are doing but
494:22 - if you want to keep it short so you can
494:25 - mention the K over there so here I I was
494:27 - doing that so here if I'm writing K is
494:29 - equal to 1 so here if I'm writing K is
494:32 - equal to 1 in that case is not able to
494:34 - remember anything so simply it is saying
494:36 - that I don't know about it it it it is
494:38 - just going to stop over here itself so
494:40 - this one and this one now uh if I'm
494:43 - going to ask this uh particular thing so
494:45 - it is saying I don't know about it
494:46 - because after this one is not going to
494:48 - track anything K is equal to 1 means
494:50 - what just one sentence means it is not
494:53 - going to remember anything uh over here
494:55 - now if I'm going to write it down over K
494:57 - is equal to 2 in that case it will be
494:59 - able to sustain something right by using
495:01 - this two particular prompt and if I'm
495:02 - going to ask something after this one so
495:04 - it is saying that yes now it is knowing
495:08 - okay now it knows about it so here uh if
495:11 - you're not mentioning any sort of a
495:12 - window is is going to keep a track for
495:15 - the ENT entire conversation but if you
495:17 - are going to mention a window parameter
495:19 - over here in that case it will be
495:21 - restricted each and everything they have
495:23 - mention inside the documentation itself
495:25 - try to read it from here got it now how
495:28 - to use a chain means how to like uh uh
495:31 - like how to uh sustain a memory and all
495:34 - means if you're going to make any sort
495:35 - of a conversation and all so this
495:37 - conversation buffer memory conversation
495:39 - buffer window memory is just for sustain
495:41 - the the memory basically the
495:43 - conversation but actual conversation how
495:45 - you make the actual conversation which
495:47 - we are doing over here actually here so
495:50 - by using this particular class
495:51 - conversation chain class this is the
495:53 - main class and this two class for
495:56 - sustaining a conversation this is for
495:57 - the entire conversation and this is just
495:59 - for the limited window means a
496:02 - customized window whatever number you
496:04 - are going to write it down till that
496:06 - particular window now it is clear what
496:09 - is a memory yes or no please do let me
496:11 - know in the chat if uh this part is
496:13 - getting clear to all of you
496:19 - are you able to get it guys uh are you
496:21 - able to understand the concept of the
496:22 - memory how to do that how to make a
496:25 - conversation how to import the different
496:27 - different import statement how to like
496:30 - uh how to go through the
496:32 - documentation yes or no please do let me
496:35 - know in the chat if you're getting it
496:37 - I'm waiting for your
496:44 - reply
496:59 - clear clear clear great
497:03 - uh if you have any doubt you can ask me
497:05 - in the chat and then I will start with
497:08 - the next
497:13 - concept what is the limit of of memory
497:15 - Li limit you can Define now you can def
497:17 - Define the limit according to your
497:19 - problem
497:20 - statement you don't want to be create uh
497:22 - to Long buffer so in that case you can
497:25 - uh you can uh like uh mention this K
497:28 - parameter it's up to you it's up like uh
497:31 - up to your requirement up like how much
497:34 - what uh how much uh like your
497:36 - configuration and all what all resources
497:38 - you are using according to that you can
497:44 - decide where the memory concept used in
497:46 - a real uh life exam application
497:49 - so here what I explained tell me so it
497:54 - is not a real time explain this chat
497:56 - GPT so this chat GPT is a real time
497:59 - application now that that that's why
498:01 - first I have explained this one only so
498:04 - let's say if you are making a
498:05 - conversation to the
498:07 - chatbot if you're making a conversation
498:09 - to the chatbot and if you ask to the
498:10 - chatbot let's say you visited a website
498:12 - any website and let's say I your own
498:14 - website side there you are asking uh
498:17 - let's say we have a chatboard on in own
498:18 - website you are asking to the chatboard
498:20 - okay what is the price of this
498:21 - particular course then U like let's say
498:24 - you are getting some sort of a prize and
498:26 - then you are asking something else who
498:27 - was a mentor and all now again you are
498:29 - asking a question related to that course
498:31 - itself that what all thing you covered
498:32 - in this course now it is saying that
498:34 - which course I don't know about any
498:38 - course even though you mention the name
498:40 - over there gener course but it is saying
498:41 - no I don't know about it because is not
498:43 - able to S it is not sustaining the
498:46 - conversation the conversation is not in
498:48 - buffer so like there it can go and it
498:51 - can like read each and everything the
498:53 - model actually it is not able to sustain
498:55 - the context is able to sustain a context
498:57 - in terms of the a sentence but not in
498:59 - terms of the
499:01 - conversation so that's a real time
499:03 - example so that's why I have explained
499:06 - you this chat GPT at the first place and
499:08 - then I back to this uh I uh went to this
499:12 - uh like python implementation by us
499:15 - using like if we are implementing the
499:17 - same thing like by using the API by
499:19 - using the openi how we can achieve this
499:21 - particular thing how we can achieve the
499:23 - memory and all how we can sustain the
499:24 - memory so it's all about that only
499:28 - please try to run it by yourself please
499:30 - revise it you will be getting and one
499:32 - more thing uh before implementing with
499:35 - uh before implementing any sort of a
499:37 - concept from the Lan chain try to go
499:39 - through with the documentation theyve
499:40 - given you each and everything along with
499:42 - the theory so first read the theory and
499:45 - read the uh like uh code snipp it and
499:48 - all whatever they have given you and
499:49 - then you can uh run it inside your
499:52 - system and then uh basically you can run
499:54 - my file as well whatever like code and
499:56 - all I'm writing it don't worry I give
499:58 - you I will give you the each and
500:00 - everything in a resource section so from
500:02 - there itself you can download
500:04 - it okay so if this thing is clear do
500:07 - please do let me know because I'm going
500:09 - to start with a new thing uh with a new
500:11 - topic and now let me create a new
500:13 - notebook over here
500:16 - I think this Lang chain is clear in the
500:17 - Lang chain I have explained you five to
500:20 - six concept which is going to be a very
500:22 - much important once uh we'll start with
500:24 - the project you will get to know the
500:26 - importance of this thing this topic and
500:29 - inside this particular top inside this
500:31 - particular notebook I have kept
500:33 - everything related to this open API and
500:35 - this L chain so here let me rename it so
500:38 - test open AI
500:40 - API test open AI API and Link Chain so
500:44 - everything you will find out regarding
500:46 - this openi API and Lenin inside this
500:49 - particular notebook guys you just need
500:51 - to visit this notebook everything I have
500:54 - written over here along with the code so
500:56 - let's start with a new topic and the new
500:58 - topic is going to be a uh hugging face
501:01 - hugging face with Len chain uh hugging
501:05 - face with Len
501:12 - chain hugging face face is
501:17 - fce so can we start now have you open
501:20 - the new
501:26 - notebook yes correct aishu uh your
501:29 - understanding is
501:32 - correct tell me guys uh have you opened
501:35 - the new jer notebook so uh I can start
501:38 - with the thing I can start with a new
501:39 - topic hugging Faith with Lin and after
501:41 - this one after explaining you this thing
501:44 - I will move to the uh like I will move
501:46 - to the project I will I start with the
501:48 - project from Monday onwards and first I
501:50 - will explain you the use case and then I
501:53 - will code in front of you only first I
501:56 - will explain the use case and the
501:57 - project setup and all and then we'll
501:59 - start with the implementation of that so
502:02 - let's start with the hugging phase with
502:04 - lench it's going to be a new thing new
502:07 - concept so let's understand uh this uh
502:10 - particular thing so first of all guys
502:12 - what you need to do so first of all you
502:14 - need to log into the hugging face
502:16 - hugging face Hub so just search in your
502:18 - Google hugging face and you will get a
502:21 - very first website this is the website
502:24 - of the hugging phas sdps do hugging U
502:27 - hugging face.com so uh try to visit to
502:30 - this particular website and uh if you
502:33 - didn't uh sign up so first do the sign
502:35 - up and then sign in and after that you
502:39 - will be able to create your profile so
502:41 - first you need to do sign up and then do
502:43 - the sign in so automatically you will
502:45 - get your profile and this is what this
502:46 - is my profile I already did a sign up so
502:49 - no need to do anything you can do the
502:51 - sign up by using the Google s well by
502:53 - using your Gmail ID as well so just try
502:55 - to sign up first and try to like create
502:57 - your profile and then sign in
502:59 - automatically you'll find out your
503:01 - profile over here so after getting your
503:04 - profile guys see uh here they have uh
503:06 - see this is the uh like uh homepage now
503:09 - just click on this model so once you
503:11 - will click on the model actually you
503:12 - will find out so here it is saying no re
503:15 - uh activity display here we have a data
503:17 - set spaces papers papers collection
503:19 - Community there are so many thing right
503:21 - so if I'm following something so it will
503:23 - be visible over here now just click over
503:25 - here this one this model so what I can
503:28 - do I can click on this model so I will
503:30 - be getting all the model these are these
503:31 - are the model basically so just click on
503:33 - this all so here basically you will find
503:35 - out all the model and here actually it
503:37 - is showing you the trending model what
503:39 - trending model is there over here now uh
503:42 - directly you can search about this model
503:44 - so what you can do I'm not able to open
503:47 - let me check with this models yes guys
503:49 - so over here you can see these are these
503:50 - all are the model which is there over
503:52 - the hugging phase now you can uh short
503:55 - it uh which is a trending one which is a
503:57 - most download one which is a recently
503:59 - one recently updated most uh liked llm
504:03 - so there you will find out like all the
504:05 - llms and all now let's check with the
504:07 - most like so here I'm going to short all
504:10 - the model with this most like okay so
504:13 - stable diffusion is is a model which is
504:15 - the most liked one now you will find out
504:17 - Bloom is there uh okay so here orange
504:20 - mix is there a control net is there open
504:23 - journey is there chat glm is there star
504:25 - coder so there are so many model even
504:28 - Lama 2 is also there this one Dolly V2
504:31 - it's a model from the uh data brakes
504:33 - this llama 2 it's a model of the meta
504:36 - it's a model from The Meta now stable
504:39 - diffusion is also there stability AI
504:41 - there's the organization name stability
504:43 - Ai and here you will find the table
504:44 - diffusion and here you can see the
504:46 - number of downloads as well so there you
504:48 - will find out the number of download now
504:50 - see llama this llama 2 how many times it
504:54 - has been downloaded
504:56 - 947k around 1 million now here you will
504:59 - find out gpt2 gpt2 is also there it has
505:02 - been downloaded 17 million times 170
505:05 - million download is there okay so okay I
505:08 - think it's not a download it may be a
505:10 - size
505:11 - uh let me check with the download so
505:14 - most
505:16 - downloaded so here now I'm going to
505:19 - check with the most downloaded I think
505:21 - it's a download only it's not a size
505:23 - actually so 73.3 million and distal GPD
505:27 - is also there robot is there there are
505:29 - so many model you will find out and you
505:32 - can see the number 4 lakh 27,000 so if
505:35 - you are talking about the open API so
505:38 - you are restricted with the open API let
505:40 - me show you that what all model is there
505:42 - so if you search over the open a so just
505:45 - open the opena website and check with
505:47 - the models just do the login First and
505:50 - try to uh like click on this API and go
505:53 - inside this model now here you will find
505:56 - out all the model this all the model has
505:58 - been developed by the openi itself and
506:01 - you will find out a different different
506:02 - variants of this model like this chat
506:04 - GPT there are so many variant of this
506:07 - Chad GPT but if we are talking about
506:09 - this hugging face Hub so it's a open
506:11 - source repository anyone can contribute
506:14 - over over here so whoever has created
506:16 - their llm so they have uploaded to this
506:18 - hugging face Hub now you can see the
506:20 - number of model you can see the
506:22 - different different uh like a task over
506:24 - here that what you want to do feature
506:26 - extraction text to image or text to text
506:29 - image to video text to video whatever
506:31 - you want to do you will find it find it
506:33 - out over here let's say what I want to
506:35 - do let's say I want to perform text to
506:36 - text generation so if I will click on
506:38 - this one so you will find out so you
506:41 - will find out all the model from text to
506:43 - text generation you can perform text to
506:46 - text Generation by using this particular
506:48 - model let's say you want to perform a
506:50 - conversation so for the conversation
506:52 - basically there is a different model
506:54 - dialog GPD is there and go is there and
506:57 - you will find out other model as well so
507:00 - from a different different organization
507:02 - you you can go through with it and you
507:04 - can check got it yes or no so this part
507:07 - is getting clear to all of you you can
507:09 - check with the training you can check
507:10 - with the training and you will find out
507:12 - like which is a trending one now let's
507:14 - say I want to do a text to text
507:15 - generation so here I'm going to use this
507:17 - particular model FL T5 base so I'm going
507:20 - to use this particular model now how I
507:22 - can do that what will be the procedure
507:24 - if I want to use this open source model
507:27 - without any charges so here I'm not
507:29 - going to pay anything as of now for this
507:31 - particular model so how I can use it how
507:34 - I can like uh perform text to text
507:36 - Generation by using this particular
507:37 - model now let me tell you that so first
507:40 - of all what you need to do so just click
507:41 - on your profile and here click on the
507:44 - setting so once you will click on the
507:46 - like this setting so here you will find
507:48 - out the token access token so click on
507:51 - this access token so already I have
507:53 - created a token over here so you can
507:55 - click on the new token you can click on
507:58 - the the create token and you will be
508:00 - able to create a new token over here now
508:02 - this is going to be a API key this is
508:05 - going to be a token you can delete it
508:07 - you can recreate it whatever you want
508:09 - you can do it and here uh you will find
508:11 - out access token probability
508:13 - authenticated your identity to the
508:15 - hugging face Hub allowing application to
508:17 - perform specific acction specify the
508:19 - spoke of permission read write and admit
508:21 - so here you can visit the documentation
508:23 - and you can read more about it so first
508:25 - of all guys you need to sign up and then
508:27 - you need to log in and after that you
508:29 - will be able to create your profile and
508:31 - then you can go inside your profile and
508:33 - go inside the setting and there you will
508:35 - find out the token this access token
508:38 - this particular option and try to create
508:40 - the new token after creating a new token
508:42 - what you need to do you just need to
508:44 - copy this token and uh I will tell you
508:47 - step by step what you need to do so from
508:49 - scratch only I'll be writing all the
508:50 - code so first of all see before starting
508:53 - with the hugging face you need to
508:55 - install some Library some other
508:57 - libraries as well so let me give you the
508:59 - name of all those Library I I like kept
509:02 - it somewhere I'm just going to copy and
509:03 - paste all the thing now here are the
509:06 - first thing first Library which I'm
509:07 - going to be install that's going to be
509:09 - hugging face Hub the second one is a
509:11 - Transformer and the third one is
509:13 - accelerate and bit sendy bytes so here
509:16 - this is to the this two is not a
509:18 - mandatory one but yeah you need you can
509:20 - install it because I was getting some
509:21 - sort of a error and for that only I have
509:25 - used this I have like installed this
509:27 - libraries so if uh U like uh so yes
509:31 - please uh like download uh this thing
509:34 - this particular uh like packages
509:36 - accelerate and bit sendy by so you won't
509:38 - get any sort of error throughout this
509:40 - implementation but this two is a
509:42 - mandatory one the first one is a hugging
509:44 - ph up and the second one is a
509:45 - Transformer so you cannot SK skip this
509:47 - two thing and L chain should be there
509:50 - inside your virtual environment because
509:52 - this hugging phase actually we are going
509:53 - to access by using the Len chain only by
509:56 - using the Len chain only we are going to
509:58 - access the this hugging phase so I
510:00 - already did it I already installed it
510:02 - you just need to run it and uh if I
510:05 - already installed then it will uh it
510:07 - will give me the message that
510:09 - requirement is already satisfied so here
510:11 - you can see it is giving me that
510:13 - requirement is already already satisfi
510:15 - got it now guys what is the next thing
510:17 - which I need to do so step by step I
510:19 - have written each and everything I'm
510:21 - going to write it down over here as well
510:23 - so the step first what you need to do so
510:25 - in the step first you need to uh
510:27 - download all the required Library so let
510:30 - me write it down over here the step
510:33 - First Step first is
510:38 - nothing
510:41 - download all the required Library
510:45 - now let me keep it over here and see we
510:47 - are able to download now in the step two
510:49 - what I'm going to do here in the step
510:51 - two I'm going to import it so let me
510:53 - import all the required Library so I
510:55 - have written it over here let me import
510:58 - it uh over here so this is the library
511:01 - which I have imported so the first one
511:03 - is H prompt template hugging phase from
511:05 - the lenon itself of okay so I'm going to
511:08 - import this hugging face Hub and here is
511:10 - what here I'm having the llm chain I'm
511:12 - using this hugging face with Len chain
511:15 - I'm using this hugging phase with this L
511:16 - chain try to remember this thing guys
511:19 - okay so if you are implementing it by
511:20 - yourself please try to remember that we
511:22 - are using this hugging phase by using
511:24 - this Len chain I told you this H Len
511:27 - chain is a wrapper on a different
511:28 - different API not even op open AI we can
511:31 - access many API by using this Len chain
511:33 - many open source model and all it has
511:35 - been designed in such a way now here uh
511:38 - I have imported this thing now what I
511:40 - need to do guys so here I'm going to
511:43 - write it down the Third thing so the
511:45 - third one is what you need to uh like
511:47 - set the environment variable so for
511:49 - setting up the environment variable let
511:51 - me tell you what is a step so here is a
511:54 - like code basically which you need to
511:55 - run so let me copy and paste each and
511:58 - everything I have written uh somewhere
512:00 - so I'm just going to copy and paste the
512:01 - small small lines and all now you need
512:03 - to uh you need to set the environment
512:05 - variable and here first of all you need
512:07 - to import this opening system so import
512:10 - OS os. environment and here is what here
512:13 - is your hugging phase API token and set
512:15 - the environment variable set the
512:17 - environment variable by using this
512:19 - particular uh like a command now if I
512:22 - will run it so here I'm able to set the
512:24 - uh like hugging fish token okay this is
512:26 - my variable name and this is my value
512:28 - value of the variable now from where I
512:30 - got this particular value so I got this
512:33 - value from here itself from the token
512:35 - itself so just try to click on this
512:37 - access token and you will get this value
512:39 - you will get the value of the token got
512:42 - it yes or no now here guys just click on
512:44 - this hugging face and here I seted this
512:46 - token I set this token and this is the
512:48 - variable and this is the value now what
512:51 - is the fourth thing which I need to do
512:52 - so here let me write it down uh this
512:54 - particular thing so step by step I have
512:57 - written each and everything now the next
512:59 - thing which I'm going to do over here
513:00 - I'm going to do text to text generation
513:03 - I'm going to do text to text generation
513:04 - I'm using sequence to sequence model
513:06 - this Transformer is what it's a sequence
513:08 - to sequence model now if we are talking
513:10 - about the uh different different llm
513:12 - actually as a base archit Ure it is
513:14 - using the same Transformer architecture
513:16 - right so either you can say sequence to
513:18 - sequence model encoder decoder model
513:19 - anything anything will be fine for the
513:21 - Transformer also now I want to do a text
513:23 - to text generation so I shown you over
513:25 - here itself in the hugging face model so
513:28 - let me show you where it is so once I
513:30 - will click on this model and here let's
513:33 - say text to text generation I want to do
513:34 - text to text generation so this is a
513:36 - model this a flan T5 base it's a model
513:40 - from the Google side it's a Google model
513:42 - flan T5 base you can read uh everything
513:45 - about this uh T5 model for what this has
513:48 - been trained what uh which data they
513:51 - have used what is a model size 2848
513:53 - million parameters is the it is having
513:56 - like 248 million parameter and here the
513:58 - number of here you can see the number of
514:00 - downloads here you can see the table of
514:02 - content each and everything basically
514:04 - they have defined they have written over
514:06 - here regarding this particular model and
514:08 - this is a Google model and yes you can
514:12 - uh check about it you can use use it
514:14 - actually uh how to use it uh let me tell
514:16 - you that but yeah you can check about it
514:18 - uh just go through the hugging face Hub
514:20 - hugging face model and click on this
514:22 - model click on this text to Tex
514:24 - generation and you here you will get
514:26 - this FL T5 base now guys what I need to
514:29 - do what will be the next thing so the
514:30 - first of all I need to Define my prompt
514:33 - and here what I'm going to do guys here
514:35 - I'm going to Define my prompt so let me
514:37 - copy The Prompt and here is what guys
514:39 - here is my prompt this is what this is
514:41 - my prompt now here I'm going to uh like
514:44 - Define the chain so let me create a
514:46 - chain over here now inside the chain
514:49 - just just try to focus guys what I'm
514:51 - going to do over here so here guys let
514:53 - me remove this max length I'm not going
514:55 - to write it down as of now so initially
514:58 - like uh not initially in my previous
515:00 - example just look into the chain uh what
515:03 - I was doing over
515:05 - there so if you look into the chain
515:08 - there I was writing there I was defining
515:10 - the model from the open a API so let me
515:13 - show you uh let me show you the chain
515:14 - prom template agent and here we have a
515:19 - chain so where is a chain where is a
515:21 - chain where is a chain this is a chain
515:23 - now see prom template is there chain and
515:25 - here I was I was defining a model from
515:28 - the opena itself what what I was doing
515:30 - guys tell me I was defining a model from
515:32 - the open itself now instead of the open
515:35 - now instead of the open now I'm using
515:38 - the hugging phas so what I did I created
515:41 - a object of this hugging face Hub and I
515:43 - given the repo ID means uh this is the
515:45 - ID of the model and here is a argument
515:48 - that U like I need to set the
515:50 - temperature and all so in this
515:52 - particular format let me take it in a
515:54 - different uh let me take it in a
515:56 - different cell let me show you so here
515:58 - I'm going to copy it and let me paste it
516:00 - over here so what is happening just see
516:04 - what is happening let me take it as a
516:06 - command so this is the code which I'm
516:09 - running see this is the code so here now
516:12 - I'm using now I am going to access the
516:15 - llm okay which llm this Google FL T5
516:18 - large now instead of the openi I'm going
516:20 - to use this particular llm FL T5 large
516:23 - and this is the uh this is hugging pH
516:25 - actually which we already imported from
516:27 - the lenen itself this is the one and
516:30 - before that actually you need to install
516:31 - this hugging phase so what you need to
516:33 - do guys tell me you need to install this
516:34 - hugging phase pip install hugging phase
516:36 - otherwise you might face issues so here
516:39 - uh you have you are using this
516:40 - particular model this is some sort of
516:42 - argument uh which you need to mention
516:44 - now let's try to create a chain and here
516:46 - the same thing you need to pass the
516:47 - prompt only now see the power of the
516:49 - length chain what it is able to do now
516:52 - uh instead of the hugging open AI I'm
516:54 - able to connect with the hugging face
516:55 - also like likewise we will be able to
516:57 - connect with many apis just check with
516:59 - the documentation uh so now here you can
517:02 - see we are able to create a object I'm
517:04 - getting some sort of a warning you can
517:06 - ignore it because just a uh it's not an
517:08 - error actually it's a dependency warning
517:11 - that uh don't use this version that
517:12 - version what whatever now here I have
517:14 - created a chain now what was my prompt
517:17 - so here I'm saying what is a good name
517:19 - for the company that make a product
517:21 - whatever like uh regarding whatever
517:23 - product I can ask over here so here I'm
517:25 - saying that chain do run the same thing
517:27 - I'm going to ask over here chain dot run
517:31 - now here uh let's say I'm going to ask
517:33 - uh which product I want so I want uh
517:36 - let's say mic or I want camera again so
517:40 - if I'm asking regarding the camera so
517:42 - let's see so here it is giving me answer
517:45 - uh Nikon what is a good company name for
517:47 - a uh what is a good name for a company
517:51 - uh that makes product so it is giving me
517:52 - a neon regarding this camera Let's uh
517:55 - let ask to the different uh uh product
517:58 - let's say watch so here let's see it is
518:01 - giving it Tata now let's see uh here if
518:04 - I'm asking colorful cloths colorful
518:08 - cloths so here you will see that it is
518:11 - giving me a DE
518:13 - so different different name I'm getting
518:15 - in a similar way uh which I was getting
518:17 - by using this open API now instead of
518:20 - the open API I'm using this flan T5
518:23 - large model you can use any sort of a
518:25 - model any other model as well there are
518:27 - like lots of model which you will find
518:28 - out regarding this text to text
518:30 - generation you can use this model also
518:32 - Mard you just need to mention the ID
518:34 - Mard this is the basically ID just open
518:37 - it and just copy it from here just copy
518:39 - it and keep it over here like uh keep it
518:42 - like this let let me show you that so
518:44 - here is your model name and what you can
518:46 - do just copy this hugging pH from here
518:49 - uh this the complete uh sentence and
518:52 - just change the name just change the
518:54 - name of the model just copy it and paste
518:56 - it over here that's it so just copy it
518:59 - and paste it over here and you'll find
519:00 - out this Facebook ambot large 50 now you
519:03 - can use this particular model if you
519:05 - want few more a few creativity over here
519:07 - you can uh pass the temperature M uh
519:10 - like temperature uh value 1.5 let's say
519:12 - so so this is what this is a model from
519:14 - the hugging face and now this time you
519:16 - are using a different model so the model
519:18 - name is what Facebook MB large 15 so
519:20 - like this you can access a different
519:22 - different model by using the length
519:24 - chain now what you can do you can create
519:26 - a one more chain so here I'm going to
519:28 - copy the same thing now let me change
519:30 - the envir variable name there's going to
519:32 - be a chain two and here what I'm going
519:34 - to do I'm going to copy this hugging
519:35 - face Hub so from here I'm going to copy
519:38 - this hugging face Hub and let me paste
519:39 - it over here so this is what this is my
519:41 - hugging face Hub this is my repo this is
519:43 - my model here I'm setting the
519:45 - temperature and this is what this is my
519:47 - prompt now if I'm going to run it so yes
519:49 - I'm able to create a object now here
519:51 - what you can do here you can call the
519:53 - method run so run and here you can ask
519:56 - anything so let's say here I'm asking uh
519:59 - which product so you can ask uh a mobile
520:03 - so here let's say regarding any sort of
520:05 - a product you can ask so it is running
520:07 - so what is the good name of the company
520:09 - that makes mobile uh it is saying that
520:12 - uh it is giving me a prompt only over
520:15 - here I think I need to follow something
520:18 - else uh chain do run let's ask regarding
520:23 - the same thing colorful cloths and let's
520:28 - see what will be the
520:31 - answer it is giving me a prompt only I
520:34 - think in between I need to run something
520:36 - over here that's
520:38 - why so Transformer this is a pipeline h
520:43 - okay
520:46 - tokenizer I think it is not giving me a
520:48 - correct answer what so so prompt is fine
520:51 - I'm passing a same prompt and this is
520:54 - the
520:54 - prompt now let's say I'm saying zero
520:58 - let's set the different value of the
520:59 - temperature or
521:02 - 05 and see what I am getting over here
521:06 - uh chain
521:09 - two what is a good company that makes a
521:12 - colorful Clause it's not giving me
521:14 - answer instead of that it's giving me a
521:16 - uh like a complete prompt
521:20 - itself so llm hugging face and M large
521:24 - 50 model is what there is a parameter
521:28 - okay no issue I will check with that if
521:30 - I need to mention something over here
521:31 - but that's a way maybe it is not able to
521:33 - uh like predict correctly whatever I'm
521:35 - asking but yeah it is giving me answer
521:37 - this flan T5 large model and even the CH
521:39 - GPD the GPD uh model also from the open
521:42 - AI but it is giving me something else it
521:44 - is running but uh I'm getting other
521:47 - answers or other answer over here not
521:50 - related to our related to our prompt I'm
521:53 - asking something El it is giving me the
521:54 - complete prompt over here okay so this
521:57 - is fine now tell me guys how to use any
521:59 - open source model did you get it please
522:01 - do let me know in the chat if you got
522:03 - this particular part that how to use a
522:05 - different uh how to use any open source
522:08 - model from the hugging
522:11 - phase
522:15 - because it is not a rule-based system
522:16 - now if I'm again running a query so it
522:19 - is not giving a same name because it's a
522:21 - AI based system again and again if you
522:24 - asked to the chat GP now it will do the
522:25 - same thing all right it won't repeat the
522:28 - thing it won't repeat the thing based on
522:30 - your uh like query it will give you the
522:32 - different different suggestions and all
522:35 - so that's why it is giving you the
522:36 - different
522:38 - name tell me guys fast uh it is free
522:41 - actually this hugging pH uh like token
522:44 - is free you can read more about it uh
522:46 - just go through the documentation there
522:47 - is some sort of charges and all U okay
522:50 - so but as of now it is free uh means uh
522:53 - like up to some sort of a tokens and
522:55 - regarding some sort of models it is free
522:58 - okay so here guys I think this hugging
523:01 - face part is clear to all of you please
523:03 - do let me know in the chat if this part
523:05 - is
523:08 - clear yes make question answer board
523:11 - will create in the next class first of
523:12 - all let let me explain you that how to
523:14 - use any uh open source uh model so here
523:18 - I'm using this open source model Google
523:20 - FL T5
523:24 - large tell me guys fast uh so this part
523:27 - is getting clear to all of you if it is
523:29 - getting clear then please do let me know
523:31 - in the chat I'm expecting yes or no in
523:33 - the chat if you have any sort of a doubt
523:35 - you can ask me I try to clarify that and
523:37 - then I will explain you how to create a
523:39 - pipeline how to create a pipeline by
523:42 - using the uh Transformer so uh we can
523:46 - import the Transformer over here we can
523:48 - write it down Leng ch. Transformer and
523:50 - we can create a complete pipeline as
523:52 - well means we can uh download the model
523:55 - we can download the model in our local
523:58 - okay and in our local memory actually we
524:01 - can do it uh we can download it and then
524:03 - we can do the prediction and all the
524:05 - same thing which I'm doing over here by
524:07 - using the API I will show you the
524:09 - pipeline over here so first of all tell
524:11 - me till here everything is clear think
524:12 - is fine yes you can use the Lama 2 also
524:15 - here you will find out the Llama 2 just
524:17 - try to check with a different different
524:18 - model related to a different different
524:19 - task got it so here you will find out of
524:22 - different different model you can use
524:23 - the Llama 2 here is a llama 2 this one
524:26 - llama 2 B Lama 2 13 billion actually
524:29 - it's from the Billy U but you can check
524:32 - from The Meta also so here I think there
524:36 - was a meta you can search about it so
524:39 - here you can write it down Lama 2 so
524:42 - once you will search it so you will find
524:44 - out the Llama just a
524:49 - second uh you can use llama from the
524:52 - hugging phase I just seen that uh
525:02 - training lamba lamba where is a lamba oh
525:06 - I think I need to check with a different
525:08 - page So Meta Meta Nick
525:14 - snip Q see
525:17 - Stark why I'm not getting it just a
525:21 - second I think I kept this text
525:23 - generation that's why now yeah there
525:25 - there is a llama so here meta Lama so
525:28 - this is the model from the Facebook side
525:30 - from The Meta side and uh you will find
525:32 - out a different different variants of
525:34 - this llama just uh take it and use it
525:37 - and it updated uh 25 days ago this
525:41 - one
525:44 - got it guys yes or no I think you are
525:47 - getting it and you are able to get this
525:49 - particular thing this particular part
525:51 - now let's try to understand that how you
525:53 - can download this model in your local so
525:55 - for that there is a certain step so let
525:58 - me write it down those particular step
526:00 - and step by step we'll try to understand
526:02 - how we can create a pipeline and how we
526:04 - can in download this model in our local
526:07 - is whatever model we want to use it we
526:09 - can download it now for that uh I will
526:12 - have have to perform some sort of a step
526:14 - so here uh let me write it down the
526:16 - heading uh here guys this is the heading
526:18 - uh basically just a second uh let me
526:21 - copy and paste um so here what I'm going
526:23 - to do here I'm going to do a text uh
526:25 - here I'm writing text generation model
526:26 - decoder only model so now I will use the
526:28 - decoder only model any model where I I
526:31 - will just have a decoder so what I'm
526:33 - going to do here so the first thing
526:34 - again I'm going to create a prompt so
526:36 - there's my prompt a same prompt I'm
526:38 - going to use or maybe I written a
526:39 - different prompt over here can you tell
526:41 - me a famous fitw footballer so here I I
526:44 - will give the name so I I can remove
526:46 - this famous from here and see the prompt
526:48 - over here that what is my prompt so here
526:50 - I'm asking that can you tell me uh about
526:52 - a footballer can you tell me about the
526:54 - footballer and here I will just give the
526:56 - name so this is what this is my prompt
526:58 - actually now what I will do guys here I
527:00 - will create a chain now in the chain uh
527:03 - what I'm going to do so just a
527:07 - [Music]
527:09 - second fine so here uh let me do one
527:12 - thing for first of all so here I'm going
527:13 - to import some sort of a library
527:15 - otherwise I will get the issues I will
527:17 - get the error so here I'm going to
527:19 - import a few libraries so these are the
527:22 - name so these are the name hugging face
527:24 - pipeline which I'm going to import from
527:26 - the lenen itself actually this is
527:28 - available in a like if you are directly
527:30 - installing the hugging phas hugging face
527:32 - have in your system in your local
527:33 - environment so by using the Transformer
527:36 - also you can import this hugging face
527:38 - hugging face pipeline but as I told you
527:40 - this Len CH is a wrapper on top of this
527:42 - uh apis on top of this libraries so by
527:45 - using this lenon also you can use this
527:47 - hunging face pipeline now what is the
527:49 - meaning of the rapper so uh you know
527:51 - right so tensor flow so this Kass
527:54 - actually it's a repper on top of the
527:55 - tensor flow if you have seen the Kass so
527:57 - there you must have seen that uh like we
528:00 - are just going to call a Kass Dot and
528:02 - pipeline we are just going to write it
528:04 - down Kass ad and we are creating a
528:06 - number of note and then kasas or this
528:08 - that whatever so in back end this T the
528:11 - tens code is running but on top of this
528:14 - T tensor flow they have created one UI
528:17 - or they have created one interface now
528:19 - you are not interacting directly with a
528:21 - lowlevel API low level code you're not
528:23 - going to write it down that instead of
528:25 - that what you are going to do you are
528:26 - using the rapper Kass so it is easy to
528:28 - use for you so similarly see the similar
528:31 - thing you can see over here this Len is
528:33 - nothing it is a wrapper on top of the
528:34 - other apis okay on top of the other
528:37 - packages so over here you can see uh
528:40 - like I need to import this particular
528:42 - thing so the first thing I'm going to
528:43 - import that is a like Pipeline and the
528:46 - second thing which I'm going to import
528:47 - that is a auto tokenizer auto model uh
528:50 - for uh casual LM Pipeline and auto model
528:53 - for sequence to sequence llm I will come
528:55 - to each and every import statement uh
528:57 - once I will write on the code step by
528:59 - step I will try to explain you that why
529:01 - I writing this a particular thing right
529:04 - now here what I'm going to do I'm going
529:05 - to download the model the same model in
529:08 - the local instead of using this API I'm
529:10 - downloading the same model in my local
529:12 - local memory in my current uh memory in
529:14 - my volatile Ram actually so here what
529:17 - I'm going to do first of all I need to
529:19 - mention the model ID now model ID wise
529:21 - you will find out like I'm using a same
529:23 - model FL T5 large and this is a model
529:27 - from the Google side Google has given
529:28 - this model this particular model fly T5
529:30 - large so this is what this is my model
529:32 - ID from where you will get a model ID
529:34 - you just need to click on the model name
529:36 - and from there itself you can copy this
529:38 - model ID so let's say I want to get a
529:40 - model ID so just copy from here just
529:43 - copy from here copy model name to the
529:45 - clipboard that's it so here's what here
529:48 - I'm having a model ID now guys what you
529:50 - want to do so here actually you need to
529:52 - uh like create a like a the object of
529:56 - this tokenizer and here actually you
529:58 - need to create one uh here you need to
530:01 - here you need to call one method from
530:03 - tokenizer it's a standard processor if
530:05 - you want to use this hugging face
530:07 - pipeline so uh at the first place you
530:09 - will have to perform the tokenization
530:11 - and uh here I'm going to do a same thing
530:13 - so whatever data which I'm going to pass
530:15 - right so this tokenizer will
530:16 - automatically uh take care of it and
530:19 - back end actually some mathematical like
530:22 - like some mathematical equations and all
530:24 - it's going on uh maybe like with respect
530:26 - to the tokenization uh you know like
530:28 - different different tokenization
530:29 - technique what is the meaning of the
530:30 - tokenization so whatever prompt you have
530:33 - that a text prompt actually are going to
530:34 - convert into a numbers so that is
530:36 - nothing that is my uh token means like
530:40 - uh the in a numbers itself so that is
530:42 - what that is your encoded value so by
530:44 - using this Auto encod auto tokenizer you
530:47 - are going to do the same thing you are
530:48 - going to encode the values got it yes or
530:51 - no I think you are getting my point so
530:53 - here uh you are going to use this Auto
530:56 - tokenizer and here I'm going to call
530:59 - this particular method so from uh model
531:02 - ID from pre-train from pre-train and
531:04 - this is what this is my method and here
531:06 - I'm passing this model idid so now what
531:08 - I'm going to do I'm going to keep this
531:10 - particular thing inside the variable the
531:11 - variable name is going to be a tokenizer
531:14 - so here is what here is my variable name
531:16 - so once I will run it now over here you
531:18 - can see we are able to create a object
531:20 - and we are able to call this particular
531:22 - method by passing this model ID now what
531:25 - I will do guys so here uh I will uh I
531:29 - will uh like uh call I will call this
531:32 - particular method let me show you the
531:34 - next one it's a standard procedure don't
531:36 - worry again I will give you the quick
531:37 - revision first of all let me run it the
531:39 - entire thing now over here I'm writing
531:41 - down Auto model for sequence to sequence
531:43 - LM and here I'm I'm calling this method
531:46 - from pre-train and here is what my model
531:49 - ID and here is device map is auto right
531:51 - just just like a like ignore this
531:53 - particular parameter just look into this
531:55 - model ID so here actually I'm passing
531:57 - this model ID Google fly T5 large so
532:00 - this model this is my model actually
532:02 - which I want to which I want to get so
532:04 - here I have a method Auto model here is
532:07 - I'm basically Class Auto model for
532:09 - sequence to sequence LM and from here
532:12 - I'm going to call this from pre-rain
532:14 - this particular method I'm passing this
532:16 - parameter model ID parameter now if I
532:19 - run it so here you will be able to see
532:21 - that we are able to run it so here we
532:23 - have created a object for this one also
532:26 - now guys the next thing what I have to
532:27 - do so here actually I'm going to create
532:29 - my pipeline so uh here uh I'm going to
532:32 - create my Pipeline and for this one uh I
532:35 - have written a code so this is a code
532:38 - this is what is my pipeline here I
532:39 - already imported it now here I'm going
532:41 - to pass the key text to text generation
532:43 - here is my model this is what this is my
532:45 - model now here is what here is a
532:47 - tokenizer this is a tokenizer and here
532:49 - is a max length so you can remove it you
532:51 - can uh remove the max length also not an
532:53 - issue with that so here uh I'm going to
532:55 - create my pipeline so for first thing
532:57 - what I need to do I need to create a
532:58 - tokenizer and the second thing I need to
533:00 - create a model I need to download the
533:02 - model see uh first time if you will
533:05 - download this model now you will get the
533:07 - uh the progress bar I'm not getting it
533:09 - why why because I I did it actually I
533:12 - was practicing with the thing so at that
533:14 - time I downloaded this I downloaded that
533:17 - particular model and this tokenizer and
533:19 - it is in a buffer itself so it is it is
533:22 - like taking from the caching memory so
533:23 - that's why you are not seeing this that
533:25 - particular progress bar but in your case
533:27 - if you're doing first time you will see
533:28 - the progress bar you will see the prog
533:31 - progress bar okay so here you are going
533:33 - to create a pipeline so this is what
533:35 - this is my Pipeline and here I passed
533:37 - the two thing the first one is a key
533:39 - text to text generation this is my key
533:41 - and here uh is what here I have written
533:43 - the model and here is my tokenizer
533:45 - that's it you just need to focus on this
533:46 - two part now here I'm going to create a
533:49 - pipeline so this is what guys this is my
533:50 - pipeline now after that what I'm going
533:52 - to do I have to pass this particular
533:54 - pipeline to my hugging phase Pipeline
533:57 - and here actually you will find out this
533:58 - is what this is my local llm means see
534:02 - what I'm going to do so this is my model
534:04 - this is my tokenizer which I'm going to
534:06 - download from the pre-train one from the
534:08 - pre-train one and this is the model ID
534:10 - the same uh tokenizer
534:12 - which has been used to this particular
534:14 - model from the pre-train see I'm calling
534:15 - this method so here is my tokenizer and
534:18 - here is my model from this particular ID
534:20 - I'm not getting any progress bar why
534:22 - because I already did it it is taking
534:23 - from a cachia memory okay but if you are
534:26 - doing it first time you will be getting
534:28 - a progress bar and you will be seeing
534:29 - that all the parameters getting
534:31 - installed over here right got it now
534:33 - here what I need to do I need to keep
534:35 - all the thing in a pipeline and then
534:36 - finally I'm passing it to the hugging
534:38 - face Pipeline and this is what this is
534:40 - my local llm now everything is done
534:42 - everything is clear now let me run this
534:44 - prompt so here is what here is my prompt
534:47 - so what I can do let me keep this prompt
534:50 - over here this is my prompt and here
534:53 - this is my prompt and this is what this
534:55 - is my local llm now let me run it and
534:57 - here what I will do guys so now uh let
535:00 - me call the chain and to the chain I'm
535:03 - going to do a same thing what I'm going
535:04 - to do guys tell me to the chain actually
535:06 - see what is a chain I told you chain is
535:08 - nothing it's a it's a like a collection
535:11 - of of the components right you are going
535:13 - to uh you are going to you are you are
535:16 - stacking the components a different
535:18 - different component have you seen the
535:19 - chain right so uh there I was stacking
535:22 - the llm and this prompt so I'm doing the
535:24 - same thing now see the power of the Len
535:26 - chain not even with the open AI we are
535:28 - able to use it with the different
535:30 - different apis with the hugging face
535:31 - also directly and even in the with uh
535:35 - with respect to the local one also with
535:36 - respect to the local LM also so it works
535:39 - with in every scenario this lenion works
535:41 - with every scenario okay now here if I'm
535:44 - going to run it uh so now I I'm able to
535:46 - create this chain now if I will ask
535:48 - anything to this chain so let me write
535:50 - it down over here chain do run now here
535:53 - what I'm going to do here I'm going to
535:54 - pass let's say Messi okay Messi now if I
535:57 - will run it so you will find out that it
535:59 - is generating a answer so Messi is a
536:02 - footballer from Argentina and I just
536:04 - asked what I asked guys so here I asked
536:07 - what was my prompt can you tell me about
536:09 - footballer so here is a name name which
536:11 - I'm passing now let me write it down
536:14 - some any Indian Indian like footballer
536:17 - name so Sunil
536:19 - Chri so let's see uh what will be the
536:24 - answer it is able to get it or not sonil
536:28 - chetri uh okay Sunil chetri born 24th
536:31 - August 1971 it's a former Indian Indian
536:34 - footballer who played up forward so
536:37 - great guys it is able to give me an
536:38 - answer and here you can see I have
536:40 - installed I downloaded the model in a
536:42 - local itself so tell me guys this part
536:45 - is clear to all of you how to use the
536:47 - hugging face API by using the lenen and
536:50 - how to download the model and how to use
536:52 - it please do let me know in the chat if
536:55 - this part is getting clear to of all of
536:57 - you so yes this is the number of tokens
536:59 - max length So within that itself within
537:01 - uh it is not going to exceed the answer
537:04 - and this is the max length basically it
537:05 - will be uh within that itself you will
537:08 - be getting an
537:10 - output
537:13 - tell me guys fast so is it clear to all
537:15 - of you if this part is clear then please
537:17 - do let me know please hit the like
537:19 - button and uh yes if you have any sort
537:22 - of a doubt then you can ask
537:26 - me you can ask about the vat kohi you
537:28 - can check over here so here you can
537:31 - write it down the vat kohi even though
537:33 - he's not a footballer let's see what
537:34 - will be the answer it depends on the
537:36 - model our GPT model is very much uh
537:38 - powerful let's see uh this uh Flame T5
537:47 - large so okay so I'm getting verat kohi
537:52 - is a s linkan footballer who plays it is
537:54 - completely wrong now you can see so it
537:57 - is uh not giving me a correct answer
538:00 - let's try to design a different prompt
538:01 - over here so here I can uh do that let
538:04 - me this let me design one more prompt
538:06 - and can you tell me about cricketer so
538:09 - here I can write it down cricketer c r i
538:12 - c k uh cricket so this is the spelling
538:16 - now let me take this thing and here is
538:19 - going to be my chain two this is my
538:22 - chain two and this is my prompt two and
538:24 - I'm using a same llm over here so this
538:26 - is my chain two now what I will do here
538:30 - I'm going to run it and let's see will I
538:32 - will I get a correct information or not
538:35 - will this model is capable or not this
538:37 - uh which is a name what is the name
538:40 - flame T5 large so let's see it is a
538:42 - capable or not so chain two. run and uh
538:46 - if I'm running it
538:50 - so in the district of balut prad is
538:53 - giving me a wrong answer I think uh
538:56 - cricketer Koh he does not belong from
538:59 - the bhalpur it belong he belong or not I
539:01 - don't know about it let's uh talk about
539:03 - the suchin uh let's talk about the sain
539:06 - or Ms D so here I can ask about the MS
539:13 - Tony chain. run and let's see who play
539:18 - the Indian Premier League site Mumbai
539:21 - okay it is saying mson plays a cricket
539:23 - from the Indian Premier League from
539:25 - Mumbai Indian so it is like a completely
539:28 - it is giving a wrong answer this flain
539:30 - T5 so you should use a different model
539:33 - in that case actually see GPD is a
539:35 - better one it always gives a correct
539:37 - answer and and is like a much more
539:39 - capable that's why I started from the
539:40 - open a and that's why I didn't started
539:42 - from the hugging page but yeah according
539:44 - to the task according to data according
539:45 - to requirement so now that will be your
539:48 - responsibility as an NLP engineer as a
539:50 - generative engineer you have to check
539:52 - you have to like check with a model that
539:54 - uh like on which data it has been
539:56 - trained okay on which data has been fine
539:58 - tuned how many parameters is there what
540:00 - is a performance performance of that if
540:03 - uh like uh we are doing a text
540:04 - generation that what is a blue score
540:06 - like blue score with that we can
540:08 - identify the uh that like how much it is
540:10 - capable for generating a text so each
540:12 - and everything you will have to read
540:14 - about the model and then only you can
540:16 - use in a production not directly so
540:18 - there will be so many uh like uh uh uh
540:22 - there will be so many experiment which
540:24 - you will have to
540:26 - perform okay there will be so many back
540:28 - and forth you will have to perform
540:29 - before deciding any sort of a model and
540:32 - here I have given you the approach guys
540:34 - here you can append the memory here you
540:36 - can play with the chains here you can uh
540:38 - like play with a different different
540:40 - prom template you can download the
540:41 - document you can import the document
540:43 - each and everything I have shown you
540:45 - inside this two notebook now you are
540:47 - enough capable to implement uh for
540:49 - implementing any sort of a project now
540:51 - whatever project I'm going to teach you
540:53 - definitely you will be able to grab it
540:55 - and uh I will uh after the like jupyter
540:58 - notebook implementation of the project I
541:00 - will uh explain you that how you can
541:02 - convert into an end to endend one so uh
541:04 - from next class onwards we are going to
541:07 - start our Inn project by using this Len
541:09 - chain open ey hugging fish and all and
541:11 - apart from that we are going to use some
541:13 - other thing as well and I will show you
541:15 - the complete setup of the project the
541:17 - project name is going to be McQ
541:20 - generator got it yes or
541:23 - no yes you can fine tune the model as
541:26 - well if you want like if you want to
541:28 - find uh if you want the process of the
541:30 - fine tuning I will give you that also I
541:32 - will give you the fine tuning process
541:34 - also just wait for some time step by
541:36 - step we try to do each and everything if
541:38 - I'm going to explain you everything in a
541:40 - single class so it might be a difficult
541:42 - for you so uh step by step we'll try to
541:45 - do it don't worry we are not going to
541:48 - like conclude or we are not going to
541:50 - step stop this community session uh like
541:52 - uh we'll be continue this uh like in
541:54 - know next week also and there uh we
541:57 - going to talk about
542:00 - many you can use uh like which open stes
542:04 - model you can use for the machine
542:05 - translation you can check over here just
542:07 - go through with the hugging phase API
542:10 - and click on the model model uh just uh
542:12 - click on the model and here you will get
542:14 - the machine translation so maybe machine
542:17 - translation is there classification
542:19 - question answering yeah here is a
542:20 - translation so just see the model what
542:23 - all models is there just try to use this
542:25 - particular model open source model apart
542:27 - from that you'll find out other model as
542:29 - well so see llama 2 is a open source
542:31 - model you will find out a different
542:32 - different variants of this llama you'll
542:34 - find out a different different variants
542:36 - of this llama okay so you can use this
542:38 - llama 2 model for your image translation
542:41 - as I click on this translation here you
542:43 - can see the result got it now you can do
542:46 - your own research you can go through
542:47 - with the different different API as I
542:49 - told you if you don't want to use the
542:50 - chat GPT so here I have created one more
542:53 - API for all of you so like I have
542:56 - written a code regarding one more API
542:57 - that's going to be a AI 21 lab so in the
543:00 - next class I will show you means after
543:01 - the project actually after completing
543:03 - the vector databases and all I will come
543:05 - to some Mis mous topic there I will show
543:07 - you the code regarding this a21 lab okay
543:10 - so here actually uh like we'll talk
543:13 - about the Jurassic model uh which is a
543:15 - very powerful model with that also you
543:17 - can do a multiple thing Falcon is there
543:19 - you can use the Falcon so Falcon you
543:21 - will find out here itself you know uh
543:23 - let me show you where is a falcon so
543:25 - once you will search over here Falcon so
543:28 - it's a model from the Google yeah uh no
543:31 - it's a not of Google one it's a not of
543:34 - Google model actually it's a model from
543:36 - this particular
543:38 - organization I think it's a Chinese
543:40 - organization maybe and one more model
543:43 - let me write it on the name Falcon let
543:46 - me recall the name Falcon was there
543:49 - Bloom is there uh let me check with the
543:51 - bloom yeah Bloom is there and apart from
543:54 - that farm is also there p a LM Palm is
543:58 - also there it is not actually you won't
544:01 - be able to find out this pal over here
544:03 - uh you uh you will have to access it
544:05 - from the separate API so it's a Google
544:08 - model pal p a l m 2
544:11 - Palm 2 API just search over the Google
544:13 - and you will find out it this Palm
544:16 - API so it's a uh model from the Google
544:20 - research Google researcher it's a model
544:22 - from the Google community so you can
544:24 - explore about the API and you can
544:26 - utilize this all you can see generate
544:28 - your API key just generate a API key and
544:30 - try to use this form model as well and
544:33 - after like so many back in fors after so
544:35 - many research and all then only you can
544:38 - decide that which is which is my best
544:39 - model which one I should which one
544:41 - should I productionize this is working
544:43 - fine or that is working fine but gpd1 is
544:46 - a like trusted one and here you we can
544:48 - you can see the clear application of the
544:50 - GPD model where they are using GPD 3.5
544:53 - turbo and GPD 4 itself so many people
544:55 - are using the GPI even though it is a
544:57 - paid one but people are checking with
545:00 - the other open source model as well like
545:02 - this Palm Falcon Bloom and all okay
545:04 - Cloud a is one of the model you can
545:06 - check about the cloud as well so I think
545:10 - now uh each and every uh thing is clear
545:12 - to all of you so guys if you're liking
545:15 - the session if you uh like the content
545:17 - then please do let me know in the chat
545:19 - or please hit the like button if you are
545:22 - able to understand everything whatever I
545:24 - have explained you in today's
545:28 - session here I will explain you how to
545:30 - build the applications and all and from
545:32 - next uh class onwards I will give you
545:34 - the different different assignments
545:39 - also
545:41 - yes we can use the mlops tools now like
545:43 - we'll do the development now in between
545:45 - we can use any mlops tools ml flow we
545:48 - can use ml flow DBC or Q flow we can use
545:51 - the uh like other melops tools like
545:53 - Docker and all don't worry regarding
545:56 - that so once I will come to come to the
545:59 - development there I will uh do
546:05 - that okay great now yeah jimin also come
546:08 - you can check with that also recently
546:10 - Google has released the
546:15 - gemin fine so I think uh now we can uh
546:19 - close the session uh now we'll meet on
546:22 - Friday uh Saturday and Sunday we don't
546:24 - have any session uh the session is going
546:26 - to be from Monday to Friday only and the
546:29 - timing is 3: to 5: p.m. IST so let me
546:32 - write it down over here uh Saturday
546:34 - Sunday we don't have any session
546:37 - Saturday and Sunday there won't be any
546:40 - session
546:43 - s session will be
546:47 - continuing
546:49 - continuing uh from Monday
546:53 - onwards Monday onwards and the timing
546:56 - will be timing will be
546:58 - sa so it's going to be from 3:
547:01 - to 5 p.m. ISD so here guys it's a short
547:06 - notice for all of you uh we don't have
547:09 - any session on Saturday and Sunday day
547:11 - the session will be going on uh from
547:13 - Monday to Friday only and the timing
547:15 - will be same 3 to5
547:17 - istd fine I think
547:21 - uh I have finished the data loader topic
547:24 - uh if you will check into this uh this
547:27 - particular notebook already I have uh uh
547:30 - like shown you this data loader and all
547:32 - now I told you now just try to check
547:33 - with the different different data
547:34 - loaders and all CSV tsv Excel or
547:38 - whatsoever just go and check you can do
547:40 - it by using the documentation but here I
547:43 - given you the example of the to data of
547:45 - this document loader so I have imported
547:48 - this uh PDF I think you missed the
547:51 - previous sess that's why you are asking
547:53 - this question fine so I think uh we can
547:56 - start with the session so welcome back
547:58 - to this community session of generative
548:00 - AI uh this is day six and today we going
548:04 - to start with our first end to end
548:06 - project that's going to be a McQ
548:08 - generator so guys uh this is this is our
548:11 - first uh like end to end project which
548:13 - we are going to implement by using this
548:16 - generative AI uh by using the LMS and
548:19 - all and in this particular project we'll
548:21 - try to use the all the concept basically
548:24 - whatever we have learned so far in our
548:26 - course in our committee session so first
548:29 - of all uh let me show you that uh where
548:31 - you will find out all the session all
548:34 - the uh resources and all because we have
548:36 - updated each and everything over the
548:38 - dashboard and each and everything you
548:41 - will find out uh in the uh resource
548:44 - section so let me show you that uh
548:47 - particular thing and for that guys you
548:50 - just need to visit the Inon website and
548:53 - after visiting the website you need to
548:55 - search about the generative AI so search
548:57 - about the generative Ai and there you
548:59 - will find out two dashboard so first One
549:03 - dashboard for the English and One
549:05 - dashboard for the Hindi so yes I'm
549:07 - taking a same session on my on the I on
549:11 - Hindi YouTube channel as well so you can
549:13 - search ion Tech Hindi so there I'm
549:15 - taking a same session and uh there also
549:18 - I'm uh explaining the concept of the
549:20 - generative a and all so guys here what
549:23 - you need to do here you need to click on
549:25 - this particular dashboard generative AI
549:27 - Community session and once you will
549:30 - click on that so it will ask you for the
549:32 - enrollment and here we are not going to
549:35 - charge you anything any cost so if you
549:37 - are new then please do sign up and then
549:40 - uh try to enroll in this particular
549:42 - course now here guys uh just enroll to
549:46 - this particular course and after that
549:48 - you will be redirected uh redirecting to
549:51 - the dashboard so after sign in you will
549:53 - get a dashboard uh here you can see this
549:56 - is uh this is a complete dashboard uh
549:59 - just a second let me show you
550:02 - that this is the one so this is the this
550:05 - is the dashboard guys and here you will
550:06 - find out all the recording so uh so far
550:10 - I took five session day one day two day
550:13 - three day four day five and in this
550:16 - particular session I covered each and
550:18 - everything regarding the generative AI
550:20 - whatever uh is required if you want to
550:22 - start with the projects and all so uh
550:25 - just go through with the very first
550:27 - session there you will find out complete
550:30 - introduction and in the second one so in
550:33 - the second session uh there I have
550:35 - discussed each and everything about the
550:36 - open Ai and in the third session I have
550:39 - discussed about the Len chin and then I
550:42 - talked about the a few more concept like
550:45 - Len chain memory and all even I have
550:47 - discussed about the hugging face API so
550:50 - if you want to use any open source model
550:53 - if you don't want to use a model from
550:55 - the open AI so uh you can access the
550:58 - model from the hugging phase also that
551:00 - thing also I taught you so if you will
551:02 - go through with my session each and
551:04 - everything you will find out now it's
551:06 - time to implement the project so we'll
551:08 - try to implement a project and and the
551:10 - project is going to be end to endend and
551:13 - not even single so uh not even this
551:16 - project so we are going to implement to
551:18 - more project with a few more advanced
551:21 - concept like vector databases and there
551:24 - will discuss about the r and there we
551:27 - are going to create our web API by using
551:30 - the fast API and flast so each and
551:33 - everything we are going to do here
551:35 - itself in a live session so please make
551:37 - sure that you enroll uh for this
551:40 - particular dashboard and please try to
551:42 - check with the ion YouTube channel as
551:44 - well there we are uploading each and
551:46 - every video so once you will search over
551:50 - the Inon so let me show you that so uh
551:52 - first of all you need to open your uh
551:54 - open your YouTube and there search about
551:57 - the uh Inon so here you can see so open
552:02 - the Inon YouTube channel and inside that
552:04 - uh like uh there you'll find out one
552:06 - live section so just click on this live
552:09 - section and you will find out all the
552:12 - recordings so here you will find out all
552:14 - the recording from day one to day five
552:17 - and uh today I'm uh teaching a project
552:19 - it's a day six and uh if you will open
552:22 - any sort of a video so here in the
552:24 - description also you will find out each
552:26 - and every detail so here you will find
552:28 - out a course detail here you find out
552:30 - each and every detail basically whatever
552:32 - is required so please make sure that uh
552:35 - like you are enrolling to the dashboard
552:36 - for the entire resources and all and yes
552:39 - recorded video is available over the
552:40 - Inon YouTube channel as well got it so I
552:44 - think uh this is fine this is clear now
552:47 - let's start with the project so as you
552:49 - have seen the uh the topic uh so the
552:52 - topic is what topic is the project name
552:55 - is what the project name is a McQ
552:56 - generator using open Ai and langen chain
552:59 - now why I took this a particular project
553:02 - because see uh we have learned each and
553:04 - everything we have learned each and
553:05 - every concept so far related to the open
553:08 - API related to The Lang chain now how we
553:10 - can utilize those information until we
553:13 - are not going to implement the project
553:16 - so in that case we won't be utiliz that
553:18 - particular information whatever we have
553:20 - learned even we won't we won't be able
553:23 - to relate those thing with a real time
553:25 - thing so that's why I kept this project
553:27 - for all of you in between and then we'll
553:30 - try to move into some Advanced concept
553:33 - like databases and all and we'll try to
553:35 - create a few more a few more project in
553:38 - our upcoming session but yeah so here uh
553:41 - we are going to start from the very
553:43 - basic project and then we'll go to the
553:45 - advanced label got it now what all thing
553:49 - I'm going to discuss in today's class in
553:51 - today's session along with the project
553:53 - so here I will teach you the entire
553:55 - setup of the project so here uh we are
553:58 - not going to implement this project in a
553:59 - jupyter notebook so for that we are
554:01 - going to create a complete development
554:04 - environment so I will show you how you
554:06 - can create a like and to and development
554:08 - environment and then we'll try to deploy
554:10 - this project as well so in tomorrow's
554:12 - session I will show you how you can
554:14 - deploy this project along with the cicd
554:17 - concept along with the continuous
554:18 - integration and continuous deployment
554:20 - concept so in today's session we'll try
554:22 - to see that how we can set up our uh
554:25 - development environment and then uh
554:27 - we'll try to uh implement the Jupiter
554:30 - notebook regarding a different different
554:31 - application and then we'll try to
554:33 - convert that jupyter notebook into a
554:36 - endtoend application got it yes or no so
554:39 - the agenda is clear to all of you please
554:42 - uh do let me know in the
554:44 - chat yes or
555:09 - no
555:14 - great so I think uh we can start and uh
555:17 - yeah if you are liking the session then
555:19 - please hit the like button and uh keep
555:22 - watching so guys uh the first of all let
555:24 - me write it down each and everything
555:26 - each and every step uh whatever we are
555:28 - going to do here and whatever uh we'll
555:30 - be doing throughout the session so for
555:33 - that uh I'm using my Blackboard and here
555:35 - itself I'm going to write it down the
555:37 - each and everything so first of of all
555:40 - let me remove it and yes uh I have
555:43 - opened the fresh one now let me write it
555:45 - down each and everything uh regarding
555:48 - today's session so guys see the first uh
555:50 - thing which we're going to do uh that is
555:53 - uh environment setup so at the first
555:56 - place uh we're going to uh set up our uh
555:59 - environment our development environment
556:02 - I will show you the complete a project
556:04 - setup so here let me write it down so
556:06 - setup development environment so the
556:10 - first thing which we're going to do uh
556:11 - we going to set the development
556:13 - environment now after that what I will
556:15 - do after setting the development
556:17 - environment then uh we'll try to uh run
556:21 - a few experiments run few experiments uh
556:25 - few experiment in a Jupiter notebook so
556:28 - we we'll run a few experiment in a
556:31 - Jupiter notebook after that we'll create
556:33 - a end to end will'll create a modular
556:36 - coding like by using this particular
556:38 - experiment and all so I will do a like
556:41 - modular coding I will create a several
556:43 - file and then I will uh try to segregate
556:45 - the code so uh after uh doing a few
556:49 - experiment in a Jupiter notebook I will
556:51 - convert this jupyter notebook into a
556:53 - modular
556:55 - one got it modular coding now after that
556:59 - after uh converting to a model one
557:01 - Modular One definitely uh like uh uh my
557:04 - code will be uh my code will be uh ready
557:08 - and then I will create my web API then I
557:10 - will create my web API by using the
557:13 - stream lid so here by using the stream
557:15 - lid I will be using I will be creating
557:17 - my web API and after uh creating this
557:20 - web API definitely for sure I will test
557:22 - it and finally we'll try to deploy our
557:26 - application on my cloud platform in my
557:28 - AWS or aor got it so these are few step
557:32 - uh these are the these are few things uh
557:35 - uh basically which we're going to
557:36 - perform uh regarding this particular
557:38 - project so today uh I will be uh cover
557:41 - this two point the first one second one
557:43 - and maybe the third one and tomorrow I
557:45 - will create a web API because we have a
557:48 - time restriction the session is just for
557:50 - the 2 hour otherwise I can complete this
557:53 - thing within a uh class itself so today
557:56 - I'm going to complete this two thing and
557:59 - tomorrow uh I will be converting uh the
558:01 - entire code in a modular one and then uh
558:04 - we are going to create a web API and
558:06 - finally we're going to deploy the
558:08 - application got it now after that now
558:11 - after that what uh we are going to learn
558:13 - so after completing this thing we're
558:15 - going to learn about the vector
558:17 - databases we'll try to learn a vector
558:19 - databases we'll try to see that what all
558:22 - options we have if we want to store the
558:24 - embedding not even the vector databases
558:27 - what all other options we have so we'll
558:29 - try to explore about the mongodb
558:32 - cassendra and we'll try to look into the
558:34 - SQL base database also and then finally
558:37 - uh we'll look into the vector databases
558:39 - different different options we have and
558:41 - then uh we'll try to use the RG concept
558:44 - on top of that and we'll create a few
558:46 - more project so yes uh from today's
558:50 - onwards our project journey is going to
558:52 - be start so don't miss it and within 2
558:54 - week uh our aim to complete at least
558:57 - three and to end project in a live
558:59 - session itself got it so I hope this
559:02 - idea is clear to all of you now uh let's
559:05 - start uh first uh with the project setup
559:08 - so the implement impation the project
559:10 - basically I'm going to implement in a
559:12 - jupyter notebook so entire development
559:14 - setup I'm going to create in my uh sorry
559:17 - I'm going to create in my vs code so for
559:19 - the entire development I'm going to use
559:21 - my VSS code and today I will show you
559:23 - how you can set up your vs code for the
559:26 - end development got it so for that guys
559:29 - uh what you need to do first open your
559:31 - CMD uh uh Implement along with me
559:34 - because uh I will share the GitHub link
559:36 - with all of you so that you can uh write
559:39 - it down the code you can copy each and
559:41 - everything from there itself and along
559:43 - with the uh code I will I will be
559:45 - writing all the commands and uh all
559:47 - whatever I'm going to use in my uh in my
559:50 - project so in my project setup and all
559:52 - so each and everything I will be uh I
559:54 - will be writing in my GitHub U I will be
559:56 - writing in my readme file and then I
559:58 - will give you uh through my GitHub link
560:01 - so guys uh you can follow uh uh each and
560:03 - everything along with me so uh first let
560:05 - me start from the project setup so uh
560:09 - here here guys uh first of all what you
560:11 - need to do so in any directory in C
560:13 - directory in D directory in whatever
560:15 - folder you need to create uh one folder
560:18 - you need to create one fresh folder okay
560:21 - so go in uh go with any directory C
560:23 - drive uh C directory D directory C drive
560:26 - D drive e Drive and inside that you need
560:29 - to create one folder so here you can see
560:31 - this is my location C user sunny and
560:34 - here I'm going to create my folder one
560:37 - fresh folder so for create a folder
560:40 - there's a command like mkdir by using
560:43 - this particular command I can create a
560:45 - folder so here I'm going to write it
560:47 - down mqd and my project name so let's
560:50 - say my project name is what McQ
560:53 - generator so this is the like uh this is
560:55 - the folder name which I have written now
560:58 - uh yes I have created my folder now what
561:00 - I need to do I need to move into my
561:02 - folder now I need to change the
561:04 - directory so here I need to move into my
561:06 - folder I need to change the directory so
561:07 - for that we have a command like CD CD
561:11 - McQ generator this is my folder name now
561:14 - you can see I'm into my folder now I'm
561:17 - inside my folder and from this
561:19 - particular folder I need to launch my vs
561:21 - code so for launching the vs code from
561:24 - the command promp there is a command the
561:26 - command is called code dot code space
561:29 - dot so once you will write it down on
561:31 - this particular command code space dot
561:34 - so in that case you will be able to
561:36 - launch your jupyter notebook in a
561:38 - current for folder right so here is my
561:41 - folder name my folder name is what my
561:42 - folder name is McQ now here you can see
561:45 - I'm able to launch my j i I'm able to
561:48 - launch my vs code inside this particular
561:51 - folder now if you want to verify so for
561:53 - that what you can do you can go with
561:55 - your terminal so just click on the new
561:57 - terminal and here you will find out the
561:59 - same location which you are seeing over
562:02 - the command prompt so guys here you can
562:04 - see you are into the same location which
562:07 - you were seeing over the command prom
562:09 - got it now let's say uh if you don't
562:11 - have this vs code so from there you can
562:13 - install this vs code so for that you
562:16 - just need to go through the Google just
562:18 - search over the Google just search about
562:19 - the google.com and here write it down vs
562:22 - code download so write it down here vs
562:25 - code download so you will get a link for
562:27 - downloading the vs code and here uh this
562:30 - is the link guys I'm giving you this
562:32 - particular link inside the chat and here
562:35 - uh like you can go through with this
562:37 - particular link and you can download the
562:39 - vs code according to your operting
562:41 - system so if you are using Mac uh so you
562:44 - can download from here if you are using
562:47 - the Linux so from uh for the Linux you
562:49 - can download from here if you're using
562:51 - Windows so for the windows you can
562:52 - download from here you will find out all
562:55 - the three option for a different
562:57 - different operating system now uh once
562:59 - you are done uh uh like with the
563:01 - download and all so after that what you
563:03 - need to do so after that you need to
563:05 - install it so just try to do a double
563:06 - click and install this vs code in inside
563:09 - your system and then you can follow the
563:12 - same procedure so you can create a
563:14 - directory you can uh write it down this
563:16 - first and then you can change the
563:18 - directory and from on that particular
563:20 - directory you can launch the vs code got
563:23 - it now if you not able to do it by using
563:25 - this command line so by using uh by
563:28 - using the UI also you can do the same
563:30 - thing so for that uh just uh go inside
563:33 - your directory and here create a new
563:35 - folder so create a new folder and then
563:38 - do the right click and check with the
563:40 - show more option and here you will find
563:42 - out option for launching this vs code so
563:46 - by using this uh GUI also you can do a
563:49 - same thing and by using the command prom
563:51 - also you can do a same thing so I took
563:53 - this command promt approach and here you
563:55 - can see I'm able to launch my VSS code
563:59 - inside this particular folder so if you
564:02 - are done till here so please do let me
564:04 - know in the chat please uh tell me guys
564:07 - if uh you are done till here
564:09 - tell me first have you opened your vs
564:13 - code in a folder if you did it then
564:15 - please write it on the chat
564:31 - yes yeah I'm waiting for 1 minute so
564:34 - until you can open
564:38 - it
564:53 - yeah you can use the pyam
564:56 - also uh not an issue with that py Cham
564:59 - will also work any ID so here I'm using
565:01 - this vs
565:04 - code okay so I think uh now everyone is
565:08 - done so so let's start with a further
565:11 - step so after opening this vs code so F
565:13 - the first thing uh the first thing which
565:15 - you need to do you need to initialize
565:17 - the git so here guys uh what you need to
565:20 - do you need to initialize the git so uh
565:22 - here see we have a uh like a various
565:25 - option here once you will click on this
565:26 - drop- down so here you will find out of
565:29 - various option like Power Cell G bash
565:31 - command prom Ubuntu Kali so in your case
565:34 - it there might be only G bash command
565:36 - prompt or Powershell but in my case here
565:39 - you will find here you can see I have a
565:41 - different different terminal right but
565:42 - maybe in your case you just have this
565:44 - git bash and command prom that's that's
565:46 - all fine right so either you can work
565:48 - with this G bash or you can work with
565:50 - the command prom but don't work with
565:51 - this poers shell because otherwise
565:53 - unnecessarily you will get uh uh errors
565:55 - and all so I won't recommend you to uh
565:58 - work with this poers shell and all so if
566:00 - you want to work uh with the like with
566:03 - the terminal so here either use this git
566:06 - bash or this command Pro don't select
566:08 - this Powershell so here I'm using this
566:10 - git bash so here I can easily run my uh
566:14 - like Linux command also so yes uh if you
566:18 - don't want to use this git bash so you
566:20 - can use this command prom also that is
566:22 - also fine now guys here uh you'll find
566:24 - out that okay so this is what this is my
566:27 - G bash now uh here if you are not able
566:29 - to see the base environment so for that
566:32 - what you need to do so just try to click
566:34 - on this View and go with the command
566:36 - pellet so here you need to go uh you
566:38 - need to click on The View and click on
566:40 - the command PL and then select python
566:43 - interpreter so here you will find out
566:45 - various interpreter so you need to
566:47 - select this base interpreter and after
566:49 - that you need to relaunch this git bash
566:51 - so in that case uh if if you are not
566:54 - getting that base environment in your uh
566:57 - G bad so after uh like following this
567:00 - step uh definitely you will be able to
567:02 - see that so here now you can see I have
567:05 - a Bas environment on my good bash now uh
567:07 - let me uh let me run the further thing
567:10 - so the first thing what you need to do
567:12 - over here like so the first thing you
567:14 - need to initialize the git right so
567:16 - inside this directory you need to
567:18 - initialize the git so for initializing
567:21 - the git I just need to write it down a
567:23 - simple command that is what that is git
567:25 - in it so by using this particular
567:27 - command I can initialize the git in my
567:29 - current folder in my local folder so now
567:32 - this local folder will be treated as a
567:34 - local repository and then I can uh I can
567:38 - upload this same folder on my uh GitHub
567:42 - and yes like that's going to be my
567:45 - central representing so GitHub is going
567:46 - to my central repository and as of now
567:49 - if I'm going to initialize the git in my
567:51 - local folder so this is what this is my
567:52 - local repository each and every thing
567:55 - each and every track actually I'm going
567:56 - to keep it keep over here itself in my
567:59 - local folder so that uh like the entire
568:02 - data you will find out inside the dogit
568:04 - folder I will show you that so here you
568:06 - need to write it down this git in it so
568:08 - once you will write down this g in it uh
568:10 - so you will be able to initialize the
568:11 - git inside this particular folder okay
568:15 - now uh here you can create a file so
568:17 - here I'm going to create my readme file
568:19 - so r e a d MD so
568:23 - readme.md so it's going to be a markdown
568:25 - file MD means what it's be it's it's a
568:28 - markdown file so here uh guys you can
568:30 - see I created my markdown file right now
568:34 - uh if I want to publish see as of now
568:36 - see if you will look into this
568:37 - particular folder so let me reveal it
568:39 - inside the file explorer so just try to
568:41 - click uh do the right click on this file
568:43 - and reveal in the file explorer so here
568:46 - you will find out this dogit and here
568:49 - you will find out each and every
568:51 - information so because of this dogit
568:53 - folder actually uh this a local folder
568:56 - is being treated as a local repository
568:58 - now here you will find out each and
569:00 - every metadata so regarding your commits
569:02 - and all so whatever codes you are going
569:04 - to upload whatever like changes you are
569:06 - going to made and all right whatever uh
569:09 - changes you are going to commit and add
569:11 - so each and every metadata you will find
569:13 - out inside this dogit folder and why we
569:17 - use this uh git guys tell me we use this
569:19 - git for the code versioning got it I
569:22 - think uh you have a basic idea about the
569:24 - git so I'm not going into the depth of
569:27 - this git and all as of I'm just like
569:29 - giving you the uh the high level
569:31 - overview that's it now here uh you can
569:34 - see I have create I have initialized the
569:36 - git and here you can see this do git
569:38 - folder inside my uh dogit folder inside
569:41 - my local repository so is it fine to all
569:44 - of you I think yes now what I can do
569:47 - here so here I can publish the branch so
569:49 - I can publish the this local repository
569:52 - to my GitHub so for that what you can do
569:54 - see you can use this uh terminal also
569:58 - and here this vs code has given you the
570:00 - GUI option so just click on that just
570:02 - click on this particular option and here
570:05 - you will find out uh the various thing
570:08 - right so uh here you will find out the
570:11 - various options and all now let me show
570:13 - you step by step so the first thing what
570:15 - you need to do so first you need to add
570:17 - your file so for adding the file you
570:19 - just need to click on this plus icon so
570:22 - uh if you want to add the file uh so for
570:25 - that you need to click on this plus icon
570:27 - and after that uh like you need to uh
570:29 - write it on the message so you write
570:31 - down now that first you run this git in
570:33 - it and then you run this git ad git ad
570:36 - and the file name so I'm doing the same
570:38 - thing over here so by using this plus
570:40 - icon I'm adding this particular file
570:42 - right so uh in my uh like staging area
570:46 - right so and then I will do the commit
570:48 - after writing a message so here I'm
570:49 - writing down writing the message uh this
570:51 - is my first commit so here uh my
570:54 - messages this is my first commit now
570:57 - after writing the message what I will do
570:59 - I will commit it after committing is uh
571:02 - after committing uh it okay so it will
571:04 - ask to me would you like to publish this
571:06 - Branch so I would say yes I would I want
571:08 - to publish this particular Branch so
571:10 - here it is asking to me how you would
571:13 - like to publish it so whether uh as a
571:15 - private repository or as a public
571:17 - repository is going to publish over the
571:19 - GitHub actually so here it is asking to
571:22 - me how You' like to publish it whether
571:24 - as a private repository or as a public
571:26 - repository so as of now I'm going to
571:28 - publish publish this particular Branch
571:30 - as a public repository so you can click
571:32 - on this public repository and yes it
571:35 - will publish a branch so it is uploading
571:37 - all the file here you can see and then
571:40 - it will give you this a particular popup
571:42 - so here it is telling you that please
571:44 - sign in with your browser so once I will
571:46 - uh click on this uh sign in with your
571:48 - browser so yes it is uh doing that and
571:53 - uh just wait it is publishing the branch
571:57 - so it has given me uh this particular
572:01 - page now let let me authorize it so here
572:04 - I need to click on this confirm and
572:07 - after that guys you can can see
572:08 - authentication succeed so now uh my
572:12 - branch is uh published let me show you
572:15 - that so here you can see you can open it
572:18 - and this is guys this is my Branch okay
572:21 - so I published this branch on my GitHub
572:23 - so I hope this thing is uh clear to all
572:26 - of you and you are able to publish your
572:29 - branch yes or no guys tell me are you
572:33 - able to publish your branch um just a
572:37 - second great so now let me give you this
572:39 - particular link and so that whatever
572:42 - code and all I'm going to write it down
572:44 - so directly you can copy and paste from
572:46 - here itself from my git so let me give
572:49 - you this uh particular uh link uh so
572:53 - that you can copy each and everything
572:55 - from here itself just a second so did
572:58 - you get it please uh do let me know in
573:01 - the chat if you got my
573:03 - code tell me guys fast sorry if you got
573:06 - if you got my link then uh please do let
573:08 - me know in the chat again I'm pasting uh
573:11 - this particular link so this is my
573:13 - GitHub link
573:17 - guys yes please do confirm if you got my
573:21 - GitHub I given you the GitHub
573:33 - guys yes or no I am waiting for a reply
573:42 - please check it check with the popup so
573:44 - first you need to sign in through the
573:45 - browser and then only you will be able
573:48 - to log in if you're not able to follow
573:50 - this GUI approach uh in that case uh
573:53 - what you can do so you can uh like uh
573:57 - push it through the command line
574:07 - also
574:11 - yeah if you are not able to log in so
574:12 - through this uh command line you can uh
574:15 - configure the username and the uh like
574:18 - email ID so for that there is a like
574:21 - command so let me show you that
574:22 - particular Command right just a second
574:25 - so what I can do I can show you over
574:27 - here itself uh so you can search over
574:29 - the Google how to configure how to
574:33 - configure get uh username so you can
574:38 - search over the Google and then you will
574:40 - get a command so let me give you those
574:42 - particular command if you are not able
574:44 - to uh sign in but please make sure that
574:46 - if you're getting the popup then then
574:48 - directly you can sign in but if you're
574:50 - getting any sort of error right so for
574:52 - that there is a command so get config
574:54 - hyphen global hyph iph global user.name
574:58 - and here you need to pass your username
575:01 - so like whatever username you have so
575:03 - you just need to pass your username and
575:05 - then you need to pass the you need to
575:07 - configure the email also so okay so here
575:10 - uh for the username and in a similar way
575:12 - you need to configure the uh you need to
575:15 - configure the email so let me give you
575:17 - this uh two command now here let me
575:20 - write it down that you need to write it
575:22 - down your your
575:24 - username
575:27 - your user
575:30 - name and here is a command guys so first
575:33 - try to configure your username and here
575:35 - again I'm giving you the same command
575:37 - along with the username you can
575:39 - configure your email also so let me
575:42 - write it on the email and in the double
575:45 - code actually you need to pass your
575:47 - email so here your email ID so guys uh
575:52 - run this two commands on your uh on your
575:55 - uh command line actually and then you
575:57 - will be able to sign in from here itself
576:00 - got it yes or no till here uh everything
576:03 - is fine everything is clear I given you
576:06 - the GitHub Link in the chat so so um you
576:08 - can click on that and you can uh like
576:11 - you can check with my repository each
576:12 - and everything I'm going to update over
576:14 - there itself so that uh you can copy and
576:17 - paste the code directly from there now
576:19 - guys uh here uh if you're not able to
576:21 - find out uh if you're not able to click
576:23 - on this link so you can search uh with
576:26 - my username also so or over the Google
576:29 - you can write it down s Savita GitHub
576:31 - you will get the GitHub directly it will
576:32 - give you the link link of the GitHub and
576:35 - this repository is a public repository
576:37 - so Direct you can go through with my
576:39 - repository and you will find out this
576:41 - particular project got
576:43 - it great yes uh from the same terminal
576:46 - you need to configure your username and
576:49 - email ID okay now here we have published
576:53 - uh this code as a uh like to my GitHub
576:57 - right this this particular repository
576:59 - this a local repository I publish to my
577:01 - GitHub now I need to follow few more
577:03 - step for setting up my environment so
577:06 - the next thing what I need to do here I
577:08 - need to create my environment because
577:10 - I'm not going to work in my base
577:12 - environment and I'm going to create a
577:14 - virtual environment over here okay so
577:17 - for creating a virtual environment there
577:19 - is very a simple command so let me write
577:21 - it down on that command so cond condu
577:24 - create condu create hyphen P okay hyphen
577:29 - p and here you need to write it on the
577:31 - environment name so here my environment
577:33 - name is going to be en EnV en EnV and
577:36 - then you can write down the python
577:38 - version python is equal to 3.8 so I'm
577:41 - using over here 3.8 and then hyphen y so
577:44 - this is my command uh which I'm going to
577:46 - run and by using this particular command
577:49 - I can create the environment in a
577:51 - current directory itself in a current
577:53 - repository so here you can see this is
577:56 - what this is my environment uh which is
577:58 - being created so just wait for some time
578:00 - it will take uh few second let it create
578:04 - so my environment name is what my
578:06 - environment name is ENB
578:08 - now here my environment is getting
578:11 - created and it is done now after that
578:14 - what I need to do guys so here I need to
578:16 - activate my environment so for
578:17 - activating the environment you need to
578:19 - write it down Source activate if you are
578:21 - using this git terminal so in that case
578:23 - instead of this cond you can write down
578:25 - this Source because sometimes this cond
578:28 - gives issue so I'm not going with this
578:30 - cond here so I'm using this source of
578:32 - over here so you need to write it down
578:34 - the source activate activate and here
578:37 - Dot dot means current directory and from
578:39 - this current directory there is a folder
578:41 - folder name is environment e andv right
578:44 - so here you can see I'm able to activate
578:47 - my environment and here you can see this
578:49 - is what this is my virtual environment
578:51 - got it now let me clear it first of all
578:54 - so here now you can see it is giving me
578:56 - a uh like uh it is giving me a how it is
578:59 - giving me so many files uh for adding
579:01 - right so U like here it is giving me
579:04 - more than 5,000 file but I cannot like
579:07 - add all all the files I cannot like add
579:10 - all the files on my GitHub right so for
579:12 - that what I will do if I want if I don't
579:14 - want to track it if I don't want to
579:15 - track this particular file so I can U
579:17 - mention this name this EnV name in in
579:20 - the file the file name is what the file
579:21 - name is dog ignore so here let me create
579:24 - one more file in this uh particular
579:26 - directory and my file name is what my
579:29 - file name is uh dogit ignore so here I'm
579:32 - writing this uh dot get ignore uh and
579:34 - the touch command is the touch command
579:36 - for creating a file so touch dog ignore
579:40 - now here you can see I'm able to create
579:42 - this particular file this dog ignore now
579:45 - inside this file you can mention the
579:48 - name the name of whatever file which you
579:51 - don't want to drag so here if I don't
579:54 - want to track this EnV folder right if
579:57 - you don't want to track these many file
580:00 - if I don't want to upload it in my cloud
580:02 - repository right or if I don't want to
580:05 - track it uh by using this git so so you
580:07 - can mention it you can mention this
580:09 - folder name inside this dot inside this
580:13 - dog ignore file so here I'm writing EnV
580:16 - uh EnV is nothing it's a folder name now
580:19 - once I return it once I return this uh
580:21 - EnV inside this do G ignore now you can
580:24 - see it is not going to track it at all
580:27 - so here uh it is not going to track uh
580:29 - this particular folder now and it is
580:32 - giving you only it is giving me only one
580:34 - file now yes I can uh add it so here uh
580:37 - first I'm going to add this file get add
580:39 - and this file name now here I'm writing
580:42 - my message so I have added I added my
580:46 - get ignore so this is my message and
580:49 - after that what I will do after after
580:52 - this after this one I'm going to commit
580:54 - it so edit my get ignore and then do the
580:56 - commit now uh you need to click on this
580:59 - sync changes your and your changes will
581:01 - be sync so the same file you will find
581:04 - out the same file you will find out in
581:06 - my G iub also so uh let me show you
581:10 - where you will find out that let me open
581:12 - my GitHub and uh here guys here is my
581:15 - GitHub let me show you the
581:19 - repository here is my all the
581:22 - repository and this is the uh like
581:25 - folder this is my like project actually
581:27 - now see uh I just added this dot get
581:29 - ignore now see see that uh commit just
581:32 - now just now I committed uh this
581:35 - particular file and here you can see my
581:37 - dotg ignore now once you will open it so
581:40 - here you will find out the folder name
581:41 - so the folder name is what EnV so I
581:44 - don't want to track this file throughout
581:46 - my process right so I uh if I don't want
581:49 - to track this file at all so yes uh for
581:52 - that I will mention it inside my dog
581:54 - ignore file got it now uh till here I
581:58 - think everything is fine everything is
582:00 - clear and I hope you are of you are able
582:03 - to follow me till here so please do let
582:07 - me know in the chat guys if uh uh
582:10 - everything is clear everything is fine
582:11 - till here what about 3.9 yes you can use
582:14 - 3.9 3.10 as well but don't use 3.11 3.12
582:18 - or 3.13 till 3.9 and 10 it's fine but
582:22 - please make sure that uh uh please make
582:26 - sure that you are going to use the same
582:27 - version which I am using uh so you won't
582:30 - face any sort of a issue any you won't
582:33 - get any sort of error uh during the
582:35 - implementation got it
582:38 - yeah so if it is done then uh please do
582:41 - let me know guys please write it on the
582:43 - chat and uh please hit the like button
582:45 - if you are liking the session
582:51 - then done can I get a quick confirmation
582:54 - in the
583:06 - chat
583:14 - great so I think uh now everyone is done
583:17 - so here I have created my environment
583:20 - now guys what you need to do so after
583:22 - that you need to create your
583:23 - requirement. txt so inside the
583:25 - requirement. txt I'm going to mention
583:27 - the entire requirement right so for
583:30 - creating a requir txt so from here also
583:34 - you can create by using this particular
583:36 - icon other you can use the same command
583:39 - same a touch command by using that
583:41 - command also you can create the require.
583:43 - txt in a current folder in a current
583:46 - repository now uh for creating a requir
583:48 - txt so I'm using this particular icon
583:51 - and here I'm writing requirement R Qi r
583:55 - m m n ts. txt now in this a particular
584:00 - file I'm going to mention all the
584:02 - requirement whatever requirement I'm
584:05 - having regarding this project right so
584:08 - I'm mentioning all the requirement
584:10 - inside this require. txt so guys uh let
584:13 - me copy and paste all the requirement or
584:16 - whatever is there all I'm going to write
584:18 - it down here itself so the first thing
584:20 - which I'm going to use uh in my project
584:22 - that's going to be a open a so I'm using
584:25 - the open a API and for that this open a
584:28 - package is required already I shown you
584:30 - how to use openi API how to install this
584:33 - particular package because earlier we
584:35 - also we have created the environment
584:37 - and there also we have installed this
584:39 - open AI if you have attended my previous
584:41 - session then definitely you must be
584:43 - aware about this particular thing now
584:46 - here uh there's a open a now the second
584:48 - thing which I need to uh install in my
584:51 - local environment in my current virtual
584:53 - environment that's going to be a len CH
584:55 - so here guys let me write down the Lang
584:57 - gen so you need to install the langen CH
584:59 - in your current environment first thing
585:01 - is open Ai and the second thing is what
585:03 - the second thing is the Len chain the
585:05 - third one uh which I'm going to write it
585:07 - down over here that's going to be a
585:08 - stream L because here I'm going to
585:10 - create a API by using this stream l so
585:13 - here I'm going to like install the
585:16 - stream lit in my local uh like
585:19 - environment in my current virtual
585:21 - environment the second thing which I'm
585:23 - going to be installed over here uh
585:25 - that's going to be a python hy. ENB so I
585:29 - will tell you what is the use of this
585:31 - particular U like uh uh this particular
585:34 - package python hyon do EnV so I'm going
585:38 - to install this uh python hy. EnV
585:41 - package and I will tell you what is a
585:44 - use of this particular package and apart
585:46 - from that I'm going to use I'm going to
585:48 - download one more package that is going
585:50 - to be a pi PDF so Pi PDF two so these
585:54 - many thing I'm going to be install in my
585:57 - current virtual environment okay and
586:00 - apart from that I'm going to create
586:02 - couple of more folder right couple of
586:04 - more folder I'm going to create in my
586:07 - local repository in my local folder so
586:10 - uh couple of more uh files and folder
586:12 - not only folder files also so here uh uh
586:15 - requ txt is done now I'm going to create
586:18 - one more file the file is going to be
586:20 - setup uh setup uh setup.py file now why
586:25 - we use this setup.py file we use the
586:27 - setup.py file for installing a local
586:30 - package local package in my virtual
586:33 - environment if I want to install the
586:36 - local package in my virtual environment
586:38 - for that we use the setup.py file got it
586:42 - so I created the setup.py file I created
586:44 - the re. txt now let me create a one more
586:48 - file so here I'm going to create so not
586:50 - file actually I'm going to create one
586:52 - folder here my folder name is going to
586:54 - be SRC SRC means what SRC means source
586:57 - code now inside the SRC I'm going to
587:00 - create a one more folder and the folder
587:02 - name is going to be so first of all let
587:04 - me create a file inside this SRC the
587:06 - file file name is going to be dot uh
587:09 - sorry underscore
587:11 - inore dopy so here inside this SRC
587:14 - folder I'm going to create init file
587:17 - okay init file I will tell you why we
587:19 - create this init file inside the a
587:21 - folder what is the requirement of that
587:23 - and uh each and everything I will
587:25 - explain you don't worry so here uh you
587:27 - can see I've created this init file and
587:29 - inside this inside this SRC folder
587:31 - itself I'm going to create one more
587:33 - folder the folder name is going to be
587:35 - McQ itself so m McQ generator and this
587:38 - is what this is my project so McQ
587:41 - generator so this is what guys this McQ
587:44 - generator is nothing it's my folder and
587:46 - inside this also I'm going to create one
587:48 - init file so here let me create the init
587:51 - file inside uh this folder also so init
587:57 - init.py so what I did guys tell me so
588:00 - here if you will look into this uh if
588:02 - you will uh let me reveal it inside the
588:04 - file explorer and let me show you that
588:07 - what I did so here uh just look into the
588:10 - SRC folder so inside this SRC folder I
588:13 - created two things first I created this
588:15 - init file and the second one I created
588:18 - the McQ
588:19 - generator folder and whatever source
588:22 - code whatever source code I'm going to
588:24 - write it down throughout my project so
588:26 - I'm I will be writing down here
588:28 - itself apart from The jupyter Notebook
588:32 - so each and every line of code modular
588:34 - coding I will be doing over here itself
588:36 - inside my McQ generator folder got it
588:41 - now here uh what I did I created this
588:43 - init file underscore uncore inore ncore
588:46 - now what is the requirement of this init
588:48 - file why I did it because see if I let's
588:51 - say uh like here I want to consider this
588:55 - folder this folder as a package as a
588:57 - local package right this folder actually
589:00 - I want to consider as a package now what
589:02 - is the meaning of the package so the
589:04 - package is nothing it's a it's a folder
589:06 - itself folder which is containing a
589:09 - multiple python file and inside the
589:11 - python file you have a code you have a
589:13 - code like a classes functions and all
589:16 - right so you have a folder inside the
589:18 - folder you have a file and inside the
589:20 - file you have written a code right so
589:23 - now guys see uh let's say if you're
589:24 - installing pandas if you're installing
589:27 - numai if you're installing maybe open a
589:29 - or let's say if you're installing langen
589:31 - so what is this tell me it's nothing
589:33 - it's a full it's a package itself it's a
589:35 - package now and package means what
589:36 - package package nothing it's a folder
589:38 - right folder is what F the package is
589:40 - equal to folder right folder itself is
589:43 - called a package now inside the package
589:45 - or inside the folder what you will find
589:47 - out inside that you'll be having a
589:48 - multiple python files right and inside
589:51 - those python file you uh someone has
589:53 - written a code uh in terms of function
589:55 - and classes and that is what uh that
589:57 - only you are going to use right so this
590:01 - uh lenen this open this pandas napai
590:05 - someone already created it and they have
590:06 - uploaded over the pii repository and
590:08 - from there itself you are going to
590:10 - install it inside your project but here
590:12 - this McQ generator actually it is your
590:15 - local package where you are going to
590:17 - create a multiple folder mul multiple
590:19 - python file and uh if you want to
590:22 - treated if you want to treat this folder
590:25 - as a package so for that there's a
590:26 - convention from the python side you will
590:28 - have to mention this init file inside
590:30 - the folder right so here my folder is
590:33 - what my folder name is SRC SRC means
590:35 - what it's a short form of the source
590:37 - code SRC now this SRC actually I want to
590:40 - treat as my local package so there is a
590:43 - convention from the python side you need
590:45 - to mention this init file or you need to
590:46 - create this init file inside this folder
590:50 - then only it will be treated as a local
590:53 - package I think the idea is clear now so
590:56 - by using the setup.py file by using this
590:59 - setup.py file I'm installing this local
591:02 - package in my current virtual
591:04 - environment got it I think now each and
591:07 - everything is clear to all of you now
591:09 - let me back to my code so here is what
591:12 - here is my code so I created couple of a
591:15 - folder couple of file now guys uh let me
591:18 - create one more file uh like one more
591:21 - folder over here and the folder name is
591:23 - going to be experiment so here I'm going
591:25 - to be create one more folder and the
591:28 - folder name is going to be experiment
591:30 - and inside this particular folder I'm
591:33 - going to create my Jupiter notebook I'm
591:36 - going to create my ipb file okay so for
591:39 - creating ipb file inside this particular
591:42 - folder so you can click on this folder
591:43 - and click on this file icon and then you
591:46 - can write down your name so here I can
591:49 - uh write down the name any any name I
591:51 - can write it down here let's say McQ dot
591:55 - ipnb uh do
591:58 - ipnb so what is the meaning of this
592:00 - ipynb so ipynb means nothing uh I python
592:04 - uh notebook okay that's the full form of
592:06 - this IP YB now here you can see this is
592:09 - what this is my jupyter notebook now
592:10 - whatever experiments uh whatever experim
592:13 - experiments will be there throughout
592:15 - this project so I'm going to do my
592:17 - entire experiment over here in my
592:19 - Jupiter notebook and then I will convert
592:22 - into an end code into my end to end
592:24 - pipeline got it now here uh the first
592:27 - thing what you need to do so you need to
592:29 - select the kernel so just click on this
592:31 - select kernel and then click on this
592:33 - python environment then you will get all
592:35 - the python environment so this is your
592:37 - current virtual environment so this this
592:40 - the this interpreter which you can see
592:41 - over here the first place which is a
592:43 - recommended one so this is from your
592:45 - current virtual environment from the EnV
592:47 - itself here you can see EnV python.exe
592:50 - so here I'm going to select the same
592:52 - kernel so here I have selected this
592:54 - particular kernel now you can see uh I'm
592:57 - done with everything now I just need to
593:00 - uh I just need to like uh install the
593:03 - recom txt I will start by writing the
593:06 - code so let me give you this each and
593:08 - every file and folder so for that I just
593:11 - need to add it from here itself so I'm
593:13 - going to add all the files and all over
593:17 - here I think it is done now I will write
593:20 - it on my uh like message so my message
593:23 - is structure updated so here is what
593:26 - here's my message guys now let me commit
593:29 - it so structure s u c Tru structure
593:33 - updated now I have written my message
593:35 - after adding all the file
593:37 - now once I will do the commit and it
593:39 - will ask to my sync it will it will ask
593:41 - to me would you like to sync changes so
593:44 - yes I want to do it now I will click on
593:46 - okay so as soon as I will click on okay
593:49 - you will find out every file and folder
593:51 - in my repository itself so now let me
593:54 - show you uh every file and folder uh so
593:58 - here guys you can see I have a
594:00 - experiment folder now inside that there
594:02 - is my file ipv file that's what this
594:05 - this this file this particular file I'm
594:07 - going to use for my entire experiments
594:10 - and all and here you will find out my
594:12 - SRC folder inside the SRC folder you
594:14 - will find out the init file and one more
594:16 - folder that is what that the McQ
594:18 - generator and then you will find out
594:20 - this setup.py also so here I have the
594:23 - setup.py as of now you won't be able to
594:26 - find out any sort of a code over here
594:28 - but don't worry I will keep it uh inside
594:30 - my setup.py file and here you can see my
594:33 - require. txt so here I have mentioned
594:35 - all the requirements got it now let me
594:39 - uh give you this link to all of you so
594:42 - I'm pasting this link inside the chat
594:44 - and if you're not able to click on that
594:46 - so you can search over the Google let me
594:48 - search in front of you only so just go
594:51 - through the Google and search Sun Savita
594:55 - GitHub so once you will search it uh
594:57 - then automatically you will get a GitHub
594:59 - link just go through with the GitHub
595:00 - link and here click on the repository so
595:03 - here is a repository click on the
595:05 - repository and the Very first project
595:07 - this one McQ generator uh so just click
595:10 - on this uh this particular project and I
595:12 - have kept each and everything over here
595:14 - itself inside one folder so if you are
595:17 - done till here then please do let me
595:19 - know in the
595:24 - chat yes in my previous class I shown
595:26 - you how to use hugging pH API Hub don't
595:30 - worry uh after this project I will use
595:33 - the open source model only I w't going
595:35 - to use any
595:36 - uh like any model from the openi itself
595:39 - but yeah in today's project in the very
595:41 - first project I'm going to use the openi
595:43 - API along with the Len chain got
595:51 - it tell me guys uh is it fine to all of
595:56 - you are you able to create an
596:01 - environment and uh did you publish
596:05 - it
596:14 - have you created a environment did you
596:16 - created a GitHub um and sorry did you
596:19 - initialize the a git basically and did
596:21 - you publish your repository if
596:23 - everything is done then uh please do let
596:25 - me know guys I will uh move with a
596:27 - further step so please uh write on the
596:30 - chat if uh you are done till here then I
596:33 - will proceed uh with the further
596:37 - commands don't worry I will give you all
596:39 - the thing all the commands and all in
596:41 - our documented format so you won't face
596:44 - any such issues at all or in a single uh
596:49 - like go you can run like each and
596:51 - everything don't worry I will give you
596:52 - that first of all tell me uh if you are
596:54 - able to do along with uh if you are able
596:57 - to do till here if you are able to do
596:59 - these many thing then uh please give me
597:01 - a quick confirmation or if you are
597:02 - comfortable till here please do let me
597:05 - know
597:26 - fine so I think uh we can proceed now so
597:30 - uh here I have created uh you can see uh
597:33 - I created uh many files and folder now
597:36 - let me open this setup. py5 okay so here
597:39 - I have opened my setup.py file and here
597:42 - I'm going to write it down uh some sort
597:44 - of a code so what I can do let me copy
597:47 - the code uh there is only just one
597:49 - function and here I pasted the code got
597:52 - it now uh just look into the code so
597:55 - what I have written over here so here I
597:57 - have imported one uh statement uh the
598:01 - statement is what the statement is a
598:03 - find package so from setup tool I'm
598:05 - going to import the find package and
598:08 - here is what here is my setup here's my
598:10 - method setup method now here I have
598:12 - mentioned couple of thing uh so I'm
598:15 - calling this particular method setup a
598:16 - method and uh I have mentioned uh some
598:19 - parameters so the first parameter is a
598:21 - name so here I'm going to write down my
598:24 - here I'm going to write down the name of
598:26 - the package now here is a version
598:28 - version of the package now here is the
598:30 - author author is a sunny sun Savita
598:33 - author email sunny. Savita a and here is
598:37 - install requirement so these are the
598:38 - package which is like required okay now
598:41 - here is a package so find package so
598:43 - once uh see uh this find package
598:46 - actually this this particular method
598:47 - only it is responsible for finding out
598:49 - the local package for from your local
598:53 - directory so wherever uh it is able to
598:56 - find out this dot init file wherever it
598:59 - is able to find out this dot init file
599:01 - it will consider that folder as a
599:05 - package got it now uh here you can see
599:09 - so I have imported this thing find
599:11 - package setup uh find package find
599:14 - package and setup method and I have
599:15 - written all like these many thing over
599:17 - here right so this is the like name of
599:20 - my package uh which I have written over
599:23 - here right each and everything is clear
599:24 - each and everything F now see guys if
599:27 - you want to install this package so for
599:31 - that there's a command the command is
599:33 - PIP install package name right I think
599:36 - you all agree so if you want to install
599:38 - this particular package open a load Lang
599:41 - Chen stream late python python. EnV P
599:45 - PDF so for that there is a command the
599:48 - command is PIP install and package name
599:50 - if you want to install this re. txt so
599:53 - for that there is a command the command
599:55 - name is what the command name is PIP
599:57 - install hyr re. txt right but if you
600:01 - want to install this a local package
600:04 - into your current virtual environment so
600:06 - uh how we can do that so for that also
600:09 - we have a command the command is what
600:11 - the command is directly you can install
600:13 - the setup.py file you can write it down
600:16 - python setup.py install so in that case
600:20 - it will install or it will download all
600:22 - the current package from your folder
600:24 - into the virtual environment got it
600:28 - that's the first way the second way is
600:30 - what so here you can write it down in
600:31 - the requir of txc itself you can write
600:33 - it down hyph e do
600:36 - right so uh if you are writing this hyph
600:39 - e dot so in that case it will search all
600:43 - the local package all the local package
600:46 - into your current directory into your uh
600:48 - current folder and it will download or
600:51 - it will install it inside your virtual
600:53 - environment again I'm repeating see if
600:55 - you want to install this particular
600:57 - package so for that there is a command
600:59 - pip install re. TX Pap install package
601:02 - name if you want to install all the
601:04 - package by using the re. TX XT so there
601:06 - is a command pip install hyphen r. txt
601:09 - got it now but see let's say if you want
601:11 - to install this local package into your
601:14 - virtual environment so how you can do
601:16 - that so for that you have two ways the
601:19 - first one python setup.py install if you
601:22 - running this command so definitely you
601:24 - will be able to install it the second
601:26 - one is what the second one is you can
601:28 - mention this hyphen e dot inside your
601:30 - record. txt so automatically it will
601:33 - search this it will search out the
601:35 - packages into your current folder into
601:38 - your current repository and it will
601:40 - execute the setup.py in backend got it
601:44 - great now what I'm going to do here I'm
601:46 - going to be install this require. txt
601:49 - and so for first of all let me show you
601:51 - that what all packages we have inside
601:53 - the current virtual environment so if I
601:55 - will write it on the PIP list uh so here
601:58 - you will find out that we just have this
602:00 - three packages three to four packages
602:02 - into my current virtual environment how
602:05 - many packages this guys three to four
602:06 - packages only right which comes uh by uh
602:09 - which is a by default only which comes
602:11 - uh along with the environment itself
602:13 - whenever we are going to create an
602:14 - environment now if I want to install all
602:17 - these packages into my current virtual
602:19 - environment so how we can do that so uh
602:22 - if I want to like run this re. txt so
602:24 - how we can do that so for that there is
602:26 - a command let me write down the command
602:28 - pip install hyr requirement. txt so pip
602:34 - install hyphen R re txt so once I will
602:37 - hit enter so here you can see my all the
602:39 - packages is getting installed into my
602:42 - current environment so just wait for
602:44 - some time uh it is getting installed and
602:47 - uh it will take some time uh tell me
602:50 - guys are you doing a with
602:53 - me yes you can use it uh if you want to
602:56 - make a mini project so definitely you
602:58 - can use it and even you can create it uh
603:01 - here itself and you can showcase as a
603:03 - mini
603:04 - project tomorrow we are going to deploy
603:07 - it also after creating a web API and
603:09 - then uh by using the advanced concept we
603:12 - are going to create one more application
603:15 - so how's the session so far uh did you
603:17 - like the
603:26 - session tell me guys uh did you like the
603:29 - session did you like the U like
603:34 - content
603:46 - if you're liking the session then please
603:48 - hit the like
604:04 - button
604:09 - yeah still it is installing so it will
604:11 - take some time I'll let it
604:34 - install
604:45 - yes you can go through with my GitHub
604:46 - link so here is my GitHub link just wait
604:48 - I'm giving you
605:04 - that
605:22 - still it is downloading
605:25 - uh I think we should wait
605:34 - more
605:48 - yeah I think now it is done so uh first
605:51 - of all let me clear the screen and uh
605:54 - here uh you will find out that it has
605:57 - created one folder uh the folder name is
606:00 - what McQ
606:02 - generator. eggy info so so it has
606:06 - created one folder and this folder
606:08 - actually uh it is having the entire
606:11 - information regarding your local package
606:13 - so you can visit and you can check with
606:15 - the different different files over here
606:17 - so this is the package information
606:19 - metadata version this one this is the P
606:22 - package version right this is the
606:24 - package name author is sunny and author
606:26 - email ID reir txt so these are are these
606:30 - all are the requirements actually right
606:32 - along with the packages now you will
606:33 - find out all the like details inside
606:36 - this particular folder the folder name
606:38 - is what McQ generator. ayen info it has
606:43 - created a various file inside that which
606:45 - is keeping all the or which is uh like
606:48 - uh keeping all the like meta information
606:51 - regarding your project got it I hope uh
606:55 - this thing is clear to all of you now uh
606:58 - what I can do uh first of all let me
607:00 - close all the files from here now let me
607:03 - open my app IP VV file and here what I'm
607:07 - going to do here I'm going to here I'm
607:09 - going to like uh run
607:13 - my uh like import statement so what I
607:16 - can do I can run import OS so here I'm
607:19 - going to write import OS import Json
607:23 - import Os Os means what opening system
607:26 - and here I'm writing import Json import
607:30 - Json now here I writing import pandas as
607:34 - PD pandas as PD and here let's say I'm
607:38 - writing import Trace bag so these are a
607:41 - few uh uh like a few packages basically
607:46 - which I imported over here now if I want
607:48 - to run it now if I want to run this
607:50 - particular cell so for that I just need
607:52 - to press shift plus enter right just
607:55 - press shift plus enter and you will be
607:57 - able to run it now as soon as you will
608:00 - run it it will ask you would you like to
608:01 - install the IPI kernel yes I want to
608:04 - install it because without that I won't
608:06 - be able to execute this particular
608:09 - notebook so here you need to click on
608:11 - the install and my IPython kernel ipy
608:14 - kernel is getting installed guys so it
608:17 - will take uh some time so let it install
608:19 - and then I will explain you the further
608:21 - thing further
608:24 - concept I given you the GitHub Link in
608:27 - the chat uh you can search over the
608:30 - GitHub uh sorry you can search over the
608:32 - Google s with the GitHub and then you
608:34 - will get the GitHub link my GitHub link
608:36 - and check with the very first repository
608:38 - very first project that is the McQ
608:39 - generator itself the project name the
608:42 - folder name is same McQ generator here
608:44 - you can see this one McQ generator just
608:46 - search over the Google Sun Savita
608:50 - GitHub so here you can see my ipy kernel
608:54 - is getting installed so let it install
608:56 - and after that I will write it on my
608:58 - further code and uh let I will show you
609:01 - uh further concept as well uh regarding
609:04 - this um and entire project
609:34 - okay
610:07 - yeah so now it is done and here you can
610:09 - see uh we are able to import this a
610:13 - particular statement import Os Os means
610:15 - operating system Json pandas and
610:18 - traceback also now guys here what you
610:21 - need to do the next uh import statement
610:24 - which I'm going to write it down over
610:25 - here which is going to be a opena itself
610:28 - so here I'm going to use the Len chain
610:31 - and by using the Len chain I'm going to
610:33 - import this chat over open API right
610:36 - because I want to access the open API
610:39 - and by using this particular method only
610:42 - I'll be able to access the open a API
610:44 - now let me run it so it's the same
610:46 - method it's the same method which I have
610:48 - shown you in my previous classes so
610:51 - there I was using the lenin. llm opena
610:54 - now in the recent version in the updated
610:56 - version they have given you one more
610:58 - method it's a similar one only it's
611:00 - updated one and which is doing the same
611:02 - thing uh like like the previous one like
611:05 - the open a method and the method name is
611:07 - what the method name is chat open AI so
611:10 - yes uh we are able to import this method
611:13 - and now what I need to do so uh actually
611:16 - we this is a this is not a method this
611:17 - is a class so here what I'm going to do
611:19 - I'm going to create a object of this
611:21 - particular class now so for that let me
611:23 - copy it and let me paste it over here so
611:26 - this is going to my llm so by using this
611:29 - particular uh method itself I will be
611:31 - able to call my open API and I will be
611:34 - able to collect the llm model inside my
611:37 - llm variable right so for that I need to
611:40 - mention couple of uh couple of parameter
611:43 - so here I'm going to mention few
611:45 - parameter let me do it over here so
611:47 - these are the parameter guys which I
611:49 - have mentioned over here so the first
611:51 - parameter is going to be open a API key
611:54 - and here basically I need to mention the
611:56 - key key of the open a open API now after
612:00 - that uh there is a model name so here
612:03 - I'm going to use gpt3 .5 turbo model and
612:06 - then uh I I I have created one more
612:09 - parameter I I'm going to write down one
612:11 - more parameter that is going to be a
612:12 - temperature you know what is the meaning
612:14 - of temperature so here I'm going to set
612:15 - the value 0.5 so between 0 to two you
612:18 - can mention any value of the temperature
612:21 - so what is the meaning of that the
612:23 - meaning is nothing meaning is very very
612:24 - simple you are going to like you want to
612:27 - create a model if you are mentioning uh
612:29 - like if you're mentioning the value near
612:31 - to two right so the range is from 0 to
612:35 - two if you are mentioning the value near
612:36 - to two this will be more creative if the
612:38 - value is will be near to zero so the
612:40 - model will be less creative it will give
612:42 - you the state forward answer that's it
612:44 - now here guys this key will be required
612:48 - this open AI key will be required how we
612:51 - can get the open key I shown you how to
612:54 - generate open key in my previous classes
612:57 - right again I'm not going to show you
612:58 - that now here actually I'm going to
613:01 - collect my openi key but this time I'm
613:04 - not going to paste it directly over here
613:06 - instead of that what I'm going to do I'm
613:09 - going to use my OS module so here what
613:12 - I'm going to write it down I'm going to
613:13 - write it down this a particular uh
613:16 - method I'm going to call this os. get
613:19 - environment method that uh os. get
613:22 - environment key method so here I'm going
613:24 - to call this os. getv and here uh this
613:29 - is what this is my environment variable
613:32 - so what I can do guys I can create uh
613:34 - environment variable I can create one
613:36 - environment variable into my uh Windows
613:39 - environment variable and I can read it I
613:42 - can read my key from there okay I can
613:45 - read my key from there the second way I
613:47 - can export it temporarily right so here
613:50 - I can U on my uh terminal itself I can
613:54 - write it down
613:56 - export and here I can mention this a
613:58 - variable name open API key and I can
614:01 - pass the value in that case also I will
614:03 - be able to read it the third Third Way
614:05 - is there the Third Way is like you can
614:07 - create your EnV file right you can
614:10 - create your local environment file and
614:12 - there inside that particular file
614:14 - whatever a variable is required whatever
614:16 - important variable is there you can keep
614:18 - it over there itself right the first one
614:20 - is a global approach uh Global means
614:22 - what so here if you are going to search
614:24 - environment variable in your windows
614:26 - search box so you will get the uh you
614:29 - will get the uh environment variable all
614:32 - the list of the environment variable
614:34 - here you can see right so you will get
614:36 - the list of the environment variable
614:38 - this one right this one now here you can
614:40 - see I I created one key and I keept it
614:43 - over here so from there also I can read
614:45 - it from there also I can read it by
614:47 - writing a same thing I I just need to
614:49 - mention the key the key name over here
614:52 - the second way the second way is a
614:53 - temporary way temporary way means you
614:55 - can export the key over here Itself by
614:58 - using the export command you just need
615:00 - to write down the export and here you
615:02 - can mention the variable name and you
615:03 - can pass the value of that particular
615:06 - variable that's the second way now the
615:08 - Third Way is what here you can create
615:11 - EnV file so EnV file in your local
615:14 - repository itself so no need to create
615:17 - any sort of a variable in your
615:18 - environment variable here itself inside
615:21 - this EnV file itself you can keep your
615:24 - all the variable all your secret
615:26 - variable and by using the same command
615:29 - you can read it so that is the third way
615:31 - so I'm going to select the third way the
615:33 - third option so here I'm going to create
615:35 - the EnV file okay so EnV file uh so this
615:40 - is what this my EnV file and inside this
615:42 - EnV file I'm going to keep my key so I'm
615:46 - going to write down the key value and
615:48 - the variable name is going to be a same
615:50 - so let me copy the variable from here
615:52 - the variable is going to be open AI API
615:55 - key and let me keep the variable over
615:57 - here and here I I'm going to write down
615:59 - the value of this particular key so in
616:02 - the double code actually I'm going to
616:03 - write down the value
616:05 - so let me paste my key over here I
616:07 - already generated it uh I believe you
616:10 - know how to generate the key so let me
616:12 - copy and paste it over here so this is
616:14 - what guys this is my key which I already
616:16 - generated now let me open my file and
616:19 - here what I'm going to do I'm going to
616:21 - read my value the value of this key so
616:25 - you can treat this EnV file as your
616:28 - local environment right so which you
616:31 - have created inside the folder itself
616:33 - and there you can keep your all the
616:35 - secret variable right so now if I'm
616:37 - going to run this OS os. G EnV now if I
616:40 - will run this particular command now if
616:42 - I'm going to print the key so here you
616:44 - will find out my key value so here guys
616:47 - uh here is what here is my key open a
616:50 - key now let me show you and here it is
616:53 - giving me none uh let me run it again
616:55 - why it is not going to why it is not
616:58 - getting it now let me show you it is
617:01 - none wait guys let me restart the
617:03 - terminal it happens in this vs code
617:06 - actually sometimes I have seen but okay
617:09 - so fine I forgot to do one thing uh why
617:12 - I'm getting this none why I'm getting
617:15 - this none because I need to load this
617:18 - environment first all right so I need to
617:20 - load this environment first and for that
617:23 - uh I will have to import something see I
617:25 - already written one module
617:28 - python.
617:30 - EnV right so here I have written the
617:32 - module python hyen do T EnV let me show
617:35 - you this module so here uh let me open
617:39 - the Pi Pi first of all and here I can
617:41 - show you the module uh just a
617:45 - second Pi Pi now let me show you this
617:48 - particular module python hy. EnV uh see
617:53 - python. uh EnV reads key value pair from
617:57 - a EnV file and can set them as a
618:00 - environment variable right so it helps
618:03 - in a development M or application uh
618:06 - following the 12 Factor principle so
618:08 - here you can read everything about it if
618:10 - your application takes configuration
618:12 - from the environment variable it's a 12
618:14 - Factor application launching it in a
618:16 - development it's not very practical
618:18 - because you have to set those
618:19 - environment variable yourself means you
618:21 - will have to set the environment
618:22 - variable in your local system um okay if
618:25 - you don't want to do it you can create
618:27 - the EnV folder in your local so that
618:29 - will be your local environment file
618:31 - local environment file itself which will
618:33 - be available inside your local uh like
618:36 - reposit itself in your local folder
618:38 - itself got it now here the first thing
618:41 - uh see first you need to import this
618:43 - thing this from. EnV import load. EnV
618:47 - and then you can you have to call this
618:50 - uh particular method so what I'm going
618:52 - to do here so I'm doing a same thing uh
618:55 - where is my vs code here is my vs code
618:57 - I'm going to do a same thing just a
618:59 - second I'm going to load it uh I'm going
619:01 - to load this uh EnV
619:04 - so here from EnV this is my EnV file
619:08 - from EnV I'm going to import a load. EnV
619:12 - and here is what here is my method so as
619:14 - soon as I will run it so here I will be
619:16 - able to load my all the values from this
619:19 - EnV file now let me run it h let's see
619:22 - whe whether I'm getting the value or not
619:24 - so it is saying this OS is not defined
619:26 - so first of all let me import the OS
619:28 - this is also fine this is also fine and
619:32 - now each and everything is fine
619:34 - now what I can do now I can call it and
619:37 - let's see whether I'm getting my key or
619:39 - not now see guys I'm able to get my key
619:41 - from from my EnV file so here is my EnV
619:45 - file and from here what I'm getting I'm
619:47 - getting my key right now let me keep
619:50 - this EnV in my do getting so I can push
619:54 - my changes in my ga in that case you
619:57 - won't get this uh key actually you you
619:59 - will just get like uh the other file so
620:03 - here I'm writing do EnV and once I
620:06 - return it now it you can see it is not
620:09 - going to track it uh at all so now uh
620:13 - you want you will find out that there is
620:15 - no such color anything and now what I
620:18 - can do I can give you all the files and
620:20 - all other files basically so let me
620:23 - click on the
620:25 - plus
620:26 - yeah now let me commit it so here I'm
620:30 - going to write it down of file updated
620:35 - file
620:37 - update and let me commit it and sync
620:42 - changes now click on okay and here guys
620:46 - you will find out my entire code Let me
620:49 - refresh it now
620:52 - and yes that is the entire code so I
620:57 - think
620:59 - uh you got the code over here set the
621:03 - print
621:12 - yeah so here is a key let me remove it
621:14 - from here just a
621:32 - second
621:58 - yeah now it
621:59 - gone so tell me guys uh are you able to
622:03 - follow till here here uh did you get the
622:05 - entire code the code which I shared with
622:07 - all of
622:10 - you please uh do let me know in the chat
622:13 - if you got the code
622:16 - then here I kept the entire code uh in
622:20 - my GitHub
622:21 - itself yes uh yes or no please uh write
622:27 - it down the chat guys please uh do let
622:29 - me know just search over the Google s
622:32 - Savita GitHub and there you will find
622:34 - out this McQ generator repository in my
622:36 - repository section and here is the
622:38 - entire
622:59 - code if you are done till here then
623:02 - please uh give me a confirmation so I
623:04 - will proceed with a further uh further
623:32 - concept
623:39 - done done done
623:44 - great fine so now let's start with the
623:48 - implementation so till here actually I
623:50 - just shown you the uh I just shown you
623:53 - the environment setup and all now we are
623:56 - ready for implementing the
623:58 - project okay so within uh this uh within
624:02 - this one hour actually I just shown you
624:03 - the entire setup now this is the onetime
624:05 - job I set up my entire environment now
624:09 - let's start with the Practical uh now
624:11 - let's start with the experiments and all
624:13 - and in tomorrow's session I will create
624:15 - uh the I will create the Modular One
624:17 - modular project and there I will create
624:19 - the steam allet application also and
624:21 - finally we'll try to deploy it now here
624:25 - uh you can see uh now each and
624:27 - everything is done let's try to call
624:28 - this a chat open a method and let's see
624:31 - we are able to access the llm on l so
624:34 - here you can see it is running and now
624:36 - it is done so if you will look into this
624:38 - llm llm now here you can see we are able
624:41 - to do it we are able to call it now here
624:45 - let's try to run the further code now we
624:48 - are going to use all the concept the
624:51 - entire concept whatever we have learned
624:53 - throughout the community session right
624:56 - throughout the throughout this community
624:57 - session in our open in the lch so we we
625:01 - are going to use those entire concept
625:03 - over here now uh for that basically what
625:06 - I'm going to do step by step I'm going
625:08 - to write it down each and everything so
625:10 - first of all I am going to import each
625:12 - and everything in a single shot right so
625:15 - here uh you can see I have imported all
625:17 - the statement so this Trace back and all
625:20 - I'm going to remove it from here which I
625:21 - already did it this is also I already
625:23 - imported now let me remove this also and
625:26 - here uh just chat open a also I already
625:29 - imported now uh here this open a prompt
625:32 - template l CH sequential and this get
625:36 - open a call back this is very important
625:39 - uh this is very important class which I
625:41 - imported over here uh I will show you
625:43 - the name I will show you the use of this
625:45 - particular class this C openi call back
625:48 - in a very detailed way because it's
625:49 - going to be very very important right so
625:52 - far I haven't discussed about it I
625:53 - discussed about the sequential chain I
625:55 - discussed about the llm chain I discuss
625:57 - about the promt template but I I haven't
625:59 - discussed about this get openi call back
626:02 - so now let me import import all the
626:04 - statements over here so you can see we
626:07 - are able to import it and yeah it is
626:10 - done now we already created a object of
626:13 - this chat open Ai and we are able to get
626:16 - my llm by using this open AI API till
626:20 - here I think everything is fine
626:22 - everything is clear now let's move to
626:24 - the next one now just tell me guys if we
626:26 - are talking about so here what I can do
626:29 - let me open my pen and let me ask a few
626:33 - questions to all of you so here uh what
626:35 - I'm doing uh just a
626:44 - second yeah so here uh just uh let me
626:48 - ask a few question so let's say we have
626:50 - imported the llm means uh we are able to
626:53 - access my llm this uh GPD model by using
626:56 - this uh open AI or API by using this L
626:59 - chain framework now to this llm what I
627:02 - will do what I will pass to this llm
627:03 - tell me so to llm to this particular llm
627:06 - I will pass my uh prompt right I will I
627:09 - will pass my input prom so here actually
627:12 - what I will have to do I will have to
627:14 - design my input promt right what I will
627:17 - have to do guys tell me I will have to
627:18 - design my input prompt and here as a
627:22 - output what I will get tell me as a
627:24 - output also I will get a prompt right so
627:26 - here what I will have to do I will have
627:29 - to design my input and output prom right
627:33 - so so whatever my whatever will my input
627:35 - so that particular prompt and here
627:37 - whatever will be my output that a
627:39 - particular prompt got it now let's try
627:41 - to design my input prompt and let's try
627:43 - to design the response as well then in
627:45 - which format I will get the response so
627:48 - here initially I clarified this thing
627:51 - the project is going to be a McQ
627:53 - generator right I am going to generate
627:56 - McQ McQ right whatever topic whatever uh
628:00 - subject I will give to my uh GPT model
628:03 - so So based on that particular subject
628:05 - based on that particular uh like based
628:07 - on that particular text is going to
628:10 - generate a McQ so let's say I'm giving
628:12 - my paragraph I'm I'm giving one
628:14 - paragraph to my GPT model So based on
628:17 - that particular paragraph let's say I
628:19 - given a paragraph related to our data
628:21 - science uh okay I I I given one a PDF
628:24 - file or text file or whatever file to my
628:26 - GPT model so in that inside that like
628:28 - you have a paragraphs you have a data So
628:30 - based on that data is going to generate
628:33 - a mcqs right so let me do one thing so
628:36 - here uh first of all let me design my
628:38 - prompt so here what I'm going to do guys
628:40 - I'm going to design my prompt by using
628:42 - this a prompt template I think you
628:44 - already know about the prompt template
628:46 - in my previous class I already clarify
628:49 - the uh the concept of the prompt
628:51 - template if you don't know then please
628:52 - go and check with the previous session
628:54 - so here what I'm going to do guys here
628:56 - I'm going to Define my prompt template
628:58 - so just wait uh let me copy and paste
629:00 - the code because already I written this
629:03 - uh like a single single line so let me
629:05 - copy and paste and I'm going to explain
629:06 - you so here my prompt is what so here my
629:10 - prompt inside the prompt actually you
629:11 - will find out in the prompt template you
629:13 - will find out two things first is a
629:15 - input variable and the second is
629:17 - template right so here you can see as a
629:20 - template I given this particular
629:21 - variable now to this particular variable
629:23 - I have to pass some sort of a text right
629:26 - some sort of a like a template and all I
629:28 - will pass it just wait right so here is
629:30 - my template variable and I will pass my
629:32 - template over here here I'm not going to
629:34 - write it down directly here I'm going to
629:35 - pass it to my variable and that variable
629:38 - I I'm passing inside my prompt template
629:40 - right now in an input variable you can
629:42 - see we have a couple of we have a couple
629:45 - of variable we have couple of parameter
629:47 - the first one is text the second one is
629:49 - a number the third one is a subject the
629:52 - fourth one is a tone and the fifth one
629:55 - is a response J so we have a five
629:59 - variable inside my input variable in my
630:02 - previous classes uh I shown you this
630:04 - prompt template along with the uh simple
630:06 - input variable along with the one input
630:08 - variable right now here inside this one
630:10 - I have written five input variable and
630:13 - here I'm going to Define my template now
630:15 - let's see what will be my template so
630:17 - from here basically I'm going to copy
630:19 - the template and let me paste it over
630:21 - here so I'm saying to my chat GPT so I'm
630:24 - saying to my chat GPT that uh you are
630:27 - expert McQ maker right so I'm giving my
630:30 - a text so on whatever text I want to
630:33 - generate an McQ I'm passing a text over
630:36 - here right and I'm saying to my chat GPT
630:38 - that you are an expert McQ maker given
630:41 - the abob text so whatever text we have
630:43 - given to you it's your job by using this
630:46 - particular text it's your job to create
630:48 - a quiz of number so how many quiz you
630:51 - want to create so five quiz six quiz
630:53 - seven quiz eight quiz you can pass a
630:55 - number over here so 5 six seven quiz
630:57 - eight quiz so you can pass the number
630:59 - and here uh you need to create a five
631:01 - multiple let's say I'm writing number is
631:03 - equal to five so five multiple choice
631:05 - question for the subject now whatever
631:07 - subject we are going to pass over here
631:09 - in tone so tone means what tone actually
631:12 - it is defining a difficulty level so
631:14 - here if tone is simple so it is going to
631:16 - generate a five simple McQ question if
631:19 - tone is uh intermediate so it is going
631:22 - to generate five intermediate question
631:24 - if tone is difficult it's going to
631:26 - generate five difficult in five
631:29 - difficult McQ question got it now here
631:32 - I'm saying make sure the question are
631:34 - not repeated and check all the question
631:37 - to be confirming the text as well so
631:39 - each and everything I'm telling to my
631:41 - GPD right so make sure to format your
631:44 - response like so here actually I have to
631:46 - for I have to pass the format also here
631:49 - I'm going to pass here I have to pass
631:51 - the format also like in which format you
631:53 - have to generate a quiz now let me give
631:56 - you the format now let me show you the
631:57 - format so uh which format actually I
632:00 - have designed over here so here what I'm
632:02 - going to do I'm giving you the format
632:04 - the format basically which uh I have
632:06 - designed so let me show you the response
632:09 - format now guys this is the response
632:11 - format just just see over here see so
632:14 - response or it's my response format so
632:16 - here I'm saying uh like there is my McQ
632:19 - multiple here I have written first okay
632:21 - this my first mean like it's a number
632:23 - itself that's it now here I'm seeing McQ
632:25 - multiple choice question now here is a
632:27 - option that uh you have a four Option 1
632:30 - 2 3 4 and here basically I will be
632:33 - getting my correct answer so it is this
632:35 - one this one actually this is my first
632:37 - McQ along with the number along with a
632:40 - question along with the number this is
632:42 - my first McQ first McQ now here will be
632:45 - my McQ now here will be my all the
632:47 - options and here will be my correct
632:49 - answer right so this is my response
632:52 - format and here is my template basically
632:55 - which I'm passing to my GPT model and
632:58 - here uh I'm going to create my prompt
633:01 - template that's it by using this
633:02 - particular template and these are the
633:05 - these are the variable which user is
633:09 - going to pass right which user is going
633:11 - to pass these are the variable now let
633:14 - me do one thing let me run it and here
633:17 - you can see we are able to create a like
633:19 - temp we have like written a template and
633:22 - this is what this is my prompt template
633:24 - which I created that's it I think this
633:26 - is fine now here uh yes once it is done
633:30 - uh like uh my template and all basically
633:32 - it will be created that is fine now
633:34 - after that what I'm going to do I'm
633:35 - going to create the chain right I think
633:38 - you already know about the chain llm
633:40 - chain I I explain you the concept of the
633:42 - llm chain that why we use llm chain we
633:45 - use llm chain for connecting a several
633:48 - component so here as of now I just have
633:51 - two component first is llm and the
633:53 - second is prompt so I'm going to connect
633:55 - both component all together and for that
633:58 - I'm going to use llm chain so let's try
634:01 - to use the llm chain and and here I have
634:03 - already written the code let me copy and
634:05 - paste it over here and so this is what
634:08 - guys this is my uh like this is my uh
634:11 - like llm chain so here I'm passing my
634:13 - llm model with whatever model I took by
634:15 - using the open API and here is what here
634:18 - is my prompt so prompt is what so quiz
634:21 - generation prompt so the prompt which I
634:23 - have created by using this particular
634:25 - template and by using this particular
634:28 - response right in this format basically
634:30 - I want a response now this is what guys
634:33 - this is the llm chain all the concept
634:36 - see whatever I have we have learned so
634:38 - far I'm going to use all those concept
634:41 - for creating this a particular project
634:43 - right so so at least you can understand
634:46 - that where we are using uh like those
634:49 - Concept in a real time right so here is
634:52 - what here is my question now let me run
634:53 - it and here I have created my question
634:56 - that is fine now guys just tell me uh
634:59 - here uh I'm creating my quiz right so
635:04 - here I'm creating my quiz now here
635:06 - actually see I created a quiz but this
635:09 - quiz is correct or not the basically in
635:12 - the at the end you can see in the format
635:14 - I have written this correct answer I
635:16 - want a correct answer from it so after
635:18 - analyzing a quiz actually I want a
635:21 - correct answer so for that also I have
635:23 - defined one more template now let me
635:26 - show you that template so what I did
635:28 - actually let me show you the template
635:31 - two which I have created uh so here I
635:34 - have created the second template now in
635:36 - the second template you will find out uh
635:38 - just a second let me copy all the like
635:42 - thing over here and see this is what
635:45 - guys this is my second template now here
635:47 - I'm seeing here I'm saying actually uh
635:50 - you are an expert English grammarian and
635:53 - writer I'm telling to my chat jpd I'm
635:55 - telling mypd actually so given a
635:57 - multiple choice quiz for this particular
635:59 - subject right this particular subject
636:02 - now you need to evaluate the complexity
636:05 - of the question and give a complexity
636:07 - analysis of the quiz right give that
636:10 - complexity analysis of the quiz only use
636:13 - at Max 50 words for complexity if the
636:16 - quiz is not at for the quantitive and
636:19 - the analytic ability of the student
636:22 - update the quiz update the quiz question
636:24 - which needs to be changed and change the
636:26 - tone such as uh such that it perfectly
636:29 - fits to the student ability so here I
636:32 - have written so here actually see here
636:34 - I'm passing my quiz whatever quiz
636:36 - basically I'm generating so in this
636:38 - second template I have written that uh I
636:41 - have written the like prompt regarding
636:43 - to the evaluation regarding to the quiz
636:46 - evaluation whatever quiz I am going to
636:48 - generate right first I will generate and
636:51 - then I will evaluate it here in the
636:53 - second prompt now let me run it and here
636:56 - I'm going to create my one more chain so
636:59 - here I'm going to create uh so here
637:01 - basically uh before create cre a chain
637:03 - basically uh let me create just a second
637:06 - so here uh what I'm going to do I'm
637:07 - going to create my template so here in
637:10 - the template you will find out only two
637:11 - variable first is subject and the second
637:13 - is quiz this two variable it is coming
637:16 - from the user side I will show you how
637:18 - like it is coming from the user side and
637:20 - how user will be passing once we'll be
637:22 - creating a end to end application got it
637:25 - now here we have a quiz evaluation
637:27 - prompt and this is what this is my
637:29 - second prompt and now what I will do
637:30 - regarding this prompt also I will create
637:33 - my chain right so here uh here is my
637:36 - quiz chain now I'm going to create one
637:37 - more chain that's going to be a quiz
637:40 - evaluation chain so let me uh like uh
637:43 - copy this particular code step by step I
637:46 - have written each and everything and
637:47 - that is what I'm going to show you so
637:49 - here is what guys here is my review
637:51 - chain right so in this one I'm passing
637:53 - my llm I'm passing my quiz Evolution
637:55 - prompt and here output key is What so
637:58 - whatever output I'm getting as a review
638:00 - so here I'm going to collect it inside
638:02 - this particular variable and verbos is
638:04 - equal to True means what means whatever
638:07 - ex means during the execution whatever
638:09 - is happening now each and everything I
638:11 - will be able to find out on my screen
638:14 - itself that's the meaning of verbos is
638:16 - equal to two that's it now here if I'm
638:17 - running this review a chain so I have
638:20 - created two chain now now after creating
638:23 - this th I have created First Chain quiz
638:25 - chain I created second chain review
638:27 - chain now I'm going to connect both
638:30 - chain right by using sequential chain so
638:34 - the same concept I taught you in my
638:36 - previous session so first I created one
638:38 - chain where I'm going to add two
638:40 - component llm and my uh prompt I have
638:43 - created second chain and now I'm going
638:45 - to collect both chain right both Chain
638:47 - by using the sequential uh by using the
638:50 - simple sequential chain now here what
638:52 - I'm going to do so here already I have
638:54 - imported this thing if you look into my
638:56 - import statement so I have already
638:58 - imported this sequential chain now let
639:01 - me create a object object of this
639:03 - sequential chain and then uh I'm going
639:06 - to write it down the both name over here
639:08 - so here what I'm going to do so let me
639:11 - uh create object of this sequential
639:14 - chain now so here guys you can see we
639:16 - have a sequential chain and to this
639:19 - sequential chain I'm passing the quiz
639:20 - chain I'm generating a quiz and I'm
639:23 - passing to my review chain right so from
639:26 - here I'm generating a quiz and I'm
639:27 - passing to my review chain and these all
639:30 - are my input variable and these all are
639:32 - my output variable and verbos is equal
639:34 - to True right clear so here I'm going to
639:38 - create a object of this same sequential
639:41 - chain I hope till here everything is
639:43 - fine everything is clear to all of you
639:46 - please do let me know I use the uh
639:49 - previous Concepts only I haven't I
639:52 - haven't taught you anything new uh I use
639:55 - the previous concept whatever I taught
639:57 - you in my previous classes so please do
640:00 - let me know if this uh part is clear to
640:02 - all of you yes or
640:04 - no it's very easy very simple don't
640:07 - worry at the end I will revise all the
640:09 - concepts uh whatever I'm using here
640:12 - whatever I'm writing over here but first
640:13 - tell me is it clear or not this
640:23 - one if you can write it down the chat I
640:25 - think that would be great you can hit
640:27 - the like button you can let me know in
640:29 - the chat so please do it guys uh I'm
640:33 - waiting for a
640:39 - reply because after uh this one the
640:41 - climax will come and in that like we are
640:44 - going to create a quizz and all whatever
640:47 - is
641:01 - there clear clear clear yes or
641:19 - no yes saan your understanding is
641:21 - correct first combining two template
641:23 - using llm chain and then two H chains we
641:26 - are going to combine by using the
641:28 - sequential chain
641:31 - okay
641:56 - okay now uh I think till here everything
641:58 - is fine everything is clear now let's
642:00 - see how we are going to gener a quiz
642:02 - from here after giving this many of
642:05 - things after doing this many of things
642:08 - so we are able to uh we are able to like
642:13 - uh here you can see we are able to
642:15 - create a sequential chain now the next
642:17 - thing is what here actually what I want
642:20 - guys tell me I want a text I want a data
642:23 - so if you have a data in PDF you can
642:25 - load the PDF if you have a data in txt
642:28 - file you can load the txt file right if
642:31 - you have data in some other file you can
642:33 - load the data from there from anywhere
642:35 - right so first you will have to provide
642:37 - a text you will have to provide a data
642:39 - on top of that data you are going to
642:43 - create or you are going to generate a
642:45 - quiz right so let me do one thing here
642:48 - I'm going to create uh I'm going to
642:51 - create one file the file name is going
642:53 - to be uh wait I'm going to create one
642:56 - file the file name is going to be
642:58 - data.txt so data.txt
643:02 - now what I'm going to do here uh I'm
643:04 - going to open my Google and from there
643:07 - uh I'm going to copy and paste some sort
643:09 - of a text so let's say I'm searching
643:11 - about the machine learning machine
643:15 - learning machine learning so here I'm
643:18 - going to search about the machine
643:19 - learning now here uh is what here is my
643:23 - machine learning now from here what I'm
643:25 - going to do so here I'm going to take
643:28 - all the data for this one right so I
643:30 - took this particular data I'm copy I'm
643:33 - going to copy it and let me paste it
643:35 - over here where I'm going to paste I'm
643:37 - going to paste in my data.txt so this is
643:40 - the complete data which I have pasted
643:41 - over here you can check it you can
643:43 - reveal this file in your folder so click
643:45 - on reveal in file explorer you will find
643:48 - out this particular file uh this
643:50 - data.txt right just open it and here is
643:54 - your data which I copy and paste it from
643:56 - the uh like Google itself from the
643:58 - Wikipedia right great now let me close
644:01 - it and here here is what here is your
644:03 - data now do one thing let's uh do one
644:05 - thing so let's try to read this
644:07 - particular data so here what I'm going
644:09 - to do so here uh let me open my file
644:13 - ipynb file and here I'm going to read
644:16 - this particular data so for reading a
644:18 - data actually we have a we have a like a
644:22 - code so let me write it down the code
644:24 - over here so I'm writing over here you
644:26 - need to open this file in a read mode
644:29 - and just read the data in this
644:30 - particular variable now here I need to
644:32 - provide the file path so for providing a
644:34 - file path let me write it down here file
644:37 - underscore path and here uh R means what
644:40 - R means read it and there I'm giving my
644:43 - absolute path so here I'm passing the
644:46 - complete path of the file so this is the
644:48 - file path guys which I have given or
644:51 - which I have written over here now let
644:52 - me run it and let me check with the file
644:54 - path that I got it or not so here what I
644:57 - can do I can uh check with the file
645:00 - underscore path now let me run it and
645:04 - see guys this is what this is my file
645:05 - path now I'm uh running this particular
645:08 - code and here you will find out inside
645:10 - the text what I got I got my data so
645:14 - here is what here inside my text you
645:15 - will find out you uh we have the entire
645:18 - data now let me print it let me keep
645:20 - this text variable inside the print
645:23 - method so see guys I got the entire data
645:26 - so whatever data I kept it inside my
645:27 - file inside my txt file so you can see
645:30 - all the data over here itself got it now
645:33 - after that what I will do see now there
645:35 - is a crucial part and there you will
645:37 - find out the new thing right and one
645:39 - more thing let me do one more thing over
645:40 - here so see I created a response I
645:43 - created a response here is what guys
645:45 - tell me here is my response now this
645:48 - response actually it's a
645:50 - dictionary this is what this is a
645:52 - dictionary right this one now over here
645:55 - if I want to convert into a Json
645:57 - serializer so for that there is a method
646:00 - json. terms and here actually I'm
646:03 - passing this dictionary now why I'm
646:05 - doing it so here if I want to serialize
646:07 - the python dictionary into a Json format
646:10 - so here U into a Json format is string
646:12 - so that's for that's why for that only
646:14 - I'm going to call this particular method
646:16 - json. dumps right so here uh I'm going
646:19 - to call this json. Dums and here you
646:21 - will be able to find out I'm going to
646:22 - convert this a particular dictionary
646:24 - this python dictionary into Json format
646:27 - his string right this is fine this is
646:29 - clear to all of you we got a text we got
646:31 - this dictionary and we got a chain now
646:35 - my final step will come into the picture
646:38 - now let me show you my final step so
646:41 - over here uh my final step is this one
646:44 - now just just be careful guys and after
646:47 - that my response will be coming and I
646:50 - will be able to generate my output so
646:53 - here guys see uh in the final response
646:56 - you will find out that we are going to
646:58 - call this get open Ai call back right
647:01 - right this is a new thing for all of you
647:03 - and here I have already imported this
647:06 - get open Ai call back if you will look
647:08 - into the import statement here a from
647:10 - blanchin do callback get open call back
647:14 - so here you will find out I'm U like
647:16 - calling a same thing I'm calling this
647:18 - get open Ai call back right now inside
647:21 - this get open a call back you will find
647:23 - out that we are going to call our
647:25 - generative evaluated generate generate
647:27 - evaluate change so this is the same
647:28 - thing basically uh the same variable
647:30 - over here you can see this one uh like
647:33 - after creating after creating this is
647:35 - the object actually generate uh generate
647:38 - evaluate chain this is what tell me this
647:39 - is the object object basically which I'm
647:41 - keeping over here sequential chain is a
647:43 - class right where I'm passing this
647:44 - particular argument and this is what
647:46 - this is my object this one generate
647:48 - evaluate chain now I'm calling this
647:49 - particular object over here this one
647:51 - right this this particular object I'm
647:53 - calling over here this is fine this is
647:55 - fine this you are able to understand and
647:58 - here we are getting a response after
647:59 - calling but what is the meaning of this
648:01 - C open Ai call back why we are using it
648:04 - so just see over here I have written
648:06 - something over here how to set up token
648:09 - uses tracking in L chain so if you want
648:12 - to understand the token uses if you want
648:15 - to track your tokens and all input token
648:18 - output token your pricing each and
648:20 - everything each and everything you will
648:22 - get by using this get openi call bag you
648:25 - can check it by using this link which I
648:27 - kept it over here here is a
648:29 - documentation link so let me copy and
648:31 - paste it over here over the browser and
648:34 - here actually you will find out a
648:35 - complete detail about this G openi call
648:39 - back so let me show you so here is
648:41 - tracking token uses so whatever number
648:43 - of uh token you are going to use what
648:45 - will be the pricing input token number
648:48 - output token number everything you will
648:50 - get it over here by using this get openi
648:53 - call back right so just see over here we
648:55 - are going to import it we are going to
648:56 - create our llm we are going to got get
648:59 - we are going to get our llm over here
649:01 - and here we are going to call this
649:02 - invoke method and there is my result now
649:05 - if I'm going to print the CV so here you
649:07 - will get the entire detail regarding the
649:09 - token let me show you in terms of my
649:12 - code right so whatever code and all
649:14 - whatever like project I'm going to
649:16 - create regarding that now before that
649:19 - just see over here uh generate evaluate
649:23 - chain this is what this is my object now
649:26 - here if you will look into this
649:27 - particular object so we are we have a
649:29 - couple of input variable the first input
649:32 - variable is text that is the same thing
649:34 - the text itself right text you know
649:36 - right which one uh what is the text like
649:38 - whatever uh which one this text actually
649:41 - so whatever uh like uh data right we are
649:45 - passing for generating a McQ right on
649:47 - whatever data we want to generate McQ
649:49 - this this this takes actually now here
649:51 - is a number how many McQ you want to
649:54 - generate subject tone simple Simplicity
649:57 - hard intermediate and here is what here
650:00 - is a uh like request response so I will
650:03 - have to mention everything over here
650:05 - inside this variable so json. dumps
650:08 - already we did it text we already did it
650:10 - now let me Define this number subject
650:13 - and tone so here let me take it as a a
650:16 - variable so here guys you will see that
650:19 - we have a number we have a subject and
650:21 - we have a tone so number how many uh
650:23 - quiz you want to generate I want to
650:25 - generate five quiz here subject let's
650:28 - say subject is machine learning let me
650:29 - change the subject I'm going to keep as
650:31 - a machine learning so here the subject
650:33 - name is machine learning now uh here
650:37 - Stone actually tone let's say it's a
650:39 - simple one simple McQ I want just like a
650:42 - simple McQ now if I will uh like run it
650:45 - so here I have initialized my variable
650:47 - now guys if I will run this one now you
650:50 - will find out that everything I'm going
650:53 - to get in my response itself so let me
650:55 - run it and see so it is running and guys
650:58 - over here you can see this is still it
651:02 - is running and it will take some time
651:04 - because it is evaluating each and
651:06 - everything in back end whatever template
651:08 - whatever prompts I have given and based
651:10 - on that it will generate a response it
651:13 - will generate a McQ so just wait for
651:15 - some time and it is working working
651:28 - working yeah now it is done guys see we
651:31 - we got a response and inside this
651:32 - response I have everything but before
651:35 - showing you the response let me show you
651:37 - something over here so here what I'm
651:39 - going to do here I'm going to show you
651:40 - the number of tokens number of tokens uh
651:43 - input tokens output tokens and the
651:46 - complete cost right so here what I'm
651:48 - going to do let me copy the code uh
651:51 - which I already written and it's a
651:52 - simple like lines and all I'm just
651:54 - copying pasting because I don't want to
651:57 - waste the time okay because if I'm
651:59 - writing it from scratch it it takes
652:01 - takes a time right so here uh I'm saying
652:03 - total number of tokens input token plus
652:06 - output token now here prompt token and
652:08 - prompt completion mean this is the input
652:10 - token and this is the output token and
652:12 - this is complete number of token and
652:14 - here there is a total cost now if I will
652:16 - run it guys so here you will find out
652:18 - that I this is my total number of token
652:20 - this is my input token this is my output
652:23 - token and this is the cost and it is in
652:25 - dollar so I'm able to track each and
652:27 - everything by using this uh open a call
652:30 - back getting my point now let's try to
652:33 - get a response so let's try to uh get a
652:36 - response from here uh so let's try to uh
652:39 - get a quizzes and all so first of all
652:41 - let me show you the response so if I'm
652:42 - going to print the response now so you
652:45 - will find out uh it's nothing it's the
652:47 - uh dictionary itself right so inside the
652:50 - dictionary uh you have uh different
652:52 - different key and value now in this
652:54 - dictionary you will find out one key
652:56 - quiz right so if I'm going to write it
652:58 - down here so here if I'm going to write
653:00 - it down response. response. getet quiz
653:04 - so if I'm going to write down here
653:05 - response. getet quiz now see guys here
653:08 - I'm able to get my quiz here I'm able to
653:11 - get my quiz right so what I'm going to
653:13 - do now I'm going to keep it inside my
653:15 - variable my variable is what quiz this
653:18 - is what this is my quiz right now what
653:20 - I'm going to do here I'm going to write
653:21 - it down Json json. load right Json do
653:26 - loads and here I'm passing my quiz q i
653:29 - now once I will write down like this so
653:32 - you will find out my all the quiz so
653:34 - here this is my first quiz and it is in
653:36 - the same format it is in the same format
653:39 - the response format which I have defined
653:41 - so this is my first quiz and here is McQ
653:44 - who coined the term machine learning so
653:47 - Donald have Arthur Samuel Samuel Walter
653:51 - pittz and Warren mlo right so here there
653:54 - is a correct answer now here the second
653:56 - quiz what was the earliest machine
653:58 - learning model introduced by the Arthur
654:00 - Samuel so speech recognization image
654:03 - classification so you can see guys your
654:05 - entire quiz over here whatever number I
654:08 - have given I have given five number I'm
654:10 - able to generate a five quiz from the uh
654:13 - from the GPT model by giving a correct
654:15 - prompt and by giving a correct uh like
654:18 - response format so there is uh you just
654:21 - uh required a python over here that's it
654:24 - nothing apart from that and you will be
654:26 - able to create the project a project
654:28 - according to your requirement and this
654:30 - type of project you can integrate
654:32 - everywhere let's say uh uh like in a
654:35 - dashboard itself in your dashboard you
654:36 - will find out the quizzes and the
654:38 - assignment so you can automate that
654:40 - project uh that process you can generate
654:42 - a quizzes and all from here uh right and
654:45 - then you can append it inside uh the
654:47 - dashboard and all so uh like something
654:49 - like that you can make a real-time
654:50 - connectivity I think you are getting my
654:52 - point now let's uh look into the uh let
654:55 - let's try to create a data frame by
654:57 - using this uh dictionary so for that
655:00 - what I'm going to do so here uh I'm
655:02 - going to create a data frame uh just a
655:05 - second uh first of all let me keep
655:07 - everything inside the list so for that I
655:10 - already written one code so here is the
655:12 - code guys uh here I'm going to create uh
655:15 - let me do one thing Let Me Keep It Quiz
655:17 - only so here is what here is my list and
655:20 - inside this list we have our items means
655:22 - uh my quiz and my uh basically value
655:25 - okay means my options now here actually
655:27 - I'm going to keep it in a particular
655:29 - format whatever string I'm going to to
655:31 - be collect from here I'm going to join
655:32 - in by using this pipe and here I'm going
655:35 - to append it everything now let me run
655:37 - it and you will get a better
655:39 - understanding so if I'm going to run it
655:40 - now see uh so it is giving me St Str
655:43 - object has no uh attribute
655:46 - items what is the issue over here okay
655:49 - so just wait uh let me keep it over here
655:52 - inside the quiz itself and
655:55 - now I think it is fine so just a second
656:00 - mm
656:01 - mhm yeah now is fine so if I'm going to
656:04 - show you this quiz table data now now
656:06 - you will get all the thing over here so
656:09 - yeah now I got each and everything in a
656:11 - list and see every value every option we
656:15 - are going to segregate by using this
656:17 - pipe and for that only I have written
656:18 - this code once you will go through it
656:20 - you will be getting it now I can convert
656:22 - it into a data frame so here uh let me
656:25 - convert this uh thing this particular
656:28 - thing in into a data frame so here if
656:29 - I'm going to write it down
656:31 - PD do data Frame data frame and here I'm
656:36 - going to say that okay I'm going to uh
656:40 - open the parenthesis and
656:44 - [Music]
656:45 - then yeah so here guys see this is my
656:48 - McQ means there is my question here is
656:51 - my choices there is four choices and
656:54 - here is a correct answer now let me keep
656:56 - this thing in my uh variable that is
656:59 - going to be a quiz and and now let me
657:01 - convert this uh data frame as a CSV file
657:05 - so here I'm going to convert this data
657:08 - this uh quiz actually into a CSV file so
657:10 - quiz do 2or CSV and here I can write it
657:15 - down the name and the name is going to
657:17 - be a machine learning quiz so machine uh
657:22 - machine
657:23 - learning. CSV right machine learning.
657:26 - CSV index is equal to false index is
657:29 - equal to false now if I will run it guys
657:32 - see in my current uh directory in my uh
657:36 - like current local directory you will
657:38 - find out this CSV file now let me open
657:40 - the CSV file and here you can see my
657:43 - quiz I just given the number of quiz how
657:45 - many number of quiz I want uh see uh if
657:48 - you will look into the code now now you
657:50 - will be getting that uh this this number
657:53 - actually this this thing basically which
657:54 - I will I was providing to my um like
657:57 - object this one number of quiz sub
658:00 - object and toone so this is the only
658:03 - thing which I want from my user and for
658:06 - this one only I'm going to create my web
658:09 - application as of now I shown you the
658:11 - simple implementation in the python
658:13 - notebook in ipb itself now in tomorrow's
658:16 - class what I'm going to do so here I
658:18 - have created the folder the folder name
658:19 - is what SRC folder and inside that I
658:22 - have a McQ generator now each and every
658:24 - line of code I'm going to write it down
658:27 - my py file I'm going to create a modular
658:29 - coding I I'm going to write down the
658:31 - modular coding here and then finally we
658:33 - are going to create a web API right web
658:36 - API and uh here U like yes by using the
658:40 - B API you just need to pass this
658:43 - particular value number of quiz you just
658:45 - need to pass this 3 to four value you
658:48 - need to pass the text this particular
658:49 - text you need to pass the number of
658:51 - quizzes subject and the tone that's it
658:55 - and you uh and after that once you will
658:58 - hit the button so the qu will be in your
659:01 - hand this
659:03 - one got it yes or no tell me guys so how
659:06 - is a project uh did you like this tell
659:10 - me do you like this Jupiter
659:11 - implementation yes or no tell me guys
659:18 - fast do you have any any like uh any um
659:23 - that doubts and all so please do let me
659:25 - know I will be clarify that and uh don't
659:29 - worry you won't face any sort of issue
659:31 - so whatever step I followed just
659:33 - followed those step and try to do this
659:35 - uh um this notebook implementation at
659:38 - least and tomorrow we'll convert this
659:40 - notebook implementation into an end to
659:42 - end project so let me give you this code
659:45 - now so here I can uh add it this file
659:48 - this file and this file also so I added
659:51 - this three file now let me write down
659:54 - the message all files updated updated
659:58 - okay so just a second all file
660:04 - updated and here let me commit it and
660:07 - sync the changes so now guys just check
660:11 - with the GitHub you will get the uh
660:14 - files and all right let me show you the
660:16 - GitHub now and here is my
660:27 - GitHub so guys uh just check with the G
660:31 - here you will find out the CSV file
660:33 - quizzes and all uh and here see quizzes
660:37 - Which I generated by using the GPT and
660:40 - here actually there is a ipv file where
660:43 - you'll find out the entire
660:45 - code
660:51 - okay yes it is generating a quiz from
660:53 - the text itself so let's say if you are
660:55 - giving this part let's say any different
660:57 - text so let me do one thing let me give
661:00 - the different text over
661:02 - here uh so just a second I'm going to
661:05 - generate a different text
661:07 - now uh so any topic uh uh any topic
661:11 - basically anything you can uh like
661:13 - search over here let's say you are going
661:15 - to search about the biology so
661:18 - biology uh Wikipedia so just search
661:22 - about the biology and here open
661:25 - the like Wikipedia page copy it from
661:29 - here copy it as of now and just keep it
661:32 - over here inside the text inside your
661:35 - txt file now see we'll automate this
661:37 - particular process so you don't need to
661:39 - paste it like this you just need to uh
661:41 - give your documentation to your
661:43 - streamlet application or to your flask
661:45 - application or Jango application we'll
661:47 - automate that particular process don't
661:48 - worry and even we can automate like many
661:51 - uh instead of providing this particular
661:53 - text and all right no need to provide
661:55 - this text by writing directly by writing
661:57 - the name also we can generate a quiz
661:59 - okay that is all also possible that is
662:01 - also possible as of now I'm giving my
662:03 - text and based on that see this is the
662:05 - biology text right now what I can do I
662:08 - can just need to open my uh IP VB here
662:11 - and after that I just need to load this
662:13 - text so here I'm going to load my text
662:16 - this one and I'm going to change my
662:18 - subject so instead of this machine
662:20 - learning I'm writing here
662:23 - biology right I have written biology
662:25 - over here let me run it so here I got uh
662:27 - the biology text this is the biology
662:29 - text and uh yes uh I think now
662:32 - everything is same this is fine this is
662:34 - fine now let me run it so here if I'm
662:37 - going to run it so now it is generating
662:39 - mcqs from those particular text whatever
662:42 - text I have given regarding the biology
662:43 - and all so it is taking that text and it
662:46 - is generating a uh mcqs and all so it
662:48 - will take some time let it
662:50 - run and then you can save uh this file
662:53 - over
662:54 - here so now it is done uh it is getting
662:58 - we are getting some issues
663:01 - incorrect API key
663:06 - provided okay it is saying incorrect API
663:09 - key provided I think some issues there
663:10 - with the API key but yeah the process
663:12 - will be same right I will check with the
663:13 - API key issues what is this uh now see
663:16 - guys uh I think you got my point you got
663:19 - the like concept and you got about the
663:22 - project also and today we are going to
663:25 - create in2 and one and we'll try to
663:27 - deploy it also so don't miss tomorrow's
663:29 - session tomorrow's class uh great so I
663:32 - think we can start with today's session
663:35 - uh now in today's session uh again uh
663:37 - we'll uh try to complete our project
663:39 - itself so in previous class uh we have
663:42 - started our uh end to end project uh in
663:45 - that I have explain you the uh Jupiter
663:48 - implementation so we did the entire
663:50 - project setup and after that uh we did
663:52 - the we implemented our jupyter notebook
663:55 - now in today's session we are going to
663:57 - create we are going to write it on the
663:58 - modular coding modular code and there we
664:01 - are going to create a several file and
664:04 - uh I will show you how you can create a
664:06 - different different file in a different
664:07 - different folder and then how you can
664:09 - create your streamlit application and if
664:12 - uh time will permit so definitely we'll
664:14 - try to deploy it also and for the
664:16 - deployment we're going to use
664:18 - AWS okay so uh don't worry I will write
664:22 - it down like uh each and every line in
664:24 - front of you only and uh and I will
664:26 - clarify the agenda but before that uh
664:29 - let me show you the resources and all so
664:31 - where you will find where you can find
664:33 - it out all the resources so for that uh
664:36 - let me go through with the Inon website
664:39 - and here you can search generative AI so
664:43 - just search about this generative Ai and
664:45 - there you will get the dashboard so here
664:47 - we have two dashboard one for the Hindi
664:50 - and the second for the English so just
664:52 - click on this English uh this uh this
664:54 - particular dashboard and here click on
664:56 - this go to the course so uh let's say if
664:59 - you are enrolling for first time if you
665:00 - are opening first time then it will ask
665:02 - you for the enroll uh for the enrollment
665:04 - and uh you no need to pay anything it's
665:07 - completely free so you can enroll to
665:09 - this particular dashboard and you can
665:11 - open it so let me open the dashboard so
665:14 - here is my dashboard guys uh you can see
665:16 - all the recording we have updated all
665:18 - the recording whatever thing I have
665:20 - covered so let me uh show you the
665:23 - resources as well I think day six
665:25 - recording is not available over here so
665:28 - don't worry it will be up uploaded along
665:30 - with the recording you will uh find out
665:32 - the assignment and the quizzes also and
665:35 - where you will find out the resources so
665:37 - let's check with the day five so uh here
665:40 - in this uh video right so once uh you
665:42 - will click on the video uh so here you
665:45 - will get a different different option
665:46 - related to the video so just click on
665:49 - this resource section and here you will
665:51 - find out all the resources so whatever
665:53 - thing I'm discussing in the class itself
665:56 - uh whatever uh like code and all
665:58 - whatever I'm writing here so uh I'm
666:00 - going to uh I'm going to upload each and
666:02 - everything here inside this resource
666:04 - section so from here itself from the
666:06 - resource section you can download it got
666:09 - it yes or
666:16 - no great so from here you will get the
666:20 - resources and all and yes U videos is
666:23 - available over here recorded videos is
666:25 - available over here and apart from that
666:27 - you will find out over the ion YouTube
666:29 - channel so just go through with the Inon
666:31 - YouTube channel U and there uh go inside
666:34 - the live section there you will find out
666:36 - all the recorded video so let me show
666:38 - you that so visit the Inon uh YouTube
666:41 - channel and here click on the live
666:44 - section this one so you will find out
666:46 - all the videos all the like lecture or
666:49 - the live lecture which I uh took so far
666:52 - and here is a day six lecture where I
666:54 - have started with a project so in this
666:57 - lecture till day five actually I have
666:59 - complet completed the Lin first I
667:01 - started from the introduction then I
667:03 - went to the open a and then I uh started
667:06 - with the different different concept of
667:08 - the Lang and then I move to this uh
667:10 - particular project the project uh which
667:12 - I have started that was the McQ
667:15 - generator by using open a and the Len
667:18 - chain so here uh you can see I have uh I
667:21 - shown you that how to do a complete
667:24 - project setup and even I shown you how
667:27 - you can push it over the GitHub and all
667:29 - how you can insize the gate each and
667:31 - everything I shown you over here and
667:33 - then uh I shown you the uh Jupiter
667:35 - notebook implementation so just go
667:37 - through with this particular video there
667:39 - you will find out uh like each and
667:42 - everything uh now uh what we can do we
667:44 - can start with the remaining part of the
667:46 - project so here in this uh particular
667:49 - project so we have created a several
667:52 - folder now in front of you only I'm
667:54 - going to create few more file and there
667:57 - I will be writing my code and finally
668:00 - we'll try to create a web application
668:02 - and if time will permit so definitely we
668:04 - are going to deploy it also so the
668:07 - agenda is clear to all of you yes or no
668:09 - please uh do let me know in the chat
668:11 - please do confirm in the
668:21 - chat
668:28 - yes
668:32 - how long this course is going to be so
668:34 - the course uh I I have planned two more
668:37 - end to project so I have to take few
668:40 - Advanced concept like uh Vector database
668:42 - R and few open source model and after
668:46 - that I have planned two more end to end
668:48 - project so you can assume that uh like
668:52 - more 8 to 10
668:54 - days got it so um I I will take two more
668:58 - end to end project and this is just a
668:59 - basic project actually after completing
669:01 - all the concepts and all I taught you
669:04 - this one but yeah after that I will
669:06 - complete one project along with the
669:08 - flask API and I thought one more project
669:10 - along with the vector database R concept
669:13 - and the fast
669:15 - API
669:23 - okay great so let's uh begin with the
669:26 - project and here uh what I can do
669:30 - so just a second just allow me a
669:53 - minute okay so I already given you this
669:55 - particular project and if you want this
669:57 - project uh this project actually so from
670:00 - where you can get it uh let me show you
670:02 - so this uh project already I have
670:05 - uploaded on my GitHub so just uh try to
670:07 - go through with my GitHub and there you
670:09 - will find out this particular project
670:11 - and for that what you need to do just
670:13 - open your Google and search Sunny Savita
670:16 - GitHub okay so open your Google and
670:19 - search Sunny Savita GitHub and after
670:22 - that you will find out my GitHub so just
670:24 - click on that uh click on my GitHub and
670:26 - here go inside the repository here
670:28 - inside the reposit
670:30 - and click on this very first link this
670:32 - McQ generator so just open this one and
670:35 - here you will find out this particular
670:38 - project so whatever I'm uh doing
670:39 - whatever I'm uh whatever code and all
670:42 - I'm writing I'm pushing in my this
670:44 - repository so I'm giving you this
670:45 - repository in the chat section if you
670:47 - are able to click click on it so that is
670:50 - fine otherwise you can search over the
670:52 - Google and directly you will find out
670:54 - this repository in my uh repository
670:57 - section got it so from from here itself
671:00 - you can download the project so you can
671:02 - download it or you can clone it anything
671:04 - is fine now uh let's start with the
671:07 - remaining part of the project now here
671:09 - guys see I created a couple of uh folder
671:12 - I have created couple of like files but
671:14 - let's try to uh uh do something more
671:16 - over here so as I told you this uh
671:19 - project is going to be end to end so
671:21 - here actually see I created the ipv file
671:24 - so each and every experiment I performed
671:26 - over here so I I return like some sort
671:29 - of a line of code here and then uh I
671:32 - called my openi API and then I generated
671:34 - the mcqs and all here I have stored
671:36 - inside my CSV each and everything I did
671:39 - in my previous class now if I want to
671:41 - convert this project if I want to uh
671:44 - like uh convert this project into an end
671:46 - to end project so for that uh I will
671:49 - have to create few more file over here
671:51 - so here guys if you will look into this
671:53 - SRC folder so here I have created one
671:56 - folder that is what that is an McQ
671:57 - generator now inside this McQ generator
672:00 - I'm going to create few more file so you
672:02 - can do along with me if you have
672:04 - completed till here so uh here actually
672:07 - you can see uh like uh whatever thing I
672:10 - have done in my previous session so you
672:12 - can find out each and everything over
672:13 - here if you have completed till here
672:15 - then you can proceed along with me now
672:18 - what I can do so here uh let me create a
672:21 - few file inside this McQ folder inside
672:24 - this McQ generator the first file which
672:27 - I'm going to create over here that's
672:28 - going to be a logger file so here let me
672:32 - create the logger file logger py because
672:35 - each and everything uh let's say
672:37 - whatever code I'm running and uh
672:39 - whatever thing I'm going to execute
672:41 - inside my project so I'm going to log
672:43 - each and everything so for that this
672:45 - logger file is very much important so
672:47 - here I'm going to Define my logging
672:49 - object and directly I will import this
672:51 - logging object in any other file and
672:54 - then directly I'm going to uh like save
672:57 - the logs and all so I will show you how
672:59 - to do that first of all let's try to
673:01 - create the folders so here uh let's try
673:03 - to create the files and all so here I
673:05 - have created my logger file logger dopy
673:07 - inside this McQ generator folder now
673:10 - after that you need to create one more
673:12 - file over here the file is going to be a
673:14 - utils file so here uh let me write it
673:18 - down the utils.py now what is this util
673:21 - file why we should use this utils file
673:24 - actually this utils file is a helper
673:26 - file so whatever helper function is
673:28 - there whatever helper function and
673:30 - method is there so each and everything
673:32 - I'm going to write it down over here
673:34 - itself got it so what what is the use of
673:36 - this utils file so it's a utility file
673:39 - it's a helper file so what is a what
673:41 - whatever helping function and all
673:43 - whatever I have inside my code so each
673:45 - and everything I'm going to write it
673:47 - down over here itself now uh one more
673:50 - file I'm going to create inside this
673:52 - folder inside this McQ generator and the
673:54 - file is going to be McQ generator itself
673:57 - so inside this particular file I'm going
673:59 - to write it down my entire code got it
674:02 - now here I'm going to create one file
674:04 - the file name is going to be a
674:07 - McQ generator so here is the file name
674:11 - McQ generator. py so I have created
674:14 - three file inside my McQ folder inside
674:16 - my McQ generator folder so the first
674:18 - file logger file the second file is a
674:20 - utils file and the third file McQ
674:22 - generator. py5 fine so I hope till here
674:26 - everything is fine everything is clear
674:28 - now let me create few more file now in
674:31 - the root directory itself I'm going to
674:33 - create one more file that's going to be
674:34 - a response response. Json I will tell
674:38 - you what is the use of this response.
674:40 - Json because yesterday uh in the
674:42 - previous class uh if you will uh let me
674:44 - show you this ipb itself so here I have
674:46 - written one response here you can see we
674:48 - have uh I have written this response G
674:51 - and inside this response G I have Define
674:54 - uh the response basically in which
674:55 - format uh like uh the response should be
674:58 - generated so here I have defined the
675:01 - response Json now uh the same thing I'm
675:03 - going to Define inside the Json file and
675:06 - I will tell you what is the importance
675:08 - of that so if I want to create a Json
675:10 - file so for that uh what I need to do I
675:13 - no need to do anything so here uh click
675:15 - on this new file and after that uh write
675:17 - it down here response uh response do
675:21 - Json response. Json now here you can see
675:25 - this is what this is my Json file so uh
675:29 - till now I have created four file the
675:31 - first file was the logger McQ generator
675:33 - utils.py and apart from that one more
675:36 - file that's going to be a response. Json
675:38 - and this file will be in a uh will be in
675:42 - a root directory this one response. Json
675:45 - I think till now everything is fine okay
675:47 - where I have created it uh let me check
675:51 - once I think I have created inside this
675:54 - experiment no need to worry just uh drag
675:58 - and drop here
675:59 - yeah so now I got it in my root
676:02 - directory yeah so here is what here is
676:04 - my response dojon now let me create one
676:08 - more file over here and the file is
676:09 - going to be a streamlit app so actually
676:12 - I'm going to create my web app by using
676:14 - the stream l so here I'm going to uh
676:16 - create one more file and the file is
676:18 - going to be a stream L and that two you
676:21 - need to create in a root directed itself
676:23 - in a root folder itself so here I'm
676:25 - going to write down stream s e a m
676:28 - stream lit uh
676:31 - app.py so this is what this is my file
676:33 - now let me keep this L as a small one
676:37 - yeah now it is fine so streamlit do
676:40 - streamlit app.py so these many file I
676:43 - have created and now I think it is like
676:46 - enough now what I can do I can give you
676:49 - like this complete folder structure so
676:51 - for that U like I can commit from here
676:53 - itself uh so let me add all the files
676:55 - from here I'm going to add all the
676:57 - changes whatever I have done done inside
676:59 - my code and I told you how to do that uh
677:02 - in the previous class I explain you each
677:03 - and everything regarding the git and all
677:05 - so if you will go through with my
677:06 - previous uh session so you will get to
677:08 - know the uh like you will get uh you
677:11 - will get the idea that how to like uh
677:13 - how to uh create a repository and all
677:15 - how to publish from here itself how to
677:17 - publish a public repository each and
677:19 - everything I have discussed in my
677:21 - previous session now uh here you can see
677:24 - I have added all the changes now I just
677:26 - need to commit it in my staging area and
677:29 - then I will push it in my GitHub so here
677:31 - I can write down that uh I updated
677:34 - updated the
677:36 - folder updated the folder structure so
677:41 - now what I can do I can commit it and
677:43 - here I can sync the changes and then
677:54 - okay yeah so now let me show you did I
677:56 - get all the files and all here so here
677:59 - guys you can see I got all the files
678:01 - like streamlit app streamlit app.py and
678:05 - here in the SRC you will find out this
678:07 - uh in the McQ generator you'll find out
678:09 - this McQ generator. py logger py
678:11 - utils.py so each and everything uh you
678:15 - can uh you can see over here inside my
678:18 - repository itself so I hope guys you got
678:21 - this entire code yes or no this entire
678:24 - file now again let me give you inside
678:26 - the chat uh or else what you can do you
678:29 - can search over the Google as well so
678:31 - directly you will get it tell me guys uh
678:34 - till here everything is fine uh can we
678:36 - start with the code and
678:39 - all please uh do let me know in the
678:53 - chat I given you this uh link inside the
678:56 - chat I hope uh you are able to click it
678:58 - otherwise directly check with the Google
679:00 - you will get this
679:04 - project Raab please check with my GitHub
679:07 - repository check with a just search
679:09 - about my username this s Savita Sun
679:13 - Savita GitHub and then you will get my
679:15 - GitHub and then from U from there itself
679:18 - you can download this particular
679:23 - code front end and all we are going to
679:26 - handle by using this stream lead so
679:28 - stream will handle everything we don't
679:30 - no need to like create a front end
679:32 - separately uh in the next project I will
679:35 - show you that once I will use the
679:36 - flask maybe with the fast API I will
679:39 - show you the uh front end part as well
679:41 - but here uh if I'm using this stream L
679:44 - then front end is not
679:57 - required
680:00 - yeah you can use any ID even you can use
680:02 - the U Inon lab also so from next project
680:05 - onwards we are going to use the in
680:07 - neural lab yesterday actually I did the
680:09 - entire setup in my uh local vs code only
680:12 - so that's why I'm continuing from here
680:14 - itself but uh from next project onwards
680:17 - I'm going to use the neurol lab so U I
680:20 - think uh no need to set up in your local
680:22 - uh directly you can launch the lab and
680:24 - whatever experiments and all or whatever
680:27 - project uh like you have uh you can
680:29 - create over there itself
680:49 - okay if you're getting any error
680:51 - relative to the API key then try to
680:53 - generate a new API key and don't use my
680:56 - API key okay
681:02 - because after the class anyhow I will
681:03 - delete it so yeah don't use my API key
681:07 - uh use your API key try to generate your
681:09 - own API key from the open a i shown you
681:12 - how to do that so go through the uh
681:15 - openi website and from there itself you
681:18 - can generate an openi key so if you're
681:21 - liking the session guys then please uh
681:23 - hit the like
681:27 - button and and yes I think now we can
681:31 - start with the coding so if you will
681:33 - look into the project so here I have
681:35 - created a various folder so I have
681:38 - started from this uh logger if you will
681:41 - look into this McQ generator so I've
681:44 - created a couple of file the first file
681:46 - was the logger the second file was the
681:47 - utils file and the third file was the
681:49 - McQ generator now here uh no need to
681:52 - write it down the separate code for the
681:55 - separate code for the front end and all
681:57 - this stream lit will take care of it
681:59 - this stream late will take care of it we
682:01 - can create a basic BB application just
682:04 - to test our API and all so no need to
682:06 - write it down the code for the front end
682:08 - and all now guys uh what we can do here
682:10 - so let's try to uh write it down the
682:13 - code for the logging so here I'm going
682:16 - to write down the code for the loging
682:17 - now why the uh logging is required so
682:20 - see whenever we are going to execute a
682:22 - code so in the code actually we have a
682:24 - various step we have a various files we
682:27 - have a various method function classes
682:29 - and all right and each and every
682:31 - function has been defined for the
682:32 - particular purpose so let's say uh if
682:34 - I'm going to write it down any sort of a
682:36 - function inside the utils file or maybe
682:38 - McQ generator so the function which I'm
682:40 - going to create or which I'm going to
682:42 - Define I'm going to create it for the uh
682:44 - for the like Define purpose for a
682:46 - particular purpose right so uh if I if
682:48 - you want to log that uh information like
682:51 - so let's say this a function is going to
682:53 - execute and after the execution like
682:55 - what you are getting or maybe after the
682:57 - let's say you have completed the
682:59 - execution now you want to save that
683:01 - particular information software okay I
683:03 - have completed this particular step I
683:05 - have executed this particular function
683:06 - or method so that information you can
683:09 - log somewhere and there this logging
683:11 - comes into a picture so always make sure
683:13 - whenever you are going to create any
683:15 - sort of a project uh whether you are
683:18 - doing a development code development
683:20 - machine learning related development or
683:21 - whe whether you are going to write it
683:23 - down a code in a gener project or
683:26 - anywhere this loger exception you and
683:28 - all this uh this particular files and
683:31 - folder will remain same it's a part of
683:33 - the infrastructure got it now here uh
683:36 - let me write it down the code inside
683:38 - this logger do py file so here uh let me
683:42 - import the logging first of all so here
683:44 - I'm going to write it down import import
683:47 - login now uh here I have imported the
683:50 - login then after uh I'm going to import
683:53 - the OS and the third module which I'm
683:56 - going to be import over here that's
683:57 - going to be a date time so from date
683:59 - time and here I'm going to write it down
684:02 - import date time so these three import
684:05 - statement this three statement I have
684:07 - imported the first one is a loging the
684:10 - second one is a OS and the third one is
684:12 - a date Tye now let's try to create our
684:15 - logger file so for that uh what I'm
684:17 - going to do so here I have written one
684:19 - expression now let me show you how my
684:22 - logger file will be looking like so guys
684:24 - here is my logger file here is my log
684:27 - file actually and inside this file I'm
684:30 - going to log each and every information
684:32 - right so just try to uh look into this
684:35 - particular file so here what I'm going
684:36 - to do see here I'm going to collect my
684:39 - uh the real uh date time so by using
684:42 - this date time do now I'm going to uh I
684:45 - I I will be getting the real date time
684:48 - now I'm uh calling this particular
684:49 - method St strf time so I'm formating
684:52 - this particular time whatever date and
684:54 - time which uh which we are getting U and
684:56 - this is the real date time okay okay if
684:58 - I'm going to call it um as of now right
685:00 - so let me show you you can perform each
685:02 - and every thing each and every
685:04 - experiment inside this experiment uh
685:06 - inside this uh particular notebook So
685:09 - Yesterday only I have created so you can
685:11 - create it and you can perform like
685:13 - whatever experiments you want to do
685:15 - before putting into the pipeline now
685:17 - what I can do here I can copy this uh
685:19 - code from here now let me copy it and
685:22 - let me show you that what I will be
685:23 - getting from here so this small small
685:25 - experiment you can do inside your
685:27 - Jupiter notebook now from uh so here
685:30 - actually I need to import the date time
685:32 - so from date time what I'm going to do
685:34 - I'm going to import the date time itself
685:37 - so from date time import date time now
685:41 - uh let me do one thing let me run it and
685:44 - here you will find out the uh the
685:46 - current date and time now if you want to
685:49 - formate it uh so here uh for that
685:51 - actually we have a method so you can
685:54 - call this method St strf time now let me
685:57 - call this particular method
685:58 - and then let's see what you will be
686:00 - getting over there so I'm going to copy
686:02 - it and let me paste it over here now you
686:06 - will find out that I'm getting a date
686:09 - time in a particular format so here is
686:11 - month day year Edge means are minute and
686:15 - second now what I'm going to do so this
686:18 - will be the file name this will be my
686:20 - file name and here I'm going to put do
686:22 - log so do log is what do log is a
686:25 - extension so this is going to my file
686:27 - name and with that easily I can identify
686:29 - that at which particular time I have
686:32 - executed my code getting my point so
686:35 - that's why I'm writing this name I'm
686:37 - giving this name to my log file and this
686:40 - this will be what this will be my uh
686:41 - this current uh date and time will be my
686:43 - name of the log file and what is the
686:46 - meaning of the do log do log is nothing
686:48 - it's a extension so here uh you will see
686:51 - inside this uh logger file so this is
686:53 - what this is the name of the file uh by
686:56 - using this particular Name by seeing
686:57 - this name I can easily understand that
687:00 - at at which time I have executed my
687:03 - pipeline right so according to that I
687:05 - can collect the logs now here you will
687:07 - find out this is what this is my file
687:09 - name so I created a loog file and after
687:12 - that guys what I will do so after that
687:14 - let me create the path as well so where
687:17 - I'm going to store my log so for that
687:20 - also I have written couple of line and
687:22 - this two line actually I'm using for
687:25 - saving my log so in which directory I'm
687:28 - going to save my log okay now here I'm
687:31 - going to call this method os. path.
687:34 - jooin os. getcwd means what so os. get
687:38 - CWD means get current working directory
687:42 - so as of now um in I am in this a
687:44 - particular directory let me show you so
687:46 - let me open my terminal and here you
687:48 - will find out that I'm in this a
687:51 - particular directory so I'm in C user
687:54 - Sunny McQ generator so this is what this
687:57 - is my folder name so this is my
687:58 - directory path as of now I'm working in
688:00 - this uh directory so by using this
688:04 - particular method os. get CW you will
688:07 - get the current working directory and
688:09 - here is what here you are going to write
688:12 - down this log so it is going to combine
688:14 - this both path all right it is going to
688:16 - combine this both path so in a current
688:18 - working directory you are going to
688:20 - create one more folder the folder name
688:22 - is going to be a log and this is going
688:24 - to be your path now you will pass this
688:26 - path to your make directory meth method.
688:29 - make directory so what it will do so it
688:30 - will create a folder so here is your
688:33 - file name here is your folder along with
688:36 - the path where it will be available and
688:38 - here you are going to create that
688:40 - particular folder after giving a path
688:43 - right I hope this three line is clear to
688:45 - all of you now what I can do now inside
688:48 - this folder what I will do guys tell me
688:50 - now inside this folder I will now inside
688:53 - this folder I will create my log file
688:56 - the file basically the name uh which I
688:59 - have uh like given over here which I'm
689:01 - trying to generate from here so now in
689:04 - this particular folder inside the loog
689:06 - folder I'm going to create mylog file so
689:10 - let me do uh this thing and here you can
689:12 - see os. paath join now here is what here
689:16 - is my lock path this this particular
689:18 - path lock path where uh like we have a
689:21 - lock folder this logs folder and inside
689:24 - that I'm going to create this dolog file
689:27 - now now after that let me create a
689:30 - object for this loging so here I'm going
689:32 - to call this loging now now let me copy
689:35 - and paste uh inside that I need to write
689:39 - couple of thing inside this logging
689:41 - method inside this logging function now
689:44 - let me show you that what all thing we
689:46 - are going to write it down inside this
689:48 - particular method so here I have already
689:50 - written the parameter that what all
689:52 - parameter which we need to pass over
689:54 - here the parameter is going to be a very
689:56 - very easy so the first parameter is
689:58 - going to be a uh label so actually we
690:01 - have a different different label of the
690:03 - loging so here I'm going to mention this
690:06 - info label so loging doino this this is
690:09 - going to be my label actually we have if
690:11 - you will look into the uh logging
690:13 - documentation so P just just type python
690:16 - logger so there you will find out a
690:17 - documentation and just look into the
690:19 - label so there you will find out a
690:21 - various label regarding this logging so
690:23 - from where you want to so from uh which
690:26 - particular label you want to log your
690:28 - information so here I'm mentioning this
690:31 - uh info so info till info and above the
690:34 - info it is going to capture all the
690:36 - information it is not going to capture
690:38 - the information below the info right so
690:41 - let's say if we have let me let me show
690:42 - you the label of this uh logging so you
690:45 - can search about the python logger so
690:48 - let me write it down over here python
690:50 - logger and here uh let me search it and
690:54 - let me open the documentation and here
690:57 - you will find out the different
690:59 - different label of the logging so just a
691:03 - second let me show you that
691:06 - [Music]
691:26 - and
691:30 - uh label they haven't given over here
691:32 - let me search directly python loger
691:43 - label yeah so these are the label
691:46 - actually so nonset and debug information
691:50 - warning is there error is there and
691:52 - critical is there so we have uh how many
691:55 - labels we have six label actually so
691:58 - info so we are going to log all the
692:00 - information from here okay so we are
692:02 - going to write it down the label label
692:04 - is equal to logging doino and from here
692:07 - onwards we are going to capture all the
692:09 - information so information warning error
692:12 - and critical we are not going to capture
692:15 - this two information debug and nonset I
692:18 - think this part is clear to all of you
692:20 - that what is a label now here you can
692:23 - see we have a like a label and apart
692:25 - from that I have mentioned the file path
692:27 - so this two thing is clear to all of you
692:30 - now let's talk about this format so what
692:32 - is this format actually so in the inside
692:34 - the format you will find out I'm going
692:36 - to mention a various parameter so first
692:39 - parameter which I have mentioned that is
692:40 - going to be a ASD time uh that's going
692:43 - to be a current time now line number at
692:46 - which line number we are going to log
692:47 - the information then we have a name then
692:50 - label name and then we have a message so
692:53 - we are going to log a various parameter
692:55 - now let me run it and then you will get
692:57 - a a clear-cut idea that how the thing is
693:00 - working so here is my logger file and by
693:02 - using this particular file I'm going to
693:05 - capture each and every information
693:07 - regarding the execution and in between I
693:09 - will be writing loging doino loging
693:11 - doino so whatever uh like information I
693:13 - want to capture so in between in my in
693:15 - between my execution I will be
693:17 - mentioning that thing and I will be able
693:19 - to capture all those information so here
693:22 - what I can do so if I want to test this
693:24 - logger file logger py so for that what I
693:28 - can do here I can write it down this uh
693:31 - test.py now I'm going to create one file
693:34 - the file name is what
693:36 - test.py now here inside this file I'm
693:38 - going to write it down let's say I'm
693:40 - going to import this loging first of all
693:42 - so where this logging is available so if
693:44 - you will look into this SRC so just go
693:47 - through with the SRC inside the SRC we
693:49 - have a McQ generator and inside the McQ
693:52 - generator you will find out this logger
693:54 - so you can write it down like this uh
693:56 - how you will write write it down your
693:58 - import statement so you will write it
693:59 - down from SRC do McQ
694:03 - generator. logger and you are going to
694:07 - import logging from here from this
694:10 - particular file so from SRC do McQ
694:13 - generator. loger import loging now here
694:17 - I'm going to write it down this a loging
694:19 - loging doino so here I'm mentioning this
694:23 - here I'm writing my login. info and let
694:25 - me write it down something over here so
694:27 - so hi uh I'm going to I'm going to start
694:34 - I'm going to start my execution so I'm
694:39 - going to start my execution now this is
694:41 - what this is my message which I have
694:43 - written over here now if I'm going to
694:45 - run this particular file so let's see uh
694:48 - will I be able to create the logger or
694:50 - not so for running this file what I need
694:53 - to do so first of all uh I need to open
694:56 - my G bash because either I'm going to
694:58 - work with my G bash or command line I'm
695:00 - not going to use this poers cell uh
695:02 - because it gives uh some sort of issues
695:04 - so I'm not going to use it now here what
695:07 - I can do guys I first of all I need to
695:09 - activate the environment so what is the
695:11 - name of my environment my name of my
695:13 - environment name is EnV so for
695:16 - activating the environment I just need
695:18 - to write it down here Source activate
695:21 - and do/ EnV now here is what guys here
695:24 - is my environment so EnV is my
695:26 - environment which I have activated now
695:29 - you can check that all the libraries is
695:31 - there or not all the thing uh we have
695:33 - upload we have installed or not inside
695:35 - this particular environment you can list
695:37 - all the import statement so for that
695:40 - there is a command pip list so just run
695:42 - this particular command pip list and
695:44 - here you will find out all the library
695:46 - all the library basically which we have
695:48 - installed and along with all the library
695:51 - along with all the packages you will
695:52 - find out my local package as well and
695:55 - the name of the local p and the name of
695:58 - the local package is what McQ generator
696:01 - so here guys this is the path where this
696:03 - package is available inside my directory
696:05 - inside my system and here you can see
696:08 - this is what this is the package name
696:10 - and how to install this package in my
696:12 - previous class I have clearly explained
696:14 - you that how to install this package
696:16 - inside the current virtual environment
696:19 - so for that either you can mention this
696:21 - Hy e do inside the re. txt or else you
696:25 - can use the setup. y file now let's try
696:28 - to execute the test.py file and let's
696:32 - see will I be able to create the logger
696:34 - or not so here what I'm going to do here
696:36 - I'm going to write down my python python
696:40 - test.py and here you can see it is
696:42 - saying that modu object is not callable
696:46 - but yeah I able to create my logger and
696:49 - inside this logger I don't have the uh I
696:52 - don't have the logger uh I don't have a
696:55 - logger log file actually so let's see uh
696:58 - what mistake we have done over here
697:00 - inside this uh inside this uh logger py
697:04 - so let me check with the logger py and
697:08 - here is saying that uh loging label
697:11 - loging
697:13 - doino um module okay so actually I
697:16 - haven't mentioned this uh I haven't
697:18 - called one method over here the method
697:20 - name is going to be a loging do basic
697:23 - info so basic configure actually so I
697:26 - missed uh that particular method now let
697:28 - me copy it and here I'm going to call it
697:31 - so my method name is going to be a basic
697:33 - configure so here is my method guys uh
697:36 - which I have copied now so let me do one
697:39 - thing let me remove it now everything is
697:42 - perfect so let me remove this part
697:45 - also yeah so here guys you can see my
697:48 - method name is what login. basic config
697:51 - this is my method and now I hope
697:54 - everything will work fine so what I can
697:56 - do do I can uh delete this particular
697:59 - module log mod sorry I can delete with
698:02 - this particular folder log folder and
698:05 - again I can run it so here let me clear
698:07 - the screen and let's see this time it
698:10 - will be working or not so I'm executing
698:12 - Python test.py and now you can see I'm
698:16 - able to uh run or I'm able to execute
698:19 - this particular file now just look into
698:21 - this log file and here uh log folder and
698:24 - inside this you will find out this uh
698:26 - particular file so just see the name
698:28 - just see the name of this file the file
698:31 - name is uh this is the date current date
698:34 - 12
698:35 - 1223 and here is a Time 347 and this is
698:38 - a second actually and do log do log is
698:41 - What DOT log is a extension now just
698:43 - look into the information that uh what
698:46 - information we are going to capture over
698:47 - here so here this is my current date
698:50 - time and here is my root actually root
698:53 - uh uh and here you will find out the
698:55 - information this is the information now
698:57 - this is my message so in whatever for
698:59 - see whatever format I have mentioned
699:01 - over here inside this format inside this
699:04 - basic config you can see in a similar
699:06 - format we are going to capture the
699:09 - information so just look into the format
699:11 - so here is a current time here is a line
699:13 - number here is a name so name is what
699:16 - name is a root I haven't defined any
699:18 - specific name so it's taking as a root
699:20 - line number U at which line actually uh
699:23 - I have mentioned this loging logging
699:25 - doino inside this test.py file so you
699:28 - can see at line number three so yes I'm
699:30 - able to capture line number three also
699:32 - now here is a logging information uh
699:35 - actually logging label that's going to
699:36 - be information and here is my final
699:39 - message so this particular information
699:42 - I'm going to log and in between I can
699:44 - mention this log uh like wherever I want
699:47 - to do wherever I want to mention it and
699:50 - then I will be uh log the information in
699:53 - this particular file I hope this logger
699:55 - is clear to all of you please do let me
699:58 - know in the chat uh please write down
700:00 - the chat if logger part is clear then I
700:02 - will proceed with the next
700:25 - concept
701:18 - okay so great I think uh this part is
701:20 - clear to all of you how to create a log
701:22 - and all and how many of you you are
701:24 - implementing along with me uh how many
701:27 - of you you are doing along with
701:43 - me great so what I can do here I can uh
701:46 - push this changes to my GitHub and then
701:49 - I will show you how you can do the
701:50 - entire setup in a lab also so before
701:53 - writing the further code uh so what I
701:55 - will do I will uh Lo the same repository
701:57 - in the lab in the neuro lab and I will
701:59 - show you how you can execute each and
702:01 - everything over there also okay so first
702:04 - of all let me commit it uh let me do it
702:07 - over
702:08 - here I'm going to add all the files just
702:12 - a second yeah it is done now here I can
702:16 - write it on the message I created a
702:20 - logger I created a
702:23 - loger now let me commit it and uh here
702:30 - okay a few more fil is remaining just a
702:35 - second now
702:55 - this
702:59 - yeah so here you can see so I created a
703:02 - log and you can see my log folder and
703:04 - here is my log file now guys you can do
703:07 - one more thing uh let's say if you are
703:09 - not able to set up this project inside
703:11 - the local see yesterday I started with
703:13 - my local setup and all so that's why I'm
703:15 - continuing uh here itself U but yeah
703:18 - from next uh class onwards I'm going to
703:21 - uh I'm going to shift uh this projects
703:23 - and all on my uh lab itself so what you
703:26 - can do so just uh open the inal lab and
703:30 - after opening the inal lab let me show
703:31 - you how you can U like clone this
703:34 - particular project in the lab itself how
703:36 - you can execute this uh this this entire
703:39 - project actually in the lab itself
703:41 - directly from the GitHub from here
703:43 - itself so what I can do let me open the
703:46 - lab and here uh first of all let me give
703:48 - you the GitHub link so what I'm doing
703:50 - I'm going to pass it inside the chat and
703:54 - here is my GitHub link now guys what you
703:56 - need to do see uh here uh how you can
703:59 - open the lab so after open the Inon
704:02 - website you just need to click on this
704:04 - neurol lab so just click on this neural
704:07 - lab and it will redirect uh to you on
704:09 - this particular page so this is the
704:11 - homepage of the lab I neural lab now
704:13 - click on this start your lab so once you
704:16 - will click on that here you will find
704:18 - out of various option so big data data
704:21 - analytics data science programming web
704:22 - development so whatever you want to do
704:25 - now let's say if I'm clicking on this
704:27 - data science now here also you will find
704:29 - out of various option so K is there Dash
704:32 - is there Jango is there flask is there
704:35 - Jupiter py toch my SQL python there are
704:38 - so many option you will get it now here
704:40 - I'm using this cond as of now so I'm not
704:43 - going to create my application in flask
704:45 - so I'm not using this dedicated uh lab
704:48 - okay this one uh I can use it if I'm
704:50 - going to create my application in flas
704:52 - Jupiter for the Jupiter only means here
704:55 - you will be able to launch the Jupiter
704:56 - this for the pyto this for the Python
704:58 - Programming this for my SQL with python
705:00 - so already you will get a like extension
705:03 - and all here itself inside the lab it
705:05 - has been configured in that particular
705:07 - way now let me open this cond and here
705:10 - what you can do so start your lab and
705:12 - here you can give the name so here you
705:14 - can write it down the name let's say I'm
705:16 - going to write down the name McQ gen
705:18 - project so this is what this is the name
705:22 - of the project now here uh what I will
705:25 - do let me write down the comp name McQ
705:27 - generator project and it is asking to me
705:29 - do you want to clone any GitHub
705:31 - repository so I would say yes I want to
705:33 - do that so it is asking to me a URL so
705:37 - uh like just just give your url just
705:39 - paste your url so here what you can do
705:41 - you can give uh this particular URL see
705:44 - here I have uploaded the my code
705:47 - actually here I have uploaded uh the
705:49 - entire code on my GitHub repository so
705:51 - first what you need to do either you can
705:53 - Fork it or else you can uh like clone
705:56 - this particular repository and then you
705:58 - can upload inside your repository right
706:00 - so as of now this code actually it is
706:03 - available in my repository I have
706:04 - created the repository McQ generator and
706:07 - here you will find out the entire code
706:09 - now in your case what you need to do you
706:11 - need to upload the upload the same code
706:13 - in your repository and that URL you need
706:16 - to pass okay that particular URL
706:19 - basically you're going to pass so here
706:21 - what I can do I can copy this URL I can
706:23 - copy this https URL just copy it from
706:26 - from here and pass it over here inside
706:29 - this enter repository URL now uh let me
706:32 - pass it and here you can see guys this
706:34 - is what this is My URL now proceed so
706:37 - once you will proceed so it will take
706:38 - some time for the launching and my
706:40 - entire code will be available inside
706:43 - this particular lab so just wait uh it
706:46 - is fetching the entire code from the
706:48 - GitHub and yes now it is going to launch
706:53 - it see guys see uh so here you will find
706:56 - out the entire code see this is what
706:58 - this is my entire code whatever code
707:00 - whatever development I'm going to do uh
707:02 - I I I'm doing basically uh which is
707:04 - available in my GitHub now uh what you
707:06 - can do see uh here let me show you so
707:10 - sttp github.com now this same thing
707:13 - actually you can see in your vs code
707:15 - here itself in your vs uh in your GitHub
707:17 - also so if I'm writing over here dab.com
707:20 - instead of this uh github.com it is not
707:24 - there I think I need to press dot just a
707:28 - second yeah GitHub do
707:34 - Deb see guys so this actually this vs
707:38 - code has been provided by the GitHub
707:40 - right this this one this uh which you
707:41 - can see over here you just need to press
707:43 - dot in your um like once you need to
707:46 - open your repository and press the dot
707:48 - so here you will get this vs code so in
707:50 - the same way actually see we are
707:52 - providing you this a particular lab now
707:54 - whatever thing now whatever thing thing
707:56 - actually we are doing in a local in our
707:58 - local actually this one this is what
708:00 - this is my local setup right so whatever
708:02 - code and all I'm executing I'm doing in
708:04 - my local but let's say you have a
708:06 - dependency issue you are not able to
708:08 - write it on the code in your local
708:09 - system your system is very slow you
708:11 - don't have that that much of
708:12 - configuration your system is lagging or
708:15 - if you're are installing or downloading
708:17 - any sort of a library is giving you the
708:18 - error so any type of issue so for that
708:22 - there is a one solution the solution is
708:24 - neural lab uh for so that uh you don't
708:27 - need to download or install anything you
708:28 - just need to visit the uron website
708:31 - after visiting the uron website click on
708:33 - the neural lab after clicking on the
708:35 - neural lab there is a various option you
708:37 - just need to select only one according
708:39 - to your requirement and then pass your
708:42 - GitHub URL there or maybe if you don't
708:44 - want to pass it don't pass it directly
708:46 - launch your lab it will be launching the
708:48 - blank lab in that case and there
708:51 - actually in that particular workspace
708:53 - you can create your own project so that
708:56 - that's uh that thing actually I'm going
708:57 - to do from my next class onwards and
708:59 - here you can see uh this is what guys
709:01 - this is my project the same project I
709:03 - have open in my uh the same project I
709:06 - have open in my neural lab now let me
709:08 - open the terminal and here is what here
709:11 - is my terminal this is what this is my
709:13 - terminal uh are you doing it guys are
709:15 - you doing along with me please do let me
709:17 - know in the chat if you are able to open
709:20 - this Nero lab and if you are if if you
709:22 - migrated your project to this nuro lab
709:25 - here is my GitHub so you will find out
709:26 - the uh entire project entire code in my
709:29 - GitHub itself you can Fork it you can uh
709:32 - clone it whatever you want to do you can
709:34 - do from here uh we are not going to use
709:37 - Google collab uh we are going to use the
709:39 - neural lab see Google Google collab it
709:41 - will just give you the notebook instance
709:44 - right so but here actually this lab is
709:46 - for the end to development so you can do
709:48 - end to development over
709:50 - here got it are you doing it please uh
709:53 - do let me know yes uh Google collab you
709:55 - can think it's a like a neural lab but
709:57 - it is for the an development and it is
709:59 - giving you like like lots of
710:07 - functionality great so this is what guys
710:10 - this is my uh project which I migrated
710:12 - to my neural lab now here see this is my
710:15 - base environment so in my base
710:17 - environment I can uh install this
710:20 - requirements or I can create the virtual
710:22 - environment also so for creating a
710:24 - virtual environment the command will
710:26 - same so let me create a virtual
710:27 - environment over here and let's see we
710:28 - are able to do it or not so for creating
710:31 - a virtual environment by using the cond
710:33 - there is a command the command is going
710:34 - to be cond cond and here cond create
710:39 - hyphen p and here you need to write it
710:41 - on the virtual environment name so my
710:44 - virtual environment name is going to be
710:45 - uh let's say I'm I can write any name
710:47 - over here uh ENB vnb your name my name
710:50 - or whatever now here the command is
710:52 - Conta create hyphen PB and uh then you
710:56 - need to mention the python version in
710:57 - whatever version actually uh with
711:00 - whatever version you want to create a
711:01 - virtual environment so here I'm
711:03 - mentioning python is equal to 3.8 now
711:06 - hyphen y okay so this is my entire
711:08 - command cond create hyphen
711:10 - PB python is equal to 3.8 hyphen y now
711:14 - as soon as I will hit enter so you can
711:16 - see it is creating a virtual
711:19 - environment in my local workspace so
711:22 - let's
711:24 - see
711:32 - yeah so it has created a virtual
711:33 - environment in my local workspace so
711:36 - just just look into the workspace here
711:38 - left hand side and here is your complete
711:41 - virtual environment now if you want to
711:43 - activate this virtual environment so for
711:45 - that there is a simple command you just
711:47 - need to write it down this Source
711:49 - activate dot means what dot means
711:51 - current working directory or current
711:53 - work working space do/ andv now as soon
711:57 - as you will hit enter so you can see
711:59 - over here that I have launched my
712:01 - virtual environment successfully so this
712:03 - is what guys this is my virtual
712:04 - environment this one EnV EnV is what EnV
712:07 - is my virtual environment and here you
712:09 - can see this virtual environment left
712:11 - hand side right now what I will do here
712:14 - I will install my re requirement. txt so
712:17 - whatever requirement is there U
712:19 - regarding this particular project I'm
712:20 - going to install those requirement
712:23 - inside my virtual environment now here
712:25 - is a very simple command for installing
712:27 - the requirements uh whatever like
712:30 - requirements I have mentioned inside the
712:31 - requir not txt and before that let me
712:34 - check uh what all uh what all packages
712:36 - we have inside this virtual environment
712:38 - so for listing all the package there is
712:40 - a command the command name is what the
712:42 - command name is PIP list so let me hit
712:44 - enter after writing this command pip
712:46 - list so here you can see we are able to
712:48 - list all the packages whatever is there
712:50 - inside this virtual environment now uh
712:53 - let me write it down here pip install
712:55 - pip install hyph R requirement. txt so
713:00 - now let's see uh are we able to install
713:03 - yes we are able to install this
713:04 - requirement inside the current virtual
713:06 - environment so are you doing it guys
713:09 - please do let me know in the chat if you
713:10 - are following this instruction if you
713:13 - want to set up the same project if you
713:15 - want to set up the same project in your
713:17 - neural lab so here I'm giving you the
713:19 - all the step uh that uh whatever you
713:21 - have to do so first you need to sign up
713:24 - uh sign in actually you need uh you need
713:26 - to open the neuro lab and after that go
713:29 - inside the start your lab there's a
713:31 - option right hand side you will find out
713:33 - and there you will find out the data
713:34 - science inside the data science there is
713:36 - a cond so just click on the cond and
713:38 - immediately you will be able to you will
713:40 - be able to launch your lab if you have
713:42 - kept your entire code in your GitHub
713:43 - then directly pass your URL and then uh
713:47 - like launch your lab that's
713:54 - it
713:59 - okay so I think it is done yeah so I
714:03 - install all the requirements over here
714:06 - now first I can check that uh my require
714:09 - whatever like packages I have installed
714:11 - it is working or not so here itself you
714:13 - can launch the python terminal and here
714:16 - you can see the environment python
714:17 - version
714:18 - 3.8.8 and here if I'm going to write it
714:21 - down import of Leng chain so let's see
714:24 - it is working or not c i yes my Lang
714:27 - chain is working now let me clear uh
714:30 - okay and here if I'm writing this Panda
714:33 - so import P
714:34 - PD so yes this is also working now
714:38 - everything is fine everything seems fine
714:41 - let me exit from here and what I can do
714:44 - now so here I have created the logger so
714:47 - if you will look into this uh SRC folder
714:50 - inside the SRC folder we have this McQ
714:53 - generator and inside this McQ generator
714:55 - we have have this logger now try to test
714:57 - uh this logger so it is working or not
715:00 - over here so for that what I can do I
715:02 - can run my test.py file so what I can do
715:06 - here I can change the message and my
715:09 - message is now I now I'm
715:14 - using now I am using neurol lab neuro
715:19 - lab so there is my message uh the
715:21 - message is now I'm using neurolab and
715:23 - let's uh execute this particular file
715:27 - python python
715:31 - test.py so if I will hit enter now let
715:36 - me check with the log folder yes uh so
715:38 - we are able to create this file and yes
715:41 - we are able to log the information also
715:45 - I hope this thing is clear to all of you
715:47 - how to log the information in all yes or
715:50 - no so the same thing which I was doing
715:53 - in my local now I'm easily able to do in
715:56 - my lab
716:00 - also oh yes we can change the theme also
716:03 - and for changing a theme there is a
716:06 - option let me
716:11 - check okay I think here you I will get
716:13 - the
716:17 - option command pallet color theme
716:20 - yeah so light is there now Dark theme
716:26 - yep so here you can see I have changed
716:29 - my theme also now if I if I want to zoom
716:32 - in then I can do that
716:35 - also just
716:38 - wait it is in my browser now so let me
716:41 - Zoom my
716:44 - browser yeah I think now it is
716:53 - perfect so guys uh if you are able to
716:57 - follow me till here so please do let me
716:59 - know in the chat then I will proceed
717:01 - with a
717:02 - further uh execution further code and
717:16 - all yeah you can upload your code over
717:19 - the GitHub and then you can clone this
717:21 - GitHub over here or else if you haven't
717:24 - created any GitHub then directly you can
717:26 - launch the lab and uh then you can
717:28 - connect to your GitHub from here also
717:30 - from the lab so that setup I will show
717:32 - you in my next class uh so in my next
717:34 - class when I will start with a new
717:36 - project so that I there I will show you
717:38 - if you are opening the blank neuro lab
717:40 - then how you can connect that neural lab
717:42 - with your GitHub got it even you can
717:45 - upload your code here also directly so
717:48 - just do the right click and maybe here
717:49 - you will find out the upload option see
717:51 - this one so just do the right click on
717:53 - this workspace over here here um
717:56 - anywhere in the uh and then you will
717:58 - find out this upload option so just
718:00 - click on the upload and here also you
718:02 - can upload your file maybe you won't get
718:05 - the folder option but yeah if you want
718:07 - to upload anything over here let's say
718:09 - data set or any any any file from the
718:11 - local system you can directly uh upload
718:15 - from here so just do the right click and
718:17 - here is upload option and then upload
718:20 - your file that's
718:22 - it great so I believe that uh everyone
718:24 - is a able to follow me till here now
718:26 - let's proceed with the further code so
718:29 - we have created a logger now it's time
718:31 - to write it down the code for the McQ
718:34 - generation so here I have created a file
718:36 - the file name is what McQ generator. py
718:39 - now uh before this one uh let me show
718:42 - you one more file this ipynb file which
718:44 - I have created in my previous class now
718:47 - here I have written the entire code of
718:49 - the open a for the Lang CH and all so uh
718:52 - directly from here itself I'm going to
718:54 - copy the code because already I have
718:55 - written it and uh yes I'm not going to
718:58 - write it down again so from here itself
719:00 - from the ipbb itself I'm going to copy
719:03 - and paste now uh there is my McQ
719:05 - generator. py file so at the first place
719:07 - what I need to do guys I need to uh at
719:10 - the first place I need to import the
719:12 - statement so let me import all the
719:14 - statement whatever statement is required
719:16 - for this project so here I have imported
719:20 - all the statement the first one is OS
719:22 - Json Trace bag is there pandas is there
719:25 - load. ENB is there now read file get
719:27 - file I will tell you uh like uh why I
719:30 - have written this read file get file so
719:32 - once I will explain you the U tools and
719:34 - here is loging so from where I'm going
719:36 - to import the login I'm going to import
719:38 - from this SRC see here uh I haven't
719:41 - mention the SRC so let me mention the
719:43 - SRC SRC Dot and here also let me write
719:47 - it on the SRC dot because uh I created
719:50 - uh like one more hierarchy actually this
719:52 - McQ generator folder it is available
719:54 - inside this
719:55 - SRC uh now I think this is fine now
719:59 - let's look into this particular import
720:01 - statement so here I'm going to import
720:03 - this Chad open Ai and then promt
720:05 - template llm chain and this sequential
720:08 - chain already I have explained you the
720:10 - meaning of this different different uh
720:12 - Imports that why we use this chat open
720:15 - why we use this prom template llm CH and
720:17 - this SQL uh and this like sequential
720:20 - check now uh what I can do here I can
720:23 - import my ID uh so actually I created my
720:27 - key openi key so let me import that
720:29 - openi key over here and then only I will
720:32 - be able to hit to my API so for that
720:34 - here I'm going to uh write it here I'm
720:37 - going to call this a
720:39 - load. EnV I told you why we use it uh if
720:43 - I want to if I want to if I want to
720:46 - create or if I want to keep my uh
720:49 - environment variable locally in my local
720:51 - folder in my local workspace so for that
720:54 - only we create this
720:56 - load. uh load. EnV uh now over here see
721:01 - if I'm going to call this method if if
721:03 - I'm running this method so actually it
721:05 - will look uh to this EnV file so it will
721:09 - it will try to find out the EnV file
721:11 - inside the current workspace now uh here
721:14 - what I can do I can create this EnV file
721:17 - so here I'm writing down uh do EnV so
721:21 - here is my file the file name is what
721:23 - the file name is do EnV so as soon as I
721:26 - am running this
721:27 - load. EnV so in back end actually it
721:31 - will try to search about this particular
721:33 - file so whatever variable whatever
721:35 - information I'm going to keep over here
721:38 - right whatever information whatever like
721:41 - variable I'm going to create over here
721:42 - so it will try to fetch from here wait
721:45 - let me show you how so uh what I can do
721:48 - now let me keep my key over here this uh
721:52 - like API key open API key I'm going to
721:55 - keep it over here inside this now what I
721:58 - can do now let me write down the further
722:01 - code so here uh once I will uh load this
722:04 - dot environment now here what I will do
722:07 - guys here I'm going to uh write down
722:09 - this dot get EnV so get environment
722:12 - variable so os. get En EnV and here
722:16 - inside this particular method I on uh
722:19 - like I will call it so I will mention
722:20 - the name of this uh key so what is the
722:23 - name of the key so the name of the key
722:25 - is open a API key so let me pass it over
722:28 - here this open API key now what I can do
722:31 - I can keep it inside the variable and my
722:33 - variable is going to be key now here
722:35 - what I'm doing guys I'm uh extracting my
722:38 - key I collecting my key by running this
722:40 - particular code by learning this
722:42 - particular line now uh here what I can
722:45 - do I can comment it out also so let me
722:48 - comment this particular thing I already
722:50 - WR the commment let me copy and paste so
722:53 - here what I'm saying load the
722:54 - environment with variable from the EnV
722:56 - file and here access the environment
722:58 - variable just like you would uh with OS
723:01 - environment so here you can see we are
723:04 - able to do it now let me follow the
723:06 - further step so after collecting the API
723:10 - key now what I will do I will call my
723:13 - open AI API for that we have a method
723:16 - the method name is chat open AI now let
723:18 - me call it and here let me show you that
723:21 - what all parameter we are going to pass
723:23 - while I'm calling this chat open AI so
723:26 - here you can see uh we are going to
723:28 - create a object of this chat open Ai and
723:31 - inside this one we are going to pass
723:33 - couple of parameter the first parameter
723:34 - is a key itself because without key we
723:37 - cannot call the API and we won't be able
723:39 - to uh get the model so here is what here
723:42 - is my API key now here is what here is
723:44 - my model name so this is the model which
723:46 - I'm going to use there are various model
723:48 - GPD 3.5 turbo or different different
723:51 - type of model you can go and check uh
723:53 - this uh I have already shown you in my
723:55 - previous session in my Open Session if
723:57 - you don't know about it you can go and
723:59 - check with my previous session now here
724:01 - is a temperature so temperature is just
724:03 - for the creativity if I want to so
724:05 - whenever I'm going whenever I'm calling
724:07 - my llm model so uh like whatever
724:10 - responses I'm generating so that will be
724:13 - a more creative if I'm mentioning uh if
724:15 - I'm writing the different different
724:17 - value of the temperature the temperature
724:18 - value from start from 0o to two so two
724:21 - means uh very creative zero means not at
724:25 - all it won't be a creative right so
724:28 - actually zero means it will give you the
724:29 - straightforward answer and two means it
724:31 - will give you the highly creative answer
724:33 - all it so between that I can set any
724:36 - sort of a value over here and according
724:37 - to that I will get the answer I will get
724:39 - a response so here you can see we have
724:43 - uh I'm able to call by API and I'm able
724:45 - to like U I'm able to get my model also
724:48 - now after that what I will do guys see I
724:50 - told you what I need to do I need to
724:52 - create my template I need to create my
724:55 - prompt template so here I'm going to
724:57 - create my prompt template now let me
724:59 - show you my uh template actually how it
725:01 - looks like so here is my template in my
725:03 - previous class itself I have shown you
725:06 - this thing I have explained you this
725:07 - thing now here you will find out couple
725:09 - of uh like variable also so variable
725:13 - like this number is there subject is
725:15 - there right we have tone we have n and
725:18 - this number so in between actually
725:20 - whatever thing you can see inside this
725:22 - curly braces that is representing a
725:24 - varable table now uh here what I'm going
725:26 - to do I'm going to create my input
725:28 - prompt I'm going to and this is what
725:30 - this is the template from the input
725:31 - prompt this is the template for the
725:33 - input prompt now here is what tell me
725:35 - guys here is my uh like a template for
725:37 - the input prompt now what I can do I can
725:41 - uh show you the prompt template and then
725:42 - I will explain you what is the meaning
725:44 - of uh this particular thing right this a
725:47 - particular template why I have written
725:48 - it again I will try to explain you even
725:50 - though I have explained you this thing
725:51 - in my previous class but again I will go
725:53 - through with that so here you can see
725:55 - guys we have a prompt template right so
725:58 - what we have tell me we have a prompt
726:00 - template and regarding uh see uh we have
726:03 - uh two variable inside this prompt
726:05 - template first variable is a input
726:07 - variable and the second variable is a
726:09 - template itself this one this one which
726:11 - I have defined over here now whenever we
726:13 - are talking about llm right so as I told
726:16 - you whenever we are talking about the
726:17 - llm so we have two type of prompt so the
726:20 - first one actually first one is called
726:22 - input prompt and the second one is
726:25 - actually it is called output prompt
726:26 - right so prompt is nothing it's a
726:28 - sentence itself uh it's a collection of
726:30 - the words it's a collection of the
726:32 - tokens right now here you can see we
726:34 - have a template and this is what this is
726:36 - my template the template is nothing so
726:38 - this prompt is nothing actually it is uh
726:40 - guiding to my uh it is guiding to my
726:42 - model is guiding to my GPT model GP we
726:45 - are using the GPT model now right so
726:47 - based on this particular prompt only is
726:49 - going to generate the answer so we have
726:51 - actually two type of prompts so we are
726:53 - talking about the prompt actually so
726:55 - measly you will find out two type of
726:56 - prompt so the first prompt first type of
726:58 - prompt actually is called a zero short
727:00 - prompt zero short prompt there we are
727:02 - not going to mention any sort of a
727:04 - context we are directly asking a
727:06 - question to my llm model the second type
727:09 - of prompt is called the second type of
727:11 - prompt is called few short prompt few
727:14 - short prompt so what is the meaning of
727:16 - the few short prompt so few short prompt
727:18 - is nothing there we are giving uh some
727:20 - sort of a direction actually some sort
727:22 - of a direction or some sort of an
727:23 - instruction in inside the prompt itself
727:26 - so this typee of prompt actually is
727:27 - called a few short of prompting now here
727:30 - we are giving an instruction to our llm
727:32 - based on this particular prompt now here
727:34 - you can see uh this is what this is my
727:37 - template uh and here I need to mention
727:40 - this particular template over here and
727:42 - this is what this is my input variable
727:44 - right this is what this is my input
727:45 - variable now we have H five input
727:48 - variable so one is text so whatever text
727:51 - on whatever text actually I want to
727:52 - generate McQ so that particular text I'm
727:55 - going to pass over here uh means
727:56 - basically based on the text itself I'm
727:58 - going to generate an McQ now there is a
728:00 - number of McQ there is a grade okay so
728:03 - to which grade actually uh the student
728:06 - belong now here is a tone tone means
728:08 - simplicity so means different different
728:11 - label of the quizzes so simple quiz or
728:14 - maybe hard quiz intermediate quiz and
728:16 - here is a response Jon so there you will
728:18 - find out the response and here in a
728:20 - curly bis actually I have mentioned this
728:23 - uh like uh I have mentioned this
728:25 - particular thing this particular
728:27 - variable now let me do one thing see uh
728:29 - here I have mentioned the subject and
728:31 - here I'm writing this grade so let me
728:33 - change this particular value here I can
728:36 - write on the subject so now everything
728:38 - is fine everything is clear so this is
728:40 - what guys this is my input prompt this
728:42 - is what what I have created I have
728:44 - created an input prompt now let me uh
728:47 - create a chain object so here already
728:50 - you can see I have like I have imported
728:54 - my llm chain and why we use this chain
728:56 - if we want to connect two component so
728:58 - we first uh at the first place we have a
729:01 - llm the second one we have a prompt
729:02 - template if you want to connect both uh
729:05 - this both component so for that we are
729:07 - using this llm chain so now let me
729:09 - create a object for this llm chain and
729:13 - for creating object for this llm chain
729:15 - so first of all let me assign to the
729:17 - variable quiz uh chain and here is this
729:21 - is what this is my object now in this
729:23 - particular object I'm going to pass two
729:25 - value two parameter the first value is
729:27 - going to be llm itself now here is what
729:30 - here is my llm which I already called
729:32 - which I already uh got from here and the
729:35 - second thing the second value is going
729:37 - to be a a prompt okay so here I'm going
729:40 - to be write the prompts and this is what
729:43 - this is my prompt quiz generation prompt
729:45 - so here I just need to uh here I just
729:48 - need to combine two component the first
729:50 - one is LM and the second one is a prompt
729:52 - so here is what here is my quiz chain
729:54 - got it so this is the first chain
729:56 - actually which I have created and this
729:58 - each and everything each and every uh
730:01 - like uh thing actually I have explained
730:03 - you in my previous classes even in my uh
730:06 - like yesterday's class now guys see
730:08 - whatever um output I will get after
730:11 - generating a quiz from here from the
730:12 - template so that thing I'm going to keep
730:15 - inside my uh inside my variable and the
730:18 - variable is going to be let me write
730:20 - down the variable over here so the
730:21 - variable is going to be output uncore ke
730:24 - is equal to and here let me write down
730:26 - the quiz so here I'm going to collect
730:29 - all the output inside this quiz inside
730:32 - this a particular variable now let me
730:34 - mention one more parameter the parameter
730:36 - is going to be a barbos so what is the
730:38 - meaning of the bbos barbos is nothing if
730:40 - I want to see the execution whatever
730:42 - execution is happening if I want to see
730:44 - on my terminal itself so for that we use
730:47 - this bbos parameter now let me write it
730:50 - down here verbos is equal to True veros
730:53 - is equal to true so here I hope each and
730:56 - everything is clear whatever I have
730:58 - explained you uh if it is clear then
731:00 - please do let me know in the chat are
731:03 - you following me are you following me
731:05 - guys tell me guys fast yes or
731:11 - no what was the command for creating a
731:13 - virtual environment so let me give you
731:15 - the command for creating a virtual
731:17 - environment cond create hyphone p and
731:20 - virtual environment name p EnV and here
731:24 - uh python version python
731:26 - 3.8 and here hyph y so this is the
731:30 - command uh which you can use for
731:31 - creating a virtual environment I given
731:34 - you the chat you can copy from
731:40 - there tell me guys first so if you are
731:44 - uh able to follow me till here then uh
731:47 - please write down the chat and if you
731:49 - are liking the uh if you liking the
731:51 - content if you are liking the class then
731:53 - please please hit the like button
731:57 - also if you have any uh sort of a doubt
732:00 - any type of doubt you can mention in the
732:02 - chat section you can uh tell me your
732:04 - doubt I will try to solve that
732:06 - particular doubt and then I will move
732:09 - forward please tell me guys I'm waiting
732:11 - for your reply so yes chat is open for
732:14 - all of you please hit the like button
732:16 - please ask your doubt and if everything
732:19 - is done uh then please say yes at least
732:50 - okay so let's move forward
733:05 - great so here uh you can see this is
733:08 - what this is my first template which I'm
733:09 - passing to my model now at the second
733:13 - place what I need to do so I I'm going
733:14 - to create one more template for
733:16 - evaluating this quiz so whatever quizzes
733:19 - and all uh basically we are going to
733:21 - generate so I want to evaluate a
733:24 - particular quiz now for evaluating the
733:27 - quiz here I'm going to create a one more
733:29 - template U Already I did it if you will
733:31 - look into my in uh this if you look into
733:33 - my ipnb file so yesterday itself I have
733:37 - I had created this uh like different
733:39 - different prompts and all so this was my
733:41 - first template this is my first prompt
733:43 - and this was my second one for checking
733:44 - the quizzes and all so whatever quiz and
733:46 - all which we are going to generate and
733:48 - here is a template now let me copy it
733:50 - from here and let me paste it down so
733:53 - where I'm going to paste it I'm going to
733:55 - paste it over here inside my McQ
733:58 - generator. py now this is going to my
734:00 - second template so let me keep it in a
734:02 - small letter itself so here I'm going to
734:05 - copy it and this is going to be my
734:08 - second template this one so just just
734:10 - read this particular template that what
734:12 - we are saying here I'm saying to my
734:14 - model that you are an expert English
734:17 - grammar grammarian and writer given a
734:19 - multiple choice question for this
734:21 - particular subject whatever subject I'm
734:22 - going to mention let's say data science
734:24 - AI machine learning so here I'm saying
734:26 - that you need to evaluate the complexity
734:28 - of the question and give a complete
734:30 - analysis of the quiz only use uh Max 50
734:34 - words so 50 words for the complexity
734:36 - analysis if the quiz is not at p with
734:39 - the cognitive and analytic abilities of
734:41 - the student then update the quiz
734:43 - question which needs to be changed and
734:46 - change the tone such that is perfectly
734:48 - fits to the student ability now here
734:51 - here is basically here I have a quiz so
734:54 - uh which one this is this this quiz so
734:56 - this quiz actually I'm getting from here
734:58 - so whatever output I'm getting after the
735:00 - first after this uh after the first
735:03 - template so whatever uh like prompt I'm
735:05 - passing to my llm this first one so
735:07 - whatever output I'm getting I'm going to
735:09 - keep inside this quiz variable and that
735:12 - uh this variable I'm passing over here
735:14 - and based on this uh like quizzes and
735:16 - all right so based on this particular
735:18 - prompt we have a prompt and we have a
735:20 - quizzes now is going to check it's going
735:23 - to evaluate each and everything is going
735:25 - to check the complexity grammar each and
735:28 - everything is going to check over here
735:29 - so this is the additional prompt of
735:31 - which I have written over here now guys
735:33 - after that what I will do so here I'm
735:35 - going to Define my uh prompt template so
735:39 - let me do it uh let me Define my prompt
735:41 - template and my prompt template name is
735:44 - going to be a review chain so let me
735:46 - take it from here and this is what guys
735:49 - tell me this is my uh like second chain
735:52 - right so here I have created first llm
735:55 - chain and the name was quiz chain here I
735:57 - have created one more llm chain and the
735:59 - name is what the name is uh this one
736:02 - review chain right and here is what here
736:04 - is my prompt so prompt is going to be a
736:06 - quiz evaluation prompt sorry uh let me
736:08 - Define The Prompt uh before this one so
736:11 - here what I can do let me copy the code
736:14 - from The Prompt so this is the small
736:16 - small code and all so already I have
736:18 - written it even yesterday in my ipbb
736:20 - file I kept all the code right so you
736:23 - can go and check with my gith repository
736:24 - you will find out the entire code
736:26 - because yesterday I written from scratch
736:28 - and I have explained you each and
736:30 - everything so today I'm I'm not going to
736:32 - write it down here again um I'm just
736:34 - going to copy and paste and I believe if
736:36 - you have seen my previous session that
736:38 - definitely you will be able to
736:40 - understand it now what I can do so here
736:42 - I can write down this quiz evaluation
736:44 - prompt so we have this quiz evaluation
736:46 - prompt and here is my prompt template
736:48 - where what I'm doing guys tell me where
736:50 - is my uh input variable these are my
736:53 - input variable subject and quiz which
736:55 - you will find out over here subject and
736:57 - the second one is what the second one is
736:59 - quiz now here I'm going to pass my
737:01 - template and the name of the template is
737:02 - what template 2 so let me mention it
737:05 - over here let me write it down the
737:06 - template 2 so here is what here is my
737:08 - quiz evaluation prom and there is what
737:11 - there is my chain which I have created
737:13 - by using two component the first one is
737:16 - llm itself and the second is what the
737:18 - second is quiz evaluation prompt right
737:21 - and here whatever output uh we are
737:24 - getting so that output I'm going to keep
737:26 - or I'm going to collect inside this
737:29 - review variable right so just just try
737:31 - to understand how the thing is working
737:33 - it is very very simple if your python if
737:36 - if you know the python if your python
737:38 - Basics is clear the definitely you can
737:40 - understand uh this particular code got
737:42 - it now here we have written bubos is
737:44 - equal to true so this is what this is my
737:46 - review chain uh which I have created now
737:49 - after that what I will do see I have to
737:52 - combine this both chain the first is a
737:55 - review chain and the second one is what
737:57 - the second one is a quiz chain so for
737:59 - combining the both chain what I can do
738:01 - so here I can create object of the
738:04 - sequential chain right so now what I'm
738:06 - going to do guys here I'm going to
738:08 - create object of the sequential chain uh
738:11 - just a wait now let me create a object
738:14 - of the sequential chain and here is a
738:17 - object of the sequential chain this one
738:20 - now already I have imported the
738:21 - sequential chain this one this one L
738:23 - chain do change the sequential chain now
738:25 - here see we are going to create a object
738:27 - and what we are going to write down here
738:29 - we are going to define or we are going
738:31 - to write down the both name both chains
738:33 - first one is quiz chain and the second
738:35 - one is a review chain now we are going
738:38 - to connect everything all together here
738:41 - is and we are passing to this chain
738:43 - parameter now there is my input variable
738:45 - so these are input variable if you will
738:48 - look into the prompt if you will look
738:50 - into the prompt template there you will
738:52 - find out of various input variable
738:54 - various input variable which I'm going
738:56 - to take from the user side I told you I
738:58 - I explained you this thing in my
739:00 - previous classes just go and check with
739:01 - that now here is what here is my output
739:04 - variable so one output I'm going to
739:06 - collect inside this quiz and the second
739:08 - output I'm going to collect inside this
739:10 - review and here verbos is equal to True
739:14 - verbos equal to True means what whatever
739:16 - execution is happening in back so each
739:18 - and every execution the detail of the
739:20 - execution I will get onto my uh screen
739:23 - itself right so that's the meaning of
739:25 - the verbos is equal to true now this
739:28 - part is clear to all of you so we have a
739:30 - completed till here means uh we are able
739:33 - to call my API we are able to create we
739:36 - are able to call my API we are able to
739:38 - create a prom template and here we are
739:40 - able to create the chains now after this
739:43 - what I have to do see here in between
739:46 - you can mention the uh log also you can
739:48 - create uh we have created a loger now
739:50 - you can write down log logging doino and
739:53 - here you can collect all the information
739:55 - in a single file itself so whenever uh
739:58 - we are going to execute it so yes the
740:00 - loging U the log loging doino U
740:03 - basically logger file also is going to
740:04 - be execute and it's going to collect
740:06 - each and every information inside the
740:08 - dolog file got it now here uh this McQ
740:12 - generator is done now uh in the previous
740:16 - session uh actually what I did so over
740:19 - here uh if you will look into that so
740:21 - open eyes find this uh temp template and
740:23 - all everything is fine now just look
740:25 - into this ipynb after creating the chain
740:28 - actually we were calling this particular
740:30 - method right so uh the method name the
740:33 - method name was what get open a
740:35 - callbacks now why we use this U Get open
740:38 - a callback because if you want to keep a
740:41 - track of uh of the token right how many
740:44 - tokens is being used inside throughout
740:46 - the execution means uh let's say uh I'm
740:49 - passing a prompt input prompt I'm
740:50 - getting an output prompt so throughout
740:52 - this process how many tokens is being
740:55 - generated so that all the thing I can
740:57 - keep track by using this get open I call
741:00 - back and inside this one I'm calling I'm
741:02 - I'm I'm creating a object of this
741:04 - generative evalution chain itself so
741:07 - this is the one generative evalution
741:08 - chain and we are passing a different
741:10 - different value now where I'm going to
741:12 - do this particular thing see main code I
741:15 - have written inside the McQ generator.
741:17 - py now rest of the code whatever uh like
741:21 - utility code is there whatever helper
741:23 - code is there I'm going to write it down
741:25 - inside this utils.py so here I'm going
741:29 - to write down the entire code which is a
741:31 - helper one right I'm not going to mesh
741:33 - up my uh McQ generator file itself okay
741:36 - so here if I'm going to write it down
741:38 - like each and everything it is going to
741:39 - be a very clumsy so I'm not going to
741:41 - write down anything now over here uh
741:43 - till here everything is fine maybe so
741:46 - yes uh we have created a chain now
741:48 - inside the utils.py file let's see what
741:51 - all thing we have to like like uh we
741:54 - have to mention so the first thing first
741:55 - of all let me write down the import
741:57 - statement all the import statements so
741:59 - the first one is uh OS the second is pi
742:01 - PDF 2 the third one is going to be a
742:04 - Json and the fourth is a trace back so
742:06 - these are the import statement which I'm
742:07 - going to write down here now here what I
742:10 - will do guys see uh what I want I want a
742:14 - data right I want a data so for that
742:17 - actually uh I have defined two method so
742:20 - let me copy and paste all the method now
742:22 - just second I'm going to copy this two
742:25 - method and I'm going to paste it over
742:27 - here so here actually we have two method
742:29 - just just look into this method I I will
742:31 - tell you that uh uh why we should use it
742:34 - how we are going to use it so just a
742:37 - second yeah so here we have two method
742:39 - the first is going to be a read file and
742:41 - the second is going to be a get table
742:43 - data so there is two helper function
742:46 - which we are going to Define over here
742:48 - right now just look into this read file
742:51 - so this read file actually this this
742:53 - particular method we are using for
742:55 - reading the file right for reading the
742:57 - file whatever file we are going to pass
742:59 - actually so here actually I have written
743:01 - a code regarding two particular files so
743:03 - the first one regarding the PDF file and
743:05 - the second one respect to uh text files
743:08 - right so here I'm going to mention this
743:10 - P pdf.pdf file reader here we are
743:12 - passing file here we are getting file
743:14 - and here we are extracting all the data
743:16 - from the file itself in which variable
743:18 - in this text variable now here if you
743:21 - will look into this uh this particular
743:23 - code right inside this LF blog you'll
743:26 - find out file. name. ends with. txt so
743:29 - if my file is a txt one so I'm going to
743:31 - call I'm going to read this particular
743:33 - file and I'm going to keep all the
743:34 - information in my VAR so here from here
743:37 - basically I'm going to return all the
743:38 - information right got it now here just
743:41 - see this one so the second method G
743:44 - table data so why we are using this
743:46 - method G table data in my previous class
743:49 - if you will look into this uh IP VB file
743:52 - so where is the ipb file let me open it
743:54 - once more time so McQ do iyb file just
743:57 - scroll down till last so here actually I
744:00 - was getting a data I was getting my McQ
744:02 - now if you want to convert those McQ in
744:06 - a data frame so for that see this my
744:08 - this is my McQ which I was getting now
744:10 - if you want to convert this McQ in a
744:12 - data frame so for that actually we are
744:14 - using this a particular code this one
744:17 - this this particular code which I have
744:19 - written inside the utils.py so here I'm
744:22 - not going to mention everything in a
744:23 - single file instead of that I have
744:25 - divided a task right so whatever thing
744:27 - is required whatever is a main code main
744:30 - script I have written over here inside
744:31 - this McQ generator whatever like helping
744:33 - function and all like uh like this
744:35 - reading file reading and all or this get
744:38 - uh data as a table and all right so I
744:40 - have mentioned over here inside this U
744:42 - and already I have created a logger so
744:44 - there I am going to Define my uh there
744:47 - basically I have defined my logger so I
744:49 - believe until here everything is fine
744:51 - everything is clear to all of you please
744:53 - do let me know in the chat now one more
744:55 - step is there one more step is remaining
744:57 - now finally we'll create our application
744:59 - our streamlet application and then I
745:01 - will show you how to run it so first of
745:03 - all tell me if uh till here everything
745:06 - is fine everything is
745:12 - clear try to generate a new API key if
745:15 - you are getting any sort of error
745:17 - related to your API key delete it
745:19 - immediately and uh generate a new API
745:22 - keyy tell me guys fast
745:25 - I'm like up for the doubts and question
745:27 - so yes you can ask me and then I will
745:30 - proceed with the forther uh
745:35 - thing please increase the font size I
745:38 - think it is visible to all of you now
745:40 - let me increase few more just
745:44 - wait ah I think now it is
745:49 - fine what is a trace bag Trace bag
745:52 - actually it's a inbuilt function wait I
745:54 - will show you what Trace back does uh
745:57 - wait I will write down the code here
745:59 - itself inside my McQ IP
746:02 - nv5 if you have any type of Doubt any
746:04 - sort of a doubt then please do let me
746:05 - know please write down the chat uh I
746:08 - will try to solve your doubt and then I
746:10 - will proceed
746:19 - further no you no need to pay anything
746:21 - uh if you're using this neurol lab it is
746:23 - completely free uh just try to launch it
746:26 - again I think uh you can launch
746:39 - it yeah we can create a new template
746:41 - file also that is also fine but here we
746:43 - just have two templates so that's why I
746:45 - have written it inside my P file itself
746:48 - inside my python file but uh not an
746:51 - issue like you you can create a template
746:53 - file and there you can keep the all the
746:55 - templates and from there itself you can
747:13 - read We are following you but needs to
747:15 - revision from yeah definitely revision
747:17 - is required could you open the logging
747:20 - file whether it contains any log or not
747:23 - so here is a logging file and here we
747:26 - have two log file. log just open the
747:28 - file and here see we have a
747:30 - log I test it now I test it from here
747:33 - test.py so yes I'm able to see the
747:50 - log yeah so I think uh we can start now
747:54 - uh yeah so I think we have done almost
747:57 - all the thing now the next thing is what
748:00 - I need to create a streamlet
748:02 - application I think uh see uh regarding
748:05 - the code and all everything is fine
748:07 - everything is clear whatever I did in my
748:09 - previous session I I'm doing the same
748:11 - thing over here I just kept in my uh py5
748:15 - that's it now see guys this uh project
748:17 - is uh actually it's a first project so
748:20 - that's why I kept I kept it uh I kept I
748:23 - kept it as a simple one only but uh from
748:25 - next class onwards uh I'm going to use
748:28 - few more files and folder inside the
748:31 - like project itself so the architecture
748:32 - which I'm going to make so it's going to
748:35 - be a little more complicated okay so
748:38 - this is fine this is clear now let's do
748:40 - one thing let's try to create okay
748:41 - response. Json is already there now let
748:43 - me keep the response over here inside
748:46 - this uh file inside this response. Json
748:48 - and after that what I will do so I will
748:51 - create my stream application so there is
748:54 - my response in which particular format I
748:56 - want a response so I kept it inside the
748:59 - response. Json so this is what this is
749:01 - the format which I want here is McQ
749:03 - question here is answer and here is a
749:05 - correct answer so in this particular
749:08 - format actually I want a response from
749:10 - my GPT model now this is this is what
749:13 - this is a response. Json now let me open
749:15 - this stream lit uh app.py file and here
749:19 - I'm going to write it down the code now
749:21 - first of all let me import the statement
749:23 - all the statement so there is all the
749:25 - statement basically uh here what I'm
749:27 - going to do so these are the statement
749:29 - which you already know now this is the
749:30 - statement read file get file from where
749:32 - from the utils itself now see I created
749:35 - uh like one more hierarchy so here uh
749:38 - let me write down the SRC so wherever
749:40 - you are able to find out this McQ
749:42 - generator just write down the SRC in
749:43 - front of that so uh here you can see we
749:46 - have I have written this SRC McQ
749:48 - generator. utils and inside that we have
749:50 - this read files get table data you can
749:53 - check it you can run it and it is
749:55 - working fine or not so definitely uh you
749:59 - can do it for that uh let me write down
750:01 - this SRC McQ generator. log. loging now
750:05 - here if I want to check this file so I
750:07 - can write it down
750:09 - one okay so here what I can do I can run
750:12 - it in front of you let me clear it first
750:14 - of all and here let me write down python
750:18 - python uh streamlet
750:21 - app.py so Python steamate
750:24 - app.py and if I'm running it so it is
750:27 - saying that this module is not available
750:30 - McQ generator let me check with the
750:32 - spelling is correct or not so the
750:34 - spelling is
750:36 - McQ generator g n Okay g n and here see
750:42 - guys the spelling is wrong so here I
750:43 - need to write down the correct spelling
750:45 - so this will be g e n e so this is the
750:48 - spelling of the generator G NE e
750:50 - generator and here also G G NE so this
750:53 - is going to be generator now let's see
750:55 - it is working fine or not now for that
750:57 - python streamate app.py so let me run it
751:02 - and module name SRC McQ generator not
751:06 - there so where it is at line number nine
751:10 - so line number line SRC McQ generator
751:15 - import generative evaluate chain so here
751:18 - we have SRC McQ generator is there
751:21 - inside this McQ generator this is the
751:24 - file so McQ g e n e again the spelling
751:28 - is wrong let me correct it uh let's see
751:31 - it is working or not so here I'm going
751:34 - to write on python stream tab.
751:39 - py SRC McQ generator
751:44 - utils so McQ G
751:47 - NE McQ g
751:50 - n r a is correct now right so why it is
751:55 - giving me this error SRC McQ generator
751:58 - do utils SRC McQ generator do utils
752:03 - import read file and get table
752:08 - data no modu SRC McQ
752:13 - generator I WR something wrong
752:17 - here McQ generator g e n e r
752:23 - it's fine now I S
752:28 - see just a second so here is fine
752:33 - now what I can do let me install this
752:37 - setup.py so
752:40 - python setup.py
752:45 - install because in my local system
752:48 - everything was working fine I moved to
752:51 - entire project project to this Nero lab
752:53 - that's why I need to check it
752:56 - first okay now let's
753:06 - see
753:08 - mCP P the
753:12 - spelling I need to save it first what so
753:16 - okay I think the file is
753:18 - different uh McQ generator. py line
753:21 - number 6 this
753:23 - one line number six yes so the spelling
753:27 - is
753:30 - wrong now it is perfect I
753:42 - believe right package rapper prompts
753:45 - extra field not
753:47 - permitted what is the issue
753:51 - here
753:57 - modle name McQ
754:01 - generator this is fine this is I have
754:03 - solved now stream lit line number nine
754:08 - there is line number
754:18 - line
754:21 - okay
754:22 - great now I think everything is fine I
754:24 - just need to pass the parameter over
754:26 - here but this uh logging statement and
754:28 - all everything is working fine over here
754:31 - see if I'm going to uh comment it down
754:33 - this one so I will be able to import it
754:37 - python stre late app. yeah now
754:39 - everything is working fine so I was
754:41 - getting the error because I need to pass
754:43 - the parameter to this particular uh like
754:46 - class okay to this particular object
754:49 - that's why uh it is giving me uh it is
754:51 - giving me I show so yes I'm able to
754:54 - import all the statement I was just
754:56 - checking actually because I migrated
754:58 - this project to my neural lab in my
755:00 - local I already tested and yesterday
755:03 - actually I shown you that but yeah I
755:05 - migrated to my uh to this uh neurol lab
755:09 - so that's why I was running it and now
755:11 - everything is working fine so let's try
755:13 - to create a stream streamlit application
755:16 - so here what I can do so for creating a
755:18 - streamate application uh this is the UT
755:21 - statement which I have imported now the
755:23 - first thing the first at the first place
755:25 - I need to load this uh response right so
755:28 - here what I'm going to do here I'm going
755:30 - to load this response so for loading the
755:32 - response actually see what I'm going to
755:34 - do I'm going to read the Json file the
755:36 - Json basically which I've created now
755:38 - let me do the right click and from here
755:40 - from here itself uh like from this uh
755:42 - neuro lab itself from the local
755:44 - workspace I'm going to copy my path
755:46 - right so because this is my local path
755:48 - actually this one that you can see over
755:49 - here the Json path now from here itself
755:52 - I'm going to copy my path so copy path
755:54 - and paste it over here right paste it
755:56 - over here this particular value now let
755:59 - me paste it and this is what guys this
756:01 - is my path right and here my Json file
756:04 - is available now uh what I will do I
756:07 - will read this Json and here you'll find
756:09 - out your Json response Json right in
756:12 - whatever like in whatever like Json
756:15 - whatever Json basically we have defined
756:17 - whatever response method we have defined
756:19 - in that particular like way only is
756:21 - going to data output now uh I have
756:24 - loaded the file I have loaded the Jon
756:25 - file now next thing what I need to do
756:27 - here so see a step by step I'm going to
756:30 - show you everything or let me copy
756:32 - everything each and everything in a
756:33 - single shot and then I can uh explain
756:37 - you right so here see what thing I'm
756:39 - going to do over here Ive already done
756:41 - the code now let me is explain you one
756:44 - by one so this is the first line this
756:45 - one st. Title St means what ST means
756:49 - streamlink here you can see this one s
756:52 - isans what streamlit and why we use
756:53 - streamlit for creating a web application
756:56 - right if you want to create a web
756:57 - application for for that we use this
757:00 - stream L and generally we use it uh for
757:02 - creating a rapid web application like we
757:05 - want to test our machine learning code
757:07 - like okay so we don't want to write it
757:09 - on the like long templates and all we
757:11 - don't want to create API by using Jango
757:13 - or flas so simply we can create a web
757:16 - app a small web app by using this stream
757:17 - lead and yes we can test our code we can
757:20 - test our application now here uh you can
757:23 - see this is the title which will be
757:24 - visible on top of my screen now here you
757:27 - can see we are going to create a form
757:29 - actually inside this stream lit we have
757:30 - a several thing right so what I will do
757:33 - I will create a short tutorial on top of
757:35 - this stream lit and I will upload over
757:36 - the Inon YouTube channel so from there
757:38 - you can learn the streamlit from scratch
757:40 - as of now I'm not going into the deep
757:42 - that what all method what all function
757:44 - it is having I'm just WR whatever thing
757:46 - was required over here and that is what
757:48 - I'm going to explain you got it now here
757:50 - see we have this streamlit st. form and
757:53 - here actually I'm mentioning user input
757:56 - right now I'm asking about the file so
757:58 - actually I'm asking about the file you
758:00 - need to upload a file and based on a
758:02 - file only uh I'm going to generate a
758:05 - mcqs now here you can see number of
758:08 - input so how many uh how many mcqs you
758:11 - want to generate so here McQ count now
758:14 - here McQ subject so like on which
758:17 - subject you want to generate McQ so here
758:20 - you will pass the subject now here is a
758:22 - input text input means here you are
758:24 - asking uh you want to keep it simple
758:27 - intermediate or the hardest one so here
758:30 - I'm uh setting the tone tone of the mcqs
758:33 - tone of the quiz now here what I'm doing
758:36 - here I'm giving a button so here I'm
758:38 - written St St is for the stream late.
758:42 - formore submit uncore button and here
758:45 - you can see create McQ this is what this
758:47 - is my message that's it nothing else so
758:49 - after that you can see I I have written
758:52 - a further code so this is what this is
758:53 - what guys tell me this is my form and
758:55 - inside form actually I have defined the
758:57 - entire template the entire UI so I have
759:00 - created a form s. form s. form means
759:03 - what stream li. form and here I'm asking
759:06 - to the user input so this first input
759:08 - regarding the file means on whatever
759:11 - like data we want to generate our mcqs
759:14 - here you will find out a number of mcqs
759:16 - here the subject of the McQ here the
759:19 - tone of the McQ whether it's going to be
759:21 - a difficult simple or intermediate and
759:24 - here I have added the button the button
759:26 - is nothing I'm going to submit this form
759:29 - so the message B by default message you
759:31 - can see over here that is what there is
759:33 - a create McQ that's it so this is what
759:35 - this is my form now after that I will
759:38 - write my main code main code over here
759:41 - see uh just just look into this
759:43 - particular variable upload file right
759:45 - this this varable upload file right and
759:48 - here I'm getting McQ count subject tone
759:50 - and button now here see this is what
759:52 - this is a respon just look into this
759:54 - particular variable because this is
759:55 - required very much this very much
759:58 - required over here now I'm saying over
760:00 - here if button and upload file is not
760:03 - none okay and McQ count and subject and
760:06 - this this thing is not none then what I
760:08 - need to do so here I'm writing this st.
760:12 - spinner it will be loading right and
760:14 - here see I'm uh reading this text file
760:17 - whatever uploaded file I got and how I
760:19 - can reading it how I am reading this
760:20 - particular file so for that I already WR
760:23 - the method inside the utils file
760:24 - utils.py so here I'm calling this method
760:27 - upload see uh let me show you this uh
760:30 - read file right read file and here you
760:33 - can see St um the stream. file uploader
760:36 - so here I get it I got the uploaded file
760:39 - now what I'm going to do here I'm uh
760:41 - keeping this file over here upload file
760:43 - and I'm giving to this read file right
760:45 - and this read file I already defined
760:47 - inside my utils.py this one see getting
760:52 - my point yes or no now if I have a PDF
760:54 - file then definitely I will be able to
760:56 - read if I have a text file then
760:57 - definitely I will be able to read so
760:59 - let's see if you're giving any other
761:00 - extensions so according to that you can
761:02 - mention the logic you can write down the
761:04 - code over here itself inside the read
761:06 - file now see guys here inside the stream
761:09 - app.py so this is what this is the read
761:12 - U we are calling this read file and here
761:14 - I'm getting this text okay this is fine
761:16 - now again I'm going to call this I'm
761:18 - going to call this uh get open call back
761:21 - if you have attended my previous session
761:23 - definitely you must be aware about this
761:24 - particular function this particular
761:26 - method in very detailed way I have
761:28 - explained you this thing get openi call
761:31 - back now after that you can see we are
761:34 - going finally we are going to call our
761:36 - object so here is my object generate
761:39 - evaluate chain and here we are going to
761:41 - pass a various parameter so the first
761:43 - one is a text so here I'm getting text
761:46 - McQ count or from the user I'm getting
761:48 - McQ count here is what here is a subject
761:50 - tone and here is my Json response
761:54 - everything I am getting over here you
761:57 - can see you can see over here guys this
761:59 - one now we are getting it and after that
762:03 - uh this is fine now in the else actually
762:06 - I have written something so you can see
762:08 - uh whatever number of token prompt and
762:10 - all I can I can print it actually this
762:12 - this particular thing right so inside
762:15 - this else block try accept and else so
762:18 - inside this else block we I have written
762:20 - this particular thing now any now this
762:22 - lse blog will run after this accept so
762:25 - yes you can see this is the thing which
762:27 - we have written now what we are going to
762:29 - do over here we are going to convert our
762:30 - data into the uh we are going to convert
762:33 - our data into our data frame so here
762:36 - actually this is the code see whatever
762:38 - data we are getting now so we are going
762:40 - to convert this data into a data frame
762:42 - this one and after that like yeah uh we
762:45 - are going to end it this particular code
762:48 - and once I will run it so each and
762:50 - everything will be clarified to all of
762:52 - you now what I can do I can run it and
762:55 - then again I can come to this particular
762:57 - code uh where again I can explain you
763:01 - the bottom part but yeah just look over
763:03 - here uh it is just printing the tokens
763:06 - and all now here we are getting a
763:07 - response and d means uh if is response
763:11 - as a DI actually this this particular
763:12 - response now what I will do here I will
763:14 - call this response doget quiz I will be
763:17 - getting the quizzes from there yesterday
763:18 - I run this particular function this quiz
763:21 - and after that I'm passing to this get
763:23 - table data the function which I defined
763:25 - inside the utility and it is going to
763:27 - return return me this table data which
763:29 - I'm passing to my data Frame pd. data
763:31 - frame and I will be getting the data
763:34 - frame over here and you can save it also
763:36 - so yesterday actually I saved this uh
763:38 - mcqs and all over here inside this
763:40 - experiment folder but you can save it
763:42 - you can save this data in the form of
763:44 - CSV file right now what I can do I can
763:47 - run it so here uh for running this
763:49 - particular application I just need to
763:52 - run it let me I just need to write it
763:54 - down one command let me uh give you that
763:56 - command here stream lit streamlit app
764:00 - sorry streamlit run and here I need to
764:03 - pass the here I need to write down the
764:05 - file name so streamlit run and then
764:08 - streamlit app.py soam lit streamlit
764:14 - app.py okay so this is the file where I
764:17 - have defined where I have created my
764:18 - streamlit application so streamlit run
764:20 - is stream lit uh app.py now as soon as I
764:24 - will hit enter let's see it is working
764:26 - or
764:27 - not so it is saying streamlit does not
764:32 - exist I WR a wrong spelling okay
764:35 - streamlit app fine so a will be a
764:39 - Capital One a a yeah now it's
764:45 - fine so see uh my application is running
764:49 - now if you want to run this application
764:51 - ation so for that just copy this URL and
764:54 - then paste it over
764:57 - here and here guys what you need to do
765:00 - just remove till till here this one just
765:03 - remove this up part okay just keep till
765:05 - app and then put the colon and from here
765:09 - just take the host uh this
765:11 - 8501 sorry Port actually this one so
765:14 - just see if you clicking on this one now
765:16 - it is not going to run because it is a
765:19 - uh like it's a local host
765:21 - right now uh actually my lab is running
765:24 - on this particular URL Somewhere over
765:26 - the cloud Somewhere over the server so
765:28 - till here I have copied the URL now put
765:30 - the colon and pass this particular port
765:33 - number
765:33 - 8501 so here I'm writing 85 01 and if I
765:38 - will hit enter so let's see whether I'm
765:41 - getting my app or not so it is not
765:45 - giving me the app let me
765:49 - check it 501 yes it is correct let me
765:53 - check with this link uh but I think it
765:56 - is not going to
766:04 - [Music]
766:06 - work are you follow me guys tell me are
766:08 - you follow me till
766:16 - here this is not giving me a URL
766:25 - when view stream
766:30 - browser
766:31 - 8501 right so this is a
766:49 - URL
767:09 - oh no it is not running just a second
767:12 - let me check with my Chrome it is
767:13 - working or
767:19 - not
767:31 - so if I'm passing over here this
767:34 - particular URL now let
767:37 - me put the colon
767:41 - 8501 uh let's hit the
767:49 - enter
768:03 - no it is not running but yeah my my
768:06 - server is up uh here you can see my
768:09 - streamlit server is
768:19 - up
768:22 - streamlit server is running on this
768:23 - particular Port
768:26 - 8501
768:28 - 851 it's a by default Port of the
768:31 - streamlet actually let me change the
768:34 - port just a second let me check
768:38 - uh
768:49 - I'm
769:12 - okay let's do one thing let's try to run
769:15 - on a different
769:17 - port so here what I can do uh I can
769:21 - mention the port just a second I can
769:23 - mention a different port
769:26 - number let be clear first of all I'm
769:29 - here Pyon stream lit run uh stream lit
769:34 - run and there is my app and then hyph
769:37 - iPhone hyph iPhone server and dobard so
769:42 - let's run out
769:45 - 8080 if I will hit enter now let's see
769:49 - it is running on on this 80 8 0
769:54 - [Music]
769:58 - so it is running on this
770:01 - 8080 now let's check over here what I
770:05 - can do I can take this particular
770:09 - URL let me remove here
770:17 - 8080 yeah here it is working fine see
770:21 - I'm getting my
770:22 - application uh before uh it was not
770:25 - working with 8501 but it is giving to
770:29 - me not a complete
770:32 - one why is so just the
770:38 - second is there something
770:49 - wrong
770:52 - so guys see on 8080 my app is working
770:56 - fine this one I'm getting it but
771:00 - uh it should give me a homepage
771:04 - now the form basically which I have
771:07 - created over here this
771:09 - one title also I'm not getting Let me
771:13 - refresh it
771:16 - once no SD form user input this this is
771:20 - everything is
771:28 - fine no no no guys I'm not getting it
771:32 - let wait let me take a different port
771:34 - over
771:49 - here
771:58 - it's getting a stuck here actually let
772:00 - me check with the Chrome is giving me a
772:04 - same issue or
772:19 - what's
772:34 - no guys see it is giving me a issue this
772:37 - particular URL I don't know what is the
772:39 - issue there's a issue with the code
772:42 - or there is a issue with the stream
772:46 - R because I can see my code is fine and
772:50 - uh I just I checked it before right
772:52 - before the class
772:54 - also and it was
773:00 - working uh not an issue what I can do I
773:03 - can show you this thing in my local as
773:05 - of now and then tomorrow I will tell you
773:08 - that uh why it is giving me such issue I
773:10 - I will check okay so as of now see
773:13 - everything is working fine maybe I'm
773:15 - able to get the URL also but
773:18 - uh with 8 5 01 it was not giving me
773:21 - anything but with 5,000 or with any
773:23 - other Port it is giving me this type of
773:25 - page now let me check the same thing in
773:28 - the local it is uh working or not right
773:31 - so just take it just take this
773:34 - particular code and paste it over here
773:36 - inside the local means this is my local
773:38 - environment right now inside this
773:41 - streamlit app.py I pasted my code now
773:46 - inside the SRC we have H utils so let me
773:49 - put the code inside the utils also so
773:52 - from here itself I'm going to copy and
773:54 - paste let me copy and paste from the
773:58 - utils this one and
774:02 - here this is my local
774:04 - utils and let me paste inside the McQ
774:07 - generator is not there let me put inside
774:10 - the McQ generator
774:12 - also here is my McQ generator so this is
774:17 - my McQ fine so logar is there McQ
774:21 - generator is there and utils is there
774:24 - now streamlit is there everything is
774:28 - fine now let's run it so for running
774:31 - this application here is a command
774:34 - stream SD stream
774:38 - lit
774:41 - run SD stream lit
774:48 - app. stream lit app. P1 now if I will
774:53 - hit enter let's see it is working or
774:57 - not yeah it is
775:08 - working okay so here it is giving me one
775:10 - error the error is
775:17 - what PR required type missing prom extra
775:21 - field
775:31 - type quiz
775:33 - [Music]
775:35 - barbos just a second guys let me check
775:38 - the
775:42 - issue we uh to validation
775:49 - error evaluation
775:51 - chain yeah this is
775:56 - fine
776:03 - commed line number five Sunny stream L
776:06 - app
776:13 - okay McQ line number
776:17 - 242 McQ generator line number
776:23 - 42 okay boms output key is equal to
776:29 - quiz okay
776:31 - file load I think here we have some
776:48 - issue okay so I I think I'm getting some
776:51 - issue over here maybe it's a python
776:54 - related issue let me check where I'm
776:56 - running it I activated my
777:15 - environment rank chain
777:18 - 0.348
777:23 - uh just a second so let me fix it don't
777:26 - worry it till be
777:39 - working so let's
777:48 - it
778:31 - yeah so now it is working and here you
778:34 - can see guys see uh this is the code and
778:38 - uh yeah it is working fine on this
778:41 - particular URL and it is uh the project
778:45 - B actually I'm running in my local
778:47 - itself in neuro lab also it is giving me
778:50 - a issue maybe there is some code issue
778:52 - uh which I tested in the local I will
778:54 - have to check because I was copy and
778:56 - pasting maybe in between I miss some
778:58 - line or I'm getting the issue because of
779:01 - the version uh basically the python
779:02 - version which I'm using now here uh you
779:05 - can see see uh my app will look like
779:08 - this the app which we have created now
779:11 - here you have to upload the file uh the
779:13 - file basically U on whatever file you
779:17 - want to generate a McQ and here you need
779:20 - to write down the number of McQ so let's
779:22 - say you want to generate 5 10 15 20
779:25 - whatever number of mcqs now here you
779:27 - need to insert the subject and here
779:30 - complexity label by default the
779:32 - complexity label will be a simple one
779:34 - right now let me browse some file and
779:36 - let me show you that how the McQ will be
779:39 - generated and how the output will be
779:41 - visible to all of you so here what I can
779:44 - do I can go through with my project
779:46 - itself because already I kept one data
779:49 - file over there there one txt file now
779:51 - let me import the txt file from there
779:55 - and here is what here is my project in
779:57 - my local system just a
780:02 - second McQ generator and here is data
780:06 - open so this is the data guys which I
780:08 - uploaded over here now after that how
780:10 - many McQ you want to generate so here is
780:13 - what here is five now here is a subject
780:15 - let's say the subject was the machine
780:17 - learning so here let me check what was
780:20 - the data inside the file here so here
780:23 - the data which I had actually so let me
780:27 - check with the
780:28 - data it was the biology uh which
780:31 - yesterday actually I collected inside
780:33 - the file so the data was the biology
780:36 - data now how many what was the like
780:39 - complexity of the quiz the quiz you are
780:41 - generating so here I want to keep it
780:42 - simple you can write as simple also but
780:44 - by default it will be a simple only now
780:46 - if I'm clicking on this create McQ so it
780:49 - will will uh directly give me the mcqs
780:51 - now over here is giving me error let me
780:54 - check what is the error yeah API key
780:57 - error so let me keep the correct API key
781:00 - over here
781:01 - because the API key which I'm
781:05 - using just a
781:08 - second yeah now it is fine and now let's
781:11 - do one
781:13 - thing okay server is up and here let me
781:18 - refresh it
781:30 - yeah it is working fine now browse the
781:33 - file a data just upload the data here
781:37 - the number of quiz you can say 5 6 10
781:40 - subject is what subject is
781:43 - biology uh b i o l o z and here the
781:47 - complexity label is going to be a simple
781:49 - then create
781:51 - mcqs now just wait for some time and it
781:54 - will create a McQ so just
782:00 - wait yeah it is running now and it got
782:03 - the response
782:13 - also yeah so here you can see uh we are
782:16 - able to generate mcqs so mcqs is which
782:19 - of the following is a unifying theme in
782:21 - a biology so these are the like uh you
782:24 - can see these are the options and which
782:26 - data I have use I have used a biology
782:28 - data so I can show you this particular
782:30 - data in the local itself so let me show
782:32 - you if you will look into this
782:34 - particular folder So Yesterday itself I
782:36 - collected a data inside this uh txt file
782:40 - so this is the file inside that from the
782:42 - Wikipedia I took the data in front of
782:43 - you only and here you can see the data
782:46 - you can uh pass any PDF or any txt file
782:50 - and based on that per subject based on
782:52 - that per data you can generate a McQ and
782:54 - here you can see the McQ and this is the
782:57 - like review the review actually right so
783:00 - uh we were evaluating the quizzes after
783:02 - generating a quizzes right so we have
783:03 - seted the limit in uh 50 wordss you have
783:06 - to evaluate the U the quizzes whatever
783:09 - quizzes basically we are going to
783:10 - generate so here you will see the review
783:11 - also on top of the UI so each and
783:14 - everything you will see uh inside the
783:17 - like uh inside the like front end itself
783:21 - here uh basically which we are using and
783:24 - if whatever number you are giving let's
783:25 - say 5 6 7 8 91 that many quizzes you
783:29 - will be able to generate now see uh
783:31 - before I was running this code in my
783:34 - local now let me show you both of the
783:36 - code so this was the code actually I was
783:38 - running in the local but uh it was
783:40 - giving me some sort of a issue uh don't
783:43 - know it was related to the maybe uh this
783:47 - library and all so see before the
783:50 - session itself I was testing with my uh
783:52 - same application actually uh like this
783:55 - is the same application only with uh
783:57 - with this particular application I was
783:59 - testing so I just run this one in front
784:01 - of you and I shown you how the output
784:02 - and all it will be looking like maybe uh
784:05 - in this uh application there is
784:06 - something wrong uh with respect to the
784:08 - library and the version or maybe I have
784:10 - uh given some wrong line and all I will
784:12 - have to debug it and the same I will uh
784:15 - I will uh like uh I will run inside the
784:17 - neural lab also but not today in
784:19 - tomorrow session and right after that I
784:21 - will deploy it but I just see I just
784:24 - want to show you the how the UI it looks
784:26 - like so here actually uh I run this
784:29 - particular application in front of you
784:30 - the same application the McQ application
784:32 - itself which I was I have created now
784:35 - how this looks like how the UI and all
784:37 - looks how the UI and all it looks like
784:39 - each and everything you can see over
784:41 - here and this is a by default Port where
784:43 - my streamlet application is running so
784:46 - 8501 right so whenever you are running
784:48 - your streamlit application so by default
784:50 - it will be running on this 8501 flask
784:54 - always take 5,000 port and this
784:56 - streamlit always take this 8501 Port
784:59 - right so don't uh do a mistake over here
785:01 - if you are running this application now
785:03 - how the answer will be looking like so
785:04 - it will looking like in the form of
785:06 - table and each and every code I have
785:08 - mentioned over here if you will go and
785:10 - check right inside the stimulate
785:11 - application now if you will look into
785:13 - the code so it will be more clear to all
785:15 - of you right so just looking into the
785:18 - code so here I'm say
785:19 - okay so this is the parameter basically
785:21 - which I'm going to print over here on
785:23 - top of the terminal and after that you
785:25 - can see I have mentioned one if
785:26 - condition so whatever response and the
785:28 - Dig right so is is response type is d i
785:31 - I'm saying yes so what you need to do in
785:33 - that case you need to exted the quiz
785:35 - then you need to pass this quiz to your
785:37 - get table data so from there you will
785:39 - get a table data now you are going to
785:41 - convert into a table and you are going
785:43 - to display that uh like you're going to
785:46 - dis see you are going to convert this
785:47 - table into a data frame and you are
785:49 - going to display it on top of the steam
785:52 - lit on top of the Steam on top of the
785:54 - basically uh UI so here uh this is the
785:57 - code this is the code actually this this
785:59 - one which you can see this one so
786:00 - display the review in a text box as well
786:04 - so here I'm going to display the output
786:06 - on top of the UI by using this
786:08 - particular code this particular line and
786:09 - rest of the code is a simple python code
786:11 - which I already explained you got it so
786:14 - this is the complete application now
786:16 - don't worry in tomorrow session uh
786:19 - again I will run it I just need to run
786:21 - it okay and again I will see I shown you
786:24 - the setup of the neural lab but in
786:27 - neural lab also I will run it and
786:29 - whatever project I'm going to build from
786:31 - now onwards I will be building in the
786:33 - neural lab itself so you can practice
786:35 - with the neurol lab and yeah tomorrow
786:38 - will be the deployment day and along
786:39 - with that I will explain you the concept
786:41 - of the vector databases so we'll try to
786:44 - discuss the vector database that what is
786:46 - a vector database and uh uh will try to
786:49 - understand the pine cone I will explain
786:51 - you the the pine cone actually how to uh
786:54 - like use that pine cone how to create a
786:56 - API key of the pine cone and how to
787:00 - store the embeddings and all what is the
787:01 - difference between normal databases and
787:04 - Vector based databases each and
787:06 - everything we're going to discuss in
787:07 - tomorrow's class in tomorrow's session
787:10 - okay and yes deployment I think it will
787:12 - take half an hour not more than 45
787:15 - minute we are going to deploy it on over
787:17 - the AWS and and I'm going to use the ec2
787:21 - instance uh I will show you along with
787:23 - the docker also so after creating a
787:25 - Docker image that how you can deploy
787:27 - that Docker image over the ec2 that
787:29 - process also I will show you regarding
787:31 - this particular application and yes
787:33 - right after that we'll start with the
787:35 - vector databases and uh then couple of
787:38 - Open Source model like Google pom is
787:41 - there Falcon is there or Jurassic is
787:43 - there so I will take one class for that
787:45 - and finally uh we'll start with more
787:48 - advanced project so one or two uh like
787:51 - other project actually which I have
787:53 - planned for all of you so uh with not
787:55 - with steam lit this is just a basic
787:58 - project which I shown you along with the
787:59 - flask and fast API also so um yeah stay
788:03 - tuned with us subscribe the channel like
788:05 - the hit the like button also if you're
788:07 - liking the content and if you are
788:09 - getting any sort of a issue then uh you
788:11 - can you can write on the inside the
788:13 - comment I'm monitoring each and every
788:15 - comment immediately I will reply to you
788:17 - uh resources wise you can check with the
788:19 - dashboard and uh yes video will be
788:22 - available over the dashboard as well as
788:23 - on a YouTube channel so you can uh watch
788:26 - on a both platform got it so how was the
788:30 - session guys uh are you able to run it
788:33 - or not don't worry I give you the
788:35 - complete code in a resource section from
788:36 - there itself you can download it here is
788:38 - my GitHub so here in the GitHub itself
788:41 - uh where is my GitHub where is my GitHub
788:43 - so this is my G so here itself I will
788:45 - upload all the code just uh forkit star
788:48 - it or or just keep it with yourself okay
788:51 - my just keep my username so from here
788:53 - itself you can download the entire code
788:55 - and don't worry the same link will be
788:57 - available in my resource section also
788:59 - got it yes or no tell me guys fast
789:02 - yes fine now uh here guys uh this is my
789:06 - project now first of all let me show you
789:08 - how this a project looks like um let me
789:10 - run this particular project so for
789:12 - running this project let me write it
789:13 - down here uh let me clear the screen
789:16 - okay now here let me write it down
789:19 - streamlit s r e a m streamlit run and
789:23 - here then I need to provide a streamlit
789:25 - file so streamlit dopy streamlit run
789:29 - streamlit app.py this is my file name
789:32 - now as soon as I will hit enter so my
789:34 - application will be running so here uh
789:38 - guys you can see my application is
789:40 - running just a second yeah so my
789:43 - application is running and this is my
789:45 - application just a second just uh wait
789:48 - yeah so this is my application guys now
789:51 - here you will find out we have a
789:52 - different different option so here you
789:55 - can upload your file and based on that
789:57 - data based on your uh based on that
789:59 - specific file you can generate a McQ you
790:02 - can provide a number like how many mcqs
790:04 - you want to generate here is a subject
790:06 - so whatever uh subject is there related
790:08 - to the data related to the file you can
790:10 - write on the subject and here is a
790:12 - complexity label so you would like to
790:14 - keep it simple hard or intermediate so
790:17 - let's try to upload one file over here
790:19 - so here already I I kept one file
790:22 - data.txt in my previous class only I
790:24 - shown you that now let me show you what
790:26 - we have inside this particular file so
790:28 - once you will open this data.txt uh so
790:32 - here actually this uh test.txt data.txt
790:35 - data.txt basically is what it was my in
790:38 - my another folder so I can take anyone
790:40 - or from anywhere I can take the data
790:42 - file so let's do one thing let's try to
790:44 - create one file okay from scratch data
790:46 - file and that to I'm going to create on
790:48 - my desktop so here uh let me create on
790:51 - new and here is my txt documentation now
790:55 - inside this particular file I'm going to
790:57 - paste my data so let's open the Google
791:00 - and here search about the AI so let me
791:03 - open my Google and let me search about
791:06 - the artificial intelligence now here I
791:09 - will get a article related to artificial
791:12 - intelligence let's say I'm opening this
791:15 - Wikipedia and I'm going to copy the
791:17 - article from the uh from the Wikipedia
791:21 - itself now I copied this article and I'm
791:23 - going to keep it inside my desktop
791:26 - inside my text one right now I can save
791:28 - it also so let me save as uh let me save
791:31 - as as
791:32 - a AI document right so AI doc so this is
791:37 - what this is my document which I saved
791:39 - now let's say if you have any sort of a
791:41 - information inside your text file inside
791:43 - your PDF so you can upload it over here
791:46 - so let me show you where you can upload
791:48 - you can upload lo you can pass it to my
791:50 - application now just click on the browse
791:52 - file and take a data from the desktop
791:55 - and here already I have this AI doc now
791:58 - open it and here guys you can see my
792:00 - file has updated now you can give the
792:03 - number of McQ now how many McQ you would
792:06 - like to generate so let's say I want to
792:07 - generate five McQ so here I'm giving
792:10 - number five so you can increase or you
792:12 - can decreas also from here itself now
792:14 - you need to provide a subject so here
792:16 - I'm writing artificial art artificial
792:19 - intelligence right artificial
792:21 - intelligence so here is what here is my
792:24 - subject okay so here is a restriction of
792:25 - the word so let me keep it like this in
792:30 - G and C so I can increase actually I can
792:33 - increase from the back end or otherwise
792:34 - I can write it down like this AI right
792:36 - so AI is fine my subject is what AI in a
792:39 - short form I have written it from back
792:40 - end actually I have given this
792:42 - restriction you can check with my
792:43 - streamlet file there I have already
792:44 - mentioned I can increase the number and
792:46 - then it's going to take like more than
792:48 - 20 words right 20 character actually now
792:51 - here I can provide the label so here the
792:53 - label is going to be a simple right I'm
792:55 - just going to create a simple uh simple
792:58 - McQ simple five McQ now once I will
793:00 - click on this create McQ so you can see
793:03 - my model uh is running in backend and
793:06 - here it will give you the answer so
793:08 - let's wait for some time and yes it will
793:10 - give me the
793:16 - answer yes Vector database Al Al will be
793:18 - covered in a live
793:28 - class yeah so if we are talking about
793:30 - the prerequisite right so I got one
793:32 - question actually so the prerequisite
793:34 - for the generative AI course is nothing
793:36 - just a python if you have basic
793:38 - understanding of the Python so just look
793:40 - into the project see guys here I'm able
793:42 - to generate a question so here I'm able
793:44 - to generate an McQ just just look into
793:46 - the McQ so uh it's a sens ible only
793:49 - right so what is the field of the study
793:50 - that develop and studies intelligent
793:52 - machine so here it has given you the
793:54 - various option like artificial
793:56 - intelligence machine learning computer
793:58 - science robotics now this is the second
794:00 - one which of the following is a example
794:02 - of AI technology used in a self-driving
794:05 - car so it is giving you the various
794:07 - option right so uh chat GPT bimo right
794:11 - Vio or YouTube Google search so like it
794:15 - is a sensible one and here you will find
794:16 - out the a correct answer so it is giving
794:19 - you the correct answer and it is
794:20 - evaluating the quizzes quiz also so here
794:22 - you can see the quiz evaluation now uh
794:25 - one question basically I got and it's a
794:27 - good one so uh what is a prerequisite uh
794:30 - if you want to if you want to start with
794:32 - the generative AI so the just just look
794:34 - into the project guys what I have used
794:37 - over here just tell me if you have a
794:39 - basic knowledge of the Python if you
794:41 - just have a basic knowledge of the
794:43 - development so yeah um you can enroll
794:46 - into the generative a and even if you
794:48 - don't don't know about the python then
794:49 - don't worry our pre-recorded session of
794:52 - the Python will be available over the
794:54 - dashboard from starting to end and apart
794:57 - from that like you can see regarding the
794:58 - development each and everything we are
795:00 - going to teach you in a live class
795:02 - itself from various skch from folder
795:04 - creation to deployment right so we are
795:06 - creating a folder in a class itself in a
795:08 - live session and we are doing a live
795:10 - coding in front of you and after develop
795:13 - after developing our application we are
795:15 - deploying it also so from starting to
795:18 - Advance right so from scratch to advance
795:20 - everything we are doing in a live class
795:22 - and the prerequisite is just a p just
795:24 - just python okay so don't worry about
795:27 - the uh this uh prerequisite and all
795:29 - already like uh the python and all will
795:31 - be available over there you can learn
795:34 - that first if you don't know and then
795:36 - you can proceed with the further thing
795:38 - right now here you can see this is the
795:41 - application which I'm able to create now
795:43 - what I want to do I want to deploy this
795:44 - application over the cloud right now
795:46 - here guys see this is the first
795:48 - application and many people are beginner
795:50 - one right and they don't know about the
795:52 - advanced concept Advanced mlops concept
795:55 - Advanced devops concept cicd and all so
795:58 - let's try to keep it simple let's try to
796:00 - deploy it over the ews there I'm not
796:02 - going to use a cicd concept in my next
796:05 - project I will show you how you can uh
796:07 - use the cicd a concept how you can uh
796:10 - create a like continuous integration
796:12 - continu deployment Pipeline and how you
796:14 - can deploy the application and even I
796:15 - will include the docker also here I'm
796:17 - keeping simple simply I'm creating a
796:20 - server on top of my AWS machine and
796:22 - there I'm going to deploy my application
796:24 - so let's see how we can do it so for
796:27 - that guys see the first thing what you
796:29 - need to do so the first thing you need
796:30 - to create your account on AWS the
796:33 - application we are going to deploy we
796:35 - are going to deploy on AWS so here what
796:39 - we are going to do guys tell me so here
796:40 - we need to create account on AWS now
796:44 - here you require a credit card debit
796:46 - card actually AWS does not ask you the
796:48 - credit card it ask it you can add the
796:50 - debit card also and it won't charge you
796:53 - anything directly right so believe me it
796:54 - won't charge you anything first it will
796:56 - ask you first it will tell you then this
796:58 - this this much of will like you have
797:00 - generated and like you can wave off also
797:03 - right or in the worst case you can
797:04 - delete the account so it won't like harm
797:06 - you it won't deduct any sort of a money
797:08 - from the account now the first thing
797:10 - which is required that is the AWS now
797:12 - here in the AWS we are going to use the
797:15 - ec2 server for deploying our application
797:18 - so first we'll try to configure the ec2
797:20 - server and here uh for uh in ec2
797:23 - actually we are going to use the Ubuntu
797:26 - machine right Ubuntu machine so that is
797:28 - the first thing basically which is
797:30 - required for the deployment now the
797:31 - second thing which is required that is a
797:33 - GitHub so just make sure that you have
797:36 - kept your project over the GitHub so
797:38 - what I'm going to do I'm going to upload
797:39 - my project over the GitHub I'm going to
797:42 - create a repository which I already did
797:44 - right I have like I have I have done in
797:47 - my previous session itself so there
797:48 - itself in my repository itself I have
797:50 - kept my project I have uploaded my
797:52 - project right so the first thing which
797:54 - is required which is a AWS the second
797:56 - thing which is required that is a GitHub
797:58 - that's it right so let me show you how
798:01 - to do how to deploy this application
798:03 - over the adws how to deploy this
798:05 - application or the ec2 instant where I'm
798:08 - going to use this Ubuntu Server right
798:10 - now uh GitHub so first of all let me
798:13 - give you the GitHub so at least you can
798:16 - follow me uh throughout this deployment
798:18 - process and here we have to run couple
798:20 - of command so I will give you those
798:22 - command also so at least you can run
798:25 - inside your uh instance inside your
798:27 - server right so here guys what I'm going
798:29 - to do I'm giving you this GitHub link
798:31 - just a second I'm going to paste inside
798:33 - the chat if you're not able to click on
798:36 - this link right so what you can do you
798:38 - can uh go through with the Google uh you
798:40 - can open the Google and you can search
798:41 - about s Savita GitHub so there you will
798:43 - get my GitHub ID and there just go
798:46 - inside my Repository and open this
798:48 - project open this gen AI project this
798:51 - gen AI so now guys see I already kept my
798:54 - project on my GitHub if you don't know
798:55 - about the GitHub and all then you must
798:57 - uh uh visit my previous session there I
799:00 - have discussed each and everything from
799:02 - scratch I'm not going to repeat those
799:03 - things otherwise we won't to Able we
799:06 - won't be able to cover the further thing
799:07 - further concept now here is what here is
799:11 - my uh here is my project right so I
799:14 - believe guys you all have you all kept
799:16 - the project in a GitHub itself you can
799:18 - uh download it from here as a jib you
799:20 - can clone it inside your repository
799:22 - everything is fine for me now but at
799:25 - least the project should be uh inside
799:27 - your system and then you need to upload
799:29 - in your GitHub right so this is my
799:31 - GitHub if you are opening it guys so
799:32 - this is my GitHub right so uh now what
799:35 - you need to do see if you're are going
799:36 - to Fork it that will also work okay that
799:38 - also you can do but the best thing what
799:40 - you can do just download it and keep
799:42 - inside your GitHub because uh whenever
799:44 - you are going to deploy it now so you're
799:46 - not deploying from my GitHub you are
799:47 - deploy from your GitHub so the project
799:49 - should be available over there because
799:51 - you will have to clone it now you will
799:52 - have to clone it right now uh here uh
799:55 - let me show you the ec2 instance right
799:57 - so how the ec2 instance uh looks like
799:59 - and all so the first thing guys what you
800:01 - need to do so I'm uh starting from very
800:04 - scratch no need to worry about it so
800:06 - just search about the EC tool so just
800:08 - open your uh AWS now let me show you
800:11 - about the AWS also um if you don't know
800:14 - about the AWS so here go open your
800:18 - Google and search AWS login so just
800:20 - simply search AWS login now here you
800:23 - will get a link so uh not this one
800:25 - actually this aws.amazon.com just open
800:28 - this aws.amazon.com just click on that
800:32 - and here guys here you'll find out your
800:34 - AWS right now it is asking to you uh
800:37 - would you like to create the account or
800:39 - you want to login so what I want to do I
800:41 - want to login because I already created
800:44 - an account and creating account is not a
800:46 - difficult task on a WS it's very easy
800:49 - it's very simple you just need to
800:51 - provide your detail over here whatever
800:54 - they are asking and simply create the
800:56 - account and it will accept your debit
800:58 - card also if you have enabled the
801:00 - international payment into your debit
801:02 - card so definitely you can add on over
801:05 - here and it won't charge anything first
801:07 - it will ask to you and you if you will
801:09 - approve then only it's going to cut it
801:11 - down cut down the payment but don't
801:13 - worry we can weev off also I will show
801:15 - you how you can weev off your money and
801:16 - you can delete the account if uh like
801:19 - you have launched so many instances and
801:22 - you generated like too long bill now
801:24 - here you can see this is what uh like
801:26 - this is a creating step like if you want
801:28 - to create an account now just click on
801:30 - the sign in Just click on the sign in
801:32 - and after clicking on the sign in right
801:34 - so here uh I already signed in so here
801:37 - it is giving me the homepage now guys uh
801:40 - what you can do so here you can search
801:42 - the ec2 instant just go inside this
801:44 - search box and here search the ec2 right
801:47 - right ec2 now click on this ec2 so after
801:51 - clicking on this ec2 right so it will
801:53 - give you the various this is the
801:55 - interface this is the home interface
801:57 - right of the ec2 so here it will give
801:59 - you the various options so no need to do
802:02 - anything just CL click on this launch
802:04 - instance right just just click on this
802:06 - launch instance so here after clicking
802:08 - in the launch instance it will give you
802:10 - one form right you just need to fill up
802:12 - this form and you will be able to launch
802:14 - your instance so you just need to
802:16 - provide some details over here and
802:18 - that's it so tell me guys how many
802:20 - people are following me please write
802:22 - down the chat and let me look into the
802:24 - doubt
802:27 - also so how much long this free
802:29 - generative AI boot camp will be so this
802:31 - a free generative AI boot camp uh like
802:35 - uh we are going to continue till next
802:38 - week so this week and the next week
802:41 - right so there is couple of concept
802:43 - which we need to discuss and couple of
802:45 - project as well so one basic project one
802:47 - advanced project and like few more
802:52 - concept do we need to learn ML and NLP
802:55 - learning for Gen VI please advise no ML
802:58 - and NLP is not see let's say there's
803:01 - different different kind of person so
803:03 - let's say if you're are beginner right
803:05 - and who don't know anything let's say
803:07 - who don't know anything and the person
803:09 - who want to start from the generative AI
803:11 - so for that person I already told you if
803:13 - you have a basic understanding of the
803:16 - Python then definitely you can start
803:18 - with the generative AI right so by
803:20 - learning the generative AI definitely
803:22 - you will be familiar with the basics of
803:24 - ml NLP and all automatically you will
803:26 - learn that but let's say there is one
803:28 - more person who is familiar with the ml
803:31 - statistic basics of ML and all right so
803:34 - yes the this is like a good thing he
803:37 - knows about the basics so definitely he
803:39 - can start with the generative a now
803:40 - there is one person who knows everything
803:42 - who knows about the ml DL NLP so that is
803:46 - well and good means um nothing can be
803:48 - better right so definitely the person uh
803:51 - can start with a generative AI so in
803:53 - every case you can start with a
803:55 - generative AI there you just required a
803:57 - python knowledge and if you are if you
804:00 - have a knowledge of the mlop if you have
804:03 - a knowledge of the NLP DL ml so yeah
804:06 - your understanding will be much clear
804:07 - over there getting my point so for every
804:10 - person the scenario is different so just
804:12 - think about your scenario but I would
804:15 - tell you that in every case in every
804:17 - scenario you can go with a generative AI
804:20 - right even non-technical person can
804:21 - enroll who don't know about anything
804:24 - right anything about the programming and
804:25 - theend
804:35 - okay so guys uh how's the session so far
804:38 - are you enjoying it tell me did you open
804:40 - this AWS page if you have any doubt you
804:42 - can ask me in the chat and then I will
804:45 - proceed
804:46 - further
805:07 - do we cover any mlops topic yeah we are
805:09 - using the mlops concept only now tool
805:11 - wise yes we can use the tool so we can
805:14 - use DVC ml flow or different different
805:16 - tools like yeah we going to use Docker G
805:18 - already we are using right so uh
805:21 - whatever is required according to the
805:22 - infrastructure and all definitely we can
805:24 - use it right and don't worry in the
805:26 - upcoming project we'll show you that
805:31 - also yes you will get a python video
805:34 - over the
805:35 - dashboard yes uh Amrit fine so I hope uh
805:40 - here you can see uh like here I have the
805:43 - ec2 so here I have click on the ec2 and
805:46 - I click on the launch instance now here
805:49 - you just need to provide the name so if
805:51 - you like just provide the name any name
805:53 - over here so here I'm saying McQ
805:55 - generator right so here I'm writing McQ
805:58 - generator this is the name of my uh
806:00 - instance now once you will uh scroll
806:03 - down so here you will get a option uh
806:05 - like here they have provided you a
806:06 - different different machine right so
806:08 - they have provided their own machine own
806:10 - Linux system Amazon Linux they they are
806:13 - providing you the Macos they're
806:15 - providing you the Ubuntu Windows right
806:17 - redit is there so different different
806:19 - like variant different different variant
806:21 - you will find out of the Linux and even
806:22 - Windows server is there so here we are
806:25 - going to select this Ubuntu right so
806:28 - here we are going to select this Ubuntu
806:29 - so just click on this Ubuntu after
806:32 - clicking on this Ubuntu so here it is
806:35 - giving you the free tire but uh here my
806:38 - application actually I I cannot I cannot
806:41 - take a chance I'm not using the free
806:43 - tire over here so as of now what I'm
806:46 - going to do I'm taking taking any larger
806:48 - instance so here okay so free tire is
806:51 - fine now what I can do yeah free tire
806:54 - Let It Be Free Tire okay so uh how to
806:56 - select the major instance let me show
806:58 - you that so here is the architecture so
807:00 - keep it as it is and keep it uh like
807:02 - free tire this one now here guys just
807:05 - just see free tire eligible just just
807:07 - click on that just just click on this
807:09 - drop down right and here instead of the
807:11 - t2 micro just select anything right
807:13 - apart from this T2 micro you can select
807:15 - uh either this small
807:17 - or you can select this medium or large
807:19 - so here I'm going to select this large
807:21 - one because as of now I don't want to
807:22 - take any uh chance so let's say if I'm
807:25 - selecting this medium or maybe small so
807:27 - maybe uh with this particular system my
807:30 - uh like this app is not going to be
807:32 - launched or maybe if I'm installing the
807:34 - requ txt and all it is giving me some
807:36 - sort of error I'm not going to take any
807:38 - chance and here I'm selecting this T2
807:40 - large but guys uh you can select U like
807:43 - this uh small one also and the medium
807:45 - one also right but in my case I'm I'm
807:47 - taking this large where it is giving me
807:49 - where it is giving me this uh 8 GB
807:51 - memory and here you can see the pricing
807:53 - and all but don't worry after the uh
807:55 - like after the session I will stop the
807:58 - instance right I will show you how to
807:59 - stop the instance now after selecting
808:02 - this instance okay after selecting the
808:04 - instance type what you need to do here
808:06 - you need to create a new pair right so
808:08 - create a new key pair so here for
808:11 - creating a new pair so once you once you
808:14 - will click on that it will ask the name
808:16 - right so here I'm giving the name so
808:18 - let's say the name is what uh McQ ke
808:21 - right so McQ key and here uh generate
808:23 - this a pem file right private key file
808:26 - format if you want to do SS or if you
808:28 - want to connect the this machine by
808:31 - using the puty or by using the SS so
808:34 - here this a key will help you right here
808:36 - this key will help you now create the
808:38 - key pair and it will ask you for the
808:39 - download so yes download it somewhere
808:42 - inside your system so I'm going to save
808:44 - it and I am done now you did two three
808:47 - things first you selected this ubu
808:49 - machine the second you selected this
808:51 - instance type and the third one you
808:53 - created the pair over here that's it now
808:56 - keep rest uh see here one more thing uh
808:59 - the fourth one actually you just need to
809:00 - click on this one right so just just
809:02 - click on this one just allow HTTP https
809:05 - and HTTP traffic also and keep it
809:08 - anywhere not no need to provide the
809:10 - specific IP address over here keep it
809:13 - 00000000 it's a global one and keep it
809:15 - anywhere uh you won't face any sort of a
809:18 - issue right so now guys this is done and
809:21 - one more thing I can do over here is
809:23 - asking to me a storage so I can increase
809:25 - the storage as well so instead of the
809:27 - eight I am going to take let's say 16
809:29 - right so here is my storage right so
809:32 - here is my storage and I hope now
809:34 - everything is fine I just fill up the
809:36 - form and once I will click on this
809:39 - launch instance so it will be launching
809:41 - my instance so are you doing along with
809:44 - me are you launching the instance tell
809:46 - me guys now see guys it has launched the
809:48 - instance now once I will click on this
809:50 - one uh so it will show me the instance
809:53 - and here the status is pending as of
810:02 - now tell me guys uh are you doing it
810:05 - along with me are you writing are you
810:08 - doing are you deploying see I have
810:10 - already given you the code I already
810:11 - given you the GitHub you just need to
810:13 - download it and keep it inside your
810:14 - GitHub and then you can follow the steps
810:17 - I'm going very slow and don't worry I
810:19 - will give you all the step in a document
810:21 - format
810:44 - also yeah so let me refresh it and let
810:47 - me check it is working or not yeah it is
810:49 - running now so see guys my status is
810:53 - running right instant state is running
810:55 - now just click on this ID just uh click
810:57 - on this ID and here click on this
811:00 - connect button right so what you need to
811:02 - do here tell me guys so once uh so click
811:04 - on the ID click on the instance ID and
811:06 - click on this connect button after that
811:09 - here it will give you the uh like option
811:11 - so here again uh like it will give you
811:13 - it will ask you for the connect
811:14 - connection so just click on this connect
811:16 - and and now your machine has launched so
811:20 - this is the machine guys this is the
811:21 - machine which we have launched now we'll
811:24 - configure this particular machine
811:25 - according to our requirement right so
811:28 - this is a machine basically which I got
811:30 - from the uh AWS side which I launch over
811:33 - here now I will configure it right so
811:36 - for configuring this machine I have to
811:38 - run few step so the first step which I'm
811:41 - going to run over here the step is Pudo
811:44 - AP update right so here once I will
811:46 - write down the the Pudo AP update so my
811:48 - entire machine will be updated right so
811:51 - here my machine is getting update and
811:53 - don't worry I will give you all this
811:54 - command I will keep it inside the GitHub
811:56 - itself uh so let me do it first of all
811:59 - let me show you and then I will provide
812:01 - you the command right so here guys you
812:04 - can see I have updated the machine or
812:06 - what I can do I can open the txt and
812:08 - there itself I can write it down so all
812:10 - the commands which whatever I'm running
812:12 - now the First Command which i r that is
812:15 - that is what that is a suit sudo AP
812:17 - update so that was a command which I ran
812:20 - now after that I will run one more
812:21 - command uh so here on the terminal
812:23 - itself I'm going to run one more command
812:25 - that's going to be a Pudo Pudo a AP iph
812:30 - G update so this is a second Command
812:32 - right sudo AP hyen G this is nothing
812:34 - this is just a package manager right so
812:36 - this AP AP G so I'm updating it uh the
812:39 - machine so here now everything is up to
812:41 - date so sudo AP update and sudo AP
812:44 - hyphen get update now let me write it
812:46 - down here this two command so the next
812:49 - one was sudo AP hyphone G update right
812:54 - so this is the second command now the
812:56 - third command which I'm going to write
812:57 - it down here that's going to be a pseudo
812:59 - up AP upgrade okay upgrade upgrade
813:03 - hyphen y right so this is the third
813:05 - command which I need to run Pudo AP
813:09 - upgrade hyphen y now let me open the
813:11 - machine and here I'm writing Pudo AP
813:15 - upgrade gde upgrade hyphen y right so
813:20 - here you can see my um like machine is
813:23 - getting upgraded so this three command
813:26 - which whatever I have written over here
813:27 - you need to run it on your terminal for
813:29 - updating your machine right so yes it is
813:33 - running let's wait for some
813:36 - time yeah still it is running and it
813:39 - will take some
813:42 - time here is a command guys this one if
813:45 - you have launched the system uh if if
813:46 - you have launched the machine so you can
813:48 - execute this three command sud sudo AP
813:51 - update sud sudo AP hyphen get update sud
813:54 - sudo APD upgrade hyphen y
814:00 - right great so here my machine is
814:04 - updating and it will take some time
814:07 - until if you have any question anything
814:09 - you can ask
814:15 - me
814:52 - yeah so here actually I just need to hit
814:54 - the enter if you're getting this uh
814:55 - warning so just hit enter and again you
814:58 - need to hit enter over here right so
814:59 - once you will hit enter it will be
815:01 - updating it so what's the meaning of
815:03 - this three command so just look into the
815:05 - command what we are going to do I'm
815:06 - saying Pudo Pudo means for the root user
815:08 - APD update right so APD is a package
815:10 - manager and what we are going to do we
815:12 - are going to update our machine by using
815:14 - this up package manager right so here we
815:16 - are going to update and upgrade each and
815:18 - everything uh inside this particular
815:21 - machine and now everything is done now
815:23 - we have updated our machine here you can
815:26 - see we have updated our machine now I
815:28 - have to install something here right I
815:30 - have to install something over here now
815:32 - for that again we have a command the
815:34 - command is going to be pseudo AP install
815:38 - right pseudo a install I'm going to
815:41 - install this git I'm going to install
815:43 - the curl right I'm going to install this
815:46 - unip
815:47 - and here I'm going to install this tar
815:50 - make right and here I'm going to install
815:53 - this sud sudo Bim Bim is what it's a
815:57 - editor right now here does w get so
816:00 - these are the thing these are the like
816:02 - uh these are the thing basically these
816:05 - are the software we are going to install
816:07 - by using this sudo APD install we are
816:09 - going to install this git call unip tar
816:13 - make and this Bim editor and here is W
816:16 - get now once I will write down this
816:18 - hyphen y so here you can see everything
816:20 - is getting installed over here now here
816:24 - everything is done so now if it is
816:28 - giving you this particular uh window so
816:30 - you just need to hit enter and let me do
816:33 - one thing let meit enter yeah here also
816:36 - and yeah it is fine so it is done guys
816:38 - now let me check one more time let me
816:41 - copy and paste over here the same
816:43 - command and I'm checking everything is
816:45 - done or not
816:47 - yeah everything is done see here right
816:49 - this is giving me already the newest
816:50 - version newest version newest version
816:52 - right now see guys my machine is ready I
816:54 - have updated the machine I have
816:57 - installed every software whatever is
816:59 - required now what I will do here I will
817:01 - clone my repository right so here is my
817:04 - repository guys this one so here
817:06 - actually I kept the application the
817:08 - entire application whatever application
817:10 - I'm running inside my system now you
817:13 - just need to clone this repository over
817:15 - there on top of that server right so
817:17 - here is my ec2 instance and here if you
817:19 - will write it down this get clone right
817:22 - and just provide the link right just
817:24 - provide the link of your repository now
817:26 - here guys see uh here is a repository
817:29 - link and hit the enter so it will be it
817:32 - will clone your repository and you can
817:34 - check it also so just just type this LS
817:36 - and here you can see this is your
817:38 - repository now you will write CD here CD
817:41 - means what change directory so just
817:43 - write CD and check uh with this
817:45 - particular Repository so here guys you
817:47 - can see I'm inside this folder I'm
817:50 - inside my repository now WR LS so here
817:53 - you will find out out all the file so
817:56 - here we have a response streamlit
817:58 - experiment means one folder McQ
818:00 - generator my main file here you can see
818:03 - require. txt setup.py and test.py and
818:06 - test.txt so I have the entire file now
818:10 - guys see uh here actually we have we are
818:12 - using the openi API if you look into the
818:15 - EnV envir in file so here actually what
818:18 - I'm doing I am creating one variable the
818:20 - variable name is what open a API key but
818:23 - here one we have an issue right so what
818:25 - is the issue you cannot upload you
818:28 - cannot upload this open AI API key you
818:32 - cannot upload this open a API key on
818:36 - GitHub right if you're going to update
818:38 - it so automatically it will delete right
818:41 - so this open actually don't know like
818:43 - what type of codee they have written so
818:45 - if you're going to upload this uh like
818:47 - this key on any uh repository okay in
818:50 - any public repository automatically they
818:52 - will detect it and they will delete it
818:55 - right so actually we cannot upload this
818:57 - particular folder this EnV folder on my
819:00 - GitHub right so there is a issue there
819:02 - is a issue so what I will do here so I'm
819:05 - going to create the EnV folder EnV file
819:08 - over here itself in my machine so for
819:10 - creating a file there is a command the
819:12 - command is what don't worry I will give
819:14 - you all the command first let me show
819:15 - you first let me run it so here is a
819:17 - command the command is touch right so
819:19 - here if I will write it on this touch
819:21 - and here if I will write en EnV do EnV
819:24 - so you can see uh let me show you so
819:26 - here I have created this EnV file right
819:29 - so it is not visible let me show you
819:30 - with ls hyph a it is a hidden actually
819:33 - this do file actually it's a hidden file
819:35 - now you will find out this EnV yes we
819:38 - have this EnV file now what I will do I
819:40 - will open this file by using the vi
819:43 - editor VI or VI editor so once I will
819:45 - write down this VI and here I will write
819:47 - down this do e and V now here guys see I
819:50 - have opened this file now after opening
819:53 - this file you just need to press insert
819:55 - right in your keyboard there's a button
819:57 - the button name is insert just press the
819:59 - insert now you can insert anything over
820:01 - here now what I'm going to do so here
820:03 - actually in my local I have my openi key
820:06 - just copy the key from here and keep it
820:09 - inside your en so let me do it uh let me
820:12 - directly paste it over here after copy
820:13 - see guys so here open I key and I pasted
820:16 - it now after that what you need to do
820:18 - you just need to press escape button so
820:20 - press the escape button it will be saved
820:22 - now if you want to come out from here so
820:24 - for that you just need to press the
820:26 - colon colon and WQ so here you can see
820:30 - uh like in the bottom bottom left bottom
820:33 - so there I written cool and WQ now hit
820:35 - the enter and you will be out from the
820:38 - vi editor right so here I created a file
820:41 - the file name was EnV and inside that I
820:43 - kept my open key now now if I will write
820:46 - this cat Dov so here you can see
820:50 - whatever content is there inside the EnV
820:53 - file I am able to see on my terminal
820:55 - right so open a API key and this is what
820:57 - this is my API key now guys what I will
821:00 - do here I will install all the
821:02 - requirements into my machine so here we
821:04 - have a requir txt file so what I will do
821:06 - here I will write a simple command and
821:08 - see guys if you are using Linux machine
821:11 - if you're using Mac OS so instead of
821:13 - writing pip or instead of writing python
821:15 - you all you must uh uh you must write
821:18 - over here pip 3 right so here what I'm
821:20 - going to do I'm going to write down pip
821:21 - 3 pip 3 uh install pip 3 install hyphen
821:25 - R require. txt right so this is my file
821:28 - name now I'm installing all the
821:30 - requirement in my machine so here once I
821:32 - will hit enter so here you can see uh
821:35 - okay it is asking sudo AP install Python
821:38 - 3 fine guys so I forgot to install
821:41 - python over here it is giving me a
821:43 - command see as soon as I've return this
821:45 - P inst install hyphen ar. txd it is
821:47 - giving me an issue it is giving me an
821:48 - error that pip 3 not found because I
821:51 - forgot to run one command here the
821:53 - command was for installing the python so
821:56 - let me write it down over here Pudo Pudo
821:59 - AP Pudo AP install so here I'm writing
822:03 - sudo AP
822:05 - install and after installation after
822:08 - install what I will write I will write
822:10 - python python and Python 3 Hy pip okay
822:15 - okay so this is the command which you
822:17 - need to write it down Pudo APD install
822:19 - Python 3 hyen pip so once you will hit
822:22 - enter now here you can see now here you
822:25 - can see we are able to install the
822:28 - requirement so yes we are going to
822:30 - install this python now once I will
822:32 - press yes here so now I'm uh able to
822:36 - install it and it is installing in my
822:44 - system
822:54 - yeah so if you getting this warning just
822:56 - press enter and here also now everything
822:59 - is done so see guys uh here is what here
823:02 - is my complete python which I downloaded
823:06 - in my system which I installed now let
823:09 - me do one thing here what I can do on my
823:11 - machine itself I can install the
823:13 - requirement file so for that let me
823:15 - clear it first of all and here I'm
823:17 - writing pip install iphr requirement.
823:20 - txt now let's see okay pip install the
823:26 - command is PIP
823:33 - install inss
823:37 - install I think now it is
823:40 - perfect
823:44 - yeah so see I installing all the
823:46 - requirements over
823:53 - here what is the issue we faced
823:55 - yesterday on top of the neural lab there
823:57 - was not the issue actually if you will
823:59 - use my updated code right so I updated
824:02 - everything over there so uh like it will
824:04 - be running the issue basically it was
824:06 - the uh regarding dependency maybe it
824:09 - took python 3.8.0 because of that only
824:12 - it was giving me the library issue but
824:14 - if you are using uh now just do one
824:16 - thing use equal to equal to sign over
824:18 - there pip install sorry cond create
824:20 - hyphen uh cond create hyphen P
824:23 - environment name python equal to equal
824:24 - to 3.8 so it will take 3.8.8 right so it
824:28 - won't give you any such of uh any any
824:30 - issues and all right now here guys see I
824:32 - have installed the require. txt now what
824:34 - I will do here I will run my application
824:38 - right after setting up the machine after
824:40 - installing the python after installing
824:42 - the requirements and all now here what I
824:44 - will do I will be writing stre stream
824:45 - late right so let let me give you the
824:47 - command there is a specific command for
824:49 - that now here is the command so let me
824:53 - copy this command and let me paste it
824:56 - over here so this is the command guys
824:57 - don't worry I will give you all the
824:59 - commands and I will revise this thing uh
825:01 - then I will give you that so here is a
825:03 - command Python 3 hyphen M streamlit run
825:06 - and here I need to provide my file name
825:09 - I'm removing this app.py and here I'm
825:11 - going to write down streamlit app.py
825:14 - right so here is a like file name
825:16 - streamlit app.py so this is the complete
825:19 - Command Python 3 hyphen M streamlit run
825:22 - streamlit
825:24 - app.py right so let me hit enter now and
825:27 - here you can see my application is
825:29 - running now how you can access this
825:32 - application so for that let me show you
825:35 - so just go through with your instance
825:36 - right now here is the instance here you
825:38 - will find out the public IP address
825:41 - right so here you can see this public IP
825:43 - address just just copy this address and
825:45 - here just open your browser and um then
825:49 - paste your address after copying this
825:50 - address copy this U public IP address
825:53 - and uh put the colon and here you need
825:56 - to mention the port number so by default
825:58 - actually this uh this one this
826:00 - application ring on
826:03 - 8501 right on 8501 now if I will hit
826:07 - enter will I be able to run it no
826:10 - actually we haven't configured this
826:12 - particular port number right so what I
826:15 - need to do here let me open my
826:17 - application now here just go inside this
826:21 - security right and uh here just a wait
826:25 - so let me go
826:27 - back ec2 instance here is a
826:33 - instance
826:36 - yeah now open the instance by clicking
826:39 - on the ID now here guys you will find
826:42 - out
826:43 - so this inbound rule let me show you
826:46 - that inbound
826:58 - rule yeah so here just click on the
827:00 - security group right and after that you
827:02 - will find out the uh this particular
827:05 - rule so just click on this edit inbound
827:08 - rule this one after Security Group
827:10 - Security Group info and addit inbound
827:12 - Rule now here add rule right now just
827:15 - keep it custom TCP and here you need to
827:17 - write it down your port number so your
827:19 - port number is what
827:21 - 8501 and then keep it custom and click
827:25 - on this uh just select this one anywhere
827:28 - only now everything is done so here you
827:30 - need to keep it custom TCP then uh give
827:33 - your port number here and keep it
827:35 - anywhere that's it right now save the
827:37 - rules that's it okay and uh let me do
827:40 - one thing I think uh this is running so
827:44 - let me first press press control+ C and
827:46 - again I can run this particular
827:47 - application so yeah now it's perfect uh
827:51 - so just go through with your application
827:53 - here and here itself you will find out
827:58 - the here itself you will find out the IP
828:02 - address so let me open the IP address
828:03 - just a
828:06 - second instance running now this is your
828:09 - instance McQ generator click on that and
828:14 - here is your IP this one 52 this one
828:17 - this is your IP right 52.
828:19 - 20414 and 155 now copy this ID and paste
828:23 - it over here in your browser so now let
828:26 - me check 155 yeah it is correct so just
828:30 - uh press the colum and give 8501 now
828:33 - once you will hit enter so you will be
828:35 - able to find out your application over
828:37 - here just a second it is running let's
828:43 - see yeah so here guys you can can see I
828:46 - have deployed the application and now
828:47 - you all can access this particular
828:49 - application I'm giving you inside the
828:51 - chat and try to generate the try to
828:55 - generate the mcqs from here now let me
828:58 - do it I'm giving you this particular
829:00 - link inside the chat just click on that
829:02 - and try to generate it now here if I'm
829:05 - clicking on this browse file now it is
829:07 - asking to me it is asking me about the
829:09 - file so here I'm giving this a do just
829:12 - open it and give the number of cues
829:14 - let's say I want to generate four mcqs
829:17 - here uh write the subject name so my
829:19 - subject is going to be Ai and here write
829:22 - the simple and then create McQ and it is
829:27 - loading here you can see guys it is
829:30 - loading now see let's see it is able to
829:32 - generate or
829:35 - not are you doing it guys along with me
829:38 - have you uh like run any sort of a
829:40 - command don't worry let me give you all
829:42 - the command at a single place and then
829:44 - you can check you can run inside your
829:46 - system I will give you 2 minute of time
829:48 - yeah so here you can see I'm able to
829:50 - generate a quiz so what is the field of
829:52 - study that develops and study
829:54 - intelligence Machin so these are the
829:56 - choices and here is the answer right
829:59 - whatever correct answer is there now
830:01 - review is also their review about the
830:04 - McQ now click on this uh so just just go
830:07 - through with this URL and you also can
830:10 - generate now someone is asking me sir
830:12 - how we can save it right for saving the
830:14 - code prods for saving this McQ in a PDF
830:17 - file in a CSV file so already I shown
830:20 - you the code in my previous lecture if
830:22 - you will go inside the ipynb file so
830:25 - here I already kept the code so this is
830:27 - what this is what my code actually uh
830:30 - where is where it is where it is uh just
830:32 - a second just a second yeah so here was
830:35 - the code actually I converted into a
830:36 - data frame and here I converting into a
830:39 - CSV file now see uh I'm converting into
830:42 - a CSV file but you can convert the CSV
830:44 - file into a PDF
830:45 - or you can uh generate a direct PDF from
830:49 - here also right you just need to look
830:50 - into that and you can append this same
830:53 - functionality inside your end to
830:55 - application also so if you you you can
830:57 - give one option over there download
830:59 - option so whatever McQ you are getting
831:01 - now on top of your steamate application
831:04 - here itself see uh here uh whatever uh
831:07 - mcqs you are able to see over here right
831:09 - so you can provide one button over here
831:11 - right hand side download button so once
831:13 - the person will click on the download
831:15 - down the script will be running in a
831:16 - back end and you can download this McQ
831:19 - in a CSV file or in the form of uh PDF
831:22 - right so this you can take as assignment
831:24 - where you can append one button one
831:26 - download button and you can write it
831:29 - down the code write it down the
831:30 - functionality okay in a in a python
831:32 - actually you can uh like you can create
831:34 - one file or maybe inside that streamlet
831:37 - itself you can uh like append this
831:39 - download functionality right you can you
831:41 - can append this download over there and
831:43 - whenever someone is hitting the download
831:45 - this all the mcqs will be downloaded in
831:47 - the form of CSV right so just take it as
831:50 - a assignment and try to do it and you
831:52 - can send it to me on my mail ID or maybe
831:55 - on my uh yeah so you can uh ping uh you
831:59 - can ping me on my LinkedIn and you can
832:01 - post it over the LinkedIn also right so
832:03 - after creating this if you are going to
832:05 - post it over the LinkedIn I think that
832:07 - that is well and good so uh and uh yeah
832:10 - so let's say this is your first end
832:12 - project and let's say first time if you
832:15 - learning the generative definitely you
832:16 - should uh you must share the knowledge
832:19 - over the LinkedIn as well so you can uh
832:21 - post it over there and you can tag me
832:23 - and all you can tag the Inon I think
832:26 - that would be fine now uh here see we
832:29 - are able to create the application we
832:31 - are able to deploy it I haven't shown
832:33 - you the cicd one I this is the manual
832:35 - approach which I shown you I kept the
832:37 - cicd for the next project I can show you
832:39 - here also I don't have any issue I can
832:41 - write it on the workflow I can deploy
832:43 - the application that not going to be
832:45 - difficult but as a beginner first you
832:46 - should adapt the like basic approach you
832:49 - should understand the server and all and
832:51 - uh you should be familiar with the AWS
832:53 - and then in the next project we are
832:55 - going to do it from scratch right so I
832:57 - will show you the complete cicd and yeah
833:00 - definitely in our course uh we have
833:02 - included so many projects so there uh we
833:05 - are going to deploy it over the
833:06 - different different platform AWS a your
833:09 - gcp and we are going to use AWS ECR okay
833:14 - or this AWS ec2 app Runner and this uh
833:18 - like different different services like
833:20 - elastic code commit uh elastic be stall
833:23 - code commit even uh Lambda function
833:25 - right so different different uh thing
833:27 - different different Services of the AWS
833:30 - we are going to use and we'll show you
833:31 - how uh you can create or and an
833:34 - application in how you can create a
833:36 - production production based pipeline
833:38 - right so this thing is clear
833:42 - now if uh it is clear then definitely we
833:45 - can move to the next topic but before
833:48 - that let me give you all the command
833:49 - which is required and let me keep
833:52 - everything inside this uh txt itself so
833:57 - see the first thing what you need to do
833:58 - guys for deploying this
834:00 - application first login to AWS so first
834:05 - login to the
834:07 - AWS and here I'm giving you the link of
834:10 - the AWS so you can uh login with that
834:13 - particular link M just a
834:18 - second AWS login now let me give you the
834:23 - link of the
834:25 - AWS
834:27 - yeah so here first you need to uh log to
834:30 - the aw the second what you need to do
834:32 - guys you need to like launch the ec2
834:35 - instance so search about the ec2
834:39 - instance search about the ec2 instance
834:43 - now after search searching the ec2
834:45 - instance what you need to do the third
834:47 - place uh you need to you need to
834:50 - configure configure the ubu machine
834:53 - ubu ubu
834:56 - machine machine right so that's the
834:59 - third thing now fourth one actually what
835:01 - you need to do after configure the one
835:03 - to machine launch the instance right
835:05 - launch the instance that's the fourth
835:07 - step after launching the instance what
835:10 - you will do after launching the one two
835:11 - instance so you need to update this by
835:13 - using a different command so I will give
835:15 - you all those command three command I
835:18 - have already written over here let me
835:19 - write it down the uh further command so
835:22 - here is the thing update the update the
835:26 - machine right so update the machine and
835:28 - here is all the command let me give you
835:30 - forur command uh here is upgrade now
835:34 - this is going to be a next
835:36 - one and here there is going to be next
835:39 - you need to clone your GitHub repository
835:42 - and after that there is a next command
835:45 - so sud sudo AP install this is the next
835:49 - now here uh pip install regard. txt and
835:53 - here this is going to be a next command
835:56 - for running your application so if you
835:59 - want to run the application now here is
836:01 - a command and the app name is what
836:04 - stream
836:05 - St stream
836:09 - lit app right so this is the command
836:12 - which you need to run right and then
836:14 - finally
836:15 - copy the IP and huh uh then what you
836:17 - need to do guys you need to add the
836:19 - environment file EnV file also so for
836:22 - adding that uh there is a command let me
836:25 - write it down over here if you want to
836:29 - add open AI API key so here the first
836:34 - thing
836:36 - create create Dov file Dov file new
836:41 - server right so create do EnV file in
836:45 - your server now here after creating this
836:49 - EnV file how will you will create it by
836:50 - using this particular command touch. EnV
836:54 - now here what you will do you will
836:56 - insert you will press insert so press
836:58 - insert insert and then write it uh no
837:02 - after creating that you need to open it
837:04 - and actually by using the vi editor so
837:05 - VI and that WR Dov then you need to
837:09 - write it down some command so press
837:11 - insert from your keyboard and after that
837:14 - after pressing the insert you have to
837:15 - write it down something so copy your API
837:18 - key and paste it
837:20 - there and paste it there the next one
837:24 - actually the next is going to be so
837:27 - after the copy you need to save it so
837:29 - press escape and then colon WQ so colon
837:34 - WQ and hit enter right so hit enter so
837:38 - that's going to be a step now after
837:40 - adding the API key what you need to do
837:43 - so yeah this will be done then uh this
837:47 - is the step for adding the API key now
837:49 - yeah inbound rule so go with your
837:51 - security go with your security and add
837:57 - the inbound rule right so here actually
838:01 - you need to add the inbound rule there
838:03 - add the
838:05 - port add the port 85 01 right this one
838:10 - so this is the complete detail of the
838:11 - deployment which I have written over
838:13 - here now let me copy it and let me paste
838:15 - it over here inside your inside my
838:17 - GitHub itself so here is my readme file
838:21 - uh I don't have readme file so don't
838:23 - worry I can edit create a new
838:28 - file my file name is what
838:32 - readme.md just readme.md and
838:43 - here
838:52 - yeah so this is the entire command which
838:54 - I kept over here now let me click on the
838:56 - commit
838:57 - changes and here I'm going to commit so
839:01 - see guys this is the entire process for
839:03 - the deployment okay now let me give you
839:06 - this link so you all can do
839:09 - it inside your
839:13 - system so this is the link guys uh which
839:16 - uh where I kept all the steps you can
839:19 - follow it and you can deploy your first
839:21 - and to and uh first application
839:24 - basically now tell me yes this file will
839:27 - be available inside the notes don't
839:28 - worry don't worry about it
839:32 - so let me check with more
839:36 - doubts this uh file you will get inside
839:38 - the dashboard see this is a dashboard
839:40 - guys this is a like Genera VI dashboard
839:43 - now again I can give you this link
839:45 - inside the chat and already you can see
839:48 - my team has updated right so inside the
839:50 - chat if you will check with the pin
839:51 - command so my team has updated the link
839:54 - of the dashboard right and just go
839:56 - through the Inon platform just just
839:58 - search about the Inon okay just open
840:00 - your Google search about the Inon and
840:01 - this is the homepage now here in the
840:04 - courses there is a section Community
840:07 - program so just click on the community
840:09 - program and here itself you will find
840:11 - out the category so just click on this
840:13 - generative AI so there you will find out
840:15 - all the dashboard so here you just need
840:17 - to click on the English one uh here we
840:19 - have a Hindi dashboard as well I'm
840:20 - taking the same lecture and On Hindi
840:22 - YouTube channel so yeah we we have a
840:24 - Hindi dashboard now here is a English
840:27 - dashboard and this is a community
840:29 - session of the machine learning so each
840:31 - and everything you can find out over the
840:33 - Inon platform let me give you the uh
840:36 - this particular link so that you can log
840:39 - in if you are new guys so that uh so
840:42 - please try to log in on this I own
840:54 - portal how how we can apply llm for
840:58 - business inside chat like interacting
841:00 - with DB and perform complex computation
841:02 - task yeah that only we are going to
841:04 - discuss now so we'll talk about that how
841:07 - we can uh like create a complex
841:10 - application here the foundation I think
841:12 - the foundation is clear to all of you
841:14 - now we'll come to the advanced part
841:17 - where we'll include the databases where
841:19 - we'll try to create few more application
841:21 - like chatbot and all and yeah that thing
841:25 - will be clarified to all of you just
841:27 - wait for some
841:31 - time so tell me guys how's the session
841:34 - so far do you like it so please hit the
841:36 - like button if you are liking the
841:37 - session
841:41 - uh and please do let me know in the chat
841:44 - also how's the session so far because we
841:47 - have completed a one phase now we are
841:50 - entering into the second
841:52 - phase yeah waiting for a reply so please
841:56 - write it down the
842:13 - chat
842:36 - you are not getting any link
842:40 - uh linkwise don't worry my team will
842:43 - give you that give uh that particular
842:45 - link inside the chat itself if I'm not
842:47 - able to paste it then but I past it
842:50 - actually I I can see here in my
843:02 - chat here we have already pinned one
843:05 - comment just just look into the Pinn
843:07 - comment so there you will find out a
843:09 - dashboard and you can navigate the
843:10 - entire dashboard and all entire website
843:12 - from there itself so just check with the
843:14 - pin
843:25 - comment so deependra has given to me
843:28 - this uh IP and this uh Port so let me
843:32 - check it is working or not he's saying
843:34 - sir I'm following you and this is my IP
843:38 - and my port
843:42 - actually no see it's a wrong I think
843:45 - just check once thein I think uh there
843:49 - is just like uh in IP V4 actually we
843:53 - have a four segment now so just look
843:55 - into your IP I think you pasted a wrong
843:57 - one see this is the
844:00 - correct
844:12 - right great
844:14 - so let's start uh with the next topic
844:17 - and that's going to be a vector database
844:20 - so we have completed a one phase of this
844:23 - uh Community session now it's a second
844:25 - phase of this community session where we
844:27 - going to start from the vector databases
844:29 - and then we'll try to do few more
844:32 - advanced uh like we'll try to solve few
844:34 - more advanced use cases so the first
844:37 - thing is basically what is a vector
844:39 - databases so how many of you know about
844:41 - the vector guys tell me do do you have a
844:44 - basic idea about the vector what is a
844:46 - vector and uh have you learned in
844:49 - machine learning in
845:12 - statistic great so I think uh we can
845:15 - start just allow me a
845:34 - minute great so let's start with the
845:36 - vector database few people are saying
845:38 - they know about the vector databases and
845:40 - the vector is nothing they have learned
845:42 - in a mathematic they have learned in NLP
845:45 - and all so uh let's try to understand
845:47 - the fundamental of the vector and the
845:49 - fundamental of the vector databases so
845:52 - if we talk if we talking about this
845:54 - Vector database so here you will find
845:56 - out that so we have a data right so this
845:59 - data actually we are going to convert
846:02 - into a vectors so Vector is nothing just
846:04 - a set of numbers right it's just a set
846:07 - of number geometrically I will explain
846:09 - about the vector in a lit term also I
846:11 - will about I will explain about this
846:13 - vector
846:14 - now here you can see this Vector
846:15 - actually we are going to store somewhere
846:17 - and that is called a vector database
846:20 - right so we have a data we are going to
846:22 - convert that data into a vectors and
846:25 - then uh basically this Vector we are
846:27 - going to store somewhere now here you
846:29 - can see one specific term the term is
846:32 - called Vector database now apart from
846:34 - that like we have other database also
846:36 - like SQL base database right we have no
846:39 - SQL databases so why we are not using
846:42 - those databases for storing the
846:44 - embedding for storing this data what is
846:47 - a disadvantage if directly we are
846:49 - storing this data into this SQL based
846:52 - SQL based database or maybe in no SQL
846:55 - database so what will be the
846:57 - disadvantage why we are converting this
846:59 - data into our vectors and then we are
847:02 - storing inside the vector databases so
847:04 - first of all we need to understand this
847:06 - a particular this this problem statement
847:09 - now uh for that what I can do let me
847:12 - move into the slide itself and here I
847:15 - have kept those uh thing now first of
847:18 - all uh let me uh show you that what all
847:20 - thing we are going to learn inside this
847:22 - Vector database so if we talking about
847:24 - the vector database so we're going to
847:25 - talk about what is a vector database why
847:27 - we need it what is the need of this
847:30 - Vector database how this Vector database
847:32 - is how will this Vector database work
847:34 - use cases of the vector databases some
847:37 - widely used Vector database that of like
847:39 - different different databases we have
847:41 - now so we'll try to understand the use
847:44 - of those Vector database will understand
847:47 - the Practical demo as well practical
847:49 - demo using Python and Lang chain so uh
847:52 - yes we are going to create an
847:53 - application there we are going to use
847:55 - different different Vector databases
847:57 - like pine cone and web chroma DV there
848:00 - are a couple of name and more than uh
848:03 - like uh this one actually three so we
848:06 - have other databases also one from the
848:08 - open a side so we'll talk about each and
848:11 - every database here so uh here guys you
848:13 - can see uh what we are going to learn so
848:15 - already I clarifi the agenda now see uh
848:18 - what is a vector database so a vector
848:20 - database is a data Bas used for storing
848:23 - high dimension vectors such as word
848:25 - iding or image aming right so either we
848:28 - can store images or we can store in in
848:32 - the form of we can store the images or
848:35 - we can store the text right so directly
848:38 - we are not storing over here we are
848:40 - storing in the form of Ming so first of
848:43 - all we'll try try to understand the
848:44 - meaning of embedding over here right so
848:46 - what is the meaning of the embedding
848:48 - which I have written now what I can do I
848:51 - can open my uh Blackboard and here I can
848:53 - explain you the meaning of the embedding
848:56 - which I was talking about so guys see
848:58 - whenever we are talking about Vector so
849:01 - let let me write it down the few thing
849:02 - over here so let's say uh here I'm
849:05 - writing one number right so here I'm
849:07 - writing let's say uh two so what is this
849:09 - two tell me so if I'm writing two over
849:12 - here so this is what this is the scale
849:13 - scal value right this is the scalar
849:15 - value now uh here if I'm going to write
849:17 - it down let's say uh something else
849:20 - let's say 100 so this is what this is
849:21 - also a scalar value right it's a single
849:24 - value it's a scalar value now if you if
849:26 - you want to like uh showcase this value
849:29 - in a geometrical in a geometry right in
849:31 - terms of geometry so what I will do I
849:33 - will uh create the axis so here let's
849:34 - say this is what this is my Axis and
849:36 - here somewhere actually my value will be
849:38 - available this data so here let's say
849:41 - there is a two there is a 100 something
849:43 - like that now uh here this is called the
849:46 - single value actually it is called the
849:47 - scalar value now if we are talking about
849:50 - the vector so what is a ve Vector so
849:52 - before explaining the vector actually
849:54 - let me uh talk about so here I can give
849:57 - you one uh example so what I can do here
850:00 - just a second let me draw the AIS so
850:03 - here I'm going to draw the first AIS
850:05 - this is my first AIS and here is my
850:08 - second now let me take this particular
850:11 - Arrow just a second yeah so this is what
850:14 - this is my first AIS this one and here
850:17 - is what here is my second AIS right now
850:20 - let's say uh here what I'm doing so I'm
850:23 - uh anting this thing this AIS with the
850:27 - uh direction right so this is my North
850:31 - this one and here this is going to be my
850:36 - South right this is my South Direction
850:39 - now here is what here is my East and
850:42 - this is what this is my West right so
850:44 - this is my East and here is what here is
850:47 - my West Direction right now let's say
850:50 - one person is here right so this one
850:53 - person basically one person is here
850:55 - right now how you will see uh let me
850:58 - show you one thing so let's say one
851:00 - person is going in this particular
851:02 - direction from here to here right so
851:04 - let's say one person is going here here
851:06 - here here here let's say there is some
851:07 - sort of a magnitude right so let's say
851:09 - the person is uh uh person is walking
851:12 - around 5 km right so this person is
851:14 - walking 5 km in which direction in East
851:18 - direction right so person is walking 5
851:20 - km in each dire in each Direction so
851:23 - here we have a magnitude magnitude along
851:26 - with that we have a direction right so
851:28 - along with that we have a Direction so
851:30 - what is the definition of the vector so
851:32 - Vector in the vector actually we have a
851:34 - scalar value and along with the scalar
851:36 - value will be having a direction also
851:39 - right so this is what this is my
851:40 - magnitude and here is what here is my
851:42 - direction the direction is e East now
851:44 - let's say if I'm going in this
851:46 - particular direction so from here from
851:48 - my origin this is my origin right now
851:51 - from here I'm going in this particular
851:52 - direction let's say I'm going to travel
851:54 - 4 kilm right 4 km so here I can say that
851:58 - I traveled 4 km 4 km in North direction
852:02 - right so this is what this is my
852:04 - magnitude and here is what here is my
852:06 - direction right now let's say the person
852:08 - is going over here the person is here
852:10 - basically here here right so how you
852:13 - will calculate it right so how you will
852:15 - calculate the distance so simply I can
852:17 - do it by using the Pythagoras Theorem so
852:19 - what I will do if I want to calculate a
852:21 - distance from my origin to this
852:23 - particular point so what I will do I
852:25 - will uh like uh I will do it by using
852:28 - the Pythagoras thorum now here uh you
852:31 - will find out see this is what this is
852:33 - my 5 kilm and here is what here is my 4
852:36 - km this is my 4 km now uh this is what
852:39 - this is my 4 km this one this this
852:41 - particular which I took from here and
852:42 - here actually tell me guys what will be
852:44 - the distance from here to here so here I
852:46 - will simply use the Pythagoras Theorem
852:48 - this is going to be a 5 + 4 is equal
852:52 - to how much tell me 25 + 25 + 9 so sorry
852:57 - 25 + 16 so here actually we'll be having
853:00 - a 16 now 25 + 16 how much U 35 and 41
853:06 - iting right so underscore 41 now here
853:10 - actually this is the magnitude of the
853:13 - person means from here to here now if we
853:15 - are talking about the direction right so
853:17 - what will be the direction of this
853:19 - person so here I can write it down like
853:21 - this underscore underscore 41 and here I
853:25 - can write it down this northeast right
853:28 - Northeast Direction so this is what guys
853:30 - tell me this is my Vector in 2D so this
853:33 - is a vector in 1D this is a vector in 2D
853:36 - right so this is a vector in 1D this one
853:39 - this is also a vector in 1D and here you
853:41 - can see this is what this is a vector in
853:43 - 2D now here you can see this is what
853:45 - this is my magnitude magnitude of the
853:48 - vector and here is what here is a
853:50 - direction actually this is what this is
853:52 - the direction now you can see the
853:53 - direction any now let's try to
853:56 - understand this thing with our X and Y
853:58 - right so tell me guys this uh example is
854:00 - clear to all of you because I'm coming
854:02 - to the embedding and I I will explain
854:04 - you the embedding but before that the
854:06 - vector concept should be clear right if
854:09 - uh and if you are not going to
854:10 - understand the vector so definitely
854:11 - won't be understand the concept the
854:14 - embedding tell me guys this thing is
854:16 - clear to all of you are you getting the
854:19 - concept of the vector here which I drawn
854:22 - which I uh
854:30 - clarify tell me guys fast I'm waiting
854:32 - for your reply if you can write on the
854:34 - chat so that would be great and then I
854:37 - will proceed
854:42 - further
854:49 - yes the vector definition is clear to
854:53 - all of
855:03 - you great now here see let's try to
855:06 - understand the same concept by using the
855:08 - XY AIS so here what I'm going to do I'm
855:11 - going to draw the axis let's say this is
855:13 - my x-axis right and here is what here is
855:16 - my Y axis this one is what this one is
855:18 - my Y axis right this one now see uh what
855:22 - I can do just a second let me draw it
855:24 - one more time this is my y AIS now uh
855:28 - let me unoted this one so here is the X
855:32 - and here is what here is a y so this is
855:36 - my x one and this is my X y1 right so
855:39 - this is a negative this is representing
855:40 - a negative and this is also negative
855:41 - coordinate now see guys here uh let's
855:46 - say uh there is one point right at this
855:49 - particular location this is what this is
855:51 - my point right now will be having some
855:55 - coordinate regarding this point tell me
855:57 - x and y coordinate yes or no tell me yes
856:01 - so this coordinate actually this X and Y
856:04 - right in this 2D space right in this 2D
856:07 - space actually this coordinate is
856:09 - nothing this is a vector right this is
856:12 - the vector so if I want to represent
856:15 - right so if if I want see this is what
856:17 - this is my point in 2D in two Dimension
856:19 - space now from here to here there will
856:22 - be having some magnitude right so it is
856:24 - having some magnitude from here from
856:27 - Orizon to to this particular point so
856:30 - this magnitude plus this is what guys
856:33 - tell me this is the direction the
856:34 - direction which I shown you over here by
856:37 - using this north east west and by using
856:40 - this uh like north south east west right
856:43 - so here now instead of that I'm taking
856:45 - this X and Y just just look over here
856:47 - this is what this is my point and from
856:49 - origin to this particular Point actually
856:51 - we have some magnitude right so there is
856:54 - a distance and here is what guys tell me
856:57 - this is a this is what this is the
856:58 - direction this is a Direction X and Y so
857:01 - let's say let's say what I can do over
857:03 - here so this x and y coordinate I'm
857:04 - assuming that this x is around I think
857:07 - five and this Y is around let's say four
857:11 - so here I can write it down I can
857:12 - represent I can represent this
857:15 - particular Point like this I can write
857:16 - it down over here five and four and this
857:19 - is nothing this is my Vector so in
857:22 - mathematics what is a vector so in
857:23 - mathematics magnitude magnitude along
857:27 - with the direction right along with the
857:29 - direction now how we represent this a
857:32 - particular Vector technically so simply
857:35 - if I'm writing like this uh like if I'm
857:37 - writing like this X and Y right and
857:40 - whatever value we have of the X and and
857:42 - Y so this is what this is nothing this
857:44 - is my vector and it's a 2d
857:46 - representation of the vector now let's
857:49 - say in my Vector I have I'm having X Y
857:52 - and Z let's say I'm having this three
857:54 - thing x y z so this's a vector in 3D
857:58 - space right this is the vector in 3D
858:00 - space now instead of this one let's say
858:01 - if I'm writing uh X1 here I'm writing X2
858:05 - here I'm writing X3 and up to xn so here
858:08 - I'm saying it's a vector in N Dimension
858:12 - space what is this guys tell me it's a
858:14 - vector in and dimension space now the
858:17 - term Vector is clear to all of you what
858:19 - is a scalar what is a vector and how to
858:22 - represent this Vector it's a
858:23 - representation of the vector right and I
858:26 - started from here from this a particular
858:28 - direction and I clarify clarify this
858:31 - thing over here right so how to
858:33 - represent the N Dimension Vector so this
858:35 - is this X and Y is nothing it's a 2d
858:37 - representation of the vector this XY Z
858:39 - is nothing it's a 3D representation of
858:41 - the vector and this this is nothing this
858:43 - is the and dimensional representation of
858:46 - the vector clear I think this part is
858:49 - clear to all of you now I'm coming to
858:51 - the next one here actually we are
858:54 - talking about the iding now what is this
858:56 - embedding so let's talk about this
858:59 - embedding let me write it down here the
859:02 - name is embedding okay now see guys
859:06 - whenever we are talking about a model
859:09 - right so here actually as a
859:10 - model I'm using the llm model which
859:14 - model U I'm using the large language
859:17 - model llm means what large language
859:19 - model there are several large language
859:21 - model from open a from hugging face from
859:23 - Google meta and all right you'll find
859:26 - out that now here actually I need to
859:28 - provide a data to this a particular
859:31 - model right let's say there is what
859:33 - there is my data which I'm going to
859:35 - provide to my
859:37 - model right now actually see this model
859:40 - is nothing it just done
859:43 - mathematical equations right
859:45 - mathematical
859:47 - equations so we are talking about the
859:49 - llm model so this llm model this large
859:52 - language model actually they are using a
859:55 - Transformer architecture they are using
859:57 - Transformer architecture as a base
860:00 - architecture which architecture
860:01 - Transformer architecture as a base
860:03 - architecture so here in the Transformer
860:05 - architecture we have two things one is
860:07 - encoder and the second one is called
860:10 - decoder right now just think about this
860:12 - encoder and decoder here actually what
860:14 - we are doing tell me here actually see
860:17 - we have a attention mechanism we have a
860:20 - neural network right we have a
860:23 - normalization so these all are nothing
860:26 - this is just a mathematical equations
860:28 - right ma mathematical operations we are
860:31 - going to perform now here the data let's
860:33 - say we are passing a text
860:34 - data right if are passing this text data
860:37 - to my model so my equation actually they
860:40 - won't adapt this text Data directly ly
860:43 - they won't adapt actually this text Data
860:45 - directly right they won't be adapting it
860:48 - actually this text data now uh in
860:50 - between actually what I I will do so in
860:53 - between I will encode it what I will do
860:56 - guys tell me I will encode this data
860:58 - right so what I will do I will encode
861:01 - this particular data now what is the
861:03 - meaning of encode so here in between
861:05 - actually I will perform the encoding now
861:08 - we have a various ways of encoding the
861:10 - data encoding is nothing it's just a
861:13 - numerical representation right it's just
861:15 - a numerical representation of the data
861:18 - right numerical representation of the
861:21 - data now we have two ways for encoding
861:23 - the data one is without so here uh the
861:28 - one is without without DL right which is
861:33 - simple frequency based method and the
861:36 - second is one with DL right with deep
861:41 - learning so we talking about without
861:43 - deep learning so there are couple of
861:45 - methods for encoding the data right so
861:48 - the first method which I can write it
861:50 - down over here that is I think you
861:52 - already knows know about this particular
861:54 - method the first method is a document
861:57 - Matrix document Matrix right so uh we
862:01 - create a document Matrix the second one
862:04 - the second method that is one that is
862:06 - called T tfidf method right so by using
862:08 - this TF IDF method also you can do the
862:11 - encoding so document Matrix is there
862:13 - this is also called like uh bag of words
862:16 - right bag of words now here you will
862:19 - find out the the third one let's say n g
862:22 - is
862:24 - there and the fourth one let me write it
862:27 - down here tfid is there andram is there
862:30 - document Matrix is there here you will
862:33 - find out one hot en coding right so this
862:36 - is also a technique now one more
862:39 - technique is the integer
862:41 - encoding integer and coding so this is
862:45 - actually uh like uh this is a without
862:49 - deep learning I converting a data into a
862:52 - so without deep learning I'm going to
862:54 - converting a data into a numeric uh I I
862:56 - creating a data into a u uh like I'm
863:00 - showing the data in a numeric U I'm
863:01 - doing a numeric I'm showing a numeric
863:03 - representation actually right so here we
863:05 - have a document Matrix DF IDF engram one
863:08 - encoding and integer encoding now there
863:10 - are several there are some disadvantage
863:13 - of this particular technique then I will
863:15 - come to this with DL okay let me write
863:17 - down the name also like with DL
863:18 - technique so here you will find out word
863:20 - to back right word to back is there
863:23 - which is very famous technique the
863:25 - second technique uh which has been prop
863:27 - proposed by the Facebook site that is a
863:30 - fast text now the third one you will
863:33 - find out that a Elmo right Elmo now here
863:38 - uh the fourth
863:39 - one what to back is there fast Tex is
863:42 - there Elmo is there even BT is there by
863:45 - using the B and and coding we can do
863:48 - that right so DL based technique now
863:50 - there is one more technique that is
863:52 - called this one glove Vector so actually
863:55 - glove is not DL based it's a metric
863:59 - Matrix factorization based right so
864:02 - Matrix factorization it's a matrix
864:05 - factorization uh
864:07 - method right so this glove Vector now we
864:10 - have so many technique for encoding data
864:12 - right now here if we are talking about
864:15 - this uh this particular technique where
864:18 - we are just like talking about the
864:20 - frequency of the data so there are
864:22 - several disadvantage of this right so
864:24 - definitely we are going to convert our
864:26 - data right from uh text to numeric uh
864:30 - text to numeric value right we are doing
864:33 - it by using this particular method but
864:35 - here are several disadvantage the first
864:37 - disadvantage actually which I can write
864:38 - it down over here that is what that is a
864:41 - uh like by using this technique right so
864:45 - at we we are by using this particular
864:47 - Technique we are ending up with the
864:49 - sparse Matrix right so we are ending up
864:52 - with the sparse Matrix what is the
864:54 - meaning of the sparse Matrix so in the
864:56 - sparse Matrix you will find out there
864:58 - are more number of zero there is less
865:01 - information right so that is called a
865:03 - sparse Matrix now the second is what
865:05 - this is here actually you won't be
865:07 - preserve your context right so here
865:10 - actually you won't be able to preserve
865:12 - context now you this this embedding this
865:15 - this number this a numeric
865:16 - representation basically which you are
865:18 - getting of your data this is meaningless
865:21 - right this is meaningless so here this
865:23 - is going to be a meaningless and you
865:25 - won't be able to preserve any sort of a
865:27 - context right so if you are going to
865:30 - convert your data right if you are going
865:32 - to convert your uh data into a numeric
865:36 - value by using this particular technique
865:39 - I'm not going to I'm not going into
865:41 - depth actually I I can show you the uh
865:43 - how to calculate and all but as of now
865:45 - I'm just giving you the overview
865:47 - advantage and disadvantage so by using
865:49 - this technique there is these U there is
865:51 - a different different like disadvantage
865:53 - of it there is two major disadvantage
865:54 - which I have highlighted one is sparse
865:56 - metrix and the second one is context
865:59 - contextless right so meaningless there
866:01 - is no there won't be any such meaning
866:03 - actually whatever vector and the numeric
866:07 - value which you are going to generate
866:08 - right now over here see if we are
866:11 - talking about our data let's say we are
866:13 - talking about the text here is a what
866:16 - here is a text so text is nothing
866:18 - actually here it's a collection of
866:20 - sentence right sentences now it's a
866:23 - collection of the phrases don't worry I
866:25 - will show you each and everything
866:26 - practically by using the python and here
866:29 - in the sentence phrases actually you
866:31 - this is the collection of words or
866:33 - tokens this is called word or it is
866:35 - called a tokens right fine now whenever
866:38 - we create whenever we perform this uh
866:41 - particular when whenever we use this
866:42 - particular technique so how we do that
866:45 - so let's say we have a data right we
866:47 - have a text so from that particular text
866:49 - what we do we generate a vocabulary
866:51 - right so we create our vocabulary and
866:54 - here let's say first what we what we do
866:56 - we create the vocabulary uh I hope the
866:59 - spelling is correct so we create our
867:01 - vocabulary and by using this vocabulary
867:04 - we perform the end coding right we
867:07 - perform the end coding so here we have a
867:10 - sentence we have a text we have a data
867:12 - now by using this data data after
867:14 - cleaning and all so we perform the
867:16 - cleaning so here we perform the cleaning
867:19 - and whatever data and all which I get
867:21 - and uh we collect the data we we we call
867:25 - it as a we call it vocabulary actually
867:28 - and by using this vocabulary we create
867:30 - the end coding right we create the end
867:32 - coding now over here see uh okay this is
867:36 - fine but here I shown you that we have a
867:38 - several disadvantage now um like there
867:42 - was several disadvantage of this
867:43 - particular technique and the major
867:45 - disadvantage was uh contextless okay
867:48 - contextless or meaningless because of
867:51 - that actually we were not able to retain
867:52 - the information so here a few more
867:56 - technique came into the picture this
867:58 - word two back actually it's a very
867:59 - famous technique this one okay is the
868:02 - old one also it's a famous one also now
868:05 - here the um the concept came into the
868:07 - picture the concept name was iding right
868:10 - so here see we were having the
868:12 - disadvantage inside this particular
868:14 - technique now the concept came into the
868:16 - P picture the concept was the iding
868:19 - concept so here what was the embedding
868:22 - concept so embedding also it's a numeric
868:25 - representation of the data so let's say
868:27 - we have a data now this data actually if
868:30 - I'm going to represent numerically so
868:32 - that is nothing that my embedding right
868:34 - so this embeding is nothing actually
868:36 - this was the vector right this is what
868:39 - this is a vector and what is a vector
868:41 - vector is nothing thing it's a a set of
868:43 - numbers right so we talking about the
868:45 - vector it is a set of number and how to
868:47 - showcase the vector how to represent the
868:49 - vector I already told you we represent
868:51 - the vector in this uh square bracket
868:53 - right technically if I have to represent
868:55 - the vector I represent like this and
868:57 - mathematically if I calculate it so yes
868:59 - so we talk about the direction plus
869:02 - magnitude so here m means what magnitude
869:04 - plus Direction so that is what that is a
869:06 - vector so we have a embedding so this
869:09 - embedding concept came into the picture
869:11 - now here also we are representing a data
869:13 - in terms of numeric value but the way
869:16 - was little different right so here
869:19 - actually we were able to achieve two
869:21 - things first one actually we are able to
869:23 - achieve the dense Vector right we are
869:26 - creating a dense vector and the second
869:28 - thing was the second thing was we were
869:31 - able to uh like sustain the meaning also
869:34 - so context full right context so
869:39 - context te X context full meaning right
869:44 - context full or meaningful meaningful
869:48 - right so we are able to achieve this two
869:51 - thing by using this embedding now let's
869:53 - try to understand this embedding by
869:55 - using this word to back so here again
869:58 - I'm not giving you too much detail
870:00 - regarding this embedding and all U
870:01 - regarding this word embedding es uh esip
870:04 - gr right or CBO method scheme gra method
870:08 - right so there are different different
870:09 - method we have inside the word itself
870:11 - but here uh let me give you the high
870:13 - level overview that how it was working
870:16 - why I'm doing that because the next
870:18 - concept is directly related to the
870:20 - embedding only if you're not able to get
870:22 - it uh if uh this Basics uh if the basics
870:26 - won't be clear here that definitely you
870:28 - will face a several issues so that's why
870:30 - first I'm clarifying this a basic thing
870:33 - so tell me guys are you getting it right
870:35 - so whatever I'm trying to explain over
870:37 - here regarding the vector embedding data
870:40 - different different technique of the
870:41 - embedding so are you getting my point
870:44 - yes or no tell
870:47 - me are you able to understand the
870:51 - concept if you are getting it if you are
870:53 - able to understand that please hit the
870:55 - like button please let me know in the
871:10 - chat
871:30 - yes tell me so I think people are
871:33 - writing now yes
871:40 - great okay
871:42 - fine so we are having the concept of the
871:45 - word to back now let's try to understand
871:47 - this embedding right now here uh what I
871:50 - can do I can give you one one example so
871:53 - let's say here is my sentence right so
871:55 - here I can give you one example actually
871:58 - so by using that you will be able to
872:00 - understand the meaning of the spark and
872:02 - the dense vector and you will be able to
872:04 - understand why we are not able to
872:05 - sustain the uh context also right so the
872:09 - example is very very simple let's say
872:11 - here I'm writing my my name is sunny
872:16 - right so here I'm writing my name is
872:18 - sunny now the next one is what let's say
872:20 - here I'm writing sunny sunny is a data
872:25 - scientist and here I'm writing Sunny is
872:29 - working Sunny is working for I neuron
872:33 - right so Sunny is working for I neuron
872:36 - so first thing what I will do so the
872:39 - first thing basically I will generate my
872:41 - Bo vocabulary right vocabulary so for
872:44 - generating a vocabulary uh so here I
872:46 - will find out the unique words so there
872:48 - is my first word second word third word
872:51 - fourth word fifth word sixth word right
872:55 - now here A S 8 n so here what I will do
872:58 - I will create my vocabulary so in my
873:01 - vocabulary I'll be having nine words so
873:04 - one is my one is name you can remove the
873:06 - unnecessary words and all by uh using
873:09 - the text cleaning techniques so here my
873:12 - name is sunny so this is my fourth word
873:15 - now here is a data science right now
873:20 - here word word and for and here we have
873:24 - a i neuron right here we have a i neuron
873:27 - so these are my vocabulary 1 2 3 4 5 6 7
873:33 - 8 9 right now let's say I want to create
873:36 - a one hot and coded Vector one hot and
873:40 - coded vector for this a particular
873:43 - sentence for which sentence guys tell me
873:45 - so I want to create it for this a
873:47 - particular sentence for the first
873:48 - sentence now if I want to represent the
873:51 - my inside this sentence what I will do
873:54 - here so here for my I will write it down
873:56 - the one and for rest of the value I will
873:59 - write down the 0o so 0 0 0 5 6 7 8 9 so
874:06 - this is the representation of my first
874:08 - word then I will write down the second
874:10 - word so here is name so here for the
874:12 - name actually there is 0 1 0 0 0 right 0
874:18 - 6 7 8 9 so this is my second word like
874:23 - like this there will be my third word so
874:25 - here let's say this is my third word so
874:27 - the third word 0 0 1 0 0 0 0 5 uh 4 5 6
874:35 - 7 8 9 and here is what here is my fourth
874:38 - word so fourth word is sunny so 0 0
874:42 - uh 0 1 0 0 so 1 2 3 4 5 6 7 8 9 so this
874:49 - is a this is my one sentence actually
874:51 - this is my first sentence which I
874:53 - uncoded which I uncoded so let me write
874:56 - it down over here this is what guys tell
874:57 - be this first sentence which I encoded
875:00 - by using the what hot encoder now see
875:03 - guys how much sparse this is so how much
875:06 - sparse this is right and here there is
875:08 - lots of zero and this might a
875:11 - contextless in a longterm sentence right
875:15 - it might be a meaningless so here is a
875:17 - example of the one H and gon and
875:20 - whatever techniques you will find out
875:22 - yes a tfidf is a better one even Google
875:25 - was using this technique for a long time
875:27 - now it uh replace this tfidf technique
875:31 - by this embedding one only because this
875:33 - tfidf it's it's a research of the Google
875:35 - right document Matrix it also work in a
875:38 - similar way like this one hot encoding
875:41 - somehow right so somehow it works with a
875:45 - one hot n coding right this uh document
875:48 - Matrix now we have TF IDF TF IDF is a
875:51 - better one NR is also there I will talk
875:54 - about the NR and here is a integer n
875:56 - coding so we U like code this value with
876:00 - the integer number right now here is the
876:02 - example of the one hot and coding now I
876:05 - will explain you the concept of the
876:07 - embedding by using this word to back
876:10 - that how this word to back is working so
876:13 - tell me guys is it clear to all of you
876:16 - so far yes or
876:19 - no think it is fine so just a
876:40 - second
876:47 - great so I hope uh this still here
876:50 - everything is fine everything is clear
876:52 - and uh just a
876:57 - second yeah it is uh clear now yeah
877:02 - great so let's talk about this word to
877:05 - I'm not going into the detail of word to
877:06 - back I'm just trying to explain the
877:08 - concept of the embedding only here right
877:11 - so how it was working so here guys if we
877:13 - are talking about the word to bag see
877:16 - let me do one thing over here what I can
877:18 - do I can uh Show You by using the
877:21 - example one
877:24 - example right so see let's say we have
877:28 - some data right so let's say we have
877:30 - some data and from that particular data
877:33 - what I did I created my vocabulary this
877:36 - data is nothing it's a text data right
877:38 - it's a text data and from this
877:40 - particular particular data I'm going to
877:42 - create my vocabulary right so let's say
877:45 - this is what this is my data and here uh
877:49 - this is what this is my data data in the
877:51 - data basically you'll find out the
877:53 - vocabulary so we are going to generate
877:54 - our vocabulary so here will be my some
877:56 - words and all now see if we are talking
877:59 - about the embedding now inside the
878:01 - embedding what we are going to do so we
878:04 - are going to create some features right
878:07 - so the first thing actually the first
878:09 - thing is what the first thing we are
878:11 - going to create the vocab and second
878:13 - thing is what we are going to create a
878:16 - features right features from this VAB
878:19 - okay we are going to create a feature
878:21 - from this book app now let me give you
878:24 - one example that how the feature and the
878:26 - book app looks like so there is one
878:29 - famous example very famous example let
878:31 - me write it down over here so let's say
878:33 - there is my book app which I'm going to
878:35 - write it down over here uh in the book
878:37 - app let's say we have some data and from
878:39 - there I I have extracted this book right
878:41 - vocabulary so in the vocab actually we
878:43 - have some value let's say there is a
878:45 - king right let's say there is a queen
878:47 - this is very famous example that example
878:50 - only I'm going to write it down over
878:51 - here that uh we have a king queen we
878:55 - have a man right we have a woman and we
878:59 - have one more word let's say we have a
879:00 - monkey over here right so this is a like
879:04 - wab actually which I have extracted from
879:06 - where from my data itself right you can
879:08 - assume that we have a data this is what
879:10 - this is my vocab
879:11 - now here actually you will find out some
879:13 - feature right so my feature is what let
879:16 - me write down the feature also so the
879:18 - first feature actually uh that is what
879:20 - that is a gender right so here the first
879:23 - feature is what the first feature is a
879:25 - gender the second feature which I'm
879:28 - going to write it down over here that is
879:29 - what that is a weth right the third
879:32 - feature which I'm going to write it down
879:34 - here that is going to be a power right
879:36 - the fourth feature is going to be a
879:38 - weight right weight and the third fifth
879:41 - feature is going to be a speak now see
879:44 - this vocab right and this feature right
879:48 - so everything is being done by the
879:51 - neural network itself neural network
879:54 - will automatically take care of it right
879:56 - so actually we have to pass this uh bab
880:00 - and it will automatically look into the
880:03 - features right this particular feature
880:05 - actually the feature which I have
880:07 - written so here what I will do I will
880:09 - create my data in such a way there we'll
880:12 - be having a vocabulary and we'll be
880:14 - having a neural network we'll be passing
880:17 - that to my vocabulary and my feature
880:19 - will be create and in between basically
880:21 - whatever Vector I'm going to generate
880:24 - that Vector itself is going to be my
880:25 - embedding right so here how the vector
880:28 - looks like so this is the high level
880:30 - representation of that mathematical so
880:33 - whatever complex mathematics is there
880:35 - now it's a high level representation of
880:37 - that that's it now here let's say we
880:40 - have a king we have a queen we have a
880:42 - man woman and monkey this is my
880:44 - vocabulary and this is my uh feature now
880:47 - here see guys we are going to assign a
880:50 - weight right to this particular vocab
880:53 - right we are going to assign a weight
880:55 - the weight value will be from 0 to 1
880:58 - right so here I'm saying King King is
881:00 - having a Zender right so here I'm saying
881:03 - yes it is having a Zender means one now
881:05 - Queen is also having a Zender right so
881:08 - here actually uh what I'm say say king
881:11 - is having a Zender now Queen is also
881:13 - having a Zender right uh here I can
881:16 - write it down the one now here I can
881:18 - write male also so you can say uh let's
881:22 - say the gender is going to be male
881:23 - female so you can specify you can
881:26 - specify let's say if the gender is going
881:28 - to be male over here this one now in
881:30 - that case what you will say so for King
881:32 - actually you will write it down one
881:34 - right so here let's say the gender is
881:36 - specified that is male so what you will
881:38 - do for the king you will write it on the
881:40 - one and and for the queen you will write
881:41 - down the zero right here the men yes it
881:44 - is one woman actually it's a zero and
881:47 - monkey let's say it's a one right I'm
881:48 - talking about the monkey it's a male one
881:50 - now if we are talking about the wealth
881:52 - right so again I will provide some sort
881:54 - of a number over here see to the
881:56 - vocabulary I will assign some number
881:59 - based on my feature okay so wealth yes
882:02 - King is having wealth so here what I
882:03 - will do I will assign one now Queen is
882:05 - also having wealth so I will assign one
882:07 - over here now if we are talking about
882:09 - the men so Men actually it's not a king
882:14 - right so men is not a king so they it
882:16 - might have a wealth or it might not have
882:18 - a wealth right so here I'm not going to
882:20 - assign a one so between this 0 to one I
882:24 - can assign any value this is going to
882:25 - work as a weight right so here I can
882:27 - assign 0.5 over here this woman also
882:31 - same right so it is having a less wealth
882:32 - compared to men let's say 0.4 and monkey
882:35 - is not having any sort of a wealth so
882:37 - here I'm going to write down the zero
882:39 - now if we talking talking about the
882:41 - power so definitely King is having a
882:42 - power Queen is also having a power but
882:45 - maybe less than to this King so here let
882:47 - me write down let's say 0.8 now here
882:50 - let's say this man is having a power
882:52 - let's say it's having very less power
882:53 - 0.2 this woman is having a power let's
882:56 - say 0.2 and monkey is not having any
882:59 - power now if we are talking about the
883:01 - weight definitely King is having a
883:03 - weight 0.8 now let's say woman this
883:06 - queen actually it's a more than this
883:08 - King in terms of weight so here I write
883:10 - down the 0.9 men also is having a weight
883:13 - right say uh is having 0.7 and this is
883:16 - 0.8 and monkeys also some weight let's
883:19 - say
883:20 - 0.5 right so to this vocab based on this
883:24 - feature I'm going to assign some sort of
883:26 - a numbers right and here let's say speak
883:29 - so yes King can speak Queen can speak
883:31 - man also can speak now here woman can
883:34 - also speak but monkey cannot speak so
883:36 - here is a zero so now you will see that
883:39 - this is my first Vector see this is the
883:42 - vector of the King right this is the
883:44 - vector of the king so here I'm
883:46 - representing the King by using this
883:48 - particular Vector now if we are talking
883:50 - about the woman so here is a vector of
883:53 - the woman guys this one sorry this is a
883:55 - vector of the queen this this particular
883:57 - Vector now if we are talking about the
883:59 - vector for the main this is the vector
884:01 - of the main I'm going to represent main
884:03 - by using this particular Vector now just
884:06 - look into this example where I was
884:09 - representing Sun by using this Vector
884:12 - now compare this vector and this type of
884:15 - vector see this Vector is actually this
884:18 - Vector is dense Vector right this Vector
884:22 - actually it's a dense vector and it is
884:24 - having more meaning right it is having
884:27 - more meaning it's not a meaningless it's
884:29 - having a meaning which I have uh which I
884:32 - can uh basically uh it is having a
884:36 - meaning which I can prove it also now
884:38 - this Vector whatever Vector I have
884:39 - designed over here it's a 5D Vector it's
884:41 - a five dimension Vector right now guys
884:44 - see I told you uh about the two
884:47 - Dimension Vector now let's say here uh
884:50 - if I'm going to draw the two Dimension
884:52 - Vector so this is my two Dimension
884:54 - Vector this one and how to represent
884:56 - this vector by using this x value and Y
884:59 - value now if I'm writing about the king
885:02 - let's say this is what this is my king
885:04 - right so here how to represent the king
885:07 - Now 1 1 1 0.8 and 1 so here is what here
885:11 - is my king Vector now tell me guys this
885:14 - King Vector actually it is in five
885:17 - Dimensions so we cannot draw it like
885:20 - this we cannot draw it like this so see
885:23 - the word to W model the word to W model
885:26 - which Google has strained it was a model
885:28 - from the Google right so this Google has
885:30 - Stained this particular model on a news
885:33 - article on a Google news article and
885:36 - actually uh the vector they have created
885:39 - the vector Vector which they have
885:41 - created over there the vector size was
885:43 - the 300 Dimension right so the vector
885:47 - size was the 300 Dimension so here I
885:49 - have just given you the Glimpse right
885:51 - with a few vocabulary and the feature
885:54 - now here uh if you will look into the
885:56 - real word to model which you can
885:58 - download from thei or maybe from any NLP
886:01 - Library like nltk and all so the
886:04 - dimension you will find out of each
886:05 - Vector which is going to be a 300 right
886:08 - which is going to be a 300
886:10 - so this is called embedding now here
886:13 - here guys see whenever we are talking
886:16 - about whenever we are talking about
886:17 - neural network so in a neural network
886:19 - what we are going to do so in that
886:21 - actually we have three layer one is a
886:24 - input layer the second is called a
886:27 - hidden layer the third is called a
886:28 - output layer so here actually what is
886:30 - happening see we are passing a input we
886:33 - are passing input now what we are
886:35 - passing over here what we are passing to
886:38 - this uh what we are passing to this
886:40 - neural network so here actually we are
886:42 - passing this a particular feature right
886:45 - this a particular feature so we are
886:47 - passing this particular feature and we
886:48 - are assigning some weight and at the end
886:51 - actually at the end at this particular
886:53 - layer in the output layer whatever
886:55 - Vector I will get right whatever Vector
886:57 - I will get in the output layer so that
886:59 - itself is called is going to be my
887:01 - embedding right here I have given you
887:03 - the high level overview how the bend how
887:05 - the embedding is going to be generated
887:07 - but the same process is going to be Auto
887:10 - by using this neural network and here
887:13 - what feature we are passing which
887:15 - feature we are passing so what I will do
887:17 - I will create one recording right for
887:19 - the word to back along with the python
887:21 - implementation there I will show you uh
887:24 - like how this word to back is working in
887:27 - actually actually right so here U yeah
887:30 - this is all about the embedding so
887:32 - embedding is nothing it just a vector
887:35 - and what is a vector you already knows
887:37 - about the vector so here you can see I
887:39 - clearly given you the explanation about
887:40 - the vector so what is a 1D Vector what
887:43 - is a 2d vector and if here let's say we
887:45 - are going to write down the five value
887:47 - right so that is a vector in a five
887:49 - dimension so we cannot draw the five
887:51 - dimension that's why I'm not able to
887:53 - show you that a 5D Vector but yeah if we
887:56 - are going to represent it let's say uh
887:58 - here what I'm going to do so let's say
888:01 - if I want to represent this five as of
888:03 - now just going to draw it in 2D itself
888:06 - so let's say this is my king Vector this
888:08 - is my king Vector now this King Vector
888:10 - will be near to this queen vector and
888:12 - this monkey Vector actually it will be
888:14 - far from this king and queen now this
888:17 - king and queen so this man and woman
888:19 - right so this is what this is my king
888:21 - and this is my queen now here let's say
888:23 - this will be my a main vector and this
888:25 - is what this is my woman Vector so this
888:27 - will be near to each other this king and
888:30 - queen Vector will be near to each other
888:32 - and here this monkey Vector will be far
888:34 - from each other and here let's see if
888:37 - I'm going to uh what I'm going to do
888:39 - guys so here let's say I'm going to uh
888:41 - substract this king from this queen and
888:45 - we are going to add something let's say
888:48 - men right so just just look uh just see
888:51 - what you will be getting after doing uh
888:53 - this much of like calculation over here
888:56 - right so you can subtract the vector
888:58 - from each other you can add it and you
889:00 - can make a new meaning over there right
889:02 - so the new meaning also will be a vector
889:04 - which will be representing some sort of
889:06 - a information right so here is all about
889:09 - the word embed and all so I just given
889:11 - you the introduction because I want to
889:13 - make a foundation as strong as much and
889:16 - here uh you can see why we need Vector
889:19 - database here uh there are different
889:21 - different uh database name here is a
889:23 - example basically which I'm showing so
889:26 - in tomorrow's session I will continue
889:28 - with this particular slide and then
889:30 - directly I will move to the Practical
889:32 - implementation where we are going to
889:34 - talk about a two database so initially I
889:37 - will start from this chroma and this
889:40 - vient right oh sorry this spine cone so
889:42 - first I will try to discuss this coma
889:44 - and the spine cone and if time will
889:46 - permit then I will come to this F also
889:48 - this F is a uh this F actually it's a
889:52 - vector database of the meta AI Facebook
889:54 - AI so yes definitely two database we're
889:57 - going to discuss in the class itself
889:59 - chroma and pine cone and there what we
890:01 - are going to do we are going to store
890:03 - iming and you got to know about the Ming
890:05 - guys Ming is nothing it's just a vector
890:08 - it's just a number which is having some
890:10 - semantic meaning and how we are going to
890:13 - do that we are going to create a feature
890:15 - which we are passing to our neural
890:17 - network and some uh like mechanism is
890:20 - there and based on that we are going to
890:23 - uh generate the vector so tell me guys
890:26 - did you like the session whatever I
890:28 - explain you over here did you understand
890:30 - each and everything how much you would
890:32 - like to rate the session if you liking
890:33 - the session if you're liking the content
890:35 - which I'm showing you in depth so please
890:37 - hit the like button please support
890:39 - support the channel so it motivates to
890:42 - me also and please write your answer in
890:44 - the chat if you're liking the session if
890:46 - you're liking the content and even the
890:48 - explanation
890:54 - also tell me I'm waiting for your reply
890:57 - so please uh tell me guys uh write it
891:00 - down in the
891:03 - chat yes did you learn something new did
891:06 - you understand uh whatever I have
891:08 - explained you that deployment all and
891:10 - the what Vector databases and uh here uh
891:13 - you will find out the session after the
891:17 - uh like see here is a session guys on
891:19 - top of the dashboard so just enroll to
891:22 - the dashboard here is my dashboard this
891:24 - one just enroll to the dashboard and uh
891:27 - you'll find out the session over here
891:28 - itself and even along with the resources
891:31 - this handwritten resources and all
891:33 - everything will be over here and uh yeah
891:36 - and subscribe the on YouTube channel we
891:38 - are uh all the thing is getting updated
891:42 - and here uh the recording also will be
891:55 - here great so fine I think now we can
891:58 - conclude it so today we have talked
892:00 - about the deployment and the vector
892:04 - database okay just go through the
892:06 - dashboard and download it then to check
892:09 - with the so this assignment and all so
892:11 - just click on the assignment and uh try
892:13 - to solve this assignment and then you
892:15 - can submit it also after solving it so
892:18 - let me show you how the assignment and
892:19 - all it look
892:25 - like this
892:30 - one yeah so here is assignment guys see
892:33 - you can okay so you here on itself you
892:35 - can write down the answer uh whatever
892:38 - questions of we have given you and then
892:40 - you can submit it directly okay great so
892:43 - I think we can start with the session
892:46 - and in today's session we'll be talking
892:48 - about the vector database so we'll
892:50 - Implement also we'll discuss about the
892:52 - pine cone database Vector database I
892:55 - will show you how to do setup how to do
892:57 - setup of the pine cone database and uh I
893:00 - will try to create a small bot also and
893:04 - in the next class I will show you how
893:06 - you can Implement end to endend
893:07 - chatboard got it so we'll discuss two
893:11 - Vector database in today's session I
893:13 - will be talking about the pine cone and
893:15 - in the next class we will be talking
893:17 - about the chroma DV so so there is two
893:21 - database which I'm going to talk about
893:23 - and we'll try to discuss the concept of
893:25 - the embeding and all and I will show you
893:27 - how you can uh generate the API key
893:29 - regarding the pine cone how to create an
893:31 - index how to create a cluster each and
893:34 - everything we'll talk about in today's
893:35 - session so so far I discussed so many
893:39 - thing in this community Series so first
893:41 - of all let me show you all those thing
893:44 - so for that guys what you need to do you
893:46 - need to go through with the Inon website
893:49 - and here you need to uh go inside this
893:52 - course section just click on this course
893:54 - section and here you will find out this
893:56 - community program so just click on this
893:59 - community program there are various uh
894:01 - option you will find out like DSA
894:03 - generative AI machine learning and SQL
894:07 - so just click on this generative Ai and
894:09 - here here we have a dashboard for the
894:11 - generative AI now there you will find
894:14 - out two dashboard one is for Hindi and
894:16 - the second is for English uh so just
894:19 - click on the dashboard now here uh you
894:22 - need to sign in first so after sign in
894:24 - actually uh first need to sign up if you
894:27 - are new on this portal and then you need
894:29 - to login and finally you can enroll
894:32 - inside the course so this is completely
894:34 - free we are not charging anything for
894:36 - this particular course now here I
894:39 - already enrad inside this course so here
894:41 - I just need to click on this uh go to
894:43 - course so here uh guys uh let me show
894:47 - you the dashboard this is the dashboard
894:50 - so so far I covered uh eight sessions so
894:54 - far I discussed like so many thing and I
894:57 - this is Day N actually and here you can
895:00 - see the till day 8 and yesterday I
895:04 - talked about the vector database I
895:05 - talked about the deployment as well if
895:07 - you will go and check with this
895:08 - particular session so I discuss about
895:11 - the deployment as well in the initial in
895:14 - the initial class and after that I move
895:16 - to the vector database there I explain
895:19 - you the theoretical concept regarding
895:21 - the vector vector databases and all I
895:24 - talked about the embedding and now in
895:26 - today's class we going to implement all
895:28 - those things so here uh just click on
895:31 - the resource section you will find out
895:32 - the resources actually here u u okay I
895:35 - already shared the resources so in some
895:37 - time uh it will be available a over here
895:40 - but if you want the project if you want
895:41 - the resources so uh for that you can
895:44 - visit my GitHub also there I uploaded my
895:47 - uh there I uploaded the project the
895:50 - project which I have implemented and all
895:52 - the steps regarding the project so how
895:54 - to deploy that and also each and
895:56 - everything I have written over here
895:58 - inside the readme file so let me show
896:01 - you that where it is uh the
896:05 - AI yeah this one so just uh go ahead
896:09 - with this particular uh go ahead with
896:12 - this particular link this particular
896:13 - project so here you just need to search
896:16 - s Savita giab there you will find out
896:18 - all the repository you will get my
896:20 - repository uh and then uh just go ahead
896:23 - with this generative AI this is your
896:25 - project and there is all the steps
896:27 - regarding the deployment and all don't
896:29 - worry in sometime it will be available
896:31 - in the resource section also so I
896:32 - already share with my team and they will
896:35 - be uploading inside the resource section
896:38 - got it now here uh see uh this is all
896:41 - about the deployment but apart from that
896:43 - I talked about the vector databases now
896:46 - Vector database wise I have discussed
896:49 - the theoretical stuff only so what is a
896:51 - vector how the vector database Works
896:54 - what is the meaning of the embedding
896:56 - what is the pros and cons of the
896:57 - embedding and the uh like different
896:59 - different encoding technique each and
897:01 - everything I talked about over here now
897:04 - in today's class we'll see the
897:06 - implementation of it uh apart from this
897:09 - apart from this uh okay so here is
897:12 - dashboard now apart from this resources
897:15 - and the lecture you will find out the
897:16 - quizzes and the assignment also and
897:18 - after completing this course so which we
897:20 - are going to complete soon because this
897:22 - is just a foundation course so we are uh
897:25 - we'll be taking uh four to five more
897:27 - classes and after completing this course
897:29 - you can generate a certificate from here
897:31 - so just click on this particular option
897:33 - and you can gener generate the
897:35 - certificate after completing this course
897:38 - right so you will get get a certificate
897:39 - for the foundation generative AI uh so
897:42 - this is the name of this course and
897:44 - apart from this one uh so apart from
897:46 - this basic course you will find out one
897:49 - more course over the Inon platform so
897:51 - for that uh just go inside the course
897:54 - section right here itself and uh let me
897:57 - show you just uh click on this
897:59 - generative a right so once you will uh
898:01 - go with the course and here you will
898:03 - click on the generative AI now inside
898:06 - that right inside that you will find out
898:09 - on the paid course right which we are
898:11 - going to launch next month next month
898:14 - from 14th January onwards so our first
898:17 - class will be on 14th January onwards
898:19 - and here you'll find out like we are
898:20 - giving you the discount and all so 40%
898:23 - discount is there and uh the price is as
898:26 - of now 6,000 you can talk about talk
898:28 - with our sales team and all they will
898:30 - give you the detail uh they will give
898:32 - you the complete detail regarding this
898:34 - particular course now the timing will be
898:36 - from 10: to 1:00 p.m. IST in morning
898:39 - morning and here after the time after
898:41 - the like class we have a doubt session
898:43 - also which is going from 1 to 2 not 1 to
898:46 - 2 basically so until we are not going to
898:49 - solve all the doubts and all so
898:50 - definitely we'll be uh we'll be taking
898:53 - the doubts okay and that will be the
898:55 - live doubt session only where you can
898:57 - interact with the mentor whoever taking
898:59 - class at that particular time means um
899:01 - in a live class itself so yeah
899:03 - definitely you can ask the doubts in a
899:05 - live doubt session right after the class
899:08 - now this course duration is around 5
899:10 - month and the mode will be in English uh
899:13 - okay so the date basically we have
899:14 - modified uh so the date is going to be
899:16 - uh this course is going to be start from
899:18 - 20th of June right now apart from that
899:21 - you will find out the instructor so here
899:23 - is the instructor of this course Chris
899:25 - sir sudhansu sir me and buy so these
899:29 - four will be your Mentor who is going to
899:31 - take this entire course and now here you
899:33 - will find out the curriculum also so
899:36 - this is the curriculum which we have
899:37 - divided into several mod modules so you
899:39 - can go through with the curriculum we
899:41 - have covered each and every each and
899:43 - everything which is like industry
899:45 - relevant and from basic to advance we
899:48 - are covering each and everything about
899:49 - the generative AI embeddings or a large
899:52 - language model different different
899:54 - Frameworks open source model fine tuning
899:57 - and apart from that U like there are so
900:00 - many things security comp compliances
900:02 - and all which you're going to talk about
900:03 - after creating a project uh evaluation
900:06 - matrixes of llm each and everything what
900:08 - whatever required on the industry level
900:11 - uh whenever you are going to work on any
900:12 - sort of a use case on any sort of a
900:14 - project which we are going to discuss
900:16 - over here right so here you can uh go
900:18 - with the website you can check about the
900:20 - curriculum and if you uh want something
900:24 - if you have any sort of a query you can
900:25 - directly ask me you can connect with the
900:27 - sales team they will be clarifying it
900:30 - now this is all about the uh course
900:33 - right so I hope guys uh you have seen on
900:36 - this particular course now coming to the
900:38 - the YouTube channel so uh where you will
900:41 - find out all the video apart from the
900:43 - dashboard so here let me show you let me
900:46 - search over the in neuron so this live
900:49 - is going on and here uh see guys uh once
900:53 - you will click on the uron YouTube
900:55 - channel uh go inside the live section
900:57 - there you will find out all the
900:59 - recordings uh like whatever uh we have
901:01 - discussed so far inside this community
901:03 - session so it is in a live section you
901:06 - can go and check and you can uh learn
901:08 - from here also and if you want a detail
901:11 - so each and every detail we have kept
901:13 - inside the description so once you will
901:16 - check with the description of this video
901:18 - you will find out all the details over
901:21 - here right so I hope uh this is clear to
901:24 - all of you now if you have any question
901:26 - you can ask me and then we'll start with
901:28 - today's
901:36 - topic so how work llm with insight and
901:39 - complex calculation on business data so
901:42 - definitely we're going to talk about it
901:44 - in our uh project right so there will
901:46 - solve a different different use cases
901:48 - and all here uh actually I shown you
901:51 - that how to call the API how to read the
901:53 - models and we have solved one basic
901:56 - problem statement that is McQ generator
901:58 - so uh business wise organization wise
902:02 - specific uh use cases wise also we can
902:05 - use this uh like llms and all and
902:07 - definitely be talking about in our
902:09 - different project in our other project
902:12 - and there will'll try to discuss more
902:13 - about use cases more use cases basically
902:15 - use cases application and their domains
902:33 - okay which one will be good for the
902:35 - streaming data Vector so as of now we
902:37 - going to talk about the Vector database
902:39 - and right after that I will discuss
902:41 - about more Vector databases and the
902:43 - graph databases also right so as of now
902:46 - uh the vector databases actually it is
902:49 - good right and I will give you the
902:50 - comparison and all uh while I will teach
902:52 - you that so don't worry just uh be in
902:55 - the class everything I will be clarify
902:57 - here itself in the live class
903:00 - okay so if you have any sort of a doubt
903:03 - guys you can ask me you can ask me in
903:05 - the chat I uh up for the questions and
903:08 - the
903:11 - s how to design the prompts and all so
903:14 - guys here if you will see uh if you will
903:16 - look into my session which uh where I
903:18 - have discussed I think each and
903:20 - everything right so on a foundation
903:22 - level so there I uh took a uh like a few
903:26 - specific time for The Prompt also right
903:28 - so how to design The Prompt what is the
903:30 - meaning of the different different
903:31 - prompt how to construct The Prompt what
903:33 - is a a few short prompting what is a uh
903:36 - like zero short prompting each and
903:38 - everything I have discussed inside my
903:39 - session now how to uh design The Prompt
903:43 - so you will definitely will get it once
903:45 - you will go through with my session so
903:47 - uh I would request to all of you if you
903:49 - haven't attended my session and if you
903:51 - are asking any question related to The
903:53 - Prompt LMS and all so first visit my
903:56 - session and then automatically this all
903:58 - the doubts will be clarified
904:07 - okay
904:09 - how organization has hesitant to adopt
904:11 - generative AI so just go and check with
904:12 - my first session uh where I have
904:15 - discussed the detail introduction of a
904:17 - generative AI why the organization
904:20 - should use the generative AI what is the
904:22 - pros and cons if we are going to train
904:24 - any model from scratch if you are using
904:27 - any pre-trained model which has been uh
904:29 - trained on a huge amount of data how we
904:32 - can reduce the cost and how we can get
904:34 - Effectiveness each and everything you
904:36 - will get it in my first session so
904:38 - please please check with the day one
904:40 - after this session and there I discuss
904:42 - everything regarding to regarding to
904:44 - this generative
904:45 - AI
904:52 - okay great so now I think uh we can
904:57 - start with
904:58 - the yeah we are going to discuss about
905:01 - the chat interaction also chat
905:02 - interaction with the database and in
905:04 - today's class itself in today's session
905:06 - itself I will show you this thing got it
905:08 - so finally let's start with the session
905:10 - let's start with the topic now the topic
905:13 - is what the topic is a vector database
905:15 - don't worry guys here the project will
905:17 - be available here inside the resource
905:19 - section if you will uh check with the
905:21 - day eight so uh there uh I will give my
905:23 - GitHub link I already Shar with the team
905:25 - and within a uh like uh within few
905:28 - minutes they will upload it over there
905:30 - got it now uh let's start with the
905:32 - session uh so today actually we're going
905:34 - to discuss about the vector databases
905:36 - yesterday I given you the introduction
905:38 - of this Vector database now let's see
905:40 - how does it work now uh if you will look
905:43 - into this slide so here I have mentioned
905:46 - each and everything that what all thing
905:48 - you're going to learn so what is a
905:49 - vector database why we need Vector
905:51 - database how Vector database work use
905:55 - cases of the vector database widely used
905:57 - Vector database right and practical demo
906:00 - using Python and lenion and there we are
906:03 - going to use open AI as well so these
906:06 - are the thing basically which we need to
906:09 - understand related to this Vector
906:11 - databases and yesterday I already given
906:13 - you the introduction about it so here I
906:16 - I have written each and everything on
906:18 - top of the Blackboard and I try to
906:20 - explain you that how this Vector
906:22 - database works right so there are like
906:24 - so many technique okay so Vector means
906:26 - what Vector I here I explain you what's
906:28 - the meaning of the vector in a layment
906:30 - term and there I have explained you
906:32 - about here I have explained you about
906:33 - the vector right so how to uh Define the
906:36 - vector how to write the vector it's
906:38 - nothing just a set of value and how to
906:40 - write it down so we we write it down u
906:43 - in a square bracket right so here
906:45 - actually see this is what this is my
906:46 - Vector which I have written so there
906:48 - might be a column Vector row Vector each
906:51 - and everything I discussed in my
906:52 - previous session right now after that I
906:55 - talked about the encoding so let's say
906:57 - we have a data and that data we want to
906:59 - pass to my model now uh here uh in
907:02 - between actually we'll have to perform
907:04 - the encoding of the data because we
907:06 - directly cannot pass the data to my
907:08 - model right text we cannot pass to my
907:10 - model because model is nothing just a
907:12 - mathematical uh equations so uh yes
907:15 - definitely it won't be able to uh like
907:18 - calculate something by using uh those
907:21 - Text data so definitely we'll have to
907:23 - convert those data into a numbers so for
907:26 - that we have a different different
907:27 - techniques if we are talking about deep
907:29 - learning so where we have a two
907:31 - technique right so first is without deep
907:33 - learning the second is with the Deep
907:34 - learning now in the without deep
907:36 - learning you will find out like
907:38 - there are so many Tech so many like
907:40 - techniques so here I have written couple
907:42 - of which is very very famous like
907:44 - document metrics TF IDF NR one hot end
907:47 - coding and integer end coding which we
907:49 - generally use while we are doing a end
907:52 - coding and here right hand side I have
907:54 - written a technique which work along
907:56 - with the neural network so word to is
907:58 - there fast Tex is there Elmo is there b
908:00 - is there Transformer itself is there
908:03 - right glove Vector is there but it's not
908:05 - a dbased technique I told you that it's
908:07 - a metrix vector ition based technique so
908:10 - here I'm not going to uh explain you the
908:12 - mathematics behind uh such techniques
908:15 - whatever I have written over here uh
908:17 - here I'm just giving you the Glimpse I'm
908:19 - just uh talking about the vectors I'm
908:21 - just talking about the embedding that's
908:23 - why I given you this overview got it
908:25 - because uh if I'm going into the
908:27 - mathematics so uh only one week will be
908:30 - required for this and coding techniques
908:32 - for the word Ting and all uh along with
908:34 - the implementation so here I'm just
908:36 - giving you the overview and trying to
908:38 - explain you the meaning of the embedding
908:41 - and vectors so if I was talking about
908:44 - the uh like here I was talking about
908:47 - here the uh disadvantage of this uh
908:50 - frequency based technique which we are
908:52 - using without uh DL means without neural
908:55 - network so here actually see this was
908:58 - the disadvantage of this particular
909:01 - technique so first was the sparse metric
909:03 - if we are using any such metrics right
909:05 - so any such technique like document
909:07 - metrics DF IDF andr one hot encoding or
909:11 - integer encoding so they actually uh we
909:15 - are going to generate a sparse Matrix
909:17 - but let's say we are not going to
909:18 - generate a sparse Matrix but in a long
909:21 - time we are not able to sustain a
909:23 - context it is going to be a contextless
909:25 - or meaningless okay now here uh it's
909:28 - going to be a contextless or it's going
909:30 - to be a meaningless uh this particular
909:32 - technique so that's why this edding
909:34 - concept came into the picture it is also
909:36 - a vector but it's a dense Vector right
909:39 - and the uh way of generating this Vector
909:41 - is little bit different compared to this
909:44 - technique now here actually we are using
909:46 - a neural network we are going to design
909:48 - our data in such a way so uh we are
909:51 - having two column one is a uh like uh
909:54 - independent column and one is a target
909:56 - column and then we are passing that
909:58 - particular data to my model and
910:00 - automatically it is generating so
910:03 - automatically it is generating a vector
910:05 - right so how it is doing that how it is
910:08 - going to create a like independent
910:10 - column and how it is going to create a
910:12 - text uh this target column so that's a
910:15 - like uh uh itself U like uh there is a
910:18 - separate process for that and definitely
910:21 - uh I will uh record one video for that
910:23 - uh like one end to end video for the
910:25 - hand coding techniques and all and I
910:26 - will put over the Inon YouTube channel
910:28 - so you can go and check in uh detail
910:30 - right so there I will I will be writing
910:32 - all the mathematical equations and all
910:34 - as of now just giving you the intution
910:36 - so here I given you the intu intution
910:38 - one high level intuition how this uh
910:41 - techniques is working this award
910:42 - embedding technique so here is the
910:44 - sparse metrix or sparse sparse Matrix
910:48 - which I have created so uh here you can
910:50 - see this is what this is my data so from
910:52 - this particular data I want to I will
910:55 - generate the vocabulary and based on so
910:58 - this let's say this is what this is my
910:59 - vocabulary over here now from that
911:01 - particular vocabulary I'm going to
911:03 - generate my Vector so here I given you
911:05 - the example of the one h encoded vector
911:09 - and you can see here this is very sparse
911:11 - Vector right this is very sparse Vector
911:13 - which I have generated regarding this
911:15 - particular document regarding this
911:17 - particular sentence right now if we are
911:19 - talking about the word embedding now how
911:21 - it is generating a vectors right how it
911:24 - is generating a vectors regarding the
911:25 - data so see let's say we have a data and
911:28 - from that data I'm going to create a
911:30 - vocabulary and from those vocabulary I'm
911:33 - going to create a features so here let's
911:35 - say this is what this is my vocabulary
911:37 - and this is what this is the feature so
911:38 - we'll assign the value between 0 to one
911:41 - to each and to each and every vocabulary
911:44 - based on a feature so here you can see
911:46 - uh I'm talking about the king so King is
911:48 - having a gender yes so here is one Queen
911:51 - is having a gender so she's U she's
911:53 - female actually so here is a zero I'm
911:55 - talking about the male here so man is
911:57 - one woman is zero monkey is one so like
912:00 - this uh I will be giving a number and
912:02 - this is what this is my one vector this
912:05 - is my one vector which is representing
912:07 - this King based on this particular
912:09 - feature now if here if you will look
912:11 - into this particular Vector so this is a
912:13 - dense Vector right which is having so
912:16 - many information compared to this Vector
912:19 - which is a sparse one right and where we
912:21 - are not able to sustain any sort of a
912:23 - context so this is what this is called a
912:26 - word embedding now uh if we are talking
912:28 - about a word embedding technique so it
912:30 - has been invented by the Google and they
912:32 - have trained the neural network on a
912:34 - huge amount of data that was the Google
912:37 - new news article right so uh the model
912:41 - basically which they have trained if you
912:42 - will look into the model if you will
912:43 - download the model so there you will
912:45 - find out a vector which is having a 300
912:48 - dimension in every Vector actually they
912:51 - have a 300 Dimension so you can use the
912:54 - pre-train embedding you can use the
912:56 - pre-train embedding if you are going to
912:58 - trainum model uh so you can pass the
913:00 - data to that particular model and
913:02 - automatically it will generate a aming
913:04 - based on a pre-trade model or else you
913:06 - can create your own m meding as well
913:08 - both thing is possible so in our case
913:11 - actually we are going to use open Ming
913:13 - so I will show you how to use open AI
913:16 - eding open AI also is having one uh
913:19 - class so edding class by using that we
913:22 - can uh generate a embedding so whatever
913:25 - data we have we can pass to that
913:26 - particular model and we can generate a
913:29 - embedding right so don't worry I will
913:31 - show you that how to generate a
913:32 - embedding from the openi class from the
913:34 - openi model and here is just a glimpse
913:37 - of the word aming which I shown in my
913:39 - previous lecture so I hope till here
913:42 - everything is fine everything is clear
913:44 - now let's move to the vector database
913:47 - tell me guys everything is fine
913:49 - everything is clear yes or
913:56 - no yes it is possible to read Excel
913:59 - using Lenin without any data loss yes it
914:02 - is possible we can read the Excel and I
914:04 - think I shown you how to load the
914:06 - documents just uh check with the
914:08 - documentation they already given you the
914:10 - code snippet use that uh particular
914:12 - snippet okay code
914:21 - snippet can change timing for the paid
914:24 - AI course evening um I think the course
914:28 - timing is in morning I will have to
914:31 - check with my team related to that so
914:34 - yeah if there will be any sort of a
914:35 - changes then definitely uh like you will
914:38 - get to know about it okay and I will
914:41 - update
914:46 - you tell me guys uh till here everything
914:49 - was fine so can we start with A New
914:52 - Concept now because here I I have
914:54 - explained you something regarding to
914:56 - this Vector database and then only I
914:58 - will move to the uh then only I will
915:00 - move to the Practical
915:06 - implementation
915:19 - great so let's start with the session
915:21 - now so here in this PDF you can see uh I
915:24 - written something that what is a vector
915:26 - database now first of all let me open my
915:30 - open oh just a
915:36 - second
915:43 - great now here you can see guys uh I was
915:46 - I'm talking about that what is a vector
915:48 - database now a vector database is a
915:52 - database used for storing high dimension
915:55 - Vector such as word embedding or image
915:58 - embedding so we can convert our text
916:00 - Data into embeddings even we can convert
916:03 - our image data also into the embedding
916:05 - and this embedding is nothing it is a
916:07 - vector so it's a vector actually and it
916:10 - is not a twood dimension vector or one
916:13 - dimension vector or three dimension
916:14 - Vector it's a high dimension Vector as I
916:17 - told you uh I was talking about this
916:19 - word aming word two B actually this is a
916:22 - model this uh word to back has been
916:24 - trained by the Google and this trained
916:26 - by the Google on a news article right on
916:29 - a news article and uh they have
916:31 - generated the embedding from those
916:34 - particular data from that particular
916:35 - data and the embedding size was 300 so
916:39 - actually see the vector which they were
916:41 - generating the size was the 300 over
916:44 - there so here we talking about the word
916:46 - embedding so it is nothing it is just a
916:48 - vector and it's a high dimension Vector
916:51 - right so the size can be anything over
916:53 - here so once I will show you this open a
916:55 - vector open a uh like open a Ming Vector
917:00 - so the size of the open a aming vector
917:02 - around 1,600 right so there you will
917:05 - find out a 1,600 value inside one vector
917:09 - right okay so yeah and even over here
917:12 - see I'm I'm talking about the word
917:13 - embedding so it is not related to the
917:15 - text Data it is related to the image
917:17 - data also means regarding the image data
917:20 - also we can generate a Ming and yes it
917:22 - is possible so over here you can see so
917:25 - this is a dog images PDF whatever
917:28 - document we have so related to that
917:30 - particular document we can generate a
917:32 - embedding and this is nothing this is a
917:35 - vector which is and what is a vector
917:37 - tell me the vector is nothing it's a set
917:39 - of value and which we are going to store
917:41 - somewhere in our Vector database now
917:44 - here if we are talking about the vector
917:46 - database so there is two term one is
917:48 - Vector and the second is database so
917:50 - this database actually it's a very
917:52 - common term which we like I think we all
917:55 - knows about this database so uh if we
917:57 - are talking about this database so
917:59 - during our uh like during our semester
918:03 - or during our college or maybe if you
918:06 - are working in an industry so definitely
918:07 - once in a while we interact with this
918:09 - database right so if we are talking
918:11 - about the database so there you will
918:12 - find out two type of database so the
918:14 - first database is called SQL based
918:16 - database and the second type of database
918:19 - is called No SQL database right so where
918:22 - we don't have to write it down the SQL
918:24 - where we don't need to create any sort
918:25 - of a schema a pre defined schema so that
918:28 - comes under inside the no SQL database
918:30 - and there we have a different different
918:32 - type of the databases like key value
918:35 - pair graph based database and document
918:38 - based database right so there is a
918:40 - different different type we have of the
918:43 - inside the no SQL database and here we
918:45 - are talking about the SQL based database
918:47 - so there you will find out only one type
918:49 - where we can store our data in the form
918:52 - of in the form of predefined SCH schema
918:54 - in the form of table in the form of row
918:56 - and columns right now what is this ve
918:58 - Vector database so Vector database
919:00 - actually see uh if we are talking about
919:02 - the database so definitely some uh
919:04 - server will be required for the
919:06 - computation and all right and we are
919:08 - talking about the database definitely
919:10 - some space will be required for storing
919:12 - something if we are if we are installing
919:14 - the my SQL in our local system so have
919:17 - you seen that we are installing the
919:18 - MySQL server and it is getting uh it it
919:21 - is occupying some sort of a spaces also
919:24 - in our system right for storing the uh
919:26 - data in the form of physical file The
919:28 - Logical view is a table but yeah in the
919:30 - back end actually storing our data in
919:32 - some physical format so here see uh we
919:35 - have a database so definitely some
919:37 - computation will be required and memory
919:39 - also will be required uh so here uh we
919:43 - are talking about specifically this
919:45 - Vector database so we are storing a
919:47 - vector now so how this database this
919:50 - Vector database is different from the
919:51 - SQL and no SQ database now let's try to
919:54 - look into that and we'll try to
919:56 - understand the differences differences
919:58 - between this uh like SQL no equal and
920:02 - this Vector database and why we should
920:04 - use this database why we should use this
920:06 - Vector database
920:07 - uh why we should not use this SQL and no
920:09 - SQL database we'll try to understand
920:11 - that also so first of all let me do one
920:13 - thing let me move to the next slide and
920:15 - uh let me explain you so here you uh I
920:18 - have written that why we need a vector
920:20 - database see over 80 to 85 person data
920:23 - which is there in the world as of now so
920:25 - there is a unstructured data now what
920:28 - comes inside this unstructured data so
920:30 - unstructured data means the data
920:31 - basically which is not a structure one
920:33 - like images okay so we have a images we
920:37 - have a videos videos is nothing just the
920:39 - collection of images collection of the
920:41 - frames uh so uh if you heard about this
920:44 - FPS frame per second that is nothing
920:47 - that's a uh mejor uh measurement unit of
920:50 - this videos okay in 1 second how many
920:53 - frame is getting processed so uh here uh
920:55 - we are talking about the images so the
920:57 - image data actually comes under this
920:59 - unstructured data where we have a pixel
921:02 - right pixel which uh we are going to
921:05 - form in the which we are going to
921:07 - collect in the form of grid right so
921:09 - pixel value usually will find out from 0
921:11 - to 255 got it so that is what there is
921:14 - an images right there is the images now
921:17 - if we talking about the unstructured
921:18 - data is text Data the text which I'm
921:21 - writing that also comes inside this
921:23 - unstructured data Text data is there
921:25 - voice data is there right so voice is
921:28 - there text is there images there videos
921:30 - is there so this is called unstructured
921:32 - data and most of the data which you will
921:34 - find out uh like uh which you will find
921:37 - out in today's world in today's era so
921:40 - that is a unstructured one only on a
921:42 - different different platform like
921:43 - Facebook Instagram what we are doing we
921:45 - are uploading a videos we are uploading
921:47 - the images we are uploading the reads
921:49 - this that whatever right so this
921:51 - platform this application are taking a
921:53 - data uh so we are uploading a like
921:56 - different different type of uh like data
921:58 - right like images videos and all those
922:01 - are called unstructured Data so I hope
922:03 - you got a clear-cut idea regarding this
922:05 - unstructured data now let's move to the
922:07 - next slide that why I have written over
922:09 - here so if we talking about the uh SQL
922:12 - based data or relational data or
922:13 - traditional data so here is some example
922:16 - which is like uh uh which is a very
922:18 - famous database dbms actually MySQL is
922:21 - there post gr is there SQL light is
922:23 - there Oracle is there right there are
922:25 - different different relational data
922:26 - wayase you will find out uh which we
922:28 - have learned once in a while means u in
922:31 - our College days in our like uh in the
922:34 - organization itself in the company
922:35 - itself right or or during the training
922:38 - so we have interacted with this
922:39 - relational database and this traditional
922:41 - database and we have seen the SQL also
922:44 - like how the cql works how to write it
922:46 - on the syntax and all in a SQL so we
922:48 - know we all know about the basics of the
922:50 - SQL right if we are talking the relation
922:52 - datab with so we usually write the SQL
922:54 - query over there right for interacting
922:56 - with this relational databases now here
922:59 - uh I think you got to know the idea that
923:01 - what is a relational database and here
923:03 - we have a problem problem related to the
923:05 - data the most of the datab basically
923:07 - that is the unstructured data now just
923:09 - see over here let's say uh if we are
923:11 - going to store this data if we are going
923:13 - to store if we are going to store this a
923:16 - particular data like images videos and
923:18 - all inside the vector database right so
923:22 - uh not inside the vector database First
923:24 - Let Me Explain you inside the first let
923:26 - me tell you that inside the uh this
923:29 - traditional database or inside the
923:31 - relational database so what will happen
923:33 - see so let's say here we have a
923:36 - traditional datab datase like my SQL and
923:38 - here if I'm going to store the image
923:40 - inside the my SQL all right we have a
923:43 - image and that particular image I'm
923:45 - going to install or I'm going to save
923:47 - inside the my SQL now guys see
923:50 - definitely I can do that I will be able
923:52 - to do that I will be able to save the
923:54 - image so it is having this capability
923:57 - where we can uh store the binary object
924:00 - so uh there is one way actually we can
924:02 - convert this particular image in a vs4
924:04 - string vs4 string and I can see save it
924:07 - but here guys see if we are going to
924:09 - save this particular image if we are
924:11 - going to save this particular image
924:12 - inside the uh traditional database so
924:15 - here I will have to define a schema
924:18 - right I will have to Define one schema
924:21 - there uh let's say if I'm going to store
924:23 - this image directly so we won't be able
924:26 - to get it now so this image belong to
924:29 - cat dog or which dog actually so if you
924:32 - will look into this dog so this dog is
924:34 - specifically is having some property
924:37 - right so this dog is specifically having
924:39 - some property some let's say this a dog
924:41 - belong to this particular breed that
924:43 - particular breed right now this um dog
924:45 - is a yellow brown or black something
924:48 - like that so this dog itself is having
924:51 - some property so if we are going to
924:52 - store this data directly in my SQL in
924:56 - that case let's say we are not passing
924:58 - any sort of a label any any anything
925:00 - over here right regarding this
925:01 - particular dog or directly we are going
925:03 - to store this dog okay dog image inside
925:06 - my my SQL now over here let's say I have
925:08 - converted into a b bs4 string or let's
925:11 - say I have just converted into a binary
925:12 - object uh so in that case I won't be
925:15 - able to identify it I won't be able to
925:17 - identify it this is the first problem
925:19 - the second problem basically so if you
925:22 - want to identify it so for that
925:23 - basically we'll have to create a proper
925:25 - schema so schema in case so let's say
925:28 - there is a image of the dog right there
925:29 - is a image of the dog then there is a
925:31 - color of the dog then there will be a
925:34 - breed of the dog right and there will be
925:36 - a lab label means this is the dog or
925:38 - let's say there's a cat something like
925:40 - that so if we are going to store this
925:42 - type of data in my SQL definitely I can
925:45 - do that but here is some problems we
925:48 - have first problem right if we are
925:50 - directly storing it so definitely we
925:52 - won't be able to identify it right so
925:54 - whether it's a dog cat or whatsoever the
925:57 - second thing we'll have to define a
925:59 - proper schema and the third thing is
926:01 - what so we'll have to define a proper
926:03 - schema where we'll be having a different
926:05 - different variable now the third thing
926:06 - is what so here actually see uh this SQL
926:10 - database let's say we are going to store
926:12 - it over there now uh whenever we talk
926:15 - about the text or images with respect to
926:18 - this uh generative AI or llms actually
926:21 - we have to perform an operation that is
926:24 - called similarity search right
926:26 - similarity search so I will show you
926:29 - what is this particular operation
926:30 - similarity search actually see whenever
926:33 - we are going to uh store this data this
926:36 - dog image inside the traditional
926:38 - database inside the relational database
926:41 - so the first problem which occur related
926:42 - to the identification if we are going to
926:44 - create a better schema that is also fine
926:47 - but we want we we cannot perform this
926:49 - similarity search actually means B let's
926:52 - say there is a dog now I want to find
926:54 - out the dog which is having a similar
926:58 - property right which is having a similar
927:00 - property like this dog so it is not
927:03 - possible in my SQL database right in in
927:06 - like traditional database or in
927:08 - relational database right so this
927:10 - similarity search or this query actually
927:13 - this will be a very very difficult if we
927:15 - are if we are going to query right after
927:17 - storing a data based on some property
927:20 - it's going to be a very very difficult
927:22 - so that's why we don't use this
927:24 - relational database and the same problem
927:27 - occur with the no SQL database also
927:30 - there also we can store the data we can
927:31 - store the Ming okay so we can use so I
927:35 - think today itself Chris has uploaded
927:37 - one video regarding the cassendra where
927:38 - we can store the embedding right we can
927:41 - do that but this Vector database which
927:43 - specifically designed for the like this
927:46 - edding and all so this gives you the
927:48 - better result compared to that right
927:51 - somehow we are able to achieve this
927:53 - thing means we are able to uh pass the
927:56 - label to the particular object whatever
927:58 - we are storing and we are able to search
928:00 - also right based on a similarity we are
928:03 - able to make a query we are able to
928:04 - perform the query but actually it is not
928:07 - that much efficient right whatever we
928:10 - want so for that only this Vector
928:13 - database has been designed I hope you
928:15 - got a problem and you are getting my
928:17 - point that uh why we are not storing
928:19 - this data inside the relational database
928:22 - got it now let's come to the next point
928:25 - and the thing will be more clear to all
928:27 - of you the next part over here if we are
928:29 - talking about the image so image looks
928:31 - like this only so where we have a three
928:34 - channel so the first one is a uh R then
928:37 - second is G the third one is blue means
928:39 - B so this is RGB means this colorful
928:43 - image actually it is having a three
928:45 - channel the first is called R the second
928:47 - is called G that is green and the third
928:48 - is called Blue right now uh here yes
928:52 - definitely if you want to perform the
928:54 - Ming right so here if you want to per if
928:56 - you want to perform the Ming we can do
928:58 - it by using uh so here we can use uh
929:02 - like different different embedding
929:03 - technique as I told you word to back
929:05 - Elmo or any pre-train embedding like uh
929:08 - which is uh available over the open a
929:10 - right which is available over the
929:12 - hugging phase so any embedding a model
929:14 - we can download and we can pass our
929:17 - object to that particular model right
929:19 - and based on a a training on uh like on
929:23 - whatever way basically it has been
929:24 - trained so it will give you the
929:26 - embedding right maybe you are not able
929:28 - to get this particular point but once I
929:30 - will show you right once I will do it in
929:32 - a python definitely you will be able to
929:35 - understand so what I'm trying to say
929:36 - over here you can perform the embedding
929:38 - related any unstructured object so here
929:40 - you can see we have a text we have a
929:42 - audio we have a image image embedding is
929:45 - also possible means we are going to
929:47 - convert images into a vector now here
929:50 - what I'm going to do so here I'm going
929:51 - to download any pre-train model any
929:54 - pre-train embedding model and yes by
929:57 - using that particular model we can
929:59 - convert our data into a vectors we can
930:02 - perform the embedding I hope this part
930:05 - is getting clear to all of you so
930:07 - whether we have a image or text or voice
930:10 - we just need to download the model
930:12 - pre-trained model and based on that we
930:15 - will be able to generate an embedding if
930:16 - you want to train your own model right
930:19 - if you want to train your own model that
930:21 - is also possible that is also possible
930:23 - or let's say if you don't want to train
930:25 - your own model you just want to
930:26 - fine-tune the pre-train model that is
930:28 - also possible so everything is possible
930:31 - there is a three possibility first is
930:33 - what first is a you can directly use the
930:35 - train model
930:37 - the second is what second is fine tuning
930:40 - all right fine tuning and the third is
930:43 - what third is training from scratch so
930:45 - here let me write it down the third one
930:47 - third is nothing third is training from
930:49 - scratch right everything is possible
930:51 - related to the embedding and here it is
930:54 - nothing so at the end we are going to
930:56 - generate a back turn after passing the
930:57 - object now I hope you got a clearcut
931:00 - idea now if we are talking about the
931:02 - embedding see uh what all embedding I
931:04 - will show you what all U like Tech te
931:06 - basically uh which uh we have so the
931:08 - first one we can use this word to bag
931:12 - right directly we can use this word to
931:13 - bag for generating Ming the second one
931:16 - we have the Elmo right we can use the
931:18 - Elmo and we can generate a Ming right
931:22 - now the third one basically we have we
931:24 - have the hugging phas API also in that
931:26 - also we have a several embedding model
931:28 - so hugging phas API Now by using this
931:31 - API hugging face API we can uh we can
931:34 - download the embedding model model and
931:36 - we can pass our object to this
931:38 - particular embedding model and it will
931:40 - give me the embedding right it will
931:41 - directly generate the embedding the
931:42 - fourth one we have this open API so in
931:45 - the open a API itself so in the open a
931:48 - itself you will find out the embedding
931:51 - model right so there also we have a Ming
931:54 - here also we have a Ming right in a open
931:56 - a itself so we have a hugging face we
931:59 - have a Elmo word to bag and various
932:01 - model here I just written couple of name
932:03 - or two to three name but we have a
932:05 - various model if you search over the
932:07 - Google you'll find out the various way
932:09 - right to convert your data into a
932:11 - vectors to convert your your data into a
932:13 - ambed vector right now here hugging
932:16 - phase API is also very very popular for
932:18 - the embedding and all and I will show
932:20 - you what all models we have right what
932:23 - all models we have uh inside the hugging
932:26 - phase actually uh for converting our
932:28 - data to into the embedding right and
932:30 - here in today's session we are going to
932:32 - use this open embedding right we'll be
932:35 - talking about the open a embedding how
932:37 - you can uh how you can like get it how
932:40 - you can access this particular class and
932:42 - after passing a data how you will be
932:44 - able to generate the eded vector so each
932:47 - and everything we're going to discuss in
932:48 - the live class itself right so I hope
932:51 - this slide is clear to all of you and
932:53 - this slide whatever I discuss regarding
932:55 - this uh uh my SQL and the sorry
932:59 - regarding this relational database and
933:01 - the no SQL and the vector database that
933:03 - part is also clear now here Vector eming
933:07 - is fine so yes uh we have the vector
933:10 - database now why we should use it
933:12 - because uh here actually this similarity
933:16 - search operation is uh like uh possible
933:19 - we can perform the similarity search
933:20 - after storing the vector and all and yes
933:24 - U now here embedding example so for that
933:27 - uh I kept some sort of example uh
933:30 - basically we can uh do the similarity
933:32 - search by making this cluster and all
933:34 - there is a this is the mathematical
933:36 - process actually so Vector this is a 2d
933:39 - uh this is what this is a 2d example of
933:41 - the vector aming as I told you now so
933:44 - what is a vector vector is nothing it's
933:46 - a set of the value in a like n
933:50 - Dimensions so here if I'm writing here
933:52 - if I have written two value only so it's
933:54 - a set of uh so actually it is
933:56 - representing a two Dimension X and Y
933:58 - right this first value is from the
934:00 - x-axis the second value five is from the
934:02 - y- axis now we can do a simility search
934:05 - uh we can make a cluster actually let's
934:07 - say this two vectors near to each other
934:09 - so we can say like they are having some
934:12 - similarity they this particular Vector
934:14 - is having some sort of a similarity like
934:16 - this this also this uh red one also see
934:19 - here is a vector this first one this
934:22 - this is my one vector this is my another
934:23 - Vector this is the third Vector so they
934:25 - are lying they are near to each other so
934:28 - here I'm saying yes this Vector is
934:29 - having some similarity this three Vector
934:32 - now this one also this also this also
934:34 - and this one so this Vector is is having
934:36 - some similarity this green one right
934:37 - this one so like wise actually what I
934:40 - can do I can perform this text
934:42 - similarity option text similarity option
934:45 - which is like uh which is little hard if
934:48 - we are going to store a data in my SQL
934:51 - post gray right or maybe in other
934:54 - databases so in that case like we won't
934:56 - be able to see in my square and post gr
934:59 - relational database it is like really
935:01 - hard right because we are going to store
935:03 - up data not in terms of embedding
935:06 - directly is going to store the object
935:07 - over there and uh for that only we'll
935:10 - have to do a we'll have to create a
935:11 - predefined schema so uh it's going to
935:14 - little hard over here actually we don't
935:15 - never use this relational database for
935:18 - this uh embedding and all okay so it's
935:20 - not our Perfect Choice yes we can use
935:22 - the no SQL database uh in the no SQL we
935:25 - can use the document with database uh or
935:28 - else what what we can do we can use this
935:30 - row columnar database that is also
935:33 - possible like cassendra and all we can
935:35 - use this uh graph based database right
935:38 - actually uh graph based database is not
935:41 - that much successful they also you will
935:43 - find out some sort of a difficulties in
935:45 - all I will tell you in further session
935:47 - but yeah we can use this raw column
935:49 - database and even the document database
935:51 - also but yeah the performance is like U
935:54 - uh it's not that much good and here also
935:57 - we'll have to label the data and all
935:59 - directly we can store the embedding uh
936:02 - but uh here actually along with the
936:04 - embedding there are so many things means
936:06 - we have to find out the similarity score
936:08 - then we have to perform the similarity
936:09 - search here you can see clearly in the
936:12 - geometry but mathematically how we can
936:14 - prove it so for that there are so many
936:16 - thing which we need to find out so there
936:18 - will be a similarity score right based
936:20 - on that similarity score we have to do a
936:23 - similarity search right similarity
936:25 - search so this is also there so
936:27 - similarity score similarity search this
936:29 - Vector database will give you everything
936:31 - Vector database will give you the
936:33 - everything so that's why we directly use
936:35 - this pre-configured Vector database and
936:37 - here also like it is running on some
936:39 - sort of a server and there are also some
936:41 - computation and all uh which is included
936:44 - which I let you know right so how to
936:45 - configure the cluster and all regarding
936:47 - this Vector database yeah so if we are
936:49 - going to store the data store this like
936:52 - embedding in a no SQL database so here
936:54 - also we'll have to make some
936:55 - configuration and it is not that much
936:57 - efficient but this Vector database
936:59 - actually it is giving us everything
937:00 - where we just need to store the uh value
937:03 - we where we just need to store the data
937:05 - in the form of vector that's it got it
937:08 - now here uh I hope this part is clear to
937:12 - all of you this vector embeddings and
937:15 - all now let me go through with the next
937:17 - slide so here again uh same thing is
937:19 - there so we have embeddings so we have a
937:21 - vectors and along with that there will
937:23 - be indexing as I told you now so if we
937:25 - are going to store this data if we are
937:27 - going to store this particular data
937:29 - inside the uh no SQL right if we are
937:32 - going to store this particular data
937:34 - inside the no SQL databases
937:36 - again we'll have to make like a some
937:38 - configuration and all according to the
937:40 - uh the vector which we are going to
937:41 - generate we'll have to conclude the
937:43 - we'll have to write down the indexing
937:44 - and all and uh maybe we'll have to write
937:46 - it down the label also to identify this
937:48 - embedding right so many things is there
937:51 - but we can do it by using the no SQL now
937:54 - here uh uh let's uh understand about the
937:57 - vector databases already I talked about
937:59 - it and here you can see uh we have a
938:02 - data which we are going to store inside
938:04 - the traditional data a vector database
938:06 - index and store Vector embedding for
938:08 - faster uh retrievable and similarity
938:10 - search right so for the faster retrieval
938:14 - and similarity search we always use this
938:16 - Vector database instead of the
938:18 - traditional database we never use this
938:20 - for storing the vector for restoring the
938:23 - this vector and all now use cases of the
938:25 - vector database so here long-term memory
938:27 - for llm semantics s similarity search
938:29 - recommendation is that the main thing is
938:32 - this one only the semantic search and
938:33 - the similarity search this concept uh
938:35 - initially this concept has been
938:37 - introduced by the Google itself if you
938:39 - search about this Vector database now it
938:41 - become too much popular after coming
938:43 - like different different llms and all
938:45 - and like this type of operation actually
938:47 - there are like uh you will find out so
938:50 - many
938:51 - operation like where you have the
938:53 - similarity search and the semantic
938:55 - search semantic meaning and all and
938:57 - where you have to sustain the long-term
938:59 - memory right so because of that this
939:01 - Vector database become too much popular
939:04 - uh I hope this thing is clear to all of
939:06 - you about the vector database now we we
939:09 - have couple of name uh now this Vector
939:11 - database this F from the openi side
939:14 - right so you will find out this F over
939:16 - the openi website actually it's a
939:18 - research of the meta now here is a webb8
939:20 - here is a choma DB pine cone is there
939:22 - redus is also there there are so many
939:25 - database or so many Vector database you
939:27 - will getting you will be find you will
939:28 - be able to find out now uh we are going
939:30 - to use this Pine con and chroma DV and
939:33 - will show you the babyit also but uh not
939:36 - in today's session later on uh after
939:38 - this uh like chroma and pine con but in
939:41 - today's class first I will start from
939:43 - the pine con because it is a little uh
939:46 - simple compared to this chroma DB and
939:48 - the we8 if we are talking about this
939:50 - chroma DB and the we8 it is little uh
939:54 - tough to configure not tough actually
939:56 - compared to Pine con it is like little
939:57 - harder so first we start from the pine
940:00 - con itself and there we try to build our
940:02 - small uh U like QA system
940:05 - okay and here and later on we'll be
940:09 - talking about this chroma DB and the
940:11 - vate so let's start uh with
940:14 - the Practical demo so for that uh what
940:18 - we can do we can open our neural lab so
940:20 - guys uh tell me are you ready yes or no
940:24 - please do let me know the theory
940:26 - whatever uh part I have discussed
940:28 - whatever thing I have discussed through
940:30 - this PP uh those part is clear to all of
940:33 - you yes or no
940:36 - again I will come to this one after uh
940:39 - implementing uh in a python right after
940:41 - doing the Practical stuff and all and
940:43 - then again I will try to give you the
940:45 - revision and then the understanding will
940:47 - be more concrete to all of you
940:51 - okay tell me guys fast if uh you will
940:55 - say yes then I will proceed
941:04 - further
941:40 - great so let's start with the Practical
941:42 - implementation now so here you can see
941:45 - uh I opened
941:46 - my uh I opened my uh neurol lab sorry I
941:50 - opened my U ion website and here you
941:52 - will find out this neurol lab so just
941:54 - click on this neurol lab here uh which
941:57 - you will find out over the website just
941:59 - go and search the website
942:01 - ion. and there uh you will find out a
942:04 - option this neurol lab option just click
942:06 - on that and here you will get the
942:09 - interface neuro lab interface so uh what
942:12 - you need to do guys here after opening
942:15 - it you need to click on this start your
942:17 - lab okay so once you will click on this
942:20 - start your lab there you will find out
942:21 - of various option like big data data
942:24 - analytics data science programming web
942:26 - development and all so here click on
942:28 - this data science as of now uh like uh
942:32 - we are working in this particular
942:33 - segment data science so there you will
942:35 - find out all the related tool right
942:37 - whatever is required for the development
942:40 - so here you will find out all the tool
942:42 - whatever is uh like related for the
942:44 - development and uh here we are going to
942:47 - use this uh here we are going to use
942:49 - this jupyter lab so just click on this
942:51 - Jupiter lab after clicking on this data
942:53 - science just click on this Jupiter lab
942:55 - and here it will ask you the name you
942:57 - can uh provide your name also you can
942:59 - write it down your custom name so the
943:01 - name uh which I'm going to write it down
943:03 - over here so Vector database Vector DB
943:09 - okay now what I will do guys here I
943:11 - don't want to clone any repositories
943:13 - like I'm saying no I don't want to do it
943:15 - and then proceed so first you need to
943:17 - write down the name and then U like just
943:20 - select this particular option or no only
943:23 - just click on that and then launch your
943:25 - Jupiter instant so here you can see uh
943:28 - this instance is getting launched
943:32 - now this instance is getting launched
943:34 - and and here after launching this
943:36 - instance you can click on this Python 3
943:40 - ipy kernel so just click on this
943:43 - particular option Python 3 ipy kernel
943:46 - and here you will get the file here you
943:48 - you will get the Untitled file so you
943:50 - can do the right click on that okay on
943:52 - top of this file and you can rename it
943:55 - so just do the right click on this
943:57 - particular file untitle do iynb and then
944:00 - click on this rename now here you can
944:02 - write down the name so let's say the
944:04 - name is what Pine con DB Pine con Vector
944:07 - DB Pine con Vector DB so here is the
944:10 - name the name is what the name is Pine
944:12 - con Vector DB now I am ready for my
944:16 - implementation I hope guys this is
944:18 - visible to all of you and you can
944:20 - clearly see this particular jupyter
944:21 - notebook please do let me know if you
944:23 - are able to do a
944:25 - setup if you are able to launch your
944:27 - jupyter notebook then please do let me
944:29 - know please write down the chat I am
944:31 - waiting for your
944:33 - reply do it guys
944:40 - fast yes or
944:50 - no I'm waiting for your
944:53 - reply if you have done all the setup
944:57 - entire setup then please do let me know
944:59 - in the
945:03 - chat
945:07 - sir show one more time yes I can show
945:10 - you one more time so click just open the
945:12 - neuro lab after opening the neuro lab
945:15 - here you will find out the option start
945:17 - your lab and my lab so don't click on
945:20 - this my lab because if you have already
945:22 - created a lab then only you will get
945:24 - your Labs the lab template over here so
945:27 - here what you can do guys tell me here
945:28 - you can click on this if you are using
945:30 - the first time right if you are creating
945:32 - your left first time or see we are doing
945:34 - first time now we are launching this
945:35 - jupyter notebook first time only
945:37 - throughout this uh throughout this geni
945:40 - commune session so click on this start
945:42 - your lab and here you will find out a
945:44 - different different template so just go
945:46 - with the data science and here click on
945:48 - this Jupiter template and then give your
945:51 - name or keep it by default only click on
945:54 - no and then proceed that's it that's a
945:57 - proed of that's that's a process and
945:59 - it's a very very simple so please do it
946:01 - guys and let me know then I will uh
946:04 - writing down the code over
946:06 - here waiting for your reply if you can
946:09 - write on the chat I think uh that is
946:11 - going to be
946:21 - great and let me share this uh link also
946:25 - okay I think let me check if I can share
946:28 - with all of
946:28 - [Music]
946:30 - you just a
946:33 - second
946:54 - great so now let's start with the
946:56 - session uh so let's start with the
946:58 - Practical implementation okay now here
947:01 - guys you can see so this is what this is
947:04 - my uh Jupiter lab now I will be writing
947:06 - the code from scratch and I will show
947:08 - you like what all whatever thing will be
947:10 - required so definitely I will show you
947:12 - in between and even I will show you that
947:15 - how you can generate an embedding how
947:16 - you can save it and we'll show you that
947:19 - how you can uh create a basic QA system
947:22 - right by using the openi Ming now here
947:25 - is what so here let's say uh so this is
947:28 - my blank notebook so first of all I need
947:29 - to install some Library so I'm I believe
947:32 - that you are uh doing along with me so
947:35 - please do it along with me because today
947:37 - I will go very very slow uh this is
947:39 - going to be a very important session for
947:41 - uh further projects the projects which
947:43 - we are going to do in our upcoming
947:45 - session so please guys do it along with
947:48 - me and I will be writing each and every
947:50 - line each and every code in front of you
947:52 - only so fine let's start now so here the
947:56 - first thing which we are going to
947:57 - install over here that's going to be a
947:59 - len chin so here I'm going to install
948:02 - Len chin let me write it down over here
948:04 - the second thing which we are going to
948:06 - install over here that's going to be a
948:08 - pine cone so here let me write it down
948:10 - pip install pip install pine cone so if
948:13 - you want to use the pine cone so you
948:15 - will have to install this pine cone
948:17 - client right I will come to the pine
948:19 - cone I will show you the pine con
948:21 - website also but first let's try to
948:24 - install this particular module so here
948:26 - the second thing is what Pine con cone
948:27 - client c e NT right the next thing which
948:30 - we are going to install over here that's
948:32 - going to be a p PDF so here let let me
948:34 - write it down Pi PDF okay Pi PDF py uh
948:40 - okay py PDF now the fourth thing which
948:43 - we are going to install over here that's
948:45 - going to be a open a so pip install open
948:48 - a right so pip install open and now
948:51 - there is one more Library which we need
948:52 - to install so here I can write it down
948:55 - pip install uh tick on so let me give
948:59 - you the name uh tick token so there is a
949:03 - library tick token so this is the
949:05 - library which you need to install take
949:06 - token so actually this library is a
949:10 - important one if we are going to call
949:12 - the open a embedding so it's a utility
949:15 - actually for that particular class for
949:17 - the embedding class got it now what I
949:20 - will do here so I will run it and it
949:23 - will be installing all the packages in
949:25 - my current workspace so here you can see
949:28 - guys my all the package is getting
949:30 - installed so meanwhile I can show you
949:32 - this Pine con so meanwhile uh I can show
949:36 - you the pine con uh just a second so
949:39 - just open your Google and here search
949:43 - about the pine just write it on the pine
949:45 - cone p i p i n e c o n e pine cone so
949:49 - once you will uh click on once you will
949:52 - like write it on this Pine con and you
949:53 - will hit enter so here you will find out
949:55 - the pine con website https www. pinec
949:59 - con. now click on that now open this
950:02 - particular website now here guys after
950:05 - uh clicking on that you'll find out this
950:07 - a particular interface this is the
950:09 - interface of the uh this is the
950:11 - interface of the pine con website so
950:14 - have you opened it guys tell
950:16 - me are you installing this uh are you
950:19 - installing all the library the library
950:21 - which I have written over here have you
950:23 - opened this Pine con website because
950:25 - from here I have to generate the API key
950:28 - if we are not if we are not going to
950:29 - generate API key in that case we won't
950:32 - be able to call this pine cone right so
950:35 - please uh do let me know if you have
950:37 - opened
950:38 - it so is it getting blurred or what so
950:42 - my screen is blood please do confirm
950:44 - guys please do let me know because I can
950:47 - see it is not a blood one it is a clear
950:51 - uh Crystal Clear actually and I can see
950:54 - in my screen please do confirm in the
950:57 - chat guys please write it down the chat
950:59 - if you have opened this uh pine cone and
951:02 - if you can clearly see this particular
951:04 - screen yes or
951:07 - no great now uh see here this is what
951:10 - this is my pine cone now what you will
951:12 - do see if you are uh if you are doing it
951:15 - first time then you need to sign up what
951:17 - you need to do you need to sign up so
951:19 - just click on the click on this sign up
951:22 - free and here you
951:24 - can and here you can uh basically you
951:28 - can uh sign up it will ask you about it
951:30 - will ask you the email ID username and
951:33 - it will ask you the like organization
951:35 - name and all it's a optional one only
951:36 - you just need to provide your email ID
951:38 - or you can directly sign up by using
951:40 - your email ID right you can directly
951:43 - sign up by using the email ID it is it
951:45 - is a very simple step just click on the
951:47 - sign up and uh then sign up by using
951:50 - your email ID and automatically you will
951:52 - be login so I already did it over here
951:54 - you can see I uh did it and this is what
951:57 - this is a interface which I will uh
952:00 - which you will get after the sign up
952:02 - right so first you need to open the
952:04 - website there you need to sign up right
952:07 - and after the sign up what you will do
952:09 - guys tell me after the sign up
952:10 - automatically you will be log in and
952:12 - you'll find out this particular page so
952:14 - if you are doing along with me so yes I
952:17 - can wait for you you can let me know in
952:18 - the chat and if you have done till here
952:21 - then I will proceed tell me guys
952:24 - first uh waiting for the reply so if you
952:27 - are hearing me if you are listening to
952:28 - me then uh please do let me know in the
952:33 - chat
952:55 - fine so let's start now here you can see
952:57 - see guys uh what you need to do
953:01 - uh here yeah in your case actually it is
953:04 - saying create the index now let me do
953:06 - one thing let me delete this index so I
953:08 - will show you from the starting so how
953:10 - to create the index and all and what is
953:13 - the meaning of it so let me delete this
953:14 - particular index and here guys you can
953:17 - see I deleted this index now in your
953:20 - case it is giving you the option for
953:21 - creating an index actually see if you
953:23 - are using a free version if you have
953:25 - created a free version right so in that
953:29 - case you can only create a single Index
953:32 - right if you're using a free tire free
953:34 - tire of this spine cone so in that case
953:36 - you only can create a single Index right
953:41 - so now uh the first thing what you need
953:43 - to do guys so here you need to click on
953:45 - this API key left hand side you can see
953:48 - this API key just click on this API key
953:51 - now once you will click on the API key
953:52 - so it will give you the option for
953:54 - creating a API key and one key you will
953:56 - find it over here by default so they
953:59 - have given you one key that's a by
954:01 - default key this one this one actually
954:03 - this one okay so this is the by default
954:05 - key which you can see over here uh which
954:08 - they which everyone will get it right
954:11 - and now here this is my key which I have
954:13 - created by clicking on this create API
954:16 - key got it so here this is my key which
954:19 - I have created or they will give you the
954:21 - by default key you can use this also
954:22 - otherwise you can create a new also both
954:25 - are fine right so if you have this by
954:27 - default key now you are well and good
954:29 - till here right you are fine till here
954:31 - so tell me guys are you getting this
954:34 - uh this key AR I think see there is some
954:38 - problem from your side because I can
954:41 - clearly see that everything is fine in
954:43 - my system and uh it is visible to all of
954:47 - other student so please check from your
954:49 - side as well it is working fine or not
954:51 - please check in your phone uh just try
954:53 - to refresh your system if you getting
954:56 - the blur
954:57 - screen because in my screen the feed is
955:00 - uh fine and I think no one is uh
955:04 - complaining about it so please check
955:07 - once yeah so if you are getting a
955:10 - default key then it is fine so if till
955:12 - here right if till here you proceed
955:15 - along with me then it is fine now let's
955:17 - go back to the code now here is my code
955:20 - guys here is my code file here is my ipb
955:22 - file so here guys you can see so I
955:25 - install this libraries pip install L
955:28 - chain Pine con Pi PDF open tikon I
955:31 - installed all the required Library is
955:34 - over here now let me do one thing let me
955:36 - write down the further code so here and
955:38 - the next cell after installing all the
955:40 - library whatever was there I'm running
955:43 - this uh like I'm running a further sale
955:45 - so here guys what I need to do so here
955:47 - now I'm going to import all the library
955:50 - so here already I have written the
955:51 - import statement now let me show you
955:54 - those import statement here is a import
955:55 - statement guys so the first import
955:57 - statement is pi PDF directory loader
956:01 - this is the first import statement the
956:03 - second four statement is recursively
956:05 - character text Splitter from the lenon
956:07 - itself now the third one open AI
956:10 - embedding right and the fourth one
956:12 - you'll find out that's the opener itself
956:14 - then we are going to import this spine
956:17 - cone from the vector store which is
956:19 - there inside the Len chain I'm using Len
956:22 - chain only and I told you this Len chain
956:24 - is a wrapper on top of each and every
956:27 - API right so whatever thing uh see
956:31 - better like you are if you're going to
956:32 - build this LM based application if you
956:34 - are using this Len chain so you will
956:37 - find out U everything inside the Len
956:39 - chain it's a wrapper on top of the every
956:42 - API on most of the API so here you can
956:45 - see you can import this pine cone from
956:47 - here itself from the Len chain right so
956:49 - from Len chain. Vector store and there
956:51 - is what there is a pine code now Len
956:53 - chain. llm here is a open a now Len
956:56 - chain chain here we have a retrieval QA
956:59 - each and everything will be clarified
957:01 - once I will write it on the code only
957:04 - now here you can see Len chen. prompt
957:06 - and here is what prompt template so you
957:08 - already know about the prompt template
957:10 - you already know about the open a you
957:12 - already know about the pi PDF directory
957:15 - loader this thing recursive character
957:17 - text splitter open a embedding and
957:20 - retrieval QA this thing is a new one so
957:22 - definitely I will explain you it don't
957:24 - worry so what I can do here uh let me do
957:27 - one thing if you are uh doing along with
957:29 - me I can give you this particular code
957:31 - and for that I what I can do I can share
957:34 - this uh Cod share. where I will be uh
957:38 - writing let me share with all of you
957:41 - this Cod
957:43 - share. okay just a
957:47 - second Cod
957:52 - share. yeah so here I can copy my entire
957:55 - code this is the code this is the input
957:58 - statement and
958:02 - here and here is what here is my all the
958:06 - library so which you need to install all
958:08 - the packages which is which you need to
958:10 - install now this is
958:13 - the just wait let me copy it from
958:18 - here this is the
958:20 - packages yep it is fine now and this is
958:24 - the import statement so import
958:29 - statement and here uh required
958:34 - package
958:36 - required package right now let me give
958:39 - you this particular link so here I'm
958:41 - giving you this link inside the
958:43 - chat just wait here it is here is the
958:47 - session which is going
958:49 - on now just wait here's the link guys
958:52 - here's the link of the here's the link
958:55 - of the Cod share. so please do confirm
958:58 - did you get it guys yes or no please uh
959:01 - do let me know inside the chat if you
959:03 - got this particular link yes or
959:07 - no I I given you this link inside the
959:09 - chat so please do
959:12 - confirm and don't worry my uh team will
959:14 - also give you that my team will ping you
959:18 - this
959:19 - link so inside the chat itself if I'm if
959:22 - I'm not able to do it just a
959:30 - second this one
959:39 - okay so I hope uh it is fine
959:42 - now yeah so now I hope you got a link
959:45 - please do let me know in the chat please
959:47 - do
959:49 - confirm I'm waiting for a reply and see
959:52 - guys just copy and paste the code don't
959:55 - remove from here right don't remove
959:57 - don't cut it from here just copy and
960:00 - paste yeah copy the entire code and run
960:02 - it inside your uh run inside your this
960:06 - uh IP
960:16 - VB yeah so I'm waiting uh please do it
960:20 - and then I will proceed
960:31 - further yeah this one
960:41 - okay
960:52 - proceed yes this uh file will be
960:55 - available over the
960:56 - dashboard Vishnu is karma is saying sir
960:59 - did not get a link I pasted now pasted
961:01 - inside the chat just look into the chat
961:03 - live
961:04 - chat check with your live chat we have
961:07 - we have given you that inside the chat
961:10 - itself fine so now let's uh move further
961:15 - here after installing all the library I
961:17 - need to import this statement so here
961:20 - you can see uh I'm able to import this
961:23 - particular statement okay so I have
961:26 - imported this particular statement now
961:28 - guys what I will do here here in this my
961:30 - in this my local workspace in my uh this
961:33 - workspace I'm going to create one folder
961:36 - right so I'm going going to create one
961:38 - folder and for creating a folder there's
961:39 - a command mkd so here I'm going to write
961:42 - it down mkd PDF right so here I'm going
961:46 - to create one folder the folder name is
961:47 - going to be a PDF so see guys uh left
961:51 - hand side if you will look into your
961:52 - workspace you will find out the PDF
961:54 - folder now inside this PDF I have to
961:57 - upload the PDF and from there itself uh
962:00 - see I can upload the text file or I can
962:03 - upload the PDF XL CSV so I just required
962:06 - a data right so I'm showing you this
962:08 - embedding and all I'm showing you this
962:10 - embedding and then I will store it then
962:12 - I will query it so on top of the uh real
962:16 - time PDF only I'm not going to create
962:18 - any dummy data over here right so in
962:20 - front of you only so here let's say h
962:22 - I'm opening my Google and from here I'm
962:25 - uh I'm searching about this attention
962:27 - all your need right so this is the
962:29 - Transformer research paper so let me
962:31 - open this research paper and let me me
962:33 - download it inside my system so here
962:35 - what I'm going to do guys so here I'm
962:37 - downloading this a
962:40 - particular yeah here I'm downloading
962:42 - this particular research paper inside my
962:45 - system right so see guys uh what I can
962:47 - do I can keep the name
962:49 - Transformer right so this is what this
962:51 - is my PDF now what I will do guys here
962:55 - uh let me check the size of this PDF uh
962:57 - if it is a huge one that definitely my
962:59 - neurol lab uh won't allow to me let me
963:02 - check if I'm able to upload it or not
963:04 - this Transformer in my neural lab so
963:06 - here what I will do I will click on this
963:08 - upload button here and I will click on
963:12 - my Transformer so as soon as I will
963:13 - click on this I will be able to select
963:15 - it then open it and here you can see my
963:18 - neural lab is saying entity is too large
963:21 - so what I can do here I can compress
963:23 - this PDF so for that I can use any uh
963:26 - online compressor so if uh your file
963:29 - size is little uh huge so in that case
963:32 - you can compress it if we are going to
963:33 - upload it inside your neural lab so here
963:36 - I'm writing about PDF uh
963:41 - compressor uh so here you can compress
963:43 - the PDF with any free compressor now
963:47 - here I'm using this particular uh
963:49 - website I'm opening my PDF and here it
963:52 - is giving the recommended compression
963:54 - now if I will click on the compress
963:58 - PDF so it got converted into a 137 MB
964:02 - from 2.11 MB now it is saying to me you
964:06 - can download it so I'm downloading this
964:08 - particular PDF and here Transformer
964:11 - compressor right so I got my compressed
964:13 - PDF it is very simple step you can open
964:16 - the Google and you can search about the
964:17 - PDF compressor if your PDF is too huge
964:20 - let's say see here we are using a PDF
964:22 - now for getting a data for collecting a
964:23 - data right real time data so for that
964:27 - only uh like I use this PDF compressor
964:29 - because this neural lab is not
964:31 - allying okay a file basically which is
964:34 - having the size around 2 MB 2.11 MB now
964:37 - let's see we are able to upload it or
964:39 - not so what I will do here I will use
964:41 - this Transformer compressed and if I'm
964:43 - going to upload it or still it is saying
964:46 - that request entity to larger okay just
964:49 - wait uh let me compress it again uh
964:51 - select PDF and here is a compress PDF
964:55 - because I want to make it a small only
964:57 - now extreme compressor okay this one
965:00 - only let's see what will be the size of
965:02 - it
965:04 - no just a
965:06 - second select PDF and here compress
965:12 - PDF extremely
965:16 - comparison uh the size is going to be
965:18 - 1.3 MB I don't think this lab will allow
965:22 - to me just a
965:28 - second otherwise I will have to use any
965:30 - other file um this just a second let me
965:35 - check so it is saying request entity too
965:38 - large no issue no worry uh see what I
965:41 - did actually let me show you my download
965:43 - section so here before the class itself
965:46 - I have uh I was exploring it and I
965:49 - downloaded couple of PDF so this was the
965:52 - PDF actually this was this is a YOLO
965:54 - research paper so let me show you this
965:56 - particular PDF this one see this is the
965:59 - YOLO research paper YOLO V7 okay YOLO V7
966:03 - as of now I was trying to show you
966:06 - with attention all your need paper but
966:08 - it is not allowing because uh the size
966:11 - is a little huge see the size of this
966:13 - compressed file 540 KB only now here the
966:16 - size of this Transformer compress around
966:19 - 1,339 so actually it is not allowing to
966:21 - me to upload this particular PDF so in
966:23 - that case what you can do so here uh you
966:26 - can uh we can use this YOLO V7 paper now
966:30 - what I'm going to do let me first of all
966:31 - rename this particular paper okay uh I
966:34 - will have to close it from here just a
966:35 - second now let me rename this paper so
966:38 - here I'm going to write it down YOLO V7
966:41 - so this is what this is my YOLO V7 paper
966:43 - and now let me upload it over there
966:46 - because I want a data and I'm going to
966:48 - read the PDF and from there itself I am
966:50 - going to collect my data for converting
966:52 - into a embeding so now see it we have
966:55 - uploaded this particular PDF so if your
966:57 - PDF is uh exceeding exceeding the size
967:00 - the size is around 1 MB so it won't
967:02 - allow to you you cannot upload the PDF
967:05 - in our neural lab so don't worry it will
967:07 - be solved in our near a future sessions
967:11 - so our team is working on that and it is
967:14 - U we are like uh making it more powerful
967:17 - as well so don't worry many more
967:19 - functionality will find out over here
967:20 - itself inside the lab now we got this
967:23 - YOLO V7 now what I will do guys so here
967:26 - I'm going to read this PDF so for that
967:29 - already I'm uh for that basically
967:32 - already I have imported this particular
967:33 - class so here I'm uh like passing it I'm
967:37 - copying and pasting over here and then
967:40 - here I'm writing PDFs right so once I
967:42 - will write on the PDFs so see it is
967:44 - giving me that PDFs is not defined uh
967:48 - PDFs where is a
967:51 - PDF okay so actually I will have to pass
967:53 - in a double code just wait let me take
967:56 - in a double code yes so I I'm able to
967:58 - load this PDF actually whatever we have
968:01 - inside this PDF folder now what I will
968:03 - do guys here I'm going to write down the
968:05 - loader so this is what this is my loader
968:07 - and now what I will do guys so here I
968:09 - will call loader loader. load right so
968:13 - by using this particular code I will be
968:15 - able to read my PDF see this is what
968:18 - this is my PDF now here I can collect
968:21 - this data so this is what this is my
968:22 - data which I'm going to be convert into
968:25 - a vectors with that I'm going to making
968:28 - a like embeddings and all and that
968:30 - embedding I'm going to store inside my
968:32 - dat database inside my Vector database
968:34 - which is a pine gon right so now let me
968:36 - show you this data so here is what guys
968:38 - here is my data which you can see over
968:40 - here and it is in a list format list
968:43 - form so here just press zero so you will
968:45 - find out all the data entire data
968:47 - basically uh whatever we have inside the
968:50 - PDF this is what this is my data right
968:52 - now here we are able to load the PDF now
968:55 - guys let me give you this particular
968:57 - code so at least you all can run inside
969:00 - your system so just a second
969:03 - uh here is a code guys this one for
969:05 - loading the PDF and here we have one
969:08 - more function that's going to be a data
969:10 - do load so loader do load actually just
969:14 - a second let me copy and paste over here
969:16 - this one so loader and here basically we
969:19 - have a PDF and we are able to load the
969:22 - data now uh yes we are able to get a
969:25 - data now what I will do guys so here I
969:28 - will perform the uh like a tokenization
969:32 - right right so here the next step is
969:34 - going to be a tokenization one let me
969:36 - show you uh The Next Step so what I'm
969:38 - going to do let me do one thing let me
969:40 - copy and paste and here is what here is
969:43 - my next step basically so just look into
969:45 - the step what I'm doing here I'm calling
969:47 - this recursive character text splitter
969:51 - right and here my chunk size will be 500
969:54 - and chunk overlap will be 20 right so
969:57 - just just go through and check over the
969:59 - Google or what you can do directly you
970:01 - can copy this particular import
970:04 - statement open it just just copy it and
970:06 - open your Google and paste it over there
970:09 - then you will get the complete
970:11 - definition of it over here inside the
970:12 - lench documentation now just look into
970:15 - that just look into this recover split
970:18 - by character so this text splitter is
970:21 - recommended for one for generic text it
970:23 - is parameterized by list of character it
970:26 - is trying to splitting one of them in
970:28 - order to until chunks are small enough
970:31 - the default list is this one means uh if
970:34 - it is going to find out any uh character
970:36 - right so based on this particular
970:38 - character is going to divide the data
970:40 - into a tokens this has the effect of
970:43 - trying to keep all paragraph and the
970:46 - sentences and the word together as long
970:48 - as possible and those would generally
970:50 - seems to be strongest semantically
970:52 - related piece of text so it is going to
970:54 - create a tokens it's going to uh split
970:57 - the text right if we are passing any
970:59 - sort of a text to this particular method
971:01 - so definitely going to be splited now
971:03 - over here see we are going to open this
971:05 - particular text here is what here is my
971:07 - data now I'm going to create a I'm going
971:09 - to import this particular class and here
971:11 - I'm passing the different different
971:13 - parameter so there is a chunk size so
971:15 - set a really small chunk size just to
971:17 - show so here the chunk size what 100
971:19 - chunk overlap 20 length function is
971:22 - length itself and is separator regx is
971:24 - equal to false right now here uh what I
971:27 - did so here I call this particular
971:29 - method create documented and here I'm
971:31 - going to pass my data so it will be able
971:33 - to create a chunks it will be able to
971:36 - create a chunks which is having a size
971:38 - of 100 and the overlap chunk overlap is
971:41 - equal to 20 right now let's do one thing
971:44 - let's try to do it by using R data now
971:47 - over here you can see we are able to
971:50 - create a object of it so Rec character
971:52 - text split chunk size 500 and Chun
971:55 - overlap is 20 now here I'm going to
971:57 - create a object of it so here is my
971:59 - object text splitter and after that guys
972:02 - what I will do I'm going to call one
972:04 - method over here so here let me show you
972:07 - the method this is what this is my
972:08 - method a text chunks to text splitter.
972:12 - split document this is what this is my
972:14 - method and to this particular method I'm
972:16 - passing my data right to this particular
972:19 - method I am passing my data now let me
972:23 - run it and here you can see we have the
972:26 - chunks of the text so text underscore
972:29 - chunks now here guys you will see so we
972:31 - are able to convert our text into a
972:35 - various chunks now let me show you so
972:37 - here this is inside the dictionary so
972:40 - let me do one thing let me first of
972:44 - all scroll down till
972:48 - last
972:50 - okay and here I'm going to pass this
972:53 - chance now here let me write down the
972:55 - zero so this is my first chunk right so
972:58 - we we have approximately 500 tokens
973:01 - right now of 500 chugs basically we have
973:03 - created from that and this is the like
973:05 - first one right now over here what I'm
973:08 - going to do see uh here I'm going to
973:11 - write it down the print statement right
973:13 - so I'm going to pass this value in a
973:14 - print function and here you will see
973:17 - that we have a data this is what this is
973:18 - my data now here textor chunks and in a
973:22 - square bracket we have a zero now what I
973:23 - will do I will call this page content
973:25 - right so pageor content so here guys you
973:28 - will find out this is what this is my
973:30 - content right so this is what this is my
973:32 - first one now let me show you the second
973:34 - one here is what here is my second one
973:36 - see uh the uh here if I'm passing first
973:39 - this is my second one right now this is
973:41 - what this is my third one right so here
973:43 - what I can do I can pass two and this is
973:45 - what this is my third chunk so we are
973:48 - going to convert or we are going to
973:50 - divide our data into a chunks right and
973:53 - this is the first chunk this is the
973:55 - second chunk now here is a third chunk
973:57 - this is what this is my chunk actually
973:59 - and from where from our PDF data
974:02 - right from our PDF data now if you will
974:05 - check the length of it so here let me do
974:07 - one thing let me check the length of
974:10 - this textor chunks right so here is the
974:14 - length of text underscore chunks Chu Ms
974:19 - now you will find out the chunks length
974:20 - is 152 means total 152 are like
974:24 - paragraphs you will find out from the
974:26 - data itself right so the chunks
974:28 - basically which we are making which we
974:30 - which we have made are from from the
974:32 - data itself the data which we have
974:34 - loaded right so here is what here is my
974:36 - 152 chunks and this is my first second
974:38 - third now you can print the 152 chunks
974:41 - as well so here what you can do you can
974:43 - write it down the
974:44 - 151 actually that will be a 152 chunks
974:47 - because the index is going to start from
974:49 - the zero so now let me print it and here
974:51 - you will find out the last one so former
974:54 - 4 and 2 and object detection in
974:57 - proceeding the International Conference
974:59 - or learning representation now if you
975:01 - want to do it see here uh I did it
975:04 - randomly means uh if you will look into
975:06 - the first chunk it is going to stop over
975:07 - here if you look into the second chunk
975:09 - it is going to be stop over here but if
975:11 - you want to do it based on any
975:13 - requirement right and based on any
975:16 - meaningful context which uh which is
975:18 - like required according to your problem
975:20 - statement so for that you will have to
975:22 - look into the data you will have to
975:23 - perform the text preprocessing over
975:25 - there right and then only you you will
975:27 - have to put some sort of a logic then
975:29 - okay if this thing is coming then only
975:31 - you have to cut the data if this thing
975:32 - is coming then only you have to cut the
975:34 - data right so here you will see guys uh
975:37 - like we are able to create uh like
975:40 - chunks over here right so um there is uh
975:44 - total 152 actually now what I will do
975:48 - after doing this thing uh I have shown
975:50 - you the chunks and all now let me show
975:52 - you the next one now what I will do guys
975:54 - here uh first of all let me uh open the
975:58 - openi openi API key now here I'm going
976:01 - to write it down this uh import OS and
976:04 - here OS do os. getb now here what I'm
976:09 - passing I'm passing this open API key
976:12 - right I'm going to set my open API key
976:16 - so all value will be in a cap so open AI
976:21 - underscore API underscore key got it now
976:24 - here I'm going to pass my API key now
976:27 - let me generate the API ke I think I
976:29 - already generated it let me copy it from
976:30 - there itself h let me open the open okay
976:34 - here it is this one this is the OPI key
976:36 - now what I can do I can paste it over
976:39 - here this one so yes I'm able to set my
976:43 - open AI API key right this is fine okay
976:49 - now get En the
976:52 - assignment what is this okay open AI
976:56 - which I don't want to fetch it actually
976:58 - I want to set it so there is a different
977:01 - uh like name in wire e
977:04 - NV R actually this is the name so I want
977:08 - to set the like API key in my
977:11 - environment variable in my system
977:13 - environment variable so this is the
977:15 - method got it now this is fine we have
977:18 - created a chunks and uh everything is
977:22 - fine now what I will do I will create a
977:25 - object of the open embeding open emding
977:28 - class so let me show you what I can do I
977:31 - can open my my open a let me open the
977:34 - open a itself just a
977:37 - second open AI right now here uh just go
977:41 - with the documentation just just click
977:43 - on the documentation over
977:47 - here yeah this is what this is your
977:49 - documentation just scroll down there you
977:51 - will find out the embeddings got it now
977:54 - click on the embeddings here is
977:55 - embedding now uh what you need to do
977:58 - guys here you need to import this
978:00 - embedding okay this this particular
978:03 - embeddings okay so if if I want to
978:05 - convert my data into a vectors if I want
978:07 - to if I want to make it like the vector
978:11 - actually the context Vector so I I'm
978:14 - going to use this embedding from the
978:16 - open a now how I can do that how I can
978:19 - use it let me show you so for that what
978:22 - uh you can do so here uh we have a class
978:25 - direct class actually open I aming which
978:27 - I which I have imported over here if you
978:29 - will look into the import statement
978:30 - right so already I have imported this
978:32 - thing and where it is let me show you
978:35 - over here see this one open AI right uh
978:38 - open AI M okay this one uh where it is
978:41 - open embedding so from Lang CH actually
978:43 - we are going to import this openi
978:44 - embedding now what I can do I can create
978:47 - a object of it so I'm going to create a
978:49 - object of the open a embedding and here
978:52 - what I'm going to do I'm going to keep
978:54 - this thing inside the embedding itself
978:56 - so this is what this is my embedding
978:58 - right open a embedding okay now the next
979:01 - is what so here I'm going to write it
979:03 - down I'm going to call one method so the
979:05 - method is what the method is nothing so
979:07 - aming dot and here I'm writing idore
979:11 - query so idore query and here what I
979:15 - will do guys here I'm going to pass
979:16 - something so here I'm passing how are
979:19 - you right so once I will run it so here
979:22 - I have passed how are you now see it
979:24 - will generate the embedding for it see
979:26 - guys it have generated an embedding if
979:29 - see I told you how it is going to
979:31 - generate embeding bding it's going to
979:32 - generate an amb bidding based on a
979:34 - features right based on a feature so I
979:37 - told you guys see uh when I was talking
979:40 - about the word to bag right just a
979:42 - second when I was talking about the word
979:45 - to bag when I was talking about the word
979:47 - to back so actually there was there was
979:51 - the vector that the size was the vector
979:54 - of 300 right 300 Dimension now if you
979:57 - will look into the open AI embedding so
979:59 - let's check the size of that so so uh
980:02 - this sentence actually they have
980:03 - converted into a vector now let's look
980:06 - into the size that what size I'm getting
980:08 - or for this particular Vector so over
980:10 - here I can copy it and what I can do
980:13 - just a second let me scroll down because
980:16 - the vector size is very very huge uh
980:20 - just a wait here is what here is my
980:28 - embedding
980:30 - okay
980:32 - just just wait guys so let me keep it
980:34 - inside the
980:40 - variable yeah here it is this one so
980:43 - what I can do I can directly call this
980:44 - length function over here so let me show
980:47 - you the number of embeddings over
980:49 - here so the number of embedding is 1 53
980:53 - 6 this is the length of the embeded
980:56 - vector getting my point guys yes or no
980:59 - so here is my sentence how are you I
981:01 - given this sentence and based on this
981:04 - sentence is it has generated one vector
981:06 - which is the size of the vector is 1 53
981:09 - 6 the size of the vector is 53 6 got it
981:14 - so I hope this part is clear to all of
981:17 - you now um I got the vector I got the
981:21 - length also now let's try to discuss so
981:25 - here uh we have this open AI right so we
981:27 - have this open a actually uh we have the
981:30 - open a API we able to call this open a
981:32 - embeddings everything is working fine
981:34 - everything is uh going seamlessly right
981:37 - now over here this is my data also so we
981:39 - have a data we have a open a now it's
981:41 - time to import this pine cone right so
981:44 - now let's uh like import the pine cone
981:47 - and whatever embedding we are going to
981:49 - generate from here so the embedding I'm
981:51 - going to store in my pine cone Vector
981:53 - database so for that basically what I'm
981:55 - going to do here uh here uh the first
981:58 - thing which I'm going to write it down
982:00 - that's going to be my Pine one API key
982:02 - right there is two thing two variable
982:04 - now what I can do till here I think
982:06 - everything is fine and please set your
982:09 - openi key and call the just just create
982:12 - this model let me give you this uh thing
982:14 - over here this one so you all can copy
982:17 - and you all can run along with me and
982:20 - this is also let me remove it as of now
982:23 - from here and Yep this is the one now
982:27 - you need to write it down your own so
982:30 - here is what here is the open AI key
982:34 - which you need to set right and the next
982:36 - one open a embedding and here if you're
982:39 - going to call it then everything is
982:43 - going fine right so just a second this
982:47 - is the length of the ambic now the next
982:49 - one basically what I can do here I can
982:51 - give you this particular code also so
982:54 - okay first of all let me remove this
982:56 - thing this particular thing and here let
982:59 - me remove this thing also so fine uh now
983:03 - it is clear and you can run along with
983:05 - me so please check out the link this Cod
983:08 - share. link inside the uh inside the
983:11 - chat box guys and please try to copy
983:13 - from there please try to copy this code
983:15 - from there right now uh see guys uh one
983:18 - more thing if you are liking the session
983:20 - then please hit the like button okay
983:23 - this motivates me a lot and please write
983:25 - down the comment please be active in the
983:27 - chat if I'm asking something see I've
983:29 - seen many people are seeing this this
983:30 - one many people are watching it in a
983:32 - live uh in a live mode but they don't
983:35 - interact actually please be interactive
983:38 - if you are interacting that definitely I
983:39 - will also get a motivation I will show
983:41 - you like two to three more new thing if
983:43 - you're not doing that in that case um it
983:47 - will be hard for me also I will stop it
983:49 - this session by explaining you one or
983:51 - two concept only if you are asking to me
983:53 - then basically definitely I will explain
983:56 - you few more thing few more concept got
983:59 - it so please be interactive please write
984:01 - down the chat and please hit the like
984:03 - button if you're liking the session so
984:05 - far now guys here what I need to do I
984:08 - need to set the pine con API key right
984:11 - Pine con API key so from where you will
984:14 - get it so just open the pine con website
984:16 - so here is my pine cone just go inside
984:18 - the API key and here is my API key so
984:21 - you can use the default also or you can
984:23 - create the new also so here I have
984:24 - created a new one so let me copy this
984:26 - particular key and let me paste it over
984:29 - here that is the first thing which I
984:30 - need to do right the second thing I need
984:33 - to pass pine cone API environment so
984:36 - where I will get it where I will find
984:37 - out this pine cone just click on the
984:39 - fine code website here is the
984:40 - environment name just copy this thing
984:42 - copy this gcp starter and here you can
984:45 - paste it inside the double code right so
984:48 - I think both thing is fine now let me
984:49 - set it okay this is fine this is clear
984:53 - now guys what I need to do here I need
984:54 - to import the pine C so here I'm going
984:57 - to import the pine C yes uh I imported
985:01 - it not an issue so there is no such
985:03 - issue with that now here guys what I'm
985:05 - going to do so I'm going to call one
985:09 - method and this method is going to be a
985:11 - very very important so my method name is
985:13 - what pine cone in it right see guys over
985:17 - here just just look over here uh this is
985:19 - not a typical at all what we are going
985:21 - to do see uh this is the method and
985:24 - which method we are going to call Pine
985:26 - con. init so here itself in a pine con
985:28 - documentation you will find out let me
985:30 - show you uh just just search over the uh
985:32 - just click on this document and here is
985:35 - what here is a pine cone documentation
985:38 - now just just click on the quick start
985:40 - uh once you will click on the quick
985:42 - start now so there you will find out the
985:45 - like all the thing right so here you
985:48 - need to import the pine cone here you
985:50 - need to set or you need to set your API
985:53 - key and your environment name everything
985:55 - is here everything over the like website
985:58 - itself in the documentation itself I'm
986:00 - taking a reference from the
986:01 - documentation now the next thing is what
986:04 - you need to call this init method so let
986:06 - me do it and let me run it yes this is
986:09 - done we are able to do it and here I can
986:12 - give you this code as well inside the
986:15 - code
986:16 - share. so this is the code guys which
986:19 - I'm going to paste and there is what
986:21 - there is an import statement also which
986:23 - I'm going to paste over here just a
986:26 - second so you can copy along with me and
986:28 - you can run it you can test it because
986:30 - it is going to be a more interesting now
986:33 - so this last 20 minutes is a climax of
986:35 - the session is going to be a more
986:37 - interesting so just wait for next 20
986:39 - minute and you will see the magic right
986:40 - so how efficient it is how like it is
986:43 - working actually you will find out a
986:44 - final conclusion over here now we have
986:47 - initialize it now the next thing we have
986:49 - to initialize the index name so here is
986:51 - what here is my index name which I have
986:53 - to initialize so where I will find out
986:55 - the index name so just go through with
986:59 - your pine cone and here click on the
987:02 - indexes here right so click on the
987:05 - indexes and click on this create index
987:07 - see this uh actually this pine cone now
987:11 - it is running on top of the cloud once
987:14 - you will search over the uh once you
987:15 - will search about this pine cone just
987:17 - let me show you uh search about the pine
987:21 - cone so open open the website and here
987:26 - you will find out
987:27 - that it is working on top of the cloud
987:30 - so the server basically which is
987:32 - using Cloud
987:38 - Server the AWS Ser or a server anything
987:42 - we can use
987:59 - okay
988:21 - uh just a second guys just a second just
988:22 - a wait uh I think I'm getting some issue
988:25 - with the connection just allow me a
988:28 - minute just
988:29 - wait
989:27 - yeah now I think it is fine so
989:35 - yep now it is clear now it is fine so
989:37 - here guys you can see if we are talking
989:39 - about if we are talking about this pine
989:41 - cone right so if we if we are talking
989:44 - about this pine cone now so this
989:46 - actually it is being created on top of
989:48 - the Cloud Server so here they have given
989:51 - you the entire detail so just check with
989:53 - the product uh so each and everything
989:56 - you will get about this pine cone right
989:58 - and here you will find out that it is
990:00 - going to fully managed by the AWS server
990:03 - either you can use AWS or Google or
990:06 - Azure and here there is a pricing detail
990:09 - also so you will find out the pricing
990:10 - detail how much it's going to be charged
990:13 - for the specific P for the indexes the
990:15 - index which you are going to create how
990:17 - you can scale it right everything you
990:19 - will get it so as of now we are using a
990:21 - free plan free tire of the spine cone
990:24 - but it is getting uh it's a chargeable
990:26 - also so you will see the prices and all
990:28 - prices is 0.096 per hour 0.111 144r
990:32 - right this this for the Enterprise the
990:34 - standard this the like just a free
990:36 - version of it just just go through with
990:39 - the website everything you will find out
990:41 - over there itself now here I have to
990:44 - create the index name now how I can do
990:47 - it how I can create the index name so
990:49 - just click on the index this this
990:51 - particular index and here it will give
990:53 - you the option for creating index so
990:55 - just write it down your name let's say
990:57 - my index name is testing and here you
990:59 - need to mention the Dimension right so
991:02 - just look into the dimension that what
991:04 - was the dimension over there so let me
991:06 - uh do one thing let me show you the
991:08 - dimension of that so for that basically
991:11 - just scroll up see here 1 1536 so this
991:14 - was the dimension actually when I
991:16 - checked uh with the open I'm Ming so
991:19 - here you will find out that this is the
991:20 - dimension which I'm getting you you can
991:22 - check with regarding the other sentences
991:24 - also so here uh let's say if I'm saying
991:26 - something whatever uh let me do one
991:29 - thing let me copy and let me paste it
991:31 - over here here I'm saying uh I am fine
991:34 - right hi hi I am fine so this is what
991:39 - this is my like sentence which I'm
991:41 - writing over here now you will find out
991:42 - the embedding and let me show you the
991:44 - dimension of this particular embedding
991:48 - now here you will find out the dimension
991:50 - is around 1 536 it's the same one right
991:54 - so this Dimension is nothing it's a
991:55 - feature right so how many feature is
991:58 - there I I told you now uh when I'm
992:01 - talking about word to back there is 300
992:03 - feature I shown you this example just
992:06 - just look into this particular example
992:08 - so we this is a vocabulary and we have
992:09 - five feature by using this five feature
992:12 - I'm representing my data so here
992:15 - actually in opena edding there is 1 5 3
992:18 - six feature by using that they are
992:21 - representing a data so here the size of
992:24 - the embedding is going to be 1536 so
992:27 - what do you need to do guys here you
992:29 - need to write it down 1 53 6 now it will
992:32 - ask you about the metrix so what should
992:35 - be the metrix for the for the simulat
992:37 - search so here there is a three option
992:40 - dot product equan and cosine so here I'm
992:42 - using the cosine because the uh cosine
992:45 - is a uh like little impactful compared
992:47 - to this dot product and the ukan right
992:50 - so here just click on the cosign and
992:52 - here I'm using the free plan free plan
992:55 - of the pine cone right so now this is
992:58 - fine this is clear let's create a index
993:00 - over here if you are going to click on
993:03 - this create index so it is creating an
993:05 - index so index creating file to create
993:07 - capacitor is okay so I already created
993:09 - one index now see uh yeah now it is fine
993:13 - uh it is created and here you can click
993:15 - on the connect and there this will give
993:17 - you the all the details and all now this
993:20 - is what this is my index name testing is
993:22 - what testing is my index name I hope you
993:24 - are able to create this index and here
993:26 - you will get this Green Dot green icon
993:30 - now what I can do I can pass the name so
993:32 - here I can write it down the index this
993:34 - my index name that is what that is a
993:36 - testing right so here is what here is my
993:38 - index name that's going to be a testing
993:40 - now what I will do guys I will run this
993:42 - particular line This one this uh which I
993:45 - shown you uh this one pine cone do index
993:49 - and equal to index so let me copy it and
993:52 - let me paste it over here let me paste
993:55 - it over here and here what I need to do
993:57 - guys tell me here I need to pass my
994:00 - index name this one right so this this
994:02 - index name actually I can pass directly
994:04 - means I can pass this particular name or
994:06 - I can pass directly also both are fine
994:08 - right so I believe you are able to set
994:10 - your index now what I will do guys so
994:13 - here um just a bit okay so now guys you
994:18 - need to create an embedding for each uh
994:21 - text Chunk so let me copy it and let me
994:24 - paste it over here this one this is
994:27 - going to be here this one so this is
994:29 - what this is my markdown actually just
994:31 - let me write it down like this yes so
994:33 - now you need to create an embedding for
994:35 - each chunks okay so this is what this is
994:37 - my index and now till here everything is
994:39 - fine right now guys what I will do so I
994:41 - need to create an embedding right so for
994:43 - that let me show you the code so here is
994:45 - the entire code this one this is my
994:47 - entire code so till here everything is
994:49 - fine you just need to call this one you
994:52 - just need to set this one let me give
994:54 - you this code as well so from here you
994:56 - can copy from my
994:58 - uh from my code share. you can copy just
995:02 - a second just a wait let me give you
995:05 - this
995:05 - particular like line of code and here
995:08 - guys you will find out so now we have to
995:10 - create an embedding for each of the text
995:13 - Chunk so whatever uh Chunk we have
995:15 - created from our PDF I'm going to create
995:17 - an embedding for that now here I'm
995:19 - saying from text t. page see I'm taking
995:23 - a uh text actually uh this is a list now
995:27 - so here I'm uh using this list
995:29 - comprehension so so this is my list of
995:31 - the text junk this is a text which we
995:32 - are getting now from here we are going
995:34 - to get a page content what is a page
995:36 - content I shown you this is a page
995:38 - contain this
995:40 - one so I'm using this for Loop and I'm
995:43 - collecting all the page content over
995:45 - here and I'm calling this embedding I'm
995:47 - using this I'm using this embedding
995:49 - object and here is my index name index
995:53 - name basically which I'm uh like which I
995:55 - have created this one okay this is my
995:58 - index name okay testing is my index name
996:00 - so three argument we are passing over
996:03 - here so Pine con from text and this is
996:06 - what this the three argument which we
996:07 - are passing over here first is data
996:10 - first is what first is a data the second
996:13 - is embedding and the third is what third
996:15 - is a index name right this one now if I
996:18 - will run it so over here you will find
996:20 - out that it is saying embeddings is not
996:23 - defined okay my name is iding only now
996:25 - let me keep it iding yeah it is fine and
996:28 - it is working
996:30 - so here is clear to all of
996:35 - you uh guys can you see
996:42 - my okay so can you see my vs code uh it
996:46 - is visible to all of you uh just a
996:54 - [Music]
996:59 - second now it is visible yes or
997:10 - no just a second guys just a second let
997:13 - me check
997:24 - once wait wait wait wait I'm checking
997:26 - don't worry don't worry I'm checking
997:28 - right just just wait just allow me a
997:29 - minute
997:37 - yeah yeah wait guys wait I'm checking
997:40 - just allow me a minute just allow Me 2
997:41 - minute I'm checking with that now it is
997:44 - working fine now it is coming to all of
997:46 - you now can you see my code screen this
997:51 - one yes or
997:57 - no don't worry I will repeat it I will
998:00 - uh revise all the thing don't worry
998:02 - right just a second just a
998:27 - wait don't worry I can revive why is the
998:30 - thing whatever I did over here so just a
998:33 - second now see uh what I was saying we
998:36 - have created an index right so till
998:38 - index I think it was fine now I just
998:40 - created a embedding for each of the text
998:42 - Chunk means whatever chunks we have
998:44 - created now for that I'm going to create
998:46 - a indexing means I'm going to create a
998:48 - emitting right now from here actually
998:51 - see this is my text Chunk this is what
998:53 - this is my text Chunk one uh like uh uh
998:56 - basically I'm iterating on top of that
998:58 - I'm iterating on top of the chunks so
999:00 - here right now I'm getting the uh like
999:02 - first chunk and then I'm collecting the
999:04 - page content similarly you can see over
999:06 - here this one I'm going to collect a
999:08 - chunk now I'm going to collect a chunk
999:10 - Now by using this particular list
999:13 - comprehension by using this particular
999:15 - list comprehension I'm going to collect
999:16 - a chunk now here is my embedding object
999:19 - which I have passed and here is my index
999:21 - name which I have created by using the
999:23 - pine cone website right now just look
999:26 - into this code share. there I have given
999:28 - you the entire code till here now let me
999:30 - give you the last line also which I have
999:33 - run uh which I have created over here so
999:36 - here let me give you this particular
999:37 - line and here is what here is my dog
999:39 - search this one now guys what I will do
999:41 - this is what this is my dog search right
999:43 - now I have to call something first of
999:45 - all let me show you that what we have
999:47 - inside this dog search actually you will
999:49 - find out one object this is what this is
999:51 - the object right this is what this is
999:52 - the object see uh here is what here's a
999:56 - pine code now from text actually what
999:58 - I'm going to do from text text I'm going
1000:00 - to create a embedding so whatever text
1000:03 - whatever chunks whatever chunks we have
1000:06 - right whatever chunks we have regarding
1000:08 - those particular chunks we are going to
1000:10 - create a embeddings right so here uh you
1000:13 - can see we are going to call Pine Cone
1000:15 - Dot from text and here is what here is
1000:18 - my text and here is my edding right and
1000:21 - here is what here is my index name don't
1000:23 - worry if you are not able to connect I
1000:24 - will give you the quick revision at the
1000:26 - end right first just just look over here
1000:28 - and just see what what is happening over
1000:30 - here right so this is what guys this is
1000:32 - my dog search now what I will do let me
1000:34 - show you the next line Next Step that
1000:36 - what I'm going to do over here okay so
1000:38 - here actually uh I'm going to find out a
1000:41 - s see uh after running this particular
1000:44 - uh statement this Pine cone. fromom text
1000:47 - right so here you are going to generate
1000:49 - an embedding now just look into the
1000:51 - dashboard the dashboard basically which
1000:53 - we have over here uh let me show you so
1000:56 - once you will refresh it now this one so
1000:58 - here you will find out all all the
1001:00 - embeddings all the embeddings from our
1001:02 - PDF from our text right so just wait let
1001:05 - me uh show you that here guys see this
1001:08 - is what this is all the embeddings here
1001:11 - is my uh text which I tokenize which I
1001:14 - converted into a small small phrases and
1001:17 - regarding that here is a embedding this
1001:19 - one just just copy it and check it is a
1001:22 - embedding Vector so this this text
1001:24 - actually we are able to convert into a
1001:27 - embeddings we are able to convert into a
1001:29 - vector vectors and here you will find
1001:31 - out the score also so this is
1001:33 - representing a similarity score right
1001:36 - how much it is similar to other
1001:37 - sentences to other
1001:40 - phrases right here you can see uh this
1001:43 - is what this is my Ming don't don't
1001:45 - worry if you not able to correlate just
1001:47 - wait for some uh just wait for few
1001:50 - minutes I will give you the quick
1001:51 - revision of it right I will give you the
1001:53 - quick revision by writing each and
1001:54 - everything and then definitely you will
1001:56 - be able to get it now here uh you can
1001:59 - see this is what this is my embedding
1002:01 - related to the particular text right and
1002:03 - here what we have we have a score right
1002:06 - related to this particular text we have
1002:07 - a score this is what this is the score
1002:09 - now what I will do so yes we are able to
1002:12 - create an embedding and that embedding
1002:14 - uh here you can see uh like it is
1002:16 - visible you can uh access here also
1002:19 - right by using this dog search uh I will
1002:22 - show you how so first of all let me show
1002:23 - you one example one uh small thing so
1002:26 - what I'm going to do I'm doing a
1002:28 - similarity search now here I'm writing
1002:30 - query actually in the in my query
1002:32 - actually what I'm doing I'm writing uh
1002:35 - one statement and let me do the
1002:37 - similarity search over here so here is
1002:39 - what here is my sentence guys which I
1002:41 - have written over here YOLO V7
1002:44 - outperform which model right so this is
1002:46 - what this is my question this is my
1002:47 - sentence now here is what here is my
1002:49 - query which I'm going to uh which I have
1002:51 - written basically now what I'm going to
1002:53 - do I'm going to find out a similarity
1002:55 - search right so let me do one thing let
1002:57 - me find out the similarity search Now by
1002:59 - using this Vector so here in this
1003:01 - particular object we have all the
1003:03 - vectors now I'm going to call one method
1003:06 - that's going to be a similar to suchar
1003:08 - and here we are going to pass our query
1003:11 - this this particular query which I have
1003:12 - written now let me show you what I will
1003:14 - get over here so here you can see as
1003:17 - soon as I run this particular uh uh like
1003:20 - uh line okay this particular code so in
1003:22 - the docs what you will find out let me
1003:24 - show you so in the docs actually you can
1003:27 - see this is the similarity search right
1003:29 - this is the similarity search basically
1003:31 - which we are able to get but the thing
1003:33 - is over here we are getting in the form
1003:35 - of Vector in the form of numbers it is
1003:38 - not a proper sentences right now let me
1003:41 - show you how we can convert this number
1003:44 - into a sentences right so I hope till
1003:47 - here everything is fine don't worry if
1003:49 - you're not able to correlate if you're
1003:50 - not able to understand once we'll create
1003:53 - a project or right after the session
1003:55 - after this particular session I will
1003:57 - give you the quick recap of it right so
1003:59 - based on that based on the quick recap
1004:01 - you can correlate this particular
1004:03 - implementation and then you can revise
1004:05 - it right and then you can revise each
1004:07 - and everything so over here you can see
1004:09 - this is what this is my embedding this
1004:11 - is my similarity search which I'm able
1004:13 - to generate by using this particular
1004:15 - query now I'm getting a number but I
1004:18 - want a sentence how I can get it let me
1004:21 - show you that also so for that guys what
1004:24 - you need to do uh you need to create a
1004:27 - llm means you need to call the uh uh
1004:30 - like open API so over here uh we have
1004:33 - this open method open a and here I'm
1004:36 - going to create a object of it so yes
1004:39 - definitely I'm able to call my open a
1004:42 - API this one by using by creating this
1004:44 - particular class right so here is what
1004:47 - here is my llm right step by step step
1004:49 - by step I'll try to go ahead don't worry
1004:51 - now what I'm going to do here uh here
1004:54 - actually I'm going to call this
1004:55 - particular method the method name is
1004:57 - what retrieval QA right so this is what
1005:00 - this is my method name retrieval Q QA so
1005:03 - this is a method this uh actually this
1005:05 - class actually this is not a method this
1005:07 - is a class and inside that we have a
1005:09 - method the method name is from chain
1005:11 - type so this is responsible for question
1005:13 - answering if I want to create a question
1005:16 - answer system so here in the open a
1005:18 - itself you'll find out this retrieval QA
1005:21 - right retrieval QA and inside that we
1005:23 - have a method the method name is what
1005:25 - from Chen type so here what we are doing
1005:28 - we are passing this l M we are passing
1005:30 - this chain type is stuff retriever is
1005:32 - dog search do as retriever right this uh
1005:37 - dot s retriever here you will find out
1005:40 - this particular method right don't worry
1005:41 - again I will explain you this particular
1005:43 - part uh first of all let me run it and
1005:45 - let me show you that what I will get
1005:47 - from here so here I'm running it and
1005:50 - here you can see we are able to create
1005:51 - this QA the object of this retrieval QA
1005:54 - right now guys what I will do here let
1005:56 - me write down the query again right so
1005:59 - here is what here is my query this is
1006:01 - what this is my query now what I will do
1006:03 - I'm going to um write down QA do run
1006:08 - right and inside this run I am going to
1006:11 - pass I'm going to pass my uh like query
1006:16 - actually this is what this is my query
1006:18 - and let's see what I will be getting
1006:19 - based on that so here if I will write it
1006:21 - down this Q qa. run and inside my query
1006:25 - so now see guys what I'm getting over
1006:27 - here um see I'm getting a similar see
1006:31 - I'm getting an answer regarding this
1006:32 - particular question I'm getting a
1006:34 - similar search right I'm getting a
1006:37 - similar search over here regarding this
1006:39 - particular question now if I want to
1006:41 - create a QA the small uh QA system so
1006:45 - can I do it definitely we can do it now
1006:47 - let me show you how we'll be able to
1006:49 - create a small QA session over here so
1006:52 - based on the PDF basically the PDF uh
1006:55 - which uh I I'm using uh for the data
1006:58 - right and with that I have generated a
1007:00 - vector I have created an embedding and
1007:02 - now over here you can see we are able to
1007:04 - do the query also here you will find out
1007:07 - so we are able to get it we are able to
1007:09 - uh we are getting this similarity search
1007:11 - in the form of uh numbers in the form of
1007:13 - vector but here once I call this llm
1007:16 - once I call the openi API and here is
1007:19 - what here is my llm so I uh just use
1007:21 - this retrieval QA and there I passed my
1007:23 - llm I passed my uh retriever that's
1007:27 - going to be a uh doc search itself right
1007:30 - doc search itself let me show you what
1007:31 - is this doc search it's the same object
1007:33 - basically where my all the embedding is
1007:36 - stored right so here what I can do I can
1007:39 - show you this uh doc search. as
1007:42 - retriever now see guys here what we have
1007:44 - we have the pine cone actually this is
1007:47 - the vector database openi we are using
1007:49 - openi embedding and here my all the
1007:52 - embedding is stored inside this
1007:54 - particular object right now you can see
1007:56 - over the uh UI also so here is all the
1007:59 - embedding this one right regarding the
1008:02 - data now what I can do see I can create
1008:04 - one small uh QA session U like QA system
1008:08 - over here for that I just need to write
1008:10 - it down the basic uh code so here is my
1008:14 - basic code guys this one so let me
1008:17 - import one module over here that's going
1008:19 - to be a CIS now what I'm saying that uh
1008:22 - here I'm asking about the input so
1008:24 - whenever I'm going to write it down the
1008:26 - exit so it will be exit right in this
1008:29 - condition I have mentioned that but here
1008:31 - if I'm not uh writing down anything
1008:34 - right so here it will be if I'm going to
1008:36 - write down anything apart from this exit
1008:38 - it will be continue and here you can see
1008:40 - what we are doing QA so here we are
1008:42 - passing the query whatever query we are
1008:44 - getting from here and finally we are
1008:45 - printing the answer right finally we are
1008:48 - printing the answer now let me show you
1008:50 - how the thing is running this this
1008:52 - particular thing basically so what I can
1008:54 - do let me run it and here I'm passing my
1008:57 - input prompt so my input let's say I'm
1009:00 - asking about the YOLO what is uh YOLO so
1009:05 - here see based on this particular query
1009:08 - it is giving me an answer it is finding
1009:09 - out the iding it is finding out the
1009:11 - similarity search and it has generated
1009:13 - an answer based on a PDF so this is a
1009:15 - PDF question answering right we are
1009:17 - asking a question from the PDF and based
1009:21 - on an embedding it is able to generate
1009:23 - answer now I think you are able to
1009:26 - correlate it that how the thing is
1009:27 - working I will give you the complete uh
1009:30 - flow right don't worry now here I'm
1009:32 - asking who is
1009:34 - invented who is invented the YOLO right
1009:38 - so this is what this is my question now
1009:40 - let's see so here I got the name I got
1009:43 - the name now uh can you tell me about
1009:46 - the so here what was the accuracy what
1009:50 - was the
1009:51 - accuracy what was the accuracy of the
1009:54 - YOLO right so YOLO 7 uh YOLO V7 now
1009:59 - let's see what I will be getting over
1010:01 - here so here it is saying that YOLO V7
1010:04 - accuracy was
1010:06 - 56.8 and here 56.8 AP uh test /d and AP
1010:12 - Min SL value right so the accuracy we
1010:14 - are getting now if I will write down
1010:16 - exit over here so from here I'm going to
1010:18 - exit now right from this question answer
1010:21 - system now guys tell
1010:27 - me
1010:44 - uh yeah now it is perfect uh please
1010:48 - quick uh give me a quick confirmation in
1010:50 - the chat if it is perfect now yeah there
1010:53 - was a issue from the internet side uh
1010:56 - from the system side I don't know what
1010:58 - was the sh screen got a stuck in between
1011:22 - itself okay so let's uh try to revise
1011:25 - this session I can give you quick
1011:26 - revision of that and then uh we can
1011:29 - close the session within 5 minutes right
1011:32 - so here uh guys uh first of all see I'm
1011:35 - using a pine cone and pine gon is what
1011:38 - it's a vector database right so there
1011:40 - are couple of import statement which I
1011:41 - imported now after that see what I want
1011:44 - to do I want to perform the mding right
1011:48 - I want to perform the mding so on top of
1011:51 - the on top of the data only I will I I
1011:54 - I'm going to perform now so I will be
1011:55 - having a data the data is going to be
1011:57 - Text data so from where I'm getting this
1012:00 - data I'm getting this text Data from the
1012:03 - PDF the PDF which we have imported right
1012:06 - the YOLO PDF the YOLO PDF right now here
1012:09 - is what here is my PDF after uh
1012:12 - importing the data what I did right
1012:14 - after that I converted into a chunks by
1012:17 - using this text splitter so here one
1012:19 - chunk size will be approx 500 wordss
1012:22 - right inside one chunk we'll be having
1012:24 - the 500 wordss and chunk overlap I've
1012:26 - given the 20 it's just the score that
1012:28 - how many any uh like words can be
1012:30 - overlap in each and every chunk right
1012:32 - the chunk has been created now this is
1012:35 - going to be a chunk size this is going
1012:36 - to be a overlapping now this value you
1012:38 - will find out the value of this Chun
1012:39 - overlap between 0 to 100 right you can
1012:41 - mention the value according to that so
1012:43 - we have created a several chunks this is
1012:45 - the list basically which I got after the
1012:47 - chunking so here we have total 153 chunk
1012:51 - and the each chunk is having average 500
1012:53 - wats means the size is around 500 over
1012:55 - here got it so this is what this is my
1012:57 - chunk now you will find out the complete
1013:00 - list and here you will find out 152
1013:02 - chunks right from the data I converted
1013:05 - my data into a chunks and there is 152
1013:07 - chunks actually see over here now if you
1013:10 - want to find out the content the data
1013:12 - from each and every chunk so here is a
1013:14 - like way so this is my first Chunk from
1013:16 - that uh like on top of that I'm just
1013:18 - going to be call this particular
1013:20 - attribute page content and there is what
1013:22 - there is my page content there is what
1013:24 - guys there is my page content over here
1013:26 - which you can see now guys uh here uh
1013:30 - you can see this is what this is my page
1013:32 - content now you can uh get uh like page
1013:35 - content and all with respect to each and
1013:37 - every chunk till 152 right over here now
1013:41 - over here I have to set my open AI key
1013:43 - first of all after chunking and all this
1013:45 - is fine now I have to set my openi key
1013:48 - and from there I have to import this
1013:50 - Ming now the size of the mding is 1536
1013:54 - this is based on a feature right so this
1013:57 - is the size of the embedding now this is
1013:58 - fine so first I got the data the second
1014:02 - I have uh imported the open a embedding
1014:05 - the third one I have seted this key
1014:07 - right so here I set the key key Pine con
1014:11 - API key and pine con API environment so
1014:13 - here I have to set two thing the first
1014:15 - is what Pine con API key and the second
1014:18 - is Pine con API environment is after
1014:21 - that you can see over here I'm going to
1014:22 - call this Pine con init now here I'm
1014:25 - going to pass this Pine con API key and
1014:27 - pine con API inv environment right I
1014:29 - have initialized it that's it now here I
1014:32 - have to create an index so for creating
1014:34 - an index just go with a pine con and
1014:37 - here you will get a option to create an
1014:39 - index right you can create a new index
1014:41 - but if you are in a free tire so in that
1014:43 - case you will be able to create only
1014:45 - single Index right and while creating an
1014:48 - index you need to pass a index name you
1014:51 - need to pass a embedding and to search
1014:53 - the method cosine similarity dot product
1014:56 - or maybe some other method is there so
1014:57 - you can select a cosine similarity over
1014:59 - there got it after that guys see so
1015:02 - after that what I did so this is what
1015:04 - this is my index basically this is the
1015:05 - name of the index now what I did here I
1015:09 - called one method Pine con from text and
1015:12 - here is what here is my text and here is
1015:14 - my eding and here is my index
1015:16 - name getting my point then what I'm
1015:18 - going to do I'm going to create a eding
1015:21 - and that I'm going to store inside the
1015:24 - database here here this
1015:26 - one okay so here here I'm storing I'm
1015:30 - here I'm storing my embedding okay here
1015:33 - I'm storing my embedding into my Vector
1015:35 - database at this particular line you can
1015:37 - see over here just just open it and you
1015:39 - will be able to find out the you will be
1015:42 - able to find out the text and the vector
1015:44 - along with that gotting my point now
1015:47 - after that what I'm going to do see here
1015:49 - uh I'm going to query actually here you
1015:52 - will find out the similarity score also
1015:54 - this one right so this is based on a
1015:56 - similarity it is going to a similar not
1015:58 - regarding the other vectors okay so this
1016:01 - is the score which you can see now what
1016:03 - I'm going to do I'm going to find out
1016:05 - the similarity search so here it is
1016:07 - giving me a similarity search but you
1016:08 - will find out it is a vector it is not
1016:11 - giving me a sentence so for that what
1016:13 - I'm going to do here see I'm going to
1016:15 - call my open API and here this is my llm
1016:19 - GPD model text thein whatever model is
1016:21 - there now here is my chain type it's a
1016:23 - stuff means it's a normal one simple
1016:25 - chain okay now here you can see
1016:27 - retriever in in the retriever actually
1016:29 - this is my all the embedding this is my
1016:32 - all the embedding right so here I'm like
1016:35 - calling this method retrieval QA means
1016:37 - here I'm uh like calling here I'm
1016:39 - creating object of this retrieval QA and
1016:41 - there is what there is my method from
1016:43 - chain type this is my model llm model
1016:46 - and here is my embedding all the
1016:48 - embedding from the vector database now
1016:51 - this is what this is my QA right I
1016:53 - created object of QA now here is my
1016:55 - query I'm asking YOLO outperform which
1016:57 - model so here I'm asking YOLO output of
1017:00 - which model if I'm run qa. run and here
1017:03 - is what here is my query it will give me
1017:04 - an answer it will give me answer based
1017:06 - on a similarity search and from where it
1017:09 - is going to from where it is giving me
1017:11 - answer how it is going to search so here
1017:13 - you will find out inside the vector
1017:15 - database we have a score we have a
1017:18 - vector so it is checking with this
1017:19 - particular score and based on a
1017:21 - similarity search based on a cosine
1017:24 - similarity it is giving me answer after
1017:27 - searching okay after searching inside
1017:29 - the vector database which is nothing
1017:31 - which is a pine cone and here you can
1017:32 - see the UI of that where I have stored
1017:35 - the C where I have store the uh like
1017:37 - edding along with the text here you can
1017:40 - see each and everything over the
1017:41 - dashboard itself now let me uh scroll
1017:44 - down and here I have created a simple QA
1017:47 - simple QA system so based on this
1017:49 - particular PDF so you can say uh like QA
1017:53 - uh QA like PDF QA you can you can give
1017:56 - the name uh basically PDF question
1017:58 - answering and all whatever so whatever
1018:00 - PDF you are going to upload or whatever
1018:01 - PDF you are going to so from whatever P
1018:04 - PDF you are going to collect a data
1018:05 - based on that you will be do a question
1018:07 - answering and based on a similarity
1018:09 - score it is finding out a vector and it
1018:11 - is giving you the response and here you
1018:13 - can see it is working fine for me and I
1018:15 - hope it is working for you as well now
1018:18 - everything is clear guys tell me
1018:20 - whatever I have explained over here I
1018:22 - hope it is clear and it is perfect now
1018:25 - now once you will revise it by yourself
1018:27 - once you will run this code by by
1018:28 - yourself definitely you will get each
1018:30 - and everything so I just want a quick
1018:32 - confirmation and then I will conclude
1018:34 - the session
1018:39 - okay tell me guys fast and please hit
1018:42 - the like button also if you like the
1018:43 - session if you like the content and I
1018:45 - have explained you from very scratch
1018:48 - from very starting so please do let me
1018:50 - know did you like it uh now if you are
1018:53 - able to understand then please tell
1018:56 - me sir how the score is decided of the
1018:59 - chunk based on a cosine similarity so we
1019:02 - have a vector and regarding that Vector
1019:04 - we are searching the we are we are like
1019:06 - collecting a cosine similarity we are
1019:08 - finding out a cosine similarity while we
1019:10 - are creating an index at that time we
1019:12 - have uh like defined over there the
1019:15 - vector search will be based on a cosine
1019:17 - similarity so that is a score of the
1019:19 - cosine similarity
1019:27 - okay
1019:30 - it can read all the pages it can read
1019:32 - all the PDF pages and
1019:35 - all you can read like entire PDF
1019:38 - whatever pages is there not even single
1019:40 - all the like pages okay you can check it
1019:43 - you can run it you can take a like PDF
1019:45 - where you have uh 10 to 15 pages and
1019:47 - then uh then like try to uh read the PDF
1019:50 - by using this PDF loader or you can use
1019:52 - any PDF loader I'm not restricting you
1019:54 - to the till this Len CH only any PDF is
1019:57 - there just try to use that particular
1019:59 - PDF loader that's
1020:06 - it great fine uh so I hope you have you
1020:10 - have entire code over here now let me
1020:11 - give you the further code as well after
1020:13 - this a pine cone that whatever I have
1020:15 - written you can directly copy from here
1020:17 - and don't worry my team will give you
1020:19 - the entire file and all in a resource
1020:20 - section it will be uploaded so here is a
1020:22 - code for the QA so let me give you that
1020:26 - uh inside this
1020:28 - code search and apart from that we have
1020:31 - a code for the open all so let me give
1020:33 - you that also so Pine con is fine this
1020:37 - is fine now yeah this is the doc search
1020:41 - which is uh here now let me okay this is
1020:44 - already here so now the next code is
1020:47 - what retriever search this is there okay
1020:49 - similarity search just just check with
1020:51 - that check with the similarity search I
1020:53 - think everything will be fine now the
1020:56 - next is what so next is this uh this
1021:00 - particular method and here is this
1021:03 - particular method now what I can do open
1021:07 - a yep open a is
1021:10 - there and
1021:16 - here okay open AI is there now we have
1021:21 - the next also this is the method and
1021:24 - here you can call this qa. run so let me
1021:27 - give give you this and let me give you
1021:29 - this QA do
1021:33 - run this one so fine I think now
1021:37 - everything is perfect now everything is
1021:39 - clear tomorrow I will teach you one more
1021:42 - Vector database the vector database
1021:44 - concept will uh will more clear to all
1021:46 - of you and then we are going to initiate
1021:49 - one more project that we are going to
1021:51 - continue in our next week uh so from
1021:54 - Monday onwards uh we are going to start
1021:56 - one more project but tomorrow tomorrow I
1021:58 - will explain you one more V Vector
1022:00 - databases and few more topic I will try
1022:02 - to discuss with you and I will discuss
1022:04 - one project idea as well the complete
1022:07 - idea related to that particular project
1022:09 - and from Monday onwards we can start uh
1022:12 - with that particular project and we can
1022:14 - Implement in a live class itself
1022:19 - okay yeah good afternoon good afternoon
1022:22 - to all so today is a today is the day 10
1022:26 - and we have completed day n u actually
1022:30 - so nine lectures successfully related to
1022:33 - this generative AI so we started last
1022:35 - week uh last week on Monday and so far
1022:39 - uh we have completed nine lecture and
1022:41 - today is a is the day 10 so today
1022:45 - actually I will be discussing about few
1022:46 - more uh Advanced topic and then uh next
1022:50 - week we'll try to complete one more
1022:52 - project uh which will be related to the
1022:55 - uh like which will be related to the to
1022:57 - this today's topic this RG and this
1023:00 - Vector database and all so we have
1023:03 - started from very basic and then I came
1023:05 - to the lenen and open and then I discuss
1023:09 - about the hugging phase then uh I
1023:12 - completed one project as well we
1023:13 - deployed also and then uh I came to this
1023:17 - vecta
1023:18 - databases uh so now uh if you are
1023:21 - following me so I have already told you
1023:24 - regarding the dashboard and all so where
1023:26 - you will find out all the dash all the
1023:28 - materials and how to navigate to the
1023:30 - dashboard okay so where you'll find out
1023:33 - the recorded session here in the uh like
1023:36 - uh this is the Inon YouTube channel so
1023:38 - once you will go through with the Inon
1023:40 - YouTube channel so just click on that
1023:41 - click on the Inon YouTube channel here
1023:44 - my live is going on as of now so just
1023:46 - just click on this live section just go
1023:49 - through the live section and here you
1023:51 - will find out all the videos now uh if
1023:54 - you will click on this particular video
1023:56 - where I have discussed about about the
1023:58 - vector databases so in my previous
1024:00 - session I have discussed about the
1024:02 - vector databases I told you that what is
1024:04 - a vector database why why it is required
1024:06 - and then we have created one QA system
1024:09 - also based on the embeding so if you
1024:11 - don't know about it if you have uh if
1024:14 - you haven't seen this uh session so
1024:15 - please go and check there uh your all
1024:18 - the basics will be clarified and once
1024:20 - you will go through with the entire
1024:22 - session all the session if you are
1024:23 - beginner so definitely guys this uh
1024:26 - session is going to help you aot a lot
1024:28 - related to the generative a and all so I
1024:30 - would recommend uh this particular
1024:32 - series to all of you uh because soon we
1024:35 - are going to and and this one and next
1024:38 - week actually so next week we will try
1024:41 - to do one more project that is going to
1024:42 - be end to end project which will be
1024:44 - directly related to this uh Vector
1024:46 - database and all there we are going to
1024:48 - use everything and even we'll introduce
1024:50 - the Llama model in that particular
1024:52 - session in the in the upcoming session
1024:55 - which is going to start from the Monday
1024:57 - today I I'll be stuck with the vector
1024:58 - database itself because there is one
1025:00 - more database which I need to discuss
1025:02 - Then I then only you can make a
1025:04 - differences between uh different
1025:07 - different Vector databases so that's why
1025:08 - I picked one more database that's going
1025:10 - to be a chroma DV so in today's class
1025:13 - we're going to talk about the chroma DV
1025:15 - how chroma DV Works how it is different
1025:17 - from the pine cone and uh on which basis
1025:20 - on which uh like uh on which basis
1025:23 - actually we have to decide that uh what
1025:26 - should be my database for my and project
1025:28 - or for my uh indry ready project so each
1025:31 - and everything we're going to discuss
1025:33 - over here we're going to uh like uh I
1025:35 - will tell you in a live session so here
1025:37 - is Inon YouTube channel where you will
1025:39 - find out all my recordings so guys
1025:41 - please go through with the Inon YouTube
1025:42 - channel and try to check with the
1025:44 - description so in the description
1025:46 - actually we have already given you the
1025:47 - dashboard link so here in the DH uh in
1025:50 - the description you'll find out the
1025:52 - dashboard link this is the dashboard
1025:54 - just click on that and this is a this is
1025:56 - completely free right no need to pay
1025:58 - anything for this particular dashboard
1026:00 - I'm telling to the people who uh joined
1026:02 - this session first time now here what
1026:04 - you need to do here you just need to
1026:06 - register yourself and after that uh you
1026:08 - will get access of this particular
1026:10 - course no need to pay anything you just
1026:12 - need to sign up and login and then you
1026:15 - can navigate to this particular course
1026:17 - now once you will go through with the
1026:19 - Course once you will go through with the
1026:20 - dashboard so there you will find out all
1026:23 - the recording now let's uh go through
1026:25 - with the previous recording so here uh
1026:27 - is is a recording of the day n so just
1026:30 - click on that and here in the resource
1026:31 - section you will find out all the
1026:33 - resources so whatever resources I uh
1026:36 - discuss in the class throughout the
1026:39 - entire session so you will find out each
1026:41 - and everything inside the resource
1026:42 - section so I discuss this uh ipb file so
1026:45 - the ipb file is available over here so
1026:48 - you can visit the dashboard you can
1026:49 - download this file and you can execute
1026:52 - inside your system and you can revise
1026:54 - your concept now here apart from this uh
1026:58 - lectures and resources you will find out
1027:00 - the quizzes you will find out the
1027:01 - assignment so just visit this uh
1027:04 - particular dashboard and there you'll
1027:06 - find out everything and the link has
1027:08 - been mentioned inside the description
1027:10 - itself so just go and check in the
1027:12 - description uh we have already given you
1027:15 - the link here is a link so just click on
1027:17 - that and try to enroll yourself uh uh in
1027:20 - the dashboard now apart from that you
1027:22 - will find out other social social media
1027:25 - handles and different different channels
1027:26 - of the I so please try to follow there
1027:29 - we are uploading amazing content related
1027:32 - to the uh like related to the different
1027:34 - different topics so just just follow to
1027:37 - uh just follow Ion on the Instagram and
1027:39 - the other YouTube channel as well like
1027:41 - Hindi YouTube channel see once you will
1027:43 - check with the Hindi YouTube channel so
1027:45 - here let me show you this Hindi YouTube
1027:47 - channel of the Inon then you will find
1027:49 - out a same playlist in the Hindi as well
1027:51 - so there I have discussed each and
1027:53 - everything in Hindi if you finding out a
1027:56 - difficulty right say if you're finding
1027:57 - out a difficulty uh like you're not
1027:59 - getting anything in English so here you
1028:01 - can cover a same thing right you can
1028:03 - cover the same thing in Hindi as well
1028:05 - here uh we have uploaded all the Hindi
1028:08 - session right I'm taking the Hindi
1028:10 - session uh so you can go and check this
1028:13 - ion Tech Hindi Channel and here you'll
1028:16 - find out the SQL series as well so we
1028:18 - are taking live SQL classes now see uh
1028:21 - this uh this is a sorab actually Sor is
1028:23 - taking a live SQL classes and we are uh
1028:26 - covering each each and everything
1028:27 - whatever is required for the data
1028:29 - science for the data analytics and for
1028:31 - the data engineering job so guys please
1028:33 - try to check with the Inon Tech Hindi
1028:36 - there we are uploading uh like refined
1028:39 - content or whatever uh is a trending
1028:41 - thing in a Hindi itself and not even a
1028:44 - single video we are uploading a complete
1028:46 - playlist so you must visit this
1028:48 - particular Channel and you should check
1028:50 - with a Content now coming to coming back
1028:53 - to my topic so here already we have
1028:56 - discussed uh so many now today is day 10
1029:01 - of of this particular of this community
1029:03 - Series so now let start with the day 10
1029:06 - where the topic will be a chroma DB so
1029:08 - yesterday I have talked about the pine
1029:10 - con so Pine con was a vector database so
1029:13 - we use this Vector database for storing
1029:15 - a vector right now here we have one more
1029:18 - DB that's going to be a chroma DB so
1029:20 - we'll try to talk about the chroma DB as
1029:22 - well and we'll see the differences
1029:23 - between this pine cone and the chroma DB
1029:26 - that how it is
1029:27 - are different from each other this pine
1029:30 - cone and the chroma DB now one more
1029:32 - thing which I would like to highlight
1029:33 - over here see many people ask about the
1029:36 - certificates and all so let's say if
1029:37 - someone is going to complete the course
1029:40 - right someone is going to complete the
1029:41 - course so definitely in their mind there
1029:43 - will be a like question so will I get a
1029:46 - certificate or not so that thing also
1029:48 - you will find over here over the LMS
1029:50 - itself so you will find out three option
1029:53 - on top of this uh dashboard the first is
1029:56 - curriculum the second is analytics and
1029:58 - the third is certificate so here you'll
1030:00 - find out the entire curriculum here
1030:02 - you'll find out your entire analytics so
1030:03 - what all thing you have completed are
1030:05 - you doing assignment or not each and
1030:07 - everything you can uh track over here
1030:10 - inside this analytics portal now the
1030:12 - third one is a certificate so if you are
1030:14 - going to complete at least 40% of the
1030:17 - course right if you're going to complete
1030:19 - at least 40% of the course then
1030:21 - definitely you will be able to generate
1030:23 - the certificate now how like the course
1030:26 - uh that that uh that will be that how
1030:29 - like the course will be completed right
1030:31 - so how my system will get to know and
1030:33 - then only you can generate a certificate
1030:34 - see after completing a video after
1030:36 - completing this particular video here
1030:38 - you will find out the tick mark this
1030:39 - this particular mark this blue tick mark
1030:42 - so that mean the meaning is that so you
1030:44 - are uh you have completed that
1030:46 - particular video and the course name is
1030:48 - what the course name is a foundational
1030:50 - or generative AI Foundation of
1030:52 - generative AI now uh once you will tick
1030:54 - mark on this particular video it will be
1030:56 - completed and now you can check inside
1030:58 - the analytics also so here just look
1031:01 - into the analytics so your video
1031:03 - progress uh will be there right so you
1031:05 - will find out the video progress over
1031:07 - here so yeah this is fine this is clear
1031:10 - to all of you now please go and check
1031:12 - with the dashboard there you'll find out
1031:14 - each and everything now apart from that
1031:17 - one more thing which I would like to
1031:18 - show you uh so uh I will uh I would like
1031:21 - to introduce you uh with One dashboard
1031:24 - one more dashboard so let me show you
1031:27 - that particular dashboard so just go
1031:29 - inside the course section and here uh
1031:31 - inside the course section you will find
1031:32 - out this generative AI right inside this
1031:35 - boot camp now just click on that just
1031:37 - click on this particular course so there
1031:38 - is a course name is mastering generative
1031:41 - AI with open AI Len CH and Lama index
1031:45 - just scroll down till last and here you
1031:47 - will find out a complete detail syllabus
1031:50 - of of for this particular course now
1031:52 - here actually we are going to cover each
1031:54 - and everything related to the generative
1031:56 - AI we are going to start from very basic
1031:59 - from the foundation of a generative Ai
1032:01 - and then we'll come to the like word
1032:03 - embedding text reprocessing we'll talk
1032:05 - about the llms we'll talk about the hung
1032:07 - face API and other different apis as
1032:10 - well and we'll talk about the L chain
1032:13 - llama index these are the different
1032:15 - different framework basically which we
1032:16 - use for creating an llm based
1032:17 - application and then you will find out
1032:20 - end to endend project also so this
1032:22 - entire curriculum is a industry ready
1032:24 - curriculum and we have added so many
1032:26 - things recent l or we are updating this
1032:28 - particular cbus uh so there are so many
1032:31 - things coming like day today actually so
1032:34 - we are analyzing all those thing and we
1032:35 - are finding out so whatever is required
1032:37 - for the industry whatever is required
1032:39 - for the community so definitely we based
1032:42 - on that we are trying to update our
1032:44 - syllabus so tomorrow itself if you will
1032:45 - look into the syllabus you will find out
1032:47 - a new changes right because many things
1032:50 - is coming uh like dayto day right so
1032:52 - regarding the fine tuning regarding the
1032:55 - like evaluation of the model regarding
1032:57 - the like Fast retrieval right so
1033:00 - regarding the fast retrieval regarding
1033:01 - the different different databases or
1033:03 - different different llm So based on that
1033:05 - only based on a current market we are
1033:07 - updating this curriculum so just go and
1033:10 - check uh over there just go and check
1033:12 - with the Inon website and there you'll
1033:14 - find out amazing curriculum and yes so
1033:16 - this course is going to be start from 20
1033:20 - uh 20th of January right and here you
1033:22 - will find out the language we have
1033:24 - launched this particular course in
1033:25 - English and here the duration is around
1033:27 - 5 month and this is going to be a timing
1033:29 - so timing is from 10: to 1:00 p.m. IST
1033:32 - and this will be a live course right and
1033:35 - here you will find out your instructor
1033:37 - so Chris sir is there Sanu is there me
1033:40 - uh is there and here is a buy so buy
1033:42 - will also take a session uh means will
1033:45 - also be a mentor along with me Sudan Su
1033:47 - and Chris so guys uh please go and check
1033:51 - uh with this particular dashboard with
1033:53 - this particular course and for the
1033:55 - further information you can contact with
1033:57 - the sales team here you can drop your
1033:58 - information so my sales team will
1034:00 - contact to you fine so I hope I have
1034:04 - clarified each and everything now if you
1034:06 - have any sort of a doubt you can ask me
1034:08 - and then we'll start with the Practical
1034:12 - implementation tell me guys uh do you
1034:15 - have any doubt sir where to find
1034:17 - neurolab code for the McQ generator
1034:19 - project it is not updated on GitHub so
1034:22 - here is my GitHub which I already uh
1034:24 - uploaded in my resource section you can
1034:27 - go and check with a resource section let
1034:28 - me give you that uh GitHub just a second
1034:32 - and don't worry I will be pasting inside
1034:34 - the chat
1034:35 - also just go with my repository my
1034:38 - GitHub repository there you will find
1034:39 - out this McQ generator right this is the
1034:43 - application not this one this one
1034:45 - generative AI so let me open this
1034:48 - generative Ai and yeah this is the app
1034:51 - this is the complete application which I
1034:52 - added in my uh resource section also let
1034:54 - me show you where you'll find out that
1034:56 - so Foundation generi course and here is
1035:00 - the this is
1035:06 - the just wait first let me give you this
1035:08 - particular link and then uh I will show
1035:11 - you so I'm giving to my team and they
1035:15 - will uh directly P inside the chat okay
1035:18 - just
1035:25 - wait
1035:30 - fine now I think we can start so guys uh
1035:34 - all
1035:35 - clear sir estra DV is a vector database
1035:38 - or it's a no SQL database it's a no SQL
1035:41 - database estra DV actually in a backend
1035:43 - it is using the cassendra and cassendra
1035:45 - is a no SQL
1035:51 - database yesterday I discussed that
1035:54 - whether you can use or not this estra DB
1035:57 - this cassendra is a vector database I
1035:59 - given you the each and every information
1036:00 - regarding that just just look into that
1036:02 - just go through with my previous session
1036:05 - you will get to
1036:10 - know uh great now I hope everyone is
1036:15 - getting that so can we
1036:19 - start here is a pine gon one so please
1036:23 - give me a quick confirmation if we can
1036:24 - start with the session then uh
1036:27 - uh I will start writing the code so let
1036:32 - me open my code share. also here I'm
1036:35 - going I'm going to paste each and
1036:36 - everything each and every line so I will
1036:39 - okay let me give you this particular
1036:41 - link also I'm giving you this code
1036:44 - share. iio
1036:46 - link just a second yeah this one so just
1036:51 - a second guys you will get this
1036:53 - particular link where I going to paste
1036:56 - each and every line each and every line
1036:58 - uh whatever I'm writing inside my
1037:00 - Jupiter notebook so today uh we going to
1037:03 - start with a chroma DB so for that guys
1037:06 - what you can do so here first of all let
1037:08 - me close everything and here is what
1037:11 - here is my session which is going on so
1037:13 - let me keep it somewhere and yes now it
1037:17 - is
1037:22 - perfect great so uh first of all what
1037:25 - you need to do here here so first at the
1037:27 - first place you need to launch your
1037:29 - neural lab so just click on this neural
1037:32 - lab guys just click on this neural lab
1037:34 - and once you will click on this neuro
1037:36 - lab so here you will find out this type
1037:39 - of interface now there is two option the
1037:41 - first option is start your lab and the
1037:44 - second option is my lab so just click on
1037:46 - this start your lab right if you have
1037:49 - already created a lab if you have
1037:51 - already uh created your uh jup instance
1037:53 - definitely you can uh go inside my lab
1037:56 - and you can launch the same jupyter
1037:58 - instance and there you can write it down
1038:00 - your code after creating the IP VB file
1038:02 - that is also fine but I'm showing you
1038:04 - from starting so here guys what you need
1038:06 - to do you need to click on this start
1038:09 - your lab so once you will click on that
1038:11 - so it will ask you about the sign in and
1038:14 - all so here you can sign in guys you can
1038:16 - pass your email ID and it is completely
1038:18 - flee no need to uh like pay anything for
1038:21 - this neuro lab as of now so here you can
1038:24 - see we have a different different stack
1038:27 - so big data analytics data science
1038:28 - programming and web development so what
1038:31 - you can do here you can click on this
1038:33 - data science so what you will click on
1038:34 - that so here you'll get all the option
1038:37 - whatever is required for developing a
1038:39 - project in this data science if you are
1038:41 - going to develop a project uh inside the
1038:44 - data sence so here you will find out all
1038:46 - the ID all the ID we have given you in
1038:49 - the form of template you just need to
1038:51 - click on that and you can launch your
1038:52 - instance so now let me show you with
1038:54 - this Jupiter so in today's session we're
1038:57 - going to use the Jupiter and in the next
1038:59 - session we're going to use this cond
1039:01 - cond for end to end development and
1039:03 - Jupiter just for the ipynb
1039:05 - implementation right now here what I'm
1039:07 - going to do so here I'm going to open my
1039:09 - Jupiter so it will ask you the name so
1039:11 - here I can write down the name chroma DV
1039:14 - so today in today's class we're going to
1039:15 - talk about the chroma DV which is
1039:17 - nothing which is a database Vector
1039:19 - database and here what I will do I will
1039:22 - proceed it and then it will be launching
1039:24 - the lab so guys please do it please
1039:26 - please uh do along with me because today
1039:28 - I'm I'm I will be going very very slow
1039:30 - and each and every line of code I will
1039:32 - be pasting inside the coda.io so that
1039:34 - you can copy from there how many of you
1039:37 - you are doing along with me please uh
1039:39 - write it down the chat I'm waiting for a
1039:43 - reply sir I have a interview for the
1039:46 - gener position can give me some tips and
1039:49 - project so if you are asking about the
1039:52 - tips if you have a generative AI uh like
1039:55 - if you have an interview to generative
1039:57 - so first of all your foundation should
1039:59 - be strong and there you need to discuss
1040:01 - about the project right so the the pro
1040:04 - whatever like practical implementation I
1040:06 - have discussed throughout this commun
1040:07 - series you can go through with that and
1040:09 - you can prepare that so the question you
1040:11 - will get around to that only so there
1040:13 - will they will ask you uh are you using
1040:15 - this API why you are why you are using
1040:18 - it what is the cost of that can you
1040:20 - prize it what all Alternatives we have
1040:22 - so what is the concept of the vector
1040:24 - database why we cannot use other
1040:26 - database what is the concept of the RG
1040:28 - how we can finetune the model what is
1040:30 - the cost what will be the cost of the
1040:31 - fine tune fine tuning of the model can
1040:33 - be like can we like keep in keep it in a
1040:37 - scal scalable mode or not right so uh
1040:40 - can we do a uh like like CPU based
1040:43 - finetuning right there is a like if the
1040:46 - model is very very huge so in that case
1040:49 - how uh if the model is very very huge so
1040:51 - in that case how I can load it so in
1040:53 - that case you need to say that I I can
1040:55 - use the quantize model model so this
1040:57 - type of question you can assume inside
1040:59 - the interview right so don't worry I
1041:01 - will share one PDF there I will keep all
1041:03 - the interview question related to the
1041:04 - generate Ai and it will be available on
1041:07 - your dashboard got it don't worry got it
1041:11 - raes Ramesh
1041:13 - nangi fine uh I think it is taking time
1041:16 - so let me refresh it and then again I
1041:19 - will launch just a second guys I have
1041:21 - refreshed it now let's
1041:25 - see
1041:40 - oh why it is taking too much
1041:51 - time yeah now it's done so let me launch
1041:54 - then uh I
1041:56 - kernel let let me launch this IPython
1041:59 - notebook so please uh give me a quick
1042:01 - confirmation if you are able to see
1042:04 - this tell me guys so here I can print
1042:08 - all
1042:10 - okay yeah so guys all
1042:17 - okay no we are not going to do a fine
1042:20 - tuning in a community session so we'll
1042:22 - restrict this community session till uh
1042:24 - the project itself till that end to end
1042:26 - project where we are going to call the
1042:28 - API that's it the so tell me guys all
1042:32 - okay yes or
1042:34 - no and I think everything is visible to
1042:36 - all of you right so can we start and
1042:40 - first of all let me save this notebook
1042:42 - so here I can write it down this chroma
1042:45 - DV so my notebook name is what my
1042:49 - notebook name is a chroma DB so let's
1042:52 - start uh let's start with the chroma DB
1042:55 - so first of all guys uh let me give you
1042:57 - the brief introduction about the chroma
1042:59 - DB that what is a chroma DB and why we
1043:02 - are using it so let's uh search together
1043:06 - and here let's search about the chroma
1043:09 - DB so once I will search uh here the
1043:12 - chroma DB so here you will find out the
1043:15 - very first website of the chroma DB just
1043:18 - click on that and let me open it first
1043:20 - of all so here is what here is a chroma
1043:22 - DV guys now they have given you the
1043:24 - different different option right so here
1043:26 - you will find out a different different
1043:27 - option on top of this website so the
1043:30 - first one is a documentation the second
1043:32 - is a GitHub the third one is a discard
1043:34 - Community the fourth one is a Blog and
1043:36 - here they have written that we are
1043:38 - hiring and here launching multimodel so
1043:41 - they have announced multimodel also now
1043:43 - from here you can start here you can
1043:45 - find out the demo as well so you can uh
1043:48 - like check with the demo and here you
1043:51 - will find out the the complete
1043:53 - architecture which they have given to
1043:55 - you and like what you are going to do
1043:58 - here tell me you are going to convert
1043:59 - your queries into a vector and that
1044:01 - Vector basically are going to save it
1044:03 - right that Vector that particular Vector
1044:05 - you are going to save it now here uh
1044:08 - let's try to discuss about the uh
1044:11 - difference between this chroma DB and
1044:13 - the pine but first of all let me go
1044:15 - through with the documentation so here
1044:16 - is a demo demo of the chroma DB which
1044:21 - you will find out over here inside the
1044:23 - collab notebook which they have provided
1044:25 - you over the website itself now if you
1044:27 - want to look into the source code so
1044:29 - here they have given the source code as
1044:31 - well this is the GitHub just click on
1044:33 - that and here you will find out the
1044:35 - complete source code of the chroma DB so
1044:38 - the uh this chroma DB is a open source
1044:41 - database and here you can see the number
1044:43 - of contributor how many contributor is
1044:45 - there 86 contributors is there like
1044:49 - 10.7k people has already used this
1044:52 - particular um database now here you will
1044:55 - find out the 9 92 commits and if you
1044:57 - will look into the package if you look
1044:59 - into the pp package so let's see the
1045:01 - first version and the last version the
1045:03 - latest version of the chroma DB so here
1045:05 - you can write it down this chroma DB
1045:08 - chroma DB on top of the Google Now here
1045:11 - you will find out the web this uh P by
1045:13 - page so this is the latest version of
1045:16 - the chroma DV
1045:18 - 0.420 right now if you will look into
1045:20 - the previous version if you want to
1045:22 - check with that so just click on that
1045:23 - just click on this release history
1045:25 - you'll find out the entire history of
1045:28 - this chroma version so how frequently
1045:30 - they are updating the thing uh so they
1045:32 - haven't completed even one year right
1045:34 - and here you will find out that these
1045:37 - many of version uh like you will find
1045:40 - out you will get it related to this
1045:41 - chroma DB because it is a open source
1045:43 - now here you will find out so many
1045:45 - contributor inside this chroma DB you
1045:48 - can check with the contributor list you
1045:49 - can check with the contributor name here
1045:52 - and here you can see the entire
1045:53 - community so guys uh this is the
1045:56 - contributor now used by 10.7k people and
1045:59 - here you will find out the fork number
1046:02 - of fork and the star so just go through
1046:04 - with this particular GitHub there you
1046:06 - will find out the entire detail related
1046:08 - to the chroma DV where you will get it
1046:10 - so you will get this thing or the
1046:12 - website itself so here on top of the
1046:14 - website you'll find out a different
1046:15 - different options so they have you there
1046:17 - you will find out the GitHub and even
1046:19 - you can join the community of this
1046:21 - chroma DB so they have given you the
1046:22 - option of the Discord so just click on
1046:24 - that and you can join their community on
1046:26 - Discord so whatever doubts and all you
1046:28 - have so you can ask it over the Discord
1046:30 - now coming to the documentation so here
1046:32 - is a documentation of the chroma DB so
1046:35 - just look into the documentation here
1046:37 - you will find out each and everything
1046:39 - whatever is required for understanding
1046:42 - this chroma DB so let's start with the
1046:44 - getting it started now here they have
1046:46 - given you the two option the first one
1046:48 - is going to be a python this one and the
1046:50 - second option is going to be JavaScript
1046:52 - right so the first option is a python
1046:54 - the second option is a Java script now
1046:56 - uh here you will find out the
1046:57 - installation detail how to install this
1046:59 - thing now here you'll find out how to
1047:02 - create a client from the chroma DB so if
1047:04 - you want to create a client of the
1047:06 - chroma DB so here is a option for
1047:08 - creating a client for the of the chroma
1047:11 - DB now here uh how to create a
1047:13 - collections and all so this is the
1047:15 - collection and here how to add it now
1047:17 - how to query The Collection each and
1047:19 - everything you will find out over here
1047:21 - so guys once you will install this
1047:23 - particular package you will get
1047:24 - everything over here this is not a
1047:26 - cloud-based database it's a like a local
1047:30 - database there if you will download this
1047:32 - thing so everything you will get inside
1047:33 - the local itself so there the first
1047:35 - major difference between the pine cone
1047:38 - and the chroma DB so chroma DB actually
1047:40 - it's not a cloud based database and here
1047:43 - actually see it's not a cloud base here
1047:45 - everything you will do inside the local
1047:46 - itself right so here you will do
1047:48 - everything inside the local itself in
1047:50 - your local workspace but if we are
1047:52 - talking about the pine cone so it's a
1047:54 - cloud-based database so in that you have
1047:56 - seen you must have seen let me show you
1047:58 - the pine con website as well so here if
1048:00 - I'm writing down this a pine con so you
1048:03 - will find out here over the pine con
1048:05 - that it's a vector database for the
1048:07 - vector search now just scroll down here
1048:10 - so here you will find out a different
1048:12 - different Cloud oper Cloud uh operator
1048:15 - so it is fully managed by Google gcp AWS
1048:18 - and AO anywhere you can create an
1048:20 - instance and then you can utilize it
1048:23 - after installing this inside your local
1048:26 - system so everything will be available
1048:28 - over the cloud after configuring this
1048:30 - pine cone so that the first major
1048:32 - difference between the pine code and
1048:34 - this chroma DB now coming to the point
1048:37 - so here uh we are talking about the
1048:39 - chroma DB so let's try to check with the
1048:42 - Google itself what is the difference
1048:43 - between chroma DB and the pine con so uh
1048:46 - everything is available to the Google so
1048:48 - here actually I found out uh find out
1048:50 - one article so let's try to look into
1048:53 - this particular article and by uh like
1048:55 - reading this articles and all you can
1048:58 - understand because this is a recent
1048:59 - thing Recent research okay it's not like
1049:01 - that that people are working on this on
1049:03 - top of this since last like 10 year or
1049:07 - 15 years so you will find out that there
1049:09 - is a recent active community so whatever
1049:12 - you will find out you will find out on
1049:13 - top of the Reddit on top of the strike
1049:15 - overflow GitHub or you will get a
1049:17 - knowledge from the documentation or from
1049:19 - a different different blog so just try
1049:21 - to read this particular blog and let's
1049:23 - try to understand the difference between
1049:25 - Pine cone and chroma DB now what is the
1049:28 - pros and cons so with that you will get
1049:30 - a some sort of idea that if you are
1049:32 - going to decide about a database
1049:34 - whatever database is there right so
1049:36 - whatever database is there whatever
1049:37 - Vector database is there so on which
1049:40 - point right on which topic you need to
1049:42 - select the database what all thing you
1049:44 - need to consider over there that is a
1049:46 - main point so let's try to discuss let's
1049:48 - try to see over here so we are talking
1049:51 - about the pine con guys so Pine con is a
1049:53 - manage Vector database designed to
1049:55 - handle real time search and similarity
1049:58 - matching at scale right so here they
1050:00 - have clearly mentioned that this uh pine
1050:03 - cone data base it designed to hander
1050:05 - realtime search and similarity matching
1050:07 - at scale which we have seen in my
1050:09 - previous class which we I have shown you
1050:11 - in my previous uh like a lecture itself
1050:14 - you can go and check it's B on a state
1050:16 - of art technology and has gained
1050:18 - popularity of its use cases of
1050:20 - performance right so here uh it is easy
1050:22 - to use and it is uh performing well
1050:24 - because of that it gain the popularity
1050:27 - now let's delay into the key attribute
1050:29 - advantage and the limitation of the pine
1050:31 - cone so here just look into the pros and
1050:34 - here they are saying that it is for the
1050:35 - real time search it is for the
1050:37 - scalability definitely we are going to
1050:39 - use the uh cluster on top of the cloud
1050:42 - so definitely we can do a horizontal
1050:44 - scaling over there right so this is the
1050:46 - scalable B so architecture has been
1050:49 - designed in such a way the installation
1050:50 - and all the computation and the dbm
1050:53 - database management is happening in such
1050:54 - a way that it is a scalable and it's not
1050:57 - a vertical scale right it we can do a
1050:59 - horizontal scaling regarding this pine
1051:01 - cone now this is for the realtime search
1051:04 - here you will get the automatic indexing
1051:06 - So Yesterday itself we have created one
1051:08 - index and there you will find out along
1051:10 - with the vector you will find out that
1051:12 - we were having an index column there we
1051:14 - are having the scoring and all so
1051:16 - automatically indexing right you no need
1051:18 - to write it down anything automatically
1051:20 - you will get the indexing now here
1051:22 - python support so this is a very
1051:24 - important thing if if you are going to
1051:25 - develop any application in data science
1051:27 - in machine learning and deep learning
1051:29 - where heavily we are using python so yes
1051:31 - definitely it is supporting of python as
1051:34 - well got it now what is the cons of it
1051:36 - so cons wise here you will find out the
1051:39 - first one is a cost right so cost is a
1051:42 - like major disadvantage of this spine
1051:44 - cone so we cannot use the spine cone
1051:46 - freely so here if you will look into the
1051:48 - pricing of this spine cone so there you
1051:50 - will find out the different different
1051:52 - pricing so if you are a starter if you
1051:54 - are a beginner definitely you can go
1051:56 - with a free tire but let's say if you're
1051:58 - are not a starter if you're not a
1052:00 - beginner you want to use it for some
1052:02 - sort of application right where you are
1052:04 - going to implement some PS and all where
1052:06 - you want to uh Implement some realtime
1052:08 - use cases for your organization for your
1052:10 - project so you can take this particular
1052:13 - pack where standard is there now here
1052:15 - you will find out uh these many thing
1052:17 - you can check according to your
1052:18 - requirement and let's say if you want to
1052:20 - productionize something right so let's
1052:22 - say if you are working in a company and
1052:24 - there you want to productionize
1052:25 - something and here so what you can do
1052:28 - you can take this Enterprise solution so
1052:30 - there you will find out many more thing
1052:32 - you can check with the pricing detail
1052:33 - you can talk with the pine cone team
1052:35 - right Consulting team they will guide
1052:37 - you regarding each and everything so the
1052:39 - first thing the first disadvantage you
1052:41 - can see over here that is a cost itself
1052:43 - the second disadvantage you will find
1052:44 - out limited query functionality so while
1052:46 - Pine cold Xcel as similar to search it
1052:48 - might like some Advanced query
1052:50 - capability the certain project required
1052:52 - maybe the mathematical model they are
1052:54 - using the different different meical
1052:56 - medical model they are using behind that
1052:58 - like like cosign similarity dot product
1053:00 - so it is not working in that much
1053:02 - effective way which people has uh felt
1053:05 - right even I haven't checked with this
1053:06 - particular cons right I haven't checked
1053:09 - that this is uh having a limited query
1053:11 - functionality because I uh just check
1053:13 - with a certain use cases so guys if you
1053:15 - are getting this particular con so
1053:17 - definitely before starting with the Pyon
1053:19 - before productionize it right or before
1053:22 - uh like uh using inside your U like
1053:24 - project definitely you should consider
1053:26 - to this particular point where you have
1053:28 - a limited query functionality right now
1053:31 - how to use pine con I think I already
1053:33 - told you how to use pine code I'm not
1053:35 - going into that much detail now let's
1053:37 - talk about the chroma DB so chroma DB is
1053:40 - similar to pine go just just try to
1053:42 - focus now just for 2 minute next for 2
1053:45 - minute and then I will go with the
1053:46 - Practical implementation right so if we
1053:48 - are talking about the chroma DB so it is
1053:50 - similar to the Pine go and designed to
1053:52 - handle Vector storage and retable means
1053:55 - we can store the data and we can
1053:57 - retrieve the data right so it offers a
1053:59 - robust set of feature that creator that
1054:02 - c various use cases making variable
1054:04 - choice for many Vector application right
1054:06 - so here uh clearly we are getting that
1054:08 - that we we can use this chroma DB for
1054:10 - storing the vectors right we can store
1054:12 - the vector and we can retrieve the
1054:14 - vector right now here you will find out
1054:16 - a different different pros and cons so
1054:18 - the first Pros is there that is what
1054:20 - that is a open source right so open this
1054:22 - chroma DB is a open source Vector
1054:24 - database base here I have shown you the
1054:26 - code of this chroma DB right you can you
1054:29 - can like uh check with this particular
1054:31 - code now here you can press the dot so
1054:34 - this entire code will be available
1054:36 - inside the vs code now you can go
1054:39 - through with this particular code and
1054:41 - you can check that what all files and
1054:43 - folder they have created and what all
1054:45 - thing they have written inside this
1054:47 - particular project right so you can
1054:49 - consider there's nothing just a project
1054:50 - only now here you will find out a
1054:52 - different different files and folder and
1054:53 - now they are maintaining the this thing
1054:55 - in the form of package also so on top of
1054:57 - the pii repository you will find out
1054:59 - this chroma DB in the form of package so
1055:01 - from there you can install it by using
1055:04 - the PIP install Command right now just
1055:06 - look into this chroma DB that what they
1055:08 - have written so here they have written
1055:10 - of they have created a various folder so
1055:12 - the first one is a API now here you will
1055:14 - find out a different different API let's
1055:16 - try to create click on this fast API
1055:18 - just read the code from here and here
1055:21 - you can see the all CLI so this is the
1055:23 - real time project right which which they
1055:25 - have deployed in a real time and which
1055:26 - they are using right which everyone is
1055:28 - using and there you will find out the
1055:30 - number of force number of star number of
1055:32 - contributor each and everything you can
1055:34 - see so there's a first uh advantage of
1055:37 - this uh chroma DB that is a open source
1055:40 - now extensible query chroma DB allows
1055:42 - more F more flexibility quering
1055:45 - capability including complex range such
1055:47 - and combination of vector attribute so
1055:49 - here you can think that or here you can
1055:51 - assume that uh this chroma DB is working
1055:54 - well right compared to the pine cone
1055:56 - where I have to do a similar search
1055:58 - right so here they have clearly
1055:59 - mentioned inside this particular block
1056:01 - based on their own experience that this
1056:03 - chroma DB is working well for the
1056:06 - similarity search if you want to find
1056:07 - out some sort of a combinations and all
1056:09 - in that case it is going to work very
1056:11 - very well now Community Support is very
1056:13 - very high as I told you that it's a open
1056:15 - source right so here you will find out
1056:17 - the complete Community just go back and
1056:19 - check with the GitHub itself so here is
1056:22 - a AT3 contributor 86 contributor and if
1056:25 - you will look into the website if you
1056:26 - will look into the website so there you
1056:28 - will find out the Discord GitHub slack
1056:32 - everything they have provided to you uh
1056:34 - for uh connecting with the community so
1056:38 - if you want to connect with the
1056:39 - community so there they have given you
1056:41 - the different different ways right so
1056:42 - this community the community of the
1056:44 - chroma DB is a very very strong now
1056:46 - let's look into the cons so here I told
1056:48 - you that this chroma DB uh set this
1056:51 - chroma DB is not for the deployment
1056:53 - deployment complexity is there because
1056:55 - you won't be able to find out this
1056:57 - chroma DV on top of the cloud right so
1056:59 - they uh the pine cone basically already
1057:01 - it is running on top of the cloud there
1057:02 - you just need to consume it by using the
1057:04 - API right there you need to use this
1057:07 - chroma DB there you need to use the pine
1057:09 - cone by using the API but it is not same
1057:13 - with chroma DB actually this chroma DB
1057:16 - whenever you are going to use it it is
1057:18 - not available in the form of API because
1057:21 - it's a open- source package you need to
1057:23 - install it inside your local workspace
1057:24 - space and you need to use it right you
1057:26 - need to install it inside your local
1057:28 - workspace and you need to use it so if
1057:30 - you're going to deploy it right if
1057:32 - you're going to deploy it so there you
1057:33 - will find out a complexity so here just
1057:35 - read U the complexity Point setting up
1057:38 - chroma DB chroma and managing it scale
1057:40 - might require more effort and expertise
1057:42 - compared to many solution like pine cone
1057:44 - because in the pine cone you're just
1057:45 - consuming the API right you're just
1057:47 - consuming the API everything is there on
1057:49 - top of the uh third party server
1057:51 - everything is running over there you
1057:53 - just need to consume it by using the API
1057:55 - but here in the chroma DB the thing is
1057:58 - not same deployment complexity
1058:00 - definitely will find out because there
1058:02 - is a no like Cloud support as of now for
1058:05 - the chroma DB you will have to install
1058:07 - inside your local workspace and you will
1058:09 - have to set up each and everything got
1058:11 - it now performance consideration yes uh
1058:14 - definitely this thing also will come
1058:15 - into the picture if we are talking about
1058:17 - regarding the realtime use cases so
1058:19 - performances also might be here and
1058:21 - there so there are some points you can
1058:24 - uh search about more regarding a
1058:26 - different different like regarding a
1058:28 - different different Vector database and
1058:31 - from there you can uh like pick out you
1058:34 - can pick up this particular points this
1058:35 - particular heading and you can do your
1058:38 - own research so whether it's a scalable
1058:40 - whether it's a whether there is an
1058:41 - indexing for the fast retrieval whether
1058:43 - there is a python support or it is fine
1058:45 - for the deployment so you can pick up
1058:47 - this point and based on that you can
1058:50 - make a differences and based on that you
1058:52 - can understand actually right so I hope
1058:55 - guys you are getting it now uh the
1058:58 - differences is clear so please do let me
1059:01 - know in the chat if uh the differences
1059:03 - is clear to all of you then we'll uh go
1059:07 - for the coding yes or
1059:14 - no yeah thank you Sati so sa saying Sun
1059:18 - sir I have enrolled for the Gen 10%
1059:20 - discount got the python free recording
1059:22 - with that that's a big surprise
1059:25 - great great satis
1059:26 - congratulation so yeah now uh I hope
1059:30 - this part is clear to all of you now
1059:32 - let's start with the Practical
1059:34 - implementation of this chroma DB so here
1059:37 - uh for uh implementation actually first
1059:40 - of all we'll have to install some
1059:42 - Library so whatever code whatever code
1059:45 - I'm pasting over here in my jupter
1059:47 - notebook the same code I will provide
1059:48 - you in my code share. I also so here is
1059:52 - my code guys which I'm going to run now
1059:54 - the same code I am pasting in my Cod
1059:57 - share. so that you can copy from there
1060:00 - so did you get a link of this Cod share.
1060:02 - IO please do let me know in the chat
1060:04 - please do confirm guys if you got the
1060:07 - link of this code share. iio so don't
1060:09 - worry my team will give it to you inside
1060:11 - the chat and from there you can copy the
1060:14 - entire
1060:16 - code how to find tune the question
1060:19 - answer data using lar 2 model and I
1060:22 - don't have context but I have only uh
1060:24 - question answer and I have so that is
1060:27 - that the the fine tuning also we can do
1060:29 - that but for that we required a huge
1060:31 - amount of resources and based on a Model
1060:34 - also like which model you are going to
1060:35 - use so as of now I'm not going giving
1060:37 - you the detail regarding the fine tuning
1060:39 - and all I understand that's going to be
1060:40 - an important topic but yeah so here I'm
1060:43 - talking about the vector database and
1060:45 - then we'll start with one more project
1060:46 - and after that maybe we'll take few more
1060:48 - classes we'll try to discuss about the
1060:50 - concept of the fine tuning right but as
1060:52 - of now you can think that uh like if you
1060:55 - have your own question answering data
1060:57 - right so there might be a different
1060:58 - different technique right different
1061:00 - different technique for the finetuning
1061:02 - the recent technique which I was
1061:04 - searching the recent technique name was
1061:05 - the parametric effective fine tuning so
1061:08 - what's the meaning of that parametric
1061:10 - effective fine tuning so there you have
1061:13 - the question answer there you have your
1061:15 - data now based on that you have to train
1061:17 - the model which will be required a huge
1061:20 - amount of resources and you can do over
1061:23 - the uh like C CPU also on like on a low
1061:26 - cost also but for that you will be
1061:28 - required a quantise model so that is a
1061:30 - different thing how you can quanti your
1061:32 - model and then how you can do a find Uni
1061:34 - there are some uh more techniques comes
1061:37 - into the picture like Laura and Cur that
1061:40 - is also a technique a different
1061:41 - different technique regarding this uh
1061:43 - parametric effective fine tuning so
1061:45 - we'll try to discuss it right and for
1061:47 - that only we have designed the course
1061:49 - just just look into that each and
1061:50 - everything we have mentioned over there
1061:52 - where we are going to discuss everything
1061:53 - you know very very detailed way got it
1061:56 - now here uh I have given you this
1061:59 - particular link and here is a
1062:01 - installation statement pip install
1062:03 - chroma DB open Lang and Tik token you
1062:05 - need to install this for library now
1062:09 - here guys uh let me install this library
1062:11 - inside
1062:13 - my inside my environment just a
1062:17 - second are you doing it can I get a
1062:20 - quick yes or no in the chat if you are
1062:22 - doing along with me
1062:25 - and please hit the like button guys
1062:26 - please hit the like button if you're
1062:28 - liking the session because I can see uh
1062:30 - you have joined the session but uh
1062:32 - you're not writing anything inside the
1062:34 - chat and you're you're just watching
1062:36 - don't don't do like this hit the like
1062:38 - button guys and if you have any sort of
1062:40 - a doubt just just uh write it on the
1062:43 - chat just cheer up okay so let's make it
1062:45 - more interactive got
1062:53 - it
1063:03 - yeah it is installing now let me give
1063:04 - you few more libraries so just a second
1063:07 - I can give you few more Library which I
1063:09 - kept
1063:11 - somewhere okay that is fine now after
1063:15 - that you can check with this particular
1063:16 - command so here is a command guys this
1063:18 - one so let me give you this particular
1063:22 - command PIP show chroma d DB just uh
1063:26 - check with this command that your chroma
1063:28 - DB successfully installed or not here's
1063:30 - a command the command is PIP show chroma
1063:49 - DB yeah it is perfect now it is done so
1063:53 - have you installed it having installed
1063:55 - uh this all the
1063:58 - library tell me guys fast then I will
1064:01 - proceed further now you can check with
1064:02 - the chroma DB then you will find out the
1064:04 - detail of the chroma DB so it is giving
1064:07 - you the it will give you the detail of
1064:08 - the chroma DB there is a simple command
1064:11 - PIP show chroma DB so we have installed
1064:14 - the chroma DB on the uh workspace in the
1064:17 - latest workspace and here you will find
1064:19 - out the detail of the chroma DV this is
1064:21 - the latest model this is the latest
1064:23 - model Vishnu I have already shared the
1064:26 - code please go and check with the code
1064:29 - share. okay join the session on
1064:32 - time because again and again I won't
1064:34 - repeat a same thing so please we aware V
1064:38 - Active I'm sharing everything that's why
1064:40 - there is a like cod share. which I have
1064:44 - shared with all of you okay just copy
1064:46 - from there and paste it inside the
1064:49 - Jupiter
1064:51 - notebook yes we have a gen related
1064:53 - project just check in a commune session
1064:55 - also we have completed a project and
1064:57 - even in the course also we have a
1064:58 - project so rames please check with the
1065:01 - course please check with the
1065:05 - dashboard now I think uh till here
1065:08 - everything is fine everything is done
1065:10 - see the first thing what I need to do so
1065:12 - here actually I need to I need to uh
1065:16 - like uh I need to get I need to download
1065:19 - a data so from here from this particular
1065:21 - link I'm going to collect a data right
1065:24 - let me show you uh what we have on top
1065:26 - of this part on over here actually at
1065:29 - this particular link so for that just
1065:31 - copy it and paste it inside your Google
1065:34 - so just just paste it over here open the
1065:36 - Google and paste it in your Google now
1065:39 - just a
1065:41 - second yeah so here is a Dropbox guys so
1065:44 - in the Dropbox actually you will find
1065:46 - out this particular data right so just a
1065:49 - second uh let me show you this
1065:51 - data m
1065:56 - specifically we have this data just a
1065:58 - second guys so here in the URL box I can
1066:01 - paste
1066:02 - [Music]
1066:06 - it yeah so here is a data guys so the
1066:09 - data actually it's a news article so
1066:12 - just just see the article uh it's a news
1066:14 - article so AI powered supply chain
1066:16 - startup pendo lens 30 million investment
1066:19 - txt just open it and read it right this
1066:22 - data is already available somewhere
1066:24 - where in the Dropbox so I just shown you
1066:26 - this particular link and we are going to
1066:27 - like use this data for creating
1066:30 - embeddings and for like uh and then
1066:33 - we'll uh then we'll store the embedding
1066:35 - inside the then we'll store the
1066:37 - embedding inside the vector database so
1066:39 - this is the data basically which we are
1066:40 - going to use here we have a several text
1066:42 - files so just go through with the data
1066:44 - there you will find out the entire
1066:45 - detail related to the data uh so here is
1066:48 - a one more article replace TB writers
1066:50 - strike. txt so go and check with this
1066:53 - particular artic article now here is one
1066:55 - more article just go and check with that
1066:56 - particular article so this is the
1066:58 - article everything you need to know
1067:00 - about the AI power chb right so
1067:03 - different different article you will
1067:04 - find out over here check the AI power
1067:06 - data protection project right so there
1067:08 - are so many article which we are going
1067:10 - to use which we are going to use for our
1067:13 - uh like this this is the article which
1067:15 - we are going to use for our embeddings
1067:16 - and all by using this data by using this
1067:19 - text data by using this particular data
1067:21 - text Data what we are going to do we are
1067:23 - going to to first we are going to
1067:24 - convert a chunks right and then we are
1067:26 - going to convert those chunks into a
1067:28 - embedding by using the embedding model I
1067:31 - will show you which embedding model
1067:32 - we're going to use so we are going to
1067:33 - use the openi model but there are so
1067:35 - many embedding model you can use the
1067:38 - buttu bag there are so many model you
1067:39 - will find out over the hugging phas also
1067:41 - so it's up to you you can do a Google
1067:43 - search I will show you how to do that
1067:45 - and then you can select your model as
1067:47 - per your requirement right now here this
1067:50 - is the data now let me give you the data
1067:52 - link over here by running this
1067:54 - particular command so this is the data
1067:56 - link and by running this particular
1067:58 - command here is a command guys where is
1068:00 - a command this is the command so by
1068:02 - using this uh particular command you can
1068:05 - install the data or you can load the
1068:07 - data or you can download the data into
1068:10 - your local workspace so let's see let uh
1068:13 - me show you the data basically so here
1068:15 - you just need to run this command so
1068:18 - just press shift plus enter and see left
1068:21 - hand side your data is is getting
1068:24 - installed and yes it is done now here is
1068:26 - a j file see guys there is a j file news
1068:30 - article J file left hand side in the
1068:32 - left hand uh in the workspace basically
1068:34 - you you will find out this news
1068:36 - article. jip but if you want to unj this
1068:40 - data so for that also we have a command
1068:42 - now let me give you that a particular
1068:44 - command so the command is what command
1068:46 - is nothing unip hyphen Q news article
1068:50 - you need to be uh like unload it uh you
1068:53 - need to be like unloaded right you need
1068:55 - to be unzip it uh and here you will get
1068:58 - this data inside this particular folder
1069:00 - now let me show you let me run it and
1069:02 - here you can see we have our data inside
1069:05 - this particular folder so I'm giving you
1069:08 - this command I'm giving you this
1069:09 - particular command just a second you can
1069:12 - check and you can run inside your system
1069:15 - so here is a data guys here you will
1069:17 - find out the data now let me unnoted uh
1069:21 - this particular thing this is the data
1069:23 - data is about the news article so news
1069:27 - article data and here you will find out
1069:31 - the command which you can run and with
1069:33 - that you can install you can install
1069:35 - this chip file install the chip file in
1069:38 - your local workspace where you need to
1069:41 - install guys tell me need to install
1069:43 - this work file you need to install this
1069:45 - file inside your local workspace so let
1069:48 - me write it down here local workspace
1069:50 - and with this particular command you can
1069:52 - unip it so so by using this particular
1069:55 - command you can unip it so each and
1069:58 - everything I have written over here you
1069:59 - just need to copy and paste inside your
1070:03 - Jupiter notebook that's it right great
1070:07 - so please use the if see someone is
1070:10 - saying ra is saying Sir W get is not
1070:12 - working so here W get is working now
1070:14 - this use this with escalation mark right
1070:17 - and use the neural lab I haven't shown
1070:19 - you this thing by using the collab or
1070:21 - maybe this local setup I'm see in Linux
1070:24 - environment definitely it will work but
1070:26 - if you are using the Windows system so
1070:28 - in in that case it might not work so use
1070:30 - the Linux environment and this lab
1070:33 - actually has been configured on top of
1070:34 - the Linux environment in a production
1070:36 - you will find out the Linux environment
1070:37 - only because for that you no need to pay
1070:40 - anything it's a open source right so
1070:42 - just like required a small amount of the
1070:45 - Linux server but yeah if you are like
1070:47 - using a Windows server in a production
1070:49 - so definitely it's going to charge you
1070:51 - very very much so here is a Linux
1070:54 - environment which I'm uh like where I'm
1070:57 - executing all this command so w Is there
1071:00 - anip is there now let me run the next
1071:03 - command so here the next command is what
1071:05 - what so here I need to set my open a API
1071:08 - so I got the data here you'll find out
1071:10 - basically I got the data this is what
1071:12 - this is what this is my data which I got
1071:14 - in my local workspace now after that I'm
1071:18 - going to set my I'm going to set my open
1071:21 - a API key you know it how to set the
1071:24 - openi key many time I have shown you in
1071:27 - my lecture so for that you just need to
1071:29 - go through the open website open the
1071:32 - open website and here search uh just
1071:35 - click on that the and then click on the
1071:37 - login you'll find out two option the
1071:39 - first option is the API and the second
1071:41 - is a chat jpt so just click on the API
1071:44 - and then click on the API key so here
1071:46 - you will find out the API key so this is
1071:48 - the API key basically which I have
1071:50 - generated and here I have passed it
1071:52 - inside my note book also so just if you
1071:55 - will see into this API key so here I
1071:57 - pass this API key into my notebook this
1071:59 - is what this is my API key right now
1072:02 - what I can do guys see uh just a second
1072:05 - let me pass the correct one because I'm
1072:09 - using the old API key over here just a
1072:12 - second just allow me a minute
1072:17 - okay I kept it somewhere I kept it
1072:21 - uh and you have to generate your opena
1072:24 - API key I'm not giving you that uh
1072:27 - because for that I have paid actually so
1072:29 - please use your API key uh there are so
1072:32 - many person which join the session so if
1072:34 - they are going to use my open key
1072:35 - definitely it will be rushed out so
1072:38 - please use your op key please generate
1072:41 - it by yourself initially it will give
1072:42 - you the $20 credit so you can use it now
1072:46 - here uh there is what there is my open a
1072:49 - API key now it is done tell me guys
1072:51 - still here everything is fine everything
1072:53 - is clear to all of you please uh do let
1072:56 - me know in the chat if everything is
1072:58 - going well so far so I'm waiting for a
1073:01 - reply and I'm giving you this particular
1073:02 - command there you can paste your openi
1073:06 - key and you can run it so this is for
1073:08 - the openi key tell me guys fast waiting
1073:11 - for a reply if you are done till here
1073:14 - then please do let me know then only I
1073:17 - will proceed sir I for the P can I my I
1073:21 - on team yes Sati you can ask your doubt
1073:23 - uh to the Inon team they will assist you
1073:26 - regarding your all the doubts all the
1073:33 - concerns so please give me a quick
1073:35 - confirmation guys if uh you are done if
1073:39 - you are able to follow me till here then
1073:41 - I will proceed
1073:44 - further tell me guys fast waiting for
1073:47 - your reply please or do let me
1073:52 - know
1073:56 - and please hit the like button guys uh
1073:59 - if you're liking this session and yeah
1074:02 - you can write down the chat chat also
1074:05 - whatever doubt you have while you are
1074:06 - implementing it and don't worry today
1074:08 - the understanding will be more clear
1074:10 - regarding this database regarding this
1074:12 - Vector database compared to the previous
1074:15 - session because today uh because already
1074:18 - we have learned it now right so today is
1074:19 - a kind of revision so don't worry we
1074:21 - have uh created Creed one project also
1074:24 - and after the after this Pro after this
1074:27 - like implementation I will show you the
1074:29 - project architecture also so uh in the
1074:31 - next class we are going to discuss about
1074:33 - that particular project we are going to
1074:34 - implement from a scratch and there you
1074:36 - will get to know that how this Vector
1074:38 - datab base is being used right so we are
1074:41 - going to create one chatboard and the
1074:43 - chatboard is going to be a medical
1074:44 - chatboard we are specifically going to
1074:46 - train on top of the medical data right
1074:49 - so just stay tuned with us uh in next
1074:52 - class uh we'll create one more project
1074:54 - and we'll try to use it the we'll try to
1074:56 - use the flask over there and fast API
1074:59 - and we'll deploy it also right got it
1075:01 - great now here after that I have
1075:05 - imported few libraries now let me give
1075:06 - you this libraries inside the uh like
1075:09 - cod. I so there what I can do guys here
1075:13 - I can uh write it down you need to
1075:16 - import this a particular Library so here
1075:19 - I have written you need to import this
1075:21 - are libraries libraries so just just
1075:25 - copy it guys and after copying it you
1075:27 - can uh uh run inside your system so see
1075:31 - guys if I'm running it then definitely
1075:33 - uh where is my
1075:35 - not yeah this one so here you can see
1075:38 - after running it uh after basically
1075:40 - importing it what I need to do I just
1075:41 - need to run it so see I'm able to import
1075:43 - each and everything now let's try to
1075:45 - understand each and every detail about
1075:47 - this libraries about this import
1075:50 - statement so for that uh just a second I
1075:53 - can open My Epic pen and that there I
1075:56 - can explain you each and
1075:59 - everything sir can I exp experience
1076:01 - certificate with a paid course yes
1076:03 - definitely in certificate and experience
1076:04 - certificate will be available right so
1076:07 - actually you can generate it um I given
1076:09 - you the walkth through in my previous
1076:11 - session just just check and uh check
1076:12 - with those particular like session just
1076:14 - go through with the introduction itself
1076:16 - uh so there I have discussed about the
1076:17 - internship portal as well if you don't
1076:19 - know don't worry again I will open that
1076:21 - and I give you I will give you the walk
1076:23 - through so how you can complete the
1076:24 - internship on top of the generative AI
1076:26 - because we are going to add more and
1076:28 - more project related to the generative
1076:29 - AI with a different different uh like
1076:31 - domain so you can complete your project
1076:33 - in a multiple domains right so don't
1076:35 - worry uh like I will show you that is
1076:39 - still it is in a pipeline uh the project
1076:41 - will be uploaded Maybe not today in the
1076:43 - next class definitely we'll be talking
1076:44 - about it right so let's try to discuss
1076:47 - about this Library so here is the
1076:49 - library the first one is the Len chain
1076:51 - do Vector store and here is a chroma
1076:53 - right so chroma it is this for the
1076:56 - chroma DB this for this is what this for
1076:58 - the chroma DB now here this is for the
1077:00 - open a embedding and as I told you right
1077:02 - so uh we can generate a embedding right
1077:05 - we can generate the word embedding and
1077:07 - this word embedding is nothing this word
1077:09 - embedding is nothing it's a vector only
1077:11 - so what is this tell me this word
1077:13 - embedding is nothing it's a vector it's
1077:16 - a vector right so here actually this
1077:18 - open I already uh trained so they
1077:21 - already took the data and they already
1077:23 - trained one model and by using this
1077:26 - particular model they have generated a
1077:27 - Ming now how to do that so how to do
1077:30 - that tell me guys so here regarding this
1077:32 - particular data regarding this
1077:33 - particular data definitely they must be
1077:35 - having the uh like vocabulary they have
1077:38 - generated one vocabulary and for this
1077:40 - particular vocabulary they must have
1077:42 - created the features right so features
1077:44 - and they are passing each and everything
1077:46 - to their model and this model is nothing
1077:48 - that's going to be a neural network
1077:50 - right this is going to be a neural
1077:51 - network and yes based on that they will
1077:54 - they are going to generate the embedding
1077:56 - right so I told you that how to generate
1077:58 - embedding and all if you will go and
1077:59 - check with my previous session there I
1078:02 - have discussed about this embedding open
1078:04 - AI embedding now here we have one more
1078:07 - package open AI this is for the this we
1078:09 - calling this open a API so by using this
1078:11 - one we can call the open API directory
1078:14 - loader we can load the directory text
1078:16 - loader we can load the text and all
1078:17 - whatever uh like files we have now we
1078:20 - have in a text format so by using this
1078:22 - uh text loader we can load that
1078:25 - particular data that particular file so
1078:27 - let's try to uh load it now so for that
1078:29 - also we have a code for loading a data
1078:32 - and here is a simple code let me copy
1078:35 - and paste it over here and along with
1078:38 - that let me copy and paste inside your
1078:41 - uh inside the inside the Cod share. also
1078:45 - so please copy from here each and
1078:46 - everything I'm giving you uh so you just
1078:49 - need to copy it and you need to paste it
1078:51 - inside your system so here what I can do
1078:54 - guys here I can write it down for
1078:57 - loading the data and guys believe me
1078:59 - after completing this much of thing the
1079:02 - understanding will be more clear to all
1079:04 - of you so for loading the data let me
1079:06 - write it down over here uh just copy
1079:08 - from here and paste it inside your
1079:11 - system now what I can do here I can load
1079:13 - and inside this news article so Globe is
1079:16 - for what Globe is for all the text files
1079:19 - so whatever text file is there so is
1079:21 - going to read the data from the entire
1079:23 - text file right so it's going to read
1079:25 - the data from the entire text file for
1079:27 - that you just need to mention one
1079:29 - parameter the parameter is going to be
1079:31 - Globe right dot means current directory
1079:34 - SL star means what so here we have
1079:36 - written the star so what is the meaning
1079:38 - of the star so star is nothing star is
1079:41 - representing the entire directory right
1079:43 - so whatever file name is going to start
1079:45 - from this txt we are going to load the
1079:48 - entire file we are going to load all
1079:50 - those file that's it that's a meaning of
1079:52 - the simple code now if I'm going to run
1079:54 - it you will find out that we are able to
1079:56 - create a loader over here I just need to
1079:59 - call one method now I just need to call
1080:02 - one method and the method is going to be
1080:04 - do load so let me run it and you will
1080:07 - find out that it is giving me a syntax
1080:08 - error now let me show you that yes we
1080:11 - are able to load the data so it is
1080:14 - saying that the file is not there okay
1080:16 - let me remove it and here is
1080:20 - this home Joy on news article is not
1080:24 - there why it is
1080:27 - so oh just a wait let me copy the
1080:31 - path to sharable
1080:34 - link should be treor news
1080:39 - article so is this a path just a
1080:46 - wait just a wait guys just a wait let me
1080:50 - check
1080:51 - once
1080:54 - lab
1080:58 - directory okay why it is giving me this
1081:02 - issue copy the path and paste it over
1081:05 - here that's
1081:13 - it are you facing the same
1081:16 - issue my open is expired you can
1081:18 - generate a next one now you can generate
1081:20 - a next API key
1081:26 - uh it is giving me a issue guys just a
1081:28 - second let me delete it and let's see
1081:31 - whe whether I will get up so this is the
1081:34 - directory actually see home Jan just
1081:37 - copy this
1081:38 - directory and just copy this complete
1081:40 - directory and dismiss it and keep it
1081:42 - over
1081:45 - here now let me
1081:50 - check yeah now I'm able to do it
1081:53 - so guys here see once you will do the
1081:56 - right click and just click on the delete
1081:58 - just click on the delete so it will give
1081:59 - you the complete uh directory I don't
1082:02 - know why I was not getting by using this
1082:04 - copy path but yeah now I getting it so
1082:07 - are you do it are you able to do it are
1082:10 - you able to load the data are you able
1082:11 - to load the document please do let me
1082:14 - know yes or
1082:16 - no so here is what here is my uh
1082:20 - document please again give me a quick
1082:23 - confirmation guys if you able to load
1082:25 - the document so just wait let me give
1082:28 - you this line also this uh loader. load
1082:32 - and please try to load the data by using
1082:35 - this loader. load tell me guys if you
1082:38 - are able to load the data then please
1082:40 - write it down the chat I'm waiting for
1082:42 - your
1082:44 - reply tell me
1082:51 - first
1083:18 - are you enjoying the session do you like
1083:20 - the session guys tell me
1083:22 - do you like the session so far all all
1083:26 - your all the doubts and all is getting
1083:28 - clear yes or no tell
1083:48 - me oh great so I think till here
1083:51 - everything is fine everything is clear
1083:53 - now we got our data right so we got our
1083:59 - data now what I will do here so just a
1084:01 - second let me show you so first of all
1084:03 - we have a data now guys tell me after
1084:06 - getting a data what I will do any guess
1084:09 - any any guess
1084:21 - anything just wait just
1084:35 - wait yeah so after getting the data what
1084:38 - I will do so after getting a data I will
1084:40 - create a chunk right so let me copy and
1084:44 - paste this particular code over here
1084:45 - what I can do just a second this data is
1084:47 - very very huge so actually it is taking
1084:50 - time if I'm scrolling down just a second
1084:52 - yeah now it's perfect so here actually
1084:54 - you will find out a data related to all
1084:57 - the text file right so you got a data
1084:59 - related to all the text file now here
1085:02 - you need to create a chunk so for that
1085:04 - basically I'm going to use this
1085:07 - particular library and here we have few
1085:09 - more code right few more code few more
1085:12 - thing uh so let me give you this
1085:14 - particular code and then I will explain
1085:16 - you the meaning of it because yesterday
1085:18 - also like many people were asking to me
1085:20 - sir what is the meaning of this
1085:21 - particular Cod code why we are using it
1085:24 - uh like what we are doing over here what
1085:26 - is the meaning of this uh text splitter
1085:28 - split document and all each and
1085:30 - everything we going to discuss over here
1085:33 - now uh let me open my Scrabble link
1085:37 - right and here we going to discuss about
1085:38 - each and everything so what I can do let
1085:41 - me zoom in first of all and now it is
1085:45 - perfect so let's try to understand so
1085:47 - guys at the first place what I did just
1085:49 - tell me guys so at the first plate at
1085:51 - the first place we have uh we have
1085:54 - generated a data right so here actually
1085:56 - we have a data so we got a data from
1085:58 - somewhere this is what this is my data
1086:01 - right after getting a data after getting
1086:03 - a data what I what I'm doing guys tell
1086:05 - me so after getting a data I need to
1086:07 - convert this particular data into a
1086:10 - embedding right so what I need to do I
1086:12 - need to convert this particular data
1086:15 - into
1086:18 - embedding now here I got a data and I'm
1086:21 - going to convert this data into
1086:23 - embedding can you tell me which model we
1086:24 - are using for this embedding can anyone
1086:26 - tell me which model we are using for
1086:28 - this embedding anyone fast which model
1086:32 - so we are using open AI embedding model
1086:35 - open AI open AI edding M bidding model
1086:41 - right we are going to use open AI edding
1086:44 - model now guys here we are talking about
1086:47 - this open a embedding model so just just
1086:50 - look into that just just open the model
1086:52 - here what I can do uh let me show you
1086:54 - the open
1086:56 - models here I'm searching about the open
1087:00 - models right so you will get all the
1087:02 - models over the whatever model is there
1087:04 - over the openi platform so these are the
1087:06 - model Guys these are all the model which
1087:08 - you can see here right so GPD 4 is there
1087:11 - GP 3.5 is there Delhi TTS whisper
1087:14 - embedding is there so just click on this
1087:16 - embedding right so just click on this
1087:18 - embedding and here you will find out the
1087:20 - embeddings and all right so uh text
1087:22 - generator uh text uh moderation latest
1087:25 - model max token you can pass 30,000
1087:27 - right 32,000 now here is a GPT based
1087:30 - model So weage based model so there is
1087:32 - like you can pass 60 16,000 token there
1087:36 - uh is a d Vinci model there you can pass
1087:38 - 16, 384 token now there is GPD 3 based
1087:41 - model so there you can pass 2,000 token
1087:44 - right this this is the token now
1087:46 - actually in our case we are going to use
1087:48 - the GPT based model this this GPT based
1087:51 - model so we are going to use GPT 3.5
1087:53 - turbo right so here which model we are
1087:56 - going to use we are going to use GPT 3.5
1087:59 - turbo right so here GPD GPD 3.5
1088:02 - basically we are using so now just just
1088:04 - look into this in a GPD 3.5 uh this this
1088:06 - model by default actually we are going
1088:08 - to use this particular model now tell me
1088:10 - guys what is the total limit here what
1088:11 - is the total limit the total limit is
1088:15 - 4,960 right and here if you will look
1088:17 - into your data so this is your this is
1088:19 - what this is your data now just look
1088:21 - into this particular data
1088:22 - now here are guys there are so many
1088:25 - tokens there are so many words if you
1088:28 - will calculate the words so definitely
1088:30 - is going to exceed 4,000 right so
1088:33 - definitely is going to execute 4,000
1088:35 - exceed 4,000 now let's say let let's
1088:37 - talk about that if you are working in a
1088:39 - real time so you will get a very huge
1088:41 - amount of data you are you will be
1088:43 - getting a very huge amount of data and
1088:46 - here if the sentence is going to be a
1088:47 - very long in that case there might be a
1088:49 - chance that my model will not be able to
1088:52 - sustain the context right my model will
1088:55 - not be able to sustain the context and
1088:57 - here you can see the there's there are
1088:58 - like two long text right and here by
1089:01 - defa which model we are going to use we
1089:03 - are going to use this GPT 3.5 turbo this
1089:05 - this particular model uh basically
1089:07 - whenever we are going to use the llm
1089:10 - right we are going to use this
1089:11 - particular model which is going to be a
1089:12 - gbt 3.5 turbo and here you can see the
1089:14 - tokens limit 4096 tokens right 4096
1089:18 - tokens now here the data which we have
1089:21 - in inside that we have a lots many
1089:23 - tokens right so we have a tokens which
1089:25 - might exceed more than 4,000 or let's
1089:28 - say this is not going to exceed more
1089:29 - than 4,000 but let's say if you are
1089:31 - working on some realtime data and there
1089:33 - there you are getting a data which is
1089:35 - very very huge and which is exceeding
1089:37 - the number of tokens right whatever
1089:39 - model you are using let's say you are
1089:40 - using a topmost model where you can give
1089:42 - 30,000 token but still it is exceeding
1089:45 - the limit in that case what you will do
1089:47 - so you will provide your data in terms
1089:48 - of chunks what you will do tell me you
1089:51 - will provide your data in terms of in
1089:53 - the form of chunks right so that is what
1089:56 - we are going to do over here so over
1089:58 - here guys what I'm going to do see uh
1090:01 - here is what let's say here is my data
1090:04 - right and here is what here is my Ming I
1090:07 - want to perform the Ming now what I will
1090:08 - do here I I will keep one thing so in
1090:11 - between this data and this Ming right so
1090:14 - actually after that after this eding and
1090:16 - all what I will do tell me I will pass
1090:18 - my model now I will pass this thing to
1090:21 - my model
1090:22 - right so I cannot deny with this thing
1090:24 - so I'm going to pass this thing to the
1090:26 - model and here we have a data right we
1090:28 - have a data and in between actually what
1090:30 - we are going to do we are going to do a
1090:33 - chunking right what we are going to do
1090:35 - we are going to do a chunking now let's
1090:37 - try to understand what is the meaning of
1090:39 - the chunking so let's say we have a data
1090:42 - right so what what I have guys tell me
1090:44 - let's say we have a data now what I have
1090:48 - to do I have to do a Chun right I have
1090:51 - to convert this data into a chunks now
1090:53 - here in the library which I have
1090:55 - imported there you will find out two
1090:57 - thing two words so let me do one thing
1090:59 - let me copy and paste this thing from
1091:01 - here so here what I can do what is
1091:04 - happening
1091:07 - okay where is
1091:11 - this oh just a second guys just a
1091:17 - [Music]
1091:20 - wait
1091:25 - yeah here is a code guys see so what I'm
1091:28 - going to do from here I'm going to take
1091:31 - uh I'm going to copy this particular
1091:33 - line this this particular line right now
1091:35 - let me copy it and let me paste it over
1091:38 - here so here is what here is my dis link
1091:41 - so here I'm going to paste this a
1091:43 - particular line and now guys here
1091:46 - actually you'll find out two thing the
1091:48 - first is a chunk size and the second one
1091:51 - is what overlap right so what I'm going
1091:53 - to do so here I'm going to copy and
1091:55 - paste some data from here itself right
1091:58 - just just focus everything will be clear
1092:00 - over here so here is what here is my
1092:02 - data now let me copy this particular
1092:05 - data this is my data this one page
1092:07 - content now I'm going to copy this
1092:09 - particular data and I copy let's say
1092:11 - till here right this just for the demo
1092:14 - this just for the demo nothing else
1092:15 - right so here is what guys here is my
1092:17 - data which I kept over here right now
1092:20 - just just looking into this data so
1092:22 - here's my data which I just took for the
1092:25 - demo so the first thing which I have
1092:27 - defined that's going to be a chunk size
1092:29 - right chunk size now what is the meaning
1092:32 - of that so here actually let's say uh
1092:35 - I'm going to divide my data into chunks
1092:37 - what I'm going to do tell me I'm going
1092:38 - to divide my data into chunks so I want
1092:41 - that I want 100 tokens over there here
1092:44 - here I have written thousand right let's
1092:45 - say I'm giving 100 tokens so what is the
1092:47 - meaning of that means let's say there is
1092:49 - first Chun one Chun in that until I'm
1092:52 - not going to complete 100 tokens let's
1092:54 - say from here to here from here to here
1092:58 - we got 100 tokens right so I will stop
1093:00 - over here and that data so that is what
1093:02 - there is my first chunk now again there
1093:04 - will be a second chunk so it's going to
1093:06 - start from here and let's say till here
1093:09 - so here I'm going to complete my 100
1093:11 - tokens so this is going to my third
1093:13 - chunk now there is a third uh third
1093:14 - chunk basically so in the third chunk
1093:16 - you will find out we are going to start
1093:18 - from here and let's say till here so
1093:20 - this is going to be my third chunk where
1093:22 - I'm able to complete my 100 tokens and
1093:24 - what is the meaning of the tokens so
1093:26 - tokens is nothing it's going to be a
1093:28 - word so what is the meaning of the
1093:29 - tokens tokens is nothing the word itself
1093:32 - is called a token right so if you are
1093:35 - going to complete 100 words in that case
1093:39 - I'm able to generate my first chunk I'm
1093:41 - going to generate my first chunk and why
1093:44 - I'm doing that because let's say data is
1093:45 - very very huge so I cannot directly pass
1093:49 - that particular data to my model it will
1093:51 - Ex the limit so the better thing is what
1093:54 - I'm going to provide my data in terms of
1093:56 - chunks in terms of small small chunks
1093:59 - right so it will be able to sustain the
1094:01 - context also and my limit is not going
1094:04 - to exceed got it now here you have a
1094:07 - three chunks regarding this particular
1094:08 - data let's understand the meaning of
1094:11 - this chunk overlap right so let's say
1094:13 - instead of this uh 200 I'm just writing
1094:17 - 20 right so now guys let's say uh my
1094:21 - first CH is going to start from here to
1094:24 - here right to here now second chunk is
1094:28 - going to start from the from this if
1094:31 - from here to here right here now let's
1094:35 - say uh I'm writing 20 so what will
1094:38 - happen you know what will happen so it
1094:41 - will take 20 wats this this second this
1094:44 - second chunk this second chunk it will
1094:48 - take it will take 20 words it will take
1094:51 - 20 words from the previous sentence so
1094:53 - let's say this is a 20 words this this
1094:55 - is a 20 words now this 20 words will be
1094:59 - carry forward to my second chunk now
1095:03 - here we are talking about the third one
1095:05 - third one so here let's say from here to
1095:08 - here from here to here this is my third
1095:10 - chunk now if I'm writing chunk overlap
1095:13 - is 20 so from the previous sentence from
1095:16 - the previous chunk my 20 words is
1095:19 - getting overlap mean means it is going
1095:21 - to forward is it is carrying forward to
1095:24 - my next chunk getting my point what is
1095:26 - the meaning of this chunk size and why
1095:28 - we are doing that what is the meaning of
1095:30 - the chunk size chunk overlap what is the
1095:32 - meaning of Chunk I hope everything is
1095:35 - getting clear now I have given you the
1095:36 - clearcut explanation so let's try to do
1095:39 - a chunking regarding my data so over
1095:42 - here if you will find out let me show
1095:45 - you the chunks and all and how we can do
1095:47 - that
1095:50 - actually what is the purpose of the
1095:52 - overlapping just just think about it
1095:54 - just think about it what is the purpose
1095:55 - of the overing we want to sustain the
1095:57 - information from the previous sentence
1095:59 - from the previous chunk that's
1096:01 - it right that's it now my data is little
1096:04 - smaller in that case uh I'm not able to
1096:06 - create so many chunks what I will do I
1096:08 - will perform the
1096:10 - overlapping getting my point right yeah
1096:12 - to maintain the context to maintain the
1096:14 - length whatsoever now here I'm passing
1096:17 - my document I'm passing my document and
1096:19 - here I'm going to create a chunk so guys
1096:22 - over here you will find out inside this
1096:24 - particular variable there is my chunk so
1096:27 - here if I want to extract the first
1096:29 - chunk so this is what this my first
1096:30 - chunk as you can see now I can call the
1096:34 - page content so here if I'm going to
1096:35 - call this a page content so you will
1096:38 - find out this is what this is my content
1096:40 - right now here I can take the second
1096:43 - chunk also so here is what here is let's
1096:45 - say is my second chunk so you will find
1096:47 - out this what this is my second Chun now
1096:49 - here you will find out the third chunk
1096:51 - so this is is going to be your third
1096:53 - chunk now let me show you the third
1096:56 - chunk so here actually you will find out
1096:58 - all the Chunk in the list so I can get
1097:00 - the length of the list also so just uh
1097:04 - call this length and this text so here
1097:06 - you will find out total
1097:08 - 233 chunks got it yes or no now let me
1097:12 - give you this particular code and here
1097:14 - is what here uh I have a code let me
1097:17 - close it first of all this is what this
1097:18 - is my code let me paste it over here so
1097:21 - just copy from here and try to extract
1097:24 - right so try to extract so here actually
1097:28 - uh you have a text right and from there
1097:30 - you can extract the content now trial
1097:34 - Junction is saying explain
1097:49 - so then you can visit ion Tech Hindi
1097:52 - Channel there I'm explaining everything
1097:54 - in English sorry in the Hindi right so
1097:57 - this is the channel for the English and
1097:59 - the channel will be for the Hindi so
1098:01 - just go and check then you will find all
1098:03 - the content in Hindi otherwise just wait
1098:04 - for one more hour from 6 p.m. onwards
1098:07 - I'm going to start a same class in a
1098:09 - Hindi also right on Inon Tech Hindi got
1098:12 - it great now here you can see we are
1098:16 - able to get a content from the page from
1098:19 - the data now uh this is the data which I
1098:22 - got I'm able to do a chunking now it's
1098:24 - time to do a now it's time to do a tell
1098:27 - me it's time to perform the eding now
1098:29 - let's try to do a eding and let's try to
1098:31 - do a a further thing over here so the
1098:35 - next thing is going to be embedding
1098:37 - itself just a second let me do the
1098:39 - embedding uh let me give you the code
1098:42 - basically so here is a code for the
1098:46 - chunking yeah so guys the next step is
1098:49 - going to be a very very uh the next step
1098:52 - is going to be a very very crucial just
1098:54 - just focus on that and within a 15
1098:56 - minute we'll try to complete it so here
1098:59 - my next step is what so here my next
1099:02 - step is creating a DB so let me remove
1099:05 - it first of all and here I'm going to
1099:08 - create my
1099:09 - database so what I'm going to do guys
1099:11 - I'm going to create my database so for
1099:14 - creating a DB actually there is a is a
1099:17 - like certain thing there is a certain
1099:19 - code which I need to write it down over
1099:21 - here so the first thing uh the first
1099:23 - thing basically what I need to do I need
1099:26 - to import the embedding so first of all
1099:28 - let me give you this entire code and
1099:29 - step by step one by one I will try to
1099:32 - explain you so just a second I'm going
1099:34 - to paste the entire code in my Cod
1099:38 - share. so here uh you can paste it you
1099:42 - can copy it from here from the codeshare
1099:44 - doio I'm giving you each and every of
1099:46 - code each and every line so at least you
1099:48 - can run along with me if you are running
1099:51 - inside your system so you can run along
1099:53 - with me here is the entire code guys
1099:56 - from 41 to 48 just copy it and run
1099:59 - inside your ipv file now let me show you
1100:03 - that what thing we are going to do over
1100:05 - here so here is a embedding let me copy
1100:07 - it from here let me paste it so this is
1100:09 - going to my embedding and let's run it
1100:12 - yes we are able to uh import it now the
1100:16 - second thing is what I told you uh I
1100:18 - told you initially that we are not not
1100:21 - going to maintain any such information
1100:24 - or we are not going to store any such
1100:25 - information on cloud right we are not
1100:28 - going to store any such information on
1100:31 - cloud because here this chroma DB is a
1100:35 - local DB right where you won't be able
1100:37 - to find out any server on top of the
1100:39 - cloud any cluster on top of the cloud
1100:41 - everything will be happening in a local
1100:42 - itself in our local workspace so
1100:45 - purchase directory there I'm going to
1100:47 - store my all the embedding here is a fer
1100:51 - this is what this is the directory now
1100:52 - let me run it and here is a directory
1100:54 - now what I will do guys so here I'm
1100:56 - going to create an embedding right so
1100:58 - here I'm going to create an embedding
1100:59 - just a
1101:01 - wait so this is going to be my embedding
1101:04 - open embedding means uh it's what it's
1101:07 - my class right for generating edings
1101:10 - which I'm going to import from the openi
1101:12 - yesterday also I shown you this thing
1101:14 - now here this is the crucial step just
1101:16 - just focus over here guys just focus and
1101:19 - don't worry I'm giving you the link
1101:20 - again so just uh call okay I'm giving
1101:24 - you to my giving it to my team and they
1101:27 - will paste it inside the chat so here
1101:30 - you will get it uh within fraction of
1101:32 - second just
1101:39 - wait so guys uh here I given this
1101:42 - particular link inside the chat now you
1101:44 - can check you can copy it and you can
1101:46 - copy you can open it and you can copy
1101:47 - the entire code from here itself so
1101:50 - within a second you will get a link
1101:52 - inside your chat now let's try to
1101:54 - understand the further things till here
1101:56 - everything is fine everything is clear
1101:58 - everything is a perfect now here is what
1102:01 - here we have a method here actually we
1102:03 - have a like class chroma and inside that
1102:06 - you will find out a method from a
1102:08 - documents right now here we are passing
1102:10 - three things the first thing is what the
1102:12 - first thing is text the second thing is
1102:14 - a embedding and the third thing is what
1102:16 - the third thing is a directory right
1102:19 - first thing is text the second thing is
1102:21 - a embedding model and the third thing is
1102:23 - a directory now as soon as I will run it
1102:25 - let's see what I will be getting so it
1102:27 - is running and it is creating a
1102:29 - embedding it is generating an embedding
1102:31 - and I will get that inside my DB folder
1102:34 - inside my database folder just wait and
1102:37 - just look into this DB folder guys so
1102:40 - here actually uh it is running still it
1102:42 - is running and now open this DB so just
1102:46 - just refresh it and here inside that you
1102:49 - will find out the m now guys
1102:52 - see there is uh one cons there is one
1102:55 - disadvantage of this chroma DB So
1102:59 - Yesterday itself I shown you the pine
1103:01 - con there you will able to see the there
1103:03 - you were able to see the embedding and
1103:05 - all on top of the screen but here
1103:08 - whatever embedding you will get you will
1103:11 - get in the form of binary
1103:14 - file getting my point so here you will
1103:17 - get all the embeding in the binary file
1103:20 - in the bin file right here is the
1103:22 - extension you can see do bin getting my
1103:25 - point yes or no so now let's try to
1103:28 - decode this thing what I can do now
1103:29 - let's try to decode this thing this
1103:31 - particular thing where I got my eming
1103:34 - now everything is going to track by
1103:35 - using this uh SQL 3 right so in back end
1103:39 - it is using the SQL 3 and it's trying to
1103:41 - store the embeding because it is
1103:43 - required some sort of a server now
1103:44 - chroma DB is not a database right it's
1103:47 - just like a just a basically you can
1103:50 - think it's just a wrapper kind of a
1103:52 - wrapper basically so back in back end it
1103:54 - is using this sql3 server and it's
1103:56 - storing the
1103:58 - embedding but not like we are not going
1104:01 - to interact with this SQL 3 and all with
1104:03 - SQL and all right no it's not like
1104:06 - that right we are storing this vector
1104:08 - and in back end it is using a sql3
1104:10 - server got it now if you want to
1104:13 - understand more about the chroma DB you
1104:15 - can read about you can go and check with
1104:17 - the documentation and all then you will
1104:18 - find out a depth intuition regarding
1104:20 - this chroma DB now here I think this is
1104:22 - clear this is fine now let's do one
1104:24 - thing let's try to understand few more
1104:26 - thing over here after storing the data
1104:28 - in the form of uh embeddings inside this
1104:31 - DB folder now what I need to do next so
1104:34 - here uh you can see so we have the U
1104:38 - directory so let me show you okay just a
1104:41 - wait Vector DV data M
1104:45 - ready okay so here guys you can see uh
1104:48 - we are going to call this particular
1104:50 - method Vector db. pures right now here
1104:53 - I'm saying that purses the DB to the dis
1104:55 - so here I can call it I can call this a
1104:58 - particular method which is there on
1105:00 - inside the vector DB so here actually
1105:03 - you will find out you this is the object
1105:05 - right so which you got which you are
1105:06 - getting over here you can call this
1105:08 - particular method persist now if I will
1105:10 - run it so here you will be able to
1105:11 - persist this thing inside your uh local
1105:14 - disk itself right this one now here you
1105:17 - can see so Vector database is done we
1105:20 - can assign this also now guys here one
1105:23 - more thing which I would like to show
1105:24 - you which I would like to write it over
1105:25 - here that is what that is this uh like
1105:28 - chroma itself right so here we are
1105:30 - saying now we can load the purs database
1105:33 - from the disc and use it as a normal one
1105:36 - so what I can do here so here I call
1105:38 - this pures now I'm going to assign this
1105:40 - none now what I'm going to do here see
1105:43 - uh I'm going to use this Pur directory
1105:45 - means in whatever directory you want to
1105:47 - keep the database so there is a DB
1105:49 - itself This One DB and here I'm calling
1105:51 - embedding function is equal to embedding
1105:53 - right so here itself like here my
1105:55 - embedding function will be this
1105:56 - embedding and here is my Pur directory
1105:59 - right now what I have written over here
1106:01 - see now we can load the purs database
1106:03 - from the disk and use it in a normal
1106:06 - fashion right over here we can uh do
1106:08 - that so let me run it and here you will
1106:10 - find out so this is
1106:12 - what so here actually you will find out
1106:14 - the database so inside this itself uh
1106:18 - okay it is getting updated
1106:21 - just a second now let me yes read me new
1106:26 - article yeah so here basically in this
1106:28 - particular Vector DB you'll find out a
1106:30 - database now now see guys what we are
1106:32 - going to do so we have created a chunks
1106:35 - right now we have we have created a
1106:37 - chunks after that this is what this is
1106:39 - my embeddings which we are going to
1106:40 - import from the lenon itself now here is
1106:43 - my directory VB itself now here you will
1106:45 - find out the open AI embedding right so
1106:48 - this is what this is for calling the
1106:49 - embedding uh embedding like class which
1106:52 - is there inside the openi platform now
1106:54 - here what I'm going to do I'm going to
1106:56 - call this chroma right chroma is there
1106:58 - which I imported just just look into uh
1107:00 - this chroma okay which uh I had imported
1107:03 - somewhere let me show
1107:05 - you and we are consuming uh this as a
1107:08 - object this chroma just wait so
1107:11 - somewhere I have imported this thing
1107:14 - M where it is where it is imported
1107:17 - chroma import chroma yeah PIP show
1107:19 - chroma
1107:20 - DB I think I have imported somewhere in
1107:23 - between you you can check in a file
1107:25 - itself I have imported now here after
1107:28 - that what I need to do I need to call
1107:29 - this particular method from document
1107:31 - right now here I'm going to pass the
1107:33 - text this is my embedding and this is my
1107:34 - directory right in which I want to
1107:36 - process the m so here Ive created this
1107:38 - Vector DV right so as soon as I did it
1107:40 - now here you will find out we are going
1107:42 - to create this we have this particular
1107:44 - directory inside this we have this uh we
1107:47 - have this bin file there you will find
1107:49 - out there you will find out your
1107:50 - embeddings and all right and it is using
1107:53 - the sql3 server in back end right this
1107:55 - is fine now purs the DB to the disk if I
1107:57 - want to purist I'm just going to call
1108:00 - I'm just going to call this Vector db.
1108:02 - pures right now here if you will look
1108:04 - into that so here I'm going to call this
1108:06 - chroma right Pur DV this is my directory
1108:10 - now here is what here is my embedding
1108:11 - okay now if I'm going to run it so here
1108:13 - I'm getting my Vector DB right so from
1108:15 - the dis itself I'm able to get this
1108:17 - Vector DB so here actually we have the
1108:19 - dat see if I will run it now if I will
1108:22 - show you this Vector DB this one so
1108:24 - there you will find out this is what
1108:25 - this is my database means I'm able to
1108:28 - persist okay I'm able to purs this data
1108:31 - I'm able to purs this data in my local
1108:33 - disk and by using this particular object
1108:35 - we can access that now let me show you
1108:38 - how you can do that okay just wait so
1108:40 - here I'm writing uh the next thing which
1108:43 - you want to do so here I'm writing this
1108:46 - make retriever so just a second here I'm
1108:49 - going to write it down this make
1108:50 - retriever now you want to make a
1108:52 - retriever basically and for that what
1108:55 - I'm going to do so here I'm going to
1108:57 - call this one more method uh which is uh
1109:01 - which this function is having the method
1109:03 - name is what as retriever right so there
1109:05 - is what this will what this will my
1109:06 - retriever now what I can do guys just
1109:08 - wait I can give you this entire code so
1109:11 - you all can run inside your system so
1109:13 - I'm passing or I'm giving you this on
1109:15 - the like codes share. so you can get the
1109:19 - entire code from from there itself so
1109:21 - just a second I passing it over here I'm
1109:23 - giving you inside
1109:25 - my uh I'm giving you this inside the Cod
1109:28 - share. just just copy from there and
1109:32 - here the last method which you need to
1109:33 - call this is going to be a as retriever
1109:36 - so just a second now we just need to
1109:38 - cover few of the few thing and then I'm
1109:40 - going to wrap up it so here guys you can
1109:42 - see we have a retriever we after calling
1109:45 - this particular method we are able to
1109:47 - click we are able to create a retriever
1109:49 - now what I will do here just just focus
1109:51 - right just focus so here I'm going to
1109:54 - run this particular method by using this
1109:56 - Retriever get relevant document right so
1109:59 - here I'm going to run this uh this
1110:01 - particular method the method name is
1110:03 - what the method name is get relevant
1110:05 - document and here I am going to pass one
1110:09 - question the question is that how much
1110:11 - money did Microsoft raise right how much
1110:14 - money did Microsoft raise so this is the
1110:16 - question based on article if you look
1110:18 - into the article if you will try to read
1110:20 - the news right so there you will find
1110:22 - out somewhere related to the Microsoft
1110:24 - and related to the different different
1110:27 - startups so here I want to here
1110:29 - basically I have created a retrieval
1110:31 - right which is there uh we have a
1110:33 - function actually this method Vector DB
1110:36 - do as retrieval so this is what this is
1110:38 - my retrieval now here I'm going to call
1110:40 - this get relevant document so what it
1110:43 - will do so it will uh search inside the
1110:46 - entire DB and based on that it will
1110:48 - generate an answer so let's see what I
1110:49 - will be getting over here so yes if I'm
1110:52 - running it and now inside the docks
1110:54 - right now let me show you inside the
1110:57 - docks that what I have so here you can
1110:59 - see I'm getting a document right I I'm
1111:02 - getting a answer here I have created a
1111:04 - retrieval and whatever question I'm
1111:06 - asking right so it is matching it is
1111:08 - checking and here I'm getting answer how
1111:11 - this thing is happening let me explain
1111:13 - you so what I can do I can open my uh
1111:16 - Blackboard and there itself I can
1111:18 - explain you about it so so just a second
1111:21 - uh what is happening see what I'm going
1111:23 - to do
1111:24 - here so let's say we have a data right
1111:29 - just a second guys yeah so we have a
1111:31 - data and the data actually what I'm
1111:33 - going to do tell me so this data I'm
1111:36 - going to be uh this data actually
1111:39 - whatever data is there I'm going to
1111:40 - convert into
1111:43 - embeddings I'm
1111:45 - beding by using what tell me so by using
1111:49 - this opening API so here I can mention
1111:52 - the open a API now let's say we have
1111:55 - this
1111:57 - open AI API got it now this open by this
1112:03 - this basically this embedding whatever
1112:05 - embedding I'm going to generate I'm able
1112:07 - to keep inside my inside my tell me guys
1112:10 - inside my chroma DB right from here to
1112:13 - chroma DB let me create one more box
1112:15 - over here so here actually what I'm
1112:18 - going to do I'm going to keep inside my
1112:21 - chroma database got it right now this is
1112:26 - fine this is perfect okay and this
1112:28 - chroma DB actually it is available in
1112:30 - the local dis space it is available in
1112:34 - my local disk space now it is using this
1112:40 - SQL light server it is using the SQL
1112:44 - light server in
1112:47 - backend right and here it is storing the
1112:50 - data in the form of binary
1112:54 - file got it now here whatever data which
1112:57 - we are going to store inside my chroma
1112:59 - DB now I want to retrieve it means I
1113:01 - want to make a request from this D right
1113:05 - so what I want to do guys I want to make
1113:06 - a request from here so what I will do
1113:09 - for that uh so actually see I want to
1113:11 - make a request so the request will work
1113:13 - in which way so let's say we have
1113:16 - created a retriever right let let me
1113:18 - create a retriever over here so let's
1113:21 - say we have created a retriever now just
1113:23 - a second here is what here is what here
1113:27 - is my retriever now let me write it down
1113:30 - the
1113:31 - retriever over here this is what is my
1113:33 - retriever now I want to retrieve the
1113:35 - data so here let's see this is what
1113:37 - chroma DV is having a database so this
1113:40 - is what this is my
1113:41 - database
1113:45 - right okay great great great
1113:50 - so this one this one and this one right
1113:54 - so this is the database where we are
1113:55 - going to store the embedding now what I
1113:57 - will do I'm going to retrieve the data
1113:59 - so with that I have created object of
1114:00 - the retriever now I make a query so from
1114:04 - here basically I make a query so here
1114:06 - let's see this is what this is my query
1114:09 - okay just a second let me Define the
1114:11 - query over
1114:12 - here query okay query now I made a query
1114:17 - and this query actually see the request
1114:19 - is going the request is going from here
1114:21 - from here from here to this database
1114:25 - right this one and from here actually
1114:28 - what I'm getting in response if you will
1114:30 - look into the response so in the
1114:32 - response actually I'm getting a output
1114:34 - right so the response will be coming
1114:37 - from here and it is going like this this
1114:41 - one and this one right so this is what
1114:44 - tell me this is the response which I'm
1114:46 - getting so here I'm making a request
1114:48 - from here this is what this is my
1114:50 - request this is also my request right
1114:53 - and here what I'm getting I'm getting a
1114:55 - response right this is what this is my
1114:57 - response got it now here actually what
1115:00 - I'm doing so here I'm going to perform
1115:02 - the similarity search right so in this
1115:04 - requency response actually the thing
1115:06 - which we are going to perform we are
1115:08 - going to perform the similarity search
1115:11 - and based on that based on a similarity
1115:14 - search itself based on a semantic
1115:16 - meaning it is generating a final output
1115:19 - right so as a retriever actually what
1115:20 - I'm getting I'm getting a final output
1115:22 - and based on the semantic search it is
1115:24 - generating that a final output I hope
1115:27 - now the architecture is pretty much
1115:29 - clear to all of you let's start with the
1115:32 - coding again so here I'm getting uh all
1115:35 - the like whatever a question I've asked
1115:37 - so based on that it is going to generate
1115:39 - output and here you can see the first
1115:41 - output second output now let's check
1115:43 - with the first output so it has
1115:45 - generated uh like a different different
1115:46 - output not a single one and here if I'm
1115:49 - to check the page content so you will
1115:51 - find out that we have the entire detail
1115:54 - right so here you will find out the
1115:56 - entire detail regarding this particular
1115:57 - question so in this particular question
1115:59 - you'll find out the entire detail now
1116:01 - you can check the length of the document
1116:04 - also so what I can do here so what you
1116:06 - can do here so here you can write down
1116:08 - this dogs and there you'll find out it
1116:10 - is generating a four answer by default
1116:12 - it is giving me a four answer got it now
1116:15 - this is fine this is clear now what I
1116:17 - can do I can uh like I can call one more
1116:21 - method just a wait so here actually in
1116:23 - the retriever itself we have a different
1116:24 - different method sorry in the vector
1116:26 - database we have a different different
1116:28 - method so here I have called this uh as
1116:31 - retriever right as retriever now here is
1116:34 - what here is my retriever Now by using
1116:35 - this retriever I'm going to call this
1116:37 - get relevant document everything you
1116:39 - will find out in inside the document
1116:41 - itself just go and check with a chroma
1116:43 - DB documentation we have uploaded or
1116:46 - sorry not basically we so they have
1116:48 - uploaded everything over there in a very
1116:50 - detailed way just go and check every
1116:52 - function every method I'm going to take
1116:54 - from there itself right so I I'm going
1116:56 - to take from there itself just go and
1116:58 - check with the documentation now over
1117:00 - here guys see uh we have a retriever now
1117:02 - here I can Define the key also so search
1117:04 - KW KW R GS k equal to 2 there will be
1117:08 - only two output now here if I'm going to
1117:10 - call it now you will find out what I'm
1117:12 - going to do so I'm going to call this a
1117:15 - particular uh keyword s retriever dok
1117:18 - search a w RGS so you'll find out two so
1117:21 - we'll be getting two output only so if
1117:23 - you are going to search it now if you're
1117:25 - going to search any sort of a question
1117:26 - so let's say here is my question is what
1117:28 - here is my question uh retriever do get
1117:31 - relevant document and here how much uh
1117:34 - did Microsoft raise so let's see in the
1117:36 - document two what I will be getting so
1117:38 - here in the document two let me show you
1117:41 - first of all let me show you the length
1117:42 - of this document two so here is the
1117:44 - length of the document will be two so
1117:46 - I'm getting only two document I'm
1117:48 - getting only two document as a relevant
1117:50 - one means it is performing a similarity
1117:52 - size so in a back end itself in a back
1117:54 - end itself there is a vector and there
1117:56 - will be also a vector each and
1117:58 - everything is going to be uh like each
1118:00 - and every permutation is going to be
1118:01 - form and based on a similarity search
1118:04 - Okay based on a similarity search is
1118:06 - providing me a output so here you can
1118:08 - see it is giving me a two output as of
1118:10 - now now if you will look into this doc
1118:12 - two so there you will find out only two
1118:15 - output right so here you can see you
1118:18 - just have to Output so initially
1118:21 - actually by default it was giving me
1118:22 - four so I hope this thing is clear to
1118:25 - all of you now here I want to do one
1118:28 - thing I want to make it more realistic
1118:31 - right what I want to do guys tell me so
1118:33 - first of all let me give you this
1118:34 - particular code so at least you can
1118:36 - also uh generate some limited
1118:41 - output Vector DB as a retriever and here
1118:45 - is the next one is what so just a
1118:48 - second Vector DB
1118:53 - retriever so this is for the by default
1118:57 - and here this next one actually it is
1119:00 - for the two only right so here we have
1119:03 - Define the two so get how much Microsoft
1119:05 - money so here actually this is what this
1119:07 - is my docs tool got it guys yes or no
1119:10 - tell me did you got it
1119:17 - yes yes or no guys guys tell me please
1119:20 - copy the code from here please be active
1119:23 - I understand it is like it is it is
1119:26 - about to hour now so so please be active
1119:30 - guys see I I have a same energy now you
1119:32 - have to keep you have to learn with the
1119:34 - same energy okay I I haven't down my
1119:36 - energy and I'm I'm like explaining you
1119:38 - with the same energy I understand
1119:40 - initially thing will get in a more
1119:42 - effective way but as we are pro
1119:44 - progressing with the session so we lose
1119:45 - our like Focus we lose our like focus
1119:48 - and all
1119:49 - and so don't do like that okay so just
1119:52 - be active just be active for for more 10
1119:54 - minute and yeah we are going to wrap up
1119:57 - this thing so you will be ready with the
1119:58 - vector databases now in the next class
1120:00 - easily we can implement the project
1120:03 - right easily we can implement the
1120:04 - project and we can perform the RG
1120:06 - retrieval argument generator so this
1120:08 - Vector database we use for the RG only
1120:11 - for the retriever agumented generation
1120:14 - and is going to play a very important
1120:16 - role if you are going to create create
1120:19 - any sort of a application related to the
1120:22 - llms right related to the generative AI
1120:25 - where you are going to use llm so please
1120:27 - guys be take a take it serious and yes
1120:31 - in interview they will ask you the same
1120:33 - thing right I have seen many require
1120:35 - whatever requirements people are having
1120:37 - right related to the generative to the
1120:39 - llm and they are specifically they have
1120:41 - mentioned chroma DB pine cone right
1120:45 - because this is a trend actually right
1120:48 - people are able to uh use it people are
1120:50 - able to productionize it right people
1120:52 - are able to achieve whatever they want
1120:55 - right with respect to their use cases
1120:56 - and all and yes as a techie you have to
1120:58 - solve this thing you have to take care
1121:00 - this thing so please be serious over
1121:03 - here now uh here guys see we are able to
1121:06 - retrieve the document a similar document
1121:09 - by using this particular method right
1121:11 - now everything you will find out over
1121:12 - the documentation if you want to
1121:14 - understand a more depth go and check
1121:16 - with the documentation now let's try to
1121:19 - understand the next concept so here you
1121:22 - can see we have a doc two now let's do
1121:25 - one thing let's make it more interactive
1121:27 - and so for that here I have written
1121:28 - something uh so let's make a chain now
1121:31 - what I can do I can make a chain and
1121:34 - here guys for that here is one Library
1121:37 - you will find out inside the Len CH
1121:39 - itself the library is going to be
1121:41 - retrieval QA now let me run it and yes
1121:44 - we are able to import this retrieval Q
1121:47 - retrieval means you just need to
1121:48 - retrieve it retrieve it you just need to
1121:50 - get it right retrieve means response
1121:52 - right so here you can see we have this
1121:54 - retrieval QA now what I will do guys
1121:56 - here I'm going to use my llm model so
1121:59 - I'm going to call my open API because I
1122:02 - want to I want to get uh see here if you
1122:05 - if you will find out in the response so
1122:07 - just just look into the response here so
1122:09 - just just print this particular
1122:13 - response um what I can do I can print it
1122:17 - now see the response so they are giving
1122:20 - you the response and they are mentioning
1122:21 - everything over there now how to make it
1122:23 - more interactive and how to work with it
1122:26 - like a question answering right question
1122:29 - answering so for that you'll find out
1122:31 - this retrieval QA over here now here I'm
1122:34 - going to use my llm now you will find
1122:35 - out the use of the llm over here what is
1122:38 - the use or I will show you one
1122:39 - architecture so here I shown you the
1122:41 - simple architecture which I created by
1122:44 - myself only here you can see clearly you
1122:45 - can understand everything I will show
1122:47 - you one more architecture and I will
1122:49 - show you what is the role of this llm
1122:51 - over here what is the role of the llm
1122:53 - over here right now just wait let me
1122:56 - show you that or first of all let me run
1122:58 - it uh here I have written couple of
1123:02 - thing so let me show you the llm
1123:05 - first see we have we are going to call
1123:08 - open API and by default we have the uh
1123:11 - by default we have the model GPT model
1123:14 - cut it now what I'm going to do here I'm
1123:16 - going to create a chain by using this a
1123:20 - particular method so retrieval QA from
1123:22 - chain type so LM open a model and here
1123:25 - we have a retriever object retriever is
1123:27 - there this one okay retriever is there
1123:31 - and here you will find out the document
1123:33 - so return Source document is true so we
1123:35 - just need to pass two thing here the
1123:37 - first is what up our model and the
1123:39 - second one is retriever so retriever is
1123:41 - here this one okay this one so we are
1123:45 - going to collect it from the vector DB
1123:47 - this retriever right so here Vector DB
1123:49 - as retriever so this is my Retriever and
1123:51 - by using this retriever only we are
1123:53 - getting an information whatever we are
1123:54 - passing as a question and we are using
1123:57 - this method and this is what this is my
1123:58 - docs so this retriever object also we
1124:00 - are passing over here so we have a llm
1124:02 - model we have a retriever and here two
1124:05 - more parameter right now let me run it
1124:08 - and here you can see we are able to
1124:09 - generate or we are able to create a
1124:11 - object and which I'm going to store in
1124:13 - qhn right now guys here what I can do I
1124:17 - have return one more method so let me
1124:20 - copy and paste it over here and one more
1124:22 - method and after that the thing will be
1124:24 - more clear to all of you so what I'm
1124:26 - doing over here see uh this is the two
1124:29 - method which I have pasted right two uh
1124:31 - two code two Cod code is snipp it
1124:34 - basically which I pasted over here so
1124:36 - here see we want to create a retriever
1124:39 - QA so just just check what is the
1124:40 - meaning of that just open the Google and
1124:43 - uh search it over the Google Now paste
1124:46 - it over here and search about the
1124:47 - retrieval Q QA so what is this retrieval
1124:50 - QA everything you will find out inside
1124:52 - the Lang CH and guys believe me this
1124:54 - langen chain is very much powerful right
1124:58 - whether whatever like framework you are
1125:00 - going to learn in future I don't care
1125:01 - llama index and all but please try to
1125:03 - learn this Len CH if you want to build
1125:05 - llm based application so just take a
1125:08 - Mastery on top of this Len chain it's a
1125:10 - important one now here you will find out
1125:13 - what is this retrieval QA this example
1125:15 - so is question answering over an index
1125:18 - right the following example combining a
1125:20 - retrieval with a question answering
1125:22 - chain to do question answering right so
1125:24 - here I just want to make a question
1125:25 - answering chain and here is a complete
1125:28 - code snipp it here is a complete example
1125:30 - which they have given to you now what I
1125:32 - can do here I can uh show you that how
1125:35 - that this uh two thing is working now
1125:38 - this is what this is the from chain type
1125:39 - which I called create a chain to answer
1125:41 - the question now see process llm
1125:44 - response so llm response is there right
1125:46 - whatever L see first of all see this is
1125:48 - a query now here we are passing a query
1125:51 - now this is what this is the query which
1125:52 - we are getting now llm response see here
1125:55 - what we are going to do see this is what
1125:57 - uh here from here basically uh what I
1126:00 - see step by step let me show you so
1126:03 - first of all let me run it right this
1126:05 - one now what I will do here so this is
1126:07 - what this is my query right so here is
1126:10 - what here is my query how much money did
1126:12 - Microsoft race right now what I can do
1126:14 - here uh I can uh like call this
1126:17 - particular
1126:19 - uh method right so what is the method
1126:20 - guys tell me here this one is qhn right
1126:23 - so here is what here is a qhn this one
1126:26 - this one so I'm passing this query to my
1126:28 - qn right so let me run it and here you
1126:31 - will find out the llm response so let me
1126:33 - copy it and let me paste it over here so
1126:35 - this is what guys see this is your llm
1126:37 - response this one right so here what I'm
1126:40 - doing I see uh retrieval QA right you
1126:45 - you are talking about the r now
1126:46 - retrieval argument generation so it is
1126:49 - related to that only it is related to
1126:51 - this only it's Advanced concept so this
1126:53 - is a basic RG which we have created this
1126:55 - is a basic RG which we have created
1126:57 - where we are not going to generate
1127:00 - directly answer from my llm no we are
1127:03 - not going to do that here we are going
1127:05 - to pass this retriever object this
1127:07 - particular object and from there
1127:08 - actually we are going to generate an
1127:10 - answer from here see we have open AI
1127:14 - model llm model we are not going to ask
1127:17 - we are not going to generate a response
1127:18 - from the open from the llm model right
1127:21 - it is just for the refinement right it
1127:23 - is just for the refinement or for the
1127:24 - better understanding is not if you are
1127:27 - not going to train it now if you're not
1127:28 - going to train this model on top of this
1127:30 - data and if you are passing this
1127:32 - retriever if you are passing this
1127:34 - retriever object over here means you are
1127:36 - passing the embedding you are passing
1127:38 - your database you are passing your data
1127:40 - over here right so instead of instead of
1127:43 - generating a data instead of generating
1127:45 - answer from the model is it is it is
1127:47 - giving you the answer from the embedding
1127:49 - itself llm is here just for the
1127:51 - refinement right just to understand it
1127:54 - not going to generate answer and this is
1127:56 - only called retrieval argument generator
1127:59 - gener generator retrieval argument
1128:01 - generator and here you are going to
1128:03 - achieve this thing by using this Vector
1128:06 - datab Base by using this Vector database
1128:10 - so here you are going to call this llm
1128:12 - right here is llm have you created a
1128:14 - function calling have you created a
1128:16 - function calling so it is working
1128:17 - similar to that if you are aware about
1128:20 - the function calling where I'm using a
1128:22 - llm but llm is not generating answer
1128:24 - some third party API is giving me answer
1128:27 - right so it is working in a similar way
1128:29 - here is my llm and this is what this is
1128:31 - my retriever which is nothing which is
1128:33 - my embedding so here I passed my query
1128:36 - and it has generated answer this LM
1128:38 - response now guys what I want to do I
1128:40 - want a response so where it is tell me
1128:43 - it is there inside the source document
1128:44 - so here what I'm going to do so I'm
1128:46 - passing my LM response over here and
1128:49 - from the result so this is my result and
1128:51 - this is my complete uh like answer which
1128:53 - is which it is giving to me so here
1128:56 - actually this llm we are using for the
1128:58 - refinement for the refined answer see
1129:00 - see over here now if I'm running it this
1129:03 - one what I'm doing I'm going to run it
1129:05 - see this I'm going to run this one so it
1129:07 - is giving me a so it is giving me this a
1129:09 - particular uh it is giving me this like
1129:12 - a particular answer this is for the
1129:14 - refinement llm is not for the generation
1129:16 - answer generation answer this is the
1129:19 - answer which we are generating from the
1129:20 - document itself from the database itself
1129:24 - based on a similarity search right and
1129:26 - this is only called R A retrieval
1129:28 - argument generation and here this chat
1129:30 - GPD or this like a GPD model we are
1129:32 - using for the refinement so it is giving
1129:34 - me a final answer so already I have
1129:36 - written a code over here so we are get
1129:38 - extracting a result and we are printing
1129:40 - a result and here is a metadata and all
1129:42 - whatever is there so we can print that
1129:44 - also so this is the metadata resources
1129:47 - now guys tell me did you get the concept
1129:49 - of the r did you get the concept of the
1129:51 - vector database did you get that how to
1129:54 - like uh do the question answering after
1129:57 - generating a aming and all in my
1129:58 - previous class also I shown you the same
1130:00 - thing in the previous class I created a
1130:02 - while loop and I was giving the queries
1130:04 - and all and I was generating answer you
1130:05 - can do the same thing over here and you
1130:07 - can create your question answering
1130:09 - system you can create your chatbot which
1130:11 - we are going to do in the next class so
1130:14 - this is just a like a basic introduction
1130:17 - and the next class we are going to
1130:19 - create a application by using this
1130:21 - particular concept now tell me are you
1130:24 - getting it guys yes or
1130:30 - no tell me how many people are able to
1130:33 - understand yes or no tell me fast
1130:35 - whatever explanation I have given you
1130:37 - regarding that how many people are able
1130:39 - to
1130:42 - understand yes sir uh we have existing
1130:46 - qua system what is uh what is the
1130:51 - difference between exis system and llm
1130:52 - model exis system is this one now this
1130:55 - is your data see let me revise this
1130:57 - thing what I can do here uh where it is
1131:02 - okay this one now what I can do here
1131:03 - itself I can revise this thing just a
1131:05 - second okay so I have one image let me
1131:08 - show you that a particular image just a
1131:17 - second
1131:20 - so this is the image right this is the
1131:23 - image can you see this image guys this
1131:25 - one is it visible to all of you this
1131:27 - this particular image tell me guys fast
1131:31 - so this is the image actually which I
1131:32 - created for uh for the project actually
1131:35 - this is the project flow now let's try
1131:37 - to understand what is happening over
1131:38 - here right so I can explain you this
1131:40 - thing in a like clear man manner just
1131:43 - just see just focus over
1131:46 - here right now what is is happening see
1131:49 - uh do you have a data just say yes or no
1131:53 - until you won't say Yes I won't proceed
1131:55 - so this is the data
1131:57 - right are we extract are we converting a
1132:00 - data so are are we extracting a data yes
1132:03 - so this is my first step this is my
1132:05 - second step right now here you can see
1132:08 - this is my third step now here you can
1132:11 - see this is what this is my fourth step
1132:12 - this one right this is what this is my
1132:15 - fourth step now after that what I'm
1132:17 - going to do so so
1132:19 - here I'm going to save my data in my
1132:22 - Vector store in my chroma DB so either I
1132:25 - can store chroma DB or vector database
1132:27 - tell me so here either I can store
1132:29 - chroma DB or vector datab everyone so I
1132:32 - think you all are enjoying s's
1132:34 - class
1132:46 - lecture okay so guys here you can see so
1132:50 - this is what here we are going to store
1132:52 - the data in a chroma DB itself right so
1132:54 - in a chroma DB yeah here actually we are
1132:57 - going to store the data in a chroma DB
1132:59 - now see if user is going to query right
1133:02 - if user is going to query now what will
1133:05 - happen if user is going to query this
1133:07 - thing now what will happen see uh here
1133:10 - let's say this is what this is my user
1133:12 - okay just wait let me remove it from
1133:15 - here um yeah
1133:18 - so this is the user right so we have a
1133:20 - data over here we have created a data uh
1133:23 - so this is what this is my data where I
1133:25 - have saved my embedding right so here I
1133:27 - have saved my embedding now here you
1133:30 - will find out the embedding now here is
1133:32 - a user this is what this is the user now
1133:35 - here user is asking the question right
1133:37 - user is asking the question now here we
1133:40 - will search like query aming right and
1133:43 - based on that so we'll go into the
1133:45 - database and here see from the database
1133:47 - will retrieve the answer and llm will
1133:50 - refine the answer right llm will refine
1133:52 - the answer just just look into the arrow
1133:54 - so what is the role of the llm over here
1133:56 - llm is just for the refinement because
1133:59 - the mding we are going to the iding
1134:02 - right so whatever iding is there right
1134:04 - so this embedding
1134:05 - actually uh this data we are going to
1134:09 - fetch from the DB itself right so here
1134:12 - is a see till here everything is fine
1134:14 - see this is the work of the uh this is
1134:16 - the work of the developer till here now
1134:19 - let's say user will ask the question so
1134:22 - the question will come over here it is
1134:23 - going to do a semantic search and and is
1134:25 - going to take a answer and here from
1134:28 - here actually it is taking an answer and
1134:30 - then it is going to rank the result so
1134:32 - in that in my case I'm getting two
1134:34 - result right or three result or four
1134:36 - result now what I will do here so it
1134:38 - will pass to my llm model and this llm
1134:41 - model will give me a final answer now it
1134:44 - is getting clear how the flow is
1134:46 - happening how the how the thing is
1134:48 - working over here tell me guys fast how
1134:51 - the thing is working over here did you
1134:53 - get it guys yes or no got it now so that
1134:56 - is a thing which we have implemented in
1134:58 - a Jupiter notebook Now by using that so
1135:00 - this thing actually we can use this this
1135:03 - particular thing we can use inside our
1135:05 - application right and we can create one
1135:07 - QA system so from the data whatever data
1135:10 - we have from the data the data basically
1135:12 - the files which we have our data from
1135:15 - there basically we can get answer and
1135:17 - llm can refine that particular answer I
1135:19 - can give the direct answer also from the
1135:20 - database or I can refine the answer so
1135:23 - that's is a use of the vector database
1135:26 - now in the next class we are going to
1135:28 - create a in the next class we are going
1135:30 - to create an application and that's
1135:32 - going to be chatboard application and
1135:34 - literally you will enjoy if you are able
1135:35 - to understand this today's session so
1135:38 - tell me guys how was the session how
1135:40 - much you would like to rate to this uh
1135:42 - application and and whatever I have done
1135:45 - over here so tell me guys fast if you
1135:49 - have any query any doubt you can let me
1135:51 - know I will give you this entire code
1135:53 - and here is the uh like I can give you
1135:56 - this particular code as well I hope I
1135:59 - have already pasted in the just a second
1136:02 - so let me give you this uh two thing the
1136:07 - first is going to be a qhn this one and
1136:11 - the second is going to be this
1136:15 - one uh just a second
1136:19 - this okay so I given you the both code
1136:22 - now what I can do here
1136:25 - so this is the code and yeah now you can
1136:30 - query you can ask anything whatever
1136:32 - query whatever like uh data actually we
1136:36 - have based on that you can query you can
1136:38 - take a bigger database right and yeah
1136:42 - now I think
1136:44 - uh you are able to get it
1136:50 - no this
1136:54 - one so fine I hope uh this part is clear
1136:58 - to all of you now please go through with
1136:59 - the code please try to run inside your
1137:01 - system just copy from here and run
1137:04 - inside your jupyter notebook data and
1137:05 - all each and everything I have provided
1137:07 - to you I have already given you and uh
1137:11 - yeah now if you want to see if you want
1137:13 - to stop the database if you want to
1137:15 - means uh the datab database basically
1137:18 - which you have created right so if you
1137:19 - want to stop it if you want to delete it
1137:22 - if you want to like clean it so for that
1137:24 - also we have a command let me give you
1137:26 - uh those particular command so here you
1137:29 - just need to so first of all let me
1137:31 - write down the heading and the heading
1137:32 - is what so heading is uh you can delete
1137:35 - the database so delete the DB now you
1137:40 - can see uh what you can do guys you can
1137:42 - delete the DB and here uh what you need
1137:45 - to do so you need to read this J you
1137:48 - need to like uh create this jip file
1137:50 - actually this jip by using first of all
1137:53 - you need to jip it actually the entire
1137:55 - thing is there just you need to jip it
1137:57 - and after that what you will do you will
1137:59 - run this particular command so let me
1138:02 - give you this two command the two
1138:05 - command the first one is delete
1138:07 - collection and the second one vector.
1138:09 - process right so to clean up entire
1138:11 - thing you just need to call this two
1138:13 - thing and here the last one you can
1138:16 - delete this jip directory so here is the
1138:19 - directory which you are going to delete
1138:21 - means here is the folder the entire
1138:22 - folder where you will be having the jip
1138:24 - directory you are going to delete that
1138:26 - and yes finally you will be able to
1138:27 - delete your data base the data base
1138:31 - basically which you have created by
1138:32 - using this chroma DB so yes or no guys
1138:37 - tell me um if you got everything then
1138:40 - yes it is well and good if you if you
1138:43 - didn't get then um definitely you should
1138:45 - revise the thing everything will be
1138:46 - available over the dashboard so just uh
1138:49 - go and check with the dashboard let me
1138:52 - show you the
1138:53 - dashboard just a
1138:55 - second so here the session is going on
1138:58 - now let me show you the dashboard also
1139:01 - this is the dashboard guys uh this one
1139:04 - so just just check with the dashboard
1139:05 - just enroll to this dashboard and apart
1139:07 - from that you can explore the course as
1139:09 - well the course which we have launched
1139:11 - on a generative AI here is a Course and
1139:13 - there you will find out everything the
1139:15 - concept which I have explained you over
1139:16 - here we are going to explain in a more
1139:18 - detailed way we are going to clarify
1139:20 - more thing regarding this RG or
1139:23 - regarding this uh like different
1139:25 - different uh tuning and all parametric
1139:26 - tuning this that whatever everything we
1139:28 - are going to clarify over here so just
1139:30 - go uh go and check uh with this uh
1139:34 - website with the uron website just go
1139:36 - and explore the course this uh just go
1139:39 - and explore this Genera course
1139:42 - everything you will be finding out over
1139:44 - here just just explore the syllabus okay
1139:46 - this is the syllabus and if you want
1139:48 - anything if you want any update anything
1139:50 - let's say this is the new one right
1139:52 - which we have launched right so if you
1139:54 - want anything any recent thing which on
1139:56 - which you are working in a market in
1139:58 - your organization you can let us know
1140:00 - you can let me know you can ping me you
1140:02 - can uh write it down on my LinkedIn
1140:04 - right so based on that um if there will
1140:06 - that will be like uh that uh I I will
1140:09 - consider I will think about that and if
1140:12 - it is really going to be an important
1140:14 - one so I will add on inside the syllabus
1140:16 - okay immediately I will add on inside
1140:18 - the syllabus and we are going to take it
1140:19 - inside the live class so I hope uh this
1140:23 - is fine to everyone now we can wrap up
1140:26 - the session and from next class onwards
1140:28 - we are going to start with one more
1140:30 - project and that's going to be on Monday
1140:33 - Monday 6 sorry Monday 300 p.m. IST and
1140:37 - yes so I'm not going to take that
1140:39 - session buppy will be available for that
1140:42 - particular session buy will start with
1140:44 - the project and all if you don't know
1140:46 - about the buy so I can show you the
1140:48 - profile of the buy just uh over the open
1140:51 - the LinkedIn and search the search uh
1140:54 - buppy okay now buy the full form name
1140:58 - the full name is a b Ahmed buy just open
1141:01 - the profile of the buy and he's like
1141:03 - really good Mentor you can visit his
1141:05 - YouTube channel as well this is the
1141:07 - YouTube channel of the Wy there you'll
1141:09 - find out the like content related to the
1141:12 - computer vision and all so just go
1141:14 - inside the video he's having a amazing
1141:16 - cont content related to the computer
1141:18 - vision and you can go and check you can
1141:21 - check with the mlops content as well
1141:23 - everything he he has kept over the
1141:25 - YouTube so you can visit the YouTube
1141:27 - channel so next class will be taken by
1141:30 - the buy and yes in that we are going to
1141:33 - implement one more project so Monday
1141:35 - Tuesday and Wednesday fine so I hope
1141:39 - guys this is clear to everyone now there
1141:43 - is one question sir can you provide one
1141:45 - end to end project for interview purp
1141:47 - yes we are going to implement that in a
1141:49 - next class in the next uh in the next uh
1141:53 - basically class and uh don't worry you
1141:55 - will find out a project soon in my
1141:57 - internship on on the internship portal
1141:59 - as well so let me show you the
1142:01 - internship portal where it is just click
1142:03 - on this click on the internship portal
1142:06 - and here okay so you will find out all
1142:10 - the project and all as of now we haven't
1142:12 - updated related to the generative AI it
1142:15 - is in a pipeline I already given to my
1142:17 - team the work is work is uh going on on
1142:19 - top of that so there's there are like
1142:22 - couple of use cases related to the
1142:24 - different different domain which is a
1142:25 - which is directly related to the real
1142:27 - world so you can explore that you can uh
1142:30 - like go through with that and then you
1142:32 - can start your internship and you can
1142:34 - generate a certificate you can generate
1142:35 - a experience certificate and you can uh
1142:37 - write it down that particular project in
1142:39 - a in resume also see one thing I would
1142:42 - like to tell you let's say if you are uh
1142:44 - like whatever I'm like telling you
1142:46 - whatever I'm teaching you let's say I'm
1142:48 - not able to teach 100% but I'm giving
1142:50 - you the direction let's say I taught you
1142:52 - 50% thing but rest of the 50% I've given
1142:55 - you the direction right so rest the rest
1142:57 - 50% thing I given you in terms of the
1142:59 - direction and all so try to explore
1143:02 - those Thing by
1143:03 - yourself like anywhere you won't be able
1143:05 - to find out that one Mentor is doing
1143:08 - everything for you let's say you ask
1143:09 - about the inter you ask about this uh
1143:12 - like uh one project which I can show you
1143:14 - in a uh in a like interview and all or
1143:17 - which I can show you somewhere so guys I
1143:20 - guided you up to certain point right now
1143:23 - it's your chance you can find out the
1143:24 - different different use cases and you
1143:26 - can Implement those by taking my
1143:28 - reference and in that you can add on few
1143:29 - more things right then only you will be
1143:32 - able to cck the interview if you going
1143:33 - to take a same project from me and you
1143:35 - are going to uh like you are going in an
1143:37 - interview then you won't be able to
1143:39 - crack it because you won't be having
1143:40 - that confidence that knowledge okay
1143:43 - which is required in an interview which
1143:45 - you will get once you will do by your
1143:47 - self okay so keep this thing in your
1143:49 - mind and learn according to that and yes
1143:52 - definitely you can crack any interview
1143:54 - this is not a big deal you just need to
1143:56 - represent yourself your work that's it
1143:59 - okay so thank you guys thank you for
1144:01 - attending this session from next class
1144:02 - onwards we are going to start one more
1144:04 - project and please do revise the thing
1144:07 - whatever we have learned in today's
1144:08 - session in today's class here is the
1144:10 - entire file here is our entire content
1144:13 - just go through with that and yeah thank
1144:15 - you bye-bye take care if if you have any
1144:17 - doubt you can write it down on the over
1144:18 - the LinkedIn and please share your
1144:20 - learning as well uh over the LinkedIn
1144:23 - you can tag me I will look into that I
1144:24 - will like it I will share it so my name
1144:27 - is B Ahmed B and uh I'm working as a
1144:30 - data scientist at Inon and I have more
1144:33 - than two years of experience uh in the
1144:35 - field of machine learning deep learning
1144:37 - computer vision Genera and natural
1144:39 - language processing and uh if you want
1144:41 - to connect me anytime so this is my
1144:43 - social media link I think some of them
1144:45 - already have connected with me so if you
1144:48 - have any issue u in the field of this
1144:50 - generative a and all with the
1144:52 - implementation of the projects so
1144:54 - anytime you can ping me okay I will be
1144:55 - happy to help
1145:04 - you okay guys thank
1145:14 - you so let me uh show you that agenda
1145:17 - for today so today actually I'm going to
1145:19 - discuss something called open source
1145:20 - large language
1145:21 - model so as of now I believe you have
1145:24 - work with like open AI based large
1145:27 - language model guys yes or
1145:38 - no uh
1145:41 - yes now uh can anybody tell me what was
1145:44 - the difficulties actually you were
1145:45 - facing whenever uh you are using this
1145:47 - kinds of Open Source lar language model
1145:50 - any anyone give me any
1145:55 - response yeah mostly open a and a your
1145:58 - open yeah I know that so what is what is
1146:01 - your difficulty level there just can you
1146:03 - tell
1146:06 - me um resources uh it's not a major
1146:13 - [Music]
1146:15 - issue okay see the major issue is like
1146:20 - uh the cost okay because I believe you
1146:24 - onlyon be having like a paid account
1146:26 - most of
1146:28 - you and before starting guys let me tell
1146:31 - you uh all the resources has been
1146:32 - updated in that uh uh dashboard actually
1146:36 - so let me show you the dashboard
1146:38 - once so if you open that
1146:40 - dashboard I believe guys you enroll for
1146:43 - the dashboard and it is completely free
1146:45 - without any cost
1146:48 - yeah see guys all the video has been
1146:51 - updated here and as well as I believe
1146:53 - the resources also has been updated even
1146:55 - maybe some quizzes and assignment has
1146:57 - been also given there okay so you can go
1146:59 - through that even it is also available
1147:02 - in your YouTube live section okay and
1147:04 - today whatever things actually I'm going
1147:06 - to do everything would be shared in your
1147:08 - resources section no need to worry
1147:15 - about yeah
1147:17 - so what I was telling guys uh see as of
1147:20 - now you have used like open AI based
1147:22 - large language model and the major issue
1147:24 - was the like cost there yes or no
1147:27 - because I believe you won't be having
1147:29 - like paid account most of you if you are
1147:32 - having also paid account so at the end
1147:34 - of the month you need to pay okay for
1147:36 - the model you are using from the open a
1147:38 - yes or
1147:41 - no
1147:43 - yes okay now see guys U how to like
1147:47 - track your cost like whenever you are
1147:49 - using this kinds of open based like uh
1147:52 - large language model okay if I'm talking
1147:53 - about open based large language model so
1147:55 - I'm mostly talking about something
1147:57 - called GPT okay GPT Series so if you
1148:00 - just search open AI pricing okay if you
1148:02 - just search openi pricing on Google so
1148:05 - there is a page actually you will get
1148:07 - from the openi site and here actually
1148:09 - they have already mentioned the cost
1148:11 - okay they're taking from you so let's
1148:13 - say if you're using GPT 4 Series model
1148:15 - okay so in GPT 4 Series you have
1148:17 - different version of the model so let's
1148:19 - say you have GPT 4 Turbo okay so if you
1148:22 - are using this particular model so this
1148:24 - is the model name as you can see GPT 4
1148:27 - uh 1106 preview so this is the model and
1148:30 - this is the cost with the input tokens
1148:32 - okay so each of the model will have
1148:35 - their input size okay what is the input
1148:36 - size input size means the number of text
1148:39 - actually you are giving as a input to
1148:40 - the model okay and that can be
1148:42 - calculated by this
1148:43 - token okay so let's say if you're giving
1148:46 - 1,000 tokens so it will charge you
1148:49 - 0.0 $1 okay this is the charge and if
1148:52 - your model is giving let's say one uh
1148:54 - 1,000 uh like tokens output so it will
1148:57 - charge around
1148:58 - 0.03 now just combine them and just
1149:00 - calculate the
1149:02 - cost okay so this is for the GPT for
1149:05 - Turbo now let's come to the GPT model
1149:07 - and you can see whenever you are trying
1149:09 - to use the core GPT model it will uh
1149:11 - take you some more charge for
1149:15 - me okay
1149:17 - okay now see not only GPT uh 4 you have
1149:20 - also GPT 3.5 turbo then you have
1149:23 - assistant API fine tuning models even I
1149:25 - think you already used embedding models
1149:27 - in your vector database guys yes or
1149:33 - no have you used this embedding
1149:42 - model
1149:45 - yeah
1149:50 - okay see that's how you can calculate
1149:53 - your cost like how much it will charge
1149:54 - you whenever you are going for any kinds
1149:56 - of model okay you can go through this
1149:58 - pricing praise and you can understand
1150:00 - this
1150:01 - thing all
1150:03 - right yeah see ADI is there DCI is there
1150:07 - there are lots of model okay they have
1150:08 - given just high level overview but maybe
1150:11 - they have some more pages actually I
1150:13 - think you can go through and like see
1150:15 - the cost there
1150:22 - all right now see why we need to use
1150:25 - open AI uh sorry why I need to use this
1150:27 - open source large language model okay
1150:29 - first of all let me discuss then I will
1150:30 - start with that uh like discussion okay
1150:33 - what like today's discussion on the Lama
1150:35 - 2 I will tell you how to use Lama 2 and
1150:37 - all even I will show you some available
1150:39 - open source model you can go through
1150:41 - okay now see guys whenever I'm talking
1150:43 - about open source model okay open source
1150:50 - open
1150:52 - source
1150:54 - llm okay op source llm so the first
1150:58 - thing uh you can consider you don't need
1151:01 - to pay any cost okay so you don't need
1151:05 - any no
1151:08 - need
1151:09 - cost okay the second thing you can talk
1151:13 - about um it is completely free to use
1151:17 - free to use for
1151:21 - the
1151:25 - research and commercial use
1151:30 - cases okay commercial use
1151:35 - cases all right but whenever I'm talking
1151:38 - about open
1151:39 - AI okay open
1151:43 - AI open so so I'm talking about GPT
1151:47 - series okay GPT
1151:51 - Series so let's say if you want to use
1151:53 - open a so the first thing actually will
1151:55 - come you need to get
1151:58 - the API
1152:01 - key okay API key and if you need this
1152:04 - API key you need to pay for okay you
1152:06 - need to pay for you need to pay it's not
1152:09 - a free all right but one advantage
1152:12 - actually will get with this open
1152:15 - AI
1152:17 - one advantage actually will get uh from
1152:19 - this open a which is nothing but uh it
1152:23 - is completely API accessible okay
1152:28 - API accessible okay so here you don't
1152:31 - need to download that particular model
1152:33 - to use so if I visit open a so let's say
1152:37 - this is my open a
1152:39 - website okay this is my open a so here I
1152:42 - will just loging with this uh website
1152:45 - and here I can generate the API keys I
1152:47 - think you already done some of the
1152:48 - projects and all right so here I can
1152:50 - easily get the open API keys and what I
1152:53 - will do I will open my local machine I
1152:55 - can also open my Google collab I can
1152:57 - also open my jupyter notebook and there
1152:59 - actually I can start my development okay
1153:02 - there is no issue with that so you don't
1153:03 - need any kinds of powerful machine there
1153:05 - because everything is running on the
1153:10 - API yes or no guys tell
1153:14 - me let's make this session
1153:16 - interactive so that I can Al also
1153:18 - understand like you are understanding my
1153:20 - concept guys reply me in the
1153:34 - chat
1153:39 - yeah thank
1153:42 - you so this is the idea of open AI so so
1153:46 - openi what they did actually they
1153:47 - created this beautiful website okay and
1153:49 - they hosted their models U um to their
1153:53 - server okay and they created some of the
1153:55 - API and with the help of API we can send
1153:58 - the request to the model and we can get
1154:00 - the response okay let's so let's say
1154:01 - this is my this is my model okay this is
1154:04 - my
1154:05 - model this is my model hosted on open
1154:09 - okay it is hosted on open
1154:11 - a now here user will give some query
1154:15 - okay user will get some some
1154:17 - quy okay with the help of the API
1154:20 - key okay with the help of the API key
1154:23 - and this model will give you some
1154:25 - response okay this model will give you
1154:27 - some
1154:29 - response response okay and this uh
1154:33 - request and response you are getting for
1154:35 - this you need to pay you need to pay
1154:36 - some money because this is not a free
1154:39 - this model is hosted on the openi
1154:41 - website and they have created the API
1154:43 - key so for this API key okay to access
1154:45 - the you need to pay
1154:49 - something hi sir as you know Lama 2 is a
1154:52 - heavy model and it's responsive time
1154:54 - also High then how can we decrease the
1154:58 - time to response the open source model
1155:00 - so F we'll be discussing this one okay
1155:02 - no need to worry about like how we can
1155:04 - use this Lama to model in our CPU
1155:06 - machine so we have a projects no need to
1155:08 - worry about I will tell you
1155:12 - okay so guys so far this understanding
1155:15 - is clear like uh what is the advantage
1155:18 - with the open AI okay why we usually use
1155:21 - open AI is it
1155:25 - clear if yes then I will move to the uh
1155:28 - open source part like why we need to use
1155:30 - open source okay and what is the
1155:31 - difficulty level with the open source
1155:38 - model okay can we set the limit of the
1155:42 - uses tokens how we get idea about the
1155:45 - pricing when the test out chatbot uh yes
1155:47 - you can also set the limit uh limit of
1155:50 - the pricing it is also possible let's
1155:52 - say you can set the limit for the $10 so
1155:54 - when it will uh come like close to the
1155:56 - $10 so you will get the notification
1155:59 - okay that can be also
1156:02 - done all right now see so whenever I'm
1156:06 - talking about open source model okay
1156:08 - open source
1156:10 - model open source
1156:13 - llm okay so the first thing you need
1156:15 - need
1156:20 - to so so the first thing you need to
1156:23 - understand uh see whenever I'm talking
1156:26 - about open source it's not hosted okay
1156:28 - it's not hosted not hosted
1156:32 - anywhere some of the model might be
1156:34 - hosted you will get API key but most of
1156:37 - the model would be available on the
1156:38 - hugging pH okay hugging face or
1156:40 - different website okay so it's not
1156:42 - hosted
1156:44 - anywhere it's not host anywhere okay so
1156:47 - what you need to do you need to
1156:50 - download download that particular
1156:54 - model download that
1156:57 - model okay then what you need to do you
1157:01 - need to load that
1157:04 - model you need to load that model okay
1157:07 - that's how you need to perform all the
1157:09 - task manually okay so there actually you
1157:11 - won't be getting any kinds of open kinds
1157:13 - of API key so that actually you can hit
1157:14 - the AP key request and you will get the
1157:17 - response it's not like
1157:22 - that uh guys my video is fine um or
1157:25 - there is any lag you can
1157:37 - feel uh video is fine
1157:42 - guys yeah I I believe it is fine
1157:49 - okay all
1157:57 - right all right now see the main
1158:01 - disadvantage of this open source llm is
1158:03 - you
1158:04 - need you
1158:06 - need good
1158:11 - configuration good fun configuration
1158:14 - system
1158:16 - okay so whenever I'm talking about good
1158:18 - configuration system you should have at
1158:20 - least Core
1158:22 - i core i5 or let's say three
1158:28 - processor processor and you should have
1158:31 - at least uh 8
1158:34 - GB of RAM okay 8 GB of RAM and if you
1158:38 - have GPU then it would be plus point for
1158:41 - you okay because it needs GPU
1158:44 - computation so whenever we'll execute
1158:46 - the uh model it needs actually GPU
1158:48 - computation but I will tell you also how
1158:50 - we can execute the model on the CPU
1158:52 - machine both can be done okay so uh and
1158:55 - think see U today actually I'm not going
1158:57 - to use this neural LA because I believe
1159:00 - in the neural La we don't have any GPU
1159:01 - integration there so I'll be using
1159:03 - Google collab today okay so whenever I
1159:05 - will be implementing the projects that
1159:07 - time I can show you on the neural
1159:14 - lab yes we have see we know that
1159:17 - actually we all have mostly CPU machine
1159:20 - okay we know that okay that is why I
1159:21 - will tell you one like technique uh
1159:24 - using that technique actually you can
1159:26 - execute any kinds of llm model on your
1159:27 - CPU machine as well it is also
1159:33 - possible okay so these are the
1159:35 - requirement actually you need whenever
1159:36 - you are talking about open source large
1159:38 - language model okay because this model
1159:40 - you need to manually
1159:41 - download okay manually download manually
1159:44 - load and manually execute deser the
1159:46 - model okay that you won't be getting any
1159:48 - kinds of API kinds of thing okay so that
1159:50 - is the
1159:56 - thing and some if I'm talking about some
1159:59 - advantage of the open open source model
1160:01 - so here actually you don't need any
1160:03 - kinds of cost okay without any kinds of
1160:06 - cost you can use this model for the
1160:07 - research purpose as well as the
1160:09 - commercial
1160:12 - purpose so guys uh is it clear the
1160:15 - difference difference between our open
1160:17 - AI model and our open source large
1160:19 - language model yes or
1160:27 - no uh see if you have 4GB of ram then I
1160:30 - think you can practice on uh Neal lab
1160:33 - it's completely fine but uh today
1160:35 - actually I will show everything on the
1160:36 - Google collab
1160:39 - okay so you don't need to worry about
1160:41 - the system
1160:44 - configuration all
1160:46 - right guys uh is it clear the difference
1160:49 - between uh open a model and
1160:57 - [Music]
1161:09 - uh uh okay just a minute uh just a
1161:14 - minute
1162:10 - okay uh am I
1162:14 - Audible
1162:22 - uh please let me know in the chat am I
1162:23 - audible
1162:25 - [Music]
1162:31 - guys
1162:36 - okay okay thank you so now uh let's
1162:39 - introduce our uh some open source large
1162:43 - language model so here if you see there
1162:46 - are like very popular and Powerful open
1162:48 - source llm
1162:54 - there okay so see uh there are very uh
1162:58 - like there there are lots of actually
1162:59 - open source large language model
1163:01 - available okay over the internet you
1163:03 - will find but there are some most
1163:05 - popular uh open source llm I will
1163:07 - introduce today so uh the first thing is
1163:09 - like I personally like this one called
1163:11 - meta Lama 2 okay so this is the model
1163:14 - for from the Facebook so Facebook has
1163:17 - trained this model and they named it as
1163:18 - Lama 2 okay so there is another model
1163:21 - called Google Pam 2 okay so this is
1163:23 - another model called Google Pam 2 so the
1163:25 - this model actually trained by the
1163:27 - Google anyone used like Google B before
1163:31 - Google B like chat GPT anyone
1163:38 - used maybe you used also Google B like
1163:41 - chat GPT yes or
1163:44 - no
1163:46 - okay do you know like which model uh is
1163:49 - running in the back end of this uh U
1163:52 - Google
1163:53 - Bart the free free uh version you are
1163:56 - using Okay so this this is the model
1163:58 - actually they're using called pal
1164:03 - 2 okay so in future uh we'll also see
1164:06 - like how we can use Google pump to model
1164:07 - okay and there is another model called
1164:09 - Falcon okay Falcon has lots of variant
1164:13 - like Falcon like 7B B okay then 13B so
1164:17 - it has lots of
1164:19 - variant not only this one so there is a
1164:22 - uh GitHub actually you will get uh just
1164:24 - search for open llm okay open
1164:28 - llms so this is the
1164:31 - GitHub and here you will see all the
1164:34 - open source model are available over the
1164:36 - internet and it is already integrated
1164:39 - here see see this guy actually uh so
1164:42 - this is this is the guy so he has
1164:44 - actually uh created this repository and
1164:46 - he has actually added all the open
1164:48 - source llm here so we have let's say T5
1164:51 - and this is the release date and this is
1164:53 - the model checkpoint okay and this is
1164:55 - the paper and blog if you want to read
1164:56 - this uh like U about this model and all
1164:59 - so you can open this paper and blog you
1165:01 - can read it okay then you have ul2 so
1165:05 - this is one of the llm model then you
1165:07 - have uh uh this uh care brace GPT so
1165:11 - this is another llm model then you have
1165:13 - pathia dolly then Delight then Bloom is
1165:17 - also there stable LM Alpha okay then MTP
1165:21 - uh MPT 7B is also there then you have
1165:25 - Falcon okay see I already told you
1165:27 - Falcon is also there see llama 2 is also
1165:29 - there okay see lots of Open Source model
1165:32 - are available here okay all the open
1165:34 - source model so this is the like GitHub
1165:37 - you can go through let's say if you want
1165:38 - to learn any kinds of Open Source llm so
1165:41 - you can go through this GitHub and you
1165:43 - can read about
1165:50 - uh
1165:51 - see for object detection actually we
1165:54 - have like lots of model OKAY already
1165:57 - even see nowadays actually people are
1165:59 - also inting computer vision with these
1166:01 - kinds of large language model so both
1166:03 - can be
1166:13 - support
1166:19 - uh yes I can share the link as well in
1166:21 - the chat so this is the link you can go
1166:33 - through all
1166:40 - right okay so this is the actually
1166:43 - GitHub actually you can go through to
1166:45 - learn about open source llm so all the
1166:47 - models are listed
1166:49 - here H all right now see today actually
1166:53 - I'm going to discuss something called U
1166:56 - Lama 2 okay meta Lama 2 so this is the
1166:59 - model from the Facebook so they have
1167:01 - trained this
1167:07 - model so uh the first thing actually uh
1167:11 - uh in this session actually I'll be
1167:13 - discussing the Llama 2 so first of all I
1167:15 - will introduce Lama 2 what is Lama 2 and
1167:17 - all about then I will show you like how
1167:19 - we can execute the Lama 2 okay without
1167:22 - like Lang chain because there is a
1167:24 - library actually they have created
1167:25 - called Lama
1167:28 - CPP okay so using that Library actually
1167:31 - I will uh first of all execute the Lama
1167:34 - 2 model then I will show you like how we
1167:36 - can execute the Lama 2 model with the
1167:38 - help of langen because in future
1167:40 - whenever you will be do doing the
1167:41 - development you will be implementing any
1167:43 - kinds of projects you should uh you need
1167:44 - to use something called Lang Chen okay
1167:47 - so you also need to understand how we
1167:48 - can use Lang Chen uh with these kinds of
1167:51 - Open Source llm as well okay so both I
1167:53 - will show you and at the last I will
1167:55 - show you uh one project implementation
1167:57 - so mostly uh I will start the
1167:59 - implementation tomorrow so we are going
1168:01 - to implement one chatboard projects okay
1168:03 - and this is going to be medical
1168:04 - chatboard okay with the help of Lama 2
1168:06 - we'll be implementing end to end okay so
1168:09 - this is the complete
1168:13 - agenda now
1168:15 - if you just search like lama lama to
1168:18 - meta okay Lama to meta on Google so this
1168:21 - is the website you will
1168:22 - get uh from The Meta Ai and this is the
1168:26 - Lama 2 actually website as you can see
1168:28 - so they have already written about L 2
1168:30 - so lar 2 is nothing but it's a Next
1168:32 - Generation open source large language
1168:34 - model okay so previously it has actually
1168:37 - another version called llama 1 okay so
1168:41 - llama
1168:42 - 1 llama 1 they have uh actually
1168:44 - developed just for the research purpose
1168:46 - okay so it was not for the commercial
1168:48 - use cases so only for the internal use
1168:50 - cases actually internal research purpose
1168:52 - they created the Llama one okay but
1168:54 - later on whenever actually they saw like
1168:57 - GPD kinds of model came in the market so
1169:00 - they so they introduced something called
1169:02 - Lama 2 model okay and this is the Lama
1169:06 - 2 and they have also tell uh to like
1169:09 - Lama 2 is available for free and uh
1169:12 - research and commercial use cases both
1169:18 - and one thing actually you need to do to
1169:19 - get the
1169:21 - model uh if you want to get the model
1169:23 - then you need to get the permission from
1169:25 - The Meta AI okay this is the requirement
1169:27 - so just click on this download model
1169:30 - this button and here you just need to
1169:32 - fill some of the information like your
1169:34 - first name your last name then your date
1169:36 - of birth your email address country and
1169:38 - organization if you're working with then
1169:40 - you just need to select these are the
1169:42 - model okay then just submit the request
1169:45 - so after uh 30 to 40 minutes actually
1169:47 - they will accept the request and they
1169:48 - will give give you the access okay so
1169:51 - this is the requirement and if you're
1169:52 - not getting the access as of now okay
1169:54 - there is another alternative I will show
1169:56 - you how we can use this model okay so no
1169:59 - no need to worry so what you can do guys
1170:01 - you can open this website uh Lama to
1170:04 - meta and just apply for the permission
1170:07 - here
1170:10 - everyone okay apply for the per
1170:13 - permission
1170:16 - so let me share you the link as
1170:26 - well so guys are you doing with me can
1170:28 - you please
1170:43 - confirm
1170:48 - uh
1170:51 - hello
1170:54 - okay I already have the access okay so
1170:57 - you already have the access then no need
1170:59 - to worry about you can directly access
1171:00 - the model and one particular things
1171:03 - actually I just need to mention so
1171:05 - whenever you are applying for the
1171:06 - request okay so it will ask for the
1171:08 - email address so I I I believe actually
1171:11 - you all have something called hugging
1171:13 - face account guys yes or no hugging face
1171:15 - account maybe hugging face has been
1171:17 - discussed previous
1171:20 - session so make sure you try to use the
1171:22 - hugging face email address the email
1171:24 - address you used for the hugging
1171:27 - face okay so this email address you need
1171:30 - to give
1171:34 - here because this model are available in
1171:36 - the hugging face website so whenever you
1171:38 - will uh apply for the access they will
1171:41 - like U ask for this email address
1171:54 - all
1171:56 - right now let's discuss about this Lama
1172:00 - 2 little bit more like what they are
1172:02 - telling so if you just go below little
1172:04 - bit so this is the Lama 2 so they're
1172:06 - telling Lama 2 was trained on 40% mode
1172:08 - data than Lama 1 I already told you
1172:11 - there was another model called Lama 1
1172:13 - and what they did in Lama 2 actually
1172:15 - they train the model of with the 40%
1172:18 - more data okay 40% more data than your
1172:20 - llama 1 and it has a has like double
1172:23 - context
1172:28 - length we can download the model into
1172:31 - our local drive as well and can play
1172:33 - with right yes you can do it I will show
1172:35 - you like how we can download the model
1172:37 - all
1172:43 - right
1172:45 - okay uh now see guys llama 2 has
1172:47 - actually different variant so it has
1172:49 - actually 7 billion parameter variant so
1172:51 - this is the 7B model and it has also 13
1172:54 - billion model that means uh uh the model
1172:57 - has actually 13 billion billion
1172:58 - parameter and there is another model
1173:00 - called 7 70b okay so this is like 70
1173:04 - billion parameter so if you want to use
1173:06 - these two model you need like good
1173:08 - machine configuration and uh I'll tell
1173:11 - you like how we can use this 1B model
1173:13 - and B model as well so first of all I
1173:15 - will like tell you how we can use this
1173:17 - 13B model okay what would be the
1173:19 - approach to access this model okay I
1173:21 - can't directly load the actual model
1173:24 - because actual model you can't ever load
1173:26 - in your low configuration machine okay
1173:28 - you need some good memory some good GPU
1173:30 - there uh but I will show you one
1173:33 - alternative there we'll be using
1173:34 - something called quantized version
1173:41 - model
1173:43 - okay yeah
1173:45 - and now see guys this is The Benchmark
1173:47 - so this is the data set on this data set
1173:50 - actually they have 10 different
1173:51 - different large language model as you
1173:53 - can see M PT uh 7 me this this is the
1173:56 - model and this is the accuracy score uh
1173:59 - 26.8% and they also trained uh Falcon
1174:02 - model falcon 7 7 billion parameter model
1174:05 - and this is the accur accuracy score
1174:07 - 26.2 and they also trained on Lama 2 7 7
1174:11 - billion model okay and this is the accy
1174:13 - score
1174:14 - 45.3% now see guys the accuracy
1174:18 - Improvement okay isn't it good model
1174:21 - guys what what you can feel like see
1174:24 - llama 2 is uh claiming uh this is this
1174:27 - model is better than your GPT uh 3.5
1174:30 - turbo anyone used GPT 3.5 turbo model
1174:34 - before maybe you have
1174:43 - used
1174:47 - yes yeah so they're claiming actually uh
1174:50 - this model is better than GPT 3.5 turbo
1174:52 - okay so that's how actually they have
1174:55 - also given the Benchmark here and see
1174:57 - Lama 2 13 billion and this is the
1174:59 - accuracy and they again trained on mpt's
1175:03 - 13 billion parameter model and this is
1175:04 - the accuracy they got okay now they also
1175:08 - trained with the Falcon 14 billion
1175:10 - parameter this is the model they got
1175:13 - this accuracy they got okay 15 uh
1175:17 - 55.4% then uh this is the Lama 1 model
1175:21 - uh this is the accuracy and llama 2 7
1175:24 - billion model okay and see this is the
1175:25 - highest accuracy they got uh
1175:28 - 68.9% okay that's how they train on
1175:31 - different different data set different
1175:32 - different open source data set as you
1175:34 - can see these are the data set actually
1175:35 - data set
1175:38 - name all right and um these are actually
1175:42 - partners and supporters for this L 2
1175:44 - okay like hugging face Nvidia they're
1175:47 - Intel they are also using these are the
1175:51 - model all right now guys uh did you
1175:54 - appli for the permission um here did you
1175:57 - appli for the permission
1176:05 - everyone uh if not uh no need to worry
1176:07 - about I will show you one one
1176:09 - alternative this alternative you can
1176:10 - follow okay no need to worry
1176:13 - about
1176:19 - can we use llama 2 for translation of
1176:21 - the codes into python code find tuning
1176:24 - custom data yes you can do it okay Lama
1176:26 - 2 has different different model variant
1176:27 - I will tell
1176:29 - you even in future we'll also see how we
1176:32 - can fine tune the Lama 2 model as well
1176:35 - it is also possible on your custom
1176:39 - data even it is already included in our
1176:41 - paid courses I think you know uh that is
1176:44 - also one paid version of this course so
1176:47 - there actually we have already
1176:48 - introduced the fine tuning technique as
1177:02 - well all right so guys uh so far
1177:05 - everything is clear everything is fine
1177:07 - you can let me
1177:12 - know uh if you have any question you can
1177:15 - ask me otherwise I will uh continue with
1177:17 - the
1177:29 - session what is the name of the course
1177:32 - could you please give me the information
1177:34 - run this model over the docker key see
1177:36 - it would be also discussed okay it would
1177:37 - be also discussed Asal okay in the paid
1177:40 - courses actually we'll show the
1177:41 - deployment we'll also integrate docker
1177:44 - okay we'll also integrate cicd so
1177:46 - everything would be discussed
1177:54 - there all
1177:57 - right now see if you want to play with
1178:00 - this Lama 2 model uh as your chat GPT so
1178:03 - there is another website actually hosted
1178:05 - just search for
1178:08 - llama Lama 2.
1178:11 - a okay so now you will see something
1178:13 - called uh this website and you will see
1178:16 - it's like chat gbt like interface so let
1178:18 - me also give you the link in the
1178:24 - chat okay now here just click on the
1178:27 - setting Okay now click on the setting
1178:29 - and from the setting itself you can um
1178:32 - like select different version of The L 2
1178:34 - model okay I already told you L 2 has
1178:36 - different different version so it has 13
1178:38 - billion parameter it has 7 billion
1178:40 - parameter and it has also uh 70 billion
1178:43 - parameter okay now first of all let's
1178:45 - select this model uh this is the
1178:46 - smallest model model I will select
1178:48 - because response time would be a little
1178:49 - bit fast okay and if you want to use any
1178:52 - system prompt your custom prompt you can
1178:54 - give it so I'll keep this default Pro
1178:56 - prompt which is nothing but you are
1178:57 - helpful assistant so it will work as a
1178:59 - assistant okay you can also set the
1179:01 - temperature okay what is the temperature
1179:03 - temperature means if you uh set this
1179:06 - temperature to close to one that means
1179:07 - your model will take the risk and it
1179:09 - will give you some random output okay
1179:11 - and if it is close to zero that means
1179:13 - this model would be more strict to the
1179:15 - authentic output okay it w be taking any
1179:17 - kinds of risk so these are the parameter
1179:18 - actually you can play with all right now
1179:21 - let's say I have selected this model
1179:23 - called llama to 7B now I can chat with
1179:25 - this model okay now I'll just write
1179:28 - hello so see it is giving me the
1179:32 - response okay see it is giving me the
1179:34 - response now you can do anything now
1179:37 - let's say you are having one error okay
1179:39 - you are having one error in your code so
1179:40 - let me search for one error so so let's
1179:43 - say this is the error I was having in my
1179:46 - uh flash code so I'll copy this
1179:49 - error and I will give it here so I
1179:54 - am getting this
1180:01 - error uh can you please uh fix
1180:06 - it let's see what
1180:12 - happens
1180:15 - uh see guys this is the response uh it
1180:17 - has given sh I would be happy to fix the
1180:19 - error can you please provide more
1180:21 - context about the error you are getting
1180:23 - uh what the line uh of the code is
1180:26 - causing the error so it is also uh uh
1180:30 - like uh telling me to send some uh more
1180:34 - uh information so what I can do uh I can
1180:36 - tell I'm
1180:39 - getting I'm getting this is the
1180:42 - error
1180:48 - in
1180:49 - my flash
1180:54 - code see now uh it has given me the
1180:58 - response okay it has given me other
1181:00 - response like how to fix
1181:06 - it now you can also select different
1181:09 - version of the model from here you can
1181:11 - also play with 13 billion and 70 billion
1181:13 - it's up to
1181:16 - you guys are you able to execute this uh
1181:20 - website this l2.
1181:35 - a
1181:42 - okay
1181:44 - all
1181:52 - right okay thank you now uh let me show
1181:55 - you the GitHub repository of the Lama 2
1181:57 - as well see this is the Facebook
1181:59 - research and llama repository they have
1182:02 - created let me share you the link as
1182:09 - well uh this is the link and if you come
1182:12 - here so they have already given like
1182:14 - where this model is available everything
1182:16 - they have given so if you want to access
1182:18 - the model so this model is available on
1182:20 - the hugging face website okay just you
1182:21 - can open the hugging face and you can
1182:23 - visit the model see all the models are
1182:25 - available okay different different
1182:27 - version of the models are available and
1182:29 - what is the chat model and what is this
1182:30 - without chat model I will tell you okay
1182:32 - so there are some like uh you can say
1182:36 - difference between these are the model
1182:37 - I'll tell you okay now see guys they
1182:40 - have already mentioned here if you go
1182:42 - below um here so Lama 2 actually has two
1182:46 - different model one is like pre-end
1182:47 - model and another is like fine tune chat
1182:49 - model okay so what is the pre-end model
1182:51 - first of all you need to understand so
1182:52 - preon model is nothing but these model
1182:54 - are not for fine tune for the chat or
1182:56 - question answering okay they should be
1182:59 - uh prompted so that uh the uh expected
1183:02 - answer is the uh natural continuation of
1183:05 - the prompt so basically let's say if you
1183:07 - want to uh generate the text okay if you
1183:09 - want to generate any kinds of text from
1183:10 - the Lama to model then you to use this
1183:12 - pretend models okay from the Lama 2
1183:15 - Series and there is another model called
1183:17 - fine tune chat model what is fine tune
1183:18 - chat model fine tune chat model is
1183:20 - nothing but the fine tune models uh were
1183:22 - trained for the dialogue application to
1183:24 - get the expected features from the
1183:26 - performance from from them specific
1183:28 - formatting defined chat completion so
1183:30 - here it is telling if you want to do
1183:32 - let's say question answering system or
1183:33 - chat operation so you can use this fine
1183:35 - tune chat
1183:36 - model okay now if I visit hugging
1183:39 - hugging face again here now I think this
1183:42 - should be very much clear like whenever
1183:44 - they're defining like chat
1183:46 - model okay whenever they defining chat
1183:49 - model that means this is the model for
1183:50 - the question answer or let's say chat uh
1183:53 - I mean chat model okay and whenever you
1183:56 - won't be seeing any kind of chat model
1183:57 - that means this is for the Tex
1183:58 - generation model is it
1184:00 - clear why different difference model you
1184:02 - can see in the hugging
1184:12 - fish
1184:14 - let me know
1184:30 - guys yes one for chat another another
1184:33 - one for like uh text
1184:38 - generation
1184:42 - great
1184:46 - okay now let me close this other the
1185:00 - tab
1185:03 - H now first of all Let's uh play with
1185:06 - this model called LMA 213 billion
1185:08 - parameter model this model first of all
1185:10 - I will tell you like how we can execute
1185:11 - this model and if you have very low
1185:14 - configuration PC so what you can do in
1185:16 - this case okay first of all I will tell
1185:17 - you this one then I will show you how we
1185:19 - can execute this uh 7 billion parameter
1185:21 - model with the help of the Lang chain as
1185:24 - well both I will show
1185:26 - you so for this first of all let's try
1185:28 - on neural lab okay so if neural lab is
1185:31 - not working then I will go to the Google
1185:33 - collab so first of all I will be using
1185:35 - the quantied model and let's see whether
1185:36 - it is working or not so everyone you can
1185:39 - open your neural app so let me open so
1185:43 - so I'll loging with the
1185:54 - website so here I can take I think
1185:57 - jupyter
1186:06 - notebook repter notebook I think I can
1186:12 - take
1186:23 - so everyone can open this uh neural lab
1186:26 - with you
1186:37 - also let me Zoom this
1186:40 - screen now my screen is visible guys
1186:54 - this text is visible you can confirm me
1186:55 - in the
1187:09 - chat all
1187:12 - right
1187:14 - so let me first of all test whether I
1187:17 - have GPU here or not maybe there is no
1187:19 - GPU here how can we uh check the
1187:27 - configuration see here no need to check
1187:29 - the configuration because this is like a
1187:32 - remote server it is
1187:41 - running
1187:43 - uh okay this command is not found maybe
1187:46 - no GPU okay then I will use quantied
1187:49 - model let's see what
1187:53 - happened and also let me share the code
1187:55 - with you so what I can do I can open
1187:58 - code
1188:02 - share and I will share this link in the
1188:05 - chat so whatever code I will be writing
1188:08 - I will be just pasting here okay you can
1188:09 - get from
1188:11 - here
1188:19 - all right now first of all let me show
1188:22 - you the model actually I'm going to use
1188:24 - uh so we'll be using some quantized
1188:31 - model so this is the website of the
1188:34 - Quant model and this Quan model is
1188:36 - already available on the hugging phase
1188:37 - okay so there are different different
1188:39 - organization so they actually did the
1188:41 - quantization of the model and they
1188:43 - publish the model here okay see Lama 27b
1188:45 - model Lama 23b model chat model OKAY
1188:48 - different different models are here now
1188:51 - do you know what is quantization guys
1188:53 - anywhere here what is the quantization
1188:56 - what quantize
1188:57 - mean you can let me know in the
1189:06 - chat if you're not familiar with
1189:08 - quantization then I will give some idea
1189:10 - how this quantization works model uh
1189:12 - comparation technique yes you are right
1189:19 - uh okay now see what happens actually so
1189:22 - whenever you train your neural network
1189:24 - okay so whenever you train your neural
1189:26 - network so let me take um one just demo
1189:30 - neural network here so let's
1189:36 - say this is my
1189:41 - network
1189:53 - okay so this is my let's say Network so
1189:56 - this network will have some of the
1189:57 - weights okay let's say W1 W2 W3 and so
1190:02 - on okay so each of the uh layer will
1190:05 - have the weights okay each of the layer
1190:09 - will have the weights yes or no guys do
1190:12 - you understand understand this neural
1190:13 - network concept
1190:23 - maybe
1190:25 - yeah now see what is this weight weight
1190:28 - is nothing but it's a value okay it's a
1190:29 - number only it's a floating number so it
1190:31 - will have let's say
1190:33 - 0.36 or let's say
1190:35 - 0.46 it might be also 1.2 it might be
1190:39 - also 0.88 any kinds of number okay it
1190:41 - would be adjusted ining back propagation
1190:44 - BP all right now one thing I think you
1190:47 - already know uh whenever I'm talking
1190:51 - about data type and data size okay so
1190:53 - whenever I'm talking about character
1190:55 - character data type okay so I can take
1191:00 - uh 32 bit I can also take 64
1191:06 - bit okay character now can anybody tell
1191:09 - me uh what is the character uh let's say
1191:13 - size in the 30 32
1191:18 - bit anyone know what is the like
1191:22 - character size okay in the memory for
1191:24 - the
1191:25 - 32bit
1191:29 - anyone because whenever you will uh
1191:31 - assign these are the number it will
1191:33 - occupy the memory okay it will occupy
1191:34 - the ram so what what would be the size
1191:38 - there any anyone any idea
1191:41 - idea for kilobyte
1191:46 - uh no in 32bit actually it would be 1
1191:51 - BTE one bite
1191:53 - okay and 64bit also it would be one
1192:01 - bite and if I'm talking about
1192:04 - short okay short or you can also talk
1192:07 - about
1192:08 - string okay then in 32 bit it would be 2
1192:12 - by
1192:15 - and 64bit also it would be 2
1192:19 - by okay now if I'm talking about
1192:21 - something called
1192:23 - integer so 32 bit it would be uh 4
1192:28 - by and 64bit it would be 4
1192:33 - by okay and if I'm talking about
1192:37 - long so long means it's a floating
1192:39 - number okay it's a float you can talk
1192:41 - about so float would be uh 32 bit it
1192:43 - would be 4
1192:45 - by and 64 bit it would be 8
1192:50 - by and long long there is another data
1192:53 - type called long long long long means
1192:55 - it's a double in Python we call it
1192:56 - double okay so mostly you will see in
1193:00 - the weight initialization they will be
1193:02 - assigning the double number okay instead
1193:04 - of floating number so it would be uh in
1193:07 - the 32 bit it would be 8
1193:09 - by okay 8 bytes and 64 bit it would be
1193:12 - be 8
1193:14 - bytes okay now tell me uh which uh data
1193:18 - type is taking more space in the memory
1193:20 - U floating or
1193:22 - integer tell
1193:27 - me just reply me guys first in the
1193:30 - chat which data type is taking more
1193:33 - memory in the uh more space in the
1193:41 - memory float yes you are correct float
1193:45 - is taking more memory so now let's say
1193:47 - whenever we are training any kinds of
1193:49 - neural network so by default the weight
1193:50 - initialization or weight adjusting is
1193:53 - happening with the floating number now
1193:55 - see you can also round the floating
1193:57 - number let's say you you are having
1193:58 - these kinds of number 1.22 okay or let's
1194:01 - say 2.33 now if you just round it let's
1194:04 - say 1.22 you can make it as 1 okay and
1194:07 - 2. 32 you can make it as two now you
1194:09 - just round the number and it has become
1194:11 - in that means integer okay some data
1194:14 - loss would be happened but again you are
1194:16 - somehow trying to adjust it or let's say
1194:18 - round it to the root root number okay so
1194:21 - we call it a quantization technique so
1194:23 - basically what you are doing uh the
1194:25 - floating number you are having okay in
1194:26 - the weight you are just trying to uh
1194:28 - round it to the actual number okay you
1194:30 - are just trying to convert the floating
1194:32 - number to integer number okay now tell
1194:34 - me uh previously it was having that uh
1194:37 - floating number now it has become the
1194:38 - integer number now is there would be any
1194:41 - uh uh like changes in the
1194:48 - memory yes or
1194:52 - no okay now see memory size would be
1194:54 - reduced because of this U integer number
1194:57 - because we have done the quantization
1194:58 - technique okay so this is the
1195:00 - quantization idea basically uh you are
1195:02 - just trying to convert your floating
1195:04 - number to integer number all
1195:06 - right yes and whenever I'm talking about
1195:10 - models uh model will have l let's say
1195:12 - billion million parameter now let's say
1195:14 - if you have billion million parameter
1195:16 - and you are converting everything to the
1195:18 - integer now just think about how much
1195:20 - memory will save let's say your model
1195:22 - size is 30 GB okay your model size is 30
1195:24 - GB initially okay now after doing the
1195:27 - quantization this model will have
1195:30 - 5gb okay and we call it as quantized
1195:33 - model and this is the actual model so
1195:36 - some accuracy might be drop in this
1195:38 - model but again this model would be fast
1195:40 - and we can easily load this model in the
1195:42 - memory okay in our low configuration PC
1195:45 - got it so let's say this model needs
1195:47 - actually 16 GB Ram but after done the
1195:51 - quantization this model has become 5gb
1195:53 - now I can easily run this model in the
1195:55 - 8GB M Ram or let's say 4GB Ram it is
1195:58 - also possible got the idea
1196:09 - guys if it is clear just write clear in
1196:12 - the the chat so that so that I can
1196:14 - understand you are getting my
1196:17 - point yes performance will reduce uh but
1196:21 - we need somehow the faster inference
1196:29 - okay but quantize model is also good it
1196:32 - will give you like good
1196:41 - responses okay now there are different
1196:43 - types of actually quantization
1196:45 - techniques okay so one of them is
1196:47 - gml okay gml gml is the quantization
1196:50 - technique or quantization Library you
1196:52 - can talk about gml gml format
1196:54 - quantization there are various kinds of
1196:56 - technique but uh they have used
1196:57 - something called gml okay gml
1197:02 - quantization so today actually I'll be
1197:04 - using one gml format model quantized
1197:07 - model of that 13 billion parameter model
1197:09 - and I will show you how we can execute
1197:10 - the model
1197:14 - all right okay now let me show you the
1197:18 - model actually I'm going to use
1197:20 - [Music]
1197:27 - here so this is the model guys I will be
1197:29 - using so let me give you the
1197:37 - link so this is the link guys and L 2 13
1197:41 - billion chat okay because I want to do
1197:43 - question answering with my model that's
1197:45 - why I I'm using chat model but let's see
1197:47 - if you want to generate text guys which
1197:49 - model you will be using tell
1197:50 - me chat model or without chat
1197:59 - model no no no it is support Lama CPP I
1198:03 - I'll I'll execute and show you
1198:05 - Prashant yeah without chat uh yeah now
1198:08 - see guys this is the chat model and this
1198:09 - is the gml model and this model has
1198:12 - different different variant as well see
1198:14 - uh some of the model is like 5gb some of
1198:16 - the model is 6gb okay 7gb so different
1198:20 - different model we have so from these
1198:21 - are the model actually I'll be using one
1198:23 - particular
1198:28 - model so this is uh your quantization
1198:31 - Technique you can talk about
1198:32 - quantization Library so Library they
1198:33 - used for the quantization okay so
1198:36 - uh so zml is the one of
1198:40 - them
1198:44 - and if you see this is the dot bin that
1198:45 - means it's a binary model okay it's a
1198:47 - binary
1198:55 - representation all right now see guys uh
1198:57 - if you want to use this quantized model
1198:59 - OKAY gml version model then you need to
1199:01 - use one Library called uh Lama CPP okay
1199:05 - Lama CPP CPP okay this is the library
1199:08 - let me show
1199:09 - you um see that's how you can install
1199:13 - this Lama CPP Library so these are the
1199:16 - command you need to
1199:17 - execute so cake so this is the command
1199:20 - so it will install your Lama
1199:22 - CPP and as well as Lama CPP python you
1199:26 - need and this is the specific napai
1199:29 - version you need and as well as the
1199:31 - hugging face Hub also you need okay why
1199:32 - you need the hugging face Hub because
1199:34 - this model is available on the hugging
1199:36 - face okay and to download this model
1199:37 - from the hugging face I need this
1199:39 - hugging face Hub okay this is the
1199:40 - library now let me EX and see whether it
1199:42 - is working here or
1199:45 - not let me also give you the code in the
1199:48 - code
1199:53 - share guys you can let me know if you
1199:55 - are able to see the code in the code
1200:10 - share
1200:20 - the code is accessible guys yes or
1200:40 - no
1200:43 - uh please give me some response so that
1200:45 - I can get to
1201:03 - know
1201:06 - okay uh maybe installation is done uh
1201:10 - okay fine so you can ALS also make the
1201:14 - installation all
1201:17 - right now I will be defining the model
1201:20 - actually I'll be using okay so now let's
1201:22 - define the model
1201:24 - here
1201:30 - so okay so see guys uh this is the model
1201:34 - I'm going to use uh Lama 2 13 billion
1201:37 - chat
1201:40 - gml
1201:43 - all right see this is the model uh Lama
1201:46 - 2 13 so you just copy copy this name and
1201:50 - just give it here copy this name and
1201:52 - give it here and you also need to give
1201:55 - the Bas model name because here you can
1201:56 - see there are lots of model OKAY in
1201:58 - binary format now which particular model
1202:00 - you should be using here so I'm using
1202:02 - this model so let me copy the name and
1202:04 - searce it
1202:08 - here see I'm using this specific model
1202:11 - and this model model size is
1202:12 - 9 76 GB actually okay this is the model
1202:17 - so this model I'll be using so let me
1202:22 - execute now first of all I need to
1202:24 - import uh hugging face Hub to download
1202:27 - the model as well as I will also import
1202:29 - something called Lama CPP
1202:36 - Library okay now let's download the
1202:40 - model
1202:45 - so let me also give you the
1203:08 - code now here if you see I'm giving the
1203:11 - repo ID so this is my repo ID model name
1203:14 - or path and this is the base model I
1203:16 - want to download okay and I'm using
1203:18 - hugging face Hub to download the model
1203:20 - now let me
1203:22 - download so see it's downloading it's
1203:25 - around
1203:26 - 9.76
1203:40 - GB
1203:45 - share the link I already shared this uh
1203:47 - code shell link all the codes are
1203:49 - available here let me share it
1204:06 - again all the codes are available just
1204:08 - copy paste uh in your notebook and ex
1204:11 - Ute one by
1204:40 - one
1204:51 - so guys is it running so far everything
1204:53 - is fine without any
1205:10 - error
1205:30 - and if you check the original uh this 13
1205:32 - billion parameter model it's like huge
1205:34 - model okay you can't U download this
1205:37 - model on this neural lab so you need a
1205:40 - good uh instance there so that is why
1205:41 - actually we are using this contest
1205:53 - model almost done let's
1206:10 - see
1206:12 - okay it's done now if you want to check
1206:14 - the model path actually where it has
1206:16 - downloaded you can just uh uh see that
1206:19 - see this is the path actually it has
1206:21 - downloaded the model okay see we have
1206:24 - locally downloaded our
1206:27 - model now what I need to do I need to
1206:30 - load my model okay so to load my model I
1206:32 - will be using this Lama CPP Library okay
1206:35 - and see I'm importing from Lama CPP
1206:38 - import uh Lama now with the help of that
1206:42 - actually I will load my
1206:46 - model okay
1206:47 - see uh if you have GPU in your machine
1206:51 - then this would be quick response okay
1206:53 - otherwise maybe it will take time let's
1206:55 - see what happened on neural app because
1206:57 - in neurolab it doesn't have any
1206:59 - GPU so here is the model path I am
1207:02 - giving and these are the parameter you
1207:04 - need to give okay like uh threshold U
1207:07 - number of threshold like CPU CES you
1207:09 - want to use then number of B actually
1207:11 - you want to use okay then number of GPU
1207:14 - layers you
1207:15 - have so by default keep this number and
1207:18 - let's execute and see what
1207:23 - happened loaded internal vocab okay so
1207:26 - it has been loaded I guess let me
1207:28 - execute it
1207:30 - again it's
1207:40 - loading
1208:03 - so this is the problem with uh open
1208:05 - source llm because here it it uh it
1208:08 - needs actually some good instance okay
1208:09 - to run the model
1208:19 - okay
1208:20 - done uh there is no error okay fine now
1208:24 - what I can do let me give you the
1208:38 - code now let's uh create one Pro prom
1208:41 - template
1208:45 - here uh guys do you know what is promt
1208:48 - template
1208:50 - anyone maybe uh you already learned this
1208:53 - thing in your open a
1208:56 - discussion just give me a quick response
1208:58 - in the chat what is a prompt template
1209:01 - what is prompt do you know why we use
1209:03 - prompt in
1209:04 - llm yes okay great see here we are
1209:08 - writing one prompt here our custom
1209:10 - prompt template so here I'm just telling
1209:12 - as a prompt uh write a linear regression
1209:14 - code okay and as a system prompt I'm
1209:17 - giving you are a helpful uh and
1209:19 - respective respectful and honest
1209:21 - assistant always answer as a helpfully
1209:23 - okay then user will give you the prompt
1209:25 - and you need to provide the answer as a
1209:27 - assistant okay so this is the custom
1209:28 - prompt template I have created now let
1209:31 - me execute and give it to my model also
1209:34 - I'll paste it
1209:37 - here
1209:39 - h
1209:42 - now finally I will give this promt
1209:44 - template to my llm okay see I'm calling
1209:47 - this Lama um that means this uh Lama CPP
1209:50 - library and here I'm giving my prompt
1209:52 - template okay see this is my prompt
1209:54 - template I have created prompt template
1209:57 - as well as I'm also giving the max token
1209:59 - length okay that means maximum response
1210:01 - okay maximum tokens actually it will
1210:03 - give me as output and I'm also setting
1210:05 - the temperature okay temperature top P
1210:07 - then P penalty I think you remember if I
1210:10 - open this one
1210:13 - Lama do Lama 2. a now if I go to the
1210:16 - settings now see these are the parameter
1210:19 - you can adjust here got it guys what is
1210:22 - this parameter see temperature max token
1210:24 - top parameter okay see everything is
1210:26 - there you can um change it
1210:31 - here so by default keep this number and
1210:39 - execute
1210:49 - can you explain the
1210:51 - penalty see uh penalty like see it's a
1210:55 - parameter actually it helps to generate
1210:57 - a like you can say uh actual response
1211:00 - okay let's say if you increase and
1211:02 - decrease this parameter so what will
1211:03 - happen actually you will see your model
1211:04 - will give some random response okay or
1211:07 - let's say the response actually it is
1211:09 - not relevant to your prompt you are
1211:11 - giving so this parameter actually
1211:12 - adjustable parameter so this parameter
1211:15 - can be changes whenever you are changing
1211:17 - the temperature parameter so here
1211:19 - temperature parameter I kept as 0.5 that
1211:21 - means I'm turning to my model uh
1211:24 - sometimes just take a risk okay
1211:26 - sometimes don't take a risk okay it just
1211:27 - a uh I mean adjusted number I have given
1211:30 - now let's say if I'm increasing the
1211:32 - temperature value let's say close to one
1211:34 - so what will happen my model will be
1211:36 - taking risk okay let's say if I'm giving
1211:38 - any kinds of prompt and if if it doesn't
1211:40 - know anything it will give risk and it
1211:42 - will generate some random response as
1211:44 - well which can be correct which can be
1211:45 - wrong as well okay and if you decrease
1211:47 - this parameter close to zero so what
1211:50 - will happen your model won't be taking
1211:51 - any risk it will only give the authentic
1211:53 - response you are expecting from your
1211:54 - model okay so these are the parameter
1211:56 - can be changed all
1212:07 - together see again it is running on CPU
1212:10 - machine that's why respond time little
1212:11 - bit High here and again we are using 13
1212:14 - billion parameter model so that's why if
1212:16 - you're taking 7 billion parameter model
1212:18 - so respond time would be a little bit
1212:23 - less so let me give you the code as
1212:39 - well
1212:46 - so it's still running let's wait for
1212:48 - some
1213:08 - times if anyone get getting response so
1213:11 - you can let me know whether response
1213:15 - uh unable to run in neural
1213:18 - lab um see I think I'm able to run it's
1213:21 - working for me so
1213:25 - far so if you're not able to run in
1213:27 - neural Labs what you can do you can open
1213:29 - Google collab Iman okay and there
1213:30 - actually you can execute
1213:34 - maybe the same code you can copy paste
1213:36 - there and make sure you selected GPU
1213:39 - there
1214:22 - it's taking time a lot guys so side by
1214:24 - side what I can do I can also show you
1214:26 - the collab
1214:29 - execution because I don't know how much
1214:31 - it will
1214:34 - take I already have the notebook ready
1214:36 - so let me just show
1214:39 - you
1214:41 - I'll share it with
1214:55 - you so let me
1215:09 - connect
1215:13 - still running on NE lab
1215:24 - okay so here I got the GPU Tesla T4 this
1215:27 - is the free version GPU and let me
1215:30 - install the
1215:39 - libraries
1216:08 - guys if it is taking time for you in La
1216:10 - so you can execute on Google collab I
1216:12 - think it you will get quick response
1216:16 - there because again I need to cover that
1216:19 - uh langen part so it will take
1216:39 - time
1217:43 - okay done now let me quickly execute
1217:45 - because I already explained these are
1217:46 - the code how it is
1218:09 - working
1219:17 - okay now let's load the
1219:39 - model
1219:57 - okay now if you want to check the GPU
1219:59 - layers so you can check it out so I have
1220:01 - 32 layers in my GPU and here is my
1220:04 - custom prom template and now let's uh
1220:08 - execute my llm and let's wait for the
1220:38 - response
1221:19 - okay done now this is the response I got
1221:22 - now if you want to see the actual
1221:23 - response so you need to uh call this one
1221:27 - like Choice then I want to take the
1221:30 - first uh list and this is the text okay
1221:32 - it will give you now see it is telling
1221:34 - uh I would be happy to help with that
1221:36 - however I want to make sure we have the
1221:38 - same understanding on the linear
1221:39 - regression
1221:40 - okay so basically if you're executing
1221:42 - for the first time so it will give you
1221:43 - this response okay now if you want to
1221:45 - get the actual response then again you
1221:46 - need to execute the same
1222:08 - code
1223:09 - so it's better better to use a 7 billion
1223:11 - version model because it will give you
1223:13 - quick response um than this 13 billion
1223:28 - one so guys are you able to execute the
1223:31 - code I shared with you this
1223:38 - notebook
1223:43 - okay done now this is the response and
1223:46 - this is my final response now see uh is
1223:49 - it correct code can anybody tell me uh I
1223:52 - told my model to generate linear
1223:54 - regression code for me now just see the
1223:57 - code and tell
1224:04 - me just give me quick response guys in
1224:06 - the
1224:08 - chat
1224:14 - yeah so for this we need to use some
1224:16 - smallest version of the model okay
1224:17 - because if you don't have good
1224:19 - configuration PC then this is the only
1224:21 - option
1224:26 - SAS all right now is it is it correct
1224:29 - code just give me a quick
1224:38 - response
1224:40 - okay great now see you can ask any kinds
1224:43 - of question okay like your chat GPT or
1224:45 - what you have done so far okay now see
1224:48 - without any cost we are able to also uh
1224:51 - use these kinds of large language model
1224:53 - okay yeah now you don't need to pay for
1224:56 - anything if you don't have money okay if
1224:58 - you don't want to buy open AI so it's
1225:00 - completely fine you have different
1225:01 - different uh large language model open
1225:03 - source large language model you can use
1225:05 - them for your development and tomorrow
1225:07 - I'll be discussing one particular
1225:09 - projects then it would be clear like how
1225:10 - we can Implement any kinds of projects
1225:12 - with respect to that okay yeah so this
1225:15 - is uh the implementation of Lama 2 uh
1225:18 - using the Lama CPP library now I'll show
1225:21 - you how we can do it with the help of
1225:22 - Lang chin because going forward all the
1225:24 - application will be uh like uh
1225:26 - developing with the help of Lin okay so
1225:29 - first of all let me uh stop that uh
1225:33 - instance I have
1225:38 - opened
1225:45 - okay
1225:53 - now all
1226:00 - right so can we try this free llm
1226:03 - instead open Ai and make a uh practice
1226:06 - with the Lang yes you can do it I will
1226:07 - show you how to use uh with the l
1226:10 - okay I'll show you everything would be
1226:13 - cleared so see the same thing you need
1226:15 - to do as of now you have done with the
1226:17 - open AI only you just need to import
1226:19 - this large language model open source
1226:21 - large language model okay then you need
1226:22 - to use that as llm that's it okay
1226:29 - yeah all right now this code is working
1226:32 - fine guys everyone are you able to get
1226:34 - the
1226:36 - response just uh give me a confirmation
1226:38 - then I think I should start with the
1226:40 - langen one if it is running fine for
1226:54 - you just give me a quick
1227:08 - response
1227:14 - okay now let's see the Lang chain one so
1227:17 - let me uh share you with this
1227:21 - code so here I'm going to use the actual
1227:24 - model OKAY actual model not the
1227:25 - quantized model and I'll be using 7
1227:28 - billion parameter model and let's see
1227:30 - how we can use it so this is the code
1227:32 - actually you can
1227:38 - refer
1227:40 - yeah so here actually GPU is required
1227:42 - okay GPU is
1227:44 - required now first of all let me connect
1227:47 - the
1228:08 - notbook
1228:12 - all right now if you want to check the
1228:14 - GPU you got or not so this is the
1228:16 - command so here again I got Tesla T4 GPU
1228:19 - then I need to install some of the
1228:20 - libraries here okay so first thing I
1228:22 - need something called Transformers okay
1228:24 - why I need to install Transformers
1228:25 - because uh this model is available on
1228:28 - the hugging face okay if you see here
1228:30 - and I'll be using hugging face pipeline
1228:32 - here to load the model that's why sorry
1228:34 - not this
1228:36 - one I think just just let me open this
1228:42 - one yeah so I have the model
1228:45 - here
1228:47 - H so see this is the model on hugging F
1228:50 - and I will be loading this model with
1228:52 - the help of hugging fist pipeline okay
1228:54 - so that's why this Transformer library
1228:56 - is required then these are the like
1228:58 - dependency you need with the this
1229:00 - Transformer then I I'm also installing
1229:02 - something called Lang chain okay then
1229:04 - bits and bu and accelerate you need you
1229:06 - don't you need to install for this
1229:08 - Transformer now let me install
1229:29 - them uh link I think I have already
1229:31 - given just just a
1229:38 - minute
1229:51 - uh link would be shared just a
1229:59 - minute okay then I need to loging with
1230:02 - my hugging face okay to loging with the
1230:04 - hugging face this is the command hugging
1230:06 - face uh CLI login okay you need to do it
1230:09 - it now let me execute now it will ask
1230:11 - for the uh token okay secret token yeah
1230:16 - so you can take time now how to generate
1230:18 - this secret token just go to your
1230:20 - hugging Fish account let me open my
1230:22 - hugging Fish
1230:26 - account hugging
1230:28 - face now here just click on the profile
1230:31 - and click on the settings okay and here
1230:34 - you will get something called access
1230:35 - tokens now click on the access tokens
1230:37 - now here I already have some of the
1230:39 - token so what I will do I will uh remove
1230:41 - one of the token from here so let me
1230:43 - delete
1230:45 - it okay now I'll generate a new tokens
1230:48 - so you can also generate a new tokens so
1230:50 - give the name I'll give
1230:54 - Lama and I will give only read access
1230:57 - because I I only want to read the model
1230:59 - okay not I I don't want to upload
1231:01 - anything that's why read is fine now
1231:02 - generate the tokens now this is my Lama
1231:05 - uh tokens now I'll copy it so you need
1231:08 - to generate your own token guys don't
1231:10 - use my token I'll remove it after
1231:12 - sometimes now here I can give the token
1231:16 - and press
1231:19 - enter now here just give yes and press
1231:24 - enter done login successful now first of
1231:28 - all I need to import something called
1231:29 - hugging face pipeline because I already
1231:31 - told you with the help of hugging F
1231:33 - pipeline I need to uh like uh load the
1231:36 - Llama 2 model okay now let me uh first
1231:38 - of all imported from the langen see len.
1231:41 - llms I'm importing hugging face pipeline
1231:45 - okay now if you're using openi model U I
1231:48 - think you remember you you used to
1231:49 - import something like that uh from
1231:51 - langen llm import openi yes or
1231:56 - no can you can you recall that concept
1231:58 - you learn in your openi so only
1232:01 - difference would be like
1232:07 - that
1232:11 - now I also uh need to import tokenizer
1232:14 - okay why I need to import tokenizer
1232:19 - because yeah so link just a
1232:37 - minute so link I will add in this
1232:41 - uh code share okay see this is the link
1232:44 - I have added at the last so you can copy
1232:45 - from
1232:58 - here now why tokenizer is required Auto
1233:01 - tokenizer so whenever you will be giving
1233:03 - uh the input to your llm so it would be
1233:05 - a raw text okay but um see Auto
1233:09 - tokenizer what it does actually it will
1233:11 - take the raw text and it will clean up
1233:12 - first of all it will do the
1233:13 - pre-processing some of the preprocessing
1233:15 - let's say if you if it is have some
1233:16 - kinds of HTML tags and all it will
1233:18 - remove then it will convert that uh uh
1233:21 - like text to numbers okay automatically
1233:23 - it would be converted using this Auto
1233:25 - tokenizer okay Auto tokenizer class so I
1233:27 - I need to import that I also need to
1233:29 - import something called Transformers and
1233:31 - torch and I will also import this
1233:35 - warnings done now first of all I need to
1233:39 - load the model okay I need to load the
1233:40 - model now see guys here one thing you
1233:43 - need to remember so I'm using this
1233:45 - particular model let me show you so if I
1233:47 - open this model on the hugging
1233:49 - face so this is the model I'm using and
1233:52 - this model is from meta Lama if you see
1233:55 - here I'm not using any quantized model
1233:56 - this is the actual model and see I
1233:58 - already have the permission here okay I
1234:00 - already have the permission you have
1234:02 - been granted access to this model but
1234:04 - for you this this will come like that
1234:06 - let me show you so if I open my en Cito
1234:09 - window and if I go to this link uh you
1234:13 - will see this window guys can you can
1234:15 - you see that can you check from your
1234:17 - computer whether you are getting this
1234:18 - one or not access Lama to on hugging P
1234:20 - then you need to submit some form here
1234:22 - you need to sign
1234:24 - up just give me a quick
1234:37 - response
1234:39 - uh can you see this window
1235:04 - guys okay so if you're getting this
1235:06 - windows so what you need to do you need
1235:07 - to log in okay you need to log login and
1235:09 - submit that information I already told
1235:11 - you so if you visit that one meta Lama 2
1235:17 - Meta Meta Lama
1235:21 - 2 sorry it would be llama 2 now here you
1235:25 - will get this this window okay here you
1235:28 - need to submit your information and
1235:30 - maybe if you have submitted for the
1235:32 - first time uh initially I showed you
1235:34 - then it's completely fine and make sure
1235:35 - the email address you are giving the
1235:37 - same email address you are using for the
1235:38 - hugging face okay now see I already have
1235:40 - the access uh to this model to The Meta
1235:44 - this organization that's why I can
1235:46 - access these are the model now see after
1235:48 - some times let's say 40 to 50 minutes
1235:52 - you will get one notification okay in
1235:54 - your email so it will be looking like
1235:56 - that let's say your name this let you
1235:59 - know that your request uh access to this
1236:01 - model has been accepted by the repo
1236:03 - author okay so once you got this mail
1236:05 - that means you would be able to access
1236:07 - this model okay then you will able to to
1236:08 - see you have the uh you you have been
1236:11 - granted to the access to the model okay
1236:13 - you will get this notification then you
1236:15 - will be able to use the official version
1236:17 - of the model and if you're are not
1236:19 - getting the access as of now so what you
1236:21 - can do you can activate this line of
1236:23 - code and you can comment this line of
1236:24 - code okay see this is another uh
1236:28 - organization that means another guy he
1236:30 - has cloned this meta model okay that
1236:32 - means this model and he has already
1236:34 - published this model from his
1236:36 - organization that means from his
1236:37 - Repository and this is completely public
1236:40 - okay you can easily download the model
1236:41 - no need any permission okay so this is
1236:44 - the alternative way to use the
1236:46 - model okay so I already have the
1236:49 - permission so I will use the official
1236:51 - model I will just comment this line but
1236:53 - if you don't have the access you can
1236:55 - uncomment this line and comment this
1236:56 - line it's up to you now let me
1237:02 - execute now first of all I need to load
1237:04 - my tokenizer okay uh so tokenizer will
1237:07 - use the same name to load the token
1237:08 - tokenizer okay now let me load the
1237:13 - tokenizer loaded now here I need to
1237:16 - create the pipeline hugging face
1237:18 - pipeline so what is the hugging face
1237:20 - pipeline see um how this hugging face
1237:23 - pipeline will work so let's
1237:24 - say uh this is your
1237:28 - model or let's say this is your pipeline
1237:31 - this is your pipeline object you have
1237:35 - created and this is the input you are
1237:37 - giving input
1237:41 - text input text okay so it will give you
1237:44 - the
1237:47 - response so in pipeline what will happen
1237:50 - so first of all it will uh apply some
1237:53 - pre-processing apply
1237:58 - pre-processing pre-processing okay with
1238:01 - the help of uh Auto
1238:06 - tokenizer auto toen
1238:09 - ner okay then second what it will do it
1238:13 - will uh convert that number okay that
1238:16 - means a text would be converted to
1238:19 - numbers that means Vector okay then this
1238:22 - Vector would be passed to my
1238:25 - model okay then prediction would be
1238:30 - happened then fourth it will give you
1238:32 - the
1238:34 - response okay so this is the pipeline
1238:36 - task actually so this is the pipeline
1238:38 - they have created so you don't need to
1238:40 - take care these are the task
1238:42 - automatically it would be done okay you
1238:43 - just need to create this pipeline
1238:45 - objects now here I already imported
1238:47 - Transformers you remember and here I'm
1238:49 - just calling the pipeline and here you
1238:51 - need to give the name so here I'm
1238:53 - performing Tech generation okay that's
1238:55 - why I'm giving Tech generation because
1238:56 - if you see the model it's a TCH
1238:58 - generation model okay although it's a
1239:00 - chat model but it's a tech generation
1239:02 - model let me show you the model card if
1239:04 - you see it's a TCH generation model okay
1239:06 - this is the key you need to give so here
1239:08 - here I already given the name Tech
1239:09 - generation now here I given the model so
1239:12 - this is the model I given and I also
1239:14 - given the tokenizer I downloaded now
1239:16 - these are the default parameter you need
1239:18 - to give okay no need to change anything
1239:19 - the default parameter you need to give
1239:21 - now let me load my pipeline now see if
1239:24 - this model is not available first of all
1239:25 - it will download the model from the
1239:27 - hugging P so it's downloading the
1239:37 - model
1240:03 - anyone doing with me
1240:07 - guys
1240:10 - so which one you are using the official
1240:12 - one or this alternative
1240:33 - one alternative one okay
1240:37 - great
1240:40 - so you can wait after applying this uh
1240:42 - uh like you can say access permission
1240:44 - you can wait for uh like 40 to 50
1240:46 - minutes or let's say 1 hour you will get
1240:49 - the email definitely you will get the
1240:51 - email then you can use the official
1240:59 - one because in the hugging pH what
1241:01 - happens actually um some of the
1241:04 - organization uh will have their private
1241:06 - repository okay and if you want to
1241:07 - access the private repository you need
1241:10 - the access from the author okay
1241:11 - otherwise you can't use their model and
1241:13 - all okay they will be uploading that's
1241:16 - why we need to apply for the permission
1241:17 - but most of the repository you will see
1241:19 - it's public okay you don't need any
1241:21 - permission but this is the meta
1241:23 - organization that's why maybe they have
1241:24 - uh given you that one maybe they want to
1241:28 - uh take your information okay because
1241:30 - whenever you are submitting the this
1241:32 - request form uh they are having your
1241:34 - name email address which organization
1241:36 - you are working on so that they they
1241:37 - will send you some mail regarding their
1241:40 - product okay maybe this is the things
1241:42 - they have
1241:55 - developed see model has been downloaded
1241:58 - now see guys this is the magic Now using
1242:00 - hugging face pipeline you can easily
1242:03 - create your llm see now as a pipeline I
1242:06 - need to give this pipeline objects okay
1242:08 - and this pipeline object is nothing but
1242:09 - my entire uh Auto tokenizer and my model
1242:12 - okay everything it is there now model uh
1242:15 - you need to give some argument so what
1242:17 - is the argument argument means the
1242:18 - temperature okay the temperature value
1242:20 - so we always give the temperature value
1242:22 - because I want uh my model like how it
1242:24 - will give me the response and all so as
1242:26 - of now I just set this temperature as
1242:28 - zero because I am telling to my model
1242:30 - don't give any random output just stick
1242:32 - to the response you are giving okay now
1242:35 - see guys this is the llm I have
1242:36 - developed now see those who have used
1242:38 - open a maybe you just used open a here
1242:40 - okay instead of llm like that maybe used
1242:43 - like that so
1242:45 - llm equal to open
1242:49 - AI okay and here you you used model name
1242:52 - let's say
1242:54 - GPT uh GPT
1242:58 - 3.
1243:00 - 3.5
1243:02 - turbo yes or
1243:06 - no
1243:08 - please tell me got the difference uh how
1243:12 - to use open open Ai and how to use open
1243:15 - source
1243:18 - one please give me give me a
1243:21 - confirmation in the
1243:35 - chat guys I can't see any response so
1243:37 - please response
1243:49 - me okay now let me uh remove this line
1243:54 - and let me open uh load my
1243:56 - llm
1243:58 - okay okay now uh what I need to do I
1244:02 - need to uh give my prompt okay so first
1244:04 - of all I will be giving the prompt like
1244:06 - that okay in just one shot so here I'm
1244:08 - giving one prompt so what would be the
1244:10 - good name for a company that makes
1244:12 - colorful socks okay so this is the
1244:13 - prompt I have given to my llm now let's
1244:16 - see what is the response it will
1244:21 - generate see 7me model is also very good
1244:24 - model me I personally use this model a
1244:26 - lot so you will see it will give you
1244:29 - like very good
1244:30 - answer and it's not a quantized model
1244:33 - okay we are using the actual
1244:36 - model
1244:48 - see this is the response okay now it has
1244:50 - given me uh some company name a good
1244:53 - name for the company that makes colorful
1244:55 - socks could be something playful and
1244:57 - crashy uh now see this is the company uh
1245:01 - uh sock
1245:02 - tastic and then toys on fire color of
1245:06 - fista then soulmates uh stre socks Hue
1245:11 - and cry uh socktopia and souls uh
1245:17 - session okay so these are the company
1245:19 - you can use uh let's say if you are like
1245:22 - stablishing any company so you can use
1245:24 - this name this is a unique name
1245:27 - actually now let's uh give another P so
1245:30 - here I have given another P here I'm
1245:32 - telling I want to open a restaurant for
1245:34 - Indian food suggest me uh some fence
1245:37 - name for this okay now let's see what is
1245:39 - the name it will give
1246:06 - me
1246:09 - okay see uh it has given me so many name
1246:12 - so tanduri kns spice route Mumbai street
1246:16 - food uh then uh Rajasthani Royal then uh
1246:21 - Tikka tandur Nan shop Biryani bazer
1246:24 - Masala am menion and
1246:27 - dosen it's taking more time to give the
1246:30 - response yeah definitely it will give
1246:32 - some time because we are using the
1246:33 - actual model not a quantised model okay
1246:36 - now isn't it good response guys what you
1246:37 - feel
1246:45 - like tell me isn't it good
1247:06 - response
1247:10 - okay now you can also uh create your
1247:12 - prompt templates okay now here I have
1247:14 - given the prompt directly now you can
1247:16 - also create your own prom templates okay
1247:17 - it is also possible so to create the
1247:19 - prom templates you need to import the
1247:21 - prom template from langen and langen I
1247:23 - think it is already discussed like what
1247:25 - is prompt templates what is prompt okay
1247:27 - uh everything actually uh uh we we have
1247:30 - already seen in the langin so that is
1247:32 - what actually I'm using we are not
1247:34 - playing right so we have to
1247:39 - compromise yeah now let's uh import this
1247:43 - prom template and this llm chain okay
1247:46 - why I need llm chain because if you want
1247:48 - to add your custom prom templates you
1247:50 - need this llm chain okay with the help
1247:51 - of llm chain you will combine your llm
1247:54 - and your prom template together okay
1247:55 - then you can execute now see the first
1247:58 - prom template I have developed this is
1247:59 - the first prom template and this is the
1248:01 - prom template and input variable is kins
1248:04 - okay now instead of giving the template
1248:06 - okay in one chance I'm just I will give
1248:08 - the name I'll give the cuine name and it
1248:11 - will automatically take take the prom
1248:12 - template from from here okay now see how
1248:15 - it will work now if I execute it now see
1248:17 - if I do format operation and give the
1248:19 - kuin equal to Indian now see this is the
1248:22 - prompt it will give me okay I want to
1248:24 - open a Resturant for the Indian food see
1248:26 - automatically it has taken the input
1248:28 - okay now this is another prompt I have
1248:31 - developed uh provide me a concise
1248:34 - summary for the book name okay now book
1248:37 - name us will give that okay instead of
1248:39 - giving the whole template user will only
1248:40 - give the Boog name and it will take the
1248:42 - entire prompt now see this is the entire
1248:45 - prompt it will make like
1248:46 - that okay provide me a uh concise
1248:49 - summary of the book of Alchemist see
1248:52 - user is giving Alchemist and Alchemist
1248:53 - will come here now I will execute my
1248:56 - final Chen now see I'm calling my llm
1249:00 - Chen and here llm is equal to G I'm
1249:01 - giving my llm which I already created
1249:04 - here this is my llm I think you remember
1249:07 - and as well as I'm also giving my prompt
1249:09 - template see prompt is equal to my
1249:10 - prompt template so let's take the first
1249:12 - prompt template first of all so I'll
1249:14 - take this prompt
1249:18 - template okay and baros is equal to true
1249:21 - that means if you want to see the output
1249:23 - as well like what is happening so you
1249:25 - can give it as true otherwise you can
1249:26 - keep it as false now let's give the uh
1249:29 - prompt here so this is prompt template
1249:31 - one means I want for the uh food purpose
1249:35 - okay that means cuisin so let me give
1249:36 - the cuisin name so I'll
1249:41 - Indian now let's
1249:48 - execute fcy Resturant thank you for
1249:51 - Advance help best
1249:52 - regard okay let me
1250:06 - again
1250:23 - now see first of all it will uh like
1250:25 - make the prompt now see it will give
1250:27 - give give you the response now see the
1250:30 - response you got now let's say I want to
1250:31 - use the prom template to so I'll copy
1250:34 - the name and here I will give it and
1250:36 - this is for the summarized book okay now
1250:38 - here you can give any kinds of book
1250:40 - let's give Harry
1251:06 - Potter
1251:42 - okay done now here is the uh Harry
1251:46 - Potter uh you can see this is the
1251:48 - summary okay like what is the Harry
1251:50 - Potter book and all about so it will
1251:51 - give you the entire summary okay so
1251:54 - that's how actually you can use this
1251:55 - open source large language model okay
1251:58 - now you can try with different different
1251:59 - variant so if you if you can visit here
1252:02 - let me
1252:04 - visit maybe this is the page
1252:09 - see you have still lots of model you can
1252:11 - explore okay uh side by
1252:15 - side now I believe guys you are able to
1252:18 - understand like how to use open source
1252:21 - large language model yes or no so
1252:23 - tomorrow we are uh going to implement
1252:25 - one particular projects called medical
1252:27 - chatbot then I will show you how we can
1252:30 - uh execute on the CPU machine as
1252:36 - well
1252:38 - so guys everything is clear give me a
1252:40 - confirmation because we are done with
1252:42 - the
1252:52 - session and one particular things
1252:54 - actually uh you need to download for
1252:56 - tomorrow so let me show
1253:01 - you
1253:02 - because we need this thing
1253:06 - actually
1253:09 - so this is the model actually I'm going
1253:10 - to use tomorrow for the medical chatbot
1253:15 - implementation so this model just try to
1253:17 - download and keep it with you so I'll be
1253:19 - using Lamas to 7B chat model gml again I
1253:23 - will be using quanti model and from
1253:28 - here and see this is the model you need
1253:31 - to download so let me give you the link
1253:33 - so copy link address so everyone you
1253:35 - need to download this model and keep it
1253:37 - with you okay so tomorrow this model is
1253:40 - required I have shared the link so maybe
1253:43 - you can get the link from here and you
1253:45 - can download the model and it's around
1253:47 - uh 3.79 GB you need to download this
1253:50 - model no tomorrow is not a last uh class
1253:53 - okay still some of the session would be
1253:55 - there so link is there in the chat guys
1253:57 - so you need to download this model and
1253:59 - keep it with you okay because this uh
1254:02 - download will take time so just try to
1254:04 - download this model and keep it with you
1254:12 - so uh how how was the session guys are
1254:15 - you able to understand
1254:16 - everything about this open source large
1254:18 - language model and
1254:20 - all and I already shared all the code
1254:23 - and everything so you can execute from
1254:24 - your
1254:28 - site if yes then let's uh I think end
1254:31 - the session I have done with the
1254:34 - discussion okay uh so let's start with
1254:37 - our session guys uh so today actually I
1254:39 - was uh telling I will be showing you one
1254:41 - project implementation so the project
1254:43 - name is n2n medical chatbot
1254:46 - yes and here I will try to integrate all
1254:49 - of the like technology you have learned
1254:51 - so far let's say Lang chain uh Vector
1254:53 - database okay then I will also use like
1254:55 - lama lama 2 model yesterday I think I
1254:58 - was discussing Lama 2 how we can execute
1255:00 - and all okay so we'll be combining this
1255:02 - thing uh together and we'll be
1255:04 - implementing this amazing projects so
1255:06 - mostly uh today actually I will show you
1255:08 - the notebook experiment okay and
1255:10 - tomorrow I will show you uh the web app
1255:13 - implementation at the modular coding
1255:14 - implementation okay so today I'll be
1255:16 - discussing the architecture overview and
1255:18 - all and I will show you the notebook
1255:20 - experiment like how we can develop this
1255:22 - thing uh in our jupyter notebook because
1255:24 - I know like most of you are like already
1255:27 - familiar with jupyter notebook
1255:28 - implementation I'll uh try to show you
1255:31 - after implementing the projects on the
1255:33 - jupyter notebook how we can convert to
1255:35 - our modular coding okay so that should
1255:37 - be our main
1255:40 - objective so are you ready guys if you
1255:43 - are ready just uh give me a quick yes in
1255:45 - the chat so that I can start with the
1255:52 - session okay thank you thank you
1255:59 - everyone all
1256:05 - right
1256:11 - uh so first of all uh let me uh tell you
1256:14 - the technology and the architecture
1256:16 - actually I'm going to uh use in this
1256:18 - projects uh then the implementation
1256:20 - would be clear in your mind uh because
1256:23 - uh I always like to discuss the
1256:26 - architecture at the very first before
1256:27 - implementing any kinds of projects okay
1256:29 - so it makes me like uh to discuss the
1256:32 - projects in a very easy way okay so
1256:34 - let's do the architecture discussion at
1256:36 - the very first
1256:39 - all
1256:40 - right um guys my screen is visible uh
1256:44 - can you see that Blackboard and all you
1256:47 - can let me know or should I zoom a
1256:49 - little
1256:58 - bit okay
1257:01 - great all right now uh let's discuss
1257:04 - with the architecture uh
1257:07 - overview so the projects actually I'm
1257:10 - going to implement called uh
1257:17 - medical
1257:22 - chatbot okay so here what is our idea so
1257:26 - the first thing actually see uh the uh
1257:28 - chatbot actually I'm going to implement
1257:30 - so this would be only uh let's say
1257:32 - depends upon our custom data okay the
1257:34 - data actually I will show to my bot it
1257:36 - will only give me the response uh with
1257:38 - respect to that okay you can also like U
1257:41 - integrate like U um all over the
1257:43 - internet data it is also possible but uh
1257:47 - first of all I want to show you let's
1257:48 - say if you have some specific data if
1257:50 - you have some specific let's say domain
1257:52 - like that data how to connect okay with
1257:54 - your Bot because we have seen like the
1257:56 - chatbot implementation U like with the
1257:59 - all over the data available in the
1258:01 - Internet it's completely fine but we
1258:03 - haven't seen like how to use our custom
1258:05 - data okay so that is the main thing here
1258:07 - so that's why uh so the first thing what
1258:09 - I need to do in the data injetion part
1258:12 - uh I'll be using my own component here
1258:14 - okay so there actually I'm going to
1258:15 - write one component called Data inje or
1258:18 - you can talk about data integration so
1258:20 - here you can use any kinds of data so
1258:22 - here in this case I'm going to use
1258:24 - something called PDF file okay PDF
1258:27 - file PDF files so in this case actually
1258:31 - what kinds of PDF PDF file actually I'll
1258:33 - be using so I'll be using something
1258:34 - called Medical
1258:38 - medical
1258:41 - book medical
1258:43 - books okay so let me just show you the
1258:46 - PDF actually I'm going to use here uh I
1258:50 - will also give the PDF um no need to
1258:53 - worries about so see guys this is the
1258:55 - book actually I'm going to use so the
1258:57 - book name is the G enyclopedia of
1259:01 - medicine okay so this is one of the
1259:03 - Great Book actually I found in the
1259:04 - internet it has actually
1259:07 - 637 pages and this book has been
1259:10 - discussed all the disease with respect
1259:12 - to the medicine as well okay if you go
1259:14 - through this book so I was just going
1259:15 - through the book and I was just checking
1259:17 - what are the contents actually they have
1259:18 - given see all kinds of disease actually
1259:21 - they have mentioned with respect to the
1259:22 - disease actually they have also given
1259:24 - the medicine okay you need to use so
1259:26 - this kinds of data actually I will give
1259:28 - to my llm and I will teach my llm like
1259:31 - uh this is my data okay and these are
1259:33 - the disease with respect to that these
1259:34 - are actually my let's say medicine okay
1259:37 - so if user is asking any kinds of
1259:38 - question with respect to that you should
1259:40 - give the response okay so this is the
1259:42 - data guys so I'll will share this PDF
1259:45 - with you so you can open it up and you
1259:47 - can go through okay you can go through
1259:49 - like what are the disase actually it has
1259:50 - discussed what are the medicine it has
1259:51 - discussed uh okay everything uh you will
1259:54 - get from
1259:55 - here all right so this is going to be my
1259:58 - data source here okay so the first
1260:00 - component actually I'm going to
1260:01 - implement which is nothing but my data
1260:04 - integration all right so after after
1260:07 - like uh data integration what I need to
1260:09 - do because it's a PDF file okay it's a
1260:11 - PDF file I just need to extract those
1260:13 - data okay if I'm not extracting the data
1260:15 - then how we will give to my model right
1260:17 - so that is why the second thing what I
1260:19 - need to do I need to extract the data so
1260:22 - here I'm going to write another
1260:25 - component and I will just name it as
1260:31 - extract extract uh
1260:34 - data or you can also tell
1260:38 - content okay content so this is going to
1260:41 - be my second component now after
1260:43 - extracting the data what I need to do
1260:45 - okay I need to create a chunks okay so
1260:47 - let me just draw it here so what I will
1260:50 - do
1260:50 - here I will create different different
1260:53 - chunks okay why this chunks is important
1260:55 - I will tell
1260:58 - you yeah so here I'm going to
1261:02 - create text
1261:05 - chunks
1261:07 - text chunks okay so let me just copy
1261:11 - this
1261:30 - component okay so this is my Tex chunks
1261:33 - okay now let me uh discuss what is this
1261:35 - test CHS okay why I exactly need that so
1261:38 - for this what I can do uh let's uh copy
1261:41 - some of the content from this book so
1261:43 - let's copy from
1261:44 - here um let's say I will copy this
1261:47 - content from
1261:48 - here I'll copy let's copy this
1261:53 - part I'll copy now I'll just paste this
1261:57 - content
1261:59 - here okay so let's say this is my
1262:05 - data
1262:10 - so let's say this is my data so let's
1262:12 - say this is my entire book data I
1262:15 - collected okay I extracted from my PDF
1262:17 - book so this is my uh Corpus okay you
1262:20 - can call it this is a
1262:22 - corpus Corpus Corpus Corpus means your
1262:25 - entire data okay you have currently but
1262:28 - why we are creating the chunks okay so
1262:30 - to understand this one first of all I
1262:32 - will show you so if you search open a
1262:34 - models okay let's give you the like demo
1262:38 - with the open a only so I'll just search
1262:39 - open AI
1262:42 - model okay if I search it now we will
1262:45 - get one page
1262:47 - here now let me Zoom a little bit yeah
1262:50 - now let's say these are uh these are the
1262:52 - model are available okay here these are
1262:54 - the model are available now let's say
1262:55 - you want to use this GPT 3.5 okay if I
1262:58 - click on this model now here you will
1263:00 - see something called this model and this
1263:02 - model description and the context window
1263:05 - okay what is this context window cont
1263:07 - context window is nothing but it's just
1263:09 - a input token size okay so like how many
1263:12 - tokens this model can accept Okay at a
1263:13 - time as a input so this is the input
1263:16 - token now let's say if you're using GPT
1263:18 - 3.5 turbo okay so this is the tokens
1263:20 - okay this is the tokens like
1263:22 - 4,096 tokens it can take as a input okay
1263:26 - now here in this case I I'm using
1263:28 - something called Lama 2 model OKAY the
1263:31 - model actually I'm going to use called
1263:32 - Lama 2
1263:33 - model llama 2 model and uh this model
1263:38 - actually uh has the Contex size that
1263:40 - means the input tokens uh is nothing but
1263:44 - 496 okay token
1263:46 - limit token limit okay but if you see in
1263:51 - this entire PDF okay if I extract the
1263:53 - data okay if I'm extracting the data
1263:55 - from this entire PDF I have around 637
1263:59 - Pages now just think about will it be
1264:01 - like more than uh this token guys 4,096
1264:05 - token yes or no just tell me in the chat
1264:08 - what do you feel
1264:09 - like token means it's just a particular
1264:12 - word you can talk
1264:16 - about if you combine three character
1264:19 - together you can call as one
1264:23 - token uh making sense guys like if I am
1264:26 - extracting the data from my entire PDF
1264:28 - so it would be more than 4,096 token yes
1264:31 - or
1264:35 - no
1264:38 - yeah so maybe you are getting okay so
1264:40 - that is why actually what I need to do
1264:42 - okay because see my input length is that
1264:45 - means input limit is 496 token but
1264:48 - whenever I'm extracting the data it
1264:50 - might be more than it might be more than
1264:52 - 4,096 tokens okay it might be more than
1264:56 - 4,096 tokens so that is why what I need
1264:59 - to do I need to just create a chunks
1265:02 - okay instead of giving all the Corpus
1265:03 - together to my model I'll be create a
1265:05 - different different chunks
1265:06 - what is the chunks guys chunks means
1265:08 - like you will be taking some particular
1265:10 - paragraph let's say I'll start from here
1265:13 - okay now let's say I will assign this
1265:15 - Chang
1265:17 - size Chang
1265:19 - size is equal to let's say I will assign
1265:21 - as 200 so what it will do it will count
1265:24 - 200 word okay let's say this is the 200
1265:26 - word I have here so it would be one CH
1265:29 - okay this is my first chunks now again
1265:32 - uh it will start from here again it will
1265:35 - count 200 wordss and it will start uh
1265:37 - like end here okay so this would be my
1265:39 - second chance so that's how like all the
1265:42 - data you have okay in this PDF it will
1265:44 - be creating a different different chunks
1265:46 - okay and now if you see one particular
1265:48 - chunks have the token size of 200 okay
1265:51 - now there won't be any input problem to
1265:53 - my model okay so this is the idea of
1265:55 - this creation of the chunks I think this
1265:57 - part is clear why this chunks is
1266:02 - important okay yes
1266:06 - so there is another concept called
1266:08 - chunks overlap okay I discuss whenever I
1266:10 - will be assigning the chunks overlap I
1266:12 - will discuss what is Chunks overlap s
1266:15 - overlap is nothing but so whenever you
1266:17 - will Design This chunks overlap par
1266:19 - parag uh this parameter Chun
1266:23 - overlap overlap let's say I will assign
1266:25 - as 20 so what it will do whenever it
1266:28 - will create the second chunks okay it
1266:30 - will just go back to your first chunks
1266:32 - and it will count 20 words again so
1266:35 - let's say here is my 20 words okay so
1266:37 - from here actually it will start the
1266:39 - second chunks and it will end here okay
1266:41 - it will end here okay so basically what
1266:44 - is happening if you see here some extra
1266:46 - word is also coming from my previous
1266:48 - chunks as well okay so with that
1266:50 - actually my model is getting the context
1266:52 - that means after this chunks actually
1266:54 - this chunks is starting okay got it so
1266:56 - this is the idea of this chunks overlap
1266:58 - so that's how actually we'll be
1267:00 - generating our embedding Vector
1267:01 - embedding then we'll be storing them to
1267:03 - the vector DB got it
1267:07 - yeah now let's go to our architecture
1267:10 - and see our uh like uh fourth component
1267:14 - what I will be
1267:16 - do now fourth component wise I'll be
1267:19 - creating something called embeddings
1267:20 - okay so here after creating the chunks
1267:22 - each of the chunks I need to convert as
1267:24 - a number okay so we call it as embedding
1267:27 - so just let me draw
1267:30 - it this is my
1267:34 - embedding now I'll just copy this
1267:46 - component uh thanks Forman for your
1267:49 - contribution thank
1268:01 - you so this is my embedding so embedding
1268:04 - is nothing but it's a a vector okay so
1268:07 - it's a vector so let's say it can be any
1268:09 - kinds of vector I'll just take some
1268:10 - dummy Vector here so let's say this is
1268:12 - my
1268:15 - Vector okay so we call it as
1268:20 - embedding this is my
1268:22 - embedding okay now what I need to do see
1268:26 - I have uh extracted my data as well as I
1268:30 - have also created my chunks and I have
1268:32 - also converted that chunks to my
1268:34 - embedding that means vector now what I
1268:36 - need to do I will be creating one
1268:37 - semantic index okay what is semantic
1268:39 - index semantic index is nothing but uh
1268:41 - see it's a vector database concept I
1268:44 - think whenever you learn the vector
1268:45 - database so in Vector database we have
1268:47 - two kinds of thing okay one is like my
1268:50 - knowledge base and other is like like
1268:52 - semantic index okay with the help of the
1268:54 - semantic index actually it will build a
1268:55 - cluster I think you remember so it will
1268:58 - build a different different cluster so
1268:59 - let's say king and queen would be
1269:01 - appearing in the same cluster then man
1269:03 - and woman will be appearing in the same
1269:05 - cluster then Mony will appearing in the
1269:07 - different cluster okay so with the help
1269:09 - of the centic index that can be possible
1269:11 - okay it will calculate the distance
1269:13 - between all the vector and will create
1269:15 - some like let's say like cluster here
1269:19 - okay so this is the idea of this centic
1269:21 - index so just let me draw it here so
1269:24 - after creating my embedding so what I
1269:25 - will do with the help of this Vector DB
1269:28 - I'll be creating one I'll just build one
1269:32 - centic
1269:34 - index uh
1269:38 - semantic index so I'll combine all the
1269:42 - vector
1269:46 - together okay and I will be building
1269:48 - this centic
1269:50 - index extra words are coming on previous
1269:53 - chunks to make relationship the vector
1269:57 - uh yeah so whenever I'm talking about
1269:59 - this chunks overlap that means I'm
1270:01 - taking some previous words as well okay
1270:03 - in my second chance that means uh my
1270:05 - model will able to understand after this
1270:07 - chunks actually this second chance
1270:09 - chunks is starting okay so because of
1270:11 - this overlap overlap
1270:14 - condition got
1270:16 - it yeah now I have built my semantic
1270:19 - index now what I need to do guys I need
1270:20 - to build my knowledge base okay
1270:22 - knowledge means I I just need to store
1270:24 - these are the vector to my knowledge
1270:26 - base so just let me create the component
1270:30 - here so I'll be creating one knowledge
1270:34 - base
1270:36 - knowledge base okay so here knowledge
1270:38 - base wise I'll be using something
1270:40 - called pine
1270:45 - cone Pine con um Vector
1270:51 - restore uh so guys I think you are
1270:54 - already familiar with pine cone I think
1270:56 - this has been covered already how to
1270:58 - work with pine cone and all how we can
1270:59 - store the vectors in my Pine con
1271:01 - database yes or
1271:04 - no
1271:11 - okay okay great now I'll be building my
1271:15 - knowledge
1271:18 - base all
1271:20 - right now see this is the part actually
1271:24 - my first part okay this is my first
1271:26 - component this is my let's say uh this
1271:29 - is my backend component you can talk
1271:31 - about now I also need to build my front
1271:33 - end component so this thing is my back
1271:35 - end compon component the entire
1271:37 - thing you can talk about this is my back
1271:39 - end
1271:44 - component this is my back end component
1271:46 - okay now see what now user will do user
1271:50 - will raise some query okay with respect
1271:52 - to that I also need to provide the
1271:54 - answer to the
1271:56 - user uh I'll be using pine cone here
1271:58 - okay you can also integrate chrb why
1272:01 - I'll be using pine con because Pine con
1272:02 - is the remote database okay it is
1272:04 - already hosted in the website so I can
1272:06 - store my Vector there but chroma DV is
1272:08 - the local Vector DV okay so that is why
1272:11 - actually I W be using chroma DV but you
1272:12 - can also integrate chroma DB the same
1272:14 - thing you can do
1272:16 - it all right yeah now let's work with
1272:20 - the user part now let's say this is my
1272:23 - user let's say this is my
1272:30 - user this is my
1272:32 - user okay so I can assign this this is
1272:35 - my user so user what uh actually he will
1272:39 - do he will raise some query okay so
1272:41 - let's say this is the question so here
1272:43 - is the
1272:47 - question is the question user will ask
1272:50 - now first of all what I need to do I
1272:52 - need to convert this question to the
1272:54 - query embedding so here is the component
1272:57 - I can call it as
1273:02 - query embedding okay so this is the
1273:04 - query embedding now this qu query
1273:06 - embedding I just need to send to my
1273:08 - knowledge base okay so here I can
1273:10 - integrate like that so I will send this
1273:13 - query embedding to my knowledge
1273:16 - [Music]
1273:19 - base uh thanks uh bright bright side I
1273:23 - think what's your name I don't know but
1273:25 - thanks for the contribution
1273:28 - yeah thank
1273:32 - you okay now this uh question I will
1273:36 - send to my knowledge base okay because
1273:38 - knowledge base has all of the vector
1273:40 - okay all of the data now now what uh
1273:44 - okay Karan thank you Karan okay for your
1273:47 - contribution thank you it really
1273:49 - motivates a lot thank
1273:52 - you all
1273:55 - right all right great now see this query
1273:59 - uh actually I will send to my knowledge
1274:00 - base okay now what this knowledge base
1274:02 - will do actually it will give you some
1274:05 - rank result okay what it will give you
1274:07 - it will give you some rank result just
1274:10 - let me draw this
1274:15 - component this will give
1274:19 - you rank
1274:27 - result that means it will give you some
1274:29 - closest Vector with respect to the query
1274:31 - you have asked okay now what I need to
1274:33 - do okay I will be intrig my large
1274:36 - language model OKAY in this case I'll be
1274:37 - using something called Lama
1274:42 - 2 Lama 2 okay so this is my large
1274:45 - language model so with the help of this
1274:47 - large language model I'll just filter
1274:49 - out my exact answer I'm looking for from
1274:51 - this rank result okay so this llm will
1274:54 - give me the response so this response I
1274:56 - will send to the
1274:59 - user okay I'll send to the
1275:04 - user
1275:06 - all right so this is the complete
1275:08 - architecture of our medical chatboard so
1275:10 - the first thing what I doing first of
1275:12 - all I am integrating my data component
1275:14 - which is nothing but PDF file in this
1275:16 - case okay I'll be using PDF book now the
1275:19 - second thing I need to extract the data
1275:21 - or content from the PDF book then I need
1275:23 - to create a chunks okay I need to create
1275:25 - different different chunks because it
1275:27 - might be more than my input tokens okay
1275:30 - to my model so that's why this chunks
1275:32 - creation is very much important so after
1275:34 - creation of the chunks I'll be
1275:36 - generating the embeddings okay
1275:37 - embeddings means the vector okay that
1275:39 - Vector I'll be combined together and I
1275:41 - will be build one semantic index okay in
1275:43 - the vector DB then it will be creating
1275:46 - one uh like system called knowledge base
1275:48 - okay this is nothing but our Pine con
1275:49 - Vector history you can talk about now
1275:51 - I'll be go going to the front end part
1275:54 - so here actually user will give some
1275:55 - question okay that question first of all
1275:57 - I need to like convert to the query
1275:59 - embedding that query embedding I will be
1276:01 - sending to the knowledge base knowledge
1276:03 - base will give me some rank result that
1276:05 - rank results I'll be sending to my Lama
1276:07 - 2 model my Lama 2 model will understand
1276:09 - the question okay understand the like
1276:11 - question so here I can I think draw one
1276:14 - more line so whatever question user is
1276:16 - asking first of all it will understand
1276:18 - the query as well as the answer okay
1276:21 - answer from your database that's that
1276:22 - means the knowledge base so both it will
1276:25 - do the processing and after that it will
1276:27 - give you the correct response okay it
1276:28 - will give you the uh
1276:31 - actual actual response
1276:36 - actual response okay so this is the
1276:37 - complete
1276:38 - idea so guys uh you can let me know
1276:41 - whether this architecture part is clear
1276:43 - or not everyone just give me a quick
1276:45 - response in the chat so that I can go
1276:50 - proceed how this entire architecture is
1276:52 - working how we have we have created
1276:55 - different different component right so
1276:57 - now this this thing would be very much
1276:59 - easy for us to implement the code right
1277:01 - now because see what we usually do okay
1277:03 - initially whenever I was in learning
1277:05 - phase I also did the same thing let's
1277:08 - say whenever I I got one projects I
1277:10 - directly jump into the coding part okay
1277:12 - instead of understanding the project
1277:13 - architecture and all okay so it it was
1277:16 - like very difficult me to complete the
1277:18 - code because I don't know like after
1277:19 - creating the data in where I need to go
1277:22 - okay so that's why uh what I started
1277:25 - actually I started creating these kinds
1277:26 - of architecture so that see I have my
1277:29 - architecture right now let's say I have
1277:30 - completed this data data component part
1277:33 - let's say I will again uh like do the
1277:35 - coding tomorrow then I can see like I
1277:37 - have completed this data like you can
1277:39 - say integration part now I I I need to
1277:42 - work on this extract data or content
1277:44 - part then after that actually I need to
1277:46 - work on this Tech chunks part okay so
1277:48 - that's how I have the plan actually
1277:49 - entire plan of my entire projects okay
1277:51 - so that's why this like architecture
1277:54 - creation is very much important what I
1277:56 - feel
1277:57 - like okay and don't need to worry about
1277:59 - I will be also maintaining the GitHub
1278:01 - and all like I'll be committing the code
1278:03 - there so that you can also get the code
1278:05 - from there everything I will show
1278:09 - you okay
1278:12 - great all right now let's try to
1278:15 - understand what are the technology or
1278:16 - what are the tech stack actually I'm
1278:18 - going to use in this projects okay so
1278:20 - let me just write here um I'll be taking
1278:24 - a different color maybe I can take this
1278:29 - color so take a
1278:33 - stack
1278:37 - take is Tech
1278:41 - used so the first thing actually um as a
1278:45 - programming language
1278:49 - wise programming
1278:53 - language I'll be using Python
1278:58 - Programming okay now the second thing
1279:01 - I'll be using something called A Lang
1279:04 - chin
1279:07 - okay langin as my um generative
1279:14 - AI generative AI
1279:19 - framework okay like uh in deep learning
1279:22 - actually I think you know in DL actually
1279:24 - we have different different framework
1279:25 - let's say we have tensor
1279:27 - flow we have tensor flow
1279:30 - okay then we have something called P
1279:33 - torch
1279:36 - okay so we have then we have also
1279:38 - something called MX
1279:39 - net so these are the framework let's say
1279:42 - we have different different in deep
1279:43 - learning but whenever I'm talking about
1279:45 - generative AI okay whenever I'm
1279:47 - developing something in the field of
1279:48 - generative AI I should use this langin
1279:51 - or there is another framework you can
1279:52 - use something called uh maybe I can name
1279:55 - it as llama
1280:00 - index Lama
1280:03 - index okay so this is the alternative
1280:06 - framework of the langen so whatever
1280:08 - things actually you can do with the
1280:10 - langen with the help of langen uh just a
1280:12 - minute yeah
1280:14 - so so whatever things actually you can
1280:17 - do with the help of this langin the same
1280:18 - thing you can also do with the help of L
1280:20 - index okay and we have Au inte Lama
1280:22 - index in our paid courses I think you
1280:24 - can go to the syllabus and you can check
1280:26 - it there okay we'll show llama index as
1280:28 - well there all
1280:31 - right all right now third thing maybe I
1280:36 - can just uh just a
1280:59 - minute okay so the third
1281:03 - thing
1281:07 - uh our uh front
1281:11 - end front
1281:13 - end or I can talk about our web
1281:18 - app okay for the web app implementation
1281:20 - I'll be using
1281:22 - flask okay maybe I think you have
1281:25 - already learned like how to use stream
1281:26 - lit okay in your previous projects guys
1281:29 - yes or no do you know how to integrate
1281:31 - stream lead with our um application and
1281:34 - all
1281:35 - so that is why I have integrated flask
1281:37 - okay I can um I just want to show you
1281:39 - different different things actually you
1281:40 - can integrate
1281:44 - here all
1281:48 - right now our model
1281:51 - Wise
1281:52 - llm Wise I'll be using
1281:57 - meta Lama
1282:00 - 2 all right and fifth vector
1282:06 - be wise I'll be using pine
1282:10 - cone okay so these are the tech stack
1282:13 - actually I'll be using to implement this
1282:14 - entire
1282:21 - projects so far guys everything is clear
1282:24 - you can let me know in the
1282:30 - chat the take is stack and the
1282:33 - architecture everything is clear
1282:38 - here okay
1282:44 - great all right now let's go to the our
1282:49 - implementation okay now the first thing
1282:52 - what I will do uh because you will be
1282:55 - also doing the coding with me so it's
1282:57 - better to use my GitHub maybe because
1282:59 - from my GitHub actually you can get the
1283:01 - code I think so what I will do first of
1283:03 - all I will be creating one repository so
1283:04 - let me create one repository at at the
1283:06 - very
1283:21 - first so here I'll be creating one
1283:24 - repository so I'll just name it as end
1283:26 - to
1283:28 - end end to end
1283:32 - medical uh chatbot
1283:42 - using Lama
1283:44 - 2 so this is the name so let's make it
1283:47 - as public repo and I will add rme file G
1283:51 - ignore I'll be taking as
1283:53 - Python and license you can take anything
1283:55 - so let's take MIT
1283:58 - license H then I will create the
1284:03 - Repository
1284:04 - okay so I'm sharing this link guys in
1284:07 - the chat so you can Fork it and you can
1284:11 - also get the code from
1284:14 - here so this is the public repo everyone
1284:17 - can access so you can Fork
1284:19 - it you can for forkit either you can
1284:21 - clone this repository so whatever code
1284:23 - actually I'll be writing I'll be
1284:24 - committing
1284:29 - here all right now let's clone this
1284:32 - repository so I'll just uh click on code
1284:34 - and copy this link address and I will
1284:36 - open my folder and here let me open my
1284:47 - terminal so get
1284:51 - clone and let's past the link and clone
1284:55 - it now I'll just go inside the folder
1284:58 - end to
1285:00 - end
1285:02 - medical chatbot using Lama 2 now I'm
1285:06 - inser my
1285:13 - folder now let's open my vs code here so
1285:17 - if you have pyam or any other code
1285:20 - editor you can use it feel free to use
1285:22 - it no
1285:30 - issue um guys can you confirm my vs code
1285:33 - is visible to all of
1285:37 - you can you see
1285:40 - the text and all clearly you can let me
1285:45 - know
1285:50 - okay so the first thing what I need to
1285:52 - do I'll be creating one virtual
1285:54 - environment okay so let's create one
1285:56 - virtual
1286:03 - environment
1286:10 - uh yes yes uh we'll be doing on CPU okay
1286:12 - that is
1286:20 - why and yesterday I told you to download
1286:23 - one particular model guys it's around
1286:25 - 4GB I think you
1286:29 - remember uh yeah see uh the same thing
1286:34 - we can do it on the neural lab as well
1286:36 - okay so you can also open up your neural
1286:38 - lab and you can also do it there but the
1286:41 - thing is like there actually I need to
1286:43 - upload my model and it will take time
1286:45 - okay it will take time to upload my
1286:47 - model there so I will show you how to do
1286:49 - it how to set up the environment here as
1286:51 - well so let me open my neural
1286:56 - lab because it's around 4GB model so if
1287:00 - I want to like upload there so it will
1287:02 - take time so that's why I'm showing on
1287:04 - on local machine so start my lab so from
1287:07 - here actually what you can do you can uh
1287:09 - launch up this one
1287:16 - python so this is my medical chat
1287:29 - Bo so here also you will get the same
1287:31 - environment as as your V code let me
1287:34 - show you
1287:46 - see all
1287:48 - right okay but I have the model in my
1287:51 - local machine I already downloaded but
1287:53 - if I want to upload it it will take time
1287:55 - so it's better to use my uh this vs
1288:02 - code
1288:05 - okay so now let me create the
1288:06 - environment so just write the command
1288:09 - cond
1288:12 - create hypen in um I'll just name the
1288:17 - environment as
1288:20 - uh
1288:23 - medical or I can just write M chatbot
1288:26 - that means medical
1288:32 - chatbot it's very EAS just open up your
1288:35 - terminal and just write code space dot
1288:37 - okay this is the command to open the uh
1288:39 - vs
1288:46 - code okay
1288:49 - yeah and now let's uh take the python
1288:53 - version equal to
1288:56 - 3.8 hyen y so everyone you should use
1288:59 - Python version 3.8 okay no you don't
1289:02 - need to use uh like less than 3.8
1289:04 - otherwise you might face some issue okay
1289:07 - you can also take 3.9 it's fine but I'll
1289:09 - be using 3.8 this specific version also
1289:12 - just let me mention the command in my
1289:14 - rme file so here step to
1289:21 - run
1289:24 - steps to
1289:28 - run the
1289:32 - project so the first thing what I need
1289:34 - to do I need to create
1289:36 - one so I can just write this
1289:43 - line I just need to create my
1289:47 - environment now let me just quickly
1289:49 - create
1290:02 - it
1290:13 - you can use it okay you can use it it's
1290:14 - up to you what particular version you
1290:16 - will be using it's up to you personally
1290:19 - I like python 3.8 because it supports
1290:22 - like
1290:32 - B
1290:59 - uh guys am I audible
1291:02 - now
1291:21 - okay uh sorry there was a small power
1291:24 - cut from my side extremely sorry for
1291:27 - that okay thank
1291:31 - you uh yes uh
1291:36 - okay see uh first of all you need to
1291:38 - create one environment okay so this is
1291:40 - the command you need to execute uh this
1291:42 - is the command you need to execute just
1291:44 - Conta create hypen in then your uh name
1291:47 - of the environment then use Python 3 uh
1291:49 - 3.8 okay and then create the environment
1291:52 - then I just need to activate the
1291:53 - environment okay so this is the command
1291:55 - so just
1291:57 - copy and paste
1292:01 - it now it has been activated so let me
1292:04 - also uh give the command
1292:19 - here
1292:23 - okay so environment creation is done now
1292:27 - I need to install the requirements okay
1292:29 - some of the requirements I need for this
1292:30 - project so let's install the
1292:32 - requirements so here I'll be creating
1292:34 - one file called
1292:39 - requirement.
1292:43 - txt okay and now let's mention uh the
1292:54 - requirements so the first requirement I
1292:57 - need
1293:00 - here uh something called C transform
1293:03 - forer I'll tell you why this C
1293:05 - Transformer is
1293:08 - required um so the first thing I need
1293:11 - something called C Transformer okay and
1293:12 - I will be using this specific version of
1293:14 - this C Transformer so you can uh use any
1293:17 - of the version but I'll be using this
1293:19 - particular version because I also want
1293:20 - to show you like whenever you are
1293:22 - creating any kinds of projects okay you
1293:23 - also need to specify the version of the
1293:25 - library you are using let's say this
1293:27 - project you are sharing after let's say
1293:29 - one year okay so what will happen at the
1293:32 - Times uh some Library changes would be
1293:34 - happen Okay and some of the
1293:35 - functionality would be removed some of
1293:37 - the functionality would be replicated so
1293:38 - it's better to use a specific version
1293:40 - always okay so that is why you can use
1293:43 - specific version let's say if I search
1293:44 - the C Transformer on Google C
1293:47 - Transformer
1293:49 - Pi so you will see different
1293:52 - different
1293:53 - uh version of the C Transformer Library
1293:56 - so release story now see guys different
1293:58 - different and this is the current one
1294:02 - 0.227
1294:04 - C Transformers that means see the model
1294:06 - actually I'm going to use it's a
1294:08 - quantized model because we'll be running
1294:10 - on CPU so that is why uh we need this C
1294:12 - Transformer library to load the
1294:14 - quantized model got
1294:19 - it I think yesterday you saw like we are
1294:22 - using something called Lama CPP library
1294:24 - right but here we are using Lang chain
1294:27 - and if you want to use Lang chain so you
1294:29 - need to use the C Transformer
1294:32 - Library
1294:34 - then the second Library I need sentence
1294:36 - Transformer okay because I want to
1294:39 - download this uh model from the hugging
1294:41 - face
1294:42 - itself uh uh like which model I'll be
1294:45 - downloading from huging face itself
1294:47 - because here I need one embedding model
1294:48 - because as the architecture I showed you
1294:51 - here we'll be generating embedding okay
1294:55 - we'll be generating embedding of our
1294:56 - text SS and to generate this embedding
1294:58 - we need one embedding model okay so
1295:00 - we'll be using one free embedding model
1295:06 - uh guys just a minute just a
1295:32 - minute
1295:55 - okay uh now I think my network is
1296:02 - fine
1296:11 - okay
1296:12 - great okay fine so that is why actually
1296:15 - uh for this embedding okay for this
1296:17 - embedding generation actually I need one
1296:19 - embedding model okay and that particular
1296:21 - model I'll be downloading from the h
1296:23 - face itself okay so that is why I need
1296:25 - this seat uh Transformer sorry sentence
1296:28 - Transformer Library got
1296:32 - it
1296:33 - thank
1296:34 - you now let's uh see our third
1296:38 - requirement actually I'll be
1296:41 - using
1296:42 - uh third actually I need to use uh this
1296:46 - pine cone client because I want to
1296:49 - integrate pine cone database okay Pine
1296:51 - con Vector DB so that's why this pine
1296:52 - cone client is needed then as I told you
1296:55 - I'll be also using something called Lang
1296:59 - chain so this is the Lang chain and and
1297:03 - I also need flask to create my front
1297:09 - end okay so these are the prerequisite I
1297:12 - need as of now if I need anything else
1297:14 - I'll add later on okay I'll add later on
1297:17 - now just let me install them quickly so
1297:20 - before that what I can do I can just
1297:21 - quickly commit the changes in my GitHub
1297:23 - so that actually you can also get the
1297:25 - code from here so requirements
1297:32 - added
1297:44 - so it's already added let me check it so
1297:47 - if I
1297:50 - refresh yeah guys see already
1297:52 - requirements has been
1297:54 - added so you can you can just refresh
1297:56 - the page of my GitHub and you can open
1297:58 - up this txt file and you can copy paste
1298:00 - the
1298:02 - code
1298:04 - uh yeah we'll be also adding Docker uh
1298:07 - cic dependra okay this thing we have
1298:09 - already added in our paid courses and
1298:11 - projects and all okay we'll show that
1298:13 - how we can do the deployment
1298:19 - yes okay now let's install the
1298:21 - requirements so I'll just write P
1298:24 - install hypen
1298:26 - R uh requirement.
1298:31 - txt
1298:41 - so it will take some time to install the
1298:42 - requirements let's
1298:44 - wait so in between what I can do I can
1298:47 - write the command
1298:55 - here P install ienr requirement.
1299:01 - txt
1299:16 - so guys are you doing with me this
1299:18 - project implementation how many of you
1299:20 - are doing with me you can let me know in
1299:21 - the chat so far everything is fine
1299:23 - everything is
1299:31 - running
1299:39 - okay okay
1299:59 - great let me take some comments uh
1300:08 - can we use Docker here cicd I already
1300:10 - answered
1300:26 - that okay now quid is
1300:31 - great uh is it NE Neary to mention the
1300:34 - version in the requirements uh yes I
1300:36 - feel like it is necessary let's say you
1300:38 - are sharing this code or let's say you
1300:40 - are executing this code after one year
1300:43 - so in that one year duration what might
1300:45 - happen actually these are the library
1300:46 - might upgrade right some of the let's
1300:48 - say functionality would be deprecated
1300:50 - now let's say if you're not mentioning
1300:52 - the version specific version so what
1300:54 - will happen actually it will install the
1300:56 - current version okay it will install the
1300:58 - current version andbody is installing
1300:59 - the current version that means the
1301:01 - upgraded version some of the
1301:03 - functionality would be deprecated and
1301:04 - this project will throw the error like
1301:06 - this is not found here so that's why
1301:07 - it's better to use the specific version
1301:09 - let's say if you are executing this
1301:10 - project after one year as
1301:16 - well okay it will work
1301:28 - fine please let me uh quickly ask did
1301:33 - you not up with the generator projects
1301:36 - we started last
1301:40 - week you did not finish up uh McQ
1301:45 - generator I think it was uh taken by San
1301:48 - s
1301:51 - maybe maybe he has completed the
1301:53 - projects we been the deployment as well
1301:55 - guys yes or
1302:01 - no
1302:10 - yeah McQ is already finished if didn't
1302:13 - downloaded the llm model that still can
1302:16 - I make this projects are still required
1302:18 - to download you need to download ano
1302:20 - okay without the model how you'll
1302:29 - predict you can uh just make the
1302:31 - download yesterday I think I shared the
1302:33 - link and everything
1302:38 - right or just let me also give you the
1302:41 - model download link so here I will be
1302:43 - creating one
1302:44 - folder and just name it as
1302:48 - model and here I'll just create one txt
1302:51 - file I'll just write as
1302:55 - instruction.
1302:56 - txt and just let me give you the
1303:00 - instruction so you need to download this
1303:03 - particular model from this
1303:08 - [Music]
1303:29 - URL okay so this is the link
1303:34 - uh let me visit the
1303:37 - link and uh this is the name of the
1303:42 - model if I do contrl F and crl V so this
1303:46 - is the model you need to download it's
1303:48 - around 3. 79
1303:52 - GB so let me just comit it as well so
1303:55 - I'll just
1303:56 - comit model instruction
1304:01 - added
1304:09 - so those you don't have the model you
1304:12 - can download from this link okay I have
1304:14 - already comitted the code in my GitHub
1304:15 - you can check it
1304:18 - out can I make this projects in desktop
1304:21 - application and make it as uh MSI setup
1304:24 - and run locally yes you can do it okay
1304:27 - you can also create as a desktop
1304:28 - application let's say you can use Tinker
1304:31 - U framework to ment the desktop
1304:33 - application and
1304:39 - all okay I think my requirement
1304:41 - installation is completed okay uh yes it
1304:45 - is
1304:46 - completed now here what I will do I'll
1304:48 - just create one uh
1304:51 - notebook so let's create one notebook um
1304:54 - new file I'll just name it as
1304:59 - trials
1305:01 - uh Tri files. IP
1305:10 - YB and let me select my kernel
1305:16 - here so the environment I created uh
1305:21 - it's m
1305:28 - chatbot where this mchat bot just a
1305:31 - minute
1305:38 - yeah this
1305:41 - one now let me test it if everything is
1305:44 - fine or not I'll just write
1305:47 - print
1306:01 - okay
1306:05 - uh yeah uh I will drop the GitHub link
1306:10 - again so this is the GitHub
1306:31 - link
1306:41 - yeah some installation is going on let's
1306:43 - wait for sometimes just a
1306:55 - minute it's done
1306:58 - now okay now everything is working fine
1307:04 - yeah so everything is working fine guys
1307:06 - how many of you have done guys you can
1307:08 - let me know for me everything is working
1307:09 - fine so
1307:14 - far okay and uh in between I just want
1307:18 - to tell you guys if you don't know uh we
1307:21 - have launched one uh paid courses of our
1307:23 - generative a you can explore this
1307:25 - courses and we have added so many module
1307:28 - here so basically we'll be covering like
1307:30 - uh fine tuning part like how we can
1307:32 - deploy it as a cicd okay how we we can
1307:35 - integrate Docker even Lama index okay
1307:38 - even we have introduced more open source
1307:40 - large language model here like Google p
1307:42 - to Falcon okay then uh we'll be
1307:45 - discussing so many things here so you
1307:47 - can go through this labus and if you're
1307:49 - interested you can enroll for this
1307:54 - course and here you will get uh lots of
1307:57 - end to end projects implementation and
1307:59 - it would be amazing implementation alog
1308:01 - together
1308:07 - all
1308:09 - right now uh let's start the
1308:12 - implementation of our notebook so just a
1308:31 - minute
1308:33 - so here I need to import some of the
1308:35 - libraries first of
1308:51 - all
1308:56 - H okay now let's import some of the
1308:59 - libraries so first thing actually I need
1309:02 - some um I need promt templates
1309:07 - so uh yes I think I can reduce the size
1309:11 - it's not visible guys I think it's
1309:13 - visible because I'm showing I think on
1309:16 - top of my picture
1309:23 - yeah all
1309:28 - right now let's import some libraries so
1309:31 - the first thing I need something called
1309:32 - prom templates so from Lang
1309:36 - Chen Lang Chen uh import promt
1309:43 - template uh
1309:46 - prompt prom template so as of now let's
1309:50 - import I will discuss why I'm using
1309:51 - these are the thing okay it would be
1309:53 - clear now I need something called uh
1309:55 - retrieval question answering uh class
1309:58 - okay from Lang Chen so I'll just import
1310:00 - it from Lang Chen
1310:03 - uh dot
1310:05 - chain
1310:07 - import uh you have a class called
1310:10 - retriever question
1310:14 - answer okay just a minute I think I
1310:17 - should move the
1310:22 - camera
1310:26 - here uh now I think the screen is
1310:30 - visible
1310:39 - okay
1310:46 - fine then I also need to import uh the
1310:50 - hugging face embedding so from Lang
1310:54 - chain
1310:56 - uh you have one function called
1310:59 - embeddings and you need to import
1311:05 - hugging P
1311:09 - embedding hugging face
1311:12 - embeddings all right then I also need uh
1311:17 - pine cone so from langen it is already
1311:20 - available in the langen so langen uh do
1311:23 - Vector
1311:25 - store
1311:29 - UT uh I need pine cone
1311:35 - you can also import Pine con from
1311:43 - here then I need uh some more Library
1311:46 - like directory loader and my uh PDF
1311:48 - loader because I'm going to load my PDF
1311:50 - here so let's import so I'll just write
1311:53 - it from Lang
1311:56 - chain uh here you have something called
1311:59 - document loaders so from this actually I
1312:02 - need to import uh Pi PDF Pi PDF loader
1312:07 - as well as my directory
1312:10 - loader okay now to uh convert my inter
1312:15 - Corpus to chunks I need another uh class
1312:18 - called recursive character text splitter
1312:20 - okay so let's import so from
1312:24 - langen uh do text
1312:26 - splitter
1312:29 - import
1312:30 - recursive text uh character text
1312:33 - splitter okay with the help of that
1312:35 - we'll be creating the
1312:36 - chunks then I also need prom template so
1312:39 - from Lang
1312:41 - chain do
1312:43 - prompts I need this prompt
1312:48 - templates okay it should be
1312:52 - import import prom
1312:55 - template then I need also uh C
1312:58 - Transformer library because I'll be
1312:59 - using quantized model okay so just write
1313:01 - from Lang
1313:04 - chain uh
1313:06 - llms
1313:08 - import C Transformer C
1313:13 - Transformer yeah maybe everything I have
1313:15 - imported now let me
1313:19 - execute okay done now first of all let
1313:22 - me move my data here so I'll create one
1313:24 - folder here called
1313:26 - data and here I'm going to move my data
1313:29 - just a minute I think I already
1313:31 - downloaded the
1313:37 - data I'll also give you the data just a
1313:45 - minute this is my data so let me just
1313:48 - comment
1313:56 - it dat add
1314:00 - it
1314:17 - okay now I think you can download the
1314:19 - data from my GitHub okay I already uh
1314:21 - push that PDF okay if I go to my
1314:29 - GitHub yeah notebook is also available
1314:32 - data is also available now you can get
1314:33 - the data from here now I also need to
1314:35 - move my model okay so I already
1314:37 - downloaded the model just let me move it
1314:56 - here this is the
1315:00 - model
1315:05 - okay
1315:12 - fine what is the difference between from
1315:15 - langin import fromom template and promt
1315:18 - you can use any of them dendra okay I
1315:19 - have showed multip like two things you
1315:21 - can use any of
1315:23 - them both are
1315:30 - same
1315:34 - okay now uh what I need to do I need to
1315:38 - uh create my Pine con cluster okay
1315:43 - because uh we'll be using pine cone
1315:45 - Vector DB so let me just uh quickly show
1315:53 - you yeah so just visit this pine
1316:00 - website
1316:08 - so let me just logging with my
1316:21 - account all right so the first thing you
1316:23 - need something called API key okay just
1316:25 - click on the API key and uh just create
1316:28 - a API key if you don't have any API key
1316:30 - you can create from here
1316:31 - so I already have one default API key
1316:33 - I'll just copy this API key I'll just
1316:37 - copy and I will open my vs code and
1316:42 - here just let me write so pine
1316:55 - cone Pine con uh API
1317:00 - key
1317:04 - so this is my API
1317:06 - key don't uh use my API key guys I will
1317:09 - be removing after the implementation so
1317:11 - you can generate your API key then I
1317:14 - need something called Pine con API
1317:15 - environment so I'll just write pine
1317:19 - cone pine
1317:24 - cone API en
1317:28 - EnV okay to get this Pine con API uh
1317:31 - environment you need to create one index
1317:34 - now let's create one index here so I'll
1317:36 - go to the index and here I'll just click
1317:38 - on create
1317:39 - index you can give the index name so in
1317:42 - this case I'll be give medical
1317:52 - chatbot and uh Dimension uh it will ask
1317:56 - for the dimension so what is the
1317:57 - dimension Dimension means the like
1318:00 - embedding model you'll be using it has
1318:01 - some particular Dimension okay so the
1318:04 - embedding model I'm going to use in this
1318:06 - case let me show you the embedding
1318:07 - model uh this embedding model is
1318:10 - available on the hugging face so this is
1318:12 - the name of the model guys all mini LM
1318:16 - six uh L6 V2 okay so this is the
1318:18 - embedding model I'll be using and this
1318:20 - model returns uh this uh Dimension that
1318:23 - means dimension of the vector of three
1318:26 - uh 384 okay so this is the dimension let
1318:29 - me just write here t 84 so this is the
1318:32 - vector
1318:37 - Dimension and I'll be keeping cosine
1318:39 - Matrix and let's create our
1318:47 - index now this is your environment API
1318:50 - now I'll copy and here I paste
1319:00 - it
1319:09 - okay all set now let me
1319:15 - execute
1319:19 - yeah now first of all I need to load my
1319:22 - data okay load this PDF from this folder
1319:25 - so for this let's create one function so
1319:27 - I'll just name it as
1319:30 - extract extract
1319:32 - data
1319:34 - from the
1319:38 - PDF so let me Define one function so
1319:41 - I'll just name it as load PDF load
1319:43 - uncore
1319:45 - PDF so it will take the data
1319:50 - directory then I'll be using this
1319:54 - directory loader I think you remember we
1319:57 - already imported this directory loader
1319:59 - here directory loader okay with the help
1320:01 - of this directory loader uh I load my
1320:08 - data then I only want to load my PDF
1320:11 - file okay so here you can set one
1320:13 - parameter called Globe so here I only
1320:15 - want to load my PDF file so
1320:18 - start.pdf
1320:27 - then you need to Define one uh class
1320:31 - here loader class is equal to Pi PDF
1320:33 - loader so with the help of this Pi PDF
1320:36 - loader uh it should be Pi PDF yeah P PDF
1320:39 - loader it will load load it so here is
1320:42 - the P PDF
1320:46 - loader by PDF
1320:53 - loaded and this thing I will store in a
1320:55 - variable I'll just name it as load
1320:59 - up okay
1321:04 - now once uh I will uh load my PDF uh so
1321:08 - I need to call load functions so I'll
1321:10 - just write
1321:11 - uh
1321:14 - loader do
1321:17 - load and I will store these other data
1321:20 - as a
1321:26 - documents then I will return these
1321:29 - documents
1321:37 - H now let me commit the
1321:40 - changes uh data loader
1321:51 - added okay uh one thing so let me just
1321:54 - stop it just a
1321:59 - minute
1322:14 - because uh here is my model as well so I
1322:16 - can't uh directly push the
1322:18 - model uh just a minute let me close the
1322:29 - execution
1322:47 - okay so in this dogit ignore I will
1322:51 - uh add this model
1322:59 - name
1323:18 - yeah now it is
1323:19 - fine now let me commit the
1323:29 - changes
1324:15 - okay so I'm getting an error because I
1324:17 - terminated that
1324:19 - uh commit operation that's why just a
1324:21 - minute read
1324:26 - add get
1324:29 - commit
1324:39 - should positive the
1324:40 - [Music]
1324:59 - POS
1325:22 - okay uh so now let me open the code
1325:25 - again so I'm having some issue with my
1325:28 - GitHub just a minute yeah it's done so
1325:32 - guys so far everything is fine for
1325:42 - you yeah so whenever we'll be doing the
1325:45 - deployment at that time I can get uh
1325:47 - keep my model uh either in S3 bucket
1325:49 - either in this one uh you can also use
1325:53 - uh Google uh like bucket okay every
1325:56 - anywhere you can store it no issue with
1325:59 - that
1326:01 - okay now let me execute
1326:15 - them H
1326:19 - done now what I need to do I need to
1326:22 - extract my data so I'll uh I need to
1326:26 - load my data so I'll call this
1326:29 - function load PDF and
1326:32 - here I'll give my data path so here is
1326:35 - my data
1326:38 - present and this variable I will call as
1326:41 - my
1326:44 - extracted extracted
1326:52 - data now let's load
1326:54 - it modle not found P
1326:59 - PDF
1327:03 - okay so what I can do I can install Pi
1327:16 - PDF by PDF this is the
1327:29 - modu
1327:31 - P
1327:43 - install no import I have imported but it
1327:46 - is the dependency okay if you want to
1327:48 - use this PDF loader you need this P PDF
1327:51 - package that is why now I think it
1327:53 - should work just let me restart my
1327:59 - kernel h huh now it should
1328:13 - work see now it is working now it is
1328:15 - loading the
1328:17 - data so you can also keep multiple PDF
1328:19 - here uh it will also work let's say you
1328:22 - have 10 different book you can keep it
1328:29 - here
1328:39 - and guys uh all the resources has been
1328:41 - updated in the dashboard you can visit
1328:44 - the
1328:47 - dashboard yesterday whatever things
1328:49 - actually I discussed everything has been
1328:51 - updated
1328:59 - here
1329:03 - so this is the dashboard and here all
1329:05 - the videos and materials has been
1329:06 - updated so you can go through it now I
1329:09 - think it's done yeah it's done now you
1329:11 - can see the
1329:14 - data see this is uh loaded as a
1329:19 - document now let me comment
1329:22 - out
1329:29 - h
1329:34 - okay now uh guys are you able to load
1329:36 - the data yes or no is it
1329:42 - working okay great now we have created
1329:45 - this uh um extract data from the PDF now
1329:48 - what I need to do now let's go back to
1329:50 - my architecture so this thing we have
1329:53 - done now what I need to do I need to uh
1329:57 - create this one uh chunks okay chunks
1329:59 - implement because I need to convert my
1330:02 - Corpus to chunks T chunks okay so that's
1330:04 - why now let's write this
1330:06 - component so for this what you can do um
1330:11 - let me just comment the
1330:13 - name yeah so I can name it as uh split
1330:19 - or create a text
1330:22 - chunks create text
1330:28 - trunks so here I will Define another
1330:31 - function called def text splitter or
1330:34 - text chunks you can name anything so
1330:36 - let's name it as text
1330:39 - split so this will take your extracted
1330:43 - data because the data you have extracted
1330:46 - that is your Corpus okay it will take
1330:47 - and it will uh create a chunks so
1330:50 - extracted data now here I'll call this
1330:53 - recursive text splitter this
1330:58 - function okay with the help help of that
1331:01 - I'll be uh creating the Chun so here I
1331:03 - need to like pass two parameter I think
1331:05 - remember one is my Chang size one is my
1331:09 - chunk uh underscore
1331:12 - size okay so you can give any chunk size
1331:15 - here so let's define as 500 I saw like
1331:17 - people starting with 500 and chunk
1331:20 - overlap chunk
1331:23 - uncore
1331:25 - overlap so chunk overlap I will be
1331:28 - giving let's say 20 okay so this is the
1331:30 - starting point you can give so I hope
1331:34 - this part is clear what is Chunks size
1331:36 - and what is CH overlap because I already
1331:37 - discussed on my board here okay what is
1331:39 - the chunks and what is the chunks of lab
1331:42 - okay all right now let's uh store this
1331:46 - thing in a variable I'll just name it as
1331:51 - text uh
1331:58 - splitter okay
1332:01 - now after that what I need to do I need
1332:02 - to split it so again I will just uh call
1332:07 - my text
1332:11 - splitter and uh here you have one
1332:16 - parameter yes you can you can put
1332:18 - multiple data it will also work okay I
1332:20 - have only one PDF that's why I kept it
1332:22 - here now split documents okay now here
1332:26 - it will take your extracted
1332:28 - data
1332:31 - now this thing I will store so I'll just
1332:33 - name it as textor
1332:36 - chunks then after that I will return
1332:38 - this Tech
1332:43 - chunks Tech chunks okay so this is going
1332:46 - to be my
1332:49 - function all right now let's apply this
1332:51 - function I'll call this
1332:54 - function and here uh I will pass my
1332:58 - extracted text okay I'm getting from
1332:59 - from
1333:03 - here and let me store it so I'll just
1333:06 - call it as take
1333:13 - chunks and if you want to uh see the
1333:16 - length like how many chunks you got so
1333:18 - you can also print it so
1333:22 - length of my
1333:28 - chunks
1333:42 - okay now let's uh do
1333:45 - it yeah so we got SE uh 7,020 chunks
1333:51 - okay uh because we have a huge data and
1333:55 - our Chun size is if you see 500 okay so
1333:57 - what it is doing actually it is just
1333:59 - counting ing the tokens as 500 okay and
1334:02 - it is creating one particular chunks
1334:04 - that's how it has created 7, and20
1334:08 - chunks okay 7,20 chunks if you want to
1334:11 - see them maybe it would be big file see
1334:15 - 720 CHS and all are
1334:20 - documents clear
1334:24 - guys now this 720 chunks actually I need
1334:27 - to store in my Vector DB okay but for
1334:29 - that I need to convert them to my Vector
1334:33 - representation so we have completed till
1334:35 - this
1334:36 - point um till this point we have
1334:38 - completed we have converted our Corpus
1334:40 - to teex
1334:46 - chunks now what I need to do I need to
1334:49 - uh create another function here and that
1334:53 - function will uh give me the vector
1334:54 - embedding so let's comment here so
1334:58 - download embedding
1335:05 - model okay
1335:09 - so
1335:11 - download I can name this function Like
1335:13 - That download huging Face
1335:20 - embedding so this function will download
1335:22 - the Hing embedding from the hangas
1335:24 - itself so here
1335:28 - embedding
1335:31 - is equal
1335:32 - to uh here I imported hugging face
1335:40 - embedding and inside that you need to
1335:42 - pass the model name you will be
1335:49 - downloading so here is the model I
1335:51 - already showed you so I'll just copy the
1335:58 - name
1336:02 - okay everything is fine then I will
1336:03 - return this
1336:13 - embedding okay it's done so uh see I
1336:17 - already uh downloaded the model
1336:18 - previously that's why it has been
1336:22 - executed okay no I think I didn't call
1336:24 - the function sorry sorry I didn't call
1336:25 - the function maybe it will download
1336:27 - again so let's download the model so
1336:29 - I'll just uh call it as
1336:37 - embedding and now let's download the
1336:44 - model see guys now it is downloading so
1336:47 - it will take some time uh because it is
1336:49 - downloading from the HF itself now so
1336:52 - far guys everything is fine are you able
1336:54 - to execute see download is
1336:58 - done
1337:04 - are you able to download the model
1337:13 - guys okay fine now uh I have my
1337:17 - embedding model okay I have my embedding
1337:19 - model you can also print this embedding
1337:23 - object uh see guys this is the uh see
1337:26 - the output Dimension it is also telling
1337:29 - uh 384 I told you this is the uh like
1337:32 - return uh like vector
1337:34 - Dimension and uh this is the model
1337:49 - name okay this is the model
1337:51 - [Music]
1337:58 - name
1338:04 - okay great now what I need to do so
1338:07 - let's just uh do it quickly because I
1338:10 - think you got the concept what I I'm
1338:12 - doing
1338:14 - exactly yeah now I have downloaded by
1338:17 - embedding model now let's test this
1338:19 - embedding model okay now let's test this
1338:21 - one uh whether it is uh giving me the
1338:24 - embedding model or not embedding that
1338:26 - means embedding on not so this is the
1338:28 - code so here here what I'm doing I'm
1338:30 - just calling this embedding objects and
1338:32 - here there is a parameter called embed
1338:34 - query now here I'm just giving one uh
1338:36 - test word okay that means T sentence I'm
1338:38 - giving hello word okay now if I execute
1338:41 - this one see it will return return
1338:43 - 384 and this is nothing but this is the
1338:46 - vector representation of hello word
1338:49 - clear guys yes or
1338:50 - no now with the help of this embedding
1338:53 - model we are able to convert our text to
1338:55 - embeddings that means vectors and what
1338:57 - is the dimension of that Vector is 384
1338:59 - four okay and this is the vector that's
1339:01 - how this Vector looks like clear can I
1339:04 - get a confirmation
1339:11 - quickly now this technique I will apply
1339:14 - on top of my data okay the data actually
1339:17 - I have extracted okay from my PDF then I
1339:19 - will be storting them to my Vector
1339:25 - DB all right now for this actually I
1339:28 - will just copy paste the code from your
1339:30 - previous session because you already
1339:32 - completed pine cone code like how to
1339:35 - initialize the pine cone and all so this
1339:37 - is the code we usually initialize our
1339:39 - pine cone pine cone client see guys okay
1339:42 - so here you just need to give uh this
1339:45 - one uh your Pine con API key and pine
1339:48 - con API environment which I have already
1339:50 - initialized I think you remember here I
1339:51 - have already initialized okay now here
1339:56 - you need to give the index name in this
1339:57 - case what is my index name I think
1339:59 - remember we created one index let me
1340:01 - show you this is the index name medical
1340:03 - chatbot I'll copy the name and here I
1340:07 - will give the name okay make sure you
1340:08 - are giving your own index name okay
1340:11 - don't try to use my index name if you
1340:13 - haven't created this one all right then
1340:16 - once it is done I'll call my Pine con
1340:19 - and from text here you need to give your
1340:21 - extracted text okay that means the
1340:23 - chunks you have created and you also
1340:25 - need to provide your embedding model
1340:26 - okay and you also need to give the index
1340:28 - name so what this Pine con will do it
1340:30 - will take all your uh chunks as well as
1340:34 - your embedding model as well as the
1340:36 - index name okay it will take all
1340:38 - together then what it will do it will
1340:39 - apply the embedding model on top of the
1340:41 - data you have it will convert that data
1340:43 - to embeddings then it will automatically
1340:45 - store that Vector to your Pine con that
1340:48 - means this index the index the cluster
1340:50 - you have created on the pine con okay
1340:52 - now let me show you so let me execute
1340:53 - this
1340:55 - code not able to see the code sir please
1340:58 - uh okay now I think you can see the code
1341:01 - let me just see
1341:05 - once maybe I can just a
1341:14 - minute yeah now I think it is
1341:19 - visible I can move my screen here just a
1341:28 - minute
1341:33 - H see now this is uh going on so it is
1341:37 - converting my text to numbers okay and
1341:40 - it is storing to my Vector DB now if I
1341:42 - go to my Vector DB now if I refresh okay
1341:45 - refresh the page
1341:47 - here now you will see it will store the
1341:49 - vector
1341:52 - here you can also see the vector this is
1341:54 - the beauty of this pine cone even I
1341:55 - personally like see this is the vector
1341:57 - okay this is the vector and this is this
1341:59 - is the text actually it has converted
1342:00 - the vector now how many Vector it has
1342:02 - stored as of now it has VOR stored 800
1342:05 - Vector okay and how many like uh chunks
1342:08 - we have guys here I think you remember
1342:11 - how many chunks we
1342:13 - have we have 7,020 chunks so it will uh
1342:17 - create 7,020 vector and it will store
1342:19 - there so you need to wait for some times
1342:21 - for all the uh Vector U like
1342:27 - conversion so again I will come here see
1342:30 - uh it has been
1342:36 - 1,536 no no no uh not full book it's
1342:39 - just storing now see still execution is
1342:41 - going on so it is storing like one by
1342:44 - one one by one one by one okay that's
1342:46 - how so it will restore till 720 because
1342:50 - 720 chunks you have
1342:53 - totally yeah each chunks corresponding
1342:56 - to each Vector counts you can you are
1342:58 - right
1343:06 - now see uh
1343:08 - 1,900 2, uh
1343:12 - 240 so I need to wait for some times
1343:15 - because it will store otherwise I
1343:17 - can't
1343:20 - execute so let's take some query guys
1343:22 - you can ask me some query in the chat in
1343:27 - between
1343:29 - okay it's updating for you also okay
1343:32 - great uh is there any alternative to
1343:35 - Pine
1343:36 - con uh to save Vector locally yes you
1343:40 - can use chroma DB just SP you can use
1343:42 - chroma DB uh otherwise there is another
1343:44 - Vector DB called f okay this is from
1343:46 - Facebook you can use as a locally and if
1343:49 - you want to uh store data on the remote
1343:51 - so you can use pine con either wave yet
1343:54 - there is another Vector DB called wave
1343:55 - yet you can also use radius so we have
1343:57 - already showed uh integrated in our paid
1344:00 - courses there will
1344:05 - show but personally I prefer this Pine
1344:07 - con because see here uh this is the
1344:09 - beautification actually you can see the
1344:11 - vector you can see the score as well see
1344:13 - this is the semantic score like uh how
1344:16 - much uh this uh Vector is similar to
1344:19 - this Vector got
1344:25 - it what is
1344:27 - autogen autogen means I can't see any
1344:30 - autogen
1344:31 - here uh we can check different Vector
1344:34 - database yes you can check maybe uh
1344:37 - chroma DB has been discussed you can
1344:38 - also integrate chroma DB
1344:43 - Imran
1344:45 - 3,936 as of
1344:57 - now
1344:59 - what is the difference between single
1345:02 - and single agent and multi-
1345:08 - agent like uh what kinds of agent you
1345:11 - are talking about because agent can be
1345:13 - like
1345:14 - many because uh in langin actually we
1345:17 - have Al
1345:23 - agent agent why we use let's say you
1345:25 - don't have any um like the prompt you
1345:28 - have asked this data is not available
1345:30 - okay with the help of agent actually you
1345:32 - can uh use some SAR API and you can
1345:34 - search over
1345:41 - internet
1345:43 - 4,800 and 32 as of
1345:56 - now is high St
1346:02 - High stack uh I didn't use high stack I
1346:05 - can't say whether it's similar to langen
1346:07 - or not but I used Lama index maybe
1346:12 - raish because these are some more
1346:14 - popular tool okay langin lamex people
1346:17 - are using
1346:27 - broadly
1346:36 - okay so let me see the vector count okay
1346:39 - 2,000
1346:40 - Moree what about you guys how
1346:57 - much
1347:04 - okay it would be done in some time yeah
1347:06 - uh
1347:17 - 6,34 and tomorrow guys we'll be doing
1347:19 - the modular coding and the web app
1347:21 - implementation so please join the
1347:23 - session tomorrow so tomorrow we'll be
1347:25 - completing these projects okay so today
1347:27 - actually I'm showing you notebook
1347:29 - experiment uh because many of you have
1347:31 - familiar with notebook experiment okay
1347:33 - so that's why now tomorrow I will try to
1347:36 - like convert this notebook to the
1347:37 - modular
1347:46 - coding okay
1347:47 - 720 it's done guys it's done
1347:54 - great see it's
1347:57 - done all right now what I need to do
1348:00 - guys I need to
1348:02 - um you can also perform some
1348:08 - uh okay so uh now you can also do some
1348:11 - centic starts okay now we have stored
1348:13 - our Vector okay I already told you we'll
1348:15 - be building one centic index here see we
1348:18 - have built our knowledge base now uh we
1348:21 - have also our centic index now we can
1348:22 - see our rank results now if you give any
1348:24 - query so it will give you some rank
1348:26 - results okay now let's test this one so
1348:28 - let's say here I'm giving one
1348:31 - uh here I'm giving one question what is
1348:34 - allergies okay now if you open this book
1348:37 - okay if you open this book see allergies
1348:39 - has been also written in this book let
1348:41 - me show you now if I crl F and contrl V
1348:45 - maybe allergy allergy yes it is
1348:51 - somewhere see it has also written about
1348:55 - allergies okay see allergy like what is
1348:58 - is allergy and all so one question I'm
1349:00 - just giving what is allergies here now
1349:03 - it is searing your knowledge base okay
1349:05 - and it will give you top uh similar
1349:08 - three result okay top similar three
1349:09 - results and that results actually I'm
1349:11 - just printing let me show
1349:13 - you
1349:15 - see this is the top uh three results but
1349:18 - it's not readable because I told you if
1349:20 - you see that U architecture it will give
1349:23 - you rank results but it's not readable
1349:25 - okay the answer we are looking for it
1349:27 - should be need clear it should be
1349:29 - correct answer and to get this response
1349:31 - actually I will take the help from my
1349:33 - llm okay I will give this rank results
1349:35 - to my llm and I will tell it this is my
1349:37 - question and this is my answer this
1349:39 - three top answer now give me the correct
1349:41 - answer with respect to that okay now
1349:43 - let's generate our correct answer with
1349:44 - the help of our llm so for
1349:46 - this uh this is the code you need to
1349:49 - write first of all I will Define one
1349:51 - prom template okay because you know what
1349:53 - is prom template you are just telling
1349:55 - your llm like you need to do this thing
1349:57 - so if uh use the following piece of
1349:59 - information to answer the question if
1350:01 - you don't know the answer just say that
1350:03 - you don't know don't try to make up the
1350:05 - answer okay so I just want the authentic
1350:08 - answer from my LM that's why I'm giving
1350:09 - the prompt so user will give the uh
1350:12 - context and question and it should reply
1350:14 - the answer okay so this is the template
1350:17 - I have written you can write any kinds
1350:18 - of promp template it's up to
1350:21 - you what is the distance is used perform
1350:24 - similarity cosine Matrix
1350:26 - justel now this is my prompt now here
1350:29 - I'll be creating the prompt template
1350:31 - okay you already know what is prompt
1350:33 - template even I yesterday I was also
1350:35 - discussing I'll be creating this prompt
1350:36 - template this prompt template I have
1350:37 - added here and I created The Prompt and
1350:39 - this thing I have created as a chain
1350:41 - type arguments because I will be using
1350:43 - chain okay question uh uh like retable
1350:46 - question answering chain okay that's why
1350:48 - now let's load
1350:50 - my llama model so here is my model in
1350:53 - the model folder as you can see so here
1350:56 - I'm just giving the path and I'm just
1350:57 - loading the L model with the help of
1350:59 - this C Transformer library and this is
1351:01 - going to be my llm now let's
1351:05 - execute done now what I will do I will
1351:09 - create my question answering object now
1351:12 - see retrieval question answer I think
1351:14 - you know what is Ral question answer
1351:15 - from langen and here I'm giving my llm
1351:19 - as well as my prompt template as you can
1351:21 - see we have implemented my prompt
1351:22 - template and some of the arguments that
1351:24 - means dock string doers what is this
1351:27 - docer doers is nothing but your
1351:28 - knowledge base which is nothing but my
1351:30 - Vector DB U representation okay and here
1351:33 - I'm just giving uh I'm just telling it
1351:36 - will give you two relevant answer and
1351:38 - from this two relevant answer you should
1351:40 - give me the correct response okay now
1351:42 - this is my question answer object now
1351:44 - let's finally ask some
1351:46 - question so this is one for loop I have
1351:48 - written so it will take the input from
1351:51 - the user then it will ask the question
1351:53 - to my llm and llm will give me the
1351:55 - response now let me execute and show you
1351:57 - see this is the input so I'll just ask
1352:00 - what is let me show you which question
1352:03 - I'm I'll be asking so contrl
1352:06 - F I'll be asking something related
1352:10 - acne maybe acne is
1352:14 - there see acne okay so acne is a screen
1352:18 - problem I think you know see this is the
1352:21 - acne so let's ask something related to
1352:23 - the acne like what is acne and all about
1352:24 - so I'll just say what is acne
1352:29 - now let's ask this
1352:31 - question so again U response time would
1352:34 - be a little bit High because we are
1352:36 - using U um like model on our CPU machine
1352:40 - that's
1352:41 - why and again I am doing live streaming
1352:43 - so for me it would be a little bit late
1352:45 - okay but if I stop the streaming so it
1352:47 - would be
1352:51 - quickly and tomorrow we'll be
1352:53 - integrating the uh like front end part
1352:55 - and you will see the beautification of
1352:57 - this projects okay it would be amazing
1353:13 - completely so for this live streaming
1353:16 - actually I'm uh having
1353:17 - some uh slow time
1353:27 - maybe
1353:35 - so anyone running is it running for
1353:50 - you okay see done now this is the
1353:54 - response guys I got acne is a common
1353:56 - skin disease character ized by pimples
1353:59 - on the face chest and back that occurs
1354:02 - when the uh pores of the skin becomes
1354:06 - clothed with the oil dead skin cells and
1354:11 - bacteria is it
1354:14 - correct is it correct response guys just
1354:16 - give me give me a quick yes in the chat
1354:19 - how is the
1354:26 - project you can ask any kinds of
1354:28 - question guys any kinds of question from
1354:30 - this book just go through the book get
1354:32 - some idea what are the disease what are
1354:33 - the med medicine you have okay and you
1354:36 - can ask the
1354:38 - question I'm not a doctor
1354:40 - sir even I'm not a doctor but I have
1354:43 - this bot right now I can ask any kind of
1354:46 - question so how was the session guys Al
1354:48 - together did you learn the entire
1354:50 - concept like how we can integrate all
1354:52 - the technology together and implement
1354:54 - this kinds of
1354:55 - projects no no fine tuning is a
1354:57 - different friend benit fine tuning will
1354:59 - show in our paid courses it available
1355:01 - okay this is the existing model we are
1355:03 - using with our custom
1355:08 - data
1355:09 - okay now let me stop the execution uh
1355:12 - tomorrow I will show you the further
1355:14 - part uh uh it is enough for today I
1355:18 - think yeah and this code would be
1355:21 - available in my GitHub the link I have
1355:22 - shared with you let me share it again so
1355:25 - I'll just comment the code after the
1355:26 - session so you'll get from here
1355:31 - so this is the GitHub link guys everyone
1355:33 - you can yeah now let me take some
1355:37 - question where did you get the data data
1355:40 - I downloaded from the internet this book
1355:42 - I downloaded okay data I've already
1355:44 - shared and please and doer CD pipeline
1355:47 - upcoming classes we'll be adding uh we
1355:49 - have a projects in our paid courses
1355:50 - dependra we'll show that how much data
1355:53 - we can give uh terabyte you can give as
1355:57 - many as data but uh you should have good
1355:59 - memory condition okay if you are like
1356:01 - very less memory then uh you can't load
1356:05 - so so much data so guys uh let's start
1356:08 - with our uh medical chatbot
1356:10 - implementation so yesterday I was
1356:12 - discussing the architecture and the uh
1356:15 - notebook experiment part uh today
1356:17 - actually I will show you how we can
1356:19 - convert this entire things to modular
1356:21 - coding even uh I will also show you like
1356:23 - how we can uh create the web application
1356:25 - and all using flas so it should be U
1356:28 - totally amazing so make sure you are
1356:30 - watching this live till the
1356:32 - end okay guys so before starting with
1356:35 - the session uh first of all I want to
1356:37 - show you um your all of the resources
1356:39 - has been updated in your dashboard so
1356:41 - let me open my dashboard
1356:43 - once
1356:46 - um so guys here is the dashboard and uh
1356:49 - if you see today is day 13 so till day
1356:53 - 12 actually it uh it has updated already
1356:55 - so all the resources all the like GitHub
1356:58 - link everything has been updated here so
1357:00 - you can check from your
1357:04 - end and guys uh if I disconnect somehow
1357:07 - so no need to worry about just stay here
1357:09 - I will uh again reconnect okay I have
1357:14 - backup all
1357:21 - right so everyone is ready can I get a
1357:24 - quick yes from everyone so that I can
1357:25 - start with the implementation so
1357:28 - just give me a yes in the
1357:40 - chat okay thank
1357:44 - you all right so uh let me open my uh
1357:48 - project actually I created yesterday so
1357:50 - this is my project guys even I have
1357:53 - already updated the code in my GitHub as
1357:55 - you can see uh this notebook I
1357:57 - implemented yesterday so this is already
1357:59 - updated here even the data is already
1358:01 - available and model actually I can't
1358:03 - upload in my GitHub because it's a huge
1358:05 - model so what I did actually I just
1358:07 - given the instruction okay so this is
1358:08 - the instruction I have given like how to
1358:11 - download this particular model from this
1358:12 - URL okay so first thing what I will do
1358:15 - uh I will try to upgrade this uh readme
1358:18 - file once because let's say if you are
1358:19 - referring this uh GitHub okay if you're
1358:21 - referring this repository so how we can
1358:24 - set up this projects and all okay first
1358:26 - of all I will just write uh some STS in
1358:27 - the rme file then I will try to start
1358:30 - with our implementation okay so let me
1358:32 - open my project with my vs code and uh
1358:35 - what I will do uh I will also show you
1358:37 - uh on the neural lab as well because
1358:39 - neural lab I was trying to upload the
1358:41 - model but it was taking time uh for me
1358:43 - okay because this model is hug so I'll
1358:46 - will also show you side by side
1358:47 - implementation how we can do it so what
1358:49 - you just need to do here you just need
1358:50 - to upload the model here in the model
1358:52 - folder okay and all the steps will
1358:54 - remain
1358:56 - same all right
1358:58 - so I have this model in my local machine
1359:01 - so this is the model now what I will do
1359:03 - first of all let me open
1359:05 - my uh vs code
1359:12 - here
1359:15 - okay so everyone you can open up your vs
1359:17 - code or you can also do it on the neural
1359:21 - lab and if you don't have the code you
1359:24 - just clone from my repository
1359:26 - once
1359:40 - okay so I hope my screen is visible
1359:42 - properly everyone just confirm in the
1359:45 - chat or should I zoom a little
1359:52 - bit maybe it's
1359:55 - fine okay
1360:03 - just a minute
1360:09 - uh okay so first of all let me write
1360:11 - down the steps what you need to do to uh
1360:14 - execute this project so I can remove
1360:17 - these are the steps
1360:19 - maybe yeah so the first thing you need
1360:23 - to clone this particular repository so
1360:25 - let me just add this
1360:28 - part so first of all you need to clone
1360:30 - the repository okay so here I have just
1360:32 - given like till github.com so what you
1360:35 - need to do you need to just clone this
1360:37 - particular repository the repository I
1360:39 - have created Okay click on the code and
1360:41 - click on this link address then uh the
1360:44 - second thing you just need to create one
1360:46 - virtual environment so we have already
1360:49 - created the
1360:50 - environment and the name of the
1360:52 - environment was here uh this is the name
1360:56 - so medical chat boo so I just written M
1360:58 - chatbot okay I'll copy this name and
1361:01 - here I'll just
1361:03 - upgrade okay and I was using python 3.8
1361:06 - version
1361:08 - okay so when the projects will be
1361:11 - available uh in
1361:13 - Inon uh this project is already
1361:16 - available okay in my GitHub Raven even
1361:19 - Inon website it is also available you
1361:22 - can check it out and today we'll be
1361:24 - completing this project implementation
1361:26 - okay entirely because yesterday I was
1361:28 - doing the notebook exper experiment
1361:35 - only then I need to active by uh
1361:39 - environment here so this is the
1361:44 - name after
1361:46 - that okay internship project you are
1361:49 - talking about so internship project
1361:50 - should be updated also okay raan just uh
1361:53 - check the internship portal it would be
1361:56 - updated
1362:01 - then uh I just need to install the
1362:03 - requirements actually so yesterday I
1362:05 - showed you I was installing some of the
1362:07 - requirements so this is the command to
1362:09 - install the requirements all right then
1362:12 - what we did exactly we just created Pine
1362:14 - con uh API key I think you remember so
1362:17 - let me open my Pine con once so pinec
1362:20 - con. let me loging with my
1362:22 - [Music]
1362:24 - account so I'm going to use the same
1362:26 - index because we have already stored our
1362:28 - data yesterday okay so I'll be using the
1362:31 - same index
1362:33 - only so this is my index guys medical
1362:35 - chatbot I created so here I think you
1362:37 - remember we collected the API Keys as
1362:39 - well as our environment okay this Pine
1362:43 - con environment so both I need to add
1362:46 - otherwise this project won't be working
1362:47 - so that thing I will also mention in the
1362:49 - rme
1362:51 - file so here I'm just telling create
1362:54 - aemv file I will tell you what is this
1362:56 - EnV file file okay how we'll be managing
1362:58 - this uh secret key and all okay so this
1363:01 - thing you need to pass in the
1363:02 - environment file then it will
1363:05 - work all right and the last thing I
1363:09 - downloaded my model so this is the step
1363:12 - to download my model so you just need to
1363:15 - download this particular model from this
1363:17 - URL and need to Pro uh like keep that
1363:19 - model in the model folder okay for us
1363:21 - actually we already kept the
1363:25 - model all right so these are the steps
1363:27 - actually we uh completed yesterday and
1363:30 - rest of the thing actually I will show
1363:31 - you today now let me commit the
1363:47 - changes okay done now if I go to my
1363:49 - GitHub and refresh the
1363:53 - page yeah it is updated now let me share
1363:56 - the link with you again
1364:06 - so here's the
1364:18 - link all
1364:23 - right so the first thing actually uh
1364:27 - what I need to do I need to create my
1364:28 - project template because yesterday I
1364:31 - completed the notebook experiment okay
1364:32 - so most of the thing I will copy from my
1364:34 - notebook only so this is my notebook so
1364:36 - most of the code actually I'll be copy
1364:37 - pasting from here and the thing is like
1364:40 - I just need to uh create a modular
1364:42 - coding pipeline okay so that is the main
1364:44 - thing here like how we can organize our
1364:47 - code so for this uh instead of creating
1364:50 - the folder manually uh so what I will do
1364:52 - I will just create a template file here
1364:55 - so that template file I will just write
1364:57 - some of the logic like what are the
1364:58 - folders I need and how it would be
1365:00 - created with the help of python then if
1365:02 - I execute that particular template file
1365:04 - it will automatically generate the
1365:05 - folder for me okay now let's say if I
1365:07 - want to create the folders and file now
1365:09 - what I need to do I need to manually
1365:10 - create it let's say I want a file I will
1365:12 - click here again I will name the file
1365:14 - then I need a folder here I will again
1365:15 - click here then I will just uh name the
1365:17 - folder name that's how I will be
1365:19 - creating manually but let's see if
1365:20 - you're doing the uh like the same
1365:22 - projects again and again okay similar
1365:23 - kinds of projects what you need to do
1365:25 - again you need to create those are the
1365:26 - files manually so instead of that what I
1365:28 - will do I'll create one template file
1365:30 - and that should be one time effort okay
1365:32 - and I will I will just write all the
1365:34 - logic there like how we can create I
1365:36 - will be creating this folder structure
1365:37 - and all so every time if you execute
1365:39 - that file so it will automatically
1365:40 - create the folder structure for
1365:42 - you okay so for this let's create this
1365:45 - file and I will name it as
1365:48 - template template.
1365:53 - pipe okay so here first of all let's
1365:56 - let's import some of the library so I
1365:58 - need the operating
1366:00 - system then I also need something called
1366:03 - path from path Le I'll tell you why this
1366:05 - path leave is required just let me
1366:07 - import it first of all so uh it should
1366:10 - be everything
1366:11 - from so from path
1366:14 - Le import
1366:17 - path then I also need something called
1366:22 - login okay so the first thing I just
1366:24 - need to create one logging string here
1366:26 - okay why I need to create a loging
1366:27 - string so let's say whenever you will
1366:29 - execute that template. Pi file so it
1366:32 - will also show you the log on the
1366:33 - terminal like whether this folder has
1366:35 - been created or not okay if it is if it
1366:37 - is created now why it is created it will
1366:39 - also show you the location as well okay
1366:40 - so to log these are the information I
1366:42 - need this login string okay I hope you
1366:45 - already know what is logging in Python
1366:46 - guys yes or no if you don't you can
1366:48 - search on Google like logging in Python
1366:51 - so logging is a inbuilt uh modu inside
1366:53 - python so maybe you already worked with
1366:57 - login so this is the documentation of
1366:59 - login
1367:04 - guys all right so if you visit the
1367:07 - documentation so you will see these
1367:09 - kinds of loging string people are
1367:11 - writing okay this is the loging string
1367:13 - we usually follow so here we usually
1367:15 - mention first of all our logging level
1367:18 - okay so here the log level is like
1367:19 - information uh like level log so
1367:22 - basically I just want to save my
1367:23 - information like why this folder is
1367:26 - creating what is the path so these are
1367:27 - the information actually so that's why
1367:29 - here I have given login. info okay and
1367:32 - you just need to uh mention also the
1367:33 - format format of the loging like what
1367:35 - particular message actually it will show
1367:37 - you so the first thing I'm just saving
1367:39 - my asky time that means the current time
1367:40 - stamp let's say I'm executing the code
1367:43 - at this time so it will save that
1367:45 - particular time with respect to the the
1367:47 - message actually you will be writing
1367:49 - okay so this is the loging string so it
1367:50 - would be clear whenever I'll execute the
1367:52 - code and I'll I'll tell you okay how
1367:54 - this log would be
1367:55 - saved
1368:01 - now here I need some list of the file
1368:04 - okay so let's create a
1368:06 - variable and I will just name it as list
1368:09 - of
1368:11 - file list of files is equal to so let's
1368:14 - make it as a list now here first of all
1368:17 - I need uh One Source folder okay so I'll
1368:21 - just name it as
1368:24 - SRC so inside SRC I'll creating one
1368:27 - Constructor so underscore uncore
1368:30 - unit I'll tell you why this underscore
1368:32 - uncore init _ Pi is needed as of now
1368:35 - just uh create the folder with
1368:37 - me and then I will be creating another
1368:40 - uh like file called helper. Pi in the
1368:43 - same folder so I'll copy the same thing
1368:47 - again and it should be helper.
1368:55 - Pi then again I will be creating another
1368:57 - file inside that and I'll just name it
1368:59 - as
1369:02 - prompt prompt.
1369:05 - Pi okay then I also need one uh file
1369:09 - called
1369:15 - envv then I also need uh something
1369:17 - called setup. Pi because requirements we
1369:19 - already created I don't need it so I'll
1369:22 - just write setup.py
1369:25 - then I also need something called U one
1369:28 - resource folder because I'm going to
1369:30 - keep this file inside a folder called
1369:32 - resource so let's name it
1369:35 - research slash and here I'm going to
1369:38 - create that trial.
1369:47 - ipnb all right then I also need
1369:50 - something called
1369:55 - app.py
1369:59 - then uh I need another file called store
1370:04 - index store uncore
1370:08 - index. Pi I'll tell you why this IND
1370:11 - store underscore index is required okay
1370:13 - I'll tell you now I think most of the
1370:16 - things I have created okay so I will
1370:18 - also integrate the flask so for this
1370:19 - actually you need one folder called
1370:23 - Static
1370:25 - uh
1370:30 - static and another folder you need
1370:33 - something called template. Pi sorry
1370:38 - templates so inside templates I will be
1370:40 - creating another file and I will just
1370:42 - name it as uh chat.
1370:46 - HTML yeah so these are the folders and
1370:50 - file I need as of now if I need it so
1370:53 - I'll uh create uh later on okay so as of
1370:55 - now let's create these are the things
1370:56 - only now I have already listed down the
1370:59 - files and folder actually I'll be
1371:01 - creating here okay now how to create it
1371:04 - okay how to create it so for this we
1371:06 - just need to write some of the logic
1371:07 - here so I'll be using simple python code
1371:09 - only to create this folder structure and
1371:11 - all so the first thing I'll be looping
1371:13 - through this list okay so I'll just
1371:14 - write one for Loop so for file uh
1371:19 - path in list of the file that means this
1371:23 - list actually I'm iterating through then
1371:26 - what I need to do first of all uh the
1371:30 - file path actually I'm having so first
1371:32 - of all I need to convert them to
1371:38 - path I need to convert them to path okay
1371:40 - why I'm converting them uh like to path
1371:43 - because if you see here the operating
1371:45 - system actually currently I'm using it's
1371:46 - Windows okay Windows machine I'm using
1371:48 - but here if you see I'm using forward
1371:50 - slash so I think you already know in
1371:53 - Windows machine actually we usually use
1371:55 - something called backward slash
1371:57 - yes or no guys backward slash if you see
1371:59 - any kinds of Windows path it would be
1372:00 - backward slash instead of forward
1372:02 - slash okay but here we are using
1372:05 - something called forward slash okay so
1372:07 - forward slash we usually use uh in the
1372:09 - Linux operating system and Mac operating
1372:11 - system okay but in Windows we usually
1372:13 - use backwards
1372:14 - slash so that is why to uh prevent this
1372:17 - kinds of issue okay I need this path
1372:19 - Library okay now how this path will be
1372:21 - working let me show you let me give one
1372:23 - demo so here I will activate my python
1372:27 - so let's import
1372:30 - W uh maybe I can import this path so
1372:36 - from path
1372:39 - leap import
1372:41 - path so let's define One path so I'll
1372:44 - just write path equal to so here I can
1372:47 - give let's say
1372:49 - test uh let's I will give uh forward
1372:52 - slash here and here I will give U app.
1372:55 - pi
1372:58 - so let's say this is my path now what I
1373:00 - will do I will just give this path in my
1373:02 - path
1373:05 - class okay if I give it now see what
1373:08 - will happen just see that it will
1373:09 - automatically detect it's a Windows
1373:12 - path okay first of all it will detect my
1373:15 - uh operating system I I'm using okay
1373:16 - with respect to that it will convert
1373:18 - that path okay so this is the advantage
1373:20 - to use this path class okay so what will
1373:22 - happen now if you execute this code in
1373:24 - the Linux operating system as well Mac
1373:26 - operating system as well everywhere it
1373:28 - will work because with with the help of
1373:30 - this path class it will first of all
1373:31 - detect the operating system then it will
1373:33 - convert that part with respect to the
1373:35 - operating system we are using okay so
1373:36 - that's why we are using this path from
1373:38 - the path Li itself all
1373:41 - right now here I got my file path again
1373:44 - so I'll just store
1373:51 - it okay now here what I need to do I
1373:54 - need to separate out my folders and file
1373:56 - because as you can see here this is my
1373:58 - folders okay and this is my files so I
1374:01 - need to separate them because as you can
1374:03 - see here I can't directly create my
1374:05 - folders and file okay all together so
1374:07 - what I need to do I need to separate my
1374:09 - folders and I need to separate my files
1374:11 - okay in a two variable then I will be
1374:12 - creating that so for this what you can
1374:14 - do so first of all I will store my file
1374:20 - directory then I will instore my file
1374:23 - name okay so there is a uh method inside
1374:27 - operating system package so just write
1374:28 - OS do
1374:31 - path uh os. path.
1374:35 - split okay so this is the method you can
1374:37 - use and inside that you just need to
1374:39 - give the file
1374:41 - path okay now what will happen let me
1374:44 - show you so let's say this is my path I
1374:46 - have so I will import o again now what I
1374:50 - will just do I'll just write uh first of
1374:53 - all uh yeah w dot
1374:57 - path do
1375:00 - split okay and here I will give my path
1375:02 - so let's say this is my path and now see
1375:05 - what will happen see it is returning the
1375:07 - folder separate and it is returning the
1375:10 - file separate okay now what I can do I
1375:12 - can create a two variables here you can
1375:14 - see I can I have created two variables
1375:16 - so the first variable will contain the
1375:18 - folder name and the second variable will
1375:21 - contain the file name okay so this is
1375:22 - the logic actually I'm just trying to
1375:25 - write
1375:27 - all right so once I got my uh file
1375:30 - directory and my file name now what I
1375:32 - need to do okay I just need to create my
1375:34 - file directory at the very first so for
1375:36 - this I can write one logic so I'll just
1375:37 - write if file
1375:39 - directory if file directory is not empty
1375:44 - okay is not
1375:45 - empty so I can write like that is not
1375:48 - empty so what I need to do I'll be
1375:50 - creating the uh file directory so I'll
1375:52 - just write w. make D okay so this is the
1375:55 - method actually you can use to create
1375:56 - any kinds of directory okay and here
1375:59 - I'll just give my file directory name I
1376:02 - want to create then after that I need to
1376:05 - give one parameter called exist okay is
1376:06 - equal to true so what will happen if
1376:09 - this file is already available if this
1376:10 - folder is already available in your
1376:12 - computer so it won't be creating okay
1376:14 - otherwise it will create so with the
1376:16 - help of this parameter you can control
1376:18 - this thing
1376:19 - okay now if you're not giving it so what
1376:22 - will happen it will replace that
1376:23 - particular folder let's say in the
1376:25 - particular folder you have some files
1376:26 - okay again it will replace that so you
1376:28 - need to recreate it again so that is why
1376:30 - you need to give this
1376:33 - method okay so once it is done I also
1376:36 - need to log the information I'll just
1376:38 - write login
1376:40 - doino and here I can give one log so
1376:46 - creating creating F uh
1376:54 - directory
1376:56 - creating directory uh first of all I'll
1376:59 - give the folder
1377:03 - name uh folder name so this is my file
1377:09 - directory and after that for the
1377:13 - folder for the uh for the
1377:18 - file and here I will give my file name
1377:21 - so this is my file name okay that's it
1377:24 - now once my folder is uh done okay let's
1377:26 - say I have created my folder now what I
1377:28 - need to do I also need to create the
1377:30 - file inside the folder okay so for this
1377:32 - I need to write another logic so
1377:35 - here uh what I can
1377:40 - do
1377:42 - yeah I'll again write one if statement
1377:46 - if maybe intention is not correct just a
1377:49 - minute yeah so
1377:52 - if uh not o do
1377:59 - path uh do
1378:03 - exist this file
1378:07 - path okay this file path that means the
1378:10 - file path actually I'm having so if it
1378:12 - is doesn't exist okay in my directory so
1378:15 - what I need to do okay I need to create
1378:18 - it but instead of using one particular
1378:20 - logic I'll be using another particular
1378:22 - logic I will also check the size of the
1378:24 - file so what I can do
1378:26 - I can write another logic here so
1378:28 - W uh dot
1378:33 - path dot uh there is a parameter you
1378:35 - will get called G size if you want to
1378:38 - check uh any particular size of any any
1378:40 - file so you can use this method actually
1378:42 - get size now inside get size you need to
1378:45 - give the file
1378:46 - name file name and that uh if it is not
1378:51 - let's say uh if it is not let's say uh
1378:55 - equal equal zero that means if this file
1378:57 - is not empty so what I need to do I need
1378:59 - to create that particular file so for
1379:01 - this I'll just use with
1379:05 - open with open and here I will give my
1379:08 - file
1379:09 - path okay and here I just need to create
1379:12 - it so that's why I need to open with
1379:14 - write mode okay once it is done I'll
1379:17 - just do the pass operation here because
1379:19 - I'm not doing anything I'm just only
1379:20 - creating that particular file here okay
1379:23 - then I also need to log the information
1379:25 - so what I can do here I I'll just write
1379:30 - login login.
1379:34 - info login. info and here I will give
1379:37 - the log so I can just write
1379:44 - creating creating empty
1379:49 - file and let's give the file name
1379:53 - here file path
1379:58 - yeah and if it is already exist so what
1380:01 - I will do I'll just write
1380:03 - else so I'll just give the log message
1380:06 - here so login do
1380:10 - info um here I can give uh this file
1380:15 - file
1380:17 - name is
1380:19 - already um created okay so this is the
1380:22 - message I think I can give yeah so this
1380:24 - is the simple I have written so guys
1380:27 - this code is understandable for you yes
1380:29 - or no give me a confirmation in the chat
1380:32 - are you getting this code how I have
1380:33 - written it's a simple python code
1380:42 - only
1380:46 - yes okay great now let's execute this
1380:51 - particular template file and see what
1380:53 - happens okay now if you see left hand
1380:55 - side I I don't have these are the files
1380:56 - and folder okay now once I will execute
1380:59 - this template. Pi let's see what will
1381:01 - happen so I'll open my terminal I'll
1381:03 - exit from my
1381:06 - python uh first of all let me uh
1381:09 - activate my environment I'll just write
1381:10 - cond
1381:12 - activate M
1381:18 - chatbot now let's execute this template.
1381:21 - Pi so template. Pi see see the magic
1381:24 - guys automatically all the files and
1381:26 - folder would be created left hand side
1381:27 - just see left hand side and see the log
1381:30 - guys it is saving my Tim stamp the
1381:33 - current time stamp I'm executing the
1381:35 - code as well as the date and it is
1381:37 - giving you the message like directory
1381:38 - created SRC for the file of uncore uh
1381:43 - init.py
1381:44 - again creating an empty file inside SRC
1381:48 - uncore init.py okay that's how all the
1381:52 - file and folder has been created and see
1381:54 - left hand side guys we are able to
1381:57 - create our folder
1381:58 - structure uh in just one
1382:01 - shot okay now let's see you need some
1382:03 - other files and folder okay in future so
1382:05 - what you need to do you just need to
1382:06 - give the list here let's say I need
1382:08 - something called test. Pi I'll just give
1382:10 - test. Pi here I'll save this one again
1382:13 - if I execute the same template. Pi uh
1382:16 - okay so it is
1382:18 - telling this system cannot find the
1382:21 - specific Pi okay I'm getting one error
1382:24 - let me see test. Pi has been cre or
1382:26 - not okay static it is throwing the error
1382:30 - okay static should not be empty so here
1382:31 - I can give
1382:33 - uh uh
1382:38 - CSS or I can give U just dogit
1382:43 - ignore
1382:45 - dogit
1382:53 - keep let me remove this static file
1382:57 - here now let me execute it
1383:03 - again okay it's throwing error just a
1383:06 - minute
1383:10 - um file name St
1383:17 - size not o. get software line five get
1383:21 - size return file not found the system
1383:25 - cannot find the file
1383:27 - specified underscore uncore unit.
1383:42 - Pi maybe my logic is
1383:54 - correct okay now it's done I think yeah
1383:57 - now if you see uh my static folder has
1384:00 - been also created now here if
1384:04 - I uh just uncomment this test. PI right
1384:07 - now and if I again execute
1384:11 - it see guys it has created okay now see
1384:15 - you can create as much as file and
1384:17 - folder okay it's up to
1384:20 - you okay so in this case I don't need
1384:22 - this test. Pi I'll just remove it and
1384:25 - here I will also remove the test.py from
1384:30 - here all right so in future let's say if
1384:33 - you're developing any kinds of projects
1384:35 - instead of creating the folders and file
1384:37 - manually what you can do you can create
1384:40 - this particular template file and here
1384:42 - just write the logic okay it would be
1384:44 - one time effort but this file you can
1384:46 - use it okay in your every projects just
1384:49 - uh execute this particular file and it
1384:51 - will automatically create the folder
1384:52 - structure for
1384:54 - you all right now let me move that
1384:57 - trials file in my resarch folder so I'll
1384:59 - just move it I'll just cut it in my
1385:01 - resarch
1385:05 - folder
1385:07 - yeah uh everything is done now let me
1385:10 - just comment the changes in my GitHub
1385:13 - quickly folder
1385:16 - structure add
1385:24 - it
1385:30 - so guys so far everything is
1385:33 - clear you can let me know in the
1385:41 - chat like how we have created the folder
1385:44 - instuction and all so far everything is
1385:48 - clear
1385:54 - okay
1385:56 - okay fine now we are done with our uh
1386:00 - project template creation so now second
1386:03 - thing I just need to write my setup. Pi
1386:05 - file okay why I needed setup. Pi file
1386:08 - because as you can see now we have
1386:09 - created so many file inside the folder
1386:13 - okay now let's say I want to import
1386:15 - something from this particular file
1386:17 - let's say help .p I have written
1386:18 - something now let's say I want to import
1386:20 - that thing inside my app.py okay so what
1386:23 - I need to do I need to write from SRC do
1386:26 - helper import something okay so if you
1386:29 - want to do this kinds of operation then
1386:31 - you need to set up this particular SRC
1386:33 - file as my local
1386:34 - package I think you already familiar
1386:36 - with what is local package okay in
1386:38 - Python let's say whenever you install
1386:41 - any kinds of like package from the piy
1386:44 - website okay it is already hosted on the
1386:46 - pii website but uh it can be also done
1386:49 - we can also create our local package as
1386:51 - well okay let's say here if I do uh pep
1386:54 - list
1386:56 - pip list so it will list down all of the
1387:00 - package actually I have installed in
1387:01 - this projects okay but here if you see
1387:04 - this SRC is missing okay SRC is missing
1387:07 - so if I want to import something from
1387:08 - the SRC then it will throw error it it
1387:11 - will tell SRC is not found okay so to
1387:13 - prevent these kinds of error what I need
1387:15 - to do I need to create this setup. Pi
1387:17 - file and I need to set up this SRC
1387:19 - folder as my local
1387:23 - package
1387:26 - no this is not a pre-installed this
1387:28 - thing I have installed from the
1387:29 - requirement. txt I think you remember
1387:32 - Iman okay because this is my new created
1387:35 - environment and inside the environment I
1387:37 - install all the package actually I need
1387:39 - for this
1387:41 - project all right but here if you see
1387:43 - SRC is
1387:44 - missing SRC is missing now let's say if
1387:47 - I'm writing something inside help .p
1387:49 - let's say if I Define anything let's say
1387:50 - import OS uh let's say I will write one
1387:53 - function here uh let let's say main
1387:55 - function I have written and I'll just
1387:57 - doing some pass operation now let's say
1387:59 - I want to import this main method inside
1388:01 - my app. Pi now what I need to do okay
1388:04 - what I need to do I just need to import
1388:06 - it first of all so from SRC so SRC is my
1388:09 - folder SRC do help part okay then import
1388:14 - main import main getting my point so if
1388:19 - I want to import like that now see this
1388:21 - SRC is not present inside my environment
1388:24 - okay it's not present as a package envir
1388:26 - environment so it will throw error like
1388:28 - SRC module is not found got it but if
1388:31 - you want to install this SRC as your
1388:33 - local package and if you want to keep it
1388:35 - inside your environment okay just to
1388:36 - prevent the error you just need to write
1388:38 - this setup. Pi so this thing actually we
1388:41 - usually use in our end to end
1388:43 - implementation always because we write a
1388:45 - modular coding
1388:47 - here all
1388:49 - right so now let's write our uh setup.
1388:53 - Pi so I'll open the setup do pi and this
1388:55 - code is very common so I already written
1388:58 - this code let me show
1388:59 - you setup. Pi
1389:02 - code uh see guys here you just need to
1389:05 - use one particular package called setup
1389:07 - tools okay setup tools is a pre-built
1389:10 - package inside python from here you need
1389:12 - to import two particular things one is
1389:14 - like find packages and other is like
1389:16 - setup now you need to create one setup
1389:18 - object here so see here I have created
1389:20 - the setup objects here you can give your
1389:22 - project name so in this case I creating
1389:24 - Genera VI projects okay that's why I
1389:25 - given generative projects you can also
1389:27 - give something called medical chatboard
1389:28 - let's give medical chatboard medical
1389:32 - [Music]
1389:33 - chatboard all right you can also specify
1389:36 - the version okay version of the package
1389:38 - you want to create so let's say this is
1389:40 - the initial phase I'm implementing the
1389:41 - project so that's why the version I have
1389:43 - used
1389:47 - 0.0.0 okay now here you can give the
1389:50 - author name so let's say I here I have
1389:52 - given my name you can also give your
1389:53 - name so let me give my full full name
1389:55 - here so I'll just write
1389:59 - B ah Bui okay this is my name you can
1390:03 - also give the author email address let's
1390:05 - say here I have given my email address
1390:07 - you can also give your email address now
1390:09 - here you need to call this find packages
1390:12 - this uh method so what it will do it
1390:14 - will look for this Constructor file in
1390:16 - each and every folder and where it will
1390:19 - get this particular file that folder
1390:20 - would be considered as my local package
1390:22 - okay so this is the idea to create our
1390:24 - local package okay so that's why we
1390:27 - created this uncore init.py because I
1390:30 - want to make this SRC folder as my local
1390:33 - package and how it will get to know with
1390:35 - the help of this find package method
1390:38 - okay so this find package method it will
1390:40 - find everywhere in every folder and it
1390:43 - will look for this particular uncore
1390:45 - uncore dop file wherever it is present
1390:48 - it will create that particular folder as
1390:50 - my local package clear guys this concept
1390:52 - is clear yes or no you can let me know
1390:54 - in the chat
1391:02 - if yes just write clear in the chat so
1391:04 - that I can get to
1391:06 - know okay
1391:08 - great now how to install the setup.py
1391:11 - how to install the setup.py for this I
1391:13 - will be utilizing my requirement. txt
1391:15 - file okay I'll be utilizing my
1391:17 - requirement. txt file so here I'll just
1391:19 - write one particular line I'll just
1391:21 - write hypen space Sorry hypen space dot
1391:25 - okay hyen eace dot if you just write
1391:28 - this particular line automatically
1391:30 - whenever you will be set uping that
1391:31 - requirement text it will look for that
1391:34 - setup.py file okay then it will open
1391:37 - that setup. Pi file then it will install
1391:38 - everything got it so whenever it will
1391:40 - install everything that means you have
1391:42 - done the installation of the local
1391:45 - package now let me show you so I'll open
1391:47 - my terminal
1391:48 - again I'll clear
1391:50 - it now here I'll just write python sorry
1391:54 - uh peep
1391:58 - install
1392:00 - peep
1392:02 - install hypen
1392:04 - R requirement. txt okay I already added
1392:07 - that uh hypen eace dot uh yes hypen e
1392:13 - space dot in my requirements now it will
1392:19 - work see now setup. Pi has been
1392:22 - installed now if you see there would be
1392:24 - a folder automatically created called
1392:26 - medical cho. EG info okay if it is
1392:29 - generating this particular folder that
1392:30 - means you are done with the installation
1392:33 - okay and inside that you will have some
1392:34 - of the metadata okay no need to worry
1392:36 - about some metadata related of your
1392:39 - package you have installed let's say
1392:40 - these are the package you have installed
1392:41 - okay as a local folder so these are the
1392:43 - information it will save here all right
1392:45 - now if I show you peep list now if I do
1392:48 - peep list operation in my terminal that
1392:51 - means I want to see what particular uh
1392:53 - Library I have now here you will see SRC
1392:55 - would be present I can show you SRC SRC
1392:59 - would be
1393:00 - present setup
1393:05 - Tool uh not SRC it would be medical
1393:07 - chatboard the name of the package I have
1393:10 - installed called medical chatbot in the
1393:11 - inside the medical chatbot I have this
1393:13 - SRC folder right now okay see this
1393:15 - medical chatbot was not present and see
1393:17 - this package is coming from my local
1393:18 - machine itself okay so that's why this
1393:21 - is needed now if I want to import
1393:23 - something from my helper I can easily do
1393:25 - it without any kinds of
1393:32 - error all right now let me uh push the
1393:35 - changes in my GitHub but before that I
1393:37 - will remove these are the
1393:45 - line so I'll just write uh
1393:50 - setup file
1393:52 - added and I'll comp it so you can
1393:56 - refresh my GitHub and you can go get the
1393:58 - code from there now same thing you can
1394:00 - do it on the numeral app so let me copy
1394:02 - this template file and I will go to the
1394:05 - Neal
1394:07 - app and here I will create one uh
1394:10 - template
1394:12 - file template. Pi
1394:16 - file let me Zoom a little bit now I'll
1394:19 - paste the code
1394:21 - here save now if I execute the template.
1394:25 - P file here so python template. Pi file
1394:28 - see it has automatically created okay
1394:29 - the same thing you can perform on the
1394:31 - Neal lab okay only you just need to
1394:33 - upload the model here upload the model
1394:35 - that thing you need to
1394:45 - do all
1394:49 - right now we have generated our folders
1394:52 - and file and uh everything is working
1394:54 - fine so far now let's add first of all
1394:57 - our environment variable okay so what
1394:59 - are the secret key and secret uh API
1395:01 - will be using so everything I'll be
1395:03 - mentioning here so in this case guys
1395:05 - what I need I think you remember so I
1395:08 - need something called my pine cone API
1395:11 - key the first thing I need my Pine con
1395:14 - API
1395:15 - key okay and the second thing I need
1395:18 - something called Pine con API
1395:23 - environment
1395:24 - so where I will get it I already
1395:26 - collected yesterday I think you remember
1395:28 - so I'll just open my
1395:32 - notebook and here I think I already
1395:34 - mentioned yeah so this is my API key
1395:35 - I'll just
1395:38 - copy and uh I'll open my environment
1395:41 - variable uh environment file and here I
1395:43 - will just paste
1395:44 - it and I will also copy my API
1395:50 - environment here I will paste it okay
1395:53 - now what you can do you can remove it
1395:54 - from here okay no need to show like to
1395:57 - your user or let's say if you are
1395:59 - uploading this thing on your GitHub
1396:00 - account so just try to remove them from
1396:02 - here okay otherwise people can also
1396:04 - access your credential I'm just keeping
1396:06 - it here just for the reference just to
1396:08 - understand the things I'll just remove
1396:09 - these are the uh index okay after
1396:12 - the yeah same same yesterday key because
1396:15 - I'm using the same same index same index
1396:17 - from my Pine con okay that's why if
1396:19 - you're creating any new index so you
1396:21 - need to collect that particular keys and
1396:23 - paste it here
1396:26 - okay all
1396:29 - right now see I have already added this
1396:33 - EMV file okay I have already added this
1396:36 - EMV file in my code but I already
1396:38 - committed my code in my GitHub now can
1396:40 - you see this EnV file in my GitHub is it
1396:43 - present guys no see it will
1396:46 - automatically ignored okay it will
1396:48 - automatically ignore by the help of this
1396:50 - dogit ignore file because if you open
1396:52 - this dogit ignore file and here they
1396:54 - have already written this kinds of EMV
1396:57 - file would be automatically ignored okay
1396:59 - let me show you so I think I can search
1397:02 - here
1397:04 - envv uh where is
1397:08 - EnV crl F do
1397:11 - EnV see guys Dov VNV EnV VNV these are
1397:16 - the files and for would be automatically
1397:19 - ignored during committing the code need
1397:21 - our GitHub okay so that's why we use
1397:23 - this method to create any kinds of
1397:25 - secret uh
1397:28 - credential okay another thing you can do
1397:30 - you can open up your environment
1397:32 - variable environment
1397:34 - variable so it is already available
1397:37 - inside your system now here you can
1397:39 - click on the environment variable and
1397:41 - here you can create a in uh variable key
1397:44 - as well as the value you are using so
1397:46 - both you can do it but this is the
1397:48 - method actually people uh usually use
1397:50 - nowadays okay instead of reading the uh
1397:53 - configuration file file from our system
1397:55 - itself okay yeah and to read this file
1397:58 - I'll be using one particular Library
1397:59 - okay so the library name is uh python.
1398:02 - EnV let me just
1398:04 - write
1398:07 - um I think I already added this
1398:12 - thing okay so there is a library
1398:15 - called EnV dot e NV Pi
1398:22 - Pi
1398:25 - yeah so this is the package name I'll
1398:26 - just
1398:28 - copy and here I will mention inside my
1398:31 - uh requirement
1398:35 - file now let me install it
1398:52 - again okay done
1398:55 - now we have also added our confidential
1398:57 - secret as well okay now what I need to
1398:59 - do I'll be start implementing the
1399:01 - component one by one right now so the
1399:03 - first thing what I need need guys if I
1399:05 - open my notebook I think you remember uh
1399:08 - the first thing yesterday we did we
1399:10 - first of all uh worked with our data
1399:13 - injection part that means data component
1399:15 - so I will copy the same function okay
1399:18 - I'll just copy the same function and
1399:20 - here I think we remember we created one
1399:23 - helper Pi inside SRC I will open the SRC
1399:26 - folder and here I will open this helper.
1399:28 - pi and here I will just mention this
1399:30 - particular function okay so most of the
1399:32 - code I'll just copy paste from my
1399:34 - notebook itself because we have already
1399:36 - done the experiment and we saw
1399:37 - everything is working fine now what is
1399:39 - our task I just need to convert
1399:41 - everything to the modular coding okay so
1399:43 - this is the thing I'm just showing
1399:44 - that's why yesterday I did The Notebook
1399:46 - experiment and today I'm referring that
1399:49 - particular notebook and I'm just writing
1399:50 - the modular coding okay all right
1399:54 - now I need this directory loader package
1399:56 - and as well as this Pi PDF loader so I
1399:59 - can copy from here only so directory and
1400:01 - Pi PDF loader I'll copy this thing and
1400:04 - here I will
1400:06 - mention and let me select my environment
1400:09 - I think it is already selected my
1400:12 - medical Chat bar yeah
1400:15 - done now tell me what is the second
1400:18 - thing you need to
1400:19 - add what is the second thing you need to
1400:21 - add just open the notebook and try to
1400:24 - see here the second thing I need to add
1400:27 - my uh uh text splitter okay I think
1400:29 - remember we are uh converting our conver
1400:32 - like Corpus to chunks why I I was
1400:34 - converting our Corpus to chunks because
1400:36 - of the model input model input token
1400:38 - limit limit okay so that's why I was
1400:41 - creating this particular function okay
1400:43 - so I'll copy this particular function as
1400:45 - it is I'll open my helper. pi and here
1400:49 - I'll mention it and again I need one
1400:52 - particular Library recursive character
1400:54 - text splitter again I will open my
1400:56 - notebook and from here I will
1401:01 - copy now guys tell me this method is
1401:04 - easy for
1401:07 - you are are you are you getting like
1401:09 - confident to write the code how to write
1401:11 - the modular coding after doing the
1401:12 - notebook experiment yes or no because
1401:15 - same code I'm just copy pasting from my
1401:17 - notebook only and I'm just arranging my
1401:19 - folder structure yes or no
1401:22 - guys
1401:25 - you can let me know in the
1401:28 - chat
1401:32 - great now going forward whenever you are
1401:35 - implementing any kinds of projects as
1401:37 - end to end the first thing create the
1401:39 - project architecture create the project
1401:41 - architecture then try to implement these
1401:43 - are the component in your notebook at
1401:45 - the very first then try to convert that
1401:48 - notebook as the modular coding I'm
1401:52 - doing
1401:54 - all right now again let's open my uh
1401:57 - trials. ipnb and see our third component
1402:00 - okay so third component was nothing but
1402:02 - uh downloading the model from the
1402:04 - hugging face I will copy this function
1402:06 - as it is and here I will mention
1402:10 - it here I will mention it now what I
1402:13 - need I need this hugging face embedding
1402:15 - package so again I will open my trials.
1402:17 - ipnb and from here I will copy this code
1402:20 - copy this
1402:21 - import and here I will paste it
1402:27 - [Music]
1402:29 - done now anything I need let me see
1402:33 - after downloading embedding uh no
1402:35 - everything is fine everything is fine
1402:37 - now uh your Pine code Cod code will
1402:39 - start okay that means you need to store
1402:41 - your vector right now so this code I can
1402:44 - write in a separate file I'll tell you
1402:45 - how to organize this thing so first of
1402:47 - all I showed you the helper function
1402:49 - implementation okay so this uh this file
1402:52 - should be my helper file
1402:56 - yeah now I'll be using this helper file
1402:57 - and I would I would be able to import
1403:00 - this particular uh function one by one
1403:02 - okay whenever I need it instead of
1403:04 - writing again and again okay inside my
1403:06 - component just follow the architecture
1403:09 - and following
1403:10 - the uh code okay one one by one okay
1403:17 - great all right now let me show you uh
1403:21 - how we can store the data again so so
1403:24 - I'll I'll what I will do I'll just again
1403:26 - remove this index from my pine cone
1403:29 - let's instore our index again so what I
1403:31 - will do uh I'll just remove this index
1403:34 - so I'll just click
1403:35 - here and I'll just delete this
1403:39 - index you need to give the name so it's
1403:45 - medical medical
1403:50 - chatbot you can also load the existing
1403:53 - index it is also possible but I'm
1403:55 - showing because I have done the modular
1403:57 - coding now I just want to test it
1403:59 - whether everything is working fine or
1404:00 - not whether it is able to create the
1404:01 - index or not okay that is why I'm just
1404:03 - creating this thing so now let me delete
1404:07 - index now it would be deleted after
1404:09 - sometimes yeah it has
1404:11 - deleted all right now what I need to do
1404:13 - I need to write uh the data uh that
1404:17 - means my uh data push uh I mean uh
1404:19 - Vector Pusher code okay that means I
1404:22 - need to convert my uh Tes two vectors
1404:24 - and I need to push them to my Vector DB
1404:26 - that particular code I need to write so
1404:28 - I'll be again referring the same
1404:29 - notebook I think I yesterday I already
1404:31 - wrote that code this is the code I was
1404:33 - initializing my pine cone that then I
1404:35 - was just sending my data to the Pine con
1404:37 - okay so I'll be referring the same code
1404:39 - so for this what I need to do uh I'll be
1404:42 - using one particular file here called
1404:44 - store index. Pi okay this file I'll be
1404:47 - utilizing to push my Vector to the
1404:49 - vector DB okay so here first of all what
1404:51 - I need guys
1404:54 - if I want to push my Vector to Vector DV
1404:56 - first of all I need to load my PDF file
1404:58 - from the folder itself so let me import
1405:00 - so from
1405:02 - SRC do help
1405:05 - part import first of all I need what I
1405:09 - need this load PDF okay this function so
1405:11 - let's import load PDF okay after load
1405:13 - PDF what I need I need this function
1405:17 - text splitter so let's import text
1405:20 - splitter then after that what I need I I
1405:23 - need this download hugging face model
1405:25 - okay so this one so I'll just also
1405:27 - import hug download huging Face
1405:29 - model okay then I also need to import
1405:32 - something called uh pine cone so let me
1405:37 - import so that's how you can import Pine
1405:39 - con you can either import from Lang
1405:42 - either import directly okay then I also
1405:45 - need to import my load EnV package okay
1405:49 - so I'll just write
1405:51 - from from
1405:54 - EnV from EnV import load EnV okay load.
1406:00 - EnV because I want to read this
1406:02 - particular file Dov file and here I have
1406:04 - my credential okay primon credential and
1406:07 - if you want to access these are the
1406:09 - secret key you just need to take the
1406:12 - help from this EMV package okay and this
1406:13 - thing I have already installed here let
1406:15 - me show you as a python. ENB I already
1406:17 - installed here okay python. ENB so this
1406:19 - is the package now let me open this one
1406:22 - yeah
1406:25 - now first of all I need to load my EMV
1406:27 - file so that's how you can
1406:31 - load uh so for this I also need
1406:33 - something called operating system
1406:34 - package so import OS now let me show you
1406:37 - how it will read exactly so what I can
1406:40 - do I can open this EnV file and I will
1406:43 - copy the API key first of all and here I
1406:46 - will restore it so equal to I'll just
1406:48 - write OS do environment doget and here I
1406:53 - need to give the key
1406:55 - name okay the key name you are using
1406:57 - inside the EMV file okay this is the key
1406:59 - name okay now once you have loaded I
1407:02 - will also load my second one which is
1407:04 - nothing but my Pine con API environment
1407:06 - I will copy and I will give the name
1407:10 - here again I'll give the name
1407:12 - here now let me print and let me show
1407:15 - you whether it is able to read or not
1407:16 - I'll just print first of all my Pine con
1407:19 - API
1407:21 - key as well as I'll also read my Pine
1407:24 - con API
1407:26 - environment now let me execute this
1407:29 - particular file so I'll just write
1407:33 - python
1407:36 - store index uh.
1407:41 - Pi it should
1407:45 - work see guys uh this is my API and this
1407:49 - is my en environment key got it how I'm
1407:52 - reading it
1407:56 - okay now I need to create again one
1407:58 - index because I deleted my previous
1408:00 - index what I will do again I will go to
1408:02 - my pine cone and here I will uh first of
1408:05 - all copy my key I'll copy my key and
1408:09 - here I will paste
1408:10 - it so this is my key I think this is the
1408:13 - same
1408:14 - key this is my key and I also need
1408:17 - something called my environment so I'll
1408:19 - again create one index so create index
1408:21 - and here you can give the same name
1408:24 - medical medical
1408:27 - bot and dimension it's uh 384 I think
1408:31 - you remember the model actually you are
1408:33 - using sentence Transformer model uh the
1408:36 - output dimension of the vector 3 uh 884
1408:39 - and I'm using cosine metric then I will
1408:41 - create the
1408:46 - index now this is my environment name I
1408:48 - will copy and I'll paste it here which
1408:50 - is nothing but gcp
1408:52 - starter
1409:01 - done
1409:05 - okay now first of all what I need to do
1409:07 - I need to load my PDF so let me load the
1409:10 - PDF so here is the code I think I
1409:13 - already written yeah this is the code
1409:16 - I'll
1409:18 - copy and here I'll paste first of all it
1409:21 - will load the PDF and PDF is is present
1409:23 - inside my data folder now after that I
1409:26 - need to extract uh sorry I need to apply
1409:29 - the text splitter that means I need to
1409:31 - create a chunks so this is the code I'll
1409:34 - copy and uh here I'll paste
1409:37 - it okay after getting the chance I need
1409:40 - to download the embedding so this is the
1409:43 - code I'll
1409:44 - copy and here I'll will paste
1409:47 - it embedding download is also done now
1409:51 - uh what I need to do I need to
1409:53 - initialize my pine cone okay so this is
1409:56 - the code I think remember how to
1409:57 - initialize the pine
1410:00 - cone it will take your Pine con API key
1410:03 - which you are getting from the
1410:04 - environment variable and this is your
1410:06 - Pine con uh API environment okay we have
1410:08 - initialize the pine cone and now how to
1410:11 - store the
1410:12 - data so this is the code okay I'll copy
1410:14 - the same code from my
1410:18 - notebook this is the
1410:21 - code so so here I'm using pine con. from
1410:24 - text here I'm giving my text chunks and
1410:28 - also need to mention my index name so
1410:30 - index name is my nothing but my medical
1410:32 - chat
1410:34 - Bo so I'll copy the index
1410:40 - name this is the index
1410:44 - name done now it will uh convert your
1410:48 - data to embeddings and it will store to
1410:50 - the pine cone okay maybe that's it yeah
1410:53 - now let me execute this file and show
1410:55 - you whether it is able to uh push my
1410:58 - data or not so I'll execute this
1411:00 - particular file I'll
1411:03 - clear and I will execute this particular
1411:05 - file python
1411:07 - store index
1411:10 - dop so again it will take some time
1411:12 - because how many chks we have guys
1411:14 - yesterday you saw
1411:21 - remember anyone remember remember the
1411:23 - Chang
1411:24 - size how many Chang size we use uh
1411:27 - pushed yesterday in our Pine con
1411:32 - database uh yeah 7020 7020
1411:36 - right no no it's 7 not 700 7020
1411:41 - 7,20 20 chunks we had okay okay okay
1411:46 - great now it will take some time first
1411:48 - of all it will uh load the data then it
1411:51 - will create the chunks after after that
1411:54 - uh it will uh convert everything to the
1411:56 - embeddings then it will push to my Pine
1411:57 - con let me see it has started or not let
1412:00 - me refresh the
1412:08 - page not started yet let's wait for some
1412:11 - times in between I will take some
1412:13 - queries guys if you have some query you
1412:15 - can ask
1412:20 - me anyone having any query you can ask
1412:22 - me in
1412:44 - between okay uh should
1412:49 - start huh see it started guys okay now
1412:52 - it has pushed
1412:54 - 576 vectors can we use this same
1412:58 - projects template for creating Finance
1413:00 - related project as well yes right side
1413:03 - you can use it no
1413:05 - issue G push error where is G push Adder
1413:09 - maybe this is your problem with your git
1413:12 - AR is you can check
1413:18 - it uh no wores I will push my code you
1413:21 - can get from there
1413:23 - okay Karan Karan sorry Karan uh uh you
1413:26 - can also use this template for your
1413:28 - Finance related project as well okay
1413:30 - this is the common template you can use
1413:31 - it as it
1413:33 - is uh when we are creating medical B
1413:37 - Medical book
1413:39 - chatbot uh will it response to the
1413:41 - normal message like hello and how are
1413:43 - you uh yes it can answer maybe yeah it
1413:46 - can answer because you are using the
1413:48 - Preen llm now so yeah it will answer
1413:51 - I'll show you
1413:56 - and if you want you can also uh like
1413:59 - fine tune that particular model as well
1414:01 - it is also possible okay and uh in our
1414:04 - paid courses we have already integrated
1414:05 - guys if you don't know so this is our
1414:08 - paid version of this gentic B course so
1414:11 - in this syllabus we have added so many
1414:13 - topics let's say if you want to learn
1414:15 - how to F tune and all everything we have
1414:17 - added here even Lama index then uh we
1414:21 - we'll be also covering like some more
1414:22 - Vector DB okay we have some more
1414:25 - interesting project here so everything
1414:26 - would be covered detail here
1414:30 - okay so if you are interested you can
1414:32 - enroll for the
1414:44 - course let me see the progress okay
1414:51 - 2,680
1415:03 - it's taking too much time to give answer
1415:06 - of any questions is my system I got
1415:08 - response 6 Minute for this uh for
1415:11 - allergies Anu what is your system
1415:14 - configuration you can let me know
1415:16 - because for me I'm using 16 GB RAM and
1415:19 - code i7
1415:21 - processor uh yeah so if you want to uh
1415:25 - decrease the response time so what you
1415:26 - can do guys let me show you so I think I
1415:29 - already showed you the model right so
1415:31 - this is the model
1415:33 - link so here I was using 4bit model
1415:37 - maybe 2 bit model is also available let
1415:39 - me
1415:42 - see 4bit 4bit 8 bit 6bit huh 2 bit model
1415:47 - is also aailable can you see Q2
1415:50 - kin you can uh download this particular
1415:53 - model so this is the smallest version of
1415:54 - the model and you can see the size so
1415:57 - those who are having 8 GB of RAM and the
1416:00 - Codi 5 processor you can go with this
1416:02 - particular model um a 2 bit model OKAY
1416:06 - in this case actually I'm using 4bit
1416:07 - model you can see I'm using 4bit model
1416:13 - Q4 yes definitely you need it uh you can
1416:16 - also execute on the Neal LA but I'm not
1416:19 - able to do because it's taking so much
1416:21 - time for me to upload the model here
1416:23 - okay so what you can do you can start
1416:25 - uploading the model once this model is
1416:27 - uploaded you can uh write the same code
1416:30 - here also because Neal laab will provide
1416:33 - more Rams and all if you are having less
1416:38 - RAM and you can also do do it on the
1416:41 - Google collab as well but flas code
1416:43 - won't be running there you can only do
1416:45 - the experiment part The Notebook
1416:46 - experiment we did
1416:49 - yesterday so these are the alternative
1416:51 - you can follow I think
1416:53 - uh you can see guys uh one thing
1416:55 - actually you can do after the session
1416:58 - those who are having low configuration
1416:59 - PC you can go with this model two bit
1417:07 - model no see here you don't use any pkl
1417:10 - file okay ANUK it's
1417:21 - a
1417:35 - uh hello everyone am I
1417:42 - audible uh give give me a confirmation
1417:45 - guys am I audible to all of
1417:51 - you
1417:52 - okay sorry actually my system got hang
1417:55 - and I got
1417:57 - disconnected uh sorry sorry sorry
1417:59 - because like too many software I opened
1418:02 - that's why my OBS Studio got hang okay
1418:05 - and I got
1418:06 - disconnected connection was fine today
1418:09 - okay there is no issue with the
1418:12 - connection because live streaming like
1418:15 - uh it takes little bit
1418:21 - yeah
1418:25 - okay fine so maybe my this thing has
1418:28 - also stopped let me again do
1418:44 - it okay now I think again it will
1418:49 - start yeah so what I was talking about
1418:52 - about I was talking about uh if you are
1418:55 - having let's say less memory so what you
1418:58 - can do in this case you can use this uh
1419:00 - eight uh two bit model guys okay two bit
1419:02 - model from the from
1419:21 - here
1419:26 - okay now maybe
1419:29 - uh it is
1419:33 - running okay let's store till this point
1419:35 - I will stop the
1419:37 - execution so let's say I have already
1419:40 - stored my Vector so let's store till
1419:44 - 5,728 okay so you can complete the uh
1419:48 - like this Vector upload operation um
1419:51 - until it gets over okay till your
1420:01 - 720
1420:03 - fine now let me push the code so I'll
1420:08 - quickly push the code
1420:10 - so uh store store index
1420:20 - edit
1420:26 - now I think you will able to see the
1420:31 - code or maybe I can what I can do
1420:38 - um um whenever I'm implementing this
1420:41 - thing so in between I can start my
1420:48 - progress I'll upload all the data again
1420:50 - just a minute
1420:53 - or let's keep it let's let's try it if
1420:54 - it is not giving correct response then I
1420:56 - will again store
1421:19 - it and guys uh if you don't know
1421:22 - actually there is a webinar of the
1421:24 - generative AI uh you don't know U or not
1421:29 - let me show you so there is the webar
1421:33 - guys so it would be happened this is the
1421:35 - date so let me share the registration
1421:37 - link as well so please join this webinar
1421:40 - guys so Krish S and sudans S would be
1421:43 - there so they will be discussing so many
1421:45 - things about generative AI so this is
1421:47 - the uh link I can give
1421:50 - you
1421:54 - so this is the webinar link so let me
1421:56 - open this one so you can register
1422:03 - here you can uh give your name email
1422:06 - address mobile number and which state
1422:08 - you are from and you can submit the
1422:12 - form and here is the video you can go
1422:20 - through
1422:22 - all
1422:26 - right okay now let's complete the
1422:28 - project guys because we are almost done
1422:30 - now what I need to do we have completed
1422:32 - our store index okay now we are able to
1422:34 - store our Vector to our Vector database
1422:37 - now what I need to add I need to add my
1422:40 - uh app component okay because I need to
1422:42 - uh create my front end right now so for
1422:45 - this actually what I need to do um just
1422:47 - a
1422:50 - minute uh yes so so I just need to uh
1422:54 - first of all give the prompt here so I
1422:57 - think you
1422:58 - remember we created one prompt. Pi here
1423:00 - so let me open this file and yesterday I
1423:03 - prepared one prompt here so let me show
1423:05 - you the notebook so here is the prompt I
1423:07 - will copy this prompt as it is and in
1423:10 - the prompt. pi I will add this
1423:19 - one okay now what will happen actually U
1423:22 - you don't need to directly write the
1423:24 - prompt inside your code so instead of
1423:25 - that what you can do you can mention it
1423:27 - like that okay so it would be pretty
1423:29 - much good for you now once it is done I
1423:31 - will open my app.py and I will uh write
1423:34 - the rest of the code here so I'll just
1423:36 - copy paste the same code I created so
1423:40 - inside app.py first of all let me import
1423:43 - flask so
1423:45 - from uh
1423:48 - flask I need to
1423:50 - import
1423:55 - plusk then I also need something called
1423:58 - render template I will tell you why you
1423:59 - need random template why you need flask
1424:02 - okay everything I'll be discussing
1424:07 - about yeah now I also need something
1424:10 - called
1424:12 - Joni as of now let's import only
1424:15 - Joni and I also need something called
1424:20 - request
1424:22 - okay then uh here I also need to load my
1424:27 - uh embedding okay so for this I also
1424:29 - need to import this
1424:31 - embedding my download embedding uh
1424:35 - method we created then I also need to
1424:37 - initialize my pine cone because I will
1424:39 - be loading that particular index and I
1424:41 - will be extracting my Vector from there
1424:43 - so that's why I need I need this
1424:45 - particular Pine con package here then I
1424:49 - think you remember yesterday I was
1424:50 - importing some more things let me show
1424:53 - you uh where is The
1424:55 - Notebook let me open the notebook again
1424:58 - uh this is the notebook and let me close
1425:01 - these at the tab first of
1425:02 - all template I don't need uh store index
1425:06 - I don't need as of now helper I don't
1425:09 - need okay here here is The Notebook so
1425:12 - here if you see I was importing some of
1425:14 - the more Library called question answer
1425:17 - then C Transformer Ral question U and
1425:19 - prom template okay so this thing I need
1425:21 - to Al import here because I need to
1425:23 - create my Ral question answer object
1425:25 - okay to chat with my llm so let me
1425:28 - import
1425:32 - them so here is the
1425:34 - code now I also need myv because I need
1425:38 - to load my secret credential from that
1425:41 - file then I need to also load my prompt
1425:45 - okay this promp template so what I can
1425:46 - do okay so maybe it should
1425:50 - be hugging face sorry I deleted by
1425:53 - mistake yeah now I also need to import
1425:56 - this prompt template from my prompt so
1425:57 - what I can do I can just write from uh
1426:01 - SRC do
1426:04 - prompt import Star okay that means
1426:08 - whatever things actually I have inside
1426:10 - this prom. Pi everything just try to
1426:12 - import here okay now after that uh I
1426:15 - also need something called operating
1426:17 - system package so I'll just use uh
1426:19 - import o now at the very first I just
1426:22 - need to initialize my flask so app equal
1426:25 - to uh how many of you are familiar with
1426:27 - flask guys here have you ever worked
1426:30 - with flask like how flask Works how we
1426:33 - usually create the app with the flask
1426:34 - and all if you have some like little
1426:38 - little knowledge on this flask I think
1426:39 - this should be pretty much Clear how I'm
1426:41 - creating this application frontend
1426:43 - application you can let me know guys in
1426:44 - the
1426:46 - chat anyone uh worked with flask before
1426:49 - I think if if you have already worked
1426:51 - with with machine learning deep learning
1426:53 - so I think you know this flask little
1426:56 - bit no not okay so no issue I will
1426:59 - explain okay it's like very easy so
1427:01 - flask is a like framework in Python it
1427:04 - will give you uh the functionality to
1427:06 - create the web application here okay yes
1427:09 - and no need to worry about the like HTML
1427:12 - code and CSS code that code you can copy
1427:14 - paste from the website itself I will
1427:15 - show you some of the website even I copy
1427:17 - pasted the HTML and CSS code from the
1427:20 - website itself okay because I also don't
1427:22 - know like how to code in HTML and CSS no
1427:25 - need to worry
1427:26 - about so we usually Define the flask
1427:29 - object like that now what I need to do I
1427:31 - need to load my uh API environment so
1427:34 - what I can do I can open the store index
1427:37 - and this code I can
1427:41 - copy and I'll paste it here then first
1427:45 - of all I will load my embedding
1427:50 - model okay okay now what I need to do I
1427:52 - need to initialize my pine
1427:55 - cone so I think you remember how to
1427:58 - initialize the pine cone so here is the
1428:00 - code initializing the pine con so let
1428:02 - initialize our Pine con and it will take
1428:05 - your Pine con API and pine con API
1428:07 - environment so it is I'm reading already
1428:09 - from here now here you need to give the
1428:11 - index name so here this is my index name
1428:14 - I'll
1428:15 - copy and here I will give my index
1428:20 - name
1428:22 - done now if you have any existing index
1428:25 - okay in your Pine con let's say you
1428:27 - already have the index present and you
1428:29 - already have the vector there so what
1428:31 - you can do instead of creating it again
1428:33 - because we have already executed our
1428:35 - store index. pi and we have already
1428:37 - stored our Vector there now I just need
1428:40 - to load that I just need to load that
1428:41 - and I will be using that okay so for
1428:43 - this this is the particular code you can
1428:44 - use load index from the pine con see
1428:48 - Pine con do from existing index here you
1428:50 - need to give the index name in this case
1428:52 - this is my index name and this is the
1428:54 - embedding model I'm using this two
1428:55 - parameter you need to give okay once it
1428:58 - is done you need to copy the same code
1429:00 - yesterday you wrote here you need to
1429:03 - create the prom
1429:05 - template I think remember you need to
1429:07 - create the promt template then you need
1429:08 - to initialize your llm so now let's do
1429:11 - it I will open my
1429:13 - app.py and here is the
1429:18 - code here is the code so this is my prom
1429:22 - template and I'm just reading my prom
1429:24 - template from where guys from prom. PI I
1429:27 - think you remember because we have
1429:28 - already imported this thing inside my
1429:29 - app. Pi here okay now this is my prompt
1429:32 - it is coming from here and this is the
1429:34 - input variable user will give the
1429:35 - question and it will return me the
1429:37 - response and this is my model what is my
1429:39 - model model is present inside the model
1429:41 - folder and this is the location of the
1429:43 - model model type is llama maximum new
1429:46 - tokens it is uh just keep this default
1429:49 - number and temperature I'm setting to uh
1429:52 - 0.8 that means I'm just taking the risk
1429:54 - and I'm taking also Randomness so
1429:56 - whenever it will give me some response
1429:57 - it will also take the risk and
1429:59 - Randomness then it will give me the
1430:00 - response so once I got this thing I need
1430:03 - to initialize my QA bot that means QA
1430:08 - object so this is the Code retrieval QA
1430:13 - from chain type and here you need to
1430:14 - initialize your llm chain type stuff and
1430:17 - this is the doc uh Dockers so doers I'm
1430:20 - getting from here my Pine con object
1430:23 - that's it now you need to create the
1430:25 - default route first of all of your flask
1430:28 - so this is the default route I can
1430:30 - create like that so here you need to in
1430:34 - uh like give this decorator called app.
1430:36 - route and if user is open your uh let's
1430:40 - say host okay or let's say the URL you
1430:42 - will be getting I will execute and tell
1430:44 - you how this thing will work so it will
1430:46 - open one particular HTML file which is
1430:48 - present inside template do uh which is
1430:51 - present inside template folder the name
1430:53 - of the file is chat. HTML okay so here I
1430:56 - need to write the HTML code as of now
1430:58 - this file is empty but I need to write
1431:00 - the HTML code like how your eyi will
1431:01 - look like this particular code you need
1431:03 - to mention here okay now let me show you
1431:05 - how this thing will
1431:07 - work so now I will initialize my
1431:10 - flask so it will uh execute your code
1431:15 - here now let's say inside the chat. HTML
1431:19 - I can copy some basic HTML code
1431:22 - welcome
1431:25 - HTML page I can copy the code from
1431:31 - here maybe
1431:35 - example so this is the code I think I
1431:37 - can
1431:47 - copy let's see what is this page I'll
1431:51 - paste it
1431:56 - here then I will run run my
1432:00 - app.py python
1432:15 - app.py now it will tell you just open up
1432:18 - your local host and port number 5,000
1432:20 - let's open my Local Host so Local Host
1432:24 - port number 5,000 it's running on port
1432:27 - number
1432:30 - 5,000 uh see guys this is the screen I'm
1432:32 - getting from this code itself so now we
1432:34 - can also change the code now let's give
1432:37 - this
1432:38 - code uh let's give this HTML code what
1432:42 - happens if you know HTML and CSS so you
1432:45 - can create a beautiful website it's up
1432:47 - to you now if I again refresh see guys
1432:51 - coming soon I'm getting that means my
1432:54 - web app is working fine and I got one
1432:56 - API okay I got one API this is the API
1432:59 - guys my uh like project is running on
1433:02 - this uh host and Port okay this is the
1433:06 - host and this is the port you can also
1433:08 - change it so what you can do here you
1433:10 - can give host uh host is equal to host
1433:14 - is equal to uh you can give like that 0
1433:18 - point
1433:19 - 0.0 uh
1433:22 - zero and Port is equal
1433:24 - to you can give let's say 8080 any kinds
1433:28 - of Port you can mention let's give 80 80
1433:31 - now if I stop the execution
1433:33 - again now if I again uh rerun my app. Pi
1433:37 - you will see it will run on port number
1433:39 - 8080 right
1433:48 - now see guys it's running on port number
1433:52 - 8080 now I'll give the permission now if
1433:54 - I open and here I will give my port
1433:57 - number
1433:58 - 8080 now see guys your application is
1434:00 - running here got it now here what you
1434:04 - can do you can visit this website called
1434:08 - bootstrap
1434:10 - bootstrap uh sorry it should be
1434:14 - bootstrap
1434:16 - bootstrap so this is the website we
1434:19 - usually copy any kinds of template so
1434:21 - here I created one chatbot template so
1434:23 - here is the example so in the example
1434:25 - you will see lots of example would be
1434:27 - there any kinds of template you can copy
1434:29 - from here it will uh give you the HTML
1434:30 - and CSS code with respect to that either
1434:33 - what you can do you can search for
1434:35 - chatbot HML and
1434:38 - CSS
1434:41 - template free okay so there are some
1434:44 - website it will give you some of the
1434:46 - template you can just download from here
1434:48 - see this this kinds of chatbot actually
1434:50 - templ template you will get so you can
1434:52 - download it and it's completely free you
1434:53 - don't need to pay for anything if we
1434:56 - have to put this on any
1434:57 - website uh then where we need to provide
1435:00 - the details no see the same thing you
1435:03 - can do the deployment okay I think you
1435:04 - saw how we we we usually do the
1435:07 - deployment on AWS so that time it will
1435:09 - run on the AWS URL okay not in the Local
1435:12 - Host we'll show the deployment Vic okay
1435:15 - in our paid courses it already designed
1435:18 - see these kinds of chatbot template
1435:19 - actually will get
1435:22 - okay so what I have done actually I
1435:24 - already downloaded one particular
1435:25 - template and I already copy pasted the
1435:27 - HTML code let me show you how it will
1435:29 - look like so this is the code and you
1435:31 - don't need to worry about for the HTML
1435:33 - code so this thing actually you can
1435:36 - download from the internet if you don't
1435:37 - know anything so this is the HTML code
1435:40 - from the chatbot I'm using and with
1435:42 - respect to that you have one uh CSS file
1435:46 - as
1435:47 - well so the name of the CSS file is
1435:52 - style let me write
1435:55 - style.
1435:57 - CSS so let me show you the style.
1436:03 - CSS so this is the CSS code okay so from
1436:07 - that uh website you can download this
1436:09 - particular thing now if I go to my
1436:12 - website right
1436:13 - now and if I
1436:15 - refresh now see that's how my chat bot
1436:18 - look like isn't it uh B beautiful app
1436:21 - guys tell
1436:23 - me uh how this template look like to all
1436:27 - of you because I personally like this
1436:29 - template uh actually I just copy paste
1436:31 - the code from the Google itself so here
1436:34 - you can give your input message and it
1436:36 - will give you the
1436:37 - response yes I will give the code no
1436:39 - issue let me just comit the code as well
1436:41 - so what I can do I can
1436:44 - give
1436:46 - templates
1436:49 - added
1436:52 - so this is the medical uh chatbot kinds
1436:54 - of Bot I have added uh yeah so now see
1436:58 - how to change the photo of this one so
1437:00 - here is the like one Nar photo I have
1437:02 - added how we can do it you can open the
1437:04 - HTML code so here you will get one jpz
1437:09 - file see guys this is the jpz file PNG
1437:13 - file okay so this is the URL of the
1437:16 - photo actually so what I did I searched
1437:19 - the photo in Google and I just collected
1437:21 - the image URL see copy the image address
1437:25 - if you copy it now see you can use any
1437:28 - of
1437:29 - chatbot medical medical medical
1437:33 - logo you can open and you can copy any
1437:36 - kinds of photo URL and you can paste it
1437:38 - here so that photo will appear here
1437:40 - actually let me show you that photo will
1437:42 - appear
1437:48 - here uh yes you can use this code okay I
1437:50 - already uh committed the codee in my
1437:52 - GitHub you can uh clone from here you
1437:55 - can copy this template as it is guys
1437:57 - okay no need to worry about how to write
1437:59 - this thing because this thing is already
1438:00 - available on the internet okay if you
1438:02 - look for lots of template people are
1438:04 - giving free these are the free template
1438:06 - you can use it as it
1438:19 - is
1438:23 - okay all right now we'll be writing our
1438:26 - final
1438:28 - route so basically I'll be taking the
1438:43 - question
1438:48 - uh yeah and and see guys if uh you can
1438:51 - enroll for the courses and you can get
1438:53 - everything for free because we have lots
1438:55 - of template as well okay we'll also give
1438:57 - that rebuild
1439:01 - template okay now let's write our final
1439:04 - uh route so this is the final
1439:10 - route so here what I'm doing guys so
1439:13 - whenever user is giving any kinds of
1439:14 - masses okay so here whenever user is
1439:16 - giving any kinds of masses I'm just
1439:19 - taking the masses in the back as you can
1439:20 - see I'm just writing request. form and
1439:23 - it will give you the message and this
1439:24 - message will come here then I'm saving
1439:26 - the message to the input variable and
1439:28 - I'm also printing in my terminal after
1439:30 - that I'm just sending this input to the
1439:32 - QA QA object okay because QA object we
1439:34 - have already defined here okay then it
1439:36 - will give you the
1439:37 - response that particular response I'm
1439:39 - printing in my terminal as well and as
1439:41 - well as I'm also sending that particular
1439:43 - response to my UI here okay now let me
1439:47 - uh let me show you how it is working or
1439:48 - not so what I will do I will stop the
1439:51 - execution
1439:53 - again I will clear the terminal and
1439:56 - again let's execute my app.py sorry
1439:59 - python it should be python
1440:15 - app.py okay it's running now let's go
1440:17 - back and refresh the page again
1440:26 - uh I think I can open it again so Local
1440:32 - Host port number
1440:36 - 8080 see now let's ask some questions so
1440:40 - here I can give uh what is
1440:43 - acne so the same question I asked
1440:49 - yesterday
1440:51 - and let's see see I asked the question
1440:54 - now uh it will take some time because
1440:56 - I'm uh doing the live streaming and all
1440:58 - so it will take some time to give me the
1441:00 - response okay but if I stop the
1441:02 - streaming so it will give me quick
1441:19 - response and the same thing we can do it
1441:21 - on the neural app so let me show you um
1441:24 - so what I will do I will copy this HTML
1441:28 - and CSS
1441:30 - code uh let's copy this HTML code and
1441:33 - open my Neal
1441:36 - LA and here I can give this
1441:44 - here also I need this static so inside I
1441:48 - have style. CSS
1441:55 - now let's copy the
1442:05 - code done now let's uh write the route
1442:19 - here
1442:35 - and uh this is the final
1442:48 - code
1442:52 - Pyon
1442:54 - app.py okay it's running now so now what
1442:57 - you need to do you need to copy this
1442:59 - URL and what is the port it is
1443:03 - using uh let me see it again it's 5,000
1443:07 - okay just paste it and give the port is
1443:09 - equal to
1443:12 - 5,000 uh okay bad request it's telling I
1443:16 - don't know because maybe my uh okay I
1443:19 - got discon Ed maybe that's why okay I
1443:21 - need to again rerun it let me see the
1443:24 - execution here see guys it's giving me
1443:27 - the response is it
1443:30 - correct acne is the common skin disease
1443:32 - characterized by pimples on the face
1443:35 - chest and back it occurs when the uh
1443:38 - porous of the skin becomes clogged with
1443:41 - the well dead skin cells and
1443:44 - bacteria see the guys eyi it is also
1443:47 - extracting the time the current time
1443:48 - actually you are asking the question
1443:51 - is it great
1444:03 - guys now you can ask any G of question
1444:06 - here it's up to
1444:18 - you
1444:23 - why it's giving bad request let me
1444:30 - Che everything is
1444:48 - good
1444:53 - okay I got the response see I think uh
1444:56 - who has asked the question if I give any
1444:58 - casual message whether it would be able
1445:00 - to answer or not see I've given hello I
1445:03 - happy to help however I don't have any
1445:04 - access to the external information or
1445:06 - context beyond what is provided uh the
1445:09 - text you gave me without more
1445:11 - information I can provide the definitive
1445:13 - answer or to your question can you
1445:15 - please provide the more context to
1445:16 - clarify your question got it so
1445:18 - basically here is uh the chatbot we have
1445:21 - implemented this is already dependent
1445:23 - upon my custom data I have given okay so
1445:25 - here I haven't given any external data
1445:27 - sources okay so this is only relying on
1445:30 - this PDF file okay so that's why it's
1445:32 - giving some warning before starting with
1445:33 - the conversation got it now you can open
1445:36 - this book you can open this book and you
1445:39 - can ask any kinds of questions so let's
1445:41 - ask another question so I'll find one
1445:43 - dis is
1445:48 - here
1445:55 - evention not this one I'll
1445:59 - take let's copy this disease
1446:02 - okay I don't know what is this let me
1446:04 - search on Google first of
1446:07 - all okay this is a medicine actually so
1446:10 - let's ask about the medicine so this is
1446:12 - my
1446:13 - bot tell me
1446:17 - about this medicine
1446:29 - so anyone is running with me guys anyone
1446:32 - here everything is
1446:48 - working
1446:59 - so you can go through this book and you
1447:01 - can ask different different question
1447:02 - different different medicine like uh for
1447:05 - this disease what would be the diagnosis
1447:07 - okay everything you can ask
1447:09 - here and make sure you are uh storing
1447:12 - all the vectors because I already stored
1447:14 - 5,000 something Vector here so make sure
1447:18 - you are storing all the 700 uh 7,000
1447:21 - and20 all the victory
1447:27 - here still running because my live
1447:29 - streaming is going on that's why a
1447:30 - little bit
1447:36 - slow okay this is the response see this
1447:39 - is used to rely many kinds of minor ax
1447:44 - and pains include headache muscles ax
1447:47 - back ax and tooth X so see this is one
1447:50 - kinds of medicine actually people use
1447:52 - for the
1447:53 - pain okay now you can see also this
1447:56 - medicine this is the
1447:59 - medicine now tell me guys how is this
1448:02 - project you like this project the
1448:04 - medical chatbot your custom medical
1448:06 - chatboard yes or
1448:12 - no because we are done with the
1448:18 - implementation
1448:20 - how is this project guys you can let me
1448:21 - know in the
1448:36 - chat all
1448:41 - right okay thank you thank you guys so
1448:44 - you can try and uh those who are having
1448:47 - uh less configuration you can use the
1448:49 - 2bit model okay I already showed you the
1449:12 - sources and uh please implement this
1449:14 - particular project guys those who
1449:16 - haven't implemented and you can tag me
1449:18 - on LinkedIn so this is my LinkedIn
1449:19 - profile guys so here you can also tag me
1449:22 - after the implementation uh you can also
1449:24 - tag ion so we'll be happy to see that
1449:26 - like you have implemented
1449:28 - something
1449:31 - okay can I add this project in my resume
1449:34 - yes vikash you can add it because this a
1449:36 - good use cases okay in the generative AI
1449:39 - uh like field you can add this
1449:42 - project and please implement the project
1449:44 - guys please implement this project let
1449:46 - me commit the code as
1449:48 - well
1450:01 - and let me write down the further steps
1450:03 - to run this project so let me complete
1450:05 - the readme as
1450:10 - well so first uh first of all you need
1450:13 - to execute that stored index. Pi because
1450:16 - you need to store your index first of
1450:17 - all then after that you need to execute
1450:24 - app.py okay then you need to open up
1450:26 - your local host and
1450:31 - Port then I can mention the take stack I
1450:34 - used in this
1450:36 - project now let me comit
1450:48 - them
1451:08 - done okay so guys yes this was our
1451:12 - medical uh chatbot
1451:14 - implementation and I have showed you the
1451:17 - entire uh like process
1451:20 - sir may I know prerequisite for this
1451:22 - course please uh no need any
1451:25 - prerequisite okay uh you can still uh
1451:28 - still join the course if you don't know
1451:29 - anything so we'll give all the
1451:48 - idea
1451:49 - and guys uh there is uh exciting news
1451:52 - for everyone we are also coming with
1451:54 - mlof session okay on this uh Monday from
1451:58 - this Monday so please join the session
1452:00 - those who are interested in mlops so you
1452:02 - can join
1452:07 - here and if you are interested in Hindi
1452:10 - so in our Hindi Channel also uh this
1452:13 - medical chatbot implementation will come
1452:15 - so it will take by Sun sir so you can
1452:18 - join uh today
1452:20 - okay see you can uh just notify click on
1452:22 - the notify
1452:25 - button deep planning and machine
1452:27 - learning fails under the data science uh
1452:30 - yes this is under the data
1452:38 - science yeah and guys yeah you can
1452:40 - mention this project in your resume
1452:42 - there is no issue with that because this
1452:43 - is a good use
1452:45 - cases yeah so MLF session actually it
1452:48 - would be conducted on our this Inon
1452:50 - Channel okay so here actually you will
1452:52 - get the MLF
1453:03 - session and uh the detail of this MLF
1453:05 - course would be shared soon okay just
1453:07 - stay tuned with our Channel everything
1453:09 - would be shared here no this is not a
1453:11 - last session maybe couple of session
1453:12 - would be there after
1453:14 - that small uh language model is
1453:18 - different
1453:19 - uh t0 llm small mod small language model
1453:23 - is different t0
1453:25 - llm I didn't got your question
1453:31 - uh okay so uh sorry guys so there uh
1453:34 - today's the last last session of our
1453:35 - generative AI okay because we have
1453:37 - already covered everything okay we have
1453:40 - already covered everything if you go
1453:41 - here if you go to the live section so
1453:44 - from the day one
1453:46 - itself uh see uh from the introduction
1453:48 - itself itself actually everything has
1453:50 - been covered Lang chain covered Hing
1453:51 - face covered openi covered uh n2n
1453:54 - project has been also covered then
1453:56 - Vector database covered then uh yeah
1453:59 - open source llm is also covered then I
1454:01 - also showed you the how use uh how to
1454:03 - use open source llm and create the Inn
1454:05 - project as
1454:13 - well and uh and if you want to learn
1454:17 - more about generative
1454:19 - so that is a paid version of our course
1454:21 - so there actually we have added so many
1454:23 - things so let me again show you so this
1454:25 - is the page guys so let me share you the
1454:27 - link so if you are interested you can
1454:29 - enroll for the course and here we have
1454:31 - already covered uh we we'll be we'll be
1454:34 - covering lots of things here let's say
1454:35 - fine tuning llms and all so you can
1454:38 - visit the syllabus here okay it's a big
1454:39 - syllabus
1454:46 - guys metal Lama API is free to use or
1454:50 - paid like open meta Lama there is no
1454:52 - Lama API okay we have downloaded the
1454:54 - model
1454:57 - because so link is uh in the chat guys
1455:00 - so you can visit this courses you can go
1455:02 - through the cabus and you can enroll for
1455:03 - the
1455:13 - course and uh why this course would be
1455:16 - like more uh you can say interesting
1455:18 - because we are also giving the job
1455:20 - assistant if you see here if you go uh
1455:22 - read this description and all about so
1455:24 - it is starting from uh 20th
1455:27 - January and uh this course version is
1455:30 - English okay and duration is 5 month it
1455:32 - would be conducted uh 10 to 1 p.m. okay
1455:36 - IST Saturday and Sunday and this should
1455:39 - be live course okay this should be live
1455:40 - lecture actually and we'll be also
1455:42 - providing the job assistant doubt
1455:44 - clearing session okay so each and
1455:46 - everything would be there so let's say
1455:48 - if you having any issue okay with your
1455:51 - like resume and all job and all so we'll
1455:53 - be like conducting a session with you so
1455:56 - we'll also build your resume we'll give
1455:57 - you the carer advice okay everything
1455:59 - would be done
1456:06 - here is this course curriculum changes
1456:09 - on a new
1456:11 - model uh see if you go through the
1456:13 - course we have added so many open source
1456:15 - llm here also new model as well okay we
1456:18 - have added f con Google Pam okay so we
1456:21 - have also added this thing as of now you
1456:23 - learn like Lama 2 model okay but there
1456:25 - are also lots of Open Source model
1456:27 - available let me show you if I search
1456:29 - for open
1456:30 - llm okay maybe I already showed you list
1456:32 - of open llm so there are lots of llm
1456:35 - there are lots of llm you can use so
1456:37 - we'll be covering them also
1456:47 - here
1456:58 - and see guys uh here you you will get
1457:00 - like one year dashboard access and uh
1457:03 - assessment uh in all the modules okay
1457:05 - you will be getting assessment for all
1457:07 - the module and guidance by the expert
1457:08 - and mentors as I already told you if you
1457:10 - are having any issue with your career
1457:12 - and all if you're not getting any jobs
1457:13 - so we'll be giving the job assistant uh
1457:15 - like opportunity as well then course
1457:17 - resources definitely will get then live
1457:20 - lecture okay like live lecture you will
1457:23 - get from here and quizzes and assignment
1457:25 - you will be getting from each and every
1457:27 - lecture okay then you'll be getting free
1457:29 - neural lab access as well so we'll also
1457:31 - show like how we can use our neural lab
1457:34 - efficiently here because many of you are
1457:36 - having less configuration machine okay
1457:38 - so we'll also show you like how we can
1457:40 - use neurolab here as
1457:44 - well then uh here you will get dedicated
1457:47 - Community Support
1457:54 - promise I'm in this course duration is 5
1457:57 - month so in a 5 month jna is
1458:00 - boosting so much okay so we'll be taking
1458:03 - care that yes so let's say in this five
1458:06 - uh five month actually if any changes is
1458:08 - there if any new thing is coming we'll
1458:10 - also Showcase in front of you okay we'll
1458:12 - also tell you that thing no issue with
1458:17 - that yes we'll also integrate mlop Tool
1458:20 - uh like we'll also show like how to
1458:22 - integrate Docker this thing how to do
1458:24 - cicd deployment everything will show
1458:27 - there okay the efficient deployment
1458:29 - process will show
1458:47 - there
1458:51 - and guys this course is uh also for
1458:54 - students and working professional as
1458:55 - well even if you are an enterpreneur
1458:58 - okay who are looking for uh using this
1459:00 - latest AI technology in your day-to-day
1459:02 - business okay so for you also you can
1459:04 - refer this course okay so this course is
1459:07 - for everyone if you are a student if you
1459:09 - are job professional if you are let's
1459:11 - say enterpreneur anyone can refer this
1459:13 - course we'll be covering each and
1459:15 - everything in the field of generative
1459:17 - High guys okay after leing this course
1459:19 - you will become a champion in the field
1459:21 - of Genera VI this is the like guarantee
1459:23 - I can
1459:29 - give see building llm uh we don't do it
1459:33 - usually okay building llm is not a easy
1459:35 - easy
1459:37 - task power okay see llm building is not
1459:40 - a easy task for this you need resources
1459:42 - you need cost you need a good
1459:44 - configuration machine okay because we
1459:47 - have already llm okay now we just need
1459:49 - to use them we can fine tune them fine
1459:52 - tuning we will show like how to fine
1459:54 - tune on the custom data if this uh llm
1459:57 - is not working for your specific task
1459:58 - you can still fine tune
1460:09 - that okay and guys please join this
1460:12 - webinar everyone so there is the webinar
1460:14 - actually conducted by creation sudans s
1460:17 - so here is the link we have already
1460:19 - given let me share it again please
1460:21 - register uh of yourself here and please
1460:24 - join the this uh uh like webinar okay so
1460:27 - you'll be learning a lot lot from
1460:31 - here and here's the video guys so what
1460:33 - are the things actually he'll be
1460:34 - covering and all so you can go through
1460:36 - this particular video it is already
1460:37 - available in our Inon
1460:44 - Channel guys now if you are having any
1460:47 - doubt you can ask me in the chat I'll be
1460:49 - taking couple of Doubt then I will be
1460:50 - ending the
1460:59 - session any any doubt guys any question
1461:02 - you you are having you can ask me then I
1461:04 - will end the
1461:14 - session so guys uh so far how was your
1461:16 - session guys uh are you able to learn
1461:20 - something in the field of generate
1461:21 - because we have covered so many things
1461:24 - like it's completely free even you won't
1461:26 - be getting these kinds of content
1461:29 - anywhere Jin if it is there okay if they
1461:33 - already post the API and all okay we'll
1461:35 - be also covering JY okay no need to
1461:37 - worry about because this is the recent
1461:39 - research uh recently it has came to the
1461:41 - market okay they haven't announced so
1461:43 - like
1461:47 - yet
1461:50 - yeah thank you thank you
1461:54 - Karan and thank you for your
1461:56 - contribution yesterday also yeah thank
1461:59 - you thank you power
1462:05 - also and if you have any query you can
1462:08 - ask us anytime no issue okay perfect
1462:11 - guys so let me talk about the agenda
1462:13 - today okay now uh many people have been
1462:17 - talking about generative AI they've been
1462:20 - talking about open AI llm models they're
1462:23 - talking about open source llm models
1462:25 - like lama lama 2 you have mistol you
1462:28 - have lot of different different models
1462:30 - and every day probably someone is coming
1462:32 - up with some good llm models right but
1462:35 - when I talk about Google right Google
1462:36 - recently came up with something called
1462:38 - as gini right and uh it after seeing a
1462:43 - lot of practical application after
1462:45 - implementing multiple things uh I could
1462:48 - see that it really have a lot of
1462:50 - capabilities so that is the reason why
1462:52 - I'm keeping this entire dedicated
1462:54 - session specifically for gini and just
1462:58 - to make you understand today what all
1463:00 - things we are specifically going to do
1463:02 - I'm going to write down the agenda what
1463:04 - all things we are basically going to do
1463:05 - today right so let me just share my
1463:09 - screen and let me know whether you are
1463:13 - able to see my screen or not okay just a
1463:17 - second
1463:20 - so just let me know whether you are able
1463:23 - to see my screen just give me a quick
1463:30 - confirmation just a second uh my face is
1463:34 - not visible why I just try to change
1463:37 - things okay so everybody's able to see
1463:41 - my screen so which view do you like
1463:44 - better this view or this
1463:47 - View
1463:49 - this view is different which view this
1463:51 - view I hope everybody likes it better
1463:55 - okay yeah visible so I'm going to
1463:58 - basically talk about the
1464:00 - agenda and uh so first of all we'll
1464:03 - understand
1464:04 - about what this Google gin llm model is
1464:07 - all about okay so we'll understand this
1464:11 - we also say this as multimodel okay why
1464:14 - do we say it as multimodel we'll try to
1464:17 - understand this
1464:18 - multimodel um why it is good with
1464:21 - respect to vision and all that also
1464:23 - we'll try to discuss okay the second
1464:26 - thing is that we'll try to see a
1464:28 - practical
1464:30 - demo so we'll try to see a practical
1464:33 - demo using Google
1464:36 - giny okay we'll try to see a practical
1464:39 - demo using Google Jin Pro okay why
1464:44 - Google G Pro right now Google has just
1464:45 - provided this it also has huge capab
1464:47 - abilities and with the help of this you
1464:49 - can actually Implement both Text Plus
1464:52 - Vision use cases okay so you'll be able
1464:56 - to use both of them third thing after
1464:59 - this we'll try to create an end to
1465:00 - endend
1465:01 - project okay and we'll try to see this
1465:04 - end to end project ug Google gmany pro
1465:08 - okay so we'll do all these things in
1465:10 - this session we'll have a couple of
1465:11 - hours session we'll discuss step by step
1465:14 - what all things we are basically going
1465:15 - to do and considering this we going to
1465:18 - discuss more about this in terms of
1465:21 - practical implementation okay um till
1465:25 - now I think Google gini also like Google
1465:27 - did not I don't know about his research
1465:29 - paper that much information is not
1465:31 - available but a kind of brief idea you
1465:34 - can actually get it what exactly Google
1465:36 - Gemini does okay so everybody clear with
1465:39 - the agenda so please hit like if you are
1465:42 - liking this video I really want people
1465:44 - to be very much interactive right now
1465:46 - okay uh because end to endend project
1465:49 - everything I'll be explaining trust me
1465:51 - at the end of the Days end of this
1465:52 - session you will learn amazing things as
1465:55 - you go ahead you know and you'll get an
1465:58 - idea like how powerful this is and uh
1466:01 - with respect to text and vision use
1466:03 - cases this will be super amazing okay so
1466:05 - hit like and yes share with all the
1466:07 - friends out there if you have some of
1466:09 - the friends who are interested in this
1466:11 - things right so definitely do make sure
1466:14 - that you ping them right and uh over
1466:17 - there also you can actually do it okay
1466:20 - so in insta also we are live so again
1466:22 - for all the guys out there in insta and
1466:24 - in Twitter so we are live in four to
1466:26 - five platforms right now so please let
1466:28 - me know like how whether you're able to
1466:30 - hear me or not okay but all these things
1466:32 - we are going to discuss so Mohammad
1466:34 - mozak says hi Chris you're my role model
1466:36 - and I follow your videos I'm currently
1466:38 - working as an AI engineer UA Dubai
1466:40 - amazing amazing congratulation uh mazak
1466:44 - congrat I hope I'm pronouncing it right
1466:46 - okay so let's go ahead and let's further
1466:49 - discuss about the Google Gemini llm
1466:52 - model and why it is so good uh you have
1466:56 - to keep on motivating me to take more
1466:58 - and more more and more right so
1467:00 - definitely do hit like keep on putting
1467:02 - up your questions I'll take up all the
1467:04 - questions as once the session completes
1467:06 - and if there is some important thing
1467:07 - that I really need to answer it I'll
1467:09 - answer in between the session okay so
1467:13 - just give me a quick yes if you have
1467:14 - understood the agenda what all things we
1467:16 - are going to do in this
1467:18 - session yeah I hope everybody's got this
1467:22 - clear
1467:25 - idea yeah everyone a quick yes thumbs up
1467:30 - something okay agenda is very much Clear
1467:33 - we'll understand about Google giny we'll
1467:34 - see some demo then we'll do practical
1467:36 - demo we'll see how we can set up the API
1467:39 - keys and all and all these things okay
1467:42 - great so let's go first of all you need
1467:45 - to know about from where we are
1467:48 - basically teaching okay so here is the
1467:50 - entire in neuron platform uh if you
1467:52 - don't know about in neuron for the
1467:54 - people who do not know about Inon we do
1467:56 - come up with a lot of different courses
1467:58 - data plus web development every coures
1468:00 - as such and if you're interested in
1468:02 - learning any of the course from us okay
1468:05 - you can see you can just go ahead with
1468:07 - ion. just go and see different different
1468:10 - courses over here like generative AI
1468:12 - course we are coming up from this Jan
1468:15 - then we have machine learning boot camp
1468:17 - uh both English and Hindi and if I talk
1468:19 - about data analytics boot camp and mlops
1468:22 - production ready project so these are
1468:23 - the four uh four important courses that
1468:27 - we are specifically coming up with okay
1468:29 - so mlops production ready projects data
1468:32 - analytics boot camp machine learning
1468:33 - boot camp and finally generative AI so
1468:36 - if you are really interested to learn
1468:38 - from us you can go ahead and check out
1468:39 - all the courses okay um the other thing
1468:43 - is that in this
1468:44 - um if you do not have a a very powerful
1468:48 - system what we will do also is that you
1468:51 - can actually use neurolab okay because
1468:54 - today I'm also going to show you the
1468:55 - Practical implementation with the help
1468:57 - of neurolab what we will do is that we
1468:59 - will try to create our own environment
1469:02 - over here you can probably do the coding
1469:04 - that you specifically want okay so it it
1469:07 - gives you a entire working development
1469:09 - environment where you can write your
1469:10 - code and this all code will be running
1469:12 - in the cloud so if you do not have a
1469:14 - powerful system I would suggest go ahead
1469:17 - and check out about the neural laab
1469:18 - itself it is very much simple go to ion.
1469:21 - click on neurolab and start working on
1469:23 - this because at the end of the day when
1469:25 - I'm showing you practical implementation
1469:26 - we may be doing in this okay perfect so
1469:31 - welcome to the Gin era so I let me talk
1469:33 - about the story because initially people
1469:36 - made a lot of fun about uh you know
1469:39 - Google uh because of the demo that was
1469:41 - put up regarding gini Pro okay and I
1469:44 - hope many of you have heard about this
1469:46 - so gini's built from ground up for
1469:49 - multimodality reasoning seamless across
1469:52 - test images videos audios and code and
1469:54 - this was a demo that they had actually
1469:56 - put and I hope uh you have seen this
1469:58 - demo right I think they should have
1470:00 - removed this demo so this was the demo
1470:02 - that they had actually put okay and this
1470:04 - demo was not that true okay it was just
1470:07 - like taking images by image frame and
1470:10 - then probably combining and doing all
1470:12 - these things okay but at the end of the
1470:14 - day many people made fun of it you know
1470:16 - uh they came up with something amazing
1470:18 - and this was what they had the first
1470:20 - impression wow this looks quite amazing
1470:22 - it can probably do any kind of task you
1470:24 - ask it map it will tell you about map it
1470:26 - if you ask about any object it will tell
1470:29 - you about that particular object like
1470:30 - that right so still it is not that
1470:33 - powerful right now okay considering the
1470:35 - kind of demo they had actually shown but
1470:38 - the most important thing that we really
1470:40 - need to understand why we should think
1470:44 - right this Gemini is an amazing model it
1470:47 - can probably be the future of llms okay
1470:51 - first of all whenever we talk about
1470:54 - multimodality okay
1470:57 - multimodality so here when we say
1471:00 - multimodality okay so here one example
1471:04 - you can see that it is being able to do
1471:06 - the reasoning seamlessly across text
1471:08 - images video audio and code okay
1471:12 - recently if you probably talk about open
1471:14 - AI gp4 model right now it has come
1471:17 - combined everything di it has combined
1471:20 - uh for the data analysis part also it
1471:22 - has combined that code interpretor
1471:24 - functionalities and all right and
1471:26 - recently it was launched and over there
1471:28 - you can probably do tasks that are
1471:30 - related to images that are related to
1471:32 - text okay here in gini when we see right
1471:36 - you are able to combine everything text
1471:38 - images videos audios and code today I
1471:40 - will show you a lot of example with
1471:42 - respect to text and images okay we'll
1471:44 - see some amazing use cases you can also
1471:46 - do it with the the help of PDF you can
1471:48 - do with multiple things as such okay and
1471:50 - all the task that are related to NLP
1471:53 - like chat with your PDF and all you can
1471:55 - also do with this
1471:57 - now the most important thing why
1472:01 - gini is the most capable AI model that
1472:05 - is because of this result okay now see
1472:09 - here you can see something called as
1472:11 - human expert MML now what is this mmu
1472:16 - okay if you probably search for what
1472:18 - exactly is MML okay mlu if you see that
1472:22 - it is nothing but massive massive
1472:24 - multitask language
1472:26 - understanding so with respect to humans
1472:30 - right it is basically able to say that
1472:34 - over here it has achieved see Gemini is
1472:36 - the first model to outperform human
1472:39 - experts on
1472:40 - mlu massive multitask language
1472:43 - understanding one of the most popular
1472:45 - method to test the knowledge and
1472:46 - problems solving abilities of AI and
1472:50 - here it is also said that it has crossed
1472:53 - the crossed the Benchmark of GPT 4 also
1472:57 - right so if you probably see this see
1473:00 - understand Guys these all are very
1473:02 - important things to understand because
1473:05 - benchmarking is done on which thing that
1473:08 - you really need to get an idea about and
1473:11 - because of this benchmarking you will
1473:13 - get a clear idea and you can assume how
1473:16 - good this specific model is and any
1473:19 - model so tomorrow if you probably
1473:21 - talking about Lama 2 if you're talking
1473:23 - about Mistral it will be benchmarking
1473:26 - based on this capabilities so if you
1473:29 - probably want to work in the field of
1473:30 - generative AI I think this benchmarking
1473:34 - is super important and you should learn
1473:36 - about this okay or get an idea about it
1473:39 - because tomorrow if you're reading a
1473:40 - research paper how can you say that this
1473:43 - model is better than the other model
1473:45 - okay so here you can can probably see in
1473:48 - mlu it is nothing but representation of
1473:50 - questions in 57 subjects right it has
1473:53 - been able to get this accuracy 90% gp4
1473:57 - it was somewhere around
1473:58 - 86.4 then in case of reasoning you can
1474:01 - see some results where it was greater
1474:03 - than GPT in two different things like in
1474:06 - big bench hard drop in h Swag like in
1474:09 - common sense reasoning for everyday
1474:11 - everyday task it did not achieve that
1474:13 - much accuracy when compared to gp4 Okay
1474:16 - so the reason see I'm telling you why
1474:19 - all these things you should know because
1474:20 - you should get an idea about it okay the
1474:23 - other thing is that with respect to ma
1474:26 - maths right basic arithmetic
1474:27 - manipulation final grade school math
1474:29 - problem it was able to uh get a good
1474:32 - accuracy of 90 4.4 but when you had
1474:35 - challenging math problem it is not able
1474:37 - to get that much accuracy right
1474:40 - somewhere around 53.2 but it is far more
1474:42 - better than gp4 gp4 was able to get
1474:46 - somewhere around 52.9 okay similarly
1474:49 - with respect to the code evaluation here
1474:51 - you can also see that it has crossed
1474:53 - this gp4 like python code generation
1474:56 - python code generation new heldout data
1474:58 - set human eval like not leaked on the
1475:00 - web right so completely a new generated
1475:02 - code right so in short it says that and
1475:06 - this is completely from the research
1475:07 - right gini surises the state of art
1475:10 - performance on the range of multimodel
1475:12 - benchmarks so you are getting this
1475:14 - specific information and there are other
1475:17 - information see this is something
1475:18 - related to text okay this is something
1475:22 - related to text now here if you go down
1475:25 - it is something related to multimodel
1475:27 - now whenever I say multimodel what does
1475:29 - that mean it is basically talking with
1475:31 - respect to images with respect to video
1475:34 - with respect to audio and here also you
1475:37 - can see that it has proven well with
1475:40 - respect to all the Benchmark when
1475:42 - compared to GPT 4V right so here you can
1475:45 - see 59.4 4 77.8 82.3 90.9 80.3
1475:52 - 53.0 and here you can see all the other
1475:54 - readings right if you want to read the
1475:56 - technical report here you can probably
1475:58 - go ahead and read it entirely okay it
1476:01 - will be talking about how it has
1476:03 - basically done the fine tuning and all
1476:05 - and all and all it's just like a
1476:06 - research paper like why it is basically
1476:08 - said as a so here you can probably see
1476:11 - here is a solution of a physics Problem
1476:12 - by a student uh the information is given
1476:15 - over here that it was not able to get
1476:17 - the answer whether the answer is correct
1476:19 - or not all the information clearly you
1476:21 - able to see right again it is based on
1476:24 - Transformer only encoder decoder so that
1476:27 - is the reason right why I say in the
1476:30 - road map of generative AI if you want to
1476:32 - learn something you really need to have
1476:34 - a good base about Transformer and BT
1476:37 - right if you understand what is encoder
1476:39 - decoder how it works right then
1476:42 - definitely all the further things you'll
1476:44 - also be able to understand it right so
1476:47 - guys till here everybody's clear right
1476:50 - now we'll talk about what all different
1476:51 - sizes are there and which model is
1476:53 - available for us so if everything is
1476:55 - clear please do hit like if you're able
1476:57 - to hear me out and
1476:59 - all so uh shini says sir what is the
1477:01 - difference between B and gin see B like
1477:05 - how we have chat GPT application
1477:07 - similarly we have Google B in Google B
1477:09 - in the back end we used to use pal to
1477:12 - right now they can change Palm to Gemini
1477:14 - right where it will also support images
1477:16 - and text it's all together an
1477:17 - application so can I get a quick yes if
1477:20 - you able to
1477:22 - understand
1477:24 - yes something quick yes come on guys I
1477:27 - should be able to hear I think there's a
1477:29 - less energy over there come on let's
1477:32 - let's make this session amazing see my
1477:34 - main aim is to make this session a good
1477:37 - one for you right you should be able to
1477:40 - understand things your Basics
1477:42 - fundamental should be strong tomorrow
1477:44 - when whatever model you should see you
1477:47 - should be able to understand so hit like
1477:49 - okay hit like hit something give a
1477:52 - smiley I'll feel happy more energy will
1477:55 - come when I'm explaining because we also
1477:56 - need to do end to end project right now
1477:59 - okay now
1478:03 - um so one question is that how to
1478:05 - generate image data using Gemini still
1478:08 - those features have not been exposed
1478:10 - completely we'll talk about what all
1478:12 - features it specifically have okay don't
1478:14 - worry okay we'll be discussing about
1478:17 - now Gemini comes in three sizes one is
1478:19 - ultra our most capable and largest model
1478:22 - for high complex task one is pro our
1478:26 - best model for scaling around a wide
1478:28 - range of task okay and the Nano part
1478:32 - which is our most efficient model for on
1478:34 - device Tas so if you are
1478:35 - specifically working with gini Pro or
1478:38 - gini in devices you can use Nano in this
1478:42 - in for normal day-to-day task or general
1478:44 - task you can use gini Pro then you can
1478:47 - use ultra right now Gemini Pro is
1478:49 - available for everyone out there without
1478:51 - paying anything you can use it and you
1478:53 - can also hit 60 queries in a minute okay
1478:56 - at a time you can hit 60 queries right
1478:59 - now no charges are there later on when
1479:00 - Ultra will come the API will be
1479:02 - basically exposed okay and then you can
1479:05 - also use now gini can generate code
1479:09 - based on different inputs all these
1479:11 - capabilities are specifically there so
1479:13 - it is now better that we try to see some
1479:15 - handson okay and all the other
1479:18 - information you can probably check it
1479:19 - out which is I don't think so it is very
1479:21 - much important right now you can also
1479:23 - check it out with respect to B now I'll
1479:26 - give you a link
1479:28 - okay I will give you a link everybody so
1479:32 - let's take this link everyone and
1479:35 - provide this link in the chat okay so
1479:37 - please go ahead with this specific
1479:41 - link okay I've given you the link over
1479:44 - here
1479:45 - okay and in this link you'll be finding
1479:48 - this particular thing now we are going
1479:50 - to see a kind of demo right kind of demo
1479:56 - like how does geminii API work and we
1479:58 - are specifically going to use AP gini
1480:01 - Pro now in this first of all I also need
1480:05 - to worry about the API key how do we
1480:08 - create an API key gini Pro create an API
1480:13 - key we'll discuss about that right
1480:15 - second we will see multiple examples
1480:18 - with text images okay so both these
1480:21 - examples we'll see in this demo and
1480:23 - finally once we see multiple examples
1480:26 - then we will create an end to endend
1480:28 - project where I'm going to write the
1480:29 - code from
1480:31 - scratch write the code from scratch okay
1480:35 - I'll build a front end back end and then
1480:37 - probably show you
1480:39 - okay um sir a video called handson with
1480:42 - Gemini interacting with multiple was
1480:43 - fake yeah I told right uh they had
1480:46 - actually integrated images to image but
1480:48 - with respect to Performance I think it
1480:49 - is very very much good okay so let's go
1480:53 - ahead and now I will click on Google
1480:55 - collab now see guys over here Google
1480:57 - collab is there you can also work in
1480:59 - neurolab okay if you want okay but
1481:02 - always understand with respect to if you
1481:05 - want to use gini Pro the python version
1481:09 - that you really need to have is 3.9 and
1481:13 - greater okay 3.9 and greater so we are
1481:18 - still updating this neural lab right now
1481:20 - by default when you open this neural lab
1481:22 - it opens in 3.8 see
1481:24 - 3.8.1 Z right so we will soon update
1481:28 - this by default you can also get an
1481:30 - option of changing this environment
1481:32 - because today I was actually seeing this
1481:34 - and it can probably also work in 3.9
1481:37 - okay so that is the reason we are
1481:38 - probably finding it out so everybody got
1481:41 - this link
1481:43 - everyone did you get this link so I will
1481:46 - post a
1481:48 - comment just check whether you are able
1481:50 - to get this link or
1481:53 - not everybody got the
1481:58 - link yeah so this is the link you have
1482:01 - to probably go ahead with you know so
1482:03 - you will get this page you have it all
1482:06 - the
1482:08 - options yeah you have all the options
1482:11 - like for go you have for nodejs you have
1482:15 - see it supports all everything right web
1482:18 - if you want to probably working on web
1482:20 - if you're working on Android device you
1482:22 - also have that you have that client SDK
1482:25 - right you have rest API right everything
1482:29 - if you want to work along with rest API
1482:31 - you can also get that as an example how
1482:33 - to get an API key I will just go ahead
1482:35 - and talk about it but now we are going
1482:37 - to focus on python okay so with respect
1482:39 - to python we are over here now do one
1482:42 - thing first of all guys when you're
1482:44 - running this before install installing
1482:46 - first of all let's go ahead and connect
1482:48 - to the GPU
1482:50 - okay and again if you Al want to do the
1482:53 - coding in neural La please go ahead and
1482:55 - do it okay but as I said uh it may give
1482:58 - you some issues because the bython
1483:00 - default version is 3.9 with respect to
1483:02 - gini Pro
1483:04 - okay but again I would suggest try with
1483:07 - this also good system all the code will
1483:10 - be saved over here and it will not get
1483:12 - deleted
1483:13 - okay great now
1483:16 - first thing first okay so we have
1483:19 - connected let's before executing
1483:22 - anything click on this get an API
1483:27 - key so get an API key will be there
1483:31 - somewhere like this and it will go to
1483:34 - this link makers. goole.com
1483:37 - slapp API ke so first of all we are
1483:40 - going to create an API key okay for API
1483:43 - key for a project okay so just give me a
1483:46 - a confirmation if you are in this
1483:48 - particular section because I'm going to
1483:50 - show you everything from scratch how you
1483:53 - can actually do it okay so please go
1483:56 - over here in this specific link did you
1483:58 - get that link did you get that link I
1484:00 - hope right just click on this link in
1484:03 - this particular uh notebook file you'll
1484:06 - be finding this specific link get API
1484:09 - key okay so click on
1484:14 - that and it will open just give me a
1484:16 - confirmation once this is
1484:19 - open
1484:21 - okay so see if you want to communicate
1484:24 - with this llm model it will be exposed
1484:26 - in the form of apis so when it is
1484:28 - exposed in the form of API you'll be
1484:30 - able to interact with it okay yes
1484:33 - everybody got this link okay I have
1484:36 - already created one so I'm going to
1484:38 - delete
1484:39 - this and I'll create a new one okay so
1484:44 - I'm creating an API key
1484:49 - now what
1484:50 - happened let's
1484:52 - see create a API
1485:02 - key the caller does not have a
1485:04 - permission I'm getting some error let me
1485:06 - see okay my account was changed okay so
1485:11 - I will just change my account so this is
1485:13 - my account okay now I will try to
1485:15 - execute it because if you doing with
1485:17 - other other account then it will be
1485:18 - creating a problem so let's go ahead and
1485:21 - create my API
1485:23 - key okay I will go over here now
1485:26 - everybody just click on this create a
1485:28 - API key still there is an issue
1485:32 - why is everybody able to create an API
1485:35 - key right now just
1485:42 - check are you able to create an API key
1485:47 - I will just open Google collab let's
1485:59 - see
1486:09 - okay okay it should not give an error I
1486:12 - don't know why it is giving an
1486:15 - error scholar does not have a
1486:19 - permission just a
1486:25 - second I think everybody should be able
1486:28 - to create
1486:32 - it just give me a second guys I'll just
1486:35 - try to create one API
1486:45 - key
1486:46 - just give me a second okay I think
1486:49 - there's some issues but I think
1486:50 - everybody may have got created it I'm
1486:53 - getting some error and I should know the
1486:57 - [Music]
1486:59 - reason just a
1487:05 - second just a
1487:14 - second
1487:19 - [Music]
1487:36 - the caller does not have a
1487:40 - permission anybody facing this
1487:43 - error I think it is due to I created did
1487:46 - the multiple keys for the task I created
1487:49 - the three app keys after that it is
1487:51 - giving Mana I guess
1487:54 - so
1487:57 - uh just a
1488:03 - second let me
1488:06 - see I'll just sign out
1488:14 - once close it and open let's
1488:19 - see maker
1488:32 - suit I got the create I was able to
1488:35 - create it yeah everybody's able okay
1488:37 - someone someone someone Someone okay
1488:41 - someone anyone ping me the key over here
1488:43 - I'll just have a look on this issue why
1488:45 - it is Happ happening with my email ID
1488:47 - okay I'll just get to know why it is
1488:50 - probably a problem but anyone just give
1488:52 - me an API key in the chat anyhow you can
1488:55 - actually request 60 request so anyone
1488:57 - someone give me the chat in the chat
1488:59 - I'll just check because this is the
1489:01 - first time I'm facing this error let's
1489:03 - see what is the issue
1489:06 - okay it should not give me an error
1489:09 - someone just uh ping it in the
1489:13 - chat let me see in whether any other
1489:16 - user ID will I be able to do it or
1489:22 - not
1489:31 - think okay so please make sure that I
1489:34 - think if you're able to create a
1489:37 - multiple okay finally I it has got
1489:40 - created I changed my login ID so now it
1489:42 - has got created now what I will do I
1489:44 - will go over here
1489:46 - okay I will keep this API key somewhere
1489:48 - here let me just keep it over here so I
1489:52 - will say OS do or let's say I will write
1489:56 - key is equal to and I will save it over
1489:58 - here okay so guys please make sure
1490:02 - that please please please make sure that
1490:06 - don't create multiple multiple this one
1490:09 - and delete keep on deleting it okay so
1490:11 - do not do that okay so don't after
1490:13 - creating one please save it somewhere
1490:16 - let's say I am saving it in my notebook
1490:18 - file okay so I have saved it over here
1490:20 - in my notebook file so that you don't
1490:22 - delete this okay don't delete it if
1490:25 - you're deleting it I think after three
1490:27 - times it will give you an is issue
1490:29 - otherwise just change your email ID okay
1490:31 - now let's start over here and let's
1490:34 - start working on it
1490:36 - okay so first of all I will go ahead and
1490:39 - connect it okay and then we'll go ahead
1490:41 - and discuss step by step
1490:44 - okay so just let me know whether you
1490:47 - have done all the steps or not you have
1490:48 - everybody has created their
1490:50 - keys
1490:52 - yes yeah everybody has created the
1490:55 - key okay now I have connected to my
1490:59 - collab
1491:01 - okay remember the requirements is that
1491:04 - you need to have python 3.9 plus okay
1491:08 - and installation of Jupiter to run the
1491:10 - notebook so 3.9 plus is the minimum
1491:13 - python version that it will work with
1491:16 - now first of all we will go ahead and
1491:18 - install this Google generative AI okay
1491:22 - so this is the library we are going to
1491:24 - create it okay so what I will do
1491:28 - parallely let me do one thing
1491:32 - parallely I will create a
1491:35 - project
1491:37 - okay let me let me create one
1491:44 - folder
1491:47 - so guys see I've created a folder gini
1491:51 - okay and in my local I will open a VSS
1491:54 - code because at the end of the day I
1491:56 - also want to create an end to endend
1491:57 - project okay so everybody follow along
1492:01 - with my steps okay now first of all it
1492:05 - is basically saying that I will be
1492:07 - having one requirement.
1492:09 - txt requirements.txt
1492:12 - yes everybody so everybody has vs code
1492:16 - can you give me a quick confirmation if
1492:18 - everybody has a vs
1492:20 - code yeah everybody has a vs code
1492:25 - yes yes so how do you open this vs code
1492:29 - just click in this particular folder
1492:31 - open with code right so I hope everybody
1492:34 - is basically having the vs code now I
1492:37 - have opened the vs code now the first
1492:40 - step over here you can see that we will
1492:42 - go ahead and install Google generate
1492:45 - ative AI right so I will copy this
1492:47 - entirely and I will execute it because
1492:50 - here I will show you the demo and there
1492:52 - we will try to create an endtoend
1492:55 - project okay so I will do this over here
1493:00 - so here you can see the installation has
1493:02 - taken place right and as you know the
1493:04 - first thing that we need to install is
1493:06 - Google generative AI so now I will go to
1493:09 - my vs code and here I will write it as
1493:11 - Google generative AI okay the next thing
1493:14 - I will also be requiring streamlet so
1493:17 - that I create my front end right so here
1493:20 - I need to create my front end okay so
1493:23 - these two libraries I'm going to
1493:25 - specifically use it okay now as said
1493:30 - what should be the python environment
1493:32 - that you are currently working
1493:36 - in what should be the python environment
1493:39 - that you should be working in can
1493:40 - anybody tell
1493:42 - me so I'll say cond deac activate
1493:46 - quickly tell me guys which python
1493:48 - environment we should keep on working on
1493:52 - it which python
1493:54 - environment at least greater than 3.9
1493:58 - plus so what we will do we will try to
1494:01 - create an environment so in order to
1494:03 - create an environment I will write cond
1494:05 - create minus P my environment name is V
1494:10 - EnV and which environment I'm going to
1494:12 - use Python equal to 3.9
1494:16 - or if you don't want 3.9 plus you want
1494:18 - so I will say 3.10 right 3.10 and here I
1494:23 - will by default give- y okay so
1494:27 - everybody clear I'm creating an
1494:29 - environment so that I will also be able
1494:31 - to work along with an end to endend
1494:33 - project so once I execute this over here
1494:36 - you'll be seeing this entire things will
1494:38 - get
1494:39 - executed okay and that is why you'll be
1494:42 - able to see one environment V and be
1494:45 - getting created see step by step we'll
1494:47 - do and I'll be able to make you
1494:50 - understand why I'm specifically doing
1494:52 - this because I want an environment so if
1494:55 - you're executing the local or in any
1494:57 - Cloud minimum requirement is that you
1494:59 - need to have python 3.9 plus that is the
1495:03 - reason I've taken python
1495:05 - 3.10 okay so here you can see that we
1495:07 - noticed a new environment has been
1495:09 - created do you want to select it for the
1495:11 - workspace folder either you can select
1495:13 - yes or if if you want to activate that
1495:16 - environment what you will do you will
1495:18 - write
1495:19 - cond create sorry cond activate vnb Dash
1495:26 - okay so now here is my activated
1495:28 - environment
1495:30 - perfect clear
1495:33 - everyone can I get a quick
1495:37 - yes
1495:39 - yeah yes yes obviously you'll get the
1495:42 - recording also don't worry so
1495:45 - everybody if you are able to understand
1495:48 - please hit like and let me know if you
1495:50 - are getting all this information or not
1495:53 - okay we will do this parallell step by
1495:55 - step whatever things are happening we
1495:57 - will work in that specific way
1496:01 - okay great okay now here also we
1496:05 - installed Google generative AI
1496:09 - okay clear shall I go ahead
1496:14 - guys shall I go ahead
1496:18 - everyone shall I go
1496:22 - ahead come on give me a quick yes great
1496:26 - now what we are specifically going to do
1496:29 - okay is that we are going to install and
1496:32 - import some of the
1496:34 - libraries for google. generative AI see
1496:38 - this is what we had installed right
1496:40 - Google Das generative AI right and the
1496:42 - same thing we are importing over here
1496:44 - import Google generative AI as gen all
1496:47 - the functionalities Let It Be text let
1496:50 - it be uh Let It Be regarding other
1496:53 - things that is videos images audio this
1496:57 - gen aai will be the allias name which
1496:59 - will have all the functionalities and
1497:01 - this is present inside google.
1497:03 - generative AI okay now here you'll be
1497:06 - able to see
1497:08 - that there is something a way to secure
1497:11 - your API data I will show you how you
1497:14 - can basically do it but let's go ahead
1497:15 - and create my API data so here I already
1497:19 - copied my API so I will go ahead and say
1497:23 - okay my API uncore key is equal to in
1497:29 - this way I'll paste it over here okay so
1497:33 - here I will give my API key which I had
1497:36 - copied from there so this will basically
1497:39 - have my API key okay so this API key I
1497:44 - will further be using using okay so
1497:46 - everybody just create your API key field
1497:49 - and this is basically converting a text
1497:53 - into markdown so that you get a good
1497:56 - display in the jupyter notebook so not
1497:58 - that important so that is what next
1498:01 - thing we are basically going to do now
1498:03 - understand this API key that we have
1498:05 - created the same thing we'll try to do
1498:08 - it in our end to endend project the name
1498:12 - that we are specifically going to use is
1498:15 - nothing but Google API key so here when
1498:20 - I probably go over here and go to my
1498:24 - here I will create a
1498:28 - file okay a
1498:32 - file okay soem file and here what I will
1498:37 - do I will paste it Google API key and we
1498:42 - will try to paste the API key over over
1498:45 - here what was the API key that I got it
1498:48 - was nothing but this entire thing
1498:54 - okay so here it is okay so why we need
1499:00 - to create an API key to play banga we'll
1499:03 - do bhang with the API key Danes sa are
1499:07 - you in the session or are you away from
1499:09 - the session H do you want to play
1499:13 - banga come on I I made you understand
1499:16 - right why we require the API ke it is
1499:17 - very simple to communicate with the llm
1499:20 - models huh without the API key you'll
1499:22 - not be able to communicate with the llm
1499:24 - models right a better answer for you
1499:27 - will be to play banga okay let's play
1499:30 - banga in that
1499:32 - okay come on guys please be serious with
1499:35 - respect to all the sessions that we are
1499:37 - doing
1499:38 - right never never uh you know whenever
1499:43 - we provide you free content you do not
1499:45 - value that free content right please
1499:47 - focus on the session try to learn along
1499:50 - with me I'm going step by step I'm going
1499:52 - slow I'm explaining you each and
1499:54 - everything right please
1499:58 - Focus right please
1500:00 - Focus if you do not focus on the session
1500:03 - if you're just watching it then it will
1500:05 - become a problem okay so practice along
1500:08 - with me so here I've created one API key
1500:11 - that is Google API key h
1500:15 - um one question was that sir at the end
1500:18 - of the webinar could you please suggest
1500:19 - some real use cases of gen VI in finance
1500:22 - yeah today the end to end project that
1500:23 - I'm going to do is an real use case only
1500:27 - okay clear everyone so can I get a quick
1500:32 - yes API key basically means we have gini
1500:36 - llm models somewhere hosted in the cloud
1500:39 - to access that you require some some
1500:41 - some tickets let's say you want an entry
1500:44 - ticket that entry ticket will be given
1500:46 - by that API key itself right you if you
1500:49 - have the right API key you'll be able to
1500:51 - contact the Jin llm model you'll be able
1500:53 - to get the result okay so clear everyone
1500:57 - till
1500:58 - here
1501:04 - okay okay perfect
1501:07 - now we will go to the next step and here
1501:11 - I will go ahead and I'll just comment
1501:13 - out this code okay I don't want this
1501:16 - code okay and let's say I will write
1501:20 - gen. configure we need to configure this
1501:23 - key okay we need to configure the API
1501:26 - key so I will just comment out this code
1501:28 - and I'll show you in an end to end
1501:30 - project how you can call this variable
1501:33 - okay and I'm saying gen ai. configure
1501:36 - API key will be equal to this key okay
1501:41 - so once I actually execute it okay
1501:46 - here you can see that now our API key is
1501:49 - basically configured now we know our ke
1501:51 - is over here but it is not a good
1501:54 - practice to Showcase this API key like
1501:56 - this that is the reason in my project
1502:00 - you'll be seeing that I have created
1502:02 - this
1502:04 - file okay file and this file has this
1502:09 - API key and this EnV is nothing but
1502:12 - environment right when you go ahead and
1502:14 - deploy this this environment file will
1502:16 - not be visible okay and since it is not
1502:20 - visible in the environment in the
1502:21 - production you will not be able to see
1502:23 - this key so over there in production
1502:25 - also you have a different way of setting
1502:27 - the API key okay perfect now here we
1502:31 - have configured it okay now this gen AI
1502:34 - after configuring it provides you two
1502:37 - amazing models one is gini pro and one
1502:40 - is gini Pro
1502:42 - Vision gini Pro is is specifically for
1502:45 - optimized for text only
1502:48 - prompts and this is probably optimized
1502:51 - for text and images prompts okay text
1502:55 - and images so one is for text and the
1502:58 - other one is for text and images I hope
1503:01 - you able to understand it okay one is
1503:04 - text and one is text and images so if
1503:07 - you want to do any kind of work that is
1503:09 - related to text and images let me tell
1503:12 - you an example okay what kind of use
1503:15 - cases you can probably get from it okay
1503:18 - now see this guys if I have this
1503:25 - invoice let's say I have this specific
1503:29 - invoice now if I
1503:32 - want anyone to
1503:35 - probably take out information from this
1503:38 - invoice what do you think I can
1503:40 - basically do or let's let's take this
1503:42 - invoice okay some some of the invoice EX
1503:44 - example this invoice has some of the
1503:46 - data okay invoice sample I will take
1503:52 - okay let's say this is one of the sample
1503:54 - invoice and if I probably save this
1503:58 - image and I will save it in my downloads
1504:02 - everybody's able to see this
1504:04 - invoice now from this
1504:06 - invoice I want my llm application to
1504:09 - probably retrieve data from it okay if I
1504:13 - probably ask who was this invoice buil
1504:16 - to it should be able to take out this
1504:19 - information isn't it an amazing use case
1504:21 - just imagine as a human being will this
1504:24 - be a very steady task means it'll be a
1504:27 - very slow task right here you'll be
1504:30 - seeing what information is there then
1504:31 - you'll be writing all the information
1504:34 - what if if I say my llm model and I give
1504:36 - this image and I say that hey what is
1504:39 - the date that is issued for this invoice
1504:42 - and it should be able to give me the
1504:43 - answer 263 2021 isn't it
1504:46 - amazing tell
1504:48 - me will this be an amazing use case to
1504:52 - work on in a company where you automat
1504:55 - all the invoices are automated
1504:58 - automatically is it good or not tell me
1505:01 - guys come on yes or no something I hope
1505:05 - you are not sleeping I know it's late
1505:08 - but I'm going to take the session till
1505:09 - 10: so that is the reason I'm asking you
1505:13 - are you able to hear me out or not right
1505:16 - so just imagine if you want to automate
1505:18 - the entire in invoice probably take out
1505:21 - all the info yeah PDF is also supported
1505:24 - not on images PDF is also supported PDF
1505:26 - you can convert that into bytes you can
1505:28 - take out the information you can even
1505:30 - chat with your PDF do whatever things
1505:32 - you want right so this is super right
1505:36 - this is this is amazing thing right you
1505:39 - will be able to get those information
1505:41 - and just imagine you have a task where
1505:43 - you need to automate all the data in an
1505:44 - Excel sheet and probably push that data
1505:46 - from into a different
1505:48 - databases right so here you'll be able
1505:52 - to see
1505:54 - that yeah I hope you able to get an idea
1505:58 - about it
1505:59 - guys clear so let's automate this let's
1506:04 - automate this entire thing where you can
1506:06 - give an image and I ask any question any
1506:10 - generic questions with respect to this
1506:12 - you should be able to get an answer
1506:13 - about that
1506:15 - okay so this is just like an invoice
1506:17 - extractor I'll say okay and in upcoming
1506:20 - projects we'll see about PDFs we'll see
1506:22 - about chatting with PDFs we'll see about
1506:25 - multiple things okay then then you'll
1506:27 - have a fun so this is what is the use
1506:29 - case that I'm going to probably solve
1506:30 - today okay now let's go ahead and let's
1506:34 - go ahead and probably talk more about it
1506:36 - okay now tell me one thing guys
1506:40 - everybody's writing the code along with
1506:42 - me I hope so if you are not writing I
1506:44 - will give you the code anyhow okay but
1506:47 - uh let's go ahead and do this okay now
1506:50 - this is done my EnV is created okay my
1506:53 - EnV is basically created I have my
1506:55 - Google API key everything is there uh
1506:58 - now let's go ahead and install these
1507:01 - requirements okay so first of all what I
1507:03 - will do I will go over here I will go
1507:06 - ahead and install these requirements in
1507:08 - requirements I have Google generative AI
1507:10 - streamlet right so I will go and write
1507:12 - pip install
1507:15 - minus r requirement. tht
1507:19 - right so now my installation is
1507:22 - basically taking place please go ahead
1507:23 - and do the installation everyone and
1507:25 - once you do the installation in your vs
1507:28 - code or in your neurol lab we will try
1507:31 - to probably install all the libraries
1507:33 - that are required okay because at the
1507:35 - end of the day we are going to create an
1507:38 - end to end project please do that
1507:41 - okay guys and uh for the people whom I
1507:44 - see lot of
1507:46 - participation I will give them an
1507:47 - opportunity to probably come along with
1507:50 - me in this live session and talk with me
1507:53 - okay so you really need to be activate
1507:55 - Okay so I'll give a couple of people
1507:57 - that specific chance okay so please
1508:00 - Focus okay and please be active because
1508:03 - this kind of session start valuing it
1508:06 - okay unless and until you don't value it
1508:08 - then it will not work out so hit like do
1508:10 - multiple things keep on posting call
1508:12 - your friends to join the session it'll
1508:14 - be quite some amazing okay so right we
1508:18 - are what we are basically going to do we
1508:19 - going to do this specific installation
1508:21 - it will take some time uh now what I
1508:24 - will do I will create my app.py
1508:27 - file Now understand one thing what we
1508:31 - are specifically going to
1508:34 - do I
1508:37 - will see what is our plan that we are
1508:41 - going to do I'll discuss about the
1508:43 - architecture so I will create one front
1508:45 - end application something like
1508:49 - this
1508:52 - okay I will what I will do I will upload
1508:56 - an image so then image will upload over
1508:59 - here okay and then I will write my own
1509:03 - custom
1509:05 - prompt so this will basically be my
1509:09 - prompt prompt basically means I will ask
1509:12 - who is this invoice will to I will ask
1509:15 - this question over here the image will
1509:17 - get uploaded over here and then I should
1509:20 - be getting my
1509:22 - output over here that saying that the
1509:25 - image was built to someone like built to
1509:28 - this particular company okay now this is
1509:31 - super amazing see now as soon as I
1509:35 - upload the image understand the
1509:37 - architecture
1509:39 - okay as soon as I upload the image right
1509:44 - so this image will get uploaded then
1509:47 - what I will do I will take this
1509:50 - image I will take this
1509:53 - image convert into
1509:56 - bytes convert into
1509:59 - bytes okay and then retrieve this image
1510:03 - over here so I will be having the image
1510:06 - info okay image info okay so this is
1510:11 - First Step as soon as I upload it the
1510:13 - image will get converted into bytes and
1510:15 - we'll be having all the image info all
1510:17 - the details inside the image because
1510:20 - Gemini
1510:22 - pro has a very strong OCR
1510:27 - functionalities OCR functionalities okay
1510:31 - so if you probably give this information
1510:33 - of the image info now in The Next Step
1510:35 - what I'll do I will take this prompt so
1510:38 - I will add this along with my
1510:41 - prompt and this entire info will be
1510:45 - going to
1510:47 - where where it will
1510:50 - go bites basically I'll show you that
1510:52 - bytes don't worry okay it is just
1510:56 - like image information it will probably
1510:59 - get converted into some encoded
1511:00 - character okay now this image info plus
1511:04 - prompt will now be we will hit it
1511:08 - to
1511:10 - Google
1511:11 - gini we will hit it to
1511:17 - we will hit it
1511:18 - to gini pro llm
1511:26 - model okay to gini pro llm model now
1511:31 - once we head it to the Gin pro llm model
1511:34 - it will look for two important
1511:36 - information one is the prompt and one is
1511:39 - the image
1511:40 - info and through that OCR
1511:42 - functionalities what this gin Pro it has
1511:44 - an internal OCR
1511:46 - functionalities it will try to compare
1511:49 - this two information and it is able to
1511:51 - get an output it will give an output
1511:53 - saying that let's say I've asked the
1511:56 - build uh who this invoice was built to
1511:58 - it'll say that the invoice was built to
1512:01 - so and so information that we are
1512:03 - getting from the
1512:06 - image okay and finally this will be my
1512:09 - output and this is what we are
1512:11 - specifically going to do we will Design
1512:14 - this we will write the code for this and
1512:16 - we will probably get this also okay so
1512:20 - finally we'll do all this Steps step by
1512:22 - step okay now let's quickly go over here
1512:26 - and I've already done the installation
1512:29 - let me clear the screen now you may be
1512:31 - thinking Krish you are not a front- end
1512:33 - developer how will you write the stream
1512:35 - late code on the Fly I will never write
1512:38 - I will use chat GPT I will use Google B
1512:40 - I'll say hey give me a stream L code
1512:43 - where I have an image upload button
1512:45 - where I have one text input box and I
1512:48 - have a submit button I will write like
1512:50 - that okay so let's go ahead and write my
1512:53 - code okay so first of
1512:54 - all I will write it over
1512:57 - here
1512:59 - invoice extractor okay now first of all
1513:03 - tell me
1513:05 - guys in my environment file I have my
1513:08 - API key right how do I call
1513:11 - this how do I call this environment
1513:13 - variable right so for that I will be
1513:15 - using
1513:17 - from EnV import load
1513:22 - uncore Dov okay so I require this load.
1513:27 - EnV what this specifically does load.
1513:30 - EnV it will help us to load all our
1513:34 - environment variables right but for this
1513:37 - I need to install it so here what I will
1513:39 - do I will go to requirement. txt I will
1513:41 - write python. EnV right and I'll save it
1513:45 - again I will go to my
1513:46 - terminal okay and I will say pip
1513:51 - install pip
1513:53 - install minus
1513:57 - r requirement. tht so this installation
1514:00 - will take place and finally you'll be
1514:02 - able to see the python. EnV will get
1514:05 - installed so here you can probably see
1514:07 - the installation has been done now it
1514:09 - will not give us an error whenever we
1514:11 - try to load this EnV okay so we have
1514:15 - specifically done this okay now after
1514:19 - importing to load all the environment
1514:23 - variables we will use this function
1514:25 - which is called as load. EnV so here it
1514:29 - will take load all environment
1514:34 - variables from dot
1514:38 - EMV okay clear everyone yes can I get a
1514:43 - quick
1514:45 - yes yeah I will show you everything
1514:47 - don't worry follow along with me I will
1514:49 - try to show you how you can convert
1514:51 - image into bytes how you can get the
1514:53 - image info everything as such I will
1514:55 - show you okay okay everything I will
1514:59 - show you but here till here I hope
1515:01 - everybody's very much able to understand
1515:04 - and they able to understand in a very
1515:06 - good way okay clear okay perfect so let
1515:10 - me go to the next step now and we'll
1515:12 - discuss further like what we are
1515:14 - specifically going to do now after this
1515:16 - I will go ahead and import
1515:19 - streamlet as
1515:21 - St so we are going to use streamlet as
1515:24 - we imported that okay we will import
1515:29 - OS because I need to call my environment
1515:32 - variables so here I'll be using OS and
1515:35 - then since I'm using images I will use
1515:37 - from
1515:38 - P import image okay this image will
1515:43 - actually help us to get the info from
1515:45 - the image okay now as you know from the
1515:49 - requirement. txt we have also installed
1515:51 - Google generative AI right so we will be
1515:55 - importing importing Google do generative
1516:01 - AI as gen AI okay so we are also going
1516:05 - to use this specific thing that is
1516:07 - google. generative a gen now as usual
1516:12 - first of all you know that we need to
1516:14 - load our API key right and we need to
1516:17 - configure it so here for configuring I
1516:20 - will write over
1516:21 - here
1516:24 - configuring configuring API key okay and
1516:29 - here I will basically write
1516:31 - gen do
1516:34 - configure API uncore key and now where
1516:39 - is my environment variable it is
1516:41 - basically present in this specific key
1516:43 - right in this specific key so in order
1516:46 - to call this I'm already calling load.
1516:48 - EnV so here I will write OS dot get ENB
1516:53 - that is get environment
1516:55 - variable get environment variable here I
1516:58 - will go ahead and use my API key done so
1517:03 - this way I'm able to configure the API
1517:06 - key
1517:08 - right
1517:09 - yes everybody clear here right
1517:14 - everybody clear so I hope you're getting
1517:15 - a clear idea what we are doing step by
1517:18 - step I've imported all these things I
1517:21 - imported streamlet I have imported Os Os
1517:23 - why I had imported because I need to get
1517:25 - the environment variable right and this
1517:27 - G environment variable is basically
1517:29 - present INB file whatever name it will
1517:31 - go okay now here you'll be able to see
1517:34 - that I have configured each and
1517:36 - everything okay so along with me you can
1517:38 - write the code if you liking the video
1517:40 - please hit like uh share with all your
1517:42 - friends as usual because all the steps
1517:44 - I'm showing you completely from scratch
1517:46 - Basics because once you understand this
1517:48 - it's your idea do whatever things you
1517:50 - can do image detection image
1517:53 - classification whatever images you want
1517:55 - okay you can basically do it now
1517:58 - done now my next step will be that I
1518:02 - will write a
1518:04 - function so I will create a
1518:08 - function
1518:10 - to load Gemini
1518:14 - provision
1518:16 - model and get response okay so I will
1518:20 - create this function so I will write
1518:22 - definition get gini
1518:26 - response okay
1518:29 - response and here I will require two
1518:31 - important information one is the input
1518:35 - right what specific input that I am
1518:38 - basically giving okay second is image
1518:43 - and third is basically prompt I'll talk
1518:46 - about this what is this differences
1518:48 - between this input and prompt because
1518:50 - both are almost similar but prompt is
1518:53 - something different and image is
1518:55 - something different this prompt or this
1518:58 - sorry this input will be the message
1519:01 - that the llm model will behave like okay
1519:05 - this prompt will be my input that I'm
1519:08 - giving what kind of information I want
1519:10 - okay so this three information I'm
1519:13 - giving it over here now I will go ahead
1519:16 - and call my model so I will write model
1519:18 - gen Dot and here I will call my
1519:23 - generative generative model so inside
1519:26 - this
1519:28 - functionalities basically to call that
1519:31 - gini provision model I have to use the
1519:33 - gen. generative model and here I will
1519:37 - call my Gemini
1519:40 - Pro Vision okay so I'm going to
1519:44 - basically call this right gini Pro
1519:47 - Vision and finally once I call this this
1519:50 - way I will be loading my model so I'll
1519:53 - give you a message over here saying that
1519:55 - loading the Gen AI model right the
1520:00 - Gemini model I can also say it as Gemini
1520:04 - model okay now after loading it I need
1520:08 - to get the response so I will write
1520:10 - response is equal to and I will say
1520:13 - model
1520:16 - dot
1520:18 - generate model. generate underscore
1520:22 - content and here in a list
1520:25 - format this is how you have to basically
1520:28 - give the input to the model so in the
1520:30 - list format the first parameter I'm
1520:32 - going to give is input images will be in
1520:35 - the form of list all the information
1520:37 - we'll get in the form of list so I'll
1520:39 - write image of zero comma it it'll be in
1520:43 - the form of list and then finally I'll
1520:45 - write prompt so once I get this
1520:47 - information then I will return
1520:50 - response and there will be a parameter
1520:52 - inside response which is basically
1520:54 - called as
1520:57 - text so all this information we are
1521:00 - getting it from the Gin right so what we
1521:04 - are doing in this specific
1521:07 - function we are creating a function
1521:11 - which will load a gity provision model
1521:15 - and then model. generate content will
1521:18 - take the input and it will give us the
1521:20 - response so here we are getting three
1521:21 - inputs I'll talk more about these inputs
1521:23 - what all it is and then finally we will
1521:26 - be getting the response. text everybody
1521:29 - clear yes yes everybody
1521:34 - clear can I get a quick yes if you able
1521:37 - to understand till here come on yes or
1521:40 - no give some heart sign give some
1521:42 - symbols
1521:43 - yes no anything it is up to
1521:47 - you
1521:50 - yeah learning is very much important as
1521:52 - I said so
1521:54 - please give your spread your love right
1521:57 - everywhere learning will be fun great
1522:01 - now what we are going to do next step
1522:04 - okay next step what I said see as soon
1522:07 - as see this part is done if I talk about
1522:10 - this part hitting through the Gemini Pro
1522:12 - with all the info image info and prompt
1522:15 - this is done and I get the response this
1522:17 - part is done but this part is not yet
1522:20 - done image upload convert into bytes and
1522:22 - probably get this info this is not done
1522:25 - so what we will do we will go ahead and
1522:26 - write that function so here I will write
1522:30 - input
1522:32 - image set
1522:34 - up and here I will say provide my
1522:37 - uploaded file so whatever uploaded file
1522:39 - I'm going to get I'm going to give it
1522:41 - over here the image I'm going to give it
1522:42 - over
1522:44 - okay now initially I did not know the
1522:47 - code for this okay how to probably get
1522:50 - the uh image data in the form of bytes
1522:53 - something like that right so what I did
1522:55 - I I I went ahead and asked chat GPT and
1522:59 - then chat GPT gave me this solution okay
1523:03 - I asked it that I'm giving an
1523:06 - image okay uh just a
1523:09 - second I'm giving an image so if
1523:11 - uploaded file is not none then it took
1523:14 - this data uploaded file and it did dot
1523:16 - get value from the dot get value it got
1523:19 - the bite data and then it gave me image
1523:21 - Parts in two different format one is the
1523:24 - mime type and one is the data okay so
1523:28 - don't worry I will give you this entire
1523:30 - code in the GitHub repository if you
1523:31 - want the GitHub repository also I can
1523:34 - give it to
1523:36 - you okay so here is the uh I'm I'm
1523:39 - putting the comment uh so everybody body
1523:42 - will be able to see the comment over
1523:44 - there in LinkedIn also I think I will go
1523:46 - ahead and put
1523:48 - it okay so this will basically be the
1523:51 - GitHub file okay so everybody will be
1523:54 - able to see this okay so what we are
1523:57 - doing over here we are taking this image
1523:59 - we converting that into bytes okay then
1524:02 - the image part will be based on two
1524:03 - parameters one is mim type where the
1524:06 - uploaded file. type is there and the
1524:08 - data by data I just asked it to chat jpt
1524:11 - and it gave me this specific answer okay
1524:14 - and then we are returning this image
1524:16 - part so by this what is exactly
1524:19 - happening this part that you have
1524:21 - created is completed see step by step we
1524:24 - created this gin Pro load it this part
1524:28 - is created image info we are
1524:30 - specifically getting it now we need to
1524:32 - get prompt and we need to get input okay
1524:35 - where it is pasted in GitHub link so in
1524:38 - vision. piy file you'll be able to see
1524:40 - that the code is given Okay so so you
1524:42 - can actually use it from
1524:44 - there perfect everybody clear so this is
1524:48 - my second task that I have actually done
1524:50 - shall I go with the third
1524:52 - task yes or
1524:56 - no yes or
1524:58 - no third task is nothing but it is
1525:01 - basically our streamlit app so here you
1525:04 - can probably
1525:06 - see I will now create my stream L app
1525:09 - see initialize our stream L app we use
1525:12 - st. page config the page title is gini
1525:16 - image demo so let's say I'm going to
1525:18 - write some other functionality over here
1525:21 - I will go and say uh image or invoice
1525:28 - extractor okay this is a Gemini
1525:31 - application I use one text box the text
1525:34 - box this text box is nothing but my
1525:36 - input okay input that I'm getting I'm
1525:40 - giving what kind of information I
1525:41 - specifically want from
1525:45 - my from what what kind of input I
1525:48 - specifically want from my invoice yeah
1525:52 - that
1525:53 - information and then uploaded file will
1525:56 - be st. file uploader now here I'm saying
1525:59 - choose an image the type should be jpg
1526:02 - jpg PNG if you want PDF you can also
1526:04 - write PDF over there but the format will
1526:07 - be little bit different so I have
1526:09 - created a file uploader over here and
1526:11 - I'm saying if uploaded file is not none
1526:14 - then what will happen it will open the
1526:16 - uploaded file and it will display the
1526:19 - file over
1526:21 - here it'll display the file over H image
1526:25 - right so some amount of knowledge in
1526:27 - streamlet is required for this if you
1526:30 - don't have knowledge be dependent on
1526:31 - chat GPT because this code entire code
1526:34 - was given by chat GPT okay so here what
1526:37 - I did I used an input box I created an
1526:41 - uploader file for image
1526:42 - and then I'm displaying the specific
1526:44 - image as soon as the upload is done okay
1526:47 - so this three input information I did it
1526:50 - okay and
1526:53 - finally I will create a submit
1526:56 - button and I will say St do
1527:03 - button and here I will
1527:06 - say tell me about the
1527:11 - invoice
1527:15 - done and finally I will give some prompt
1527:19 - I I I need to
1527:20 - say I need to say how my Google Gemini
1527:24 - pro model needs to behave so for that I
1527:27 - will give some kind of input prompt and
1527:30 - I'll say
1527:31 - hey let's say I'm going to use
1527:33 - multi-line
1527:36 - comment and here I'll say okay let's
1527:39 - give a message a default message you you
1527:42 - are an
1527:44 - expert in understanding
1527:50 - invoices okay you will
1527:55 - receive you will receive input
1528:00 - images as invoices I'm writing a message
1528:04 - and you will have
1528:07 - to
1528:09 - answer
1528:11 - questions B based on the input
1528:14 - image so I'm giving some prompt right
1528:18 - some prompt template like kind of stuff
1528:20 - so that I'm saying hey you need to
1528:22 - behave in this way okay you are an
1528:25 - expert in understanding invoices you
1528:27 - will receive an input image and invoices
1528:29 - and you'll have to answer question based
1528:31 - on the input image right so this is my
1528:36 - in by default you can basically say a
1528:38 - default instruction to the gini pro
1528:41 - model that you need to behave like this
1528:44 - okay now finally if submit button is
1528:49 - clicked now what should happen now let's
1528:51 - go ahead and understand with respect to
1528:53 - this when this submit button is clicked
1528:56 - first of all the image should get
1528:57 - converted into bytes I should be able to
1528:59 - get the image info then image info along
1529:02 - with the prompt should hit the germini
1529:04 - pro model right this is what we really
1529:06 - want to do so here I will say if
1529:10 - submit if I am submitting
1529:14 - if the submit button is clicked first
1529:16 - thing first what I will be requiring my
1529:18 - image data the image data will call
1529:21 - which function this function only no
1529:24 - input image setup okay so here it will
1529:27 - basically call the input image setup and
1529:30 - here we will go ahead and write my
1529:31 - uploaded file right the uploaded file
1529:34 - that I get and now I got the image data
1529:36 - right now all I to need to call is my
1529:38 - response and I will go ahead and call my
1529:40 - get gini response and and here I will
1529:43 - give my three information what three
1529:44 - information is basically going uh over
1529:47 - here input image data and
1529:51 - prompt so input is uh this input prompt
1529:54 - so I will copy
1529:56 - this then you have this image
1530:00 - data image data okay this image data you
1530:04 - have and third one is basically what is
1530:07 - your input right so your input is over
1530:11 - here so what whatever input you are
1530:12 - basically writing in this okay so all
1530:16 - this three information has basically
1530:18 - gone right so I hope everybody's clear
1530:22 - with this and finally I get my response
1530:24 - right now once I get my response all I
1530:27 - have to do is that display this specific
1530:30 - response okay display this specific
1530:33 - response so for this I will go ahead and
1530:35 - write St
1530:37 - Dot
1530:40 - subheader and I will write the
1530:43 - response
1530:45 - is and here I will write ht. WR and here
1530:50 - I will display the response okay
1530:53 - whatever response is coming over here
1530:55 - let's
1530:57 - see excited so done the project is done
1531:01 - so there is three functionalities one is
1531:04 - this one is the image
1531:06 - processing then one is simple streamlit
1531:09 - app creating your input prompt and done
1531:12 - now shall we run this how excited are
1531:15 - you will we get an error or shall we
1531:19 - just directly run it tell
1531:21 - me should we run it
1531:25 - or shall we run it
1531:29 - everyone so let's go ahead and run it so
1531:32 - here I will write
1531:33 - streamlet
1531:35 - run
1531:37 - app.py so I'm running this allow exess
1531:43 - and here we
1531:45 - go do you see this
1531:51 - everyone yeah now let me go ahead and
1531:54 - browse the file one of the invoice that
1531:56 - I downloaded it looks something like
1531:58 - this see am I able to see the sample
1532:03 - invoice right Cho let's see bigger
1532:09 - information it will obviously be able to
1532:10 - give it okay
1532:15 - okay let's take out this information can
1532:18 - we take out this information what is the
1532:20 - deposit requested in the invoice let me
1532:23 - ask what is the deposit requested come
1532:28 - on you can see the answer what is the
1532:31 - deposit
1532:32 - requested okay so I will just go ahead
1532:35 - and this is my prompt that I'm giving
1532:39 - now I will go ahead and click on tell me
1532:41 - about about the invoice now let's see
1532:43 - whether it will run or
1532:46 - not so it should be able to give me the
1532:49 - answer it is
1532:51 - running do you see the answer
1533:10 - 169.99
1533:13 - yes or
1533:14 - no right let's go ahead and see
1533:17 - something who is this invoice build
1533:21 - to who is this
1533:24 - invoice build
1533:28 - to and I will go ahead and click on tell
1533:32 - me about the invoice so who is this
1533:34 - invoice build
1533:40 - to
1533:44 - who is this invoice build to let's see
1533:47 - it's
1533:56 - running L by answer low
1533:59 - see all the same
1534:03 - information
1534:07 - good now tell me how strong this is you
1534:11 - see like do
1534:13 - like Give Love share love spread
1534:20 - love yeah any more question okay let's
1534:24 - try multil
1534:26 - language Hindi
1534:28 - invoice
1534:31 - format let's try some Hindi invoice
1534:34 - no let's save
1534:36 - this will it be able to work Hindi
1534:40 - invoice let's go ahead and browse
1534:44 - it yes we can also save the data
1534:48 - anywhere we want in databases and
1534:51 - all okay how many of you know
1535:01 - Hindi response times took little long
1535:04 - yeah we can optimize it it is a free API
1535:07 - no okay let's let's ask some complex
1535:10 - question in Hindi okay
1535:12 - I will ask in English only what is the
1535:15 - HSN see over here you find HSN HSN is
1535:19 - over here right of Lenovo 5125 I okay
1535:25 - what is the HSN
1535:26 - of
1535:31 - Lenovo
1535:33 - Lenovo the item I'm writing in English
1535:36 - see Lenovo 5125 I 5125 5 I let's try
1535:45 - tell me about the
1535:52 - invoice we can optimize this if this is
1535:54 - the format right we can optimize
1535:58 - it do you see this
1536:00 - number is it same 301
1536:06 - 0 yeah so I know in many companies
1536:09 - they'll be requiring this
1536:13 - see it is written in English
1536:17 - Hindi
1536:20 - okay let me just go ahead and write what
1536:22 - is the billing address
1536:24 - okay what is the billing
1536:29 - address okay tell me about the
1536:35 - invoice
1536:38 - right tell me about the invoice
1536:42 - take SCB building building defense
1536:49 - State Gino Maharashtra see all the
1536:52 - information is
1536:55 - here good enough see Maharashtra also it
1536:59 - is
1536:59 - taken
1537:01 - right okay see dinak is written now so
1537:05 - let's see I will write what is the date
1537:08 - of the
1537:10 - invoice
1537:15 - what is the date of the
1537:22 - invoice
1537:24 - tick 1227
1537:29 - 0221
1537:33 - good now try any invoice let's see what
1537:37 - is the cgst okay let me go ahead and
1537:40 - write
1537:42 - what is
1537:43 - the
1537:48 - cgst let's go ahead and see about the
1537:55 - invoice there is no limit of the image
1537:58 - you can upload as cgst is 80% where it
1538:01 - is
1538:02 - written okay it is given see okay GST
1538:06 - 18% is the cgst is 18% okay
1538:13 - okay uh let's see what I'll write what
1538:17 - is the
1538:19 - total what is the total
1538:24 - bill what is the total bill I'm just
1538:26 - writing anything let's see where it
1538:28 - tries
1538:30 - to yes yes you can do 500 PDF 100 PDF in
1538:34 - my next session I will show you working
1538:36 - with PDF
1538:37 - okay 1 170 392 see guys
1538:43 - amazing
1538:45 - right
1539:02 - so yeah 500,000 how much you all results
1539:06 - got correct sir
1539:08 - yes yeah nag as I'm saying any number of
1539:11 - pages take one lakh pages also it is
1539:14 - possible there we can use Vector
1539:17 - database to save
1539:19 - it so guys good
1539:23 - video hit like shower Your Love share
1539:26 - with all your friends and this was about
1539:29 - today's
1539:36 - session so tell me how was the session
1539:39 - see at the end of the day okay one more
1539:41 - thing that I really want to share so
1539:43 - that you don't miss
1539:49 - things so guys uh we are happy to
1539:51 - introduce one amazing course for you
1539:54 - that is regarding generative AI so we
1539:56 - will be building this kind of
1539:57 - application we show you how to do the
1539:59 - deployments and all so this is the
1540:02 - mastering generative AI course you can
1540:03 - go ahead and check it out in ion. page
1540:07 - okay so I'm giving you the link in the
1540:10 - comment section if you like it please go
1540:12 - ahead and watch it so here we will be
1540:15 - developing all these kind of projects
1540:16 - we'll be using Google gini we'll be
1540:18 - using open AI Lang chain Lama index you
1540:21 - can check out and again at the end of
1540:23 - the day mentors you'll be seeing myself
1540:25 - Sunny bappy so everybody will be taking
1540:28 - a part of it if you have not seen the
1540:30 - community sessions in Inon so definitely
1540:33 - go ahead and watch out and see the
1540:34 - talent of all the mentors that are there
1540:36 - but at the end of the day the projects
1540:38 - level that we going to develop is much
1540:40 - more complex with respect to this so go
1540:43 - ahead and check it out and if you have
1540:45 - any queries please do call to our team
1540:48 - counseler team which is over here in the
1540:51 - bottom of the page you'll be able to see
1540:52 - them right and uh anything that you have
1540:56 - a queries regarding you can probably
1540:57 - contact us okay so this was one of the
1541:00 - thing not only that if you are
1541:02 - interested in learning machine learning
1541:04 - deep learning anything as such or data
1541:07 - analytics we also have that there's also
1541:09 - mlops production ready projects you can
1541:11 - also join that
1541:12 - okay so yes this was from my side I hope
1541:16 - you like this particular
1541:18 - session my final takeaway is that uh in
1541:22 - the field of AI it is it is really
1541:24 - really evolving every day you really
1541:27 - need to learn if you think that you're
1541:29 - just going to learn today get a job
1541:31 - tomorrow and after that your learning
1541:33 - stops that is not at all possible Right
1541:36 - learning is continuous and you really
1541:38 - need to learn continuous you need to
1541:39 - find out ways you need to find of
1541:41 - creativity in doing the projects and uh
1541:44 - at the end of the day you work for the
1541:46 - benefit of the society right so uh this
1541:51 - is the main and amazing thing that I
1541:52 - have probably seen in this AI field is
1541:55 - that the amount of learning is amazing
1541:56 - it is quite well and the kind of things
1542:00 - that we have actually done right in the
1542:03 - AI field like everybody throughout the
1542:05 - world right it is amazing right I I can
1542:09 - definitely say like it's wow okay so uh
1542:15 - yes this was it from my side at the end
1542:17 - of the day I would again
1542:19 - suggest uh keep on looking on different
1542:23 - things that you can do with this just
1542:24 - imagine today we just did this entire
1542:27 - invoice extractor tomorrow you can think
1542:30 - of multiple use cases think in the
1542:32 - different domain Healthcare domain right
1542:35 - and uh let's see where you'll come and
1542:38 - definitely do share this content
1542:40 - everywhere in LinkedIn show your talent
1542:42 - show your things what more additional
1542:45 - thing you can basically do on top of it
1542:47 - okay so yes uh this was it from my side
1542:50 - guys I hope you like this particular
1542:52 - session if you liked it all the
1542:53 - recordings will be available also I
1542:55 - would suggest please see in the
1542:56 - description of the YouTube channel all
1542:58 - the community link will be given over
1542:59 - there uh and if you want to learn any qu
1543:02 - any courses from us you can check out
1543:04 - in. page and I will see you all in all
1543:07 - the sessions and class till then I will
1543:09 - see you all in Next Friday with one more
1543:10 - amazing
1543:11 - sessions where we'll discuss more
1543:13 - amazing use cases this was it from my
1543:15 - side have a great day bye-bye take care
1543:18 - keep on rocking keep on learning thank
1543:20 - you everyone and yes at the end of the
1543:23 - day keep sharing your knowledge with
1543:24 - everyone right uh okay so sir please
1543:28 - tell me if there is any prerequisite for
1543:30 - this course don't worry about any
1543:31 - prerequisite it will get handled only
1543:33 - thing that you really need to know about
1543:35 - generative AI is about python okay so
1543:38 - probably When You Learn Python if you uh
1543:41 - you need to have some amount of
1543:42 - knowledge of python for that also we
1543:44 - have put recorded videos in the course
1543:45 - so that you can actually check it out
1543:47 - okay uh thank you so much for your
1543:50 - wonderful efforts thank you thank you
1543:52 - thank you uh how can we integrate into
1543:55 - databases and then ret information that
1543:57 - I will show you in the next class we'll
1543:59 - use some kind of um uh we we'll try to
1544:03 - use some kind of vector databases okay
1544:07 - it'll be fun it'll be fun it'll be
1544:09 - amazing okay
1544:22 - okay let's see some more okay I'll take
1544:23 - some more
1544:25 - question sir every time we click on run
1544:28 - it trains the model with the image
1544:29 - provided then extract no it need not
1544:32 - train itself the model is already
1544:34 - trained so you give the necessary bite
1544:37 - information over there it'll be able to
1544:39 - extract all the details like OCR
1544:42 - right excellent session thank you sir as
1544:45 - I said how can we integrate with
1544:47 - databases and we will be using Vector
1544:49 - databases okay that I'll show you in the
1544:51 - next class it'll take one hour
1544:53 - session yes sir we have a lot of learned
1544:55 - from Krishna thanks to give top
1544:57 - knowledge sharing with us thank
1545:01 - you I really enjoyed my Friday evening
1545:04 - with this new learning every day like
1545:06 - every Friday I will come over there and
1545:08 - I'll teach you
1545:09 - something
1545:15 - okay it's okay so please try to learn
1545:17 - from others also because there is some
1545:20 - experience that is basically displayed
1545:22 - over
1545:23 - there
1545:35 - okay NLP is important to learn
1545:38 - generative AI yeah so let me just share
1545:40 - my screen again so that you get an idea
1545:43 - if you probably see what all things
1545:45 - you'll be
1545:47 - learning so if you go ahead and see our
1545:50 - generative AI course sorry this is
1545:52 - machine learning boot camp so in the
1545:54 - generative AI course the prerequisits
1545:56 - are uh only python is there and we will
1545:59 - be teaching you all NLP so this is
1546:01 - basically NLP we'll be teaching you all
1546:03 - these
1546:04 - things right uh NLP NLP NLP so basics of
1546:08 - NLP then we'll go with RNN and and we'll
1546:11 - try to learn
1546:25 - this
1546:33 - okay guys the team has shared some Link
1546:36 - in the
1546:38 - chat let's see
1546:41 - so which are the best books for genda
1546:44 - see guys I not suggest right now to
1546:46 - follow any books because this is not
1546:49 - fixed every day some changes are there
1546:52 - right so guys there is a temporary URL
1546:56 - link that we could see over there let's
1546:58 - see I think uh NLP is important to learn
1547:02 - generative AI new
1547:05 - comments can you make an one end to
1547:07 - tutorial on rag yes I will do that in
1547:09 - the next class
1547:26 - okay perfect so hit like guys if you
1547:31 - like this
1547:32 - session and uh there are lot many things
1547:34 - that is probably going to come in the
1547:36 - future
1547:37 - okay sir say up data scientist B so this
1547:42 - question is good
1547:49 - enough
1547:51 - sir dat
1547:55 - SST this is just for testing purpose
1547:57 - guys in front end there are lot many
1547:59 - things other than
1548:02 - this
1548:05 - Okay click on the link and join the
1548:08 - session with Chris sir
1548:12 - link so this is the link
1548:18 - right is this the
1548:39 - link
1548:52 - okay
1548:54 - uh so we are not getting any
1548:57 - notification about jobs see guys jobs uh
1549:01 - things like how you can specifically
1549:03 - apply And all I'll will be discussing
1549:04 - more about it as we go ahead okay um
1549:09 - just give me a day session time I'll
1549:12 - probably talk about this with respect to
1549:14 - resums with respect to building profile
1549:16 - and all so all those things I will
1549:18 - discuss
1549:21 - okay can we do prediction using tabular
1549:24 - data in gen what kind of
1549:28 - predictions is it something related to
1549:30 - text text you can basically do
1549:39 - it
1549:49 - okay anybody wants to
1549:52 - join this
1550:00 - session yeah prakash if you have any
1550:02 - questions please do let me
1550:05 - know you
1550:08 - can you can un mute yourself if you want
1550:11 - to
1550:15 - talk yeah Prashant do you want to talk
1550:18 - sorry prakash he got
1550:39 - disconnected okay okay
1550:41 - perfect uh are you adding feret in
1550:44 - course I will just try to see that think
1550:47 - the documentation that is available and
1550:49 - I think this is an llm model from
1550:51 - Microsoft I guess
1550:54 - right so Mahesh has joined Mahesh do you
1550:57 - want to talk
1550:59 - anything yeah hi sir it's a pleasure to
1551:02 - uh talk to you yeah hi hi mes yes please
1551:06 - tell me you want to show your face you
1551:09 - can also on your
1551:11 - video uh so actually I'm not in a
1551:14 - position to show my face uh I'm me
1551:17 - outside uh actually I'm a student of in
1551:21 - neuron and to be frank sir I'm just I
1551:25 - was just clueless initially when I
1551:27 - started to learn this uh data science
1551:30 - part so again my education background is
1551:33 - I'm from
1551:34 - biology mhm okay so I don't have any
1551:38 - background on mathematics but but to be
1551:41 - frank when I just started to learn the
1551:44 - things from in neuron so without any uh
1551:49 - excuse me so without any um knowledge on
1551:52 - mathematics also I still I'm able to
1551:55 - learn lot of things and I can just I'm
1551:59 - just getting more confidence when it
1552:01 - comes to data science topic as well as
1552:04 - I'm just getting more confidence so that
1552:07 - I can just get play in future
1552:10 - mhm
1552:11 - mhm so you're saying that how first of
1552:15 - all how is your learning things going on
1552:17 - right
1552:17 - now yes sir I'm just uh building in
1552:20 - projects and uh I started to implement
1552:23 - melops in my own architecture means like
1552:27 - implementing the mlops from scratch sir
1552:30 - I just did are you are you working
1552:32 - somewhere right now yeah I'm working as
1552:35 - a data analyst but my working nature is
1552:38 - not exactly as data analyst but somewhat
1552:42 - similar to data
1552:43 - analyst okay my suggestion in this case
1552:46 - right uh in your current company if you
1552:48 - see any ideas and if you see anything
1552:50 - that is probably coming up right try to
1552:53 - participate in that try to see that what
1552:56 - all things you can basically do over
1552:57 - there you know try to see whether you
1552:59 - can apply any data science knowledge
1553:01 - because that is the experience that you
1553:02 - can probably put as a p project in your
1553:04 - resume right and later on with respect
1553:08 - to with respect to that kind of work
1553:10 - you'll be able to tell that in the
1553:11 - interviews right in any interviews that
1553:14 - you specifically go yeah yes sir and um
1553:19 - I just want to thank you for uh being a
1553:22 - good Mentor and I'm really thankful for
1553:26 - anuron for giving me S such an good
1553:29 - support in my career so I'm just always
1553:33 - talk so I'm really excited I'm not able
1553:36 - to
1553:37 - talk okay no worries no worries so drink
1553:40 - some water and be chilled okay and keep
1553:42 - on working hard okay thank you sir thank
1553:45 - you very much
1553:48 - hello I am so much excited to talk to
1553:51 - you uh your your videos are so much uh
1553:54 - informative and uh I'm really uh glad to
1553:58 - talk directly with you like this uh I
1554:01 - used to follow your ml series and DL
1554:04 - series and uh they're very informative I
1554:06 - have enrolled to gender course also uh
1554:10 - just I would like to uh know few
1554:12 - questions sir um please kindly answer
1554:15 - I'm um I'm poor at a data stres and
1554:18 - algorithms uh will that be uh requ for
1554:21 - this generate course may know please no
1554:23 - no no no it's okay like basic inbuilt
1554:26 - data structures will be
1554:27 - sufficient um it's more about how you
1554:30 - can use generative AI to solve
1554:32 - applications right Basics that is
1554:35 - specifically required you need to be
1554:36 - good at that for cracking interviews
1554:39 - okay okay I'm I'm six years of
1554:42 - experience as a tester uh okay uh is it
1554:45 - okay just means if I get into this field
1554:49 - does companies accept my profile as a
1554:51 - tester and switching to this uh
1554:53 - transforming to this carer as a tester
1554:55 - whatever projects you're currently doing
1554:57 - make sure to apply some data science
1554:59 - stuff over there it can be automation it
1555:01 - can be anything as such because that
1555:04 - same thing you'll be able to explain in
1555:05 - the
1555:06 - interviews okay yeah yeah okay sir thank
1555:09 - you so much sir yeah thank
1555:12 - you one more question fet Apple released
1555:16 - one fet llm right are you going to add
1555:18 - this in general a course uh fet right
1555:22 - now the entire documentation is not
1555:24 - available so once let's say once we
1555:26 - probably go and we see lot of use cases
1555:28 - then we'll try to add it okay okay sir
1555:31 - any update that will probably coming
1555:33 - then and there we'll try to add it okay
1555:35 - okay sir yeah thanks yeah thank
1555:38 - you yeah yeah Mahesh please unmute
1555:43 - yourself yes sir sir is this session
1555:45 - being
1555:47 - recording
1555:48 - yeah okay fine and uh sir is there is
1555:52 - there any option for me to visit anuron
1555:55 - so that we can just meet um yeah sure
1555:59 - you can come Inon in the working days
1556:02 - right yeah Monday to Friday anytime H
1556:06 - yeah sure sir okay so that I can just uh
1556:09 - talk to personally so uh maybe maybe
1556:12 - within that within two or 3 months I
1556:15 - might be getting uh place I'm applying
1556:17 - for the jobs so once I just transing
1556:20 - means I'm just placing in a new company
1556:23 - so I'll be coming uh to IUN and directly
1556:27 - meeting to you okay sure sure sure
1556:31 - definitely okay you thank you
1556:35 - much yeah Danish
1556:38 - SA you can unmute yourself yeah hello
1556:42 - sir yeah hi
1556:48 - yeah yeah
1556:50 - yeah please is it okay
1557:08 - for
1557:29 - students
1557:38 - thank
1557:40 - as a
1558:08 - fresher
1558:22 - [Music]
1558:34 - M definitely sir I want
1558:37 - to sir may
1558:50 - [Music]
1558:55 - defitely be
1559:08 - there
1559:12 - and thank you so much for sir thank you
1559:16 - thank you yeah thank you definitely
1559:38 - thank
1560:01 - yes thank you sir thank you thank you
1560:03 - sir
1560:04 - yeah yeah thank
1560:08 - you
1560:10 - okay
1560:13 - uh
1560:16 - Joy
1560:19 - rubul P
1560:23 - questions please
1560:25 - P
1560:30 - Jo sir from past three years I'm
1560:32 - following your YouTube channel sir M uh
1560:36 - Mission learning I studied your mission
1560:38 - learning sir my my aim is I'm following
1560:42 - generative AI course now sir can you
1560:43 - please provide a free in your YouTube
1560:46 - channel sir 8,000 is too much sir for us
1560:50 - so that's why I'm asking
1560:53 - sir anyhow sir we have done live
1560:56 - Community session about generative AI a
1560:58 - lot of free content we have uploaded
1560:59 - already and more free content whatever
1561:02 - will be coming we still be uploading
1561:04 - don't worry about it sir
1561:08 - okay
1561:10 - yeah but llama model these models is not
1561:13 - uploaded in your YouTube channel right
1561:15 - sir it will get uploaded sir give some
1561:17 - time then we'll try to upload that also
1561:19 - but it needs to take time no sir we also
1561:21 - need to create uh we need to get time
1561:24 - for recordings and all we'll be doing
1561:26 - that kind in live session let's say next
1561:28 - Friday I'll do about llama index and all
1561:33 - okay sir uh M course era is there now
1561:37 - sir which which course we want to follow
1561:40 - out for generative AA llm models because
1561:43 - I am the beginner of this I learn
1561:46 - machine learning from your YouTube
1561:47 - channel if I follow want to follow
1561:49 - course era which uh because course era
1561:52 - is offering for our University free so
1561:54 - that's why I'm
1561:55 - askre sir I did not check out corsera
1561:58 - all the courses sir yet you know I did
1562:00 - not check it out like which one is there
1562:02 - but I think some or the other will
1562:04 - you'll be able to find it over there sir
1562:06 - okay but I did not check it out and that
1562:08 - is the reason I I usually learn from
1562:10 - documentation
1562:16 - githubschool but I don't have any idea
1562:20 - about corsera
1562:22 - Sir okay sir thank you sir while you are
1562:25 - while you are explaining in your YouTube
1562:28 - channel sir first explain the
1562:31 - documentation for me also so that next
1562:33 - time we will read little bit the
1562:35 - documentation while we are reading the
1562:37 - documentation we did not get the content
1562:39 - if you tell the keywords now then only
1562:42 - we will understood that we will digest
1562:44 - while we are I mean reading the research
1562:47 - paper like that sir sure sir sure I'll
1562:50 - do that sir
1562:54 - sure thank you sir okay yeah next
1563:01 - question yeah please go ahead
1563:06 - yeah very big very big thanks for thanks
1563:09 - to you uh so I I am your fan since you
1563:14 - started I new run so after that only I
1563:18 - come to know that you are teaching so
1563:19 - many uh courses belongs to a machine
1563:23 - learning everything so initially I'm
1563:27 - worrying about which one I need to
1563:29 - choose so whether I need to choose
1563:31 - machine learning or whether I need to
1563:33 - choose that and so I want to learn in
1563:36 - multiple things but I cannot
1563:39 - on single things okay by luckily uh my
1563:43 - my in my work space I have a opportunity
1563:47 - to work on gener P one years when the
1563:50 - open a released okay sir so I know
1563:54 - something about that so I I know
1563:58 - something about the open a what are the
1563:59 - features it can do so I have a handon
1564:02 - training on that one so now you announce
1564:05 - this generative a course so it will help
1564:07 - me a lot so I'm choosing your way that I
1564:10 - need to break a leg on this General ta
1564:14 - so I admire you and I like your videos
1564:17 - so I already purchased your course so I
1564:20 - am excited to start on January 18
1564:22 - onwards so very big thanks to you but
1564:25 - what you are um so I'm learning like a
1564:30 - surviving language only so whatever the
1564:33 - whatever the mean my Works needs so I'm
1564:37 - go and picking those kind of stuff
1564:39 - reading the stuff then I'm working on it
1564:41 - like the way so whatever the things you
1564:43 - example you saw in today's session I
1564:46 - have have completed those scenarios when
1564:48 - the J announced that you can use you can
1564:51 - build this application on WE that you
1564:53 - you put some video right the next day
1564:56 - itself I explored all the things so only
1564:59 - that I'm excted to do is that video part
1565:01 - only but nobody I don't see any video
1565:05 - video
1565:06 - paring yeah video paring yeah yeah don't
1565:08 - worry we will I'll create a video on
1565:10 - that also so don't worry okay so exact
1565:13 - exact to work on Inon no sir our data
1565:16 - science team has already done that okay
1565:19 - okay super passed 20,000 videos so we
1565:23 - have created a support system which is
1565:24 - pass 20,000 videos for the support
1565:27 - Channel very great very great to know I
1565:30 - ex from you yeah we'll speak to you sir
1565:33 - thank you thank you thank you for yourk
1565:35 - you thank you for your s and you are you
1565:38 - are boosting our confidence more more
1565:41 - thank you thank you prashan thank you
1565:44 - yeah kimah
1565:47 - yeah hello sir hello hello H hello sir I
1565:52 - am from
1565:53 - Pakistan yeah hi hi sir I'm your big p
1565:58 - and I I have a
1566:01 - question I am a student of electrical
1566:03 - engineering and I want to learn machine
1566:05 - learning and deep
1566:07 - learning I want to Chase your course uh
1566:10 - uh which course you would suggest for me
1566:13 - sir just go to ion. website there will
1566:16 - be a counseler number okay uh just try
1566:19 - to contact them in WhatsApp they will
1566:21 - help you out with all the information
1566:23 - right there is a ml boot Cam that is
1566:24 - probably coming up you can join that
1566:26 - course that will be completely from
1566:29 - Basics okay so there you can probably
1566:31 - join that but again go to ion. for more
1566:35 - better communication I think you can
1566:37 - contact the there'll be a number for The
1566:39 - Counselor or you just fill up the form
1566:41 - the counselor will try to contact you
1566:43 - sir oh thank you sir yeah thank you
1566:47 - thank you yeah Dean
1566:51 - josi sir sir hi uh sir I'm engine I'm
1566:57 - btech engineering first year student and
1567:01 - my specialization in AI n
1567:03 - DS so I'm I'm asking with you that sir
1567:08 - AI in the AI my college was not studying
1567:13 - this AI specialization they were already
1567:17 - uh the basic languages python uh C+ and
1567:21 - this then sir I'm what language I'm
1567:26 - beginning to start begin to start so uh
1567:31 - are you guide me for the AI and DS and
1567:34 - the
1567:36 - best okay so python
1567:39 - is the programming language you have to
1567:40 - probably start with okay in this field
1567:44 - because nowadays the cloud platforms
1567:46 - everywhere the libraries everything is
1567:50 - something that is related to Python and
1567:52 - that is only coming up in the future
1567:54 - okay yes sir
1567:57 - sir can I speak in Hindi h z z I'm not
1568:02 - in the proper way to speak in
1568:05 - English yeah yeah it's okay Hindi
1568:16 - a
1568:18 - only in jaur skit
1568:22 - College only a but I'm
1568:27 - watching
1568:37 - Dr
1569:07 - starting beginning
1569:37 - tops
1570:07 - sir
1570:35 - mainly
1570:37 - basic
1570:49 - B right okay sir
1571:03 - yeah thank
1571:06 - Youk thank you thank you
1571:10 - yeah Aman Kumar Helm yes sir J sir J
1571:15 - jind
1571:23 - by dat science machine learning
1571:37 - learning
1571:51 - [Music]
1571:57 - UK based remote job but machine learning
1572:01 - deep learning
1572:04 - basically data entry or some research
1572:06 - work or LCA related
1572:13 - basally data science machine
1572:30 - learning
1572:36 - full start applying for
1572:45 - both preparing for government
1572:48 - job I started learning about data
1572:52 - science data
1573:07 - analytics
1573:09 - okay
1573:11 - sir internship like we will get like
1573:15 - free free
1573:21 - internship
1573:25 - [Music]
1573:31 - 11a
1573:36 - descrition okay sir sir okay thank you
1573:40 - sir thank you
1573:44 - sir hel yeah go ahead yes uh good
1573:48 - evening it's good morning here in the
1573:50 - United States I hope it's okay that I'm
1573:52 - not from India I
1573:55 - wanted wanted to thank you for the the
1573:58 - videos you posted for Gemini Pro I I did
1574:01 - all of them and I was on the road so I
1574:05 - couldn't watch this one um or follow
1574:07 - along but I will watch the recording and
1574:11 - do it as well I subscribed or I enrolled
1574:13 - to the class the master class that is
1574:16 - coming up so wanted to ask if Gemini Pro
1574:19 - will also be covered yeah yeah we'll add
1574:22 - that up because see any updates that
1574:24 - will probably come up with respect to
1574:26 - any llm models we'll try to update that
1574:29 - okay and which we feel that it is
1574:30 - important and it can really be a
1574:32 - breakthrough for developing my
1574:33 - application we will keep on updating it
1574:37 - wonderful one other question as far as
1574:40 - machine learning deep learning NLP it
1574:43 - sounds like NLP you're going in depth to
1574:46 - some quite a bit will there be any
1574:49 - machine learning or deep learning that
1574:50 - we should study up on before the
1574:53 - course uh whatever is the prerequisite
1574:56 - we'll try to teach in the course
1574:58 - whatever is necessary for that okay but
1575:01 - again at the end of the day if you
1575:03 - really want to become a full-fledged
1575:04 - data scientist who has capabilities of
1575:06 - machine learning deep learning
1575:08 - and generi I think you need to also
1575:10 - learn about machine learning and deep
1575:12 - Lear SE okay to that point I'm I don't
1575:15 - think I'm I want to become a machine
1575:18 - learning engineer I want to more be on
1575:21 - the on the front lines creating
1575:24 - applications but I want to know enough
1575:27 - with what I do I don't I don't have any
1575:29 - uh computer uh programming background I
1575:32 - just started learning pythons you know
1575:34 - four months ago then this course will be
1575:36 - perfect for you I think uh then then you
1575:38 - don't have to probably work worry about
1575:40 - that it depends on the kind of work that
1575:42 - you're specifically doing okay wonderful
1575:46 - well thank you very much again really
1575:47 - appreciate it thank you thank you
1575:50 - sir so when will the course start I
1575:52 - think you can go ahead and check out in
1575:54 - the course dashboard uh the dates are
1575:56 - basically given it is 28th Jan 2024
1576:02 - ni okay guys so because of time
1576:04 - constraint it's almost 10 uh this was it
1576:07 - from my side I hope you like this
1576:09 - session I hope you liked it uh please do
1576:11 - make sure that you hit like share with
1576:13 - all your friends share your learning
1576:15 - develop the application from your side I
1576:17 - will see you all in the next video next
1576:18 - Friday session we'll do some more
1576:20 - amazing things we'll try to use Vector
1576:22 - databases we'll try to create more
1576:24 - projects and we'll implement it some
1576:26 - same thing so thank you have a great day
1576:28 - and keep on rocking keep on learning and
1576:30 - have a happy weekend that is coming up
1576:32 - thank you guys bye-bye take care perfect
1576:35 - uh now let's go ahead towards the agenda
1576:37 - so what is the agenda of this particular
1576:39 - session what are we specifically going
1576:41 - to discuss right and uh what is the end
1576:44 - to- end project that we are going to
1576:46 - develop over here so it is very simple
1576:49 - the agenda is that we will be developing
1576:52 - a text to
1576:54 - sequal application or I'll say llm
1576:57 - application now just by the name you
1577:00 - think that text to sq may be simple here
1577:03 - we will be having a specific database
1577:05 - we'll write some queries we'll insert
1577:07 - some records
1577:08 - and then we try to develop llm
1577:10 - application wherein the main task of
1577:12 - this llm application will be that take
1577:15 - the text whatever text or prompt that
1577:17 - you give let's say I I ask uh hey tell
1577:21 - me tell me in this particular classroom
1577:23 - how many students are there right so
1577:26 - this text will be sent to the llm model
1577:29 - and here the llm model will be Gemini
1577:32 - Pro okay and this Gemini pro model will
1577:35 - specifically give you a query right and
1577:39 - this query will try to execute and read
1577:41 - from my SQL database okay so this is the
1577:44 - entire project that we are going to do
1577:47 - right we need to have a c database we
1577:48 - need to have a table over there and this
1577:52 - entire project will be buil in this
1577:53 - specific way itself right so this text
1577:56 - that you will be seeing this is nothing
1577:58 - but it is a prompt okay so this will be
1578:00 - my input prompt in English language and
1578:03 - then this will be sent to the llm llm is
1578:05 - nothing but our Gman pro model this will
1578:08 - in turn convert this into a query and
1578:11 - then with the help of SQL libraries
1578:12 - we'll go ahead and hit the SQL database
1578:14 - and get the response okay so this is the
1578:17 - entire agenda of this specific project
1578:19 - and we'll also try to see how we can
1578:21 - actually deploy this okay so everybody
1578:24 - clear with the agenda what you are going
1578:26 - to do in this specific project itself
1578:28 - yeah can I get a quick yes if you are
1578:31 - able to hear me out I hope you are able
1578:35 - to understand this project that we are
1578:36 - going to do and this is is going to be
1578:38 - done by Google gini pro okay we will do
1578:41 - the line by line coding from scratch so
1578:43 - just give me a quick yes if you got the
1578:46 - entire agenda of the specific project
1578:48 - yeah and we'll develop part by part so
1578:51 - just quickly give me a quick yes guys
1578:53 - come on come on be somewhat active you
1578:56 - know you need to be active then only the
1578:59 - session will be fruitful okay so I would
1579:01 - suggest please be active and try to say
1579:04 - yes give some symbol give some thumbs up
1579:07 - that would be quite amazing okay perfect
1579:11 - so let's go ahead and let's start this
1579:13 - particular project now here how we are
1579:16 - going to implement things right
1579:17 - implementation part so the first step
1579:20 - what we are going to do is that you can
1579:22 - use any SQL database as such here I'll
1579:25 - be suggesting to use sqlite so that
1579:27 - we'll be able to show everything in the
1579:29 - demo itself and this is just not
1579:31 - restricted to sqlite or SQL database you
1579:33 - can also do it in a no SQL database you
1579:35 - can do it in Cassandra DB you can do it
1579:37 - in mongodb whatever database you
1579:39 - specifically want second uh we'll do
1579:41 - this setup we'll insert some records
1579:44 - okay we'll insert some records and again
1579:47 - this all things will do with my Python
1579:49 - programming language okay so Python
1579:51 - programming language will be used to do
1579:53 - this the second thing after we implement
1579:56 - this we will start creating our llm
1579:58 - application and inside this llm
1580:00 - application we'll create a simple UI
1580:03 - where you can specifically write the
1580:04 - query and this llm application will
1580:07 - probably communicate with gini Pro and
1580:10 - then it will communicate to the SQL
1580:12 - database to give us the answer okay I
1580:15 - just written two steps over here so you
1580:17 - may be thinking that this may be simple
1580:19 - but it is not that simple you will be
1580:21 - seeing there will be a lot many things
1580:22 - that will probably be coming over here
1580:24 - okay and uh uh again at the end of the
1580:29 - day please code along with me uh see
1580:31 - what all things we are specifically
1580:33 - writing in this what all requirements
1580:34 - are there you know and step by step
1580:36 - we'll go ahead and do the implementation
1580:39 - perfect uh so everybody has got the
1580:42 - agenda and the implementation part so
1580:43 - let me go ahead and open my vs code okay
1580:46 - now for opening the vs code over here
1580:49 - you'll be able to see the first step you
1580:52 - know when we start any project is that
1580:54 - what we really need to do please answer
1580:56 - someone we really need to create a
1580:59 - environment right now a interview
1581:01 - question may come for you like why you
1581:03 - specifically require environment or why
1581:05 - do you create an environment for every
1581:06 - project that you probably create right
1581:08 - there's a simple fundamental in this is
1581:11 - that every project has a different
1581:13 - dependencies you really require
1581:15 - different libraries over there right so
1581:17 - that is the reason you have to create
1581:19 - different different environment for this
1581:21 - again create an environment I will just
1581:23 - go ahead and open my terminal okay so
1581:26 - this is my terminal you can also do it
1581:27 - in Powershell you can do it in command
1581:30 - prompt so the first prerequisite is that
1581:32 - you really need to have Anaconda
1581:34 - installed okay so here is my
1581:38 - uh in this particular location I have my
1581:40 - project so let's go ahead and quickly
1581:42 - create my environment so go ahead and
1581:44 - write cond create minus P VNV python
1581:49 - okay always remember as I said that
1581:52 - Google gini pro works well with 3.10
1581:55 - right sorry greater than 3.9 version so
1581:57 - that is the reason I'm going to use 3.10
1582:00 - and it is going to ask me for a
1582:02 - not request saying that whether it
1582:05 - should go ahead with the installation or
1582:06 - not so I give that preand that symbol AS
1582:09 - why why basically means yes so let me
1582:12 - quickly go ahead and create this so you
1582:14 - also can parall start creating it guys
1582:17 - okay go ahead and create it uh everybody
1582:21 - go ahead and create the environment
1582:23 - itself so be work along with me then
1582:26 - you'll be able to understand
1582:30 - everything go ahead and create the
1582:32 - environment and let me know once the
1582:33 - environment is created come on and hit
1582:36 - like if each and every step you are able
1582:38 - to work out and at the end of the day I
1582:40 - will also give you the entire GitHub
1582:42 - code so that you'll be able to see it
1582:44 - okay so quickly just tell me whether you
1582:48 - will you are able to create a new
1582:50 - environment or not I'll wait I'll wait
1582:52 - slowly uh like I want everybody to
1582:55 - execute it and probably you can go along
1582:58 - with me and you can actually execute
1583:00 - each and every line of code along with
1583:02 - the project okay so at the end of the
1583:04 - day I don't want you to just see the
1583:06 - code but also
1583:07 - Implement along with me okay so perfect
1583:11 - over here so nanu is along with me he's
1583:13 - also implementing things that's
1583:16 - great everyone come on create the
1583:20 - environment along with me and give a
1583:21 - quick confirmation if you are able to do
1583:23 - it okay there are 64 people watching I
1583:26 - want everyone of you to do it along with
1583:28 - me come on quickly let's do this
1583:33 - okay
1583:35 - great so in M done okay okay sir yes yes
1583:40 - yes okay so I hope everybody has done
1583:43 - the first step now as usual I will go
1583:45 - ahead and clear the
1583:47 - screen and now what we are going to do
1583:50 - in the next step is that here you'll be
1583:52 - able to see my V andv environment is
1583:53 - created okay in this specific
1583:56 - environment we will go ahead and start
1584:00 - installing all the libraries so for this
1584:02 - we need to activate the environment so I
1584:04 - will go ahead and write p activate VNV
1584:09 - right so cond activate VNV I'm giving
1584:12 - this specific folder location over here
1584:14 - and once I execute it here you'll be
1584:16 - able to see that my path has changed now
1584:18 - it is inside my VNV environment okay so
1584:21 - this is the second step step by step we
1584:23 - are specifically doing it so please
1584:26 - participate in this start implementing
1584:28 - things you know give me a confirmation
1584:30 - it would be really great okay sir can
1584:34 - was this actually I could not complete
1584:35 - ml it's okay you can also watch this the
1584:37 - prerequisite is only python okay uh
1584:40 - perfect so this is done which
1584:42 - application you are using what do you
1584:44 - mean by application I'm using a vs code
1584:46 - so there only I'm probably writing the
1584:48 - code itself okay perfect so done we have
1584:53 - activated the environment now let's go
1584:54 - ahead and create our requirement.
1584:57 - txt
1584:59 - requirements.txt file okay now
1585:02 - requirement. txt what it says it it
1585:06 - basically says that what all libraries I
1585:09 - may specifically require you know so for
1585:12 - this let me go ahead and write all the
1585:14 - libraries that I'm actually going to use
1585:16 - one is streamlet okay because we are
1585:18 - going to create the front end with
1585:20 - streamlet the other one is Google
1585:22 - generative Google generative
1585:25 - AI now this Library also we require
1585:28 - because at the end of the day we are
1585:29 - going to use Google gini pro the another
1585:32 - one is python. EnV now why we require
1585:36 - this Library so that we can load all our
1585:37 - environment variables and as you all
1585:39 - know that we are going to create a
1585:41 - Google gini pro uh API and then we are
1585:45 - going to insert that in our environment
1585:46 - variable okay um along with this uh I
1585:51 - think this three libraries will be more
1585:53 - than sufficient to start with perfect
1585:56 - okay great so this three libraries I'm
1586:00 - going to use over here now once I have
1586:02 - actually written all these libraries
1586:03 - over here then what I'm going to do is
1586:06 - that
1586:07 - go ahead and write pip
1586:12 - install minus r requirement. txt okay so
1586:16 - once I go ahead and write pip install
1586:18 - minus r requirement. txt you'll be able
1586:21 - to see that all the installation of all
1586:23 - these libraries will happen okay and
1586:25 - this is actually happening in the v EnV
1586:27 - environment so please go ahead and do
1586:29 - this step create your requirement. txt
1586:33 - and then after that start doing the
1586:35 - installation and this is the basic
1586:37 - initial step that we really need to do
1586:40 - in every project so till here
1586:42 - everybody's clear give me a thumbs up
1586:44 - give me some symbol some something
1586:46 - laughing emoji right hit like and if you
1586:50 - have chances call all your friends in
1586:52 - this live session okay come on this kind
1586:54 - of sessions you'll not get it anywhere
1586:56 - live that also I'm coding along with you
1586:58 - live so that you understand all these
1587:00 - things come
1587:01 - on
1587:05 - so
1587:07 - great sir all of the requirements for
1587:09 - this project are free yes absolutely
1587:11 - free you don't even have to put credit
1587:14 - card that much free okay so uh the
1587:18 - installation is basically happening
1587:19 - please let me know whether the
1587:20 - installation is done from your end or
1587:23 - not okay and hit like come on you need
1587:27 - to probably see the entire
1587:29 - session and code along with me that is
1587:32 - the main purpose of coming life you have
1587:34 - to code along with me okay so this was
1587:38 - one of the question sir all of the
1587:39 - requirements for the projects are free
1587:41 - yes it is completely free I believe in
1587:43 - open source so that you don't have to
1587:45 - pay anything over there okay perfect the
1587:48 - installation has been done we are good
1587:51 - to go over here now great can you give
1587:54 - me a thumbs up if the installation if
1587:56 - you have done at least partially you
1587:58 - have done the installation come on let
1588:00 - me
1588:03 - know great now we will go ahead and
1588:06 - create ourv file now for our EnV file
1588:10 - environment file we require Google gini
1588:13 - pro API okay so what I will do I will
1588:16 - quickly go ahead
1588:18 - and go to this website which is called
1588:21 - as maker maker suit. goole.com
1588:25 - slapp API key okay I just change my
1588:28 - email ID because I've created my API key
1588:31 - and another email ID okay so go to this
1588:34 - particular website which is called as
1588:35 - maker suit . google.com /a/ API key okay
1588:41 - all keys needs to be put yes so just go
1588:44 - ahead and click on this create API key
1588:46 - new project so this will basically
1588:48 - create your API key for Google giny okay
1588:52 - so go ahead and click this right once
1588:54 - you probably click it you'll be able to
1588:56 - see this kind that is getting created
1588:58 - the API key I've already created it so I
1589:00 - will go ahead and copy it from here okay
1589:02 - so I have copied it from here okay so
1589:05 - everybody are you able to do this step
1589:09 - just let me know and if you're following
1589:11 - let me know okay I want everyone of you
1589:14 - to implement along with me please that
1589:17 - is a request then this session will be
1589:19 - fruitful okay if I keep on teaching like
1589:22 - this if if you say that no I'll do the
1589:24 - implementation later on trust me later
1589:26 - on nothing will happen you not be able
1589:28 - to do it you know if you give excuses
1589:31 - and keep on postponing things uh that
1589:33 - will not work out you know when you have
1589:35 - an opportunity when you're seeing this
1589:37 - live please go ahead and Implement along
1589:39 - with me great so can you add the link
1589:44 - okay perfect let me go ahead and add it
1589:46 - over here let me go ahead and add from
1589:50 - stream key
1589:52 - okay so I am adding this link over
1589:57 - there perfect is everybody able to see
1590:00 - the link
1590:02 - now
1590:04 - yeah yes yes
1590:10 - great now from this link you have to
1590:13 - create your API key once this is done go
1590:17 - to the environment variable now and now
1590:20 - for this API key you really need to
1590:21 - create a key itself right so how do you
1590:24 - create a key over here so here I will
1590:26 - keep it in the form of key value pairs
1590:29 - so here you can see that I've use the
1590:31 - key that is Google API key and then this
1590:34 - is my key that I've actually copied it
1590:36 - from there okay so please keep in this
1590:39 - format with respect to the key value
1590:41 - pairs okay and initially you definitely
1590:43 - require this because if you don't have
1590:45 - the right key your application is not
1590:47 - going to work
1590:49 - perfect great now this is done our
1590:52 - environment key is set we have activated
1590:54 - the environment we have installed all
1590:56 - the requirements okay now let me go to
1590:58 - my
1591:00 - notepad now the first thing with respect
1591:03 - to the implementation as I told you that
1591:04 - we will take a database like cite right
1591:07 - and we'll insert some records to just
1591:09 - show that there are some records there
1591:11 - is a table there is a database there is
1591:14 - there is a sqlite over there you know so
1591:16 - that you can query you can query from
1591:19 - those particular SQL database itself
1591:21 - okay so for this what I'm actually going
1591:23 - to do quickly I'll go ahead and create
1591:25 - one file let's say this file name is
1591:27 - sqlite dopy okay so here I'm going to
1591:30 - write my code and this code will be
1591:34 - responsible in inserting any records in
1591:37 - the sqlite database okay so I'm going to
1591:40 - close this over here and now I'm going
1591:42 - to start writing my code and remember
1591:45 - one thing guys over here whatever code
1591:47 - I'm writing this is something also this
1591:50 - will also help you to understand how we
1591:52 - can connect python with sqlite and how
1591:54 - we can insert records and all okay so
1591:57 - first of all uh to start with I'm going
1591:59 - to import sqlite so sqlite is again a
1592:03 - lightweighted database okay sorry sqlite
1592:06 - right uh three so we are going to by
1592:09 - default in Python 3 right you have this
1592:11 - imported already okay now we will go
1592:14 - ahead and
1592:16 - connect connect to the cite database
1592:20 - okay cite
1592:23 - database now for this I usually write
1592:25 - the code AS connection is equal to I
1592:28 - will go ahead and write
1592:31 - connection connection is equal to sqlite
1592:35 - 3 do
1592:38 - connect and the I will keep a database
1592:40 - name let's say the database name is
1592:42 - student. DB okay so this is my database
1592:46 - name I'm going to create my database in
1592:48 - this specific name okay so in short what
1592:52 - we are doing is that we connecting to
1592:53 - this particular database so if this
1592:55 - database does not exist okay then it is
1592:58 - going to create this new DB okay so this
1593:00 - is the first step the second step is
1593:03 - that we'll create a
1593:08 - cursor object to insert records to
1593:12 - insert and create tables let's say to
1593:14 - insert records or create table because
1593:17 - inside a database we going to create a
1593:19 - table right so till here I hope
1593:22 - everybody's clear what we are
1593:23 - specifically doing because this will be
1593:25 - a this will be another py file which
1593:27 - will be responsible in creating your
1593:29 - database it will also insert all the
1593:32 - records okay so please do along with me
1593:34 - so that you'll be able to understand
1593:36 - perfect now what we are going to do over
1593:39 - here is that quickly we will go ahead
1593:41 - and create a cursor object so for this
1593:43 - we will go ahead and write
1593:46 - cursor cursor is equal to
1593:51 - connection connection dot cursor so that
1593:54 - basically means inside this particular V
1593:58 - database connection right whatever I'm
1594:01 - basically using this particular function
1594:02 - this method will be responsible in
1594:04 - traversing the entire table going
1594:06 - through all the records and all whenever
1594:08 - we try to insert or retrieve the records
1594:10 - okay so this method will be responsible
1594:13 - for doing all those things now we will
1594:15 - go ahead and create the table right now
1594:18 - with the help of this cursor object we
1594:20 - will try to create the table now here
1594:22 - will be my table
1594:24 - info let me go ahead and create my table
1594:27 - info and I will say this will be three
1594:29 - columns okay and let me start writing my
1594:32 - query name so here I will say create
1594:35 - table
1594:37 - student I'll try to write it in capital
1594:39 - letter and inside this I will use first
1594:43 - first parameter or first uh variable
1594:45 - right name and here I'm going to use
1594:48 - this as we care and let me go ahead and
1594:51 - write to 25 character so that basically
1594:53 - means name is a field okay and in that
1594:57 - it supports variable character you can
1594:58 - write numbers integers uh values string
1595:01 - anything that you specifically want to
1595:03 - write so this will be my first first
1595:06 - First Column you can basically say in
1595:07 - that way in that particular table second
1595:10 - one is let's say I go ahead
1595:13 - and uh go ahead and write something
1595:15 - called as class okay so I'm writing the
1595:18 - student information in which class he or
1595:21 - she may study um and this class will
1595:25 - also be a Vare and inside this I will go
1595:28 - ahead and write this will be my two 2 25
1595:30 - characters okay and the third parameter
1595:33 - I'm going to specifically use is
1595:34 - something called as
1595:38 - let's say I'm going to write this as
1595:42 - section so this will basically be my
1595:44 - section and here also I'm going to use
1595:45 - my VAB and this will also be 25
1595:48 - character so once we do this we will
1595:50 - close this entire command that the query
1595:54 - that we specifically have so simple
1595:56 - query initially we'll just go with
1595:59 - simple one so that you'll be able to
1596:01 - understand it so sqlite 3 wasn't in
1596:04 - requirement file Yeah by default with
1596:06 - python 3.10 cite 3 comes installed so
1596:09 - this is going to work okay I've already
1596:11 - tried it out fine we have done the table
1596:15 - info over here and you'll also be able
1596:17 - to see that now what I'm going to do is
1596:19 - that I'm going to create this specific
1596:21 - table okay so for creating this specific
1596:24 - table I will go ahead and write
1596:26 - cursor dot
1596:29 - execute table okay so this this table
1596:34 - info cursor do execute so as soon as
1596:37 - this line gets executed this table is
1596:39 - going to get created with the name of
1596:41 - student okay perfect now we will go
1596:44 - ahead and insert some more
1596:47 - records okay now for inserting this
1596:51 - records how do you write an insert
1596:53 - statement so here I will go ahead and
1596:56 - write cursor.
1596:59 - execute okay let me go ahead
1597:03 - and create this multi-line comment
1597:06 - and let me say that what is the command
1597:08 - I will say insert into
1597:12 - students student of student student
1597:16 - values insert into student
1597:23 - values inser into student values and the
1597:26 - values will be the three parameters that
1597:29 - I'm going to give name class and section
1597:31 - okay so here I'm going to use the name
1597:34 - as
1597:35 - crish then let's say the section or the
1597:38 - class that he is probably studying is
1597:40 - data science okay and over here you'll
1597:44 - be able to see I'm also going to use a
1597:46 - section let's say section is a okay so
1597:49 - this three information you'll be able to
1597:51 - see as soon as I execute this will
1597:54 - basically be inserting this record in
1597:56 - the data science like with this
1597:57 - information the name the class and the
1598:00 - section okay so I will copy this
1598:01 - entirely so this will be my first record
1598:04 - second record third record fourth record
1598:06 - five records let's let's go ahead and
1598:08 - see with respect to five records okay
1598:10 - here I will change keep on changing the
1598:12 - data right now when I say I'll keep on
1598:15 - changing the data that basically means
1598:17 - I'm going to use my second record as
1598:19 - let's say I here I will write sudhansu
1598:22 - okay so Dano data science and I will say
1598:25 - this belongs to section B okay uh let's
1598:30 - go ahead and write more over here let me
1598:32 - go ahead and write darus so Darius is
1598:35 - also in data science SS and let's say
1598:36 - he's also in section A okay I will go
1598:40 - ahead and write one more record because
1598:42 - let's say because is in another section
1598:45 - which is called as devops and this is
1598:47 - section A and let me go ahead and one
1598:50 - more record like the I will go ahead and
1598:52 - write
1598:53 - thees and this time I will keep thees
1598:56 - also in
1598:58 - devops okay and let let it be in section
1599:01 - A so this information I am probably
1599:04 - inserting in in this specific table okay
1599:08 - all this information will be basically
1599:09 - inserted in the specific table now as
1599:12 - soon as it is inserted we will display
1599:15 - all the
1599:17 - records okay here I will say
1599:21 - print the
1599:23 - inserted records are okay and let me go
1599:28 - ahead and write data is equal to
1599:32 - cursor.
1599:34 - execute okay and let me go ahead and
1599:37 - write this triple code statement so that
1599:40 - it can be multi-line also select star
1599:44 - from
1599:46 - student okay the table name is capital
1599:49 - so once I probably execute this I will
1599:51 - have all the information over here in
1599:53 - the data and then what I will do I will
1599:55 - write for Row
1599:58 - in
1600:00 - for for Row in data I will go ahead and
1600:04 - print
1600:06 - my row okay so this is what we are going
1600:09 - to do so this becomes my entire query
1600:12 - with the help of Python programming
1600:14 - language where I am creating a database
1600:17 - I'm creating a table I'm executing this
1600:20 - particular table info I am inserting
1600:22 - records I'm displaying all the records
1600:25 - everybody clear with this can you get me
1600:28 - can you tell me whether you're able to
1600:30 - understand till
1600:32 - here quickly come on let me know till
1600:35 - then I I'll drink some
1600:45 - water yeah
1600:49 - everyone come on quickly yes or
1600:53 - no sudu says yes Prashant says yes what
1600:57 - about others come on guys you are not
1601:00 - implementing is sad you know so if you
1601:03 - do not show interest then there will be
1601:05 - no of doing this live session right div
1601:07 - also says yes what about others 84
1601:10 - people are watching please do hit like
1601:13 - let's make it a target of at least 100
1601:15 - likes in this session you know because
1601:18 - if this session we teach in some batch
1601:20 - you know it'll be so fruitful for us
1601:22 - come on we are doing this completely for
1601:24 - free for the entire Community you really
1601:26 - need to show some proactive measures
1601:28 - okay either be active otherwise drop off
1601:32 - if you feel that this is not important
1601:34 - for you okay
1601:36 - done perfect now let me go ahead and
1601:39 - open the terminal and now this time what
1601:41 - I will do I will execute this file and
1601:43 - let's see once we execute this
1601:45 - particular file that basically means uh
1601:48 - we will be able to see our database that
1601:51 - is created okay database that is created
1601:55 - so in order to execute this file I will
1601:58 - go ahead and write python sqlite dopy
1602:02 - okay so if I execute this my data should
1602:06 - get created my table should get created
1602:08 - and at the end of the day so here you'll
1602:11 - be able to see right at the end of the
1602:13 - day One DB file should be created over
1602:14 - here and the name should be student. DB
1602:17 - okay so let's see whether we'll be
1602:19 - getting any error or it'll just execute
1602:21 - perfect the inserted records are chrish
1602:23 - data science a sudu data science B
1602:26 - Darius data science a vikash devops a
1602:29 - the dev off say so student. DB file is
1602:31 - also created that basically means my
1602:34 - insertion has happened perfectly well
1602:37 - right now all the data has been inserted
1602:40 - into my DB and this is the student. DB
1602:42 - file that you'll be able to
1602:43 - see now
1602:47 - this completes
1602:50 - our sqlite insert some records Python
1602:52 - Programming this completes our first
1602:55 - step now in the second step we will try
1602:57 - to create an llm
1602:59 - application and now the same DB see that
1603:02 - DB is already created now what my llm
1603:04 - application should be able to do is that
1603:06 - whenever I give some English
1603:08 - text it should be able to retrieve the
1603:12 - records from those
1603:14 - database you may be thinking how that
1603:17 - will be possible I will just show you
1603:19 - just stay along with me and code along
1603:21 - with me right step by step I will show
1603:24 - you each and everything okay so just be
1603:26 - along with me and just stay over here
1603:28 - right so let me go back to my code and
1603:31 - now I will start writing my code with
1603:33 - respect to this uh in my SQL py file now
1603:36 - this file will be responsible and again
1603:39 - I'm repeating this file will be
1603:40 - responsible for creating our llm
1603:43 - application okay so let me go ahead and
1603:46 - write first of all we will go ahead and
1603:48 - import from
1603:50 - EnV import
1603:54 - load.
1603:57 - envv okay and then to load all the
1604:00 - environment
1604:02 - variables I will go ahead and write like
1604:04 - this and let me go ahead and write take
1604:08 - environment or or
1604:10 - load all the environment
1604:13 - variables okay and that is the reason we
1604:16 - have also installed those now the next
1604:19 - thing is that we will go ahead and
1604:21 - import
1604:23 - streamlit
1604:25 - as
1604:27 - St we are going to import streamlit I'm
1604:29 - going to import
1604:34 - OS I'm going to import OS along with
1604:37 - this I'm also going to import site 3
1604:41 - okay site 3 because we are going to
1604:44 - specifically use this again and then I
1604:47 - will go ahead and input from Google dot
1604:50 - generative AI
1604:52 - import gen okay so I'm going to use this
1604:56 - gen and as usual first step is to set
1605:00 - our API key so in order to sorry import
1605:04 - as okay
1605:06 - as J now in my next step what we are
1605:09 - going to do is that we going to
1605:10 - configure so here I'm going to write
1605:15 - configure
1605:17 - gen AI key okay so for this I will write
1605:22 - gen do
1605:25 - configure and here I'm going to
1605:27 - specifically use my API key so here I
1605:30 - will go ahead and write my API key is
1605:32 - equal to OS do get
1605:36 - EnV os. get EnV and here I'm going to
1605:41 - give my key name okay so whatever is the
1605:44 - key name and you know that my key name
1605:46 - I've kept it as Google API
1605:48 - key okay perfect everybody clear till
1605:53 - here are you following
1605:56 - everyone come on let me know whether you
1605:59 - feel following each and every
1606:02 - step yes yes or no so till here I have
1606:06 - set up the environment variable okay now
1606:09 - is the main thing that we will start our
1606:10 - coding with so if hit like if you're
1606:12 - able to understand till here and uh
1606:15 - you're able to follow each and
1606:16 - everything with respect to sqlite SQL
1606:19 - everything that we have actually created
1606:23 - okay
1606:25 - perfect now let me go ahead and show you
1606:28 - the next step what we are going to do
1606:29 - over here now
1606:32 - okay now we'll try to create a function
1606:39 - function to load gen AI generative AI
1606:43 - model or Google gin
1606:46 - model Google gin model okay now one
1606:51 - thing that you really need to understand
1606:53 - two information will definitely go in
1606:56 - this function right The Prompt that we
1606:58 - are specifically giving and what the
1607:02 - Google gin model needs to behave like
1607:04 - right
1607:05 - so over here I will create a function
1607:08 - and I'll say getor
1607:11 - Gore
1607:15 - response and inside this response I will
1607:17 - give my question and prompt like what
1607:21 - what the gini pro model needs to behave
1607:23 - like okay this prompt we will be writing
1607:26 - question is the input that we are giving
1607:28 - let's say if I go ahead and ask hey how
1607:30 - many people are there in the data
1607:31 - science batch right let's say something
1607:34 - like this so so let me go ahead and
1607:36 - create model is equal
1607:37 - to gen do generative model so this will
1607:43 - be my model Now understand one thing
1607:45 - over here we're going to use gini Pro we
1607:47 - are not going to use gin Pro Vision gini
1607:49 - Pro is for text gini Pro Vision is for
1607:52 - uh images video frames and all so here
1607:55 - I'm going to specifically use gin Pro
1607:57 - and then let me go ahead and create my
1607:59 - response my response will basically say
1608:02 - model dot generate content and now this
1608:05 - is the most important thing I need to
1608:07 - give two information to this right the
1608:10 - first is that what the model should act
1608:13 - like so for that I will go ahead and
1608:14 - create my prompt I'll give the first
1608:16 - parameter as prompt and this will go in
1608:19 - the form of a list so prompt the second
1608:22 - thing that I'm going to probably give is
1608:23 - my question okay now I can also give
1608:26 - multiple prompts if I want okay that
1608:28 - also I will try to show you like how
1608:30 - multiple prompts can also be given okay
1608:33 - so this is what my model is B basically
1608:35 - given so I will go ahead and write
1608:36 - return response
1608:39 - dot response.
1608:42 - text
1608:43 - okay so here this entire information so
1608:47 - this model will be responsible in giving
1608:49 - the query okay let's say if I say that
1608:52 - hey how many people studies in the data
1608:54 - science batch or data science class so
1608:56 - this entire function will be responsible
1609:00 - in giving you the query so function to
1609:02 - load Google jiny model and
1609:05 - provide queries okay as response so this
1609:10 - is the function that it is going to do
1609:12 - understand one thing right because first
1609:14 - when we hit when we write any input our
1609:17 - llm model should be able to generate the
1609:18 - query and then that query will get go
1609:21 - and hit to the cite database where you
1609:23 - get this response right so I hope
1609:27 - everybody is able to hear till here
1609:28 - right so guys there is no such
1609:30 - prerequisite for Google gin Pro you
1609:32 - really need to know Python programming
1609:33 - language and you should know how API is
1609:36 - basically used over here right so can I
1609:38 - get a quick yes if you're able to
1609:40 - understand till here and why I have
1609:41 - created this specific function okay just
1609:44 - give me a go- ahead and please keep on
1609:46 - hitting like at least we'll try to make
1609:48 - it 100 in the live session itself and
1609:50 - understand at the end we are also going
1609:52 - to have some live discussion you can
1609:53 - come and ask me questions by voice and
1609:56 - I'll be happy to provide a response to
1609:58 - you okay now this is what we have done
1610:01 - now second function that we are going to
1610:03 - create function to
1610:09 - retrieve query from the database okay so
1610:15 - this is what we going to do in the
1610:16 - second function so for this let me go
1610:19 - ahead and Define my function so here I
1610:20 - will write definition
1610:23 - read SQL
1610:25 - query okay the first parameter will be
1610:28 - SQL right whatever SQL query this model
1610:32 - gets create this model provides a
1610:35 - response as and the second parameter
1610:37 - will be my DB name right whatever DB
1610:39 - that I have now if you really want to
1610:42 - convert this into a rail World scenario
1610:44 - we can just make sure that we can put
1610:46 - our databases in the cloud and how to
1610:48 - read it and all already so many videos
1610:50 - has been created both in my YouTube
1610:52 - channel and in ION channel also so you
1610:54 - can probably go ahead and watch in that
1610:56 - specific way but here the main idea is
1610:59 - to integrate multiple tools and show you
1611:01 - how powerful an llm application can be
1611:03 - with the help of Google mini pro now the
1611:06 - next thing will be that I will try to
1611:08 - create a connection so sqlite 3 dot
1611:12 - connect I will write and this connect
1611:14 - will be with respect to my DB okay and
1611:17 - then I will go ahead and create my
1611:18 - cursor so let me go ahead and write con
1611:20 - do
1611:22 - execute sorry con do cursor I will try
1611:25 - to create my cursor now this cursor will
1611:28 - be responsible in executing our query
1611:33 - right now what query the SQL query right
1611:36 - and once I get all the results once I
1611:38 - execute this uh uh you know the SQL
1611:41 - query inside this itself C dot if I do
1611:46 - fetch all it is going to fetch all the
1611:48 - records with respect to that right so
1611:51 - this is the prerequisite that you really
1611:52 - need to know a brief idea about how you
1611:54 - can work with SQL databases and this
1611:57 - will basically be my row okay I will get
1611:59 - all the rows over here now to retrieve
1612:01 - or print the rows what I can do I can
1612:03 - write for Row in
1612:08 - rows I can print the rows so that you
1612:10 - can also see the rows over here what all
1612:13 - records I've been uh generated okay um
1612:18 - the next thing what I'm actually going
1612:19 - to do is that return all the rows okay
1612:23 - return all the
1612:24 - rows perfect everybody clear with
1612:28 - this
1612:31 - yeah yes so this is the the function
1612:35 - which will be retrieving the query from
1612:37 - the database so whenever I give a SQL so
1612:40 - in short what is happening the output
1612:42 - query that is getting generated by this
1612:44 - model it will get sent to the database
1612:48 - and from this database we will get the
1612:51 - records okay so this is done now this is
1612:55 - my function that is got created right
1612:56 - now now the next step what we are going
1612:59 - to do is that do our setup of a
1613:01 - streamlet app now before doing our stre
1613:04 - setup with respect to the streamlet app
1613:07 - this will be the most important step
1613:10 - that is defining your prompt so now we
1613:14 - are going to Define your prompt now this
1613:17 - prompt because of this prompt this
1613:20 - entire application will work so
1613:23 - efficiently trust me in that it will
1613:25 - work very much efficiently right now
1613:28 - what is the specific prompt that I'm
1613:29 - going to create and as I said I can
1613:31 - create multiple prompt so I will give it
1613:32 - in the form of list okay
1613:35 - so my first prompt let me go ahead and
1613:38 - use triple
1613:40 - quotes because it will be a multiple
1613:43 - prompt itself okay I'm going to copy and
1613:46 - paste one important prompt that I have
1613:49 - written over here now this is the main
1613:52 - game of the prompt guys without this you
1613:55 - won't be able to write or you won't be
1613:58 - able to make the llm work in a better
1614:00 - way so here what is this prompt all
1614:03 - about see you are an expert in
1614:06 - converting English question to SQL code
1614:09 - or I can also write SQL query
1614:13 - okay converting a English text also you
1614:16 - can write question also you can write to
1614:18 - SQL query the SQ database has the name
1614:23 - student and following columns name class
1614:26 - and section for example example one how
1614:30 - many entries of records are present the
1614:32 - SQL command will be something like
1614:34 - select count star from student right
1614:38 - similarly I can go ahead and write
1614:39 - example
1614:40 - two let's say I go ahead and write
1614:43 - example two so this is just one query
1614:45 - understand one thing guys this is just
1614:47 - one query right I can write like this
1614:50 - multiple queries so this this is my
1614:52 - example one
1614:55 - okay let's say I copy this in a similar
1614:58 - way and I go ahead paste it over here
1615:00 - okay let's go ahead and write example
1615:03 - two you can write many number of
1615:04 - examples as such uh let's say how many
1615:08 - how many
1615:09 - people how many
1615:12 - students
1615:14 - study
1615:16 - study in data science
1615:20 - class if this is the query if this is my
1615:23 - English statement query tell me what
1615:25 - will be the
1615:28 - command select count star from
1615:31 - students
1615:33 - or let me just change this okay tell me
1615:38 - all the
1615:39 - students studing in the data science
1615:43 - class right so in this case what will be
1615:46 - my query my query will be select star
1615:48 - from student
1615:51 - where
1615:53 - class is equal
1615:56 - to where class is equal
1615:59 - to data science data science I have
1616:04 - written it in small
1616:05 - right where class is equal to data
1616:09 - science so I will go ahead and write it
1616:11 - over
1616:14 - here okay so this becomes my query right
1616:18 - and we will end this query also like how
1616:20 - we have end it over here right like a
1616:23 - colon something like this so this is
1616:25 - also ending in this way right so now I
1616:29 - hope everybody will be able to
1616:30 - understand this yes you are getting it
1616:32 - right and after this I'm also saying
1616:33 - also the code SQL code should not have
1616:36 - this kind of in the beginning at all
1616:38 - I've given some more additional
1616:39 - statement for the clean one okay does
1616:42 - this make sense
1616:47 - everyone
1616:49 - yeah so this basically is your
1616:53 - prompt okay and let me paste it over
1616:55 - here so that you can also work
1616:57 - accordingly with
1617:02 - me so
1617:05 - this is the entire
1617:11 - prompt see okay this entire prompt has
1617:14 - been divided into multiple sections
1617:19 - okay just see to this okay but this is
1617:22 - how things are I'll will give you some
1617:24 - time go ahead and write
1617:26 - this okay go ahead and write this
1617:29 - because this will be the magic this is
1617:30 - the most magical thing right and that is
1617:34 - how you'll be able to see that how
1617:36 - powerful these llm models are right so
1617:39 - here you can see you are an expert in
1617:40 - converting English questions to text or
1617:43 - English text to SQL query the SQL
1617:45 - database has the name student and has
1617:47 - the following columns name class section
1617:49 - for example this how many entries of
1617:51 - records are present the SQL command will
1617:53 - be something like select count star from
1617:55 - student example two here you can
1617:57 - specifically use in this particular way
1618:03 - right
1618:11 - clear
1618:12 - everyone okay you want it in code
1618:17 - share I will also do it in code share
1618:20 - just
1618:26 - a let me see whether I'll be able to see
1618:29 - in code share or
1618:32 - not but don't ch change the prompt okay
1618:35 - and don't delete the prompt once I
1618:36 - probably share
1618:39 - it okay
1618:42 - share so I will share the link everybody
1618:45 - can copy it from
1618:48 - there
1618:50 - okay everybody got it in the code
1618:53 - share
1618:55 - yeah so in that code share I have given
1618:58 - this entire thing you just can copy it
1619:00 - from there and uh start seeing it okay
1619:06 - clear everyone can I get a quick yes
1619:08 - because this will be the most important
1619:11 - step creating your own
1619:13 - prompt right so please do hit like till
1619:17 - here if you are able to understand each
1619:19 - and everything trust me this is an
1619:21 - amazing application by this you will get
1619:23 - multiple ideas multiple ideas trust me
1619:26 - in this okay so this becomes my
1619:29 - prompt now the next step obviously the
1619:32 - next step is basically to set up our
1619:34 - our streamlit app so let's start our
1619:37 - streamlit
1619:39 - app and understand this prompt will tell
1619:42 - Google J how it needs to add
1619:46 - okay so first of all I will go ahead
1619:50 - and create my std. Sate page page config
1619:57 - and here I'm going to give my page title
1620:01 - as
1620:02 - text
1620:04 - or I can say I can
1620:10 - retrieve any SQL
1620:13 - query okay so this will basically be my
1620:16 - P page config and then I will go ahead
1620:18 - and write s.
1620:23 - header gemin app to
1620:28 - retrieve SQL data
1620:32 - okay now I've have given some examples
1620:34 - guys see this prompt you can take it to
1620:36 - any extent even write complicated
1620:38 - queries you know once I probably show
1620:41 - you the result you'll be able to
1620:43 - understand why I'm saying like this okay
1620:44 - now I will create a text box which will
1620:47 - probably take the question from my side
1620:48 - so here I will write question is equal
1620:50 - to st. textor input and this will
1620:56 - basically be my
1620:59 - input let's go ahead and Define my input
1621:02 - and key I'm going to write it as as
1621:04 - input okay we can basically write any
1621:07 - key according to you then we will go
1621:10 - ahead and create a submit button only
1621:12 - two things we specifically required
1621:13 - submit button and let me go ahead and
1621:15 - write St do
1621:17 - button and here I can basically write
1621:20 - ask ask the
1621:23 - question
1621:25 - done now if submit is
1621:30 - clicked so I'm I'm using one field a
1621:33 - text box and I'm specifically using
1621:38 - one I'm using one text field text field
1621:41 - and I'm using one submit okay perfect
1621:51 - everyone
1621:54 - yeah
1622:01 - everybody good enough everybody
1622:04 - can I get a quick yes if you're
1622:06 - following everyone
1622:09 - okay perfect simple now if submit is
1622:13 - clicked I will go ahead and do all the
1622:15 - activities that I specifically want
1622:18 - okay great so let's go ahead and see the
1622:21 - next step now in the next step if submit
1622:23 - is clicked I will write if
1622:28 - submit I will go ahead and write
1622:31 - response is equal to
1622:34 - get Gemini response and here I'm going
1622:37 - to give my question comma prompt right
1622:40 - now question comma prompt if I give this
1622:43 - prompt is in the form of list so when
1622:46 - I'm going over here I will just make
1622:47 - this as prompt of zero the first prompt
1622:51 - that I specifically want to give you can
1622:53 - also give multiple prompts and by that
1622:54 - you can give in that specific way let's
1622:57 - say I have three buttons in the first
1622:59 - button I want to behave it in a
1623:00 - different prompt in the second button I
1623:01 - want to probably behave it in a
1623:03 - different prompt so here I'll write
1623:04 - prompt of zero okay once I get the
1623:07 - response I will say St do
1623:11 - subheader the response
1623:14 - is okay and then I will write for Row in
1623:20 - response print
1623:23 - row I'll print all the rows okay and if
1623:27 - it is printing in my field let's say I
1623:29 - will go ahead and write something like
1623:30 - this St Dot
1623:35 - header and I will display all the row
1623:38 - elements over
1623:39 - here done guys almost done now it's like
1623:44 - whether this will work or not we need to
1623:45 - check if it does not work we need to
1623:47 - play with this prompt okay remaining all
1623:50 - code you know see first step is probably
1623:54 - taking with respect to get Gemini
1623:56 - response based on question and prompt it
1623:58 - will generate a SQL query and that same
1624:00 - SQL query uh what will basically happen
1624:03 - over here so question and prompt
1624:05 - response what I'll get over here just a
1624:08 - second I think um get Jin
1624:13 - response generate
1624:16 - content and then I have to probably go
1624:18 - ahead and read my SQL query okay so just
1624:22 - give me a
1624:32 - second
1624:39 - wait wait wait wait wait wait I will get
1624:41 - the
1624:42 - response and I have to probably call
1624:44 - this read SQL
1624:47 - query because here it is not getting
1624:53 - called so I'll go ahead and write my
1624:56 - response
1624:57 - read SQL
1625:01 - query now inside this SQL quy I'll give
1625:04 - my
1625:05 - SQL whatever SQL response I'm getting
1625:08 - over
1625:09 - here comma whatever is my DB name my DB
1625:13 - name is basically what student.
1625:21 - DB
1625:25 - student. perfect now I should be able to
1625:28 - get the response I
1625:30 - guess does this look good everyone
1625:41 - yep
1625:45 - everyone second is the response of it
1625:55 - response now let's see whether it will
1625:57 - run or
1626:00 - not DB is student. DB perfect
1626:04 - now it is clear I guess response is also
1626:06 - there this response it will go over here
1626:09 - and do done now let me go ahead and run
1626:11 - it and I hope so it runs absolutely fine
1626:14 - if it does not run we'll try to debug
1626:16 - okay so in order to run it I will write
1626:22 - streamlet
1626:24 - run SQL
1626:28 - dopy so this will run let's
1626:32 - see
1626:34 - now here is the thing let me go ahead
1626:37 - and write a require tell me the
1626:41 - student
1626:44 - name and data
1626:47 - science class let's
1626:49 - see I will go ahead and ask this
1626:51 - question as you all know how many
1626:53 - students are there over here in this
1626:55 - particular
1626:56 - class 1 2 3 so Kish soans and darus
1627:02 - right so let me go ahead and execute
1627:04 - this I hope so it
1627:06 - works so I'm not getting the response so
1627:11 - this is not good
1627:14 - oh something is
1627:16 - happening oh I did not receive anything
1627:21 - why let me execute this once so the
1627:26 - cursor did I execute SQL py so
1627:31 - sorry it should be s equal py now just a
1627:43 - second no it was working fine I
1627:51 - guess let me see once
1627:55 - again but last time we did not get
1627:58 - anything tell me the student name
1628:03 - in the data science
1628:07 - class if this is not getting executed
1628:11 - there should be okay operational where
1628:14 - syntax the problem is coming let's see
1628:16 - what kind of query it has generated let
1628:19 - me print the query
1628:21 - also print print print print the
1628:24 - response okay I will go ahead and print
1628:27 - the response let's see whether we are
1628:29 - getting any error or we need to
1628:32 - change
1628:35 - okay so I'm just doing some kind of
1628:37 - debugging guys so
1628:39 - please be with me okay we will try to
1628:42 - run
1628:46 - this select the name of the student
1628:49 - where class is equal to data science
1628:50 - this looks perfectly
1628:54 - fine select name from
1628:57 - student name from student where class is
1628:59 - equal to data science this looks fine
1629:02 - when I executing this DB this DB is
1629:06 - there student.
1629:09 - DB response I'm giving it over
1629:14 - here fetch
1629:20 - all okay this is coming as an error let
1629:23 - me see why this error is
1629:25 - coming execute
1629:32 - SQL
1629:34 - current
1629:36 - dot con. cursor
1629:45 - SQL there's some error with the
1629:47 - retrieving the query just a second
1629:54 - guys connect DB DB name is this
1630:01 - one let me see one
1630:03 - second let me debug
1630:06 - this the query is generated correctly
1630:09 - when we hitting this particular database
1630:11 - it is not working let me see
1630:14 - test.py okay SQL
1630:17 - dopy import sqlite
1630:20 - 3 and I'm going to use this command
1630:24 - let's see it will work or
1630:32 - not
1630:43 - cursor.
1630:46 - execute select star from
1630:51 - student let's
1630:53 - see DB name
1630:56 - is student.
1631:00 - DB come on
1631:05 - so some error in executing this let me
1631:08 - open my terminal let's see whether this
1631:10 - will get executed or
1631:12 - not
1631:16 - Python and once I execute this I will
1631:20 - just go ahead and write this three
1631:27 - records we'll just go ahead and print
1631:30 - this records let's
1631:31 - see
1631:43 - python
1631:46 - test.py
1631:54 - from nothing is getting
1632:01 - printed why is not getting
1632:19 - printed now it should work let's
1632:23 - see still not getting printed but it is
1632:26 - getting executed select star from
1632:30 - student but this record should be
1632:32 - visible
1632:33 - just a second I will just delete this
1632:36 - once and let me go ahead and write
1632:39 - python sqlite
1632:43 - dopy the record is done student.
1632:47 - DB oh student student student I'll close
1632:50 - this
1632:53 - requirement try printing line number
1632:58 - five line number
1633:01 - five
1633:06 - oh this is fine now let me go ahead and
1633:10 - write test.py still it is not getting
1633:12 - printed that basically
1633:15 - means is not able to read this
1633:25 - why
1633:27 - print
1633:29 - rows let's try this also just a second
1633:32 - can rows are coming as empty why
1633:36 - student. DB is
1633:38 - there I could see over here the insert
1633:41 - statement has happened and is displaying
1633:44 - all the
1633:51 - records okay why it is coming as
1634:00 - null select star from student is
1634:04 - done while I'm
1634:15 - reading what is the mistake over
1634:23 - here select start from
1634:28 - student I'll I'll try to fix it guys
1634:30 - just give me a
1634:31 - second select start from
1634:36 - student c table
1634:39 - [Music]
1635:01 - info
1635:03 - let's
1635:06 - see no nothing is
1635:09 - coming where did my database
1635:18 - go select star from student is my
1635:21 - student spelling wrong or
1635:25 - what
1635:31 - student we need to welcome this gu this
1635:33 - helps us to the opportunity line by line
1635:37 - yes
1635:40 - student just a second guys let's fix
1635:44 - this
1635:47 - issue oh I feel there is one problem
1635:50 - over
1635:52 - here let me delete this once
1635:57 - okay working for godam says working for
1636:01 - me
1636:06 - student. DB I will delete this let me
1636:08 - create another DB over here wait I will
1636:11 - go ahead and write test. DB let's
1636:21 - [Music]
1636:22 - see SQL py this is done now if I go
1636:27 - ahead and execute test. py let's
1636:31 - see
1636:34 - python
1636:38 - test.py okay sorry so this should be
1636:43 - test.
1636:48 - DB no it is not able to read
1637:01 - why
1637:20 - object is
1637:31 - coming
1637:35 - so some major error in connection.
1637:42 - commit is that
1637:46 - so oh is the cursor not closed so that
1637:50 - I'm getting the
1638:01 - problem
1638:10 - I'll do one
1638:11 - thing I'll commit the
1638:15 - connection so print row and I will say
1638:18 - okay I got a problem what was that
1638:20 - commit your changes in the
1638:24 - database con do
1638:29 - commit so here I've have created my
1638:31 - connection connection.
1638:34 - commit now along with this I will also
1638:38 - say CN
1638:41 - do connection. close now I think it'll
1638:45 - work so let me go ahead and delete this
1638:49 - let me go ahead and delete this now I
1638:52 - will go ahead and change my name to
1638:53 - student now I think it should
1638:55 - work I think I did not close the
1638:58 - connection that is the main
1639:00 - reason equal. py so this is done
1639:03 - student. DB is created now let me go
1639:06 - ahead and write streamlet streamlet SQL
1639:10 - py no I think it should
1639:12 - work definitely it should
1639:16 - work tell me the students tell
1639:20 - me all the students
1639:25 - name from data science
1639:31 - class
1639:33 - let's go ahead and ask the
1639:41 - question now let's
1639:48 - see quer is
1639:50 - Right
1640:01 - 29th
1640:13 - still I do not get the
1640:15 - response now this
1640:20 - is here also I have to probably close
1640:22 - the connection I guess so let's close
1640:24 - the connection here
1640:31 - also
1640:38 - so I did not close the cite connection
1640:40 - at the
1640:42 - end Connection cursor. close
1640:48 - Okay cursor is over
1640:59 - here we don't have to close the cursor
1641:02 - connection if it is closed I think it is
1641:24 - sufficient
1641:26 - anybody prompt is giving the response
1641:29 - from stimulate app this worked for
1641:31 - me
1641:34 - read the S
1641:39 - rows for rows in print rows return rows
1641:42 - so the same function I think I've
1641:43 - written over
1641:45 - here for Row in rows return
1641:54 - rows so you have not close the
1641:56 - connection now I've closed the
1641:57 - connection I think now I think you
1641:59 - should not have that
1642:01 - issue
1642:02 - anybody's facing this issue
1642:09 - still now once I close the connection I
1642:12 - have my student DB in my
1642:17 - SQL I'm giving my student.
1642:23 - DB cursor connection
1642:30 - C
1642:36 - for reading I don't have to probably do
1642:39 - anything as
1642:41 - such so this work for
1642:44 - me yes still same data science
1642:47 - Capital no no the query is getting
1642:50 - created perfectly the problem is in this
1642:52 - read SQL
1643:00 - query
1643:03 - I don't think so I need to write this
1643:05 - but I'm just trying it out let's
1643:09 - see sqlite May commit and close is done
1643:13 - this is also
1643:15 - done no no I have the data no so data is
1643:18 - getting printed over here see so this
1643:21 - was the data that was got printed
1643:26 - right let's see once again
1643:30 - rerun
1643:34 - oh now finally now I get the response
1643:38 - see so I just did
1643:41 - this
1643:43 - I just go ahead and write
1643:46 - it okay so I have to close the
1643:48 - connection over here
1643:51 - also okay so now you can see Krish
1643:54 - sudhansu and darus is
1643:58 - visible minor mistake I can understand
1644:01 - but again a good error to fix tomorrow
1644:04 - if you get any error over here you can
1644:06 - probably check it out okay everybody got
1644:12 - this
1644:17 - yeah all happy enough tell me any more
1644:27 - queries tell
1644:29 - me tell me the CL class
1644:34 - where sudano let's say I'll say tell
1644:39 - me tell me Sudan Shu I written his full
1644:45 - name or
1644:46 - not I think I've written just his single
1644:49 - name right uh SQL
1644:52 - py
1644:53 - sqlite okay tell me sudano's
1644:57 - class tell me Sano section let's say if
1645:00 - I write like this
1645:02 - ask the
1645:04 - question see the b b section is coming
1645:07 - over here and the best thing will be
1645:09 - that you'll also be able to see what
1645:11 - query it is generating select section
1645:14 - from student where name is equal to
1645:16 - sudhansu right and here you can probably
1645:19 - clearly see right this is this is really
1645:22 - really
1645:27 - nice right
1645:30 - so
1645:40 - let's see what CL tell me the class of
1645:43 - vikas and
1645:47 - dpes whether it'll be able to write this
1645:49 - queries also or not we'll
1645:52 - see devops tell me the class of vikas
1645:56 - and D devops devops
1645:58 - see now how many queries see select
1646:01 - class from student wear name in vikash
1646:03 - and
1646:04 - thees so this is good right see this
1646:07 - kind of queries also it is able to
1646:08 - generate now the more amazing thing we
1646:11 - basically write in the prompt template
1646:14 - right in the prompt more complex queries
1646:16 - we specifically write and here you can
1646:18 - probably see vas and thees was in devops
1646:22 - right tell me the student name from
1646:28 - section
1646:30 - A
1646:35 - Krish Darius vikash Dees everybody
1646:39 - sudhansu is missing so sudhansu is
1646:41 - another section I guess see sudhansu is
1646:44 - in B section so did you like this
1646:47 - project guys everyone so if you liked it
1646:49 - please do make sure that you hit
1646:51 - like and uh yeah between there was some
1646:54 - challenges because I did not close the
1646:55 - connection okay it is good to close this
1646:58 - specific connection okay uh so close
1647:02 - this connection make sure that you close
1647:03 - this connection okay otherwise you'll
1647:05 - get an error because see if you don't
1647:06 - close this connection right the DB will
1647:08 - be open right and uh there you'll not be
1647:11 - able to do it now the most amazing thing
1647:13 - is about how you write this prompt in a
1647:15 - better way you can check with Google bar
1647:17 - you can check with different different
1647:19 - ways you know whenever you write a query
1647:21 - you'll be able to and this definitely
1647:23 - works for advanced advanc SQL queries
1647:26 - Also let's say if there are two tables
1647:28 - and all you can also probably write it
1647:29 - over there tell me any query any
1647:31 - complicated query that you feel that we
1647:33 - can write and try it
1647:35 - out
1647:38 - [Music]
1647:39 - um tell me all the students who are from
1647:42 - class data science who are from section
1647:44 - A and B let me go ahead and write in
1647:46 - this
1647:48 - way from section A and B I think this
1647:52 - should this should be an easy one itself
1647:54 - I don't think so it'll be the response
1647:56 - is Krish sudans darus Vias dipes
1648:00 - okay
1648:03 - let's say if I probably go ahead and
1648:05 - write one more column name like marks I
1648:07 - can still write more complicated text
1648:10 - over here right let's see okay fine
1648:13 - marks also will do it okay so I will go
1648:15 - ahead and create one
1648:17 - more one
1648:19 - more marks and this will basically be
1648:23 - int and what I will do I will just go
1648:25 - ahead and create this once
1648:29 - again so let's say marks will will be
1648:31 - over here as
1648:33 - 90
1648:37 - 100 uh darus I will write it as
1648:42 - 86 because I will go ahead and say
1648:47 - 50 the I will go ahead and say 35 okay
1648:52 - so I will use this all and now let's see
1648:56 - whether this will work I will delete
1648:57 - this
1648:59 - database control C
1649:04 - C python site.
1649:08 - py so the database is created now let's
1649:11 - go ahead and run my SQL query so
1649:17 - streamlet
1649:19 - run SQL
1649:22 - py now tell me what sentence should I
1649:28 - ask tell me all the student
1649:32 - name whose
1649:35 - marks marks is greater
1649:39 - than
1649:41 - 90 so if I ask this
1649:45 - query will it
1649:47 - work sudhansu see sudhansu it is
1649:51 - basically showing so let's go ahead and
1649:53 - see the query greater than 90 how much I
1649:57 - have got 90 see greater than or equal to
1650:00 - 90 I sent and my name should also come
1650:04 - right if I say greater than
1650:11 - 80 uh there is one
1650:14 - question hello from the generative AI
1650:16 - course starting next week how often will
1650:18 - the doubt section be checked I noticed
1650:19 - the community version has not respond to
1650:21 - often see right now we have come up with
1650:24 - an amazing support uh system so every
1650:26 - day within 24 hours you'll be able to
1650:28 - get the response
1650:30 - okay
1650:32 - every day within 24 hours you'll be able
1650:34 - to get the response so guys this is
1650:36 - amazing right
1650:38 - happy now you write any complicated
1650:40 - queries just give some examples over
1650:43 - here right so Kish sudans and Darius is
1650:46 - having greater than 80 if I probably go
1650:48 - and see what is the query that is
1650:50 - generated here you can probably see
1650:55 - select or I I I'll I'll just do
1650:57 - something okay greater
1650:59 - than greater than or equal to
1651:05 - 90
1651:06 - and less than 50 let's see whether this
1651:10 - query is also possible or
1651:15 - not okay here now the problem is because
1651:18 - we have not given those kind of
1651:19 - scenarios I don't know what select name
1651:22 - from student where marks is greater than
1651:24 - or equal to 90 and marks is less than 15
1651:26 - this is good but
1651:28 - the but the column name is is what let's
1651:33 - see the column name marks I think this
1651:35 - should have got executed
1651:39 - oops select name from student where
1651:41 - marks is greater than and marks is less
1651:44 - than
1651:45 - 50 okay both the condition is not
1651:47 - getting
1651:48 - matched less than 50 we had one right
1651:52 - thees okay please ask to give rank on
1651:55 - basis of
1651:59 - marks tell me
1652:06 - tell
1652:17 - me let me do one
1652:20 - thing Marx is greater than or equal to
1652:24 - equal to
1652:27 - 90 greater than or equal to 90 greater
1652:30 - than less than
1652:41 - 50 okay and uh less than so I have
1652:47 - written the condition in a way that I
1652:50 - have to reverse this okay till let's try
1652:53 - this one tell me the
1652:56 - student
1652:58 - rank tell me the student name based on
1653:02 - Marx rank let's see I try like this
1653:06 - something like
1653:08 - this again you can try multiple things
1653:11 - so see sudhansu Kish Darius vikas and
1653:15 - dipes this is nice let's see the query
1653:18 - select name from student order by
1653:26 - [Music]
1653:30 - marks
1653:31 - so previous condition I'll say tell me
1653:34 - the student name where marks is lesser
1653:40 - than 90 and greater than
1653:48 - 50 see darus is there
1653:57 - okay if I say marks is great greater
1654:02 - than
1654:04 - 90
1654:07 - or lesser than
1654:10 - 50 let's try this also so danu should
1654:14 - come and thees should come Perfect all
1654:17 - good
1654:21 - everyone tell me students having marks
1654:24 - greater than also tell me the number
1654:26 - okay yeah you can write
1654:29 - this fetch me the topper of all the
1654:33 - classes fetch me the topper of all
1654:44 - classes
1654:46 - see section B Sudan is the topper vikash
1654:49 - why it is showing devops a branch yeah
1654:53 - uh fetch me okay one more give me the
1654:55 - third highest rank by sudano let's see
1654:58 - give me the third highest
1655:04 - rank third highest rank
1655:08 - marks usually this is an interview
1655:12 - question okay there is an error let's
1655:16 - see what it has
1655:19 - generated operational error
1655:23 - mhm first I'll print the response wait
1655:26 - over here some error has come over here
1655:29 - so uh print response get Gin
1655:34 - response select name from name section
1655:37 - marks over by as marks from table as
1655:40 - table where rank is equal to three so
1655:43 - this is the problem guys right so let me
1655:45 - write it in a better give me the third
1655:47 - highest rank give me the
1655:51 - name give me the student
1655:54 - name of
1655:58 - third of third highest mark
1656:03 - something like
1656:08 - this
1656:10 - Darius right so here you can probably
1656:13 - see Darius is coming now so this way so
1656:16 - we also have to write prompt in a better
1656:18 - way right so here you can see select
1656:20 - name from student order by class limit 2
1656:23 - comma
1656:24 - 1 so Q song says one more way of writing
1656:29 - this query tell me
1656:31 - how about tell me who is the third best
1656:32 - student on
1656:35 - marks Darius perfect so this is working
1656:38 - really
1656:42 - good oh my God this this is nice people
1656:46 - are creative in writing prompts okay so
1656:49 - this is can you provide a list of
1656:50 - student categorized as first class if
1656:52 - their marks are greater than 60 and
1656:54 - categorize the second class if their
1656:56 - marks are between 50 and
1656:59 - 60
1657:01 - so let's ask this question first class
1657:04 - Kish first class sudhansu first class
1657:08 - Darius let's see the query the query is
1657:11 - quite complicated in
1657:13 - this so here oh big nested quer is there
1657:17 - select case where marks is greater than
1657:19 - first class then marks is between 50 to
1657:21 - 60 second class else null nice see the
1657:24 - output is coming
1657:26 - up try to run the rank with the table
1657:29 - name
1657:32 - uh s give the query give the prompt it
1657:36 - will be
1657:38 - better but this is nice guys see this so
1657:41 - complicated query it is being able to
1657:43 - give the marks over
1657:45 - here will this replace human why it is
1657:49 - going to replace
1657:51 - human see first class first class first
1657:54 - class Vias is second
1657:59 - class
1658:09 - give me the second okay give me
1658:18 - the give me the second last rank student
1658:21 - name from student
1658:23 - table so danu second last
1658:27 - rank second last rank it should
1658:32 - be select name from
1658:35 - student why is giving
1658:43 - error let's see if it's a let's run
1658:54 - this give me the second last rank
1658:57 - student name from student table
1659:03 - near offsets I think some error is
1659:05 - coming over here let's
1659:10 - see now it is getting complicated
1659:13 - writing so this query may not work
1659:16 - select name from student Group by null
1659:18 - order by
1659:19 - count so this makes me feel I'm learning
1659:23 - SQL for 3 months okay
1659:27 - perfect anything other than this you
1659:29 - want to try everyone
1659:34 - one so hit like if you like this video
1659:38 - and tell me how was it did you
1659:41 - enjoy shall we do the deployment for
1659:46 - this everyone wants to do the
1659:49 - deployment so let's go to hugging face
1659:52 - okay go to
1659:54 - spaces and create a new space just let's
1659:58 - go ahead and write text to SQL
1660:02 - generative
1660:05 - AI
1660:06 - generative
1660:08 - AI okay text to SQL generative
1660:11 - AI license you can probably use Apache
1660:14 - License streamlet I'm going to use and
1660:16 - this provides
1660:17 - you uh CPU basic uh 2 CPU 16GB free
1660:23 - public and all I will go ahead and
1660:24 - create the space now for this what you
1660:26 - really need to do is that I will close
1660:28 - this till then
1660:30 - I will close this I will rename this
1660:33 - particular file SQL to app.py app.py
1660:40 - oops okay I'm just going to rename it
1660:42 - because this takes app.py and
1660:44 - requirement. tht is there okay I will go
1660:47 - ahead and open in the reveal in the file
1660:51 - explorer and I will go ahead and create
1660:53 - this
1660:54 - space please match the requirement okay
1660:57 - text to SQL okay go ahead and H what is
1661:04 - happening no
1661:07 - spacer text to SQL generative
1661:12 - AI let's create this space now after
1661:16 - creating the space what we can
1661:18 - specifically
1661:19 - do so this is the space that has got
1661:22 - created I will go to the files and here
1661:25 - is my entire file so I will go ahead and
1661:27 - upload this three files student DB
1661:30 - this this this okay so I will go ahead
1661:33 - and add upload files and probably drag
1661:38 - and drop these three files okay so this
1661:41 - is dragged and drop I will go ahead and
1661:43 - commit the changes to the
1661:45 - main so here it is now you just go to
1661:47 - the app it will start
1661:50 - running it internally creates a
1661:52 - Docker the deployment of this llm app
1661:55 - will be very simple uh the DB is there
1661:57 - obviously in the real term scenario we
1661:59 - have database is in some Cloud so when
1662:02 - we are using Docker we have to probably
1662:03 - give the IP address and all okay so here
1662:05 - you can probably see that everything is
1662:07 - happening in front of you the
1662:08 - installation of requirement. txt and all
1662:11 - so let's continue this very
1662:19 - simple so guys overall everything is
1662:22 - good did you enjoy the
1662:29 - session
1662:34 - yeah so application startup let's see if
1662:37 - everything works fine this is getting
1662:40 - builded once this building will be
1662:42 - happening and you can probably execute
1662:43 - it
1662:47 - okay I hope it was fun okay now we'll
1662:51 - have a doubt clearing as soon as this
1662:53 - application
1662:55 - works all good the streamlit app is
1662:59 - running
1663:03 - m is not running let's see so here it is
1663:05 - now just let's go ahead and write the
1663:07 - query what query was that last I had
1663:08 - written okay everybody was giving so
1663:11 - many different different queries right
1663:13 - so we'll run one of the
1663:16 - query let's run the more complicated
1663:18 - query
1663:20 - okay can you provide a list of student
1663:22 - categorized In First Class second class
1663:24 - and all I think this should work
1663:26 - absolutely fine oh one thing is
1663:28 - remaining this will not work
1663:30 - I have to go ahead and put my API key
1663:33 - okay so if you go down in the settings
1663:36 - so just click on settings over here and
1663:39 - there will be something called as
1663:40 - Secrets right so I will go ahead and
1663:41 - create a new secret my secret key name
1663:44 - will be Google API key I will copy this
1663:48 - paste it over here and we will go ahead
1663:50 - and paste this also over here the value
1663:54 - and I will remove the
1663:56 - codes save
1663:59 - it
1664:00 - okay this is done now let's go back to
1664:02 - my
1664:03 - app now again it'll build and again
1664:05 - it'll do all the installation again as
1664:08 - soon as I probably do each and
1664:09 - everything that is required okay so now
1664:12 - this is my
1664:14 - input okay now I'll paste it over here
1664:17 - oh not this what I was
1664:20 - pasting I will paste this
1664:26 - query so this is the thing can you
1664:29 - provide a list of of students
1664:30 - categorized as first
1664:35 - class so I will go ahead and ask this
1664:38 - question it should be able to give me
1664:40 - the response okay your default
1664:42 - credential were not found to set up
1664:44 - default credential this is that why this
1664:48 - is not working let's
1664:52 - see it should
1664:54 - work my settings is
1664:57 - there and
1665:02 - Google API
1665:10 - key save it over here let's see
1665:19 - again let's see whether it will work or
1665:21 - not till then
1665:24 - uh my team will provide a link in the
1665:27 - chat section if you want to join and ask
1665:29 - any queries that you have you can
1665:32 - specifically ask me
1665:34 - okay so Prashant you can share the link
1665:37 - in the chat
1665:41 - okay okay perfect guys it's running so
1665:44 - it's running in the hugging phas as I
1665:46 - said in order to set up the secret key
1665:49 - just go over here down there will be
1665:52 - something called as secrets and variable
1665:54 - create a new secret write the Google API
1665:56 - key and write the value over there
1665:57 - that's it okay and here is the entire
1666:00 - app it is working absolutely
1666:03 - fine okay perfect
1666:10 - everybody yes yes yes yes yes yes yes
1666:14 - yes or
1666:15 - no please make sure
1666:19 - that you write the quote over there
1666:27 - okay okay guys so please join with me in
1666:30 - the session and I will allow you to ask
1666:32 - any queries if you have but I hope you
1666:35 - like this session altoe guys yes or
1666:39 - no so if you specifically want the code
1666:44 - uh the GitHub link I will provide you
1666:46 - the GitHub link of the code over here
1666:52 - okay so go ahead and join the link guys
1666:54 - if you have any question if you want to
1666:56 - ask me anything and regarding all the
1666:58 - paid courses in n neon you can probably
1667:01 - see the description of this particular
1667:02 - video so we are coming up with Gen AI
1667:06 - course mastering generative AI machine
1667:08 - learning boot
1667:09 - camp uh in both in English and Hindi we
1667:12 - are coming also with data analytics boot
1667:14 - camp and mlops production ready data
1667:16 - science project everything is basically
1667:18 - coming up you can probably check in the
1667:19 - description of this particular video
1667:21 - check out the
1667:22 - course and if you are interested right
1667:26 - because this kind of projects what I
1667:28 - have actually discussed right now
1667:30 - this is still I will say basic to
1667:31 - intermediate we'll still discuss more
1667:33 - advanced project when we are doing in
1667:34 - the course itself okay so yes this was
1667:38 - it so how did you like the session first
1667:39 - of all was it good
1667:41 - bad
1667:46 - yeah yeah Vishnu Khan please go ahead
1667:49 - with your
1667:58 - question
1668:01 - mishuk Kant can you hear
1668:03 - me unmute
1668:11 - yourself vishant Vishnu Kant if you have
1668:14 - any questions you can ask me okay what
1668:17 - about next people who want to
1668:19 - join hi sir am I audible to
1668:22 - you yeah tell me sir my question is that
1668:26 - how to fix that response error which you
1668:28 - have fixed I was trying to fix that
1668:31 - still it's not showing the
1668:33 - response response first of all see
1668:36 - whether your SQL quer is getting
1668:37 - generated or not is it getting generated
1668:41 - no
1668:42 - sir then I would suggest just check the
1668:45 - GitHub link that I've actually sent with
1668:46 - the code okay try to run that code once
1668:51 - okay okay I've sent you the GitHub link
1668:52 - so this is the GitHub code that we have
1668:57 - okay so just try to run this I will try
1669:00 - to edit this over here itself in front
1669:02 - of
1669:02 - you sure whatever things we have ran
1669:06 - everything I'm going to put it over here
1669:08 - okay uh SQL light. py so this will
1669:13 - basically be my insertion
1669:17 - database I will commit this
1669:20 - up I'll commit this
1669:24 - changes and uh in SQL py I will go ahead
1669:28 - and use this code that uh I have written
1669:32 - app.py
1669:34 - okay so you can go ahead and check it
1669:37 - out okay sure
1669:42 - sir yes please next
1669:50 - question
1669:55 - yes jbin AI will be able to generate
1669:58 - images yes yes it will be we have
1670:01 - discussed about that in the last
1670:04 - session yes the session was informative
1670:08 - live coding session helps us to
1670:10 - understand in a better way I would
1670:12 - appreciate if you could continue adding
1670:14 - more interview questions and answering
1670:16 - videos sure I'll do
1670:20 - that any more question guys if you want
1670:22 - to probably join please make sure that
1670:24 - you join the link that is given by our
1670:28 - team okay okay if you want to talk with
1670:30 - me if you have anything as
1670:35 - such you have to go to this link and you
1670:38 - can join it along with me
1670:58 - okay yes any more questions guys just go
1671:01 - ahead and ask very good everything is
1671:04 - fine so please create one more session
1671:07 - for generative AI images okay fine I
1671:09 - will try to create that in my next
1671:11 - session we'll try to create a health
1671:12 - management app okay and then we will
1671:15 - work on
1671:26 - that sir please can you tell gen is in
1671:29 - job oriented course yes obviously
1671:32 - whatever things are people are using in
1671:35 - the industry that same thing we are
1671:36 - teaching in the course
1671:44 - okay is gini better than chat GPT I
1671:48 - would still
1671:50 - suggest I'll say
1671:52 - suggest that many
1671:55 - people we cannot just come to a
1671:57 - conclusion right now okay
1672:05 - we cannot come to a conclusion right now
1672:07 - with respect to that but when the high
1672:08 - Advanced model will come then we can
1672:10 - probably see so guys use the link that
1672:12 - is probably given over here we have put
1672:14 - that in the comment section you can join
1672:16 - directly to my streamyard and here I
1672:18 - will allow you to probably talk with me
1672:21 - and if you have any questions we can
1672:28 - discuss
1672:29 - please go ahead join the streamyard link
1672:33 - and if you have any question you can ask
1672:35 - me I said
1672:38 - right what are the timings of the
1672:40 - generative AI
1672:43 - course so if you probably see over
1672:47 - here if you click this link the timing
1672:51 - is given
1672:52 - 10 10: a.m. to 1: p.m.
1672:56 - IST okay every Saturday and Sunday this
1672:59 - course will go for five
1673:02 - months yeah STI please uh tell me your
1673:07 - question uh sir K great talking with you
1673:11 - uh I enrolled for gender course uh for
1673:13 - python uh actually as a beginner I just
1673:17 - know till oops Concepts not much in data
1673:19 - structures and uh much more advanced
1673:22 - concepts uh even I'm not a developer I
1673:25 - am from uh non-developer background and
1673:28 - just doing some uh like manual testing
1673:30 - and all uh will that help me this gener
1673:33 - course can land me other than testing uh
1673:36 - jobs just want to know yes ma'am so the
1673:39 - thing is that the more first of all the
1673:41 - prerequisite in our course is Python
1673:42 - programming language so that is the
1673:43 - reason we have given already recorded
1673:45 - videos also in our curriculum okay the
1673:48 - more you go become better in Python
1673:50 - programming language the more better
1673:51 - courses you'll be able to I mean the
1673:53 - more better projects you'll be able to
1673:55 - develop okay so I would suggest still
1673:57 - focus more on python and then probably
1674:00 - start learning all these things and how
1674:01 - to create uh entire llm application
1674:04 - which you need to focus in the class
1674:06 - after that try to do some internships
1674:08 - try to do try to see in in your work can
1674:11 - you do something something related to
1674:13 - that you know all those things will
1674:15 - matter okay actually actually I enroll
1674:17 - for this course because I don't want to
1674:20 - be in testing domain anymore so uh if
1674:24 - even if I am not a developer uh can I
1674:29 - get some hands if I get handson in this
1674:31 - project can I switch my from domain from
1674:34 - testing to any
1674:36 - other yes ma'am but again you need to
1674:38 - follow some steps over there you know do
1674:40 - multiple projects see currently in
1674:43 - testing also many things can be used llm
1674:45 - task can be used that is what I'm trying
1674:46 - to say you know so if you're able to use
1674:49 - this that experience you'll try to put
1674:51 - in your resume okay if you already
1674:53 - working that is what I meant but yes
1674:55 - definitely there is an opportunity with
1674:57 - respect to that okay if I if I am not
1675:00 - able to understand how to put this
1675:02 - knowledge in testing can uh get get can
1675:05 - I get mentorship from Team uh so that I
1675:08 - can implement this in the classroom
1675:10 - we'll discuss of those kind of use cases
1675:13 - see right now I did I I'm not a let's
1675:16 - say I'm not a good SQL Developer but
1675:18 - still I'm able to write queries right
1675:21 - yes sir from this application you saw
1675:23 - right now in testing also you you have
1675:26 - you do manual testing you do automated
1675:28 - testing right
1675:29 - yes so in that also you can do something
1675:31 - with respect to that there are lot of
1675:34 - different different things which you can
1675:35 - specifically do with this llm models
1675:37 - okay sure sir sure daily I will be
1675:40 - waiting for your videos okay today Chris
1675:42 - will be giving new video on which topic
1675:44 - I'm curiously every day waiting for your
1675:46 - videos your videos are so great and
1675:49 - helpful thank you ma'am thank you
1675:52 - thanks Kish this mju here yeah hi mju
1675:57 - yeah so what I'm looking for is like uh
1676:00 - I required uh company oriented realtime
1676:03 - projects for computer vision and large
1676:05 - language which you already teaching but
1676:07 - I I'm looking for a project which on
1676:09 - computer vision uh thing so will your
1676:13 - team will be helping on that already
1676:15 - already in our data science uh full
1676:18 - stack data science batch we are already
1676:20 - doing all those things end to endend
1676:22 - projects that are related to computer
1676:23 - vision and everything if I want to get
1676:26 - only the related to project because I
1676:27 - know all the things which is required
1676:29 - prequest for data sence I know all the
1676:31 - stops in that so now I only want the
1676:33 - project so so so so sir I I'll tell you
1676:36 - what we have come up with okay so are
1676:39 - you able to see my screen yeah yes I can
1676:42 - see now here you are able to see my
1676:45 - screen right so in I neuron right we
1676:47 - have something called as one neuron okay
1676:50 - now inside this one neuron we are
1676:51 - creating this data science project
1676:53 - neuron right so here you'll be able to
1676:56 - see computer vision set of projects
1677:00 - mhm right so this this entire neuron is
1677:03 - specific to projects only right here we
1677:06 - are not teaching anything from scratch
1677:08 - but instead focusing on solving projects
1677:10 - and these are like end to endend
1677:11 - projects with
1677:13 - deployment okay okay okay so just go to
1677:16 - one neuron and there is a data science
1677:17 - project neuron
1677:19 - sir oh okay Kish yeah thank you for that
1677:23 - yes
1677:27 - please yeah more question
1677:34 - guys I think mju had asked right right
1677:36 - now hello yes yes
1677:39 - mju okay any more question mju yeah but
1677:43 - seriously one thing I want to tell you
1677:45 - man you you are amazing honestly
1677:46 - speaking like you are making the things
1677:48 - like you know anybody can pick up things
1677:50 - and become a know any any from any
1677:54 - background and they can become a
1677:55 - programmer and move to the carer so the
1677:59 - way you are doing the way you are
1678:00 - teaching is you know you are reaching to
1678:02 - the worldwide you are not limited to
1678:04 - India like across the world people are
1678:05 - recognizing you that that is a level but
1678:07 - you need to give one motivation speech
1678:09 - like how you came from a know you are
1678:11 - from Karnataka from Karnataka so how you
1678:14 - grown up how you made yourself know that
1678:16 - one kind of know motivation video you
1678:17 - have to give like how you built your
1678:21 - know profile to to this level like to
1678:23 - you can reach out to the world that is
1678:25 - really amazing I'm very proud that you
1678:27 - are from my state
1678:29 - thank you thank you Manju definitely
1678:31 - we'll do a specific Meetup where in know
1678:33 - closed
1678:34 - audience specific office in Bangalore or
1678:37 - anything yeah yeah so in Bangalore we
1678:39 - have office so it's near uh this brigade
1678:42 - and we our building name is Brig
1678:45 - signature Tower oh okay okay yes try to
1678:48 - come up see at the end of the day U
1678:51 - again the main Vision over here is to
1678:53 - democratize AI education you know uh the
1678:56 - way that we are selling courses because
1678:58 - this courses adds values right uh it
1679:00 - helps you to get jobs it helps you to
1679:02 - make Transition it help you joined
1679:04 - multiple other I spent a lot of money
1679:07 - and learning but I see always I get a
1679:09 - very small like you always do in the
1679:11 - jupyter notebook know jupyter notebook
1679:13 - thing is a outdated stuff like where you
1679:15 - cannot use it in the company now we are
1679:17 - moving to the you need to build an app
1679:18 - company is looking for that because I'm
1679:20 - I'm working on that I'm already in the
1679:21 - industry I have a 10 plus experience and
1679:24 - I'm using it because you need to need to
1679:26 - build a app end to end so that that is
1679:28 - what industry is looking so there your
1679:31 - you stand out from rest of the crowd
1679:33 - which you are teaching so that is really
1679:35 - amazing continue to do M see we are
1679:37 - already coming from that background you
1679:39 - know so we know see my total years of
1679:42 - experience if I say it is somewhere
1679:43 - around 13 to 14 years okay and uh if I
1679:46 - talk about I we started at 2019 right so
1679:49 - that till that experience we were
1679:50 - already 8 to nine years experience
1679:52 - specifically me now I know like what
1679:55 - things are required in the company
1679:56 - working in company getting into a
1679:58 - company transition making a transition
1680:00 - in the company what in a project what
1680:03 - what skill sets you specifically require
1680:05 - right so hardly you'll be seeing any
1680:07 - Jupiter notebook session but instead we
1680:08 - focus on creating an end to- end project
1680:11 - or a module you know which will be very
1680:13 - much applicable in the sessions but
1680:15 - thank you for your uh amazing words that
1680:18 - you have actually said uh this is really
1680:21 - Heartfield you know because I I hear
1680:23 - from the people who are in us and
1680:24 - Australia different countries right they
1680:26 - they speak they watch your videos that's
1680:28 - you know from such a background like
1680:30 - where you are reaching today that is
1680:31 - really amazing it's it's inspiration for
1680:33 - everyone you know thank you thank you
1680:36 - mju again at the end of the day I need
1680:38 - to add values in others life and that is
1680:40 - what we our team in auron are doing with
1680:43 - the same vision we are working on thank
1680:46 - you uh
1680:47 - hello yeah yes sh
1680:50 - sh yes sir actually uh so what we are
1680:54 - doing is generally uh we are fine tuning
1680:56 - the llm and based upon our own data set
1681:00 - and we are getting that as some text
1681:02 - okay so is it possible to integrate the
1681:05 - uh you know so Panda's AI so to get that
1681:10 - plots uh sir I will just have a look
1681:12 - onto the Panda's AI I I've kept a point
1681:15 - over here first let me explore that you
1681:17 - know so once I probably explore that
1681:20 - then I can definitely come with that
1681:22 - thing okay so first of all let me
1681:24 - explore because I've never explored that
1681:25 - Panda's AI okay it is a kind of
1681:29 - yeah sure sure thank you yeah
1681:33 - yeah good evening next
1681:37 - question sir can yeah sir can you create
1681:41 - some Transformer projects or you explain
1681:43 - the two hours transform how it is going
1681:45 - on attention can you create some
1681:48 - projects sir so I seen your YouTube
1681:51 - channel
1681:52 - because uh llm and lstm projects is not
1681:56 - there in your playlist uh can you create
1681:59 - some projects within two weeks I mean or
1682:02 - else this month sure sir sure definitely
1682:05 - I'll do that sir you are creating the so
1682:07 - many projects right can I can I do that
1682:10 - projects to I mean fin year projects
1682:13 - like fin year projects yeah yeah you can
1682:15 - do it you can do it I mean how to uh sir
1682:19 - in my laptop you said that K python
1682:22 - version 3.10 right K is not available in
1682:25 - your laptop
1682:27 - it
1682:29 - you have to
1682:30 - install sir I install anakonda sir but
1682:33 - you have not you may have not set the
1682:35 - path that may be the problem the default
1682:37 - path will be there now that you have not
1682:40 - can I use can I can
1682:43 - I so without see if you try to do
1682:46 - without K it is possible by using pip
1682:48 - but again there'll be a lot of clashes
1682:50 - within your environments it will not be
1682:52 - at one specific place you know where all
1682:54 - the tracking of those environment is
1682:55 - done so it is a good idea to in your
1682:58 - YouTube channel sir actually I did not
1683:01 - see this actually I did not see this
1683:03 - live uh you upload one video on the
1683:06 - morning right I seen that two hours
1683:08 - video uh I follow your YouTube channel
1683:11 - very much as compared to this uh can I
1683:15 - uh downloading that uh K it is there in
1683:18 - your YouTube
1683:20 - channel yeah it is there but don't worry
1683:23 - I may also create another video where
1683:25 - you can directly use Python and create
1683:27 - an environment okay
1683:28 - okay can I see the okay sir I'm not
1683:32 - created yet I'll create those videos I'm
1683:33 - saying yeah no sir you to this I struck
1683:37 - in the starting only sir I entire thing
1683:39 - I writing the notes because I struck
1683:41 - there when I stuck there I did not come
1683:43 - the interest to go further so I writing
1683:46 - the notes so that's why I'm asking the
1683:49 - doubt okay don't worry see it's more
1683:51 - about creating python environment if
1683:57 - you hm
1684:00 - V see I'll I'll show you one link over
1684:04 - here okay just give me a
1684:08 - second sir one more idea is uh iuran you
1684:13 - are connecting that 16,000 right sir
1684:16 - mean gen CES mhm
1684:20 - 16,000 5
1684:22 - 8,000 huh sir that much money I did not
1684:26 - bother sir because my friend also want
1684:28 - to contribute me can I both join ion
1684:34 - sir just talk to the just talk to the
1684:36 - team like let's see what team can
1684:38 - actually do okay just talk to our
1684:40 - counselor team how how I want to contact
1684:43 - to the team sir uh see in the website
1684:46 - itself right you will have the number
1684:48 - see over here talk to our
1684:51 - counselor
1684:53 - bottom their number is given you can
1684:55 - talk to them okay so see over here
1684:57 - creation virtual environment uh this
1685:00 - entire documentation is given okay you
1685:02 - can use this and create an virtual
1685:04 - environment just follow the steps
1685:07 - automatically you'll be able to do it
1685:09 - okay okay sir I don't know the internal
1685:12 - parts how YOLO is working from where I
1685:14 - want to study that wo V8 that all I
1685:17 - don't know I mean where I want to
1685:20 - study see YOLO documentation is given in
1685:23 - a amazing way over there if you have
1685:26 - seen
1685:27 - YOLO
1685:29 - V8 right if you see this specific
1685:31 - documentation right I think most of the
1685:33 - things are given step byep installation
1685:35 - everything is given over there but don't
1685:37 - worry in ion no we'll be coming up with
1685:39 - live classes with respect to deep
1685:40 - learning also okay
1685:43 - from YouTube paid live session in paid
1685:48 - code also if you want to join there is
1685:50 - already but in YouTube also we'll have
1685:52 - live session going on okay yeah can you
1685:55 - explain you sir how internal parts is
1685:58 - working math behind that sure definitely
1686:02 - okay thank you sir thank you yeah thank
1686:05 - you yeah next
1686:08 - question hi sir yeah hi Hari uh sir
1686:14 - uh yeah nice to meet you sir sir uh I
1686:18 - have a question so in machine learning
1686:20 - and deep learning how we use uh graph
1686:23 - modeling sir I mean uh I uh I mean I I
1686:28 - saw the one article regarding graph
1686:31 - modeling but depends on what kind of use
1686:34 - case right graph modeling can be used in
1686:36 - multiple use case uh it is
1686:38 - AA fraud detection uh I mean like
1686:44 - that so see again you can use this
1686:48 - techniques but sometimes right you also
1686:50 - need to think which algorithm is very
1686:52 - much feasible to use with respect to a
1686:54 - project okay okay yes your uh uh the
1686:59 - algorithm with respect to this will
1687:00 - speeden up the process but again try to
1687:02 - understand this I've not yet created any
1687:05 - videos with respect to that you know let
1687:08 - me have a look onto that and see if I'm
1687:10 - able to create one project I'll try to
1687:11 - upload that in my channel okay okay sir
1687:14 - actually uh I mean uh last couple of uh
1687:18 - days
1687:19 - weeks I watched your video sir and uh uh
1687:23 - I uh mention those uh project Basics
1687:26 - projects regarding the generate U uh in
1687:29 - my uh resume and I I got a call I mean
1687:33 - the interview call and I clear the first
1687:36 - round I have technical rounds right now
1687:39 - and so I I don't know exact exact I mean
1687:44 - how how we'll go so can I get the some I
1687:48 - mean like knows like how the interview
1687:51 - is going to go always make sure that
1687:53 - when you have a technical round prepare
1687:55 - well your projects right it should be
1687:57 - till deployment
1687:58 - what all things you have done in that
1688:00 - you have to explain that properly so
1688:01 - that you know you guide the interviewer
1688:03 - what what should be the next question
1688:05 - that he should ask you know try to try
1688:08 - to make sure that you have the control
1688:10 - of the interview not the interviewer you
1688:12 - know so the information that you have
1688:13 - portraying in front of him right try to
1688:16 - provide him some some things that you
1688:18 - have actually done which may be
1688:19 - something new for him because see
1688:22 - interviewer would like to just
1688:23 - understand that what all things you know
1688:25 - so how well you specifically speak with
1688:27 - respect to a project the more the better
1688:29 - it is okay okay sir actually I uh I
1688:33 - enrolled the I mean Genera a clause sir
1688:36 - uh I mean the but I mean I I mean l i
1688:40 - mean the S I mean sa also teaching the
1688:44 - generate UI I mean the community section
1688:46 - so I watched those videos and I took one
1688:49 - project uh I mean he I mean what he's
1688:52 - teaching and I uh mentioned that project
1688:55 - in my resume and I'm not expert in a
1688:58 - Genera right now so I'm very scared of
1689:01 - that what how will go the don't be don't
1689:04 - be scared of it see if you know how to
1689:06 - use apis that's it you just need to be
1689:09 - scared whether you know Python
1689:10 - programming language or not the more
1689:12 - better you know Python programming
1689:13 - language the more better you'll be able
1689:15 - to create this llm application okay okay
1689:18 - sir so don't worry see anyhow you are in
1689:20 - the course and uh when you are in the
1689:22 - course you don't have to worry with us
1689:24 - okay okay
1689:26 - sir yeah thank you sir
1689:28 - yeah next question
1689:31 - please hi sir
1689:33 - rendra rendra you're my inspiration
1689:36 - basically to be frank sir can you make
1689:39 - some in your playlist based upon llm sir
1689:41 - large language modules with python
1689:43 - custom
1689:44 - gpts from scratch you're saying yeah yes
1689:48 - sir see I will take llama 2 model okay
1689:51 - so llama 2 is there it is a very good
1689:53 - open source model on top of that I will
1689:55 - try to show you fine tuning okay by
1689:57 - using this or clor method okay yeah okay
1690:00 - sir and I have one doubt sir regarding
1690:02 - YOLO before doing NM I mean non maximum
1690:06 - sub Su we do some something called we do
1690:11 - sorting desing order before that we do
1690:14 - something we give some threshold values
1690:15 - and if it is less than 0.3 threshold
1690:17 - threshold we we make it as zero Suppose
1690:21 - there is a some small object tiny object
1690:24 - is there suppose there's a tiny object
1690:26 - which it has a score of 0.2 in the sense
1690:29 - so we may lose the data in we may lose
1690:31 - the data in that case so rinda just give
1690:35 - some days okay what we will do is that
1690:37 - we'll try to create a dedicated video
1690:39 - for that okay I'll tell my team also
1690:41 - with maths don't worry everything will
1690:44 - broke break break into math smaller
1690:46 - smaller parts so that you'll be able to
1690:48 - understand okay directly explaining
1690:50 - right now will be difficult so let's
1690:51 - wait for one video okay from our end
1690:54 - yeah I purchased the dlcv NLP from inur
1690:57 - sir I have completed the course I have
1691:00 - completed the course I have this this
1691:02 - just have qued to the neuron support
1691:05 - team and one small can you explain da
1691:09 - data
1691:10 - argumentation see data argumentation is
1691:12 - like let's say you have one of my image
1691:15 - okay now to train a model you know what
1691:19 - I can do is that I can change my face
1691:21 - like this like this and give the model
1691:22 - give the model different different
1691:24 - images to identify me data augumentation
1691:26 - what it does is that it takes all the
1691:28 - images it tries to horizontally rotate
1691:30 - it vertically rotate it expand it zoom
1691:33 - in zoom out so it tries to creat a
1691:35 - variety of the same images so that the
1691:38 - vision model whatever Vision model you
1691:40 - are actually creating it'll be able to
1691:42 - understand that image very much
1691:45 - easily so you're just trying to create
1691:47 - multiple images by applying some
1691:49 - techniques some transformation
1691:51 - techniques where it can probably zoom in
1691:53 - zoom out horizontal flip vertical flip
1691:56 - it can do multiple things in the image
1691:57 - and create a new one okay uh the day
1692:00 - before yesterday I was doing a project
1692:02 - based upon deing sir I was trying to
1692:04 - read I have created a folder and I
1692:06 - created some dogs photos of dogs I have
1692:09 - downloaded and some photos of cats when
1692:12 - I was trying to read that in the collab
1692:14 - it's not getting running it's showing an
1692:17 - error for me sir why better drop US mail
1692:20 - to the support provide the collab link
1692:22 - over there okay and let them have a look
1692:25 - with respect to that okay so we have a
1692:27 - dedicated team who will take care of all
1692:29 - these things okay try to do L
1692:34 - from
1692:36 - python thank you sir that's yeah
1692:40 - thank sir I sir I have one question sir
1692:44 - uh currently Vision language models are
1692:46 - coming up are you going to include that
1692:48 - in our course generative course sir mean
1692:51 - I'm not sure whether the document papers
1692:53 - released or not but Vision language
1692:55 - models are coming up right so are you
1692:57 - going to include that in generative
1692:59 - course yeah sure see the thing is that
1693:02 - at the end of the day whatever things
1693:04 - are coming in generative AI let's say
1693:06 - the vision language model you basically
1693:07 - saying large image models right so uh
1693:10 - the gini Pro Vision whatever
1693:12 - functionalities whatever projects will
1693:13 - be developing over there also we'll take
1693:15 - that in the class H okay sir and I heard
1693:19 - one of the uh student asked that about
1693:22 - python may I know what level of python
1693:25 - is required sir because as I asked you
1693:27 - before data structures and algorithms I
1693:29 - am very poor at data structures and
1693:30 - algorithms until what level I have to
1693:33 - Learn Python may please the python you
1693:35 - definitely need to note in modular
1693:37 - programming language you know oops
1693:39 - inheritance classes all these things
1693:41 - that is the reason we have given that as
1693:43 - a prerequisite along with that we have
1693:45 - given the entire recorded videos in the
1693:47 - curriculum okay yeah I'm aware of till
1693:49 - oops sir but data structures and
1693:51 - algorithms like in advanced uh tree
1693:54 - graphs and all uh is that will not be
1693:57 - required to create projects okay that
1693:58 - will not be
1693:59 - required okay sir thank you and in in
1694:02 - Project do we get some real time
1694:05 - industry level uh how they are
1694:08 - using all the deployment techniques
1694:10 - we'll teach you all the deployment
1694:12 - techniques you know what all things are
1694:14 - currently happening and in the future
1694:16 - let's say when the curriculum is going
1694:17 - on when the course is going come when
1694:19 - anything new comes we will also take
1694:21 - care of that you are going to add in
1694:23 - that course sir not add but at least
1694:26 - we'll discuss that modules in the last
1694:28 - okay first we'll complete the entire
1694:30 - curriculum and then we'll try to include
1694:32 - that yes definitely I want to get into
1694:35 - this uh generative uh field because I
1694:40 - have only the hope is about this only
1694:42 - this course sir after this course I I
1694:45 - don't have any other way to switch to in
1694:48 - testing I have only hope is this gener
1694:50 - course sir I try your best yes sir thank
1694:55 - you sir thank
1695:01 - you okay guys so it's already 10: so 2
1695:04 - hours of session I hope you like this
1695:06 - session please do hit like uh and as
1695:10 - usual uh keep on supporting and again I
1695:12 - will be coming in the next week Friday
1695:14 - live session we will be discussing more
1695:16 - about amazing projects and all uh again
1695:19 - let's see what all things are basically
1695:21 - coming till the next week I'll come up
1695:22 - with that and we'll have a good one so
1695:25 - thank you this was it for my side so if
1695:27 - you are new please make sure that you
1695:28 - subscribe the channel subscribe all the
1695:30 - Ion channel share with all your friends
1695:32 - share share share the post like whatever
1695:34 - things you specifically do tag me over
1695:36 - there I'll be happy to answer or
1695:39 - probably comment down like what kind of
1695:41 - works you have specifically done uh yes
1695:46 - uh at the end uh I would always like to
1695:50 - say one thing guys uh see there are new
1695:54 - things that are coming in the market
1695:55 - right the reason why we are teaching all
1695:58 - this new stuffs is that it actually
1696:00 - increases your effic efficiency
1696:03 - productivity at the end of the day the
1696:05 - more you work the more you put effort
1696:08 - the more you become a successful right
1696:10 - you go in any company you go anywhere
1696:13 - right the more knowledge you gain and
1696:15 - trust me in anything that you do in your
1696:17 - life if you spending two hours in
1696:19 - learning if you are spending three hours
1696:21 - in learning if you are not learning also
1696:23 - right some or the other thing you
1696:24 - specifically learn with respect to each
1696:26 - and everything
1696:28 - right
1696:29 - and one more thing that if I probably
1696:32 - talk about in neuron right so this in
1696:35 - neuron support if you want to really see
1696:37 - a real practical example okay so let me
1696:42 - just show share my screen so in this
1696:45 - example you'll be able to see there is
1696:47 - something called as support system right
1696:50 - the main llm we have integrated in this
1696:53 - entire support application right so let
1696:56 - me just go through this so that you get
1696:58 - an clear understanding what all things
1697:00 - are basically there let's say once you
1697:02 - join a batch let's say you are in
1697:04 - generative AI so mastering generative AI
1697:07 - batch is over
1697:08 - here you can join the group in this
1697:11 - particular batch right so let's say I'm
1697:14 - in machine learning boot camp okay or
1697:16 - I'm in this particular boot camp in all
1697:18 - the all the batches I've probably joined
1697:20 - let's say there is data science
1697:21 - interview batch going on okay now you
1697:24 - may be asking various question like can
1697:27 - we probably communicate with our team
1697:29 - members can we have a onetoone session
1697:32 - can I probably study in a group so for
1697:34 - this let's say I in this specific batch
1697:36 - if you go ahead and join over here there
1697:38 - is something called a join group as soon
1697:40 - as you join group right then here you'll
1697:43 - be able to see that this group will be
1697:45 - added right let's say over here the
1697:46 - machine learning boot camp is over here
1697:48 - I've joined this the data science
1697:50 - interview back so all your team members
1697:52 - will be in this specific group you can
1697:54 - ask any question as like as you like you
1697:56 - know you can ask any any question as you
1697:58 - want right over here like you can
1698:00 - probably ping hi all the members you'll
1698:03 - be able to see you'll be able to ask any
1698:05 - question if you want to probably do a
1698:07 - group study everything will be in one
1698:09 - platform itself right apart from this if
1698:11 - you want to communicate with anyone
1698:14 - right if you want to probably
1698:15 - communicate with anyone here right you
1698:17 - can also do that now see karik Kash
1698:20 - basically says that why one 121 support
1698:23 - is stopped because this was when we are
1698:25 - developing things right so here you can
1698:27 - probably see thanks Chris not sure if
1698:29 - this is Chis in human or chish the chat
1698:32 - bot I'm the human over here right now
1698:34 - let's say if you want to get more
1698:36 - queries and right now there are many
1698:38 - people who pay some pay they pay $20 to
1698:41 - chat GPT but by using this Megatron you
1698:44 - don't have to pay anything you can
1698:45 - directly chat it over here let's say
1698:47 - give me the python
1698:49 - code python
1698:51 - code
1698:53 - to create a floss cap okay if I write
1698:57 - like this if I execute it I'll be able
1698:59 - to get the entire
1699:01 - code right so here what we have done by
1699:03 - using see over here in the Megatron we
1699:05 - have used llm but the other entire
1699:08 - application looks more like a WhatsApp
1699:10 - message right where you can probably do
1699:11 - one to one group chat you can have any
1699:13 - kind of discussion now see all the
1699:15 - questions are basically there right not
1699:17 - only that once you probably go to the
1699:19 - knowledge ocean let's say if you have
1699:20 - any query right you can go ahead and
1699:22 - write the query right so it'll you have
1699:25 - to probably select the batch where you
1699:26 - are in let's say I'm in mastering
1699:28 - generative Ai and I say hey what is
1699:31 - generative AI right now before when we
1699:35 - were giving the support sometimes
1699:37 - because of huge queries we are not able
1699:40 - to solve that in 24 hours but now by
1699:42 - using the support system we'll be able
1699:44 - to solve within 24 hours let's say I'm
1699:46 - asking what is generative AI okay and
1699:48 - I've asked this question and I post it
1699:51 - over here right so here when you go to
1699:54 - knowledge session you'll be able to see
1699:56 - new to Old what is generative AI you'll
1699:59 - be able to see over here wait new to Old
1700:01 - this is old to
1700:02 - new um let me just go ahead over here in
1700:06 - the homepage so you'll be able to see
1700:08 - all the queries that people have asked
1700:10 - now this is where uh the most amazing
1700:13 - thing will be that as soon as you
1700:14 - probably click over here you'll be able
1700:15 - to see all the responses from the
1700:16 - students right large language models are
1700:19 - this this this this let's say if some if
1700:22 - none of the student provides a response
1700:24 - over here then what will happen is that
1700:26 - our our llm model will provide the
1700:28 - response within 24 hours it will first
1700:31 - of all go ahead and filter and see which
1700:33 - question is not been answered and then
1700:36 - we probably what we do is that we
1700:37 - provide a response over here itself
1700:39 - right normally none of the vendors
1700:41 - allows to talk with other batment in the
1700:43 - join course yes but we allow the reason
1700:46 - is that people waste their time people
1700:49 - waste their time joining multiple groups
1700:51 - right someone will be joining telegram
1700:54 - someone will be joining WhatsApp and
1700:56 - other than
1700:57 - studies other than studies you know they
1701:01 - will talk all rubbish things right
1701:03 - they'll not talk more about studies but
1701:04 - other than that everything they'll talk
1701:06 - right so this is one specific place
1701:09 - where you can have a discussion about
1701:10 - each and everything right and not only
1701:13 - that let's say you want to provide if
1701:15 - you have any queries and you want to
1701:16 - probably write a mail to us you can
1701:19 - compose the mail here itself you don't
1701:20 - have to open a Gmail probably go ahead
1701:22 - and write query at theate ion. a or
1701:25 - support at theate ion. AI right
1701:27 - everything and in the future what is
1701:29 - going to happen right in the future
1701:32 - you'll be able to see that right now we
1701:34 - have this chat right in the future our
1701:36 - Megatron will be so strong since we are
1701:39 - processing with two 20,000 videos see we
1701:42 - have highlighted over here 20,000 videos
1701:45 - has been
1701:46 - processed along with that it has
1701:48 - generated 6,000 question and its answers
1701:50 - so any question that you specifically
1701:52 - ask either you can get a video or either
1701:55 - you can get any kind of answer from our
1701:57 - Megatron itself or from our this
1701:59 - specific chat B right so that is how
1702:02 - strong it is going to have become in the
1702:05 - future so at the end of the day this we
1702:07 - are specifically doing because you'll be
1702:09 - able to communicate with your batchmates
1702:11 - you'll be able to do group study you'll
1702:12 - be able to do projects you'll be able to
1702:14 - do internships multiple things all at
1702:16 - one place and if I probably show you
1702:20 - ion. every tab that you see over
1702:23 - here every tab right this altogether has
1702:27 - a complete different story let it be
1702:30 - with respect to internship portal let it
1702:32 - be with respect to job portal neuro laab
1702:35 - neurolab why did we come with neurolab
1702:37 - because many people did not have that
1702:40 - strong laptop or machine to do the
1702:42 - coding so that is the reason we came up
1702:44 - with this Virtual Lab wherein you can go
1702:46 - ahead and probably uh you know open any
1702:50 - IDs probably work with flask work with
1702:52 - python it provides you an entire
1702:54 - development environment which is running
1702:55 - in Cloud so you don't face that specific
1702:57 - lag then support system was one of the
1703:00 - challenges which you are trying to fix
1703:01 - from past two to three years now this is
1703:04 - completely fixed and still we are making
1703:07 - it much more better you're going to
1703:08 - provide lot of features as I said all
1703:11 - these things are basically coming over
1703:12 - here the best thing is that you don't
1703:13 - have to pay any money for this right if
1703:15 - you are part of a course you will be
1703:17 - able to use this right that is the most
1703:20 - powerful thing and again why we are
1703:22 - doing this this is for our community we
1703:24 - really want to build our community in
1703:26 - such a way that you learn you learn in
1703:29 - an amazing way and at the end of the day
1703:31 - get placed somewhere make Transitions
1703:34 - and yes obviously help others also
1703:36 - whenever you get that particular
1703:37 - opportunity okay so thank you uh this
1703:41 - was it from my side uh I hope you like
1703:43 - this entire things that I've actually
1703:45 - shared okay and yes this was it for my
1703:50 - side keep on rocking keep on learning um
1703:53 - other than this please go ahead and
1703:54 - check out all the courses in the Inon
1703:56 - and will be provided in the description
1703:57 - of this particular video uh and yes I
1704:00 - will see you all in the next video have
1704:01 - a great day thank you take care bye-bye
1704:04 - everyone Tata at least say Tata I know
1704:06 - you did not ask answer much question
1704:08 - over there okay but yes a good happy
1704:12 - weekend for all of you out there thank
1704:13 - you guys thank you so if you able to see
1704:17 - my screen just give me a quick
1704:18 - confirmation everyone so we will go step
1704:20 - by step we'll go with the agenda we will
1704:22 - try to understand many things as such
1704:24 - you know topic by topic I will be
1704:27 - writing in front of you wherever Google
1704:29 - is required I will take the help of
1704:31 - Google I will show you research papers
1704:33 - and many more things as well okay so let
1704:36 - me just see in LinkedIn also whether I
1704:38 - am visible or not so I'm just going to
1704:40 - see in multiple
1704:41 - places uh so I'm excited about this sir
1704:46 - as an India llm for large language will
1704:47 - be taking flight off yes many many
1704:49 - companies are specifically using in use
1704:51 - cases and all so it'll be quite amazing
1704:53 - so let me see whether we are live ion
1704:57 - LinkedIn page or not okay just give me a
1704:59 - second okay perfect I can see myself
1705:02 - over here there are chats there are
1705:05 - messages that are probably coming up
1705:06 - okay
1705:10 - great okay let me hide the current
1705:12 - comment okay so what is the agenda of
1705:15 - this specific session what all things we
1705:17 - are specifically going to discuss so the
1705:19 - first topic as usual is to
1705:23 - understand what is generating
1705:28 - AI okay so we are going to first of all
1705:32 - understand what is generative AI okay
1705:36 - because you may have heard about machine
1705:37 - learning deep
1705:39 - learning you may have heard about
1705:41 - natural language processing where does
1705:43 - it exactly fit okay so we'll also be
1705:45 - able to understand it then after
1705:48 - completing this we will try to
1705:50 - understand how
1705:53 - llms model are trained
1705:59 - so what what does llm model basically
1706:01 - mean large language model okay we'll
1706:04 - also understand what is large language
1706:06 - model when we are discussing about
1706:07 - generative AI so the third thing we will
1706:10 - be discussing about open
1706:17 - source we will be discussing
1706:20 - about open
1706:22 - source and paid llm models
1706:30 - and which one you can specifically use
1706:32 - if you don't have money enough what you
1706:34 - have to really take care of see at the
1706:36 - end of the day these all are models okay
1706:39 - and uh if you have powerful gpus and is
1706:42 - it possible that you can also train your
1706:43 - llm model from scratch yes so everything
1706:46 - is possible I will be taking up making
1706:48 - sure that I'll explain each and
1706:49 - everything okay right now the models
1706:54 - that are very much famous that are in
1706:56 - the industries right now right so you
1706:58 - may be hearing about chat GPT right so
1707:01 - chat GPT I will just write the model
1707:02 - name let's say gp4 right we will discuss
1707:06 - about some some of the good open source
1707:08 - models like Lama 2 we will be also
1707:11 - discussing about gini Pro right why gini
1707:15 - pro why gini Google Gemini right I'm not
1707:18 - talking about Palm or B Google BS and
1707:21 - all right gini Pro um recently Google
1707:24 - has launched this three amazing llm
1707:26 - models right three versions of gini
1707:28 - models right and geminii pro right now
1707:31 - is available for everyone out there to
1707:33 - use it to create an end to end project
1707:35 - and it is completely for free right you
1707:37 - can probably use 60 queries per minute
1707:40 - you know you can you can actually give
1707:42 - somewhere around 60 queries per minute
1707:44 - for uh for using it in your use cases
1707:47 - yes soon it will also be coming up with
1707:49 - uh paid models uh if you want more
1707:52 - queries to hit right so it is good to
1707:54 - start with all these things I'm just
1707:56 - given some list of llm models over here
1707:59 - other than this there are a lot of llm
1708:01 - models also open source llm models like
1708:03 - Falcon Mistral right so I hope everybody
1708:06 - has heard about all the specific things
1708:09 - okay so let's see how many topics I will
1708:12 - be able to cover step by step and if
1708:14 - something is remaining again we will
1708:15 - continue in the next week Friday session
1708:18 - so first of all let's go ahead and
1708:20 - understand about generative AI okay so
1708:25 - the first topic we will go ahead and
1708:27 - discuss about what is generative AI okay
1708:31 - so everybody understood about the agenda
1708:34 - what we are specifically looking at
1708:37 - right agenda we'll also be discussing
1708:39 - about large image models also that
1708:41 - question will also be coming up okay so
1708:44 - there's a question a little bit about
1708:46 - llm models and open AI I will discuss
1708:48 - about it okay
1708:51 - um okay I have a good knowledge of
1708:54 - python okay I'll take up questions okay
1708:55 - so but I hope everybody's clear with the
1708:57 - agenda that we are actually looking at
1708:59 - so now let's go ahead and understand
1709:01 - with respect to generative AI now before
1709:04 - understanding generative Ai and where
1709:05 - does it fall in this entire universe of
1709:09 - artificial intelligence you know so if I
1709:11 - probably consider this as an example
1709:13 - let's say and this this diagram probably
1709:15 - I've I've taught in many of the classes
1709:18 - I've explained you all and all let's
1709:19 - let's consider the entire universe and
1709:22 - this universe I would like to say that
1709:24 - this is nothing but this is this is
1709:26 - artificial
1709:27 - intelligence okay this is nothing but
1709:29 - this is artificial intelligence right
1709:32 - and what is the main of aim of
1709:34 - artificial intelligence is that whether
1709:36 - you work as a data scientist whether you
1709:38 - work as a machine learning engineer
1709:41 - whether you work as a software engineer
1709:43 - who specifically wants to harness the
1709:45 - power of machine learning deep learning
1709:49 - at the end of the day you creating
1709:50 - applications those are smart application
1709:53 - that can perform its own task without
1709:55 - any human intervention so that
1709:57 - specifically is called as artificial
1709:58 - intelligence right so what is exactly
1710:00 - artificial intelligence it's just like
1710:02 - creating smarter application that are
1710:04 - able to perform its own task without any
1710:07 - human intervention okay so that is what
1710:10 - AI specifically means so tomorrow you
1710:13 - work as a data scientist you work as a
1710:15 - machine learning engineer or you work as
1710:16 - a software engineer who wants to harness
1710:19 - the power of machine learning deep
1710:20 - learning techniques at the end of the
1710:22 - day you will try to create an AI
1710:24 - application only right some some of the
1710:26 - examples with respect to this AI
1710:27 - applications as I've already told
1710:29 - earlier Netflix right Netflix is one
1710:33 - streaming platform let's say movie
1710:34 - streaming
1710:35 - platform here an AI module is integrated
1710:39 - right so there is an AI module that is
1710:42 - integrated now this AI module I would
1710:44 - like to say it is nothing but movie
1710:45 - recommendation system right movie
1710:48 - recommendation
1710:50 - system movie recommendation right
1710:53 - Netflix is already a software product it
1710:55 - is a movie streaming platform but we are
1710:57 - trying to make it much more smarter so
1710:59 - that it will be able to give us or
1711:01 - provide us movies right recommend us
1711:04 - movies without any human intervention
1711:06 - see our human inputs will get captured
1711:08 - over there what movies you like like
1711:10 - action movies whether you like sentiment
1711:13 - movies comedy movies all those
1711:14 - information is getting recorded right
1711:17 - but we are not asking human to to to
1711:20 - take some decision in short this AI app
1711:23 - will take its decision by itself right
1711:25 - so so this is what artificial
1711:26 - intelligence is all about now coming to
1711:28 - the second one if I probably consider
1711:30 - the second one that is nothing but we
1711:33 - basically talk about machine learning so
1711:35 - what exactly is machine learning here I
1711:37 - will be talking about ml okay now with
1711:40 - respect to ml right what what exactly is
1711:43 - machine learning machine learning
1711:45 - provides you what it provides you stats
1711:50 - tools stats tools it provides you stats
1711:53 - tools to
1711:57 - analyze
1712:01 - data right to analyze data to to create
1712:05 - models and these models will be
1712:07 - performing various task it can be
1712:10 - forecasting it can be
1712:12 - prediction it can be feature engineering
1712:14 - anything as such right but all these
1712:18 - activities that you are specifically
1712:20 - doing in this I would like to consider
1712:23 - all those as stats tools it is provided
1712:25 - ing this tool to do or to perform this
1712:28 - work right so here you'll be seeing that
1712:31 - we learn about different things like
1712:34 - supervised machine learning unsupervised
1712:35 - machine learning we learn about
1712:37 - techniques wherein you create models
1712:41 - that models are able to do
1712:42 - classification regression problem
1712:43 - statement forecasting Right Time series
1712:45 - prediction right different different
1712:47 - tasks can be performed with the help of
1712:50 - machine learning right and machine
1712:52 - learning initially what was famous if
1712:55 - probably say five to six years back
1712:57 - everybody used to probably use machine
1712:59 - learning techniques and now also they
1713:01 - use it for most of the use cases they
1713:03 - use it right but now because of
1713:05 - generative AI now they able to think
1713:07 - much more with respect to different
1713:08 - different business use cases right so at
1713:11 - the end of the day with the help of
1713:12 - machine learning we are trying to do
1713:13 - that okay still now coming to the next
1713:16 - one what about deep learning right so
1713:20 - deep
1713:20 - learning is another part of or I can
1713:23 - also say it as a subset of machine
1713:26 - learning now what was the main aim of
1713:27 - deep learning over here here we had to
1713:30 - create multi-layered neural
1713:33 - network
1713:36 - multi-layer neural
1713:38 - network okay multi-layered neural
1713:41 - network now multi-layer neural network
1713:43 - why we specifically
1713:45 - require multi-layer neural network see
1713:48 - we human being wants the application to
1713:50 - perform like how we human being think
1713:53 - right let's say I want an application to
1713:55 - perform like how I am able to teach how
1713:57 - I am able to study in that similar way
1713:59 - if I want to make a machine also learn
1714:02 - in a similar way I have to use
1714:03 - multi-layer neural network right and
1714:05 - that is where deep learning was becoming
1714:07 - famous and this is from 1950s but right
1714:10 - now we have huge amount of data and if I
1714:13 - compare the differences between machine
1714:15 - learning and deep learning is that the
1714:16 - more data I have and I train a deep
1714:19 - learning model the performance also
1714:21 - increases the same thing does not happen
1714:24 - with respect to machine learning
1714:26 - right so that is the reason we are
1714:27 - discussing about multi-layer neural
1714:29 - network and this is where deep learning
1714:31 - come into picture and again they are
1714:33 - different techniques that we have
1714:34 - already learned about you know Ann CNN
1714:38 - RNN these are the basic building blocks
1714:41 - other than this you have seen about many
1714:43 - things like you have object detection
1714:44 - rcnn you have YOLO algorithms in RNN you
1714:47 - have lstm RNN Gru right Transformer B
1714:51 - encoder decoder all these things you
1714:53 - have specifically learned that all are
1714:55 - are part of deep learning these are
1714:57 - solving some specific use cases some
1715:02 - specific use cases right these are
1715:06 - solving some specific use cases right so
1715:09 - this is again deep learning is a part or
1715:12 - subset of machine learning okay now
1715:15 - comes I hope everybody's clear till here
1715:17 - because this I already taught it earlier
1715:19 - also to all of you the reason why I'm
1715:21 - teaching you over here is to make you
1715:23 - understand where does generative I fall
1715:25 - into picture so if you if you are able
1715:28 - to understand till here please give me a
1715:30 - confirmation by writing in the chat yes
1715:32 - no something you're able to understand
1715:34 - over here right so just give me a
1715:37 - confirmation give me a thumbs up okay
1715:39 - give me something hit like for this
1715:41 - specific video so that it reaches many
1715:43 - people to so that you'll be able to
1715:46 - understand because nowadays from the
1715:48 - students who have already made
1715:49 - transition specifically in uron they're
1715:52 - working on generative AI they're working
1715:54 - on llm application they're creating some
1715:56 - amazing application to solve different
1715:58 - different business use cases so that is
1716:00 - why I am basically discussing about all
1716:02 - these things right so I hope everybody
1716:05 - is able to understand tiia perfect so I
1716:07 - I'm able to get the confirmation they
1716:09 - good signs like this and all so
1716:11 - everybody uh is able to understand it
1716:15 - amazing now let's go ahead and
1716:17 - understand where does generative AI fall
1716:19 - into picture again guys now if I
1716:22 - consider generative Ai and what exactly
1716:24 - generative AI we'll discuss in some time
1716:27 - but generative AI will be falling as a
1716:30 - subset of deep learning okay as a subset
1716:33 - of deep planning so this circle that I
1716:36 - am considering is nothing but it is a
1716:38 - generative AI okay now why it falls why
1716:42 - it falls as a subset of deep learning
1716:45 - because at the end of the day we are
1716:46 - using deep learning techniques also most
1716:49 - of the llm models that you'll be seeing
1716:52 - is nothing but is based on two models
1716:54 - one is Transformers another one is Bert
1716:57 - okay these two models are super amazing
1717:00 - models I hope you may have heard about
1717:02 - something called as attention is all you
1717:05 - need right attention is all you need
1717:12 - right so attention is all you need there
1717:15 - you have these amazing models
1717:17 - Transformers and birds this are also
1717:18 - called as encoder decoder sequence to
1717:20 - sequence models these are the base of
1717:24 - many many many gener AI models or llm
1717:26 - models that we will be seeing
1717:29 - okay so all these things you should
1717:32 - definitely know it because these are the
1717:35 - basic building block today we have so
1717:38 - many models in the market we have chat
1717:40 - GPT we have GPT 3.5 we have GPT 4 now
1717:44 - GPT 4 Turbo is also coming right you
1717:47 - have llama models you have Falcon you
1717:49 - have Mistral you have gini right jini
1717:52 - Pro you have Google B pal models many
1717:55 - many models are there in the Market at
1717:57 - the end of the day they most of them
1717:59 - most of them I know most of them has
1718:01 - this as the base model that is
1718:03 - Transformers of bir right and many more
1718:06 - things over here now considering this
1718:09 - people or companies what they do they
1718:12 - train with some different techniques
1718:13 - they add reinforcement learning they do
1718:15 - some type of fine-tuning to to make
1718:18 - their model become much more better so
1718:20 - that is the comparison that is basically
1718:22 - made now recently Google came up with
1718:25 - with gini Pro so it started making
1718:26 - comparison okay it is so much better
1718:28 - than chat GPT sorry GPT 3.5 it is so
1718:31 - much better than this particular model
1718:33 - it is it is able to uh reach mmu of this
1718:37 - much accuracy right human understanding
1718:39 - accuracy is this much reasoning accuracy
1718:42 - is this much all this particular
1718:44 - information is basically the metrics
1718:46 - right at the end of the day the base
1718:48 - that you're specifically using is either
1718:51 - Transformer bird in short you're using
1718:53 - this advanced architecture of the neural
1718:56 - networks and you're training or you're
1718:58 - pumping you're training this models with
1719:00 - huge amount of data and that is where
1719:03 - someone will come and say hey this model
1719:05 - has somewhere around billions of
1719:06 - parameter everybody will get shocked wow
1719:09 - billions of parameter wow amazing nice
1719:11 - great we are going to get a good model
1719:13 - then right but understand the context
1719:16 - when we say billion of parameters that
1719:18 - basically means how much how much
1719:19 - weights is basically considered how many
1719:21 - weights parameter are there how many
1719:22 - bias parameter there how many so many
1719:24 - things are there there and many more
1719:25 - things right I'll be discussing about
1719:26 - gini Pro as I go ahead okay and I will
1719:29 - be showing you some of the accuracy
1719:30 - metrics also as we go ahead once I see
1719:33 - reach the research paper but what
1719:34 - exactly is generative AI I will discuss
1719:36 - about it in some time now there is also
1719:39 - one more thing which is called as llm
1719:41 - models right where large language models
1719:44 - see in generative AI also we have llm
1719:47 - models we have large image
1719:49 - models L IM okay llm and LM llm
1719:54 - basically means large language models
1719:57 - that basically means it will be able to
1719:59 - solve any kind of use cases that is
1720:02 - related to text very much simple so
1720:05 - whenever I talk about llm in short we
1720:08 - are talking about text whenever I'm
1720:10 - talking about large image model we are
1720:12 - talking about
1720:14 - images okay any use cases with that is
1720:17 - with respect to images or video frames
1720:19 - or anything as such okay so this is
1720:21 - nothing but this is called as large
1720:26 - image
1720:28 - models right there is one more thing
1720:31 - where many people may have heard about
1720:33 - it okay and recently gini Pro right it
1720:36 - Google says that gini
1720:39 - Pro is a multimodel what does multimodel
1720:43 - mean multimodel what does it mean it
1720:47 - basically means that it is able to solve
1720:49 - use cases for both that is text and
1720:53 - images text and images it is able to do
1720:57 - both this task okay so that is why it is
1721:00 - basically called as multimodel right
1721:03 - most of the I hope everybody has heard
1721:06 - about a tool called as mid Journey which
1721:08 - is able to generate amazing
1721:10 - images mid Journey right mid journey is
1721:13 - what it is an Li large image model right
1721:18 - mid Journey it is able to create image
1721:20 - it is when you write a text it is able
1721:22 - to create an image gin Pro what it does
1721:25 - is that you give a image it'll be able
1721:26 - to do all the object detection within
1721:28 - then it'll be able to write a blog for
1721:30 - you right so all amazing things are
1721:32 - basically happening now why this is
1721:34 - beneficial for companies because
1721:35 - companies don't have to waste time
1721:37 - startups don't have to waste time to
1721:39 - quickly create some applications that
1721:41 - solves a problem statement before
1721:44 - everything used to happen from scratch
1721:47 - they used to create projects they used
1721:48 - to create models they used to do
1721:49 - finetuning they used to worry about data
1721:52 - they used to do multiple things but now
1721:54 - it has really becomes simplified okay so
1721:57 - I hope everybody is able to understand
1721:59 - about generative AI what exactly is
1722:01 - generative AI I'll just discuss about it
1722:03 - understand this term generative okay and
1722:07 - we will discuss as we go ahead di di is
1722:09 - a large image model yes di is definitely
1722:13 - a large image model yes perfect right so
1722:18 - guys still here if you have understood
1722:19 - please make sure that you hit like it
1722:21 - will motivate me because you want me to
1722:23 - come in the next week also right right
1722:25 - every week Friday we will do a session
1722:27 - where I will be teaching you all the
1722:29 - specific things right so do hit like
1722:32 - let's target that till the end of the
1722:34 - session we should make the like button
1722:36 - hit more than 500 okay I want that right
1722:39 - more than 500 come on you can do it huh
1722:42 - see so nice handwriting in front of you
1722:44 - you should be motivated by seeing this
1722:46 - handwriting not your like a college
1722:48 - professor and writing right I'm using
1722:49 - multiple cols making it much more
1722:51 - interactive and the best thing is that
1722:54 - everything will be available to you I
1722:55 - will also upload this um if you Pro
1722:59 - probably find in the description there
1723:00 - will be a webinar link over there
1723:02 - everything I will try to provide you
1723:03 - over there itself
1723:05 - okay so chat GPT is llm yes chat GPT is
1723:09 - using GPT 3.5 GPT 4.0 those are llm
1723:13 - models large language models if Chad GPT
1723:15 - is using di that basically becomes a
1723:17 - large image model okay perfect great now
1723:22 - let's go ahead and let's talk about so
1723:24 - this is what I gave a brief idea where
1723:27 - does generative AI fit into okay now
1723:30 - let's understand what exactly is
1723:31 - generative AI okay still we are able to
1723:35 - Now understand now what is generative
1723:39 - AI okay let's let's go
1723:42 - ahead I'll talk about Lang chain why
1723:45 - Lang chain chain lit Lama index where
1723:47 - does it fall first of all let's start
1723:49 - with some Basics okay and here again two
1723:53 - things are obviously going to come
1723:57 - large
1724:00 - language
1724:02 - models and the second one is
1724:06 - large image models okay so let's go
1724:10 - ahead and let's discuss about
1724:16 - this great
1724:19 - now when we are discussing about large
1724:21 - language models and large image models
1724:23 - so first of all the question question
1724:25 - that you should be asking fine
1724:28 - Krish what exactly is generative AI why
1724:31 - why the word
1724:33 - generative why the word generative at
1724:35 - the first instance so see some years
1724:39 - back we used to use traditional machine
1724:41 - learning algorithm see over here first
1724:44 - of all we started with something called
1724:47 - as
1724:48 - traditional ml
1724:52 - algorithms okay we started like this so
1724:55 - in this ml algorithm what we did is that
1724:59 - we had to perform feature engineering we
1725:02 - had to probably create a model right
1725:04 - train
1725:05 - model right we had to probably do fine
1725:08 - tuning
1725:11 - right right and then as we went we
1725:14 - finally did the deployment now from
1725:16 - traditional machine learning algorithm
1725:18 - why did we first of all move to deep
1725:21 - learning algorithm again traditional I'm
1725:24 - I'm writing over here as traditional DL
1725:30 - algorithms okay now we move towards
1725:34 - traditional deep learning
1725:36 - algorithms okay why did we move over
1725:40 - here we saw that when we were increasing
1725:45 - the data set even though we increase the
1725:48 - data set and the best way to show this
1725:52 - diagram is basically to create like this
1725:54 - see
1725:55 - so this is my machine learning let's say
1725:57 - this is my graph this graph is with
1726:00 - respect to two thing data set and
1726:06 - performance okay data set and
1726:10 - performance now over
1726:12 - here with machine learning algorithm
1726:15 - with traditional machine learning
1726:16 - algorithm you could see that when data
1726:19 - was increasing after one point of time
1726:22 - the performance of the traditional
1726:23 - machine learning algorithm started
1726:26 - bending in this way that basically means
1726:27 - even though I increased the data at
1726:29 - certain point of time right then also my
1726:33 - performance was not
1726:34 - increasing right but now this was the
1726:39 - problem now with deep learning
1726:40 - algorithms when I say deep learning
1726:41 - algorithms I'm specifically using over
1726:43 - here multi-layered neural network okay
1726:47 - multi-layered neural network now with
1726:49 - respect to multi-layered neural
1726:51 - network as I started increas increasing
1726:54 - the performance or as I started
1726:56 - increasing the data set the performance
1726:58 - also started
1727:00 - increasing and this was with DL
1727:07 - algorithms and this
1727:10 - was with
1727:13 - traditional ml
1727:18 - algorithms this was with traditional ml
1727:22 - algorithms now that is the reason deep
1727:25 - learning become became very very much
1727:28 - famous so most of them started solving
1727:32 - problems such as
1727:35 - supervised
1727:37 - unsupervised machine learning techniques
1727:39 - or deep learning techniques or problem
1727:40 - statement with the help of deep learning
1727:42 - algorithms and now you know right from
1727:45 - object detection to NLP let it be any
1727:48 - task from computer
1727:51 - vision to
1727:53 - NLP to any task you're also able to do
1727:57 - with the traditional deep learning
1727:59 - algorithm
1728:01 - right now till here everything was good
1728:03 - companies were working nice hugging face
1728:05 - had so many deep learning algorithms
1728:07 - probably now it has deep learning
1728:09 - algorithms for any task that you want
1728:11 - any task let it be any any task for any
1728:15 - task you have a traditional deep
1728:17 - learning algorithm available where you
1728:19 - can download the model where you can do
1728:21 - fine-tuning where you can use transfer
1728:23 - learning techniques and you can probably
1728:25 - create your own application now this is
1728:28 - where one amazing thing
1728:31 - happened and I'll tell you that was the
1728:33 - time you know uh where blockchain was
1728:36 - also becoming very famous when
1728:38 - blockchain hype was there you know
1728:40 - mainly all the people were
1728:42 - focused Mo most of the audience most of
1728:44 - the people most of the researcher were
1728:46 - also focused on web3 but they were also
1728:47 - some good set of researchers who are
1728:50 - focusing on something called as
1728:52 - generative AI now now here is what I'm
1728:55 - going to draw a diagram for you to make
1728:57 - you understand what exactly is
1728:59 - generative AI first of all I will go
1729:02 - ahead and write deep learning over
1729:04 - here as you know generative AI is a
1729:06 - subset of deep learning
1729:09 - right now in generative AI with all the
1729:13 - traditional deep learning
1729:15 - algorithms we usually say this
1729:19 - as
1729:22 - discriminative now you'll understand
1729:24 - what is the difference between
1729:26 - discriminative models and generative
1729:32 - models so mostly all the Deep learning
1729:35 - algorithms is divided based on these two
1729:38 - important
1729:39 - techniques one is the discriminative
1729:41 - technique one is the generative
1729:43 - technique okay now in discriminative
1729:46 - technique which all task you are focused
1729:50 - on
1729:52 - doing first most of our task like
1729:56 - classify
1729:59 - predict right or object
1730:04 - detection or any supervised unsupervised
1730:08 - technique here the data
1730:13 - set these models are basically trained
1730:18 - on trained on labeled data
1730:23 - set
1730:25 - right and this
1730:27 - discriminative is with
1730:31 - traditional DL
1730:34 - algorithms okay traditional deep
1730:37 - learning algorithms over here we
1730:39 - specifically use traditional deep
1730:42 - learning algorithms now let's understand
1730:46 - about generative model and this is where
1730:48 - your I you will get a clear idea about
1730:50 - it what exactly I'm going to talk about
1730:53 - in generative models the task I'm just
1730:56 - going to write the task here the task is
1731:00 - just to
1731:03 - generate new
1731:07 - data trained
1731:10 - on trained
1731:13 - on some
1731:17 - data okay here what is the main task of
1731:21 - generative model is that the word
1731:23 - generative now you'll understand the
1731:26 - main importance of this word generative
1731:28 - here you are generating new data trained
1731:31 - on some data set okay
1731:35 - example write a write an essay on
1731:41 - generative AI if I ask this
1731:44 - question it will be able to answer let's
1731:47 - say it has been trained with some huge
1731:49 - amount of data that is available in the
1731:50 - internet now I will go ahead and ask
1731:53 - write an essay on generative AI should
1731:55 - be able to give me the answer now let me
1731:58 - go ahead and talk about one simple
1732:02 - example so that you get a clear
1732:05 - understanding what exactly I'm talking
1732:07 - about with respect to generative AI a
1732:10 - real world example because people
1732:12 - usually like this kind of real world
1732:13 - example okay and with this real world
1732:16 - example you will be also able to
1732:18 - understand multiple things right so
1732:21 - let's go ahead and understand it with
1732:23 - real world examp example and that is
1732:25 - where you'll be able to understand about
1732:26 - generative AI so how does a generative
1732:31 - AI task look like okay let's imagine
1732:35 - okay Kish is over here
1732:40 - okay let's imagine not let's not take
1732:43 - Kish let's take some person is over
1732:50 - here and this is relatable okay
1732:54 - this person is in 12th
1732:57 - standard let's say it clears NE exam
1733:01 - neat exam and now it is basically doing
1733:05 - mbbs mbbs mbbs is specifically for
1733:09 - becoming doctor okay now over here you
1733:13 - will be able to see that how many years
1733:16 - this person will probably learn in the
1733:20 - college 4+ 1 right I guess 4 plus 1 four
1733:23 - years of learning learning one year of
1733:25 - internship so after learning for 4 plus
1733:28 - 1 years will it be trained or will it
1733:31 - learn from multiple book sources at
1733:33 - least thousands of
1733:35 - books yes or
1733:38 - no will it will this person learn from
1733:40 - many books at not tell me guys just give
1733:43 - me a quick confirmation can you just
1733:45 - read one book and become a doctor no
1733:47 - thousands of books right thousand of
1733:51 - books right so this person will be
1733:54 - spending those five years reading
1733:56 - thousands of books and after reading
1733:59 - thousand books okay don't fight on the
1734:01 - number if I'm saying thousands that
1734:03 - basically means many books okay I know
1734:06 - some people will say sir how come
1734:07 - thousands are in my whole life I did not
1734:09 - learn thousand okay many
1734:13 - books
1734:14 - okay many books so once he or she or
1734:19 - this person learns from many books
1734:21 - spends those 4 plus one year one year
1734:23 - here with internship so internship
1734:25 - knowledge is also going to come over
1734:26 - there now what is the final aim this
1734:30 - becomes the this person becomes a
1734:33 - doctor so let's consider this is my chat
1734:38 - GPT with
1734:40 - doctor doctor chat
1734:43 - GPT okay now tell me if you go and ask
1734:48 - this doctor any
1734:51 - question any question related
1734:54 - to any medical
1734:57 - problem generic medical
1735:00 - problem generic medical problem will you
1735:03 - be able to get the
1735:06 - answer will you be able to get the
1735:09 - response yes yes or
1735:12 - no now is it necessary the doctor will
1735:14 - say only with accordingly to the books
1735:16 - only no it can create his own answer
1735:19 - you'll say that hey I'm feeling I'm not
1735:21 - feeling well you know I'm having this
1735:23 - kind of symptoms the doctor will come up
1735:24 - with his own word because he has all the
1735:26 - knowledge from all those books all those
1735:28 - experience that he has put in his
1735:29 - internship all the people he has
1735:31 - actually treated in those five
1735:34 - years right it will be able to provide
1735:37 - the response right so what what what is
1735:41 - this doctor right now can I say this
1735:43 - doctor can act like an llm model
1735:46 - now large language model who is an
1735:49 - expert in
1735:52 - medicine
1735:54 - who is expert
1735:55 - in medicine right this is just like a
1735:59 - large language model who is an expert in
1736:01 - medicine and this is what recently openi
1736:03 - is trying to do right what is open
1736:05 - trying to do over here openi is planning
1736:08 - to come up with something called as GPT
1736:12 - store have you heard about this GPT
1736:14 - store GPT store basically means what you
1736:17 - can now create your own llm
1736:20 - models and train it with your own custom
1736:26 - data right and on the go you can create
1736:29 - this particular app right in open that
1736:32 - option is already there right I have
1736:34 - also tried it out and it works
1736:36 - absolutely fine I will tell those model
1736:39 - how it has to
1736:42 - behave now here you're spending 4 plus 1
1736:45 - years and you are becoming a doctor now
1736:48 - this becomes an llm model who's an
1736:49 - expert in medicine now the next step of
1736:53 - this doctor is to become an MD now there
1736:55 - are some questions which this doctor
1736:57 - will not be able to understand which the
1737:00 - doctor will not be able to give the
1737:01 - proper answer it may give you a generic
1737:04 - answer so what we need to do we need to
1737:06 - train this llm model again with more
1737:08 - data and this time the
1737:11 - specialization right you want to become
1737:13 - an MD in cardiology you want to become a
1737:15 - MD in Ortho you want to become a MD in
1737:18 - some other field so that expertise will
1737:20 - again G when this person will be trained
1737:23 - with more three to three two to three
1737:25 - years of books
1737:28 - right along with experience where you
1737:32 - given those kind of task I hope you're
1737:34 - getting it right guys I'm trying to use
1737:36 - many more examples that is the most
1737:38 - important thing the more examples you
1737:41 - see the more well you'll be able to
1737:43 - understand so at the end of the day what
1737:46 - this doctor is doing it is able to
1737:47 - generate its own response based on the
1737:50 - problem statement it sees
1737:54 - yes based on the problem
1737:58 - statement so this is how we are trying
1738:00 - to learn it tomorrow all you have to do
1738:03 - if you're working in any business in any
1738:05 - companies tomorrow what you will do you
1738:07 - will take any model you can f tune with
1738:10 - your own data set and that particular
1738:12 - model can behave accordingly based on
1738:14 - the company's use case at once right so
1738:17 - this is how things goes ahead right so
1738:19 - if you have understood till here please
1738:21 - give some thumbs up sign I hope
1738:22 - everybody's able to understand please
1738:24 - give it a thumbs up say something Krish
1738:26 - I'm happy I want to see some happy faces
1738:29 - please do hit like please do make sure
1738:31 - that you subscribe the channel and I
1738:33 - want from every one of you you have to
1738:35 - share these videos
1738:37 - everywhere right we are trying to
1738:40 - democratize AI education over here
1738:42 - everybody should know the importance of
1738:44 - AI because tomorrow trust me you going
1738:48 - to use it somewh the other way right
1738:51 - anywhere you are going to use it no one
1738:53 - is going to say that you cannot use it
1738:55 - you have to use it right many people
1738:59 - will say hey there is no job by use it
1739:02 - in your personal personal day-to-day
1739:05 - activities and don't worry about job if
1739:07 - you're good at something whether you are
1739:09 - from any technology you will be able to
1739:11 - get jobs all you have to do is that have
1739:14 - that knowledge right if you're able to
1739:16 - have that specific things trust me it is
1739:18 - very good easy to learn and it is
1739:20 - absolutely when you also try to convey
1739:23 - this information to someone right then
1739:25 - you'll be able to understand that how
1739:27 - important all this technology is
1739:28 - tomorrow in a company a business use
1739:31 - cases getting solved and you provide a
1739:33 - solution wherein you don't have to spend
1739:35 - much money in those use cases right
1739:39 - those people will keep you instead of
1739:41 - anyone right and they'll give you most
1739:42 - of the problems to solve right so in
1739:45 - this way so please make sure that you
1739:46 - hit like share with all the all the
1739:48 - friends some or the other way someone it
1739:51 - may be helpful for anyone who will be
1739:52 - learning over here okay now let's go
1739:56 - ahead to The Next Step where here we
1740:00 - have understood about generative AI so
1740:02 - what is the main aim of generative AI
1740:03 - the main aim of generative AI is to
1740:05 - generate some content now let me talk
1740:08 - about some of the use cases right so use
1740:11 - cases I will be talking about and use
1740:13 - cases we will discuss with respect to
1740:14 - both techniques one is discriminative
1740:17 - technique discriminative technique
1740:19 - whenever the name comes discriminative
1740:21 - it is going to discriminate based on the
1740:24 - data it will give you some kind of
1740:26 - output right some classification problem
1740:29 - regression problem something right so
1740:31 - first technique is nothing
1740:33 - but discriminative technique in this
1740:36 - discriminative technique let's say I'm
1740:39 - taking a use case I have a data set
1740:42 - which which says types of
1740:46 - music types of music so here I will try
1740:51 - to create
1740:54 - a discriminative ml discriminative model
1740:58 - discriminative DL
1741:00 - model and this work will be to basically
1741:04 - classify whether this music belongs to
1741:07 - rock whether this music belongs to
1741:10 - classical or whether this music belongs
1741:13 - to
1741:15 - romantic right so this is basically
1741:18 - discriminative technique right now
1741:21 - coming to the next one which is B
1741:23 - basically called as generative
1741:27 - technique generative technique let's
1741:30 - consider I have a music again same use
1741:33 - case only we'll try to do let's say this
1741:35 - is my music okay it looks like a hard
1741:37 - bit but I'm considering it as a music
1741:40 - and this music I will train it my my
1741:44 - generative model how the training will
1741:46 - happen I will talk about it so let's say
1741:48 - this is my generative model and now the
1741:51 - generative model will talk askask is to
1741:53 - basically generate a new
1741:58 - music this is just one use case of
1742:00 - generative AI I'm not worried about
1742:02 - whether it is large image model large
1742:04 - language model and all I'm just showing
1742:06 - you with respect to do same use cases
1742:09 - what discriminative models will do and
1742:11 - what generative models will specifically
1742:12 - do right so in short we are generating
1742:16 - new content this is super important this
1742:18 - is what this is new content clear every
1742:22 - everyone
1742:24 - happy yes
1742:28 - everyone just give me yes or no if you
1742:31 - able to understand this
1742:34 - things yeah so till here everybody's
1742:37 - clear I hope you got an idea with
1742:39 - respect to discriminative and generative
1742:42 - technique okay now is the main question
1742:46 - how llm models are trained now you'll
1742:49 - understand
1742:51 - this
1742:54 - okay guys don't worry Lang chain Lama
1742:57 - index I will teach what exactly it is
1743:00 - okay
1743:02 - how
1743:04 - llm models are
1743:10 - trained just wait B till the end of this
1743:14 - session you'll understand all these
1743:16 - things right and once you understand it
1743:18 - it will be very good amazing you'll get
1743:21 - a clear idea and that is what is my
1743:22 - target Target today tomorrow if somebody
1743:24 - ask a question related to generative llm
1743:26 - models you should be able to understand
1743:29 - it okay perfect now how are llm models
1743:33 - trained so let me just go ahead and use
1743:37 - one open source model llama 2 paper Okay
1743:41 - so llama 2 is a model that
1743:44 - is that is generated by meta okay So
1743:47 - Meta has trained this model and this is
1743:49 - the research paper
1743:51 - okay this is this is the research paper
1743:53 - the reason why I'm showing you this
1743:54 - research paper because based on this
1743:58 - model only I will teach you how this
1744:00 - model may have also trained
1744:03 - okay yeah yeah this video will be
1744:05 - available in the future in the YouTube
1744:07 - in the dashboard along with all the
1744:09 - materials that I'm writing that I'm
1744:11 - showing to you okay so don't worry focus
1744:13 - on the class now over here see there are
1744:17 - three important information that you can
1744:19 - see from this content okay one is the
1744:24 - pre-training right it talks more about
1744:27 - the pre-training data it talks about the
1744:29 - training data details and it talks about
1744:32 - Lama to pre-train model evaluation the
1744:35 - next one is it talks about fine tuning
1744:37 - see fine tuning here we are going to
1744:40 - discuss the supervised finetuning please
1744:42 - remember this word okay supervised
1744:46 - finetuning super important super amazing
1744:49 - technique altoe and I will break down
1744:51 - this technique and make you understand
1744:54 - how training usually happens everything
1744:56 - will be taught in this session then the
1744:58 - third one is something called as
1745:00 - reinforcement learning with human
1745:02 - feedback R
1745:05 - lhf please remember this techniques
1745:07 - because same technique is also used chat
1745:09 - GPT models supervised fine-tuning
1745:13 - reinforcement learning with human
1745:15 - feedback along with there is something
1745:18 - called as reward system also which I
1745:20 - will be
1745:21 - discussing so the reason why I'm showing
1745:24 - you this research paper because this
1745:27 - research paper are very easy to
1745:29 - understand if you have some prerequisite
1745:31 - knowledge about Transformer about
1745:34 - something about some accuracy concept
1745:36 - some performance metrics concept if you
1745:38 - know that much that will be more than
1745:40 - sufficient okay so let me go ahead and
1745:43 - show you so if I go to introduction see
1745:47 - large language model that is talking
1745:49 - about this this this Lama 2 now llama 2
1745:52 - has been it scales up to 70 billion
1745:56 - parameter okay there was three specific
1745:59 - models in Lama 2 which we'll discuss uh
1746:02 - it is with respect to 7 billion 13
1746:04 - billion and 70 billion
1746:06 - parameters here I am just trying to show
1746:08 - you some important information and based
1746:11 - on this only I will teach you okay now
1746:14 - let's understand
1746:16 - this so this is how entirely it happens
1746:20 - you have pre-training data you have self
1746:23 - supervised learning you have Lama 2 you
1746:26 - have sft supervised finetuning you have
1746:30 - rejection sampling proximal policy
1746:32 - optimization because everything will be
1746:34 - taught this is nothing but reinforcement
1746:37 - learning with human feedback and based
1746:39 - on this particular feedback we assign
1746:43 - something called as safety reward model
1746:45 - and helpful reward model everything I'll
1746:47 - teach you don't worry just see the
1746:49 - diagram focus on the diagram and try to
1746:51 - just see this
1746:54 - okay okay over here so every component
1746:58 - that you're seeing I will break it down
1747:00 - and I'll explain you now where does this
1747:03 - model take the predating data from so
1747:06 - here you can probably see our model
1747:10 - right is everybody able to see
1747:13 - this when we say it parameter train from
1747:16 - 17 billion yes so everybody's able to
1747:19 - see
1747:21 - this
1747:23 - yeah so on pre-training data includes a
1747:27 - new mix of data from publicly available
1747:30 - sources so from where they have taken
1747:33 - the data from publicly overed sources
1747:35 - which does not include data from meta
1747:37 - products or
1747:38 - Services okay we made an effort to
1747:41 - remove data from certain sites known to
1747:43 - contain a high volume of personal
1747:44 - information about private
1747:47 - individual so from where it has taken
1747:49 - the data in short this is all lie I gu
1747:52 - yes they have taken the data from
1747:54 - wherever it is they are saying we made
1747:56 - an effort they're saying we made an
1747:59 - effort to remove data from certain sites
1748:02 - effort you know how much effort it is
1748:04 - there okay so understand okay efforts
1748:08 - then we trained on two trillion tokens
1748:10 - of data as provides a good performance
1748:13 - cost trade up so two trillion tokens of
1748:17 - data it has been trained in okay so here
1748:21 - the next thing see see see see see we
1748:24 - adopt most of the pre-training setting
1748:26 - and model architecture from Lama 1 we
1748:28 - use the standard Transformer
1748:31 - architecture they by Transformer
1748:35 - architecture see tomorrow if you give me
1748:38 - a chance I can also create a I can also
1748:40 - create an llm
1748:42 - model creating an llm model is not very
1748:46 - difficult but the main problem will be
1748:50 - cost of the GPU
1748:54 - how much cost of the GPU it will take
1748:56 - what should be a team size to do
1748:57 - reinforcement learning over there
1749:00 - everything in that particular thing that
1749:01 - cost will be doing so you'll be able to
1749:03 - see only big companies can only afford
1749:06 - all these things who have billions and
1749:08 - billions of dollars in fundings and all
1749:11 - tomorrow if you say whether I can also
1749:14 - do it yes the answer is you should have
1749:16 - just money to do it because you require
1749:19 - those huge gpus the gpus cost training
1749:22 - time it will cost how much data you
1749:24 - require they will you'll also require
1749:26 - people for working for you who will be
1749:28 - doing that annotation task labeling task
1749:30 - indexing task reinforcement
1749:33 - task right but for this you require a
1749:36 - huge amount of money tomorrow if someone
1749:38 - comes and say hey take this much money
1749:39 - create your own model we can do that no
1749:42 - worries right but in India we don't
1749:45 - Focus much on Research right we focus
1749:47 - much
1749:48 - on we focus much on what solving
1749:51 - business use case and trying to earn
1749:53 - Revenue out of it okay research I have
1749:56 - not seen much companies who are doing
1749:57 - research that much okay so
1749:59 - infrastructure cost is there so see
1750:00 - Transformer architecture so if anybody
1750:02 - knows about Transformer architecture
1750:04 - done you'll also be able to do it apply
1750:07 - pre-normalization some techniques will
1750:09 - be there code will be available you can
1750:10 - also do it okay now if Lama 2 is an open
1750:14 - source you can also use the same code
1750:15 - and try to do it okay then we trained
1750:18 - using adamw Optimizer see these all
1750:20 - videos I've already created explained
1750:22 - you like anything what Adam Optimizer
1750:25 - how does it work this this everything is
1750:27 - Basics I'm not teaching I'm not showing
1750:30 - you anything
1750:31 - new right beta 1 is there beta 2 is
1750:34 - there this is there we we use a cosine
1750:36 - learning rate what is cosine learning
1750:38 - warm-up step DK final running rate
1750:40 - everything is same nothing new it's like
1750:44 - build sand sand sand and make a castle
1750:47 - okay I have sand I have bricks I will
1750:50 - combine them and make a uh make a five
1750:53 - star hotel in short right and everybody
1750:56 - cannot make a five star hotel right who
1750:58 - has money they can make it who has money
1751:00 - they can make a huge Bungalow right a
1751:03 - Maharaja Palace something right they can
1751:05 - do that so I hope you're able to
1751:07 - understand all this things you need to
1751:09 - have money for that okay so here are
1751:13 - there Lama one had come up with 17
1751:14 - billion 13 billion 33 billion 65 billion
1751:16 - now Lama 2 is coming up with 7 billion
1751:18 - 13 billion 34 billion 70 billion now why
1751:21 - this billion is increased inreasing why
1751:23 - this parameters are increasing some f
1751:25 - tuning will be done more data will be
1751:27 - added more data will be included more
1751:29 - reinforcement will be done multiple
1751:32 - things will be put up over there and
1751:34 - that is how your parameters will
1751:36 - increase and there is no other way the
1751:38 - parameter is not going to increase over
1751:40 - there right parameter will increase over
1751:42 - here itself right something you do in
1751:45 - that more parameters will get added more
1751:47 - weights more bias it's all about more
1751:50 - weights and more bias okay less Dropout
1751:54 - more Dropout more normalization less
1751:56 - normalization that that way only
1751:58 - parameters are getting added you may be
1751:59 - thinking parameters is getting added I
1752:01 - think they have put a rocket launcher
1752:03 - inside that model no nothing like
1752:06 - that just they have added more data set
1752:08 - maybe more fine-tuning techniques and
1752:11 - because of that more weights more bias
1752:13 - are getting added that's it right don't
1752:16 - think that no something is happening the
1752:18 - model will now go to Mars no nothing
1752:20 - like that okay so this is what is all
1752:23 - about Lama 2 okay
1752:25 - now this is my training loss you have
1752:28 - seen in many many videos in deep
1752:29 - learning how the training loss will be
1752:31 - shown over here right so training loss
1752:34 - is over here see training Hardware we
1752:36 - trained our models on meta research
1752:38 - super
1752:40 - cluster meta research super cluster okay
1752:43 - by this name only gpus both clusters use
1752:46 - Nvidia a00 let's let's see what is
1752:48 - NVIDIA a00
1752:51 - cost
1752:53 - let's see
1752:55 - okay Nvidia 800 powering many of this
1752:58 - application this is just roughly $10,000
1753:02 - chip just $10,000 chip just
1753:07 - imagine see 27 L 27 lakhs dollar is
1753:12 - NVIDIA Amper
1753:14 - 800 who will be able to do which startup
1753:17 - will be able to do this much money will
1753:18 - be able to invest this much
1753:20 - money tell me
1753:23 - the reason why I'm showing you this
1753:24 - because the research paper talks more
1753:26 - many things about it right so over here
1753:29 - they have used Nvidia a00 you SE in the
1753:32 - cost of
1753:33 - it amazing right how much is this cost
1753:36 - 27 lakh I guess sorry
1753:41 - 27,000 and more chips if you try to put
1753:43 - up more chips over there the cost will
1753:45 - keep on increasing right we are still we
1753:49 - are our laptop has RTX 490 that
1753:52 - basically means we are our laptop is
1753:53 - very powerful there will be electricity
1753:55 - cost involved there will be multiple
1753:56 - things
1753:57 - involved
1753:59 - right so everything is over here you can
1754:02 - probably see with respect to this right
1754:04 - it is somewhere around 27k sorry not 27
1754:06 - lakh it is 27k as as I just saw 0. I did
1754:11 - not leave that part okay so but you can
1754:15 - just understand the cost is keep on
1754:16 - increasing okay so here you can see that
1754:19 - RSC uses Nvidia Quantum in Infinity band
1754:22 - where product cluster is equipped with
1754:24 - Roc you can probably see
1754:27 - this C see see see CO2 emission during
1754:30 - pre-training you have to also give this
1754:32 - information if you want to publish the
1754:33 - research paper total GPU time required
1754:35 - for required for training each model
1754:38 - power consumption PE power Peak capacity
1754:40 - per CPU device for gpus see how much
1754:43 - carbon is emitted right 7B is this
1754:47 - much power consumption 400 watt 400 watt
1754:51 - 350 watt 400 wat total total GPU hours
1754:56 - take 33 lakh 31,000 no no 33 laks 11,000
1755:02 - hours GP
1755:05 - hours who has this much time guys if a
1755:07 - startup in India will spend this much
1755:09 - time in training
1755:12 - done I don't know this is how many years
1755:15 - let's say 24 into 12 uh 24 into 365 just
1755:20 - do how many hours will be there how many
1755:22 - years it has basically trained right
1755:25 - carbon P for print pre-training and all
1755:27 - these information are basically there
1755:29 - right and then here also you can
1755:31 - probably see the comparison size Code
1755:33 - common sense reasoning World Knowledge
1755:35 - reading comprehension math mlu mlu is
1755:37 - basically human level understanding uh
1755:39 - BBH and AGI right now I've have told all
1755:42 - this information now let's understand
1755:45 - how this models are basically trained
1755:47 - how llm models are trained okay so till
1755:50 - here everybody happy
1755:53 - yes everybody happy with the teaching
1755:56 - that I'm actually doing so now we are
1755:58 - going to move towards how llm models are
1756:00 - trained and we will discuss it step by
1756:02 - step so guys clear or
1756:05 - not clear or not just tell me give me a
1756:09 - quick
1756:10 - information so here I'm going to
1756:12 - basically write the stages
1756:19 - of stages of
1756:28 - stages of training so first information
1756:31 - here I specifically
1756:35 - have I will just
1756:38 - draw the stage
1756:42 - one so this is my stage one based on
1756:45 - that research paper I'm basically going
1756:47 - to draw okay so this is nothing
1756:50 - but generative
1756:53 - pre
1756:55 - tring okay generative pre-training
1756:59 - second
1757:09 - stage so second stage is nothing but
1757:16 - supervised
1757:18 - fine tuning which we also say it as SF
1757:21 - the same information what is written
1757:24 - over there that research paper same
1757:26 - thing I'm writing third
1757:31 - stage third stage is
1757:34 - what
1757:40 - reinforcement
1757:44 - through human feedback this is my third
1757:49 - stage Okay so initially in this stage in
1757:54 - generative
1757:56 - pre-training we give huge data so this
1757:59 - can be so any any llm model basically
1758:03 - takes internet Text data or any document
1758:07 - Text data in PDFs in all all those
1758:10 - formats and here we specifically create
1758:13 - or use this generative pre-
1758:15 - technique now generative pre-training
1758:17 - basically means here specifically we use
1758:20 - transform architecture
1758:25 - model Transformer of bir architecture
1758:27 - model the outcome of this is what the
1758:31 - outcome of this
1758:34 - is the outcome of this is we basically
1758:38 - say it
1758:39 - as
1758:41 - base let's say if I probably
1758:46 - consider if I probably
1758:50 - consider so I will write this is my
1758:54 - base Transformer
1758:59 - model what is this the base Transformer
1759:02 - model okay now this base Transformer
1759:05 - model is then base Transformer model
1759:07 - basically means whatever Transformer I
1759:10 - basically trained on I will basically
1759:11 - say this as base Transformer model okay
1759:14 - now the base transform model is in turn
1759:17 - connected with supervised fine tuning
1759:19 - because same model will be taken and and
1759:21 - supervised fine tuning will be done on
1759:23 - top of it
1759:25 - okay top of it right now this understand
1759:28 - this base transform model will be able
1759:30 - to do various task like text
1759:31 - classification text summarization
1759:34 - multiple things it will be able to do
1759:36 - okay now here only we will not keep it
1759:38 - in case of uh llm model we will take it
1759:41 - to the next step the next step is
1759:44 - supervis finetuning now here what we are
1759:47 - specifically going to do we are going to
1759:50 - use
1759:52 - human trainers
1759:55 - also we are going to involve human
1759:58 - trainers to put some kind of
1760:04 - conversation some kind of conversation
1760:06 - and here we will create some more custom
1760:09 - data this is important to understand
1760:12 - here we will try to create some more
1760:14 - custom
1760:16 - data right so some more custom data will
1760:19 - be created in this case in this
1760:21 - particular step and those custom data
1760:25 - which is created it is created basically
1760:27 - by whom by human trainers I will talk
1760:30 - about what exactly is human trainer when
1760:32 - I probably Deep dive more into it okay
1760:36 - then it based on this custom data we
1760:38 - will train the specific model and the
1760:40 - outcome of this
1760:42 - model outcome of the model will
1760:46 - be okay just a
1760:49 - second oops it got closed let's see
1760:52 - whether it is saved or
1760:57 - not I hope so it should be saved oh my
1761:03 - God okay apologies the system got
1761:06 - crashed I don't know what happened
1761:09 - because of that the entire material got
1761:15 - deleted
1761:18 - sad can't help
1761:21 - okay so how much content I had actually
1761:23 - written I don't know whether it's the
1761:25 - system got crashed or the scribble
1761:28 - notebook automatically got
1761:30 - deleted sad to hear about it but it's
1761:34 - okay I don't think so anywhere it
1761:38 - is okay I don't
1761:43 - know generative AI the materials got
1761:47 - deleted I'm extremely sorry I don't know
1761:50 - what happened over here but I'm not able
1761:53 - to see
1761:54 - that materials got deleted yeah okay no
1762:01 - worries anyhow you'll be able to see in
1762:03 - the recordings so don't worry about that
1762:05 - uh let me continue
1762:09 - okay let me continue okay okay now let's
1762:12 - go step by step I was just talking about
1762:14 - some important things over there so
1762:17 - first step I will go with respect to
1762:18 - stage one okay so stage one
1762:28 - generative
1762:30 - pre training okay this is basically my
1762:33 - stage
1762:34 - one now what all things we basically
1762:37 - discussed in
1762:40 - this okay in generative pre-training
1762:44 - what we specifically do is that we use
1762:47 - Transformer architecture okay so here
1762:50 - what we are doing
1762:51 - we basically
1762:53 - use
1762:59 - Transformers Super beneficial for NLP
1763:01 - task and then along with this we take
1763:05 - Internet Text data and document Text
1763:08 - data so this is nothing but
1763:12 - internet Text
1763:14 - data
1763:16 - and
1763:18 - document Text data
1763:22 - okay and this is what is my stage
1763:26 - one okay stage one now once we train
1763:29 - with this specific Transformer we what
1763:32 - we get we get
1763:35 - base
1763:37 - Transformer
1763:39 - model we get base Transformer model now
1763:43 - what this base Transformer model is
1763:46 - basically is Cap capable of right what
1763:50 - this base Transformer model is capable
1763:52 - of you need to understand this specific
1763:54 - thing okay this base Transformer
1763:58 - model is capable of doing
1764:01 - task here I will write down all the
1764:05 - task number
1764:06 - one text
1764:17 - summary I will save this saving this is
1764:20 - always better so that if it gets deleted
1764:23 - I can open it so the task which is able
1764:26 - to do is like task text
1764:30 - summary sentiment
1764:35 - analysis third task can be something
1764:38 - like text
1764:43 - uh word
1764:45 - completion I'm writing some
1764:48 - task fourth task is basically like text
1764:53 - translation so all these things it will
1764:55 - be able to do it all this task this
1764:59 - model will be capable to do it but what
1765:02 - is our maining when we make sure that we
1765:05 - have a generative AI our expectation is
1765:09 - basically to create a model which will
1765:12 - be able to do chat and
1765:15 - conversation right this is what is our
1765:17 - main
1765:18 - name right but what we have achieved we
1765:22 - have achieved this right by using this
1765:24 - technique we have achieved this but what
1765:27 - is our goal our goal is to achieve this
1765:31 - right this is my goal so that is the
1765:34 - reason we just don't stop in stage one
1765:38 - we go to next stage that is stage two
1765:42 - now in stage two see stage one it is
1765:44 - very much simple we have used amount of
1765:46 - data we make sure that we do that
1765:48 - labeling whatever is required we train
1765:50 - it with the Transformer we create a base
1765:53 - Transformer model this base Transformer
1765:55 - model is able to do this thing but it is
1765:58 - not able to do this but this is our goal
1766:02 - goal of generative AI is this one right
1766:04 - this is what is our main aim goal of
1766:07 - generative AI right this is what a
1766:09 - generative AI does agree
1766:13 - everyone this is what generative AI does
1766:16 - and this is what is my goal agree or not
1766:18 - everybody do you agree if you AG agree
1766:21 - please do make sure that you hit a
1766:22 - thumbs up okay now to make a generative
1766:25 - AI on top of this I need to do some more
1766:27 - thing and that is where I go to my stage
1766:30 - two so this second step is basically
1766:34 - my stage
1766:37 - two what exactly stage two now what
1766:41 - exactly stage two stage two I've already
1766:43 - told you it is nothing but from the
1766:45 - research paper also I've told you it is
1766:47 - nothing but it is basically super
1766:52 - supervised fine tuning which we also say
1766:55 - it as
1766:58 - sft now what exactly supervised fine
1767:01 - tuning what exactly this is this is the
1767:05 - second round now in supervis fine tuning
1767:08 - what happens now see this is the most
1767:11 - important step
1767:14 - okay we require humans in this
1767:19 - step
1767:23 - humans now in human what we
1767:26 - do we create request we make some set of
1767:31 - people sit over here so this will be my
1767:33 - human
1767:35 - agent this human agent will send some
1767:38 - request just like in a chat bot how we
1767:41 - send it and based on this
1767:45 - request based on this
1767:48 - request we generate an idle response and
1767:52 - this idle response is given by another
1767:54 - human
1767:56 - agent it is just like a chat
1767:59 - conversation let's say I have I have
1768:02 - I've set I have made one person sit over
1768:05 - here one person sit over here when this
1768:07 - person asks a question this person will
1768:08 - answer the
1768:10 - question then similarly next request
1768:12 - will be created then next response will
1768:16 - be
1768:17 - created then next request will be
1768:20 - created then next response will be
1768:22 - created so what is basically happening
1768:25 - this human agent is basically giving the
1768:29 - request this human agent is basically
1768:31 - giving the
1768:33 - response right idle response when I say
1768:35 - idle basically means whatever is the
1768:37 - question based on the question we are
1768:39 - giving some kind of answers this way we
1768:42 - will set up our
1768:45 - sft training data
1768:49 - set so this will be a label data set now
1768:52 - this data set has what this is my
1768:56 - request this is my
1768:59 - response this is my
1769:01 - request this is my
1769:04 - response this is my
1769:06 - request this is my
1769:09 - response this is my complete data set
1769:12 - yes or no this is my data set that we
1769:15 - are going to create from this
1769:17 - process request and response request to
1769:20 - response request and response whatever
1769:23 - these human beings have had a
1769:24 - conversation with right now we going to
1769:28 - take this data set and further send this
1769:32 - data set to
1769:34 - our base Transformer
1769:41 - model
1769:42 - base Transformer model along with this
1769:46 - we will do some fine tuning or we'll use
1769:49 - a optimizer let's say we have using Adam
1769:52 - W Optimizer this Optimizer was done is
1769:54 - in the Llama right in the Llama itself
1769:58 - right and then
1770:00 - finally I get a
1770:03 - sft Transformer
1770:09 - model why Optimizer is used to reduce
1770:12 - the loss this is an Optimizer right this
1770:15 - is specifically an
1770:18 - Optimizer okay
1770:21 - everybody clear so this is the step that
1770:24 - is basically happening in the second
1770:26 - one sft is done by real human being
1770:29 - human
1770:30 - agents right and that is how things are
1770:33 - going ahead right and this way you are
1770:36 - able to create your own data so this
1770:38 - will basically be my data or labeled
1770:41 - data during the sft
1770:46 - process
1770:47 - okay and the same data will be used to
1770:50 - train your base Transformer model after
1770:53 - training you will basically create a saf
1770:56 - Transformer model okay now what will
1770:59 - happen still this model you'll be
1771:01 - thinking okay it'll be able to give me
1771:02 - more accurate result but still this
1771:05 - model will be facing hallucination it
1771:08 - may not give you good correct accuracy
1771:11 - because there may be also some kind of
1771:12 - request and response which this model
1771:14 - may have never seen
1771:15 - it okay so for that case what we need to
1771:19 - do we need to probably go with our next
1771:22 - step or stage three and that stage three
1771:25 - is specifically called
1771:29 - as where we will be using
1771:32 - reinforcement okay and that step is
1771:35 - basically stage three in the stage three
1771:38 - we
1771:41 - use
1771:46 - reinforcement
1771:49 - learning
1771:54 - through human
1771:57 - feedback because we also need to do
1772:00 - human feedback and without this
1772:02 - reinforcement learning this model is
1772:06 - probably it will face hallucination it
1772:08 - will make give you rubbish answer and
1772:10 - all okay now what happens in
1772:12 - reinforcement learning let's discuss
1772:14 - about this okay let's say this is my sft
1772:17 - train model Okay so so this is my
1772:21 - sft Transformer
1772:28 - model now in this sft Transformer model
1772:31 - what happens after training whenever a
1772:35 - human gives any kind of respon
1772:38 - request whether a human gives a request
1772:41 - after the model is trained we can get a
1772:43 - response
1772:45 - from from whom from
1772:48 - sft ch bot right we'll be able to get
1772:52 - some kind of response the SF Transformer
1772:55 - model okay now what we are going to do
1773:00 - now based on this request I may also get
1773:02 - multiple response now that is where
1773:05 - you'll be understanding reinforcement
1773:07 - okay let's say this sft chatbot we will
1773:11 - try to record its multiple response
1773:13 - let's say this is response a this is
1773:16 - response B this is response C
1773:21 - this is response
1773:24 - D and this is multiple response like
1773:27 - this okay now once you probably get this
1773:31 - response so let's say this is my
1773:32 - response a as said this is my response b
1773:35 - as said this is my response C this is my
1773:38 - response d right multiple responses
1773:42 - there
1773:44 - okay now for this
1773:47 - response a human being will do some
1773:51 - ranking and this is where reinforcement
1773:53 - is applied
1773:56 - ranking okay now this ranking of this
1774:01 - response like for this request this
1774:03 - should be given first rank that
1774:05 - basically mean this should be the idle
1774:06 - response this should be the second idle
1774:09 - response this should be the third idle
1774:11 - response like that a ranking is given by
1774:14 - another user
1774:17 - agent another user
1774:21 - agent okay see this step by step First
1774:25 - Step then Second Step then ranking is
1774:27 - done okay and what this specific ranking
1774:31 - is basically going to do just imagine
1774:33 - this okay ranking is just going to say
1774:36 - that my response a rank should be
1774:40 - greater than response B rank should be
1774:44 - greater than response D let's say d is
1774:47 - greater than C okay
1774:50 - so this ranking will get applied okay
1774:54 - and once we
1774:55 - specifically assign this kind of ranks
1774:58 - these are my ranked responses what we
1775:00 - can do we can train after this what this
1775:04 - is done is that we train a fully
1775:07 - connected neural
1775:11 - network fully connected neural network
1775:14 - in this neural network let's say these
1775:15 - are my nodes like this and this is my
1775:19 - output
1775:26 - like let's say like this so here my
1775:30 - inputs will be my conversation
1775:36 - history my conversation
1775:38 - history and my outputs the real outputs
1775:41 - are my ranks ranks
1775:45 - responses so based on this I will be
1775:48 - training my entire neural network and
1775:52 - this model is basically called as reward
1775:56 - model okay so in this step in
1776:00 - reinforcement what are specific things
1776:01 - we are doing we creating an SF
1776:04 - Transformer model based on multiple
1776:06 - responses we are applying reinforcement
1776:08 - where we are giving a human feedback so
1776:10 - here in short we are giving a human
1776:16 - feedback human feedback based on this
1776:19 - human feedback Fe back we will be
1776:21 - specifically getting which response
1776:22 - should be greater than the other
1776:23 - response we assign a rank and then we
1776:26 - create a fully connected neural network
1776:28 - with conversation history and ranks so
1776:31 - that based on this ranks we will be able
1776:34 - to provide rewards rewards to what this
1776:37 - Transformer
1776:39 - model I hope you're able to
1776:43 - understand
1776:45 - yes yes yes
1776:48 - everyone yes if you're able to
1776:51 - understand hit like please make sure
1776:53 - this is the most important thing in
1776:55 - generative AI right of creating this
1776:58 - entire llm models right and trust me to
1777:03 - understand these things because after
1777:05 - understanding this reading research
1777:06 - paper will be very very much easy okay
1777:10 - and that is where my reward model is
1777:12 - basically created in my stage three
1777:18 - okay so this is the most important thing
1777:22 - okay I will use one image to show you
1777:25 - the next model okay and this is the most
1777:28 - important
1777:35 - one um just a second
1777:48 - everyone
1777:54 - just a second everybody I think my
1777:57 - system is hanged
1778:02 - okay okay till then let me go ahead and
1778:04 - continue it
1778:15 - okay so finally after we have this
1778:19 - entire reward model and all okay we also
1778:23 - make sure that we create some kind of
1778:29 - models see at the end of the day once we
1778:31 - create all these things that basically
1778:33 - means what happen this three steps helps
1778:36 - us to create any llm model as such what
1778:38 - is the difference thing that is
1778:40 - basically going to happen right your
1778:43 - training data needs to be created right
1778:48 - the more the training data the more
1778:50 - better thing is second thing is the
1778:52 - reinforcement
1778:57 - learning reinforcement
1779:00 - learning
1779:02 - with human
1779:06 - feedback right this is also important
1779:10 - coming for the third thing the fine
1779:12 - tuning
1779:14 - part right the fine tuning part
1779:17 - specifically with respect to sft
1779:20 - what kind of
1779:22 - request and
1779:24 - response the human being are taking and
1779:28 - reinforcement the most important thing
1779:30 - is that how the ranking is done right
1779:34 - these are the main things and obviously
1779:36 - the architecture that we are
1779:37 - specifically going to use over here is
1779:39 - nothing but
1779:42 - Transformers okay so this is very much
1779:45 - important with respect to all the things
1779:47 - that we have discussed how was was the
1779:51 - understanding scenario guys with respect
1779:52 - to all these things have you understood
1779:54 - or not please do let me
1779:57 - know please do let me know are you able
1780:01 - to understand everything or not with
1780:02 - respect to whatever things we have
1780:04 - actually done or discussed over here
1780:08 - just let me know
1780:16 - guys got it got it yes yes yes yes yes
1780:20 - yes so everyone is giving me a right
1780:22 - answers over
1780:24 - here great great great great great great
1780:27 - now going forward what you really need
1780:30 - to focus on okay what you really need to
1780:33 - focus on see as a person who is
1780:37 - interested to get into generative AI
1780:40 - okay what are things you should
1780:41 - basically focus on the road map if you
1780:44 - really want to start the road map to
1780:47 - generative AI
1780:53 - road map
1780:56 - to generative
1781:00 - AI okay now in order to understand the
1781:04 - road map of a generative AI or how you
1781:07 - can also start the
1781:10 - prerequisites prerequisites what are the
1781:13 - prerequisite obviously one programming
1781:15 - language
1781:18 - okay one is python okay second you
1781:24 - really need to be strong at NLP so when
1781:27 - I say NLP machine learning concepts with
1781:30 - respect to
1781:31 - NLP right where you learn different
1781:34 - texes of embedding techniques let's say
1781:37 - what is embedding here you specifically
1781:39 - learn how you can convert a text into
1781:42 - vectors right now converting a text into
1781:45 - vectors has many things in mind okay so
1781:48 - guys there is also one St page uh that
1781:50 - is after this okay probably I will
1781:53 - explain you that because my another
1781:54 - screen have got stuck okay so what I'm
1781:56 - actually going to do is that probably
1781:58 - one more thing is something called as
1782:00 - proximal policy optimization I will
1782:03 - create a a live video on this next week
1782:07 - we basically say this as
1782:10 - prox let me just write it down for you
1782:14 - after creating the reward model we
1782:17 - basically use this in
1782:21 - proximal policy optimization we will
1782:24 - discuss about this for this I will come
1782:26 - next week live or probably in whatever
1782:29 - next live session we will discuss about
1782:31 - this entire thing this is an another
1782:33 - important algorithm altogether okay but
1782:36 - after this our final llm model will be
1782:39 - cleared and this is super important
1782:41 - because this will assign rewards this is
1782:44 - responsible for assigning rewards based
1782:46 - on various responses that we are giving
1782:50 - or my llm model will give okay so uh I
1782:54 - will probably cover this because this is
1782:57 - another long topic uh in the upcoming
1782:59 - classes we'll see any live sessions
1783:01 - we'll discuss about this also okay now
1783:04 - let's go ahead and understand the NLP
1783:05 - now as as I said that right the
1783:07 - prerequisite is that in machine learning
1783:09 - you need to understand how a words are
1783:12 - converted into vectors and they are
1783:14 - multiple techniques uh I hope you have
1783:16 - heard about bag of words you have heard
1783:18 - about TF IDF you have heard about
1783:22 - embeddings you have heard about uh word
1783:25 - to right word to V so all these
1783:28 - techniques are specifically used in
1783:31 - converting uh the words into vectors so
1783:35 - that the machine when it is trained
1783:37 - based on input and output it'll be able
1783:38 - to understand the entire context so
1783:40 - basics of machine learning I still say
1783:42 - this as basics of machine learning you
1783:46 - really need to have a good amount of
1783:48 - idea with some of the algor knowledge
1783:49 - and all third thing when I say you
1783:52 - really need to understand deep learning
1783:54 - techniques
1783:56 - also in deep
1783:58 - learning you need to understand about uh
1784:02 - Ann hown Works what are
1784:05 - optimizers what is loss function what is
1784:09 - loss
1784:10 - function what is uh let's say what is uh
1784:16 - overfitting right uh what is activation
1784:19 - for
1784:20 - functions what is multi-layer neural
1784:22 - network what is forward propagation
1784:24 - backward propagation so many different
1784:26 - topics are there so these are again the
1784:28 - basic building
1784:31 - block the basic building
1784:35 - blocks okay so the basic building blocks
1784:39 - with respect to all these particular
1784:40 - topics is super important so please make
1784:42 - sure that you have to be really good at
1784:45 - this I'm not saying that someone cannot
1784:47 - directly jump to generative a
1784:49 - they can if you are a developer if you
1784:51 - are developing some kind of application
1784:53 - without knowing all these things any one
1784:55 - programming knowledge you can directly
1784:56 - go ahead and probably use the API
1784:58 - consume it build application but these
1785:00 - are for those people who specifically
1785:02 - wants to work as a data scientist as a
1785:05 - generative AI engineers in the companies
1785:08 - right for them they really need to
1785:10 - follow this without this basic knowledge
1785:12 - they cannot probably learn generative AI
1785:14 - why I'll tell you if you directly jump
1785:16 - to generative AI you may be able to
1785:20 - develop application but when you go
1785:21 - ahead and with the interviews there
1785:23 - people are going to ask you basic things
1785:26 - right basic things over here and if you
1785:28 - are not able to answer that they'll not
1785:29 - directly start with generative AI first
1785:31 - of all they'll see how good your basic
1785:33 - skills is if you good at something then
1785:36 - only they'll further go ahead and ask
1785:37 - some more questions right so it is super
1785:40 - important to understand you cannot
1785:41 - directly jump it jump into things okay
1785:44 - so the fourth topic that you will
1785:46 - probably be seeing after deep learning
1785:48 - uh is advaned deep learning techniques
1785:50 - so here we focus on on RNN lstm
1785:55 - RNN Gru so all these neural networks you
1785:58 - really need to understand Gru uh encoder
1786:02 - decoder encoder decoder Transformers as
1786:06 - I said Transformer attention is all you
1786:08 - need all these architectures you should
1786:10 - be able to understand because in the
1786:12 - interview again they are going to ask
1786:13 - you this they'll tell you that design or
1786:15 - write a code on a basic
1786:17 - Transformer okay and they'll tell see
1786:19 - how things are basically done whether
1786:21 - you are able to write it or not all
1786:23 - those information will be basically
1786:25 - asked in the interviews because
1786:27 - everything with respect to generative AI
1786:29 - is built on top of Transformer right now
1786:33 - the fourth Thing Once you this I usually
1786:37 - consider as a prerequisite to get into
1786:39 - generative AI right it's okay it's okay
1786:42 - if you have some good some basic
1786:44 - knowledge on all these things right but
1786:47 - it is always good to have this so that
1786:49 - you will be having an indepth knowledge
1786:52 - in-depth knowledge of working in
1786:53 - generative AI okay then coming on to the
1786:55 - fifth part right here where I'm going to
1786:58 - focus on different different libraries
1787:00 - open AI open AI has come up with this
1787:03 - gpts model right GPT 3.5 GPT
1787:07 - 4.0 GPT uh 4 Turbo all these specific
1787:11 - models you can use to develop
1787:14 - applications llm applications not only
1787:17 - this you can also use other Frameworks
1787:19 - like Lang chain Lang chain is quite
1787:20 - popular right now because many people
1787:22 - are using this to create llm application
1787:25 - and the best thing about Lang chain is
1787:26 - that it has created this framework in
1787:28 - such a way that you can use paid apis
1787:30 - also you can use open source uh open
1787:33 - source llm models also and you can
1787:35 - perform any task that is basically
1787:36 - required along with prompt engineering
1787:39 - there is one more framework which is
1787:40 - called as Lama
1787:42 - index so Lama index is also a very good
1787:45 - framework and this is specifically used
1787:47 - for quering purpose
1787:50 - quering vectors right so this also is
1787:53 - very important framework right now and
1787:56 - as you all know right now Google gini
1787:58 - gini has basically come up with this
1788:00 - amazing model Google has come up with
1788:01 - this and right now jini Pro is
1788:04 - available so you can also use gini Pro
1788:06 - it has its own libraries and you can
1788:08 - specifically use for performing any llm
1788:11 - applications right now we don't have the
1788:13 - documentation of how fine tuning is done
1788:15 - but in some days that too will also come
1788:19 - right now in all these libraries all
1788:21 - this open source open source as I said
1788:23 - right open source models llm
1788:29 - models in this open source models also
1788:31 - you can also do fine tuning but again at
1788:34 - the end of the day for fine-tuning you
1788:36 - really need to have huge gpus it's see
1788:39 - open source models are readily available
1788:40 - you can directly download it you can
1788:42 - quantise it you can make it in a form
1788:44 - where it will be of less size you can
1788:46 - directly find tuning with your own data
1788:48 - set for that you require hug gpus for
1788:50 - inferencing purpose also you require
1788:53 - good machines in short right so in short
1788:57 - if you are good at all these things
1788:59 - trust me you able to work with
1789:00 - generative AI but again it is a process
1789:03 - where you have to probably learn all
1789:05 - these things okay in the future we'll
1789:07 - also try to uh I'll try to take a
1789:10 - session where we'll discuss about all
1789:11 - these prerequisites in depth and we'll
1789:13 - try to understand all the mathematical
1789:15 - intuition okay CNN is not at all
1789:17 - required see CNN is required if you are
1789:20 - interested in large image
1789:22 - models but here most of the use cases
1789:26 - that are probably coming up are on large
1789:28 - language models right but if anybody's
1789:30 - interested in this you can learn about
1789:32 - CNN if you want but I feel uh if you are
1789:36 - interested in Tech side llm you have to
1789:38 - focus on all these things right so guys
1789:41 - how was the session all together good
1789:45 - enough good or
1789:47 - not
1789:59 - oh
1790:15 - great just a second I will take up
1790:18 - questions
1790:19 - my screen has got
1790:40 - stuck okay so let's take some questions
1790:43 - till
1790:44 - then uh yeah every week okay great
1790:50 - you are able to hear me out so please uh
1790:52 - let me know about more
1790:55 - things how was the session if you liked
1790:57 - it please make sure that you like it
1790:59 - guys uh it takes a lot of effort to keep
1791:01 - this kind of sessions and uh we are
1791:03 - planning for every Friday this sessions
1791:05 - so it'll be amazing to teach and all
1791:08 - it'll be
1791:09 - great okay got something new to learn
1791:13 - great amazing sir salute valuable great
1791:17 - great great great I I hope everybody's
1791:19 - happy so uh please make sure that you
1791:22 - share it with your friends in all the
1791:25 - platforms that is specifically required
1791:28 - because trust me at the end of the
1791:30 - day these all are free content our main
1791:33 - aim in in neuron is to democratize AI
1791:35 - education
1791:41 - we so at the end of the day please try
1791:43 - to learn in that specific way try to
1791:46 - understand these techniques and then try
1791:47 - to build application
1791:49 - okay can a non-developer also learn this
1791:51 - yes anyone can learn this anyone okay
1791:54 - anyone because it is very much simple
1791:56 - with respect to
1792:04 - coding
1792:12 - okay what is the boundary of sft and
1792:15 - interface for quering is only
1792:17 - sampling
1792:19 - so tell us about the course you're
1792:21 - launching on generative AI on in neuron
1792:24 - so guys uh we are launching generative
1792:26 - AI course it is probably from next month
1792:29 - you can find all the details in the
1792:31 - description of this particular video or
1792:33 - visit iron. page okay there generative
1792:36 - AI course is basically coming up
1792:40 - uh So based on that uh you'll be able to
1792:43 - see to it and check it out okay check it
1792:46 - out in the description of this
1792:47 - particular video so video recording
1792:49 - today's class yeah it'll be available in
1792:50 - YouTube it will be available in the
1792:52 - dashboard that is given in the
1792:56 - description
1793:14 - okay okay perfect so hit like
1793:17 - guys
1793:20 - any more questions any
1793:43 - queries hi sir can you tell me about the
1793:47 - differences great sessions are really
1793:49 - and really appreciate so guys just give
1793:52 - me a 5 minutes break and then we will be
1793:54 - taking up the questions my system is
1793:56 - hanged so I will restart the system till
1793:58 - then okay so just give me another 5
1794:01 - minutes break uh we will go ahead and
1794:02 - take a five minutes break so Prashant uh
1794:05 - you can just uh stop sharing if possible
1794:08 - I will just take five minutes break
1794:11 - and okay and I will be talking about
1794:14 - that thank
1794:17 - you
1802:03 - [Music]
1802:20 - [Music]
1802:33 - [Music]
1802:46 - n
1803:16 - e
1803:46 - e
1804:16 - e
1804:30 - okay am I
1804:35 - audible am I
1804:37 - audible hello
1804:42 - hello okay 2 minutes 2 minutes 2
1804:46 - minutes okay audible right perfect
1804:53 - sorry
1804:56 - okay so let's take so first of all
1804:59 - people were saying about what is the
1805:01 - differences between generative Ai and
1805:02 - gini pro
1805:05 - okay so generative AI as I said guys
1805:09 - large language models are a part of
1805:11 - generative AI similarly large image
1805:13 - models are also part of generative AI
1805:16 - okay so generative AI is already a
1805:19 - subfield of deep learning our main aim
1805:22 - is to create new content based on the
1805:24 - data that we have trained right so we
1805:26 - have all these kind of llm models
1805:36 - okay okay let's let's take this
1805:39 - questions so great session sir really
1805:41 - helpful and really appreciate your
1805:43 - initiative of democratizing gener uh
1805:46 - generative AI learning thank thank
1805:49 - you so going forward all ml or DL
1805:53 - techniques will not be in use we will
1805:54 - focus more on llm plus
1805:57 - finetuning yes it depends on companies
1805:59 - to companies right so if there is a
1806:02 - company where we are focusing on
1806:04 - creating use cases quickly and they
1806:06 - don't have that cost issue they can
1806:08 - directly use this because see at the end
1806:10 - of the day if you're also creating any
1806:11 - application with respect to machine
1806:12 - learning or deep learning you have to do
1806:13 - everything from scratch
1806:16 - yeah
1806:22 - okay let's take more
1806:26 - question so how much large data set of
1806:29 - request and response is created by human
1806:30 - agents under sft as manually to create
1806:32 - such large data set is impossible yeah
1806:35 - if they put 100 people every day that
1806:37 - many task is there then just imagine how
1806:39 - much data we'll be able to create right
1806:41 - huge amount of data you'll be able to
1806:43 - create okay what all task we will
1806:46 - perform from J Pro everything text
1806:48 - summarization Q&A document text uh
1806:51 - document Q&A embeddings everything is
1806:54 - possible right so one session I also
1806:57 - I'll plan for gmin pro
1806:59 - okay why focuses more on llm in gen AI
1807:03 - because you're able to do task you're
1807:05 - able to create solve business use cases
1807:06 - in a much more accurate way right so it
1807:10 - is very
1807:15 - good how can gender a used for solving
1807:18 - real life business problem there are lot
1807:20 - of real world business problem that is
1807:22 - specifically required by companies from
1807:24 - chatbot to text summarization to
1807:26 - document classification to everywhere it
1807:29 - is specifically used uh in in inur also
1807:32 - we are trying to automate the entire
1807:33 - support system along with human
1807:36 - intervention both we are trying to
1807:38 - include and over there also we will be
1807:39 - using llm models too
1807:42 - right for assignment generation we are
1807:44 - planning to use llm models many as such
1807:46 - so okay so in uron also we have built
1807:49 - our own models itself
1807:56 - right so can you show how to finetune a
1807:59 - GPT model using API yes it is possible
1808:02 - but uh again we need to make sure that
1808:04 - we have some good configuration
1808:07 - configurable system uh if you want to do
1808:09 - it with open source llm if you want to
1808:11 - go with paid that also we'll try to do
1808:13 - it in the upcoming
1808:15 - sessions okay
1808:22 - okay tell us more about generative AI so
1808:25 - here is my page I'm going to share my
1808:27 - page over here ion website so if you are
1808:31 - interested you can go ahead
1808:34 - and so I'm going to share my
1808:37 - screen
1808:40 - okay so I hope everybody is able to see
1808:42 - my screen please uh give me a
1808:45 - confirmation
1808:50 - can you see my
1808:52 - screen give please give me a
1808:54 - confirmation so I will just try to
1808:55 - answer this specific
1809:00 - question okay so here you'll be able to
1809:03 - see as soon as you go to the homepage
1809:04 - the first course that we are launching
1809:06 - on generative AI mastering generative AI
1809:08 - open AI Lang chain and llama index also
1809:11 - from 20 January 2024 okay this will be a
1809:16 - 3 to 4 4 months course altogether one
1809:19 - year dashboard access is there this is
1809:20 - for everyone out there whether you are a
1809:22 - college student working professional
1809:24 - along with this we will also be
1809:26 - providing you access to the Virtual Lab
1809:28 - of uron okay here what all things we are
1809:31 - going to learn we are going to master
1809:32 - everything that is related to open Lang
1809:34 - chain and Lama index okay and
1809:36 - specifically developing application end
1809:39 - to end till deployment okay we will show
1809:42 - you multiple things over there now when
1809:45 - this batch is starting 20th Jan 2024 the
1809:49 - language is English 5 months duration 10
1809:51 - to 1 p.m. Saturday Sunday class timing
1809:53 - it will be live instructor lead okay uh
1809:56 - you have onee dashboard access
1809:58 - assessment in all modules the reason why
1810:00 - we are putting one year dashboard access
1810:01 - is that because this content will get
1810:04 - upgraded every six months I guess right
1810:07 - there are a lot of upgrades in the field
1810:08 - of generative AI right so that is the
1810:11 - reason is no use of giving you lifetime
1810:12 - or anything as such okay so neural laab
1810:15 - access is there dedicated community
1810:17 - support these all things are there
1810:19 - mentors will be myself sudhansu s Savita
1810:22 - and bppi right so some portion I will be
1810:26 - taking some portion Sanu will be taking
1810:28 - some portion s Savita will be taking
1810:29 - some portion bmed B will be taking okay
1810:33 - and you have already seen they have
1810:35 - they're doing the live sessions on
1810:36 - generative AI in the in the in in in the
1810:39 - YouTube channel of ion itself okay so
1810:42 - you can definitely check it out over
1810:43 - there then if you have any queries you
1810:46 - can talk to a counselor or you can also
1810:48 - contact the ivr number that is given
1810:50 - over here right in the website itself so
1810:52 - if uh any question that you have
1810:54 - regarding counseling anything and this
1810:56 - is the entire syllabus we are going to
1810:58 - start from Basics what road map I have
1811:01 - shown you today based on that road map
1811:04 - only we are going to start see bag of
1811:05 - words TF IDF word to F test engrs Elmo
1811:09 - bird based right then large language
1811:12 - model what is BD GPT T5 Megatron right
1811:16 - GPT 33 3.5 how chat GPT train
1811:19 - introduction to chat GPT 4 right and
1811:21 - then we are going to probably learn
1811:23 - about hugging pH we are going to see
1811:25 - different different models open source
1811:26 - then we are going to talk about llm
1811:28 - power application we're going to create
1811:29 - end to end projects then we are going to
1811:31 - use open AI this this this all every
1811:34 - everything that is available in open aai
1811:36 - because many companies are also using it
1811:38 - then we are also going to cover prompt
1811:39 - engineering Lang chain Lang chain
1811:42 - completely L chain in depth we'll try to
1811:44 - complete then we will also be completing
1811:46 - l Lama index all these
1811:48 - Frameworks right so everything will be
1811:50 - covered up and finally you'll also have
1811:52 - lot of end to end projects in every
1811:54 - section lot of endtoend projects is
1811:55 - there and these all projects are with
1811:57 - respect to
1811:58 - deployment so all these things are there
1812:00 - you can probably check it out in the
1812:02 - cabus okay uh all the information will
1812:05 - be given in the description of this
1812:06 - particular video as I said if you have
1812:08 - any queries talk to the counselor okay
1812:10 - they'll help you
1812:13 - out what Hardware is required to learn J
1812:16 - no need of any hardware we will be in
1812:19 - uron lab itself you'll be able to
1812:21 - execute all your code you'll be able to
1812:23 - do it if anything is required we'll let
1812:24 - you know in the latest stages okay but
1812:26 - whatever is in the flea platform
1812:28 - available in uron Virtual Lab and all
1812:31 - you'll be able to do this so please tell
1812:33 - is there any prerequisite yeah Python
1812:35 - programming language so for that also we
1812:37 - are giving you pre-recorded videos so
1812:39 - python you should know only python you
1812:41 - should know remaining all is
1812:45 - fine
1812:50 - Community
1812:53 - Edition difference please uh Community
1812:57 - session is only up to some level okay
1812:59 - you can probably say 100% of what we are
1813:02 - teaching over here it is hardly 10 to
1813:04 - 15% okay will we require opening API key
1813:08 - yes we will show you a way how to do
1813:10 - that okay um but yeah at the end of the
1813:13 - day if you want to do fine tuning and
1813:14 - all you'll be requiring open API ke h
1813:19 - so do you have projects Hands-On course
1813:20 - for machine learning and data science so
1813:22 - again I'll let me share my screen for
1813:23 - that also we have launched it so let me
1813:27 - share my
1813:32 - screen so for project Hands-On course uh
1813:36 - if you probably go over here we have
1813:38 - also launched this one which is called
1813:40 - as production ready data science project
1813:43 - so if you click over here production
1813:45 - ready data science project this is a one
1813:48 - month course where we are solving end to
1813:50 - end five projects five five and it
1813:54 - includes machine learning deep learning
1813:57 - natural language processing and
1813:58 - generative AI so this is completely end
1814:01 - to endend and this is with
1814:03 - mlops machine learning operations right
1814:06 - all the tools the timing again this is
1814:08 - from 27 Jan the timing is 88 to 11:00
1814:11 - p.m. Monday Wednesday Friday so in one
1814:14 - week we will be completing one project
1814:16 - okay three days and it will be live all
1814:20 - the sessions will be live it is live
1814:22 - instructor lead so again you can go to
1814:24 - ion. a page check it out if you want to
1814:27 - talk to the counselor talk to them
1814:29 - mentors again all these things s Savita
1814:32 - bapi will be the main mentors over here
1814:33 - will will be taking this entire session
1814:36 - Monday Wednesday Friday will be the
1814:37 - session 8 to 11: at night now here what
1814:40 - we have done is that best thing we have
1814:42 - included mlops everything that is
1814:44 - basically required right mops mlops
1814:47 - mlops right let it be so what all things
1814:49 - you'll be covering in this open a AWS
1814:51 - GitHub Docker Azure lanin Jenkins along
1814:54 - with this we will be seeing Circle CI
1814:56 - we'll be seeing uh GitHub action cicd
1814:59 - pipeline Dockers kubernetes everything
1815:03 - that is required is covered in this so
1815:04 - it is a complete mlops syllabus right
1815:08 - DVC dockerization AWS Jenkin cicd
1815:11 - pipeline so every project that you'll be
1815:13 - seeing right you will be seeing over
1815:15 - here we are using some some of the other
1815:16 - things let's say Industry Safety here
1815:19 - also we'll be doing dockerization AWS
1815:21 - GitHub action cicd right and if I go
1815:23 - with name entity here you'll be seeing
1815:25 - DVC dockerization Azure Circle cicd so
1815:29 - everything will be covered with respect
1815:30 - to that and then I've also we have also
1815:33 - included uh the generative AI project
1815:39 - okay
1815:40 - great so I'm stopping and anything any
1815:43 - info that you require you can probably
1815:45 - go ahead and ask ask in the
1815:48 - uh just contact the ivr number over
1815:50 - there
1815:54 - okay okay perfect so how was the session
1815:57 - all together did you like
1816:02 - it so do we need to do projects on mldl
1816:05 - to get job in gen aai yes obviously
1816:09 - mlops mlops mlops see the generative AI
1816:12 - projects also that we are going to do in
1816:13 - gen AI course there we are going to
1816:15 - include lot of mlop activities also it's
1816:18 - more about creating
1816:20 - applications
1816:23 - okay okay
1816:31 - perfect course fees and all you can find
1816:33 - out in the course page itself
1816:36 - okay perfect guys so thank you this was
1816:40 - it I think we have completed the 2hour
1816:42 - session uh from coming Monday we are
1816:45 - also coming up with the mlops community
1816:48 - series from coming Monday so please make
1816:51 - sure that you subscribe the channel
1816:52 - press the Bell notification icon that is
1816:54 - super important um we will be starting
1816:57 - from next week itself okay you can
1816:59 - probably check it out uh all the
1817:01 - reminders everything will be found out
1817:03 - in the channel itself there will be
1817:04 - dashboard exess materials everything
1817:06 - that you actually require so thank you
1817:09 - uh this was it from my side if you like
1817:12 - the video please make sure that you hit
1817:13 - like subscribe share with all your
1817:15 - friends
1817:16 - this was it from my side okay and I will
1817:20 - see you all in next week Friday session
1817:22 - we will be discussing more things but
1817:24 - again we have lot many things that are
1817:26 - coming from Inon itself we'll be having
1817:28 - mlops entire Community session and it is
1817:31 - from uh next week uh Tuesday is going to
1817:34 - probably start and we'll be discussing
1817:36 - about all those things how an end to-
1817:38 - end project is basically created Let It
1817:39 - Be an LP project machine learning geni
1817:42 - project how mlops can be used and many
1817:44 - more things so thank you uh have a great
1817:48 - day and keep on rocking if you like this
1817:51 - session please do hit like and yes I
1817:52 - will see you all in the next session so
1817:54 - thank you guys have a great day bye-bye
1817:56 - take care and keep on rocking thank you
1818:00 - bye

Cleaned transcript:

this massive course about foundational generative AI was originally recorded live we've put it all together into this one video this course offers insights into generative models and different Frameworks investigating the production of text and visual material produced by AI the course is taught by three experienced instructors okay I think uh we can start with the session so hello everyone good afternoon to all uh this is the very first session for the uh generative AI uh from today onwards we are going to start with a community session of generative AI so uh yes in today's session we'll be talking about that what all thing we are going to discuss uh throughout the sessions and uh this session actually it will be happening for uh upcoming two weeks and uh it will be on the same time I'm going to take the session from uh 300 p.m. onwards uh maybe 3 to 5 so here in this uh committee session we'll try to to discuss many more thing regarding the generative AI so we'll start from very basic and we'll go to the advanc there we'll try to develop different different type of applications as well uh first of all I will start with the theory uh so there I will uh discuss about the theoretical uh uh like stuff and all that what is generative AI what is a llm and after that I will uh like go with the open a Lang and don't worry each and everything I will discuss in a very detailed way and and uh I will show you the dashboard as well where all the lectures and all will be uploaded and apart from that I will uh show you the uh like uh where you can find out all the videos quizzes and uh assignments and all because along with the session I will give you the different different assignment different different quizzes so at least you can practice with the concepts got it guys yes or no so are you excited please do let me know in the chat if you are excited then great so I think we going to start and uh so first of all guys what I will uh do I will give you the uh the detail introduction of the course that what all think we are going to discuss in this committee session and uh here basically this is our dashboard so let me share this link with all of you so uh don't worry my team will share the link of this dashboard in the chat so from there what you can do you can enroll it is completely free you no need to pay anything for this uh committee session and all the lectures and all the assignment and quizzes will be uploaded over here don't worry I will come to the curriculum also so here first of all let me show you the homepage uh this is the homepage guys uh this is the homepage of this dashboard and there uh uh like you can enroll in this particular dashboard and don't worry uh each and every video you will find out over the Inon YouTube channel as well so all the recorded video and all it will be available inside the Inon YouTube channel uh definitely this video is going to be record after the session so this video will be available inside the I YouTube channel as well as uh over the dashboard so here guys this is the dashboard I think you got a link of the dashboard so there you can enroll and then uh like you can start your journey of the generative AI so here guys uh me and buy both are going to take this particular session so there we are going to discuss in depth uh about the generative AI about the llm we'll try to discuss about a various application various recent model llm models and all uh we have so many things uh to discuss about the generative AI we have planned for the two weeks but uh maybe uh more than 2 weeks uh we'll try to uh take if we are not able to cover and like all the curriculum whatever we have defined whatever we have thought uh so definitely we'll be extending the date as well but yeah we will make sure that within 2 week whatever curriculum we have defined we'll try to complete it so here guys are me and uh buy so if you don't know about me guys so my name is Sun my name is s Savita I'm working in Aon from past three year and I have I'm having an expertise in data science uh I have explored U every aspect of the data science like machine learning deep learning and advanced deep learning like computer vision NLP I have worked with the mlops as well uh there I have designed a various applications and all got it so yeah uh you can search me about more over the LinkedIn uh there you will get uh you will you will get got my profile and you will uh like uh get each and everything in a detailed way so here guys uh what you need to do so first of all you need to enroll to this particular dashboard uh you no need to pay anything over here and if you are going to login after login what you need to do uh so uh you will be redirect redirecting to this uh particular dashboard and uh so let me show you the dashboard first of all this is the dashboard guys as of now there is no such videos and all uh definitely after the session we'll uh upload the videos and assignment and quizzes so definitely along with the sessions and all you can practice so this thing is clear to all of you yes or no have you enroll uh through this dashboard did you get this Dashboard please do confirm in the chat I'm waiting for your reply please do it guys great so I can see uh uh many people are saying yes so definitely now uh we can discuss about the curriculums and all so whatever thing we are going to discuss throughout this committee session first of all I will give you the detail uh like uh detail introduction of the uh syllabus uh what all topics we have uh we'll try to more focus on the re recent Trends I'm not going into the uh classical uh machine learning and the Deep learning basically so I will focus more Focus basically on the open Ai langen and all so don't worry I will give you the detail introduction of the syllabus uh that whatever thing we are going to discuss inside this committee session so the first thing what you need to do guys you need to enroll inside this dashboard and uh whatever like videos and all you will get uh you will like go through and basically you can watch it over here itself directly now let's discuss about the curriculum and all that what all thing we are going to discuss and uh for that basically I have created one PPT so let me show you that particular p PPT uh just a second so here is a PPT guys can you see this PPT yes or no please do confirm in the chat if it is visible to all of you great I think uh this uh PP is visible to all of you now guys uh we can discuss uh that uh what will be our uh like topics and all uh that what all thing basically we have to discuss throughout this committee session so here uh first of all I will start from the generative AI so there I will give you the detail overview of the generative AI that what is a generative AI uh why uh we should use a generative AI uh what all type of like application we can create and uh each and everything each and every every theoretical stuff we try to discuss regarding the generative Ai and after that after the generative AI I will come to this uh large language model so just a second let me open my uh pen as well so I can write it down um each and everything yeah so here guys uh we can uh I can write it down as well now so here the first thing basically first I'm going to start from the generative AI there uh definitely I'll will be talking about each and everything each and every aspect of the generative AI then after that I will come to this large language model there I will try to discuss this llms large language model in a very detailed way we'll try to see the complete history of the large language model that what is a large language model what types of model we have what was the classical model and uh what is a recent model okay so each and everything we'll try to discuss regarding this llms and after that after completing this uh theoretical part theoretical of this uh stuff and all regarding the generative AI regarding this llms I will come to this open AI open Ai and this lenen so there uh we'll try to discuss in a very detailed way that what is the open AI what is the open AI API and inside the open AI API we have a different different them right so in OPI openi itself you will find out a various model that like openi open has created a various model uh that different different version of the gpts okay so it is having some uh like a old model as well some legacies and all and some upcoming models so each and every model will try to discuss I will give you the walk through regarding those particular model and I will discuss about the python API python uh API uh that uh how you can uh use utilize those particular model by using the python getting my point and apart from that apart from the python API and all will try to discuss that uh like if we are going to be uh if we are going to use the Lenin right so how it is different from the open AI so at the first place I will give you the uh detailed differences between this open Ai and this lenen that how it is different to each other that why this Lenin is required then I will come to the Lenin and then again we'll try to create uh again basically we'll try to Define the lenen and all uh by using the python we'll try to uh use the lenen or different different like a component of the Lenin like memory chain agents and all and yes after that I will try to create one application okay so here uh basically we'll try to create one application and with that uh definitely we'll be able to justify the knowledge whatever actually uh we are going to learn regarding this llm open lenion by using uh that by creating that particular project and after that I will uh come to the advanced part Advanced part like uh Vector databases uh we'll try to discuss about a different different Vector databases and first of all we'll try to discuss the need of the vector database that why it is required what is the meaning of the embedding uh how we can uh like uh save the embedding how we can retrieve that and how this a vector database this a vector database plays an important role whenever we are going to create any application related to this llms okay so there we'll try to discuss about the vector databases and then I will come to the some open source model so uh first of all I will come to this uh llama uh and I will discuss about the Llama indexes what is the Llama index and we have a like couple of Open Source model which is a very very famous so we'll try to talk about those model as well like we have a llama to itself we have a falcon we have a bloom there are various model and we'll show You by using those model how you can create uh like a how you can create your end to and application uh you can solve any sort of a task just take a name don't worry I will give you the detail overview about the NLP and all that what all task does exist what all task basically we have what all task we can solve by using this llm each and everything we'll talk about and then finally we'll create one more end to endend project there we'll try to uh use the entire knowledge uh whatever we are going to be learn uh like this Vector databases different different open source model and a length CH open a llama indexes and finally we'll try to deploy that model by using the amops concept so did you uh like this syllabus yes or no please do let me know guys please do let me know in the chat if you like the syllabus yes or no the agenda is clear to all of you if you can write it down the chat I think uh that would be great great so I can see many yes in the chat and many people are saying yes they are able to get yes don't worry we'll give you the PPT and all each and everything will be there in a uh resource section so from there you can download this PP you can download this entire thing whatever I'm uh like I will be using throughout the session yes uh so fine I got a confirmation now uh the first thing uh many people are asking the prerequisite what will be the prerequisite if you are starting with this committee session so prerequisite wise uh if you have a basic knowledge of the Python if you have a basic knowledge of the Python if you know about the core python uh in a core python actually we have uh uh like a ifls for Loop and uh different different type of data structure and the knowledge of the database exception handling if you are uh if you know about the basic python the basics of python then definitely you can proceed with this go along with that if you have a like some basic knowledge about machine learning and deep learning so you will understand uh the concept basically whatever uh like we are going to teach you in a better manner in a better way because here I'm not going to talk about the classical uh ml or the basics of the deep learning like uh artificial NE Network CNN and all definitely I will give you the overview about the transfer learning fine tuning and all but here uh uh I won't talk about the neural network and this recurr neural network lstms and all so uh if you have a basic understanding of machine learning and uh deep learning so definitely you will understand the concept in a very well manner otherwise basic python knowledge is fine for creating application basic python knowledge is uh like fine okay so you no need to worry about it uh whatever thing actually I need to explain you definitely I will do that uh in the class itself and uh we'll do the live implementation I'm not going to show you any uh prewritten code and all uh definitely I will write it down each and everything in front of you only got it so prerequisite is clear so prerequisite nothing just a python or uh I can write it down over here basic knowledge basic knowledge of ML and DL if you know this much then definitely uh like uh you will be able to understand each and everything in a well manner great so yes we'll talk about the RG approaches and all each and everything diffusion model is there there are some recent model in l each and everything will talk about and you will be capable so uh let's say if you are working in your company or maybe you are trying to switch into the generative AI or maybe you are fresher in every uh case right so this community course will help you definitely if you if you are going to attend every session if you are going to learn along with me definitely you can build anything after learning all sort of a thing got it great so I think uh this uh introduction is clear to all of you now I already discussed about uh about the dashboard and all so uh I given you the walk through of the dashboard so link you can find it out inside the chat inside the chat and from there itself you can enroll now the syllabus is clear dashboard is clear each and everything is fine so I think we can start with the introduction of generative AI generative Ai and llm because from today's on uh from tomorrow's onwards I I will be like move to the Practical part and there I will be talking about the open a how to generate a open key how to use the open API and uh we'll try to understand the chat completion API functional API and uh we'll try to understand the concept of the token also that what is a token uh like how many token should I use whenever we are giving any sort of a prompt what is a different different prompt template and all there are lots of thing which we need to understand so today's session actually it will be uh like completely introduction session and in this particular session uh we'll talk about the generative Ai and the history of the large language model so guys uh are you ready can I uh get a quick yes in the chat if you are ready then yeah definitely we'll talk about the uh like use cases of the generative and all u in today's session itself I will like give you that uh particular idea that where you can uh utilize this generative AI in a real time yes definitely this course content and all whatever you are seeing over here this one definitely it will be available over the dashboard as well so this is our dashboard we'll update it over here inside the course syllabus section so each and everything uh like uh we'll try to update in the dashboard itself here is a class timing and all and uh I will make sure that the uh the link also okay so uh we are not going to uh we are directly streaming over the YouTube so directly you can uh join through the YouTube so for that you just need to subscribe the channel and you will get a notification in that case great so people are saying yes sir we are ready ready ready great yeah definitely Wy we'll try to discuss the applications and all and uh I will explain you all the thing and that uh specific way only don't worry we are going to build AI application by using the AI tools AI based application great so I got uh many yes in the chat now I think uh we can start with a uh with the introduction of generative Ai and the LM so guys uh first of all tell me that how many of you you are uh you have started with the generative Ai and all already means uh you have learned something at least you have learned the basics in all uh so if you can write down the chat so that would be great means you are starting from very U like a scratch or you have some sort of idea great so many people are saying uh so some people are saying they know about the basics and some people are saying uh they're starting from the scratch don't worry so uh basically I will start from the scratch only now here guys uh you can see I have created One PP for all of you so let me uh first of all let me go through with this particular PP and later on what I will do I will again I will give you the revision by using this PP only and in between I will use my Blackboard also for explaining you some uh Concepts and all so here is my Blackboard so here I will be writing down uh the whatever basically thing I need to explain you and in between I will be using the ppds and all so first of all let me go through this particular PP and here you can see so uh I have written some sort of a name uh so in the generative AI whenever we are talking about the generative AI or a large language model so couple of name are very famous nowadays and in in those name actually this chat GPT is a uh like very very famous so here I have written this chat GPT it's a product of the open AI as we know about this Chad GPT everyone knows about the chat GPT yes or no I think yes now if we talking about this Google bar so it's a product of the Google and we talking about this meta llm 2 so this meta llm 2 it's a product of the Facebook got it guys yes or no so yes uh nowadays actually everyone using this chat GPT Google B meta lm2 is it it's also a platform similar to this chat GPT uh where you can uh chat or where you can ask a specific question which you uh which you do in a chat GPD itself So Meta lm2 it's a a model from the Facebook site now here guys if we are talking about the generative AI or we are talking about the large language model so in our mind the first image which comes into the picture that is a chat GPT Google B and meta llm 2 yes or no tell me guys yes because of that only uh because of this chat GPT Google B and like the other the different like whatever application you are seeing nowadays right so mid journey is one of the application or maybe Delhi uh or different different application because of that only I think you are learning this uh particular uh thing this particular course this generative AI course yes or no yes so but guys this generative AI is having their own Roots it's not all about the chat jpt Google B and some other uh application which you are seeing chat jpt is just a application of this generative AI chat GPT or this Google B is just a application of this uh like llm large language model basically we are using this large language model in a back end U like whatever application you are seeing like chat GPT and all in the back end but apart from this this generative Ai and this llm is having their own Roots so first of all what I will do I will explain you the concept of the uh like first of all I will uh start from the deep learning itself means I need to explain you few uh terms and terminology regarding this deep learning so let me uh back to the Blackboard so there I will be talking about the basics of the deep learning So within uh 5 to 10 minutes I will be discussing the types of the neural network and all and then I will directly move to the uh like LMS and this uh genem so here guys uh you can see uh what I can do I can uh draw one box over here so this is the uh you can think this is what this is the neural uh uh basically if we are talking about the okay so first of all let me start from the deep learning itself so uh if we talking about a deep learning so uh we can uh divide this deep learning into three major segments so let me write it down over here this a deep learning so guys this deep learning actually we can divide into three major topic so the first topic actually which is called artificial neural network artificial neural network netork the second topic is called convolution neural network CNN the third one basically which is called recurrent neural network so we have a three types of the neural network and we can divide this a deep learning into this three major section apart from this you will find out other uh like topics as well so let me write down those uh thing over here so the fourth one uh which I can write it down over here that is a uh reinforcement learning and uh the fifth one we generally talk about it uh so that is what that is a gain so this gain also it comes under this generative AI I will talk about it I will talk about this game I will like give you the glimpse of this uh generative advisal Network that what is this and how the architectures look like of this gains and why I'm saying that this gains comes into the generative AI so if we talking about thisn so let me draw the box now so if we are talking about this n so here guys see we have an input layer inside this Ann actually what we have we have a input layer and uh you will find out the output layer and in between actually in between this input and output we have a hidden layers so just a wait now over here guys see we have a input layer and we have a output layer now in between actually you will find out a hidden layers various hidden layer so let me write it down over here input and here you'll find out the output now here in between this input and output you will find out of various hidden layers so let me write it down the hidden over here so this hidden layer actually it is nothing it's a hyper parameter so we can have as many as hid layer we can have as many as node inside the hidden layer we all know about the artificial neural network I'm assuming that thing now if we talking about this uh CNN actually so the CNN is nothing so in the CNN uh one more thing you will find out in terms of this CNN that is what that is a convolution we always perform the convolution in terms of this CNN so here if we are talking about this enn so uh we are using the uh like structure data where we have a like different different features numeric feature or categorical feature and uh we try to solve the regression and classification related problem but whenever we are talking about this CNN so here uh the CNN actually specifically we use for the image uh related data image or video related data you can say that uh we use the CNN and all for the grid type of data okay so we use the CNN for the grid type of data and there uh like you will find out one more component that is what that is a convolution so here uh let me write it down so the component name is what component name is a convolution so in the convolution actually you will find out a various step so uh we have a various step in the convolution itself so the very first step which we perform what we do guys tell me we perform the feature X section by using a different different filter after that what we do we perform the pooling and then we flatten the layer so there are different different like uh uh steps you will find out inside the convolution itself and after that what we do we apply the fully connected layer so that is nothing that is my Ann itself so over here I can write it down we have this convolution and we have a artificial neural network so this is my first architecture which is a like uh which is the Ann itself and and this is my second one that is what that is a CNN now if we talking about the third one which is a very very interesting that is called recurrent neural network that is called recurrent neural network so this enn we generally use for the structured data where we have a numerical column or categorical column and in the Target column like it will be a numeric or categorical one and based on that basically we are going to decide whether it will be a classification problem or a regression problem now if we talking about this CNN so already I told you if you're talking about this RNN so the name is what the full form what the full form is the recurrent neural network so this RNN actually we are using for the sequence related data so wherever we have a sequence wherever we have a sequence so this RNN we used for the sequence related data now let me do one thing let me draw the architecture of this RNN so over here guys in the RNN what you will find out so let's say this is my uh box and here is what here is my input so this is what guys tell me this is my input now here is what here is my output so let me draw the output one more time this is what this is my output got it now here guys see uh this is my input this is my output and this is what this is my hidden layer now in the hidden layer actually you will find out one thing one concept and the concept is nothing the concept is called a feedback loop okay so whatever output I'm getting from the hidden layer actually again we are passing that output to hidden layer until the entire time stem so that thing actually uh we learn or we learn in in the RN itself actually this RNN is nothing it's a special type of neural network and there you will find out the feedback loop feedback loop means what so whatever output we are getting from the hidden layer again we are passing the same output to the hidden layer until we are not going to complete the entire time stem that is what that is the RNN now uh you are uh we are talking about the llm so why we are uh why I'm discussing this RNN and all because this llm actually somehow it is connected to this RNN itself before starting with a llm a large language model we'll have to understand the concept of the RNN lstm attention uh like encoder decoder and then attention self attention and all so here I'm not going to discuss in a very detailed way I'm just giving you the glimpse of that that what is a like RNN what is the lstm what the Gru and then what was the sequence to sequence mapping and where this attention comes into a picture then how they have invented the self attention then how they started the using this transfer learning and this finetuning in terms of this uh in terms of this large language model why we are calling it is a large language model why we are not calling it a model okay so each and everything we'll try to discuss now uh you all know about this uh reinforcement learning and all so in the reinforcement learning uh you will find out one agent environment regarding that particular agent you will find out a different different state getting my point and then you will find out the feedback so that actually it comes inside the reinforcement learning and that is also part of the deep learning only now if we are talking about gain so gain is uh nothing actually so in the gain again you will find out a neural network uh which we are using for generating a data and that also comes in under inside the generative Ai and we have a different different types of game so first of all tell me guys uh this uh uh like types of the neural network this is clear to all of you please do let me know in the chat if uh this thing is clear then uh I will proceed with the next topic use cases wise I will come to the use case and I will uh try to discuss a different different use case I will come to the use case then I will tell you the applications of that and then I will come to the domains as well then in what all domains you can apply those use cases so don't worry each and everything we'll try to discuss over here yes I will directly come to the generative a itself but before that I will give you the timeline don't worry from Tomorrow onwards I'm going to be start uh I'm going to start from the uh like uh from the open ey itself uh like complete practical and all so no need to worry about it s Prasad I think you got your answer I think uh this basic introduction is clear now yes coming to the generative only don't worry yeah it's going to end to end uh we'll try to discuss end to end thing don't worry about it if you have any questions and all so you can directly ping into the chat uh so I will reply to you don't worry okay so I think now we can proceed so guys here uh in the uh PP itself I was talking about the generative AI then I given you the uh like uh uh the types of the neural network and I just explain you the uh like the regarding the artificial neural network and the CNN and this RNN so here in the generative AI uh you'll find out that I have like included a few slides and all so let's try to understand a few uh thing from here and then again we'll go back to the uh the Blackboard and then I will try to discuss few more concept so over here uh we have seen the chat GPT like I was talking about the different different application like chat GPT Google B and metm and all now let's talk about the generative AI that what is a generative AI now here you can see the definition of the generative AI uh which I have written over here uh that is what that a generative AI generate new data based on a training sample right so the name is uh the name is selfexplanatory right so the name is explaining everything generative AI the AI which is generating something now what all thing we can generate so here if we are talking about the generative AI so you can generate images you can generate text you can generate audios you can generate videos as a output you can generate anything uh so uh this image text audio video it's nothing it's a type of the unstructured data and definitely it is possible by using the generated AI we can uh generate this type of data by using the generative AI now if we are talking about the generative AI so uh as I told you that it is having their own Roots okay so it is having their own roots and if we are going to divide this generative AI so we can divide into two segment so the first segment is called generative image model and the second segment is called generative language model and this llm actually it falls into this particular segment into this generative language model are you getting my point yes or no I think yes so if we talking about this generative image model so I told you when I I was talking about the Deep learning uh like Ann RNN and CNN reinforcement learning and there was a gain so initially we were using the gain for generating a data so let me show you the architecture of the gain so the how the architecture of the game looks like so with that you will get some sort of idea in the game we are using this uh neural network only so let me show you the architecture of the game so let me search it over here over the Google game architecture now uh here in the image uh let me open the architecture of the game so here guys uh just see so in the gain actually we have two main components so the first component is a generator this is what this is a generator okay so uh I think this is visible to all of you this is what this is a generator and here you will find out discriminator so this generator and discriminator is nothing it's a neural network so we are passing this real data so here basically what we are going to do we are going to pass a real data and here we have a generator which is generating some sort of a uh like synthetic data and here we have a discriminator based on that we are going to discriminate between real data and the synthetic data so this is the architecture of the game and inside this architecture you will find out we are using two main thing we are using two main component the first one is generator and the second component is a discriminator I think you're getting my point and this generator and discriminator is nothing it's a neural network got it so this is also comes under this generative AI so now let me show you this generative AI now over here I have written two points generative image model and generative language model so if you're talking about generative image model so in our previous days in our back back days actually in our old days in 2019 18 so this gain was very popular for generating a data again uh this gain is very uh like EXP uh like expensive in uh terms of computation power and all so it is very like very much expens uh like expensive in terms of like uh computation uh so over here you can see so we were using this gain uh we were using this gain for generating images and all in our back days in 2018 and in 2019 and it was very very popular and we have a different different uh variants of the Gams if you'll find out the type of the gain you will find out many types now uh recently actually you will you have find out the trend of the llm large language model now guys here uh we are uh we are talking about the game and then uh this gain basically it was the old concept it is a old concept basically and there are different different variants of the gain as well now over here if we are talking about this large language model so it become very famous from the Transformer I will come to the Transformer I will tell you the complete history of the Transformer as well now uh this image model and this language model but a recent days in a recent days what I have seen in terms of this llm and all even we can generate the images by using this llm we got those llm basically which is like that much powerful so by using those particular llm we can generate generat images as well okay so we I will show you couple of models and all uh regarding this uh like image generation and definitely you will get some sort of idea that how the uh those part particular alms is working in terms of image generation I can give you a couple of example uh like Delhi so Delhi is a example you can uh check over the open a which is a model which is like a uh like a famous for the image generation now here uh if we are talking about this image model so actually see this image model basically it was working for image to image Generation image to image generation now this generative model actually so if we are talking about this generative model it is working Tech uh it is working in terms of text to image generation text to image generation and text to text generation so this two tasks definitely we can perform by using this llm model and this image to image generation before we were doing it by using this gain model in 2018 and in 2019 now uh as I told you that we have those powerful model in our recent Days by using those particular model definitely we can Implement image to image generation as well that is also possible so uh regarding that uh definitely I will show you couple of model so we are having four tasks here I have written it now let me move to the next slide and let me show you that what I have so here guys you can see uh this cat is representing a genitive model where you are giving a prompt uh means where you are giving a question and uh as a response U again as a output basically you are getting a response so in terms of uh see here we are talking about generative model I'm not talking about specifically this El M okay so I told you this uh generative model actually uh you can think it's a super set this generative Ai and under this generative AI you will find out this llm and gang is also part of the generative AI getting my point I think this thing is getting clear so over here we are talking about the generative model so we are giving a input and we are getting a like output now specifically if I'm talking about regarding this llm regarding this large language model so this input actually this is called input prompt and the output actually it is called output prompt so this cat you can imagine as a generative model or as a llm model so what we are passing as a input we are passing input prompt and we are getting as a output output prompt so this prompt term is a very very important I think you have heard about this uh prompt engineering and all that uh uh like uh prompt engineer is getting this much that much and this prompt engineer plays a very important role if uh we have to design any sort of of a prompt now uh different different types of prompt of like zero short prompt few short prompt few short learning and all we'll talk about it as I will progress with the like implementation and all in between I will give you like idea regarding each and everything now over here guys you can see uh where this generative AI exist so if you will look into the uh look into through this particular slide so here you will find out this generative AI actually it lies inside the Deep learning getting my point so the generative AI actually it uh like reside inside the Deep learning uh initially only I have explained you that uh we have a different different types of neural network and it's a part of the deep learning only now whether we are going to generate an images by using the llm or by using the gains or whether I'm going to perform text to text generation text to image generation or image to text Generation by using the llm both lies inside this generative Ai and this generative AI is a part of the it's a part of the tell me it's a part of the deep learning now over here guys I have written a couple of more slid so I will try to explain you uh but first of all let me give you the timeline of the llm and then I specifically I will come to the llm and all and I will be talking about this discriminative Ai and the generative AI as well so tell me guys uh this part is clear are we going good are you able to understand whatever I'm explaining to all of you so if you are getting it so please write down the chat and you can ask me the questions as well if you have any uh type of Doubt or U like if you're getting it or not getting it whatever you can ask me in the chat uh like chat section uh I will reply to your questions no reinforcement learning is not required uh uh specifically we should not go for the reinforcement learning and all yes this is a part of the uh like this Genera way is a part of the deep learning right right yes llm model used in a generative AI correct you got it uh guys mathematical intuition so we will talk about the mathematical intuition and all but this uh more uh this course this comp session is it is more focusing on the applied side so I will create a various application in between whatever math iCal concept and all will be required I will let you know that don't worry great so I think uh people are getting it and uh they are trying to understand fine so whatever I have explained you let me explain you the like Blackboard uh and then again I will come to this PP and we'll try to uh wrap up the theoretical stuff and U then I will explain you the applications and all so over here guys see I was talking about this Uhn CNN RNN RL and G now I started from the generative AI itself so I have started from the generative Ai and I told you this generative AI is nothing you can consider it as a super set as a super set now inside this generative AI you will find out many uh like uh many uh concept many topics and all so here uh regarding the generative AI there is uh two main thing which you will find out the first one is gain gain that is a generative aders Network the second is what llms llms large language model now we have a various task so here let me write down the task as well so the task wise so here I told you the different different task basically so the first task which I can write it down over here that is a image to image Generation image to image generation now the second task was the uh image to text uh text to text generation text to text generation text to text generation now the third task was the uh image to text Generation image to text generation and the fourth one was the uh image to image generation sorry uh text to text Generation image to text and text to image generation so let me write it down over here text to image generation text to image generation now if we are talking about this image to image generation yes we were able to do this particular thing by using this gain we have seen the gains now we are talking about this text to text generation yes it was possible by using the lstm RNN and the uh different different by using the different different model as well but yeah this text to text generation actually nowadays you are seeing uh we are preferring this large language model for this text to text generation and you this chat GPT is a biggest application uh biggest like example for that the chat GPD which we are seeing image to text generation yes uh this is also possible by using a different different model like RNN lstm and Gru image captioning if you have if you uh if you have heard about this uh like image capturing task so that is also possible uh by using this uh like uh classical model but yeah by using this llm also we can perform it we can uh do it now if we are talking about this uh text to image generation so yes uh this type of task nowadays it is possible by using the uh llm so yes yes uh llm is able to do llm is able to perform a various amount of task uh whether it's a homogeneous or it's a hetrogeneous now uh I was talking about the uh llm uh sorry I was talking about this generative AI so where it exists so this generative AI actually it exists uh in a u like a deep learning itself so you can think that AI is a superet machine learning is a subset deep learning again is a subset of the machine learning and this generative AI is a subset of the deep learning because as I already told you we have a different different uh like other neural network also in a uh like a deep learning and this CNN is one of them this a convolution neural network okay so I think this part is clear to all of you now let me draw the architecture uh that where this uh generative AI exists so you can think this is what this is my AI this is one uh this is the like a super set now here this is what this is my machine learning this one now uh inside that you will find out the uh deep learning and inside the Deep learning you will find out this generative AI uh so let me take a different color over here uh let me take uh this color so here you will find out the generative AI so this is what this four circle is what this is the generative AI got it now here uh you can see why we are saying so why we are saying this is a like a subset so I think each and every explanation I have given you over here uh you can uh prefer this uh like a this particular slide that why I'm saying this generative AI is a subset of the deep learning so let me write it down over here this is what this is nothing this is a gen Ai and it's a subset of the deep learning now guys let me explain you the timeline of the uh this llm so uh now you got it that this uh llm is nothing it's a part of the generative a itself this large language model now let me talk about the complete timeline of this large language model so how it evaluate and uh uh I can like talk about the complete history of it and uh here guys you can see that first I was talking about the RNN so as you know that uh what is the RNN tell me RNN is nothing it's a type of the neural network it's a type of the neural network so uh there basically we have a feedback loop again we can pass the information to our H layer now you will find out a different different types of RNN or some Advanced architecture in terms of this RNN itself El the second uh like thing which is a type of the RN itself that is called lstm lstm right so in the lstm actually uh if we are talking about this lstm so here you will find out the concept of the cell state so in the RNN we just have a Time stem and it is for the shortterm memory it is for the shortterm memory we cannot retain a longer sentences by using this RNN it is not not possible if our sentence is a very very huge or it's a very very long so we cannot retain that particular sentence by using this RNN but if we are talking about this lstm yes we can do it by using this lstm so in this lstm you will find out the concept of the cell state so uh this uh lstm is nothing it is for the shortterm dependency and it is for the longterm dependency also it is for the short like a memory shortterm memory and is for the longterm memory as well if you look into the architecture of the lstm so you will find out along with this uh time stem so here we have the time stem U like it's a hidden State actually uh like on a different different time stem along with that you'll find out one cell state so it is going to retain it is going to retain the longterm dependency and in between in this a time stamp in this shortterm memory and in this cell State you will find out a connection the connection in terms of gates so here you will find out one connection uh like uh one gate basically that is called forget gate so here I can write down the forget gate now here you will find out one more gate actually so that is called input gate here you are passing the input now here you will find out one more gate over here that is called output gate output gate okay so we have three gates inside the lstm for sustaining a longterm dependency or for reminding a longterm uh long sentences now uh you will find out one more updated version of the lstm so this RNN is a old thing this lstm is also old thing now you will find out one more updated version of the lstm that is what that is a GRU so this Gru actually they have invented in 2014 and they had they took the inspiration from the lstm itself now inside this Gru you won't find out the concept of the cell State everything is being done by the hidden State itself and here basically in the gru we just have two gate update gate sorry reset gate and update gate and it's a uh Advan or you can say it's a updation on top of this lstm it's a updated version of the uh like lstm itself now what is the full form of the gru G and recurrent unit now over here guys see this was the three architecture which was very very famous during 2018 and 19 in our old days now here see uh one concept comes into the picture if we are talking about this RNN lstm and Gru so by using this particular architecture what we are doing so by using this particular architecture we are going to process a sequence data yes or no we are going to process a sequence data now here one concept comes into a picture sequence to sequence mapping and for that only we are using this particular architecture so we have a different different type of uh like a mapping technique so let me write it down over here uh different different type of mapping technique uh now it is fine uh I think I'm audible to everyone now now I am audible guys please do confirm in the chat I think there were the issue from the mic side now I'm audible so please do confirm in the chat if I'm audible then and uh is there any Eco or uh what so guys are you facing any Eco in my voice now it is fine yeah it is perfect I think great fine fine fine uh it's clear great uh I think now I am audible to everyone sorry I think there was a issue from the do let me know in the chat uh from where I lost my voice so this concept is clear this one to many or one to one one to many many to one many to many yeah so I think uh I was there RNN lstm and Gru now I think it is fine I'm audible to everyone great so I was talking about RNN lstm Gru and then U I talked about the different different mapping sequen now uh this mapping sequences actually we can Implement by using this uh RNN lstm and Gru so over here uh yes so 1 to 1 one to many many to one many to many RN and LSM and Gru this was the sequences actually I was talking about now in 2014 actually see this was the sequences by uh we can Implement by using this different different models getting my point now over here uh if we talking about this particular sequences definitely we can uh like uh per we can uh create a various uh application by using this model but here basically we are having some sort of a restriction uh as I told you the different different application like one to many many to one so many to one means uh you can think that sentiment analysis one to one to many means what one to many you can say image capturing many to many image uh sorry uh language translation so there are various application of the sequences now see uh we are talking about the sequences uh the sequence to sequence mapping now uh we can definitely implement it by using this particular architecture so the problem we were having the problem was actually uh we cannot see let's say we are giving an input in the input actually we have a five words so whatever output we'll be getting in the output also we should have a five words so it's a fixed length input and output getting my point what I'm saying so by using this particular mapping 1 to one many to one or like many to many specifically we are talking about many to many so there was some problem there was some issue the issue was fixed length input and output so whatever number of inputs we are passing in terms of this many too many I'm talking about okay so whatever number of inputs we are passing so those many output on we can get it over here in the output itself so uh here actually one a research paper came into the picture in 2014 you can search about uh the research paper sequence to sequence learning so inside that uh paper they have introduced the concept of the encoder and decoder in the encoder and decoder actually the one segment the one segment was the encoder segment segment so let me uh draw it over here so the one segment was the encoder segment and the another segment was the decoder segment this another segment was the decoder segment and in between actually in between we were having in between actually we are having the context Vector so here uh in between this encoder so we are having the encoder and we are having the decoder decoder one part was the encoder and one part was the decoder and in between we having the context Vector means whatever information was there whatever information was there from encoder to decoder we are passing through this context Vector means we are wrapping all the information in this context vector and we are passing to the decoder that actually the paper uh has been published in 2014 you can search about it you can search over the Google sequence to sequence learning so let me uh search in front of you only now over here I can write it down sequence to to sequence learning research paper now uh over here guys you will find out this uh particular research paper now just try to read this paper now here in this particular paper they have clarify the issue that what was the issue with the classical mapping so that was restricted to the input and output now over here you if you will read this particular research paper so easily you can find it out the issue here itself in the like introduction itself they have mentioned they have mentioned this uh despite their flexibility and power can only be applied problem who inputs and targets can be sensibly encoded with the vector of fixed dimensionality it was just for the fixed dimensionality and basically there was we were having a limitations so for solving that particular limitation this a sequence to sequence learning paper came into the picture and there was three person Ilia sasar and orol and this there was one more person and this paper from the Google side now here guys uh let me open this uh Blackboard again so there was a context Vector but this uh encoder and decoder also was not able to uh perform well for the long uh longer sentences so here in the research basically they have proved if my sentence is going uh is going uh like above from 30 to 50 words right if it is longer than 30 to 50 words so in that case it was not able to sustain the context it was not able to sustain the context if we are using this encoder decoder architecture now you will ask me sun what we were having inside the encoder and decoder so we are talking about the encoder so again here we were using the either RNN lstm or uh lstm and we were using this Gru and here also in the decoder also we are using this rnl we are using the lstm and we were using this Gru got it I think you got the problem now and you got to know about the encoder and decoder so we have started from the RNN then now we came to the lsdm Gru and then we have a different different mapping and for solving this particular issue which is related to this many to many uh like uh mapping many to many sequence mapping and this uh uh this language translation is one of the example if you will search over the Google translate uh just search over there anything let's say in the in H you are saying that or whatsoever so it will generate output so this input word and output word will would be a mismatch but that was a restriction with this uh like with the classical mapping so for using this encoder and decoder architecture we can solve that particular problem now here also we are having the issue that we cannot proceed a longer sentences we cannot proceed a longer sentences so here One More Concept comes into a picture inside this context itself and that was the attention that was the attention so uh here neural translation with just a second let me search about the neural trans TR a NS relation with attention yes this was the paper and uh this was the first paper let me search about the research paper yeah now guys uh this was the paper in this particular paper they have introduced the concept of the attention and just try to download it you need to download this particular paper and uh then you can see there so just a second let me show you this paper as well and this is the main uh like main papers uh basically which you will find out uh while you will be learning this deep learning and all so this paper actually this has been introduced in 2015 I think in 2015 or 16 now here they have introduced the concept of the uh attention actually so just try to read uh this particular paper at least try to read the introduction of it uh there we have uh there they have defined that uh what was a problem with the encoder and decoder and where this attention comes into the picture and what is the actual meaning of the attention they have introduced each and everything over here inside this particular paper inside this particular paper they have introduced each and everything regarding the attention see this is the architecture of the attention model and uh before going through with any blog any website or any tutorial try to uh go through with the research paper and try to understand the motive of that research paper now see guys uh here I'm not going into the detail of the attention because this attention itself uh is a longer topic but I can uh like give you the glimpse of that that uh uh what what they were doing in the attention so they were mapping so let's say we have a five words in the sentence so they were trying to map each word whatever word we have a input we were trying to match each each input word with the output word means this input and output this encoder and decoder if we are talking about this decoder actually so this is having the uh information each and every information of the Hidden State whatever like in the encoder like you will find out this RNN lstm or whether it's a GRU so uh we have a hidden State actually right so uh this decoder part is having the information regarding those particular hidden State all the hidden State and because of that it was able to uh it was able to predict so whatever like sentence and whatever words or longer sentences or like U like uh the longer sentences and all which uh whatever basically we were passing it was able to predict okay so this word is related to that particular sentence so what I will do I will create a like a one dedicated video on top of it there I will try to discuss uh this attention mechanism but yeah here I'm just giving you the timeline U and with that um you can clearly understand so uh here we were having the attention mechanism now guys by using this attention mechanism by using this attention mechanism in 2018 Google again Google published one research paper and the research paper name was attention about this encoder in the encoder and this decoder we were using what we were using guys tell me we were using this LSM either we are using the lstm RNN or maybe Gru now uh there also we are having the lstm maybe RNN or maybe you are having the Gru and uh if we are talking about the attention so whatever uh information we are passing from here to here so you are having the context Vector context Vector now on top of that we are having the attention layer attention layer and it was nothing it was just a mapping from input words to out output word now here actually they have published one paper in 2018 and the paper name was attention all your need attention all your need now this paper actually it was a breakthrough in the NLP history this paper has been published in 2018 and here actually decoder but there is one uh there is one thing basically in terms of this encod and decoder you won't be able to find out this lstm RNN and Gru they are not using any RNN cell any lstm cell or any Gru cell so here actually they were using something else and here the what is a uh name of the research paper so they were saying that attention all your need only attention is required for generating us let's say we are passing any sort of an input means any longer input so from that particular input only attention is required for generating output now how let me show you that this Transformer architecture or let me show you the attention all your need research paper so attention all your need research paper so guys this is a very uh prestigious paper in our NLP history and uh this changed the complete history of the NLP and whatever llm and all whatever you are seeing like nowadays so they have used this Transformer architecture as a base model I will come to that and there I will try to uh discuss that uh what is the encoder and decoder again I'm not going into the depth of the mathematics but yeah definitely I will try to give you some sort of a glimpse so over here uh let me zoom in first of all this paper and and here guys the paper name was attention is all your need so this was the researcher asish Nome Nikki Jacob you can uh search about these particular people and here is the abstract uh you can see and this is the introduction at least try to read the introduction try to read this particular background and the model architecture so this was the model architecture which has been introduced by the uh by the Google researcher and the architecture basically which you will find out inside this research paper I think everywhere you will find out this uh this particular architecture in uh whatever NLP tutorial or if you are going to understand the attention mechanism and all so this is the architecture now in this particular architecture let's try to understand that what all things we have so see first of all we have a input okay try try to understand try to focus over here so we have a input over here then we have a input embedding so this is my first thing input and this is what this is the input embedding the third thing which we have that is a positional encoding getting my point and then after that you will find out the multiheaded attention then we have a normal uh normalization and all and then we have a feed forward Network now guys just tell me this is what this is a encoder part this is what this is a encoder part and this is what guys this is this is a decoder part this is the decoder part got it getting my point so here also we have a two segment first was the encoder and the second was the decoder but here we are not using any RNN cell lstm cell or maybe Gru cell here actually we are using something else some other concept and the concept actually I think this is not a new thing for you this embedding and all uh this embedding attention already I talked about the attention that what it is mathematically it is having a like uh like a some different explanation but yeah I think you got to know the idea now here we have a feed forward neural network you know like what is a like artificial neural network what is a feed forward neural network so it's not a like a new thing for all of you and by assembling all those thing they have created one cell one architecture and the name is called this uh Transformer so this architecture itself is called a Transformer what is this guys tell me this is a Transformer now here guys just see uh this uh Transformer if we are talking about this Transformer and all so let me uh tell you few things regarding this Transformer uh so first of all guys this is a uh fast compared to the classical architecture if we are talking about this RNN lstm and all so there we are passing the input based on a Time stem based on a Time stem but if we are talking about this Transformer guys so here what is the importance or what is the like plus point which we have inside the Transformer it is a faster why because we can pass the input in a parallel manner we can pass all the inputs all the tokens in a parallel manner in a parall actually we can pass the input now over here see we have a input embedding we are doing an embedding over here and then we have a positional encoding means we are arranging a sequence sequence of the sentence then we have a multiheaded attention again we are trying to uh figure out the uh meaning see let's say uh the sentence is what I am Sunny now uh here it is trying to find out the relation I with M and sunny is trying to find out the relation M with uh this I and sunny it's time to find out a relation this sunny uh and this m and this I so it is trying to find out a relation with each and every word so it is doing the same thing inside the multiheaded attention then you will find out this feed forward Network neural network actually and yes uh this is what this is my encoder part as I told you this is what this is my encoder part now if you will look into the decoder side so again we have a same thing so here we have a outputed output embedding means in uh uh like whatever uh like a sequence uh in whatever like U am format I want output so that is uh this particular thing this output Ting and then again we have a like multiheaded attention and we are passing this thing uh to the next one to the next layer and again we have a feed forward neural network over here on top of this you will find out the soft Max and finally we are getting a output output probability so don't worry I will try to discuss this Transformer architecture mathematically in a detailed way in some other video but as of now I'm just giving you the GL Glimpse because whatever llms we are going to discuss okay as a base architecture they are using this Transformer so guys until here everything is fine everything is clear please do let me know in the chat yes or no yes you can uh let me know in the chat uh then I will proceed with the pp and all and uh we'll try to wrap up the uh introduction of this llm and all and in tomorrow's session we'll try to talk about the open a and we'll discuss about the open API and all and a different different models of the openi any doubt anything so if you have any sort of a doubt please do let me know guys please do let me know in the chat uh I will try to clarify that uh those doubt and uh so did you get a timeline timeline of the llm I will come to the llm now the specific word and uh after deep learning an NLP what is the topic uh for generative AI please give up uh so after the Deep learning and see after the Transformer actually by using this particular Transformer people has created a different different llms and all large language model now I will come to that by using the slide I will try to show you that I think this is pry much clear now let me go back to this uh uh notes and here you can see so I started from the deep learning then generative VI and all then you got to know that where generative a lies then Alm Gru different different mapping encoder decoder attention and finally attention all your need now let's try to understand uh like rest of the thing by using the slide so here guys uh one more thing I think we were uh trying to understand this particular part where this generative AI exists and I hope you got a clearcut idea now let me go back to the uh let me like come to the next slide so in this slide you can see uh I'm talking about the generative versus discriminative model so what is the difference between this generative and discriminative model so we are talking about this discriminative model so whatever you have learned so far in a classical machine learning and deep learning so uh let's say uh I'm I'm talking about this uh any classification based model let's say I'm talking about this uh RNN so here actually see uh you are training your model on a specific data so this is your data this is your input and here is your output what you are doing guys tell me you are performing a supervised learning you are performing a supervised learning by using this recurrent neural network there is a classical model or we have like other classical model and all you can use any uh uh like a machine learning based model as well like na buers and uh different different variants of the nap bias or maybe some other model you can uh use that particular model also uh so over here we have a model and we are going to train this model by using the supervis machine learning there we are going to pass a specific type of data to this particular model and here we have a different different output like a rock this music is belong to the rock music classical music or maybe ranting so here we are passing this uh like music to my model and finally it is going to predict something like that this is a descriptive model now if we are talking about a generative model so this is a little different compared to this discriminative model how it is different uh compared to this discriminative model so here guys see we are training this see first of all the if we are talking about the generative model if we talking about the generative model so the training process is a little different if we are talking about the large language model if we are talking about the llms so uh the proc of training this llms is a little different compared to this discriminative model now over here we are talking this discri this generative model basically so we are passing the input to this generative model and we are getting an output how how so here basically we have a different different step for Gen for like training this generative models so gain wise I already told you that what is a like process if you want to like train uh any gain model if we are talking about llm large language model so at the first first place there will be unsupervised learning unsupervised learning then at the second place we'll be having a supervised finetuning and at the third place uh basically we have a reinforcement learning reinforcement learning they have recently used inside the chat uh in the GPD model itself uh which we are using for the chat GPD but before that whatever llm model they have created they have created they have trained on a large amount of data so for that first they have performed the unsupervised learning and then they have performed the supervised fine tuning so because of that that model were able to understand each and every pattern which was there inside the data and because of that it was able to generate the output so this generative model is nothing in that basically we have a data on top of that particular data we are training a model and for that we have a various step and uh basically then only we are going to do a prediction so what it is giving me as a prediction so whatever input we are passing so that input it is taking and finally it is generating uh the output related to that particular input means it is generating a new data getting my point I think this part is clear to all of you how this generative model is different from this discriminative model discrimin model is a classical model like supervised learning uh we are performing The supervis Learning now right so here we are having the RNN and we are passing a data and all and we are trying to train it generative model various step we have like for the training and all and it is responsible for generating a new new data that's it so I hope guys this uh thing is clear to all of you now I have kept couple of more slide regarding uh this particular concept just try to note down the uh the headings and all and try to remind uh this particular thing this discriminative versus generative model and all now here uh the same thing unsupervised supervised learning which is related to this uh discr model got it and here uh you can see uh this is the generative like model so in the generative model what we do first we perform the unsupervised learning we are doing a grouping and all and then we discri we perform the supervised finetuning supervised learning so that is a like process for training a uh like any sort of a llm model which comes under inside the generative AI itself and again wise I already talked about it now here actually uh we're going to talk about this uh llm so let me give you the quick idea about this llm and all that is what that is a large language model so for that all Al I have created one slide and there specifically I kept the thing related to this uh llms only so let me start from the very first slide uh let me give you the overview and uh from tomorrow uh actually in tomorrow session I will give you the detail uh like overview uh with respect to different different models and all whatever we have as of now just a quick introduction now what is the llm so llm is nothing it's a model it's a large language model which is trained uh like U it's a large deep uh it's a large language model which has been trained or a huge amount of data and it is behaving like it is generating something right so actually by using this uh llm we can generate any uh like a sort of a data like Text data or maybe image data and that is a like uh that is a advantage or that is a like uh uh one uh very uh like a very famous uh thing regarding this llm and all now if we are talking about this why this is called llm why this is called large language model so here guys if we are talking about this large language model so because of the size and the complexity so here specifically I have mentioned regarding this large language model regarding this llm why this is called this uh this large language model so here because of the size and because of the complexity of the neural network uh neural network neural network as well as the size of the data set uh which has has been uh which is trained on actually this is trained on the huge amounts of data because of that only actually it is called a large language model so here uh if we are talking about this uh L large language model so uh actually before we were not having the huge amount of data so uh recently actually uh you know uh this uh data generation and all uh Big Data actually came into the picture and this companies and all generated a huge amount of data and this Google also Google Facebook and the other companies is having a huge amount of data so uh they uh they are able to like find uh means uh actually they have uh gathered that particular data and on top of that data they have uh like as I told you they have performed the unsupervised learning and all and they have categorized a data and they have provided to a different different model which U like has been created like GPT B and all and because of that uh like they were able to predict the next next sentence and that is a like a main thing main advantage of this large language model now over here you will find out so in the next slide uh I have mentioned that what is the what makes llm so powerful so here by using one single model by using one single llm actually we can perform a different different type of task like text generation chatboard uh we can create a chatboard also we can uh do the summarization translation code Generation by using a single LM we can do that particular thing now here uh if you will find out so already I told you that what is the base architecture of the llm so here this Transformer is what it's a base architecture behind this llm behind this large language model and I have already explained you the concept of the uh Transformer that what we having inside the Transformer now here guys uh this is a few Milestone which we have in terms of the llm like bird is there I think you know about the bird if we are talking about the uh we are talking about the like a bad days right or old days in 2018 19 or 20 when uh chat GPD was not there just uh this uh GPT was not there GPT 3.5 and all the recent model which we are using inide of chat GPT so there were few Milestone and we were using this thing in our old days like B was there GPT uh actually GPT is having a different different variant it is having a complete family GPD 1 2 3 and 3.5 and recently GPD 4 came into the picture and other variants as well so xlm is also there uh cross lingual language model pretraining by uh this particular guy now T5 was also there this a text to text transfer text to text transfer transform Transformer and it was created by the Google Now Megatron was also there so Megatron actually it was created by the Nvidia now M2M was there so it was the part of the Facebook research so there were many uh like uh there was the uh like many model actually actually okay and this was a milestone in uh this uh in terms of this large language model now over here guys see this bird GPT xlm T5 they are using a base architecture as a Transformer one only now if you will see in the next slide so I have categorize this thing so they are using a base architecture as a Transformer one only but in that you will find out some of the model are using a encoder and some of the model are using a decoder and some of the model are using both encoder and decoder now here I have categorized this particular thing that uh this is the model like B Roberta xlm Albert Electra DTA so these are the model they are just using the encoder only and if we are talking about this decoder uh if we are talking about the GPT GPT uh 2 gpt3 GPT new or like the entire family of the GPT so they are using this decoder so we have a two segment of the Transformer architecture few of models they are using an encoder side encoder part and few model basically they are using a decoder and uh here guys you will find out some model which is which are using both encoder as well as decoder so this T5 Bart M2 m00 Big B so these are the model actually they are using both encoder and decoder in the Transformer architecture if you'll find out we have a two segment so this is a this segment basically this one is called an encoder segment and this particular segment this is called a decoder segment so here uh like I think you got to know uh you got to know the idea that uh this is what this is a like uh transform this is the encoder segment and this is what this is a decoder segment and this model this T5 B M2M and big but they are using both and we have other models as well I just written this uh couple of name over here now apart from this you will find out some openi based model open a based llm model so GPD 4 is there GPD 3.5 is there GPD based is there Delhi Biser iddings okay so these are the different different model which you will find out over the open website itself and uh here uh definitely GPT is uh one of the prestigious model or this is one of the very important model which uh people are using uh nowadays for creating their like applications and all and it is it can perform any sort of a task related to a generation okay now over here uh this is the openi based model which I have written now apart from this you will find out other open source model so this is the model from the openi side so if you are going to hit this model so definitely open is going to charge you regarding the tokens regarding the uh regarding like how many tokens and all whatever you are using according to that it is going to charge you but here we have some couple couple of Open Source model as well and I have written the name like Bloom Lama 2 Palm Falcon Cloud amp okay stable LM and so on we have a various model various open source model and uh yes but I I will show you that how you can use this particular model if you are going to create your application so definitely I will let you know I will show you that how you can utilize this model as well I will show you the use of the Falcon I will show you the use of the Llama 2 if you don't want to use this GPT uh GPT 3.5 GPT 3.5 turbo I will show you the use of this llama and this Falcon and some others open source model as well I think you are getting my point now here uh if we are talking about what can llm be used for so if we are talking about llm that what it can do so it can uh we can use this llm for any sort of a task like classification text generation summarization chat board question answering or maybe speech recognization speeech identification spelling character so this uh llm actually uh if we are talking about this L LM so first of all it's a model it's a large model U it's a language anguage model and it's a large model it's a large language model and what is a like what we can do by using this large language model we can generate the data okay it can identify the pattern of the data it is having that cap cap uh that uh that much of capacity so it can identify the pattern from the data and by using those pattern we are we can perform a various amount of task okay that's why this llm is too much powerful and here we can use this llm for any sort of a task and yes uh we know about this it and already I have uh like I explain you this thing I hope this introduction is clear to all of you now coming to this uh prompt design so prompt design and all uh definitely I will talk about it uh once I will come to this open a API there will try to hit the uh different different models of the open a and uh we have a different different type of prompts so as as of now you can think that the prompt is nothing whatever input we are passing to the model uh that is called input prompt and whatever output we are getting from the model itself that is called the output prompt and here how cat GPD was trained so generative of pretraining supervise fine tuning and this reinforcement learning there was three step which I have mentioned so I will be talking about this also and not in today's session in the like next session uh I'll be talking about this uh how CH GPT and all it was stained uh okay now what I can do so over here guys uh I think uh we should uh conclude the session so how was the session please uh do let me know in the chat it was good bad or what so did you uh understood everything did you understand everything whatever I have explained you uh regarding this uh regarding this llm and this generative AI the complete introduction because uh I want that before starting with any sort of a practical the basics should be clear everything did you understand amazing great to what is the topic yes fine uh if you have any doubt and all so you can ask me I will try to answer for that now before concluding with uh like uh before concluding the session let me show you few more things over here so see uh here first of all what you need to do uh first of all you need to like uh go through with the open a and you need to generate a open a API and all so that uh basically don't worry I will show you while I will be doing a practical and all so you need to like at least you need to create an account and uh and you need to login it over here so so once you will log in guys here you will get two option first is chat GPT and the second is API just go through with this API and generate this API key generate the API key from here don't worry in the next session in the next class again I will show you this thing and here I see we have a different different model so let me show you those model and whatever open source model and all is there so you will find out over the hugging phase so let me show you the hugging face models hugging face Hub and uh here you will find out the model Hub so guys uh here actually we have a model Hub just a second yeah models now you will find out a different different type of model see these are the models which is a open source and uh uh you'll find a complete description let's say this uh we are talking about this Orca 2 so this updated 12 days ago and it's a recent uh llm model uh which has been published uh by the Microsoft now over here you can see so it like you will find out the complete description or complete detail regarding this model and like uh how to use it and uh each and everything basically definitely we'll talk about it now for what all task basically we can use it okay so according to that also you can uh like select the models so just go through with the hugging phase models and there you will find out many uh like a different different models okay and yes for sure openi is also having uh different different llm model so we'll talk about that we'll try to understand the concept of this uh we'll try to understand this uh assistant actually and we'll try to talk we'll try to understand the chat U actually so what is this and how to use it how to use this chat option and this assistant option and here if you will go inside the documentation so you will find out of different different models over here this GPT GPT 3.5 Del TTS whisper embedding moderation GPT W gpt3 right right different different models we have and uh apart from that you can find out the different different task according to that also they have given you the model so text generation so they have given you the complete code and all so just try to visit it just try to go through it uh by yourself now uh we have other uh platform as well so if you are not going to use the uh maybe J uh if you don't want to use this uh GPT and all so here uh I can show you one more uh like option so AI 21 okay so AI 21 Labs AI 21 Labs so this is the Recently I figured it out actually this is the uh like alternative of the GPT so we'll talk about this also if you don't want to pay to this uh if you don't want to pay for the GPT so you can use this AI 21 lab uh and it will give you the uh like a uh one model one llm model so you can use it uh like freely actually it gives you the $90 credit so so yes I will show you how you can use this AI 21 lab uh so let me show you the documentation and let me show you the models as well so here you will find out the uh model basically which is there so Jurassic 2 is a model and it's like a pretty amazing model and uh uh yes definitely I'll be talking about it and along with that uh the applications of it which is very much required that for what all task we can use it whether if you are going to create a chat board or maybe if you are going to do a question answering or text generation or like sentiment analysis for what type of task we should use it and how to design a prompt and all regarding the specific task got it so we'll talk about this also so uh yes many things is there and definitely uh uh like from Tomorrow onwards I'm going to start from the open a lure and step by step I will come to the uh different different models and all so I hope guys this is uh clear yes practical implementation will be there don't worry yes recording will be available over the YouTube yes all the uh all the topic will be covered in the upcoming session uh all the discussed topic and all yes definitely this will be available in the dashboard you can go and check uh your dashboard this uh video along with the video you will find out the assignment you will find out the quizzes and regarding the particular topic fine I think uh we can conclude the session now is gener andm are also used in computer vision based project so for computer vision based project we have a uh like others model we have a different models uh because uh the task is different over there so the task wise we are talking about the computer vision related task like object detection object segmentation tracking OCR object classification and for that we have a different model and definitely we can use a transfer learning of finding over there now uh by using this L llm um like this llm is for the like a different task it is related to the language related task it is not related to that detection or a segmentation or tracking it is not related to that particular task it is related to the language related task and uh here see let me show you one uh one more paper one more research paper so here I can show you this uh ULM fit now see uh so just try to go through with this particular paper universal language model find tuning for text classification now here in this particular paper you will find out that see uh this uh if you know the Deep learning so in the Deep learning we have uh two major concept so the one one concept is uh called transfer learning transfer learning the second concept is called fine tuning F transfer learning means what so you are transferring the information from uh from one state to another state okay or like you can I can give you very simple example for that let's say you know like how to how to write the cycle so for you like for if you know how to write the cycle definitely you can use that information and you can write the motorcycle also so that is the same thing basically which we uh do inside the transfer learning let's say we have trained the model uh like let's say we are talking about the computer vision so inside that uh you'll find out uh we have a various Tas like detection classification tracking and all so let's talk about the model let's say YOLO so or we have other model also like faster rcnn rcnn and all SSD SSD and all like a different different model related to a detection so the model already has been trained on some sort of a data some amount of data on some Benchmark data so by using that particular information we can uh like perform the detection and all for our specific task if we are not able to do it then definitely I will finetune my model but how we can use the same thing in NLP because in NLP actually we have a task uh the task is very specified we have a specific task let's say we are talking about um if we are talking about a task let's say uh ner name entity recognization or let's say we are talking about the task let's say a language gener language translation language translation language translation or maybe sentiment analysis so these are the specific task specific task ask means regarding to the specific uh regarding to the specific topic let's say if I want to do a sentiment analysis so not for the entire data whatever there in the world for the specific uh let's it for the Twitter data only means whatever TW tweets and all we are getting now if we are giving any other data un any other like a task related data so it won't be able to perform that so actually in this particular paper you will find out that how we can use this uh language model language model for uh like for the universal task and there only this llm comes into a picture L this llm actually it came from the language model itself okay because we are training this uh language model on a huge amount of data that is why it is called llm large language model because we have we have trained this data on a huge amount of we have trained this model on a huge amount of data got it so here in this particular paper they have like shown you that how to use this transfer learning because uh in before 2018 uh actually we were using this transfer learning in the computer vision only in the uh like in a different different tasks of the computer like object detection or segmentation you will find out the image data so on top of that data we have trade like a Ben model and directly like like vgg rset and all and directly we are using those particular model for our like a other task so here if we are talking about the NLP so we are not able to do it before this Transformer and all so actually see we got a Transformer we got this particular concept like how we can use this transfer learning and all in the like NLP field so this two concept came together transfer learning and the architecture like Transformer self attention and all and from there itself this uh llm came into the picture llm means large language model which has been train on a huge amount of data which is able to perform the transfer learning and we can do it uh we can find T it also and the main uh like uh the main cap or the main uh role of the llm is what it is able to generate a text text generation got it so fine I think we are done with the session now so rest of the thing we'll try to discuss in the uh tomorrow session and we'll try to more focus on the Practical side so all the recordings and all it will be updated on a dashboard and uh yeah that is it yes so I think uh we can start with the session now so yeah uh welcome again again uh so you all are welcome in this uh Community session generative AI Community session uh yesterday we have started this uh generative AI Community session where we have discussed about the generative AI so there I have given you the introduction related to the generative Ai and large language models and here you can find out the video so this is the dashboard uh it's a free dashboard actually uh which we have created for all of you the same video actually it is available over the Inon uh YouTube channel as well if you we will go in a live section so this uh same video you can find it out over there as well now uh let me show you uh that particular video so here is my YouTube now let me search over here I neon and here guys uh go inside this uh live section and this is the video so the same video same lecture you will be able to find out inside the live section apart from this uh the same uh thing basically we are uploading or the in neuron dashboard and here along with the video you will find out the resources so all the resources basically whatever I'm using throughout the session uh so whatever notes and all which I'm writing and whatever PPS and all or whatever code file I'm using throughout the session you will find out all the resources over here got it guys yes or no so do you have this dashboard do you have this dashboard tell me I think uh many people are androll yesterday uh for this free community session and yes all the videos and all basically we are going to upload over here not even video and resources along with the video and resources you will find out the uh live uh you will find out the quizzes and assignment as well so already uh I have prepared the quizzes and assignment so soon it will be uploaded over here so in this particular video you will find out one more section so the section will be quizzes and assignment so there you will find out a uh like uh a video related or a topic related quizzes and assignment got it yes or no so please uh give me a quick confirmation in the chat if this uh dashboard related thing and this uh video related thing is clear to all of you I'm waiting for your reply in the chat and if you have any sort of a doubt then you can ask me in the like chat section as well and don't worry my team will give you the link of the dashboard so if you haven't enrolled so far so uh by using that particular link definitely you can enroll it you can enroll U inside the dashboard great all clear all clear great fine so here I got a confirmation now uh so let's start with the session let's start with the uh second day so in the first day actually so what I discussed I discussed about the generative AI so where I have like told you that what is a generative AI so this is the slide basically which I was using and here actually this was the agenda the complete agenda which I going to discuss this uh throughout this committee session and uh today is the second day where I will start from this open AI so in the previous session I was talking about this generative Ai and I discussed each and everything related to this generative a and I hope you got a clearcut idea that what is a generative Ai and in the generative AI actually what all things comes into the picture where llms lies so if we are talking about this large language model so regarding the large language model also I have clarify each and everything I have given you the complete timeline of this large language model where I have discussed about the uh the complete history of the large language model from the RNN so first I have started from the RNN then I came to the lstm then uh I discussed about the uh different different sequence to sequence mapping I talked about the encoder and decoder and after that I have explained you the me uh the concept of the attention and then I have discussed about the attention is all your need uh the Transformer architecture and I told you that whatever llms which you are seeing nowadays so those uh all the llms are using Transformer as a base architecture so I have explained you the the like whatever thing was there inside the Transformer architecture whatever component whatever segment was there each and everything I have discussed over there and apart from this generative AI I have talked about this llm also so there I have talked about that what is a llm why it is called large language model and uh why it is so powerful because this one uh because this one llm is able to perform lots of like task lots of uh one basically llm we can use for the different different type of application so here uh I have written the couple of name like text generation summarizer translation or code generation and so on we all know about the chat GPT uh chat GPT is are application and uh chat GPT is using gpt3 gpt3 is a a base model so GPD 3.5 actually it's a base model so how it is how much it is powerful we all know about it and that is a example of the large language model which is capable to do so many things why because uh it is having a power so so that actually it can generate a it can generate a data based on a previous data it can understand the pattern and because of that only we are able to trans we are able to use this Transformer as a or whatever like Transformer based model we have we are able to use those transforma based model as a transfer learning I have explained you the concept of the transfer learning and the fine tuning as well so here I was talking about this llm and then I talked about the few milestone in a large language model so here I have written couple of name bird GPT xlm T5 Megatron M2M so these are the uh like a few milestone in a large language model now this model has been trained on a huge amount of data now specifically we are talking about GPT so in a GPT Family itself you will find out of various model I will talk about it it I will come to the open Ai and each and everything I will keep in front of you only and uh I will uh I will show you that how much it is powerful so we are talking about GPT so it's like really powerful and it it has been trained on a like huge amount of data and it is having a billions of parameter so here is few Milestone so in our back days in our history basically we are using this particular models now in a recent day we got so many uh architectures so many uh open source models and so I will talk about uh regarding those model as well so here in the next slide I have shown you so what all encoder based architecture we have what all decoder based architecture we have if we are talking about anod and decoder right so in which architecture you will find out both encoder and decoder if we are talking about B xlm Electra DTA so these all are these all the architecture actually it is based on an encoder we're talking about this GPT GPT family so it's a based on a decoder itself and the idea has been taken from the Transformer itself now here you can see this T5 Bart M2M big but so these are the model which are which is using this encoder and decoder both got it so now here uh then I talked about the openi based llm model so here uh the very first thing comes into the picture that is a GPD itself GPT 3.5 which is a like base model behind this chat GP chat GPT just a application it's not a model now here you will find out this Delhi whisper DCI there are many model I will be coming to that particular model and I will show you how you can get all the model from the opena itself and uh yes we'll try to use those model for our task for our like a uh for the for our like a like a requirements and all definitely will try to use this particular model like GPT GPT 3.5 I will show you how you can use GP 3.5 turbo viso da in or other model as well like aming and moderation so apart from that this apart from this uh like uh Milestone whatever Milestone I shown you and this openi based model here you will find out some other op Source model like Bloom llama 2 Palm is a model it's a very famous model from the Google side nowadays like most of the people are using this pal Falcon is a model cloud is there MP 30 uh MP is there uh this B actually it is showing a parameter right and here we have a stable Im so a stable LM so there are like so many open source model so I will come to that also and I will show you how you can utilize those particular model and apart from that I have like kept some more slight over here inside this particular PP so you can go through with that and you can understand some other uh like concept like how this chat GPD has been trained and all so I hope guys still here everything is fine everything is clear now we can move to the Practical part so please do let me know in the chat if everything is clear so far in terms of theory guys I'm waiting for your reply uh just a wait so let me give you the link of the website and uh yes guys I'm waiting for your reply so if you can confirm in the chat uh uh like everything is fine or not so that I can proceed with the Practical stuff yeah definitely this uh PP is already there so just try to enroll in this course the dashboard Bic basically which we have created this is our dashboard which you will find out over the Inon website so just try to log to your Inon website first of all if see if you are a new person so what you need to do you need to sign up after sign up uh you will login and after login you will search uh regarding this dashboard so here actually what is the name of the dashboard so the name of the dashboard is generative AI Community Edition so just click on this dashboard and here after clicking on this dashboard you it will ask to you whether you want to enroll or not so yes uh you will click on the enroll and it is completely free so it won't ask you any sort of a money and after enrolling into this particular course uh you can get the videos and you can get the resources as well so all the resources we have uploaded over here inside this resource section got it clear great so I think everything is fine everything is clear now let's start with the uh let's start with the Practical implementation so first of all guys uh let me clarify the agenda that what all thing we are going to discuss in today's session so for that what I'm going to do I'm going to open my Blackboard and here I will try to explain you each and everything uh like what what whatsoever we are going to like cover in this particular session so let's start uh let me write it down all the thing step by step now first of all I can write it down over here a day two Community session and then I will begin with the topic so here guys are day two of the community session now uh yesterday actually I I talked about the introduction part I talked about the introduction of the generative Ai and the llm now today I will be more focusing on the open a so here I will be discussing about the open AI so first I will give you the U like a complete walk through of the openai website of the openai documentation after that I will come to the openai API that how you can use this open API how you can use this open API and this API we are going to use by using this python so guys if you you know python so definitely uh like uh you will be able to write a code along with me uh and don't worry I will show you how to do the entire environment setup and all each and everything I will try to uh I will try to do in front of you uh from very scratch so uh you all can do along with me now over here I will come to this openi API and there I'm going to use Python and we have couple of more option like nodejs on all so if you are familiar with the JavaScript or maybe some with other language so in that case also you can use this openi API after that I will uh I will come to the openi playground so here uh they have given you very specific feature or very uh like uh very interesting feature that is what that is a openi playground so over here I will explain you that uh how you can use a different different model how you can uh like pass a different different prompts and how you can generate output how you can set up your uh like a different different uh sentiments and all regarding the system that okay so my system should behave like this or that so each and everything I will explain you over here and after that what I will do I will show you the chat completion API so I will use this chat completion chat completion and by using this chat completion actually uh we can call the GPT model so whatever uh like uh we can call the like openi API and uh with that definitely we can use any sort of a model like a GPT model or any other model so first I will uh start with the openi API we'll use we'll be using a python over here and I will show you how you can generate the openi key and after that I will come to the playground and assistant and then chat completion API and then I will explain you the concept of the function call function call now this is the agenda for today's session this is the agenda for today's Community class now before starting with the openi I will uh I will explain you that why openi is this much important why not other other like things or uh if we have like a other competitor of the openi that why we are not using that instead of this open ey and if we are going to use that then how we can do that okay and one more thing I would like to explain you over here so along with the open a I will uh talk about the hugging face so see over the hugging face actually hugging face is has provided you one uh hugging face hub for all the models so there you will find out all the open source model so directly you can generate a hugging face API key and you can utilize all sort of a model whatever is there over the hugging face Hub yesterday I have shown you that let me show you again uh that particular Hub so guys here once you will write it down so over the Google so once you will search uh once you will write it down hugging face model Hub so there uh you will get a link and you just need to click on that so here you will uh and then basically it will be redirecting to you to this particular model Hub now here you will find out all the open source model from a different different organization so yesterday I was talking about this Ora 2 now here you will find out other model as well like whisper large V3 now from the Facebook side there's a seamless okay now here you will find out other model as well so see from The Meta side there's a lamba Lama 2 so I will show you how you can utilize these particular model for the different different tasks according to your requirement getting my point so we will not restrict it uh we will not restrict to ourself to the till the open ey itself apart from that we'll try to explore few other model few other open source model and yesterday actually I have shown you one more platform and here's the platform AI 21 studio so it it gives you one model this Jurassic model so we can utilize that particular model also and this all are called large language model this IDE this thing is clear to all of you yes or no so uh what is the difference between hugging face and open AI so open AI is a different organization hugging face is a different organization and over the hugging face Hub see uh if you have heard about this Docker or this GitHub so first of all let me show you this GitHub so if I'm searching about this GitHub so here actually over the GitHub you will find out uh like see this is my GitHub and uh you all have the GitHub ID right you all have log to the GitHub and all and first you sign up and then you log in and whatever course and all you are having and definitely you are going to upload it over here uh in terms of repository now let's see if I if I have to find out something so what I will do here let's say if I'm going to write it down GitHub machine learning uh linear regression so GitHub machine learning machine learning linear regression so here if I will search uh like this then definitely I will get a link and here you can see so it has suggested me one repository and you will find out uh this uh code and all whatever code and all has been uh uploaded by this particular person and definitely you can download it and you can use it similarly we have a Docker Hub similarly we have a Docker Hub so let me show you the docker Hub so the docker Hub actually you will find out all the images and all so let's say uh like uh you downloaded Docker in your system you did setup and all now uh you don't want to install it from scratch you want to run it by a Docker so yes there is a Docker Hub and there you'll find out different different images and all so you can uh like uh you can pull that image and definitely you can run it inside your container so similarly we have a hugging face Hub there uh like it is uh it it is going to provide you a different different model actually on a single place so yes uh just uh you just need to log in over there and after that you need to generate a API key and directly you can use those particular model whatever is there like over the hugging face Hub now similarly we have openi it's other another organization so yes by using the openi API we can access the open a model as well so here uh okay so if you will find out if you will see to this open a this one this is the open a right now I will show you what all models this openi is having it is having a different different model various model I will come to that I will show you from very scatch so till here everything is fine guys everything is clear so uh just give me a quick quick confirmation so that I can show you the entire setup related to this opena API and we can run a couple of uh couple couple of line of code as well so please do let me know in the chat if uh everything is clear so far yes we'll talk about the fine tuning and all so how we can uh do the fine tuning regarding a different different model uh it's not a like easy task it's a a very expensive thing so we'll talk about it yes hugging pH model are free yes correct for building a model uh so for using uh if you want to use that particular model so either I can use open a so or else I can use hugging phase see whatever model is there over the hugging for definitely we can access that but let's say open a is having there uh like a uh it's a separate platform right so whatever model is there over the open a so we'll be able to access those model only from the open a not all the model which is there inside the hugging face also but hugging face actually is having all the models open source and all whatever model is there and some of the model from the openi side as well but openi actually it's a specific specific one specific organization clear yes or no so please do let me know if uh this thing is clear to to all of you so that I can proceed with the uh next part next section great so people are saying sir it is clear clear clear okay great yeah the model is already created over the hugging face and open ey they already trained the model we don't have all the models in the ging phase that's why we are learning this open great so I think uh all the thing uh like each and everything is clear to all of you now let's start with the uh like uh next part of this session so here I have uh discussed about this open Ai and this hugging phase and I clarify the agenda that what all think we are going to discuss but before starting with the open AI so let me give you the a brief introduction of the open AI that why this open AI is too much important so for that what I did I have created one small PP so with that actually you will get some U uh some basic idea uh regarding this open AI so here uh let me start uh let me start the slideshow so over here guys you can see about the open if we are talking about the openi so what is the openi open a is leading company in the field of AI it was founded in 2015 as a nonprofit organization by same Alman and Elon Musk as we know about the uh founder of the like open a so yes uh I think we are we are aware about uh with this particular names right same Alman and this Elon Musk and it has founded in 2015 as a nonprofit organization just for the research purpose now here in the next slide I have kept the name so he's a like he's a CEO of the open a Sam Alman and uh yes I think you know about the Sam Alman he was fired by the open board we'll talk about that also what what might be the reason behind that so we will discuss about that uh as well now over here you can see uh openi founded in uh 2015 and the company founded with the goal of developing and promoting friendly AI in a responsible way that was a logo of the open AI so with the focus on transparency and open research and he was the and they are the founder member of the like open a so Elon mus Sam Alman Greg Brockman okay this guy is a like great researcher and vak and zon so these are the founder founding member of the open AI now over here are open goals so there are some goals of the open related to the AI and all now openi Milestone so I was talking about that why this openi is too much important why not other does because if you will look into the market there are other uh there uh there are you will find out other organization as well uh so we have a Google and Google is having their separate Department Google uh AI research and all so Microsoft is also having their own department for the AI research even meta is having that even IVM so all the like big big giant so there they are having their own research uh like Department related to this Ai and all and they are working on that and they were working on that actually but why this openi is too much popular and why we should start from the openi itself so you know about the openi in 2020 actually they have launched the Chad GPT and guys believe me it was the Milestone and it was the major breakthrough in the history of the AI because before that also we are having so many llm model and it was able to do uh some sort of a thing but not like to not similar like to this GPT this GPT actually the GPT model which is a backbone of this Chad GPT application uh it was a a breakthrough in the history of the NLP and because of this this open AI came into the Limelight and uh apart from the GPT then uh uh like they have shown or they have released the other different different research so here here I have written couple of name basically so generative model is one of the Milestone of the open now apart from that you will see that they are going to uh they are going to participate in the robotic research and all and here uh like other uh like other few more thing basically so solving uh robic Q with a robot hand and here multimodel neurons and artificial neural network you can search about uh this particular things and yes uh this open ey actually it become uh very uh important uh basically because of this uh like GPT and all because of this uh chat GPT application and yes they were using a different technique for training this uh GPD model which we are using for the chat GPT and the idea from where they took the idea uh for training this GPT model there we have unsupervised learning we have a supervised learning and we have this reinforcement learning so they took from the ULM fit research paper yesterday I have shown you that which has been published in 2018 and in 2019 in 2020 actually they have released this GPT GPT got it now here you can see buildin with open AI API so these are couple of name getup copilot keeper Tex Bible dingo so these are some application which is using this openi API and apart from that you will find out so what is the openi vision so the vision is like uh promote a friendly AI in a way that benefit all the humanity and all so this is a vision of the openi now feature so chat GPT Delhi whisper alignment so so these are the feature of the open AI Chad GPT is a a milestone Delhi is also there Delhi 2 recently they have they have released the Delhi 2 whisper is uh one of them whisper actually it is a very good model for generating a transcript and all so whatever like text we are giving or whatever like videos we are giving to this particular model it is able to generate a transcript from that and here uh alignment is there startup fund so these are some feature of the open AI now guys uh before starting with the open AI API I think got enough amount of idea uh regarding this open AI yes or no please do let me know in the chat if uh this part is clear so I will proceed with a uh open a API so how you can generate a key and all and how you can utilize that yes are you getting guys whatever I'm explaining you over here uh if you have any sort of a doubt anything so you you can ask me in a chat section I will reply to all of your doubts so step by step we'll try to proceed uh and uh so each and everything will be clarified great so clear yes waiting for your reply uh if you can write it on the chat so then I will proceed what is the learn tool what is the aim to learn open AI so that I can utilize the same capability same AI capability in my application whatever model has been trained by the openi so that I can use the same model in my application for a different different task great so I think I have uh discussed each and everything related to the open a now this is the website of the openai so if you will search openai definitely you will get a website of that so in the website itself they have mentioned everything so latest update whatever uh latest update and all it is there so they are mentioning over here and Sam Alman return as a CEO of the open a I think you know about this controversy of the open a so let me uh give you some sort of a glimpse of that uh if you know about the open a so it was founded as a nonprofit organization but uh in 2019 actually they have uh started with their uh forprofit organization as well if you will search about the four profit organization of for profit organization of this open a so in 2019 actually they have started this a for profit organization and uh it was doing uh lots of work uh regarding this Ai and all and they collected uh like uh funds from different different companies and all from a big big giants and uh they were working on the G GPD model itself okay now after that uh this chat GPD has been released and in 2022 actually 2022 or 23 basically so uh they started work on a uh like a different type of project so the project name was the qar the uh basically the project name was the qar and it was more specific to it was more specific to towards this AGI so may I know guys what is the full form of the AGI if if you know uh the full form of the AGI so please write it down in the chat what what do you uh understand with this AGI so the full form of the AGI is please write it down in the chat if you know about the full form of the AGI please do it yes artificial Journal intelligence correct so the full form of the AGI is artificial Journal intelligence actually see we talking about the chat GPD now this particular application it's not it is not representing a general artificial intelligence it is a restricted one it's a specific one getting my point so let's say there one side there is a Chad GPT and one side there is a human so definitely this Chad GPD can answer in a better way it can generate answer in a better way compared to this human but still it is not like a human so still we are not on that particular level where we can achieve a artificial intelligence like a human that is called artificial general intelligence and the project name was given by this openi the project name was the qar and that was happening in the forprofit organization this is the subsidiary of the open itself getting my point now because of that uh so there was a conflict in between the board member and uh this uh Sam Alman was fired and now again he joined the company uh there is a long story story but yeah I have given you the Glimpse you can search over the internet and you can uh read about it U okay so if you like to read the AI news and all AI related news news and all so definitely uh you should check it on a daily basis because on a daily basis there's something is happening on a teex side on a like organization side uh whatsoever so over here guys uh here you can see the open a website now if I will scroll down so you will find out each and everything over here itself that what all research is there uh what all upcoming models is there uh on whatever applications they are working so each and everything actually you will find out over here itself so here uh recently they have released this Delhi 3 so in October uh 20123 3rd of October 2023 they have released this Delhi 3 there was a GPD 4 gp4 Vision where we can uh upload the images and we can do a lots of lots of task related to the images and all getting my point so here you will find out a research whatever latest research is there from the open a side no need to go anywhere everything you will find out over here itself if you want to start from the open a if you are using this open a in your organization if you want to use it and before that if you want to explore it so please go through the website and here you will find out each and everything now guys here is a question I told you that why uh what is the open a now why we are learning it I have to give you the specific answer of this particular question if you will ask me S why we are learning this open a what is the main Aim so now let me tell you that so first of all guys after opening this opena website what you need to do you need to log in it you need to log to this particular website and here you will get two option so the first option is a chat GPD and the second option is a API so we all know about this chat GPT I think uh we all have used this chat GPT and I think we are using it on a daily basis now we are not going with this chat GPT we are going with this API so I will click on this API option and once I will click on this API option so I will get this type of interface so I believe guys you all are getting this particular interface after clicking on this API please do let me know in the chat if uh everything is uh uh like going fine uh like me so please do let me know in the chat great so yes I think uh people are doing along with me now see guys here is what so here is a uh like open a API uh so once you will click on that you will get this particular interface now just uh overover your mouse left hand side and here you will get a different different option or various option now what you need to do guys for here first of all you need to click on this documentation so just click on this documentation and you will come to this particular page now here you will find out this overview so here they have given you the complete overview about the openi API that what all things they have and uh for what all applications we can use this openi API now here you will find out the introduction section as well so in the introduction section they have defined some sort of a thing related to a different different task like text generation aming assistant tokens and all now here you will find out the quick start so let's say uh you want to explore this open API so what you will do at the first place so after opening this open uh a openi API and after opening this after opening this particular documentation you just need to click on this quick start so after clicking on this quick start you will get all the code which initially you need to run inside your system getting my point if you want to use this open API if you want to use this openi API and you want to run the code if you want to start then for that what you need to do you just need to click on this quick start and over here you will find out uh different different option so let's say you know the nodejs so here you can click on this nodejs and you will find out entire setup related to this nodejs how to install the package how to uh set the key and all now here you'll find out the different different uh like Windows different different operating system related option and here you will find out the code snippet so directly you can run it and you can use it now if you are a python lover if you know the python only in that case yes they have given you the option so you just need to click on this uh Python and here you will find out the complete setup guide so how to install a python how to install how to create a virtual environment how to install this openi Library so and after that you will find out this uh setup openi key uh regarding this Mac OS and windows now here you'll find out how to uh request to your openi uh API how to request to the different different models so here is a code snippet so we are going to use this particular process uh if uh so yes you can use the same process don't worry I will show you how you can do the entire setup and all and how you can call the different different model now over here you will find out a model now guys this model actually this model is a uh like a very important part of the openi API now here they have given you the various model like GPD 4 gp4 Turbo G PD 3.5 Delhi is there TTS is there whisper is there iding moderation GPD 5 is there GPD 3 which is a legacy now and here you will find out some deprecated model so here they have given you some a deprecated model like uh GP 3.5 Turbo with this much of tokens and here you will find out this text Ada Ada text weage text cury text DaVinci so these are the depricated model you can use it if it is required definitely you can use it so here you will get a complete list of the model whatever model you want to use for your task for your particular task now over here uh this is the uh like overview regarding the model now if I'm clicking on this GPD 3.5 so once I will click on this GPD 3.5 so here I will get a complete detail regarding this particular model now here is a what here is a model name so what is the name of the model GPT 3.5 turbo 1106 okay now over here you will find out two things so the first is what context window now in the context window you will find out the number of tokens now guys this tokens actually the number of tokens displays a very very important role if we are talking about this tokens so really it plays a very very important role and I told you if we are giving an input to our model to our LM model so we'll give in the form of prompts and prompt is nothing it's a collection of token so whatever input and output we are getting we are getting in the form of prompts right so we are giving a prompts to our model and we are getting a prompts from our model and this prompt is nothing it's a collection of tokens now we'll talk about this tokens and all then how much token is uh so as a return actually how much token you can get as a output as a free one actually this uh Chad this open a actually it stopped the free services now so before actually uh uh you would be getting this uh let me write it down over here so $20 of credit so earlier if you have used this uh open a so you must have seen that uh if you are uh like uh if you are going to create a open API key so in that case it was giving you this $20 free credit now they have stopped this particular service now they are not giving to you so first of all what you will have to do so first of all you will have to add the method a payment method actually so so you will have to add your credit card or debit card details and after that you will have to set your limit let's say $20 $50 $100 or whatever uh like limit um actually you find out it is fine so inside uh in that basically in that particular limit uh my work will be done so first of all uh you need to add the payment method and you need to set the limit and then only you can use this open API so recently they have updated this particular thing now we have alternative also so we have this AI 21 lab so I will uh show you this uh thing as well where we have a Jurassic model and it gives you the $90 fre free credit $90 free credit but you won't be able to use this GPD 3.5 because it is only it is only available in this opena itself if you want to use this GPD 3.5 model GPD 3.5 turbo or gbd4 so it is only available in the opena itself and they haven't open source it and for this one you will have to pay if you want to use it in your organization in uh with respect to your task so definitely you will have to pay for that getting my point now over here guys see uh it return return a maximum of 4096 output token so regarding this particular model now here you can provide this much of tokens actually so this much of tokens as a uh input as a input basically and you will get this much of token as a output if you are going to use this particular model now here GPD 3.5 turbo So currently point to GPD 3.5 turbo 0 613 will Point GPD format turbo 11 starting date this is this is the starting date and here this is the token size now here this is the token size basically they have given to you so you can uh provide this much of token and here you will be getting output in uh like as uh this is the maximum token size actually uh with respect to this particular model so you can go and read more about this model and all and here you will find out this training data so this uh model has been trained up to 2021 SE number 2021 and here uh these all are the model so I will uh use any sort of a model from here itself and I will show you how you can hit it by using this P openi python API now apart from that uh you will find out some other uh thing so let's say if I want to do a text generation so they have given you the complete detail regarding that and here they have given you the API endpoint as well so you can click on that and here in this particular way actually you need to write a prompt and all you need to define a prompts and all uh so actually this is the uh rate assistant uh as of now it is not working so you can click on that or you can use it this API endpoint inside your application so uh here they have given you the code that if you want to perform this particular task this text generation task so directly use this Uhn code snippet after setting up the environment and all after generating the openi key and you can perform this text generation over uh text generation if uh this is required according to your uh like application and all now over here you will find out the other option so embedding is there so embedding is nothing uh embedding actually you are just going to be uh convert your text into a uh some numeric uh numbers and here uh this ambing comes into a picture and this this is very robust model from the openi side and definitely you should use it uh I will show you how you can utilize this particular model and you find you will find out the complete code in s it and all and yes you can generate a Ming regarding your test Ming is nothing it's just a numeric representation of your text now here uh if you want to do a fine tuning so regarding that also you will find out a complete detail so how you can do a fine tuning and all now image generation is also there so if you want to do a image generation so which model you should use from here Vision related to The Vision also there is a GPT 4 now Vision related facilities it is there inside the gbd4 itself text to speech speech to text moderation so no need to train your uh no need to train your model your uh NLP model from scratch now so they are giving you everything you just need to call the API and you can utilize it now many people are asking to me that sir what is the aim to learn behind this open ey and all so the aim is very very simple if you want to use this particular model for your uh uh different different task the task basically which they have mentioned over here you can directly use it you no need to like train it by your yourself because this model has been trained on a huge amount of data now that's why it is called llm I told you clearly right yesterday what is the meaning of the llm and yes uh in most of the cases in 99% of the cases it will work fine if let's say if you want to do a fine tune this particular model so definitely you required a higher resources and in that case you will have to pay to the openi as well getting my point so here you can read uh entire detail regarding this fine tuning and all so once I will come to this fine tuning part I will explain you this uh thing as well how to do the fine tuning and all regarding this model definitely I'm not going to do it uh in the live class but yeah I will give you the uh quick guidance regarding uh this fine tuning so I hope guys uh this model related thing model related part and this quick start and this introduction and what of capabilities is there so this thing is clear to all of you if it is clear then please do let me know in the chat yes or no so waiting for your reply please do let me know in the chat what what are the job opportunity after this particular course so after that you can apply as a NLP engineer uh you can work on a gentic way related project you can work uh as a uh gen VA engineer so if you are going to complete this particular course so after that you can join uh the company uh like whatever designation I told you on that particular designation and uh here in an interview do they ask from the scratch inside of using API no they won't ask you that you need to like uh you just show them like how to use the API and all no they won't ask you this particular thing uh they you just need to tell you what was your use case which model you have used and uh what was the cost regarding behind that particular model uh how you you have designed your prompt template how many tokens basically there uh you were uh defining inside your prompt in U basically inside the input input prompt and how much tokens basically you are getting inside the output prompt okay so these are the thing uh like uh they might they might ask you regarding this uh uh like openi API and all and open AI models uh they won't ask you that uh generate this key that key or whatever do we need to learn all the underlined math behind the model hugging pH and open ey yes the architecture should be clear so the architecture part should be clear uh architecture means what so uh the base architecture Transformer architecture they definitely they might ask you the or Transformer architecture in one of the interview they they have asked to me that uh can you uh explain me the Transformer architecture what is the meaning of the positional uncoding why we are using a skip connection over there and can you code it as well so if you want to use this Transformer in the python how you can do that which uh like which Library you will call or can you write it down the code from scratch so this type of question you might face if they are going on a architecture level they won't ask you the uh they won't ask you the architecture of the different different model which is there over the hugging face and all no they won't ask you that so can we proceed now if uh this part is clear tell me guys fast yes or no I given you the complete walk through of the open uh website openai API now I will show you how you can utilize it and don't worry guys I will uh show you the advanced thing as well I will show you the advanced part as well uh I will show you this function uh calling and all and uh first let me complete this uh uh chat completion and after that I will come to the function calling great so here uh I think this thing is clear now let's try to start with the Practical implementation so for the Practical implementation first of all uh what you need to do so let me uh write it down the step all the step so here uh the first thing what you need to do see uh you should have uh you should have this uh Anaconda inside your system I think you know about this Anaconda what is this Anaconda it's a package uh it's a package manager for the data science projects and all so you should have this uh Anaconda inside your system the second thing uh python must be installed python must be installed all now here whatever practical which I'm going to do so I'm going to do by using the Jupiter notebook so here let me write it down uh the Jupiter notebook now whatever practical and all whatever I'm going to do I'm going to use basically I'm going to do by using this jupyter notebook in the next class uh I'm going to uh create an end to end project first of all uh before starting with the end to end project I will come to the Len chain and there I will explain that each and every concept of the Len chain that how it is different from the openi and why should uh why we should use it and after that once I will come to the end to project then I I will start from the vs code itself vs code Visual Studio code so any ID you can use I'm not restricting you for the ID and all so if you are familiar with the py charm you can use that also if you are familiar with the like any other ID you can use that but yeah I love this vs code so uh for the project for the end project I will use this vs code as of now I going to use the Jupiter notebook uh just for the uh like open a uh python API uh so guys if you have this two thing this three thing actually inside your system so after that what you need to do you need to create one virtual environment so uh here by using this cond by using this cond you need to create one virtual environment I will show you all the step don't worry so here you need to create a virtual environment there inside after creating a virtual environment you need to activate it activate this virtual environment and here you need to install all the packages all the required packages inside this virtual environment so here you need to install all the required packages so let me write it down over here install all the required packages now uh required packages means what required packages means so you need to install this open a as of now and we have other packages also like pandas napai and all so if I will be uh if I will be having any sort of a requirement uh regarding the pandas numine uh or regarding any other packages so definitely I will install that also in my virtual environment now after installing all sort of a thing so after like creating a virtual environment after activating it and after installing all the packages then what I will do I will be starting with the Practical implementation so guys in my system I already having Anaconda so you can uh download it by searching this Anaconda so just go through with the Google and search over here Anaconda download so on once you will search this Anaconda download so here you will get the website uh here you will get a link so just click on that and here you will get a option for downloading this Anaconda now uh it is giving you the option based on your operating system so if you are using Windows if you using Mac or Linux according to that you can download this Anaconda now apart from that uh one more thing will be required so if you don't have python in your local system so you need to download that as well so python uh download so here I'm going to write down the python download and yes uh this is a website of the Python and uh here you need to uh here basically you can uh download the python by clicking on this particular website I would suggest you uh download this 3.10 or 3.11 don't download the latest version this 3.12 or this 3.13 actually uh it is having some sort of a like issues so better uh okay don't download this 3.11 also either download the 3.10 or 3.9 it will be working fine or you can download this 3.8 also this all three version is a stable version fine now after downloading this anaconda and this python inside your local system then what you need to do so once you are ready with the Anaconda and this python after downloading and installing and all you need to search Anaconda prompt so here uh you will find out the uh like Anaconda prompt so once you will search over here in the search search box Anaconda prompt so there itself you'll find out the Anaconda prompt now this is what this is my anaconda prompt guys this one now here actually this is what it is it is showing me a base environment as of now this base is a by default environment now here what I need to do I need to create a virtual environment how I can do that how I can create a virtual environment so for that we have a command now here the command is what cond create so cond create hyphen n and here I need to write it down my environment name so here my environment name is what testing open AI so testing open AI this is what this is my environment name you can give any XY Z name over here I don't have any issue now you need to mention the python version so here you need to write it down the python equal to 3.8 now guys here I'm going to use 3.8 you can use 3.9 3.10 don't use 3.11 12 and 13 3.8 7 9 10 these are the stable version and you can use it for your project now as soon as I will hit enter ENT so yes I will be able to create an environment so yes let me hit the enter and it is creating an environment so are you doing along with me if you are doing along with me then please do let me know in the chat guys yes I okay so people are saying yes we are doing it can we do sir using API as well as our make model if you have trained your own model then definitely you can do it great so many people are doing a lot with me I think now here you can see so uh this is what uh this is my base environment sorry this is my base environment and here I have created a virtual environment and this is my virtual environment if I want to activate it so for that this is the command so here you need to copy this command and just just paste it over here and so you will be able to find out that I have uh I'm able to activate my environment now you can clear the screen so for that you just need to write it down the CLS and here is what guys here is my virtual environment now here what you will do see uh first of all you need to check that what are libraries is available inside your virtual environment so for that you can write it down the command the command is what the command is PIP list so once you will write it down this pip list here you will find out all the library what ever is there as of now inside your virtual environment so these are the library which is there inside my environment and here I uh still I haven't uh downloaded this uh open open Package because by using the open by downloading the openi package only by using that open Package only I can hit the API getting my point yes or no so don't worry I will give you the entire step whatever step I'm following over here now here first of all you what you need to do see I took told you over my Blackboard that after creating a virtual environment you need to activate it and then you need to install the required package and before that I told you one thing that everything I'm going to do inside the jupyter notebook so guys here in this particular environment in this virtual environment you need to download or you need to install the Jupiter notebook and for that we have a command so let me write it on the command pip install Jupiter notebook so here I can write it down g u p y t e r n o t e b k so this is the command pip install jupyter notebook and with that you will be able to download the jupyter notebook and oot te so this is the correct spelling let me rewrite it again yeah so installing J notebook are you doing along with me tell me yeah so here let me write down the command in the chat section so cond create hyphone n and you can write it on environment name whatever you want to write it down so let's say testing open a and here python version is what 3.8 so this is the command uh you need to run this particular command for installing the sorry for creating a virtual environment now let me give you one more command so here you can check all the listed uh Library uh all the like Library whatever is there inside the virtual environment pip list is a command now let me give you one more command so here is one more command pip inst install Jupiter notebook so pip install Jupiter notebook so these are the three command did you get it uh please do uh confirm in the chat please give me a quick confirmation the chat see if you're not installing this Jupiter notebook in your current virtual environment in that case it will launch the jupyter notebook from your base environment so it is a better practice if you are creating a virtual environment then please install the jupyter notebook or please install the ipnb kernel over there so now if you will find out uh now if you will search pip list over here so just search pip list now once you will search pip list then you will find out lots of libraries or lots of packages which came along with the jupyter notebook now see here you can see all the packages and all after installing the jupter notebook now once I will write it down the Jupiter Notebook on my anaconda prompt so here let me write down the Jupiter notebook and it will open the notebook so once I will write it down the Jupiter notebook and you will see that yes it has open the Jupiter notebook so got it guys yes or no please do let me know in the chat if you are able to launch your Jupiter notebook if you are are able to launch the Jupiter notebook then please do let me know in the chat yes or no yes and after that you need to launch your file so you need to launch your notebook so click on this notebook and here is what guys here is your notebook so this is your notebook and each and everything we are going to do here itself inside this particular notebook now uh just make sure that you have this python uh Python 3 over here uh this uh ipynb kernel if you don't have that so so please try to select this Python 3 ipy kernel and I think now everything is ready so let's try to oh let's start with the open API so test open API and now let me rename it so here guys you can see this is my test openi API uh this is my file actually this is my notebook I hope you all have created this particular notebook if you have any doubt then please do let me know in the chat everything is clear everything is sorted please guys go ahead so just be a little interactive uh please write it down the chat if I'm asking something so if you if you can if you'll write it down the chat so definitely I will get U motivation great so now let's start with the uh like open AI API so first of all what you need to do so here is what here is my notebook so let me do one thing let me keep it uh keep this notebook over here itself and this is what this is my Jupiter notebook so first of all just go through with the openi website so here is your openi website guys this one now here you need to click on this quick start here what you need to do here you need to click on this quick start after clicking on this quick start so here they have given you the option the option is what python so here they have given you the three option Cur Python and node.js so click on this Python and here they have given you the complete instruction so first of all guys what you need to do you need to install a python so yes uh I think you already have installed this python you need to set up a virtual environment yes we set up the virtual environment and why this virtual environment is required so see uh for uh one particular project we have a lots of dependency if I want if I want to if I want to segregate all those dependency project to project okay so for that only we create a virtual environment so what is the requirement of the virtual environment because we have a several dependency on a single project if I want to keep it apart for that only we create this virtual environment got it so here they have created a virtual environment directly by using this python uh en and you can use this also for creating that but I'm using the Anaconda now here after that you need to install this open AI so here uh what you need to do guys so here you need to install this open a package and then only you can hit the open API getting my point so just copy this particular command and install this openi package in your virtual environment so here is what here is my virtual environment let me open that particular environment uh just a second what I can do here I can keep it this to my same TP fine now over here guys what you need to do you need to open your anaconda prompt see here actually I have launched this jupyter notebook so you cannot stop the server of this jupyter notebook so I'm opening a new Anaconda prompt so here you just need to write it down this Anaconda prompt and you will be able to launch a new Anaconda promt now guys just tell me what is my environment name testing open AI so here uh you just need to write it down uh cond EnV list so once you will write it down this K EnV list k EnV list so let me write it down this cond EnV list so you will get all the all the environment name so here guys you can see this is my all the environment which I have created in my system by using this Anaconda now uh here uh this is my environment testing open I want to activate this particular environment so I can write it down over here cond activate and here I can write it down my environment name testing open AI so once I will write down this and if I will hit hit enter so I will be able to activate my environment I'm going to uh I'm going to do a uh transition from base environment to this testing openi environment this is what this is my virtual environment this base environment is a default environment now over here what I will do I will I'm going to write down the CLS for clear the entire screen now over here I will just paste this particular command pip install hyphen iph upgrade open AI now once I will hit enter so yes uh I'm able to install this open AI inside my virtual environment so are you doing along with me are you able to install this open AI inside your virtual environment if yes then please do let me know in the chat in the virtual environment you need to install the jupyter notebook by using this pip install jupyter notebook command if you're not doing it in that case it will be taking a jupter notebook from the it will be launching a jupyter notebook from the base environment many people now people are saying yes we are doing it how many of you you are doing along with me please do let me know in the chat how many of you you are doing along with me yes yes yes okay great yes please write it down the chat if you are doing along with me then if you uh launching uh jupyter notebook from the base environment it will take a all the packages from there itself that's why I want a fresh one that's why I'm installing jupyter notebook in my current environment now over here I think I have already installed it so yes it is done now and if I want to check it so for that I'm uh I'm opening my jup notebook again and here you need to write it down uh import open AI so just write it down this import open Ai and here guys you can see we are able to import this open AI if you are done till here then I will proceed with the further python code so please give me a quick confirmation in the chat if you are able to import this open I'm just I'm waiting for 1 minute I'm waiting for uh 1 minute uh to okay so please uh give me a confirmation in the chat if you are able to import this open AI inside this jupyter notebook we are ready to go great now uh let's start with the uh open API that first of all guys we need to understand that what is what is this openi API so for that what I did I kep uh I return like uh some sort of a like uh um wait let me do one thing over here let me copy and paste yeah so here guys what I did I written some sort of questions and answers and here the first question is what the first question is what is open a API so by uh uh like uh so here by using this particular question so by reading this particular answer actually we can understand that what is this open API so this openi API has been designed to provide developer with seamless access to stateof Art pretrained artificial intelligence model like GPD 3 GPD 4 Delhi whisper ambing Etc so what is the meaning of it so if you want to use if you want to use the same model whatever model has been trained by the open AI so these are the different different model uh the name basically I have written over here GP 3 gbd4 Delhi is a model whisper is a model aming there are different different model right if you want to use this particular model inside your application so that uh so then basically you should use this open API now over here by using this openi API you can integrate Cutting Edge AI capabilities so this model actually it's a large language model and it is having a lots of capability in terms of a different different task as I explain you so by using this particular models you can uh like utilize uh that capability you can utilize the capability and uh you can utilize that particular capability and you can integrate inside your application getting my point and regardless the programming language so here they have they have given you two option so the first one is a Python and the second one is a nodejs so uh what is this open API so this open API is nothing it provide you the seamless exess of a pretrained artificial intelligence based model uh for your uh like a different different application whatever application you are going to create and let's say if you are going to create any individual application which is based on NLP use case yes directly you can uh use this particular model instead of trading your model from very scratch now here so the conclusion is what so the conclusion is by using this openi API you can unlock the advanced functionality and you can enhance the intelligence and performance of your application so let's say there is Inon website and the Inon website you must have seen the chatbot option so in the chatboard actually uh you are doing uh you are connecting with our expert so let's say there there's a one person who is having a doubt so now this person what he is doing he is going to be connect with a uh like expert so here is the expert which is sitting behind this particular chat board now he is asking the question and he's getting a reply yes or no now guys just see over here so here uh like you have integrated this chatboard and this chat board is a uh it's not a like eii related chatboard so the person so here uh in the behind behind behind to this chatboard actually when expert is sitting he is giving you the answer now you want to uh like uh what you want to do guys over here so you want to use some sort of a AI now here you want that that type of model which will be able to answer all of the answer basically whatever the person is asking like chat GP so in that case you cannot train your own model if we are talking about if we are talking about like the llm model so in that CA in that case basically you cannot train your own model because it's a very very expensive let's say if you if you are just a startup okay or let's say if you are just a Learner in that case in that case you cannot invest this much of amount for training this particular model because it's a expensive process if you are going to set up the infrastructure if you're are going to uh like if are like hiring a developer ai ai developer and all amops engineer so in that case definitely the cost will be around 1 to 10 CR because in that case you will have to create a distributed setup you will have to purchase a gpus there should be a team one proper team okay for the monitoring and all for each and everything there there will be a developers so the cost will be very very high in that case what you will do if you want to uh take advantage of this AI uh cap if you want to take a leverage of this model whatever model model has been created or trained by this open a what you will do you will use this openai API you will uh call this open API and by using this openi API you will be able to access this GPD model and directly you will be able to uh like append this model inside your chatboard so whatever person is asking definitely your GPT will be replying in that case and let's say any escalation is is happening in that case so definitely you can uh write it down your logic your code in uh in such a way that this request will be moved to the expert and now the it will be handled by the expert itself so like design you can like this basically you can design your system this is just a one example which I have given to you great I think uh everything is clear now over here so what is opena API this part is clear now the second question is what the second question is generate a open a API key so here what I have to do I have to generate a open API key what I need to do guys I need to generate open API key without this I cannot use the open API without this particular key so for that what I need to do what is the process let me tell you that so if I want to generate if I want to generate a open a API key so just go through with the open a website so here is your open a website and here just over your mouse uh on this particular side on the left hand side now here is the option this API key just click on that and here guys you will find out a option to generate or to create a new secret key are you getting this option are you getting this particular option please do let me know in the chat if you're getting it then after logging in to the openi website then only you will be able to find out this API key option and guys uh you cannot uh generate a openi key without adding any sort of a payment method so first of all you will have to add the payment method and don't worry in the next class I will show you how you can use hugging face API key for the same thing for the same task definitely we won't be able to access uh other uh models like gbd3 GPD 3.5 turbo or gbd4 and all but yes uh we'll be having access of a different model different open source model or whatever model is available over there in tomorrow's session I will show you how you can utilize the hugging face API key you you can finetune the model again it will be an expensive task Vishnu great so here you can see we have a uh like option to generate a like here basically what we can do we can generate a API key now for generating a API key you just need to click on this create a new secret key and here you need to give the name so let's say I'm going to write down the name uh my API key so this is the name of my API key once I will click on this create secret key so yes uh definitely I will be able to generate it now guys over here you can see this is my key uh definitely I will delete it right after the session otherwise you will exceed uh the limits and all all right so here I have generated my key and after the session I will delete it so no one will be able to use it so I have generated a key now what I will do I will paste it down in my Jupiter notebook over here so here is what guys here is my key so this is what this is my key basically which I have generated so here uh let me uh paste it down this particular key this is what this is my key now you have to generate your own key okay and don't share your key with anyone else so here this is what this is my key now what I need to do after generating this open a key I have generated the open a key and I kept it over here now after that I need to call the open AI API so how we can do that so for that we have a couple of couple a couple of line of code so let me paste it over here or let me write it down over here and then I will I will show you how we can hit any sort of a model now for that uh basically what I did so over here uh just a second yeah so first of all let me show you the list of the model as well now over here I can write it down uh one line of code so open a uh do API key API unor key and here I need to write it down my key here I need to write it down the variable basically where I have kept my key so once I will run it so here you can see open AI open AI API key yes I'm able to set my key now here I will call one method so my method name is what open AI dot model model underscore uh model. list so once I will call this particular uh method so here you will be able to find out your all the model see there is all the model basically which is available as of now now in the openi plateform now here you can see it is giving me some uh it is giving me output in a different way so what I can do I can convert it into a list so over here what I can do I can convert this uh particular output this particular response in a list so here uh this is my all the models so I can create a variable allore models and here I can pass this thing to my list method now see guys uh I will be getting all the model all the models uh whatever model is there inside the openi so the first one is a text search weage uh doc 001 and here is a date actually they have mentioned the date or maybe the version uh now the created when they have created and here is a object object is what model and owned by owned by open AI de now here what you can do you can create a uh data frame also so what you can do you can create a data frame so here uh let me write it down the code for the data frame so import pandas s PD now here I can write it on PD do data frame so here what I need to do you just need to pass this particular uh you just need to pass this particular value this one so let me keep it over here uh this uh list uh list of all the models so once I will run it so here you will be able to find out is giving me error the pandas is not there so for that uh just download the pandas or just install the pandas inside your virtual environment because in this virtual environment pandas is not available so let me write it down over here click install pandas and once I will hit the enter we will uh we will be able to install this pandas it will take some time so let it install yes I'm coming to the code I will show you the code just wait for some time just wait yeah so I'm done with the pandas I have installed it and uh now what I can do I can run it and you will be able to find out your data frame so here this is the model this is the like when it is created and object is what object is a model and owned by so now it is in a perfect format and you can read each and everything clearly and here I can provide the column name as well so let me give the column name let me write on the column name as well and here I already WR the code of for the column name so once I will run it so here you will find out the column name so here is my ID this is the like model ID and when it has created what is a uh like what is this actually so it's a object is a model now here owned by owned by this openi development team openi internal openi development or here you will find out some other name as well so I believe you are able to run this entire all like entire code whatever I have written over here now here uh this is what this is my code for uh seeing the model and all now the next thing uh here I got all the model now the third thing basically which I would like to uh explain you that is what that is a open AI Playground open a playground and after that I will come to the chat completion API now I will take uh more 15 minute and within that uh I will conclude this session and in tomorrow's session I will start with a chat completion a uh this function call and I will explain you the uh the hugging face API key as well so how you can utilize the hugging face API key for a open source model now let me copy and paste the entire uh thing whatever I have written for you so here here I have written some sort of a thing let me go through step by step so here I'm talking about this open AI Playground now what is this what is this open a playground now once you will uh search over the Google so open your Google guys and here search open AI open a playground now just search over here open playground and uh here you will find out this Playground now once you will click on this assistant so here you will find out a different different option so one is a assistant the second one is ched third one is a complete fourth is a edit I'm not going through with this complete and this edit because it's the Legacy now I will explain this chat first I will explain this chat and then I will come to this assistant now inside this chat uh so once I will click on this chat so here I can test uh my different uh I can test like different different prompts and all I can generate output I can test with a different different model and along with a model you will find out a various parameter so so first of all guys what you need to do you need to set you need to set your system right so here you will find out three options so the first one is what first one is a system the second one is a user and the third one is this one right so you can divide this entire interface into a three segment now let me give you step by step that what is the meaning of the system what is the meaning of this uh user and this assistant and what is the meaning of this model each and everything we'll try to understand over here so guys system is what so system is means system means uh how your model is going to behave here you are going to set the behavior of your system what you are doing tell me here you are going to set the behavior of your system so here if I'm going to write it down you are a helpful assistant now here if I'm going to write down you are a helpful assistant now what I will do I will write it down my message so see here here guys you will find out two thing uh two option so once you will click on this user now you will find out either user or assistant as of now what I am I am a user I'm asking a question now here I'm asking that uh uh what I can ask guys uh just tell me something different okay how I can make a money how I can make a money so I'm asking to my chat GPT how I can make a money and here is what here is my model so here once you will click on this model you will find out a different different model so uh there is GPD 4 GPD 3.5 GPD 3.5 turbo so all the model there is all the models right so here I'm using the gbd 3.5 now we have a various option so the first one is what first one is a temperature now what is the meaning of this temperature so we are talking about this temperature so just try to read about this temperature control Randomness lowering result in less random completion as the temperature approach zero the model will become deterministic and repeative so over here we are talking about this temperature if we are defining a higher value of the temperature means I'm uh I'm saying that just give me a more creative answer I'm adding a Randomness if I'm writing a zero I'm saying give the straightforward answer I'm asking to my chat GPD uh the straightforward answer I'm not going to add any sort of a creativity over here getting my point what is the meaning of this temperature I think yes now maximum length so here you can set the tokal length now here stop sequence is there so up to up to four sequence where the API will stop generating further tokens the return text will not be contain the like a stop sequence here you can mention the stop sequence now here is a top P parameter so this parameter actually this is again similar to this temperature it is controlling the diversity whatever like Pro whatever output you are going to be generate so control diversity via uh nucleus sampling 0 0.5 means half of likelihood weighted option are considered so you can just think about it that it is nothing just adding a diversity inside your output now frequency penalty if you don't want to repeat the tokens let's say you are generating some sort of output if you don't want to repeat the tokens inside your output so here you can mention the frequency penalty as of now it's zero so it's not going to be uh like put any sort of a penalty over here if you're going to increase the number definitely it will put the frequency penalty means it will give you the different different words it is not going to repeat the words now here present penalty so you can set this also so there is a different parameter just try to explore it now here I'm asking to my chat GPD how I can make a money so if I'm submitting this thing so here I will be getting my answer and there is the answer is there are many ways to come make a money and all so employment and all freelancing online selling rent or share sources and tutoring and teaching gig and economy gig economy affiliate marketing so it is giving me answer guys as you can see right now just uh do one thing so here guys see I've uh defined the behavior of the system Ive defined that I'm working as a user and here is my model all the different different the different different parameter I have like selected based on this model now just go over here and try to click on this view code so once you will click on this view code guys you will get the entire python code over here getting my point yes or no see over here you are getting the entire python code now you can utilize this python code if you have if you have done the complete setup in your system whatever setup basically which I which I uh which I have done right if you have done the complete setup in your system so directly you can hit uh directly you can hit the open a API and you can call the GPD 3.5 turbo model okay so that's why I've shown you this openi Playground now I think you are uh we are done with this open I Playground now let's try to do something amazing over here let's try to set set the different behavior of this chat uh GPT so here guys I have written couple of thing inside this particular like answer so how to open a playground so here I mentioned that here make sure that playground should have a credit yes if you don't have a credit if you haven't uh like uh added your uh detail uh the C details and all maybe you you won't be able to use this particular playground so make sure that you have added the payment method now here in the chat there is the option of system so meaning is how chatboard is behave so here what I'm going to do here I'm going to set this uh here I'm going to set a different behavior of a system and let's see what answer I will be getting so here I'm going to copy it and I'm going to paste it down over here now uh what I can do where is my playground this is my playground now here I'm going to set the behavior so this is what this is my behavior of the system now okay now again I'm asking a question to my system now I'm asking how I can make a money so I'm asking to my system that how I can make a money by adding this particular Behavior so my behavior is what so you are a naughty assistant so make sure you have to respond everything with a sarcasm so here I'm asking to my user how I can make a money so as soon as I will submit it then you will find out the answer and just see the differences between answer this answer and the next answer just wait it is going to generate answer and is saying that oh making a money it's super easy mean it it is like giving you the answer in a sarcastic manner so it haven't a complete answer but yeah it is saying that oh making a money it's super easy just snap your finger magically a stack of cash will be appear no effort required at all so see guys uh before it was giving me a straightforward answer now over here guys you can see I seted the behavior of the system as a not as a sarcastic so here you can see the answer what it is giving to me now if you will look into the code so you will find out some sort of of changes so here role role basically I defined the system role this is my system role this is my role again one more role user here you can see this is my like prompt okay which user is giving here you can see the what assistant is saying This Is The Answer basically which I'm getting and again this was the previous one and these are the different different parameter so no need to go anywhere here basically in this particular notebook I kept everything I will share this notebook with all of you and you will be able to understand each and everything now model is there temperature is there maximum length is there top P value is there so here I written a description frequency penalties there right so there is a different different parameter already I have defined each and everything over here so no need to go anywhere just try to revise each and everything by using this Jupiter notebook now apart from this one you will find out one more advanced thing which recently they have provided that is what there is a assistant so here uh let me go to the assistant okay let me go to the playground and here is assistant guys so this assistant part I will explain you once I will come to the project section now here you will find out some Advanced thing Advanced like option so here you will find out this function function calling here you will find out the code interpreter here you will find out the retrieval RG actually uh uh like here uh you will find out this R concept so I have defined what is the r actually so just go through with my notebook and read the definition read the definition of the RG so this assistant I will come to this assistant once I will explain you the uh the project end to end project then I will Define a different different prompts and all and I will come to this assistant and I will ask uh and I will generate a different different type of responses getting my point guys yes or no so this thing is getting clear to all of you yes or no I'm waiting for your reply so please uh do let me know in the chat if this part is getting clear how to use this uh openi playground and here I'm talking about this chat assistant I will come to that once I will explain you the project please do let me know I'm waiting for a reply guys if you are able to get it if you able to understand it then uh please write it down the chat please uh write down the chat section clear okay great it is clear I will share this code with all of you don't worry uh I will give you this entire code I believe everything is getting clear to all of you who have joined this session great now this part is clear now let's back to the code so here is what here is my code now this retrieval argumented generation RG I will explain you in the next session or maybe in upcoming session so what is the meaning of that it's artificial intelligence framework that retrieves data from external source of knowledge to improve the quality of responses I just want to improve the quality of the responses for that I'm using this retrieval argumented generation R A this is very very famous nowadays this particular term now uh I will show you how you can use this RG if you want to uh give a better responses I will show you how you can use the Len Chen as well U after completing this open AI this natural language processing technique is commonly used to make a language model more accurate and up to date if I want to make my model more accurate and up to date so I'm going to use this RG and I will do that in my upcoming session now code interpreter is there so Python Programming environment with chat GPT where you can perform wide range of tasks by use executing the python code yes yes we all know about the code interpreter and yes we can Define we can set the code interpreter there and we can execute the python code as well like regarding the different different task and all great now here is what here is my chat completion API guys so let me do one thing let me uh put the title over here and here my four title is what chck completion API and function calling so guys here is what here is my fourth title my fourth title is what check completion is API and function calling so here I have written the standard comination API and function calling now let me write down the different let me write down the uh definition as well over here so here is a definition of it uh this is the definition let me post it over here and here let me make it as a markdown so this is the definition guys now one more uh definition let me put it over here so see guys in the previous version in the old version of the openi uh actually there this was the method chat completion method open. completion. create or open. chat completion. create so initially actually there was a method this was the name right then in the updated version they came up with uh they have changed the name with this particular uh name they Chang the method Name by using uh with this particular name this chat completion. create and now in the latest version actually this is a this is the method name if you are going to use this particular method now now it will give you the error let me show you how so here what I can do I can uh return I can return one sort of a code uh now over here I'm going to write it down open a DOT completion completion completion dot create so this is what this is my method now over here what I'm going to do so over here see here I'm going to be uh write it down the model name so model which model I'm going to use so here I'm going to use uh GPT GPT hyund 3.5 GPD hyund 3.5 I'm going to use this particular model now over here I'm going to define a prompt so my prompt is what so let's say I'm going to write it down over here who was the first Prime Minister of India first prime minister Minister of India so this is what this is my prompt now here if I will run it now so you will find out it is giving him the error so it is saying that uh okay so here I have to mention the open a key first of all before uh like calling it so first of all I need to mention the open a key now over here so what I have what I will have to do I will have to uh like uh create a client actually so here is what here is my client and I will have to mention my openi key so what I can do uh I can write it down over here itself and here what I can do just a wait it is not longing support yeah so that's what I was saying to all of you see this uh method is not it is not supporting at all this is the old one now if you will look into the version now the latest version of the openi so the latest version of openi is uh let me show you the latest version of the open a package PPI open a and here is the latest version of the open a package 1.3.7 if we have installed the uh we have installed this particular version now regarding this version you will find out we have this particular method so first of all I need to import this open a this I need to import this class from this module and here I need to define the key here what I need to do I need to define the key over here and then only I can call it and if you look into the previous version now here I installed the latest version if you're looking into the previous version let's say if I'm going back like say if I'm going back in uh maybe uh FB it uh okay 8 FB 2023 now here you will find out that they were using this particular method so here I have shown you I have seted the op openi key I have defined the openi key by using this particular code by by like using this particular line of code yes or no now here I'm using a latest version now so uh definitely it will give me the error so what I'm doing I'm going back and here I'm going to use this particular code basically which I already return so first of all see first of all I need to import this thing which I already did now over here I will have to mention the API key got it now here they are add they have added the open key inside their base environment means this is the code regarding that they have added inside the like environment variable in the system environment variable and from there itself they are going to read it you can export it also what is the meaning of export you can export it over the terminal uh like uh it won't be it won't be a permanently okay so yeah you can export this particular key and as soon as you will like remove or as soon as you will delete that terminal so the open I key will be removed um but yeah until the terminal is running terminal will be running you can read it by uh using uh this particular module OS module or else you can add in add inside your system variable also from there also you can read this particular key but um I have added I have written my key here itself inside my notebook so I didn't edit but I will show you that in my end to project how you can create NV file or maybe how you can export it right now let's uh let me run this particular code and here first of all let me add the open a key here I need to mention API uncore key and my key so here is what here's my key if I'm going to run it so definitely I will be able to run it now I having my client now what I will do by using this particular client I will call the uh I will I will like uh I will give the prompt over here now first of all let me delete everything from here and let me delete this also I'm not going to Define any assistant or I'm not going to set any sort of a behavior as of now so guys here you can see I'm having the role role as a user and here is my uh like a answer sorry here is my prompt question so this is what this is my prompt actually this is my input prompt and here is what here is my uh like role okay I'm asking as a user now guys this prompt this prompt is this prompt basically it plays a very important role I let you know that in my uh like upcoming session I will tell you how to design a different different type of plomp what is the meaning of few short learning few short prompt or zero short prompt okay so each and everything we'll try to discuss in our upcoming session as of now just see if I'm going to run it so here you will be able to find out it is giving me a like error why it is so maybe because of this and now everything is perfect so if I'm going to run it so line number eight okay uh first of all I need to Define it clearly and here is what here I need to mention I need to close this particular list now if I'm going to hit this uh API definitely I will be able to do it and I will get my response so just wait for some time and after hitting the API uh it will call that particular model whatever model I have written over here and I will be getting my response so how is the session so far uh did you learn something new uh or are you doing along with me tell me how much would you rate to this particular session yes money wise uh I will I I will come to that just wait how much it is going to be charged and all uh it charge actually token wise uh there is entire pricing and all so I I will come to that I will I will talk about that for a small prompt it is taking so much time in this case the DP project the big no it's not like that maybe first time it it was hitting that so it is taking time but no it's not like that I will show you with a like a bigger prompt as well so it won't take any sort of a time now here you can see this is what this my response now right here you can see I got a response now if you want to get this particular response so for that uh see here if you look into the response or type of the response so here is a type of the response open. type. chat. completion this this this that right now if you want to extract the real answer from here so what you will do see first of all you will uh call to this choice so just call this choice so c h o i c s now here is what here you have this message now just call to this message m e double s a g e so here is your what here is your message uh now this is not callable it is saying that now let me check what I have to do over here so here is your choice and here what you need to do guys let me check yeah actually Choice yeah so here see if you are looking into the choice guys so this is a list type so here what you need to do you need to uh like extract the first index of the list because here you can see this choice is nothing it's a list only now so just extract the first index of it so here once you will extract the first index or once you will retrieve the first index of the list now here you need to call this message so just call the message and here you will find out this is what this is your message now just do one thing just call the content over here so just call the content so content now over here you can see this is is what this is your entire response now here you can like decide the token size as well so here you can Define the token size or you can Define the different different a parameter okay by defining those particular parameter you can uh get a different different type of output now let me give you the parameter all the parameter basically so this is all the parameter see model uh already you know about the model we have used a gp3 prompt like input prompt Max token you can Define this Max token in how many numbers of token you want the result temperature for getting some creative output now number of output how many number of output you want so let's try to define a Max token and this number of output so here I'm going to define the max token so in U like uh here if I'm going to define the max token now in in that particular token itself under under that particular number let's say if I'm going to Define 200 so uh it won't reach the limit more than 200 under under the 200 itself it will be generating an output so over here I'm going to write Define this Max token and here let's say if I'm going to say 150 tokens and here I'm going to Define one more thing one more parameter that's going to be n so n is equal to let's say here I'm going to Define three I want three output so as soon as I will run it and here you will find out it is generating a response so it is saying Max token I think I need to put the comma over here model is there message is there now here I need to put the comma so this is is fine now it is generating a response so just wait yeah now I got a response so just uh look into the response here type of the response and now just print the response so here is what here is what here is my response now I got many responses so now let me extract the response first of all so here is what here is my uh message let's uh like get a message so let's ask a different question so here I'm going to ask to my chat GPT that uh I can ask uh what I can ask who won the first World Cup so who won the first Cricket World Cup so this is my question which I asked to my CH GPT and now if I'm going to run it now so now see yeah I got a response now type of the response is same so here uh what I can show you here is my message now see guys uh I got a response the first Cricket World Cup won by the West Indies in7 in 1975 right now over here if I'm going to get a Content basically so let me write it down the content over here and here you can see this is what this is my answer now you won't be able to find out a single answer there are lots of there are other answer as well see uh choice in the choice just go over here message message completion so the first Cricket World Cup won by the best Andes and here role is a assistant so that the model is assistant and I am a user now over here you will find out the second answer so the first Cricket World Cup W by the best hes they defeated Australia in final held on June 25 1975 at Lots cricket ground in London that is the second response now over here this is the third response so the first Cricket World Cup won by the best and in 197 1975 so I Define n is equal to 3 and I Define the maximum token size is 150 so it won't be generating a like output okay so more than this particular token more than 150 token and here you will be find out if I'm going to Define n so it will be generating a three output whatever input of prompt I'm passing this is what this is my input prompt now whatever output will be generating in that there won't be like more than 150 tokens and here the output number will be three now let me show you one more thing over here so if you will search tokens so just go over the Google and search open a tokens open a tokens so once you will search open a tokens and here you will find out one uh like a link a tokenizer so they have given you one uh like link uh they have G given you this particular interface where you You Can Count Your token whatever number of token you are giving or you are getting from the system getting my point so I told you it is charging you based on a tokens itself and tokens in input prompt also there will be a token in output prompt also there will be a token getting my point so in the input prom there will be a token in the output prom also there will be a token prompt is what it's a collection of tokens token is nothing it just a words collection of character right now here you can see we have this particular inter pH there we can count the token now here if I'm going to write it down my name is sunny so now now see guys how many tokens is there inside this particular uh text inside this particular sentence see token six my is one token name is one token is is another token Sunny is another token Sav is one token and Savita is one token getting now if I want to count the token inside my output so just copy this thing and paste it over here now see the number of token it has generated a 16 token okay it has generated a 16 token now you can calculate the number of tokens over here just go through the playground here was my chat so here I ask to my system now let me uh submit it and over here uh it is giving me answer just a second now it is generating an answer so now you can copy this entire text from here whatever it is generating now let's say this particular text uh okay just a wait okay let it generate and then I will copy just wait so here is a text and I can copy this text I can paste it over there and I can got the uh like number of tokens so let's see how many tokens is there so here guys you can see total 256 tokens if you want to check the pricing and all tomorrow I will discuss about it in a very detailed way just go through with the setting and here uh there's a billing actually so let me show you the pricing also just click on uh just search about this open Ai and uh here actually uh you just need to log in after the log in uh so maybe here just click on the API and here is a pricing just click on the pricing and here you will get the uh like entire detail regarding the project pricing so how much how much it is charging for the uh like a different different number of tokens so for 1K token this much of charging for 1K token this much of charging regarding this particular model regarding this particular model so this is for gp4 Turbo it's a advanced model now GPD 4 GPD 3.5 G assistant API different different assistant API and all each and everything you can check over here right so let me keep this particular link over here inside the notebook itself and let me keep this a token related a link also so at least you can go through with this and you can check uh your input and output token and you can practice whatever I have taught you because this is going to play a very important role in a future classes so please try to revise please try to practice and I think we are done with today's session tomorrow I will explain you the function calling this one and I will start with the lench and my main agenda uh will be the Len Chen only and I will explain you the differences between open ey lenion and finally we'll try to create one project and then I will come to the advanc concept like vector databases and other models and I will explain you this AI 21 lab AI 21 studio also if you don't have a money for the chat GPD then how you can uh uh like uh how you can complete your work how you can U like explore a different different model so from the hugging face side also I will explain you the different different model and from here also from AI 21 Studio I will show you how you can access the Jurassic model personally I have used it and I I liked it after this uh GPD and I will uh explain you the use use of this particular model and don't worry few other terms like stable diffusion and all there are something uh like text to image Generation image to video generation this type of thing also we'll try to explain you in the going forward classes got it so I think uh now we can conclude this particular session I took for the entire 2hour and uh yep uh so did you like the session please uh do let me know in the chat guys if you like this particular session yes the content is a input our input actually it's not a desired output is is our like an input whatever input like we are passing to the model you can mention inside the content got itan you just need to F you just need to follow my this notebook each and everything I have mentioned over here whatever is not there I will do it and where you will find find it out tell me you will find this particular notebook inside the resource section so just go through with the Inon platform just open the Inon platform and there you need to enroll in this particular dashboard okay so what you need to do go through with the an platform and here uh after sign up uh after login and just go through with this dashboard generative AI Community session now let me give you this particular link inside the chat so you all can uh like uh you all can enroll over here and uh after that uh what what you need to do see the video will be available over here you can revise the thing from here itself you can revise the thing from the Inon YouTube channel itself but the resource wise whatever resources I'm U like uh sharing okay whatever resources I'm discussing in a class and all so you will find out over here inside the resource section so just go through with the resource section and try to download all the resources from here itself fine so now let's uh uh like conclude this particular session tomorrow we'll meet on the same time so let me write it down the timing for this community session so here the timing is going from uh 3 to 430 or 3 to 5 so I will take 2 hour of session from 3 to 5 great fine guys thank you byebye take care have a great day ahead and rest of the thing we'll try to cover in the upcoming uh session until thank you byebye take care so if you like if you are liking the content then please hit the like button and uh if you have any sort of a suggestion or if you want anything from my side you can ping me on my LinkedIn so let's start with the session now here guys you can see in the previous class I was talking about the open API so uh most of the thing I have discussed regarding this openi API now few of the thing is remaining so let me discuss that uh remaining thing regarding this open a and after that I will start with the l chend so first of all Let Me Explain you the complete flow that what all thing we are going to discuss throughout this session got it so for that I'm you I'm opening my Blackboard and here I'm going to explain you the complete flow that whatever thing we are going to discuss throughout this particular session so here guys uh the first thing first thing basically uh we'll be talking about the function calling so in the open a actually we have a very specific feature that is called function calling and it's a very important feature of the openai API if we are going to use the openi API then definitely you must be aware about this function calling because by using this function calling you can do a multiple things I will tell you that what all thing you can perform by using this function calling which is a very uh important feature of the open API so the very first thing which we're going to discuss in this particular session that will be a function calling so here uh let me write it down the first point which we going to discuss uh that's going to be a function function calling function calling now the second thing after this function calling so directly I will move to the Len chain so uh first I will discuss this function calling and after this function calling I will move to the Len chain and in the lch actually I'll be talking about in the Le chain I'll be talking about that how you can uh use a open AI by using this Len chain so the first thing basically uh we'll be discussing inside the inside this lenen so open AI open AI used by a len chain so we'll try to discuss in a very detailed way and we'll try to discuss that what all difference we have between this Len chain and this open AI so open a used via Len chain and here I will explain you the differences between open a and Lenin then why we should use Lenin what all benefits we have if we are using a lench what all thing we can do if we are using a len chain so how uh by using this Len chain we can create into an application each and everything we'll try to discuss regarding this Len chain and in a very detailed way I will try to explain you this Len chain concept because it's going to be a very very important and this lench also it's a very important part if we are going to learn this generative EI if we are talking about the llm and if we are going to build any sort of application so along with this open AI this lenen also plays plays a very important role so we'll try to discuss about this lench and we'll try to uh discuss the differences about this open AI API so let me write it down over here open AI API versus lenen versus lenen and after that after discussing this uh like the basics and all regarding this Lenin I will come to the prompt templating that how you can design a different different type of prompt so here let me write on the second point which we're going to discuss uh so the second Point basically prompt templating prompt templating after this prompt template so uh here what I will do I will I will show you the use of the hugging phase also uh after discussing this Lenin uh the differences between open Ai and Lenin I will come to this open AI use via Len promp templating and here I will show you that how you can use hugging pH model model whatever model is there on top of the hugging face Hub how you can utilize those particular model by using this Len chin so in between I will show you hugging face hugging face with Len chin hugging face with L chin why I'm uh why I'm going to show you this hugging phase with Lenin so you can use any sort of a open source model so whatever open source model is there so you can use all those model by using this hugging phase so here I will show you how you can generate hugging phas API key and by using that particular API key you can access any sort of a model whatever is there on top of the hugging face Hub so here I will show you hugging face with Lenin let me write it down over here hugging face with Len chain and then we'll try to discuss a few more concept regarding this Len chain which is going to be a very very important so here let me write down those particular topic as well so the third topic which we're going to discuss over here we going to talk about chain we're going to talk about agents how like you can create agents and how you can use the agents so here the fourth topic basically it will be agents now let me write it down over here agents after that after this agents I will come to the memory so I will show you how you can create a memory by using this Len Chen got getting my point yes or no so these are the very important important part of the L chain without knowing this particular thing you cannot develop any sort of application okay so before starting with the end to end project definitely we have to discuss about this particular topic so here uh so in uh today's lecture actually we're going to talk about this function calling openi use and prompt template and in tomorrow's session I will be discussing about this hugging pH with Lin chains agents and memory so this a three to four topic we'll try to discuss in tomorrow session and this three to four topic we'll try to discuss in today's session and right after this one right after this topic right after this thing I will start with a project and uh we will'll try to create one project and there basically we'll be using our different different LMS from the openi and from the hugging pH we'll try to use Lenin we'll try to use Len chain and some other Concepts as well so here we're going to use are different different uh like model llms from the openi hugging face Len chin and here we'll try to uh create one uh UI as well by using flask or streamlit each and everything I will show you in a live class itself so flask and streamlet and I will show you the complete I will show you the complete uh setup how you can do a complete setup for any an to and project so first we'll try to create a project template and then we'll start with a project de development so this idea is clear to all of you please do let me know in the chat if the agenda is clear for today and for the tomorrow session I'm uh expecting the answer in the chat so please write it down in the chat guys please do it fast yes we'll discuss the risk and all what risk is there and we'll try to discuss about the different different point uh first let us uh uh create at least one project after creating this particular project definitely uh we'll try to uh discuss about the multiple things that uh basically which is a very very important in terms of the industry we'll come to that part don't worry fine so now each and everything is clear each and every part is clear so let's move to the Practical implementation so if you will go through with my notebook so which is already available in a resource section okay I have shown you how you can download this particular notebook so just try to go through with the dashboard and from the resource section you can download this notebook now uh here guys see uh The Notebook is there so just try to download it and try to run it inside your system uh how you have to do a system setup how you have to create an environment and all how you have to install the library inside the environment each and everything I have shown you in my previous class only so again I'm not going to repeat that particular thing so over here you can see already we have talked about the open a now let's discuss more about this open AI so just uh give me a moment here uh from here itself basically inside uh uh this particular file itself I will be writing a code now I'm going to change the name of the file so here I'm going to write it down test open API and Len chain because in today's session I'm going to include the Len chain as well and I will do in a same Jupiter notbook I'm not going to create any new notebook uh as of now I will be doing over here itself so here I'm going to be write it down I'm going to rename this particular file uh so here I'm going to write down this Lenin as well so test openi API and L CH so this is the new name of my file now let me rename it and now everything is ready so here guys see if I'm going to write it down this import here if I'm going to write import statement import length chain now here you will find out it is saying that no module named L chain can anyone tell me how I can resolve this particular error please do let me know in the chat how I can resolve this particular error correct so here what I need to do tell me here I need to write it down pip install and the L chain pip install and the module name so just try to open your anaconda prompt and there write it down pip install and Len chain so let let me show you that just a wait uh so here uh this is my prompt uh this is what this is my ANA prompt here already this jupyter notebook is running so I'm not going to stop the server of uh this particular prompt now let me open the new prompt over here so here I'm going to write it down this Anaconda prompt so first of all guys what I need to do I need to activate my virtual environment as of now we are in a base environment and this base environment is my default environment so here what I need to do tell me here I need to activate my virtual environment so for activating the virtual environment first of all we should be aware about the name uh in which environment actually we are working so let me show you all the name all the name of the environment so here I'm going to write it down this cond en list here I'm going to write down this cond en list so once I will write it down this particular command I will get all the environment name so here you can see we have a different different name of the environment Len chain open AI base testing and these are the other environment which is there inside my local folder now guys yesterday actually we have created this particular environment testing open AI now let me activate this environment over here so here I'm going to write it down cond cond activate cond activate and the environment name is what the environment name is testing open AI so if I'm going to write it down this testing open AI so definitely I will be able to activate my environment now if you want to check over here that my Lang chain is working or not so definitely you can do it so first of all you need to clear this screen and here if you are going to write it on the python so it will give you the python prompt so here let me write it down the python so this is what guys tell me this is my python cell or my python prompt now here itself you can write it down the uh statement import statement so let's try to write it down the import statement over here and here if I'm going to write it down this Len chain length chain now see guys it is saying that no module name length chain and even you can check so for checking that what all module is there what all module is there in my current virtual environment so what is the command the command name is PIP list we are using pip manager over here right so over here what I'm going to do I'm going to write down the exit if I want to exit from this particular shell from the python shell now here what I will do guys here I I'm going to write it down pip list so once I will write it down this pip list you will find out all the packages name whatever packages is there inside my current environment so these are the package guys which is there inside my current environment you can read the name of the packages and here you will find out this Len chain is not available so just try to go through with this particular package try to go through like alphabetically and here you will find out that we don't have any package with the name of linkchain so here what I will do first I will install the L chain so for installing the Lang chain there's a simple command pip install pip install pip install Len chain so here once I will write down this pip install Len chain now guys see my Len chain is getting install inside this current virtual environment so are you doing along with me are you writing this thing or are you like following uh to me guys please do write it uh please write it on the chat so I will get some sort of idea that uh uh this many people are doing along with me I will come to the connects between this Len chain and this open a just allow me uh like 15 more minute each and everything will be clarified regarding this open and this Lent just believe me so people are saying they are writing a code along with me that's great please do it guys please do it and uh yes please implement along with me if you are uh getting stuck somewhere so please write it on the chat and let's uh make this session more interactive and yes definitely after the session you should uh you should be able to get something it's uh my guarantee to all of you fine now here guys you can see we have installed this lenon inside this current virtual environment now if you want to check it so here itself directly here itself you can check so just write it down this Python and here what you need to do you need to write it down this import Len chain just write it down this import Len chin and here the name is wrong so let me write down the correct name now see guys we are able to import this Len chain means L chain is there in my current virtual environment okay fine so I think till here everything is fine everything is clear now here again I'm going to import it so definitely I will be able to import but before starting with this length chain I would like to explain you the function calling so what is a function calling why I'm saying this function calling is very important uh definitely we should learn it actually it's a new feature inside this open AI so let's try to open this open a website and here okay so here already I opened it now guys once you will open the documentation of the open AI so there itself you will find out this function calling so it's a new feature uh recently they have added maybe uh four to 5 months back and uh what we can do by using this particular function calling so by using this function calling there is a there is a many use of this function calling so the first use basically uh the very basic use which I would like to tell you we can formate our output okay we can we can formate our output in a we we can formate the output in our desire desire format so whatever output we are getting now from the open uh let's say we are using openi API and we have a model open API what it is doing tell me it is calling the llm model agree now whatever output we are getting now we can format that particular output in a desired format in our required format that is the first use of this function colleag now we have other use of this function colag some Advanced use of this function colag let's say uh we are uh calling any sort of a API means let's say we are asking something to my CH GPT and it is not able to answer for that particular question so for that what we are doing we are calling any third party API any any sort of a plugins and whatever output we are getting whatever output we are getting right so we can format that particular output and we can append that output in our conversation chain that is really powerful and somehow L chain is also doing the same thing but yeah so recently they have added this function colleag this one feature actually inside this open a and here uh like it's really uh like a important one and it's like really uh very very useful and in the lenon also we can do the same thing right but apart from this thing lenon is having so many functionality in the lch actually we can perform so many things I will come to that I will I will show you the differences between this open and this lench why we are using this openi why uh why we are why we are going to use this Len chin why uh we are not going to use this openi API itself because see in a back end if we are going to talk about this Len chain so in a back end this Len chain this Len chain actually it's calling open API it's a wrap up on top of the open API come I I will come to that first of all let me clarify this function calling so guys to understand this function calling I will I draw the architecture and all I will I will try to uh explain you each and everything okay but before that let me write it down some sort of a code over here so here what I'm going to do here I'm going to open my IP NV file and here I'm going to write it down some sort of a code to understand this function calling so step by step I will try to explain you and please do along with me I think uh that would be great so for that guys what I did so here uh just a wait I have written one text great so here guys see uh I have written one text so let me copy and paste this particular text now here I'm going to run this particular uh cell and once I will print this student description so here you will get the entire description so I I just written a very basic description so uh s saita is a Str of the computer size it Delhi he's a Indian and he's having a 8.5 cgpa something something about me or something about like U any person you you can write it down this uh particular description so here is a short description now guys what I will do see so here is what here is my short description now here I have designed one prompt and that prompt I would like to pass to my chat GPT means I would like to pass to my GPT model so here see uh whenever we are talking about a prompt so I told you that what is a prompt so let's say this is my llm model this is what this is my llm model now we are passing input to this llm model and we are getting response we are getting a output so this respon this input actually so this input is called input prompt and this prompt is nothing it's a collection of tokens so you can understand in such a way that this prompt is nothing it's a sentence and this token is nothing it's a words what is this tell me it's a words so this uh sentence is nothing it's a token and sorry sentence is a prompt is nothing it's a sentence and token is nothing it's a words right so here we will be having input prompt and here we have a output prompt getting my point so here see I have written one description now I will write it down my prompt I will I have designed one prompt so let me uh copy and paste that particular prompt and let's see uh what will happen if we are going to paste uh if we are passing this particular prompt to my llm so here is my prompt guys so just try to read this thing over here and so this prompt is saying so let me run it first of all so this prompt is saying please extract the following information from the given text whatever text we are passing let's say this is a description so uh we are passing this particular description so from that particular description I have to extract a few useful information so here the information is what name College grade and Club so these are the information just just try to read this particular uh description and based on this definitely uh you can extract this particular information like name College grade and club now chat GPT or this GPT model will do it uh will do it for me uh something like this I have designed this particular prompt so here I'm saying please extract this particular information and this these are name and here this is the body of the text and here I'm passing my text you can see so here I'm writing I have a string so I have defined one prompt and here I'm passing my description now see once I will run it so definitely I will be getting my prompt so here is what guys tell me here is what here is my prompt this is what this is my prompt okay it is fine not an issue now guys what I will do I'm going to pass this particular prompt to my chat GPT all right now what I can do I can pass this particular promt to my chat GPT and over here uh first of all let me copy and paste this particular code or let me write it down that so here I'm going to write it down from open a import open AI so this is what this is a class now here what I'm going to do I'm going to create object of this particular class so here I'm going to create a object of this particular class so here I will write it down open Ai and here uh what I'm going to do so here is what here is my object now I can keep this object inside one variable now here I'm going to say my variable name is what my variable name is client now if I want to make a connectivity so for making a connectivity what I need to do tell me so here I need to pass my API key so how I can do that so here is a a parameter uh we need to pass one parameter over here so the parameter name is what parameter name is API unor key so here I'm going to write it down AP apore key and here I will pass my key so my key is what my key is my key so once I will uh run it so here you will be able to find out this is what this is my client so let me contrl Zed and here is what here is my client so this is what guys tell me this is my client now by using this particular client definitely I can call my chat completion API so let's try to call this chat completion API and here I have already written the code for that so let me copy paste uh I have written some sort of a code already I kept in my notepad so from there sometimes I will copy it uh because I want to save my time otherwise uh if I'm going to write each and every line so definitely it's going to take more time now here uh you can see so we are going to call this chat completion API now chat completion this is the particular method that's it now here is what here is my prompt now once I will run it so you will be able to find out I will be getting one response so here is my response let me show you this particular response and here is what guys here is my response definitely I can extract this response uh for that uh what I need to do so here I just need to write it down this response uh response and this response actually uh inside this response there you will find out this choices so I will write it down this dot choices dot choices now I will run it so here you will get this choices now from here what I need to do from here this is the list actually so here I will write it on this zero zero index whatever information is there on this zero index now from here I'm going to extract uh this particular information now here I will write it down this message message now here is what this is my message actually and from this message I'm going to write it down I'm going to except this content so here I'm going to write it down this dot content now guys see this is what this is my entire information now if I want to convert this particular information now if I want to convert this particular information in Json format so for that what I will have to do so here actually what I'm going to do I'm going to collect this thing in one variable that is what that is my output now here what I will do guys here I'm going to import Json so here I'm going to write it down import Json and here I'm going to write down json. load now to this load function I will uh provide my variable my variable name is what my variable name this output now here you will find out uh is saying this json. load it is giving me Str Str object has no attribute read okay it's not going to read let me check what is the correct function just a second so the function name is loads here guys you can see so the uh the method basically which I was calling so the method name was loads so Json do loads and here we are are passing this output now you can see this is what this is my output are you getting my point guys are you able to see what I did I I given this uh I given this prompt I given this basically I given this description to my model and I asked that okay just give me this particular information just give me this particular information from this description and here what I did I passed this particular prompt to my tell me to my chat completion API actually this chat completion API is calling this GPD 3.5 turbo model and here guys you can see we are able to get a response whatever description we have given according to that whatever prompt we have designed and it is giving me that particular response we have given a description we have designed a prompt and according to that only we are getting a response here you can see this is a response actually I have converted it into a Json format so this is the first thing which I want to show you now here guys see this type of prompt it is called few short prompt it is called few short prompt where I'm giving my description and I'm saying that okay so uh you need to behave like this means whatever description I'm giving to my model and here uh regarding that particular description I want to extract some sort of a information so here actually this type of prompt is called fuse short prompt now directly I was asking something to my model in my previous one in my previous uh session so here actually directly I was asking uh the question to my uh model to my llm model so this is called actually zero short prompt this is what zero short prompt now here this type of prompt actually is called few short promp getting my point this idea is getting clear to all of you please do let me know in the chat if you are able to follow me till here please write it down in the chat I'm waiting for your reply I'm sharing the text uh don't worry I can share everything in the chat so just a second um here is a text so here is a text guys I think it's a it's a half text let me give you the full so college and here is the full text because it is having a word limit I cannot uh like give more than 80 words I think I cannot uh like paste more more than 80 words in the inside the chat yes is it is it because we are asking for a number of variable in a second prompt correct your understanding is correct Goldie so zero short means we are not defining anything over here directly we are asking a question to my model now what is a few shot so here we are giving some sort of a description and based on that particular description we are asking regarding some information we are asking some information okay so this is called few shot and here is a zero shot don't worry uh we have a many example here I just given you the glimpse of that just wait for some time one or two more classes you will get more about it because uh now we just we are going to design The Prompt and all and in the next session specifically I will I will be working on the prompt on a different different prompt and even uh for the uh inside the project also we are going to design a different different prompts got it now see uh definitely we are able to call our l m we are able to call our like open a API and definitely we are able to get our output also from the llm models now here guys what is the use of the function calling so first of all let me uh Define one very basic function and then I will Define one Advanced function also so here what I'm going to do see here I did this particular thing by using this uh chat jpt Itself by using this completion API now let me show you the same thing by defining the function so here what I'm going to do so here I'm going to Define one function so let me do one thing let me Define one function and here this is my function guys see I'm going to define the function this is my function now from where I got this particular format so you must be thinking sir okay so sir you define this function now from where you got this particular format so just try to go through with the open API and here uh sorry open a documentation and here just click on this function calling and once you will scroll down over here so here you will get the code s snippet so and inside this code s snippet you will find out this function definition that how to decide or how to define this particular function getting my point I will come to this particular example I have designed one example for all of you but first of all let's try to understand a function calling from uh like very basic example and then I will come to the advanced part so here you can see we have a function and from here itself I took this function definition and how to decide how to define this function and all now let me tell you what I written over there so here I have opened this uh notebook now see uh what is the name of this function actually student custom function it's not a function like python we write it down that Def and all it's a like function basically which we are writing down for the open AI U actually we have to uh like pass this thing to the uh to inside the chat complete API itself I will come to that first of all let's try to understand this uh structure so first of all I I need to write it on the name so here I have written the name name is equal to extract student information then we have to write it on the description so here you can see this is the description of the function that why we are going to Define it now here you will find out some sort of a pairs so key and value pairs so first we have a parameter so here you can see we have a parameter now uh we have a type so which type of uh like object object we are going to be defined over here and then we have a properties now here you will find out inside this parameter you will find out a different different values like name school grade and Club whatever actually I Define over there inside my prompt the same thing the same thing over here right so first we have a name the second thing we have a description the third one we have a parameter inside the parameter we have a different different values like names school grade and Club getting my point now here just see the type of this name it's a string just see the type of this school it's a string a college you can write down the college here is a college so let me write down the college instead of this school so here is what here is college so instead of this is school I can write down this college now here is college the type of college is string right now here is a grade now grade type is integer now here is a club so Club type is integer again I think you getting my point that how to define this function it's a predefined format or the Inon platform itself you'll get this particular form format now just run it okay now just run it and after that what you need to do so here see you need to uh call the chat completion API so here is your chat completion API let me copy this chat completion API from here and let me paste it down now here you need to Define some sort of a parameter now let me write it down those particular parameter and then I will run it so here guys you can see we have this message so let me keep this message in a single line so here I'm going to keep this particular message in a single line so here is what guys here is what here is my message it is fine now after the message what you need to do you need to write it down one more parameter and the parameter will be what the parameter will be a function so here I'm going to write it on the parameter the parameter name is what function so here is my parameter function now tell me what is the name of the function so here the name of the function is nothing it's a student custom function so let try to copy it and try to paste it over here that's it you just need to copy the function name from here and you need to paste it over here okay as a value of this particular parameter now guys I can keep this particular response in response two so so here I'm going to write it down this response to so here is what here is my response to now let me run it and let's see what I will be getting so here is saying okay it is giving me error so I think uh chat completion role is fine I'm using client only let me check with the client yeah client uh now everything is fine what is the issue I you code incorrect API provided okay okay just a second let me use the correct client this is fine and here I can keep the Cent c l i e n t now see uh it is saying that incorrect invalid key uh why it is so um just to check let me check this key over here student custom information prompt is fine U but before it was giving me output now why it is saying like that let me check with a key over here so my key and here is what here is my key just a second guys let me take a correct key uh okay don't worry I will delete this particular key uh I'm running in front of you everyone but after the session I will delete it fine so now I am having my key and here what I can do again I can run it great now let's see yeah now everything is working fine so this is what this is my response to two and here guys you you will find out that we are getting a output so we are getting output in whatever format we have defined this thing so we have defined this thing like uh name College grade and club now here you will find out the same thing so name is there college is there grade is there and Club is there if you don't if you want to change any sort of a description you can change it and you again you can check it and now actually we are not we we are not uh doing directly this thing we are using a function over here and this is a very basic use of the function as of now which I have shown you getting my point so directly also you can do that you can call it but here they have given the function by using this function also you can call it okay so here actually this is the basic use of the function and at this point of time you you won't be able to find out any differences in a direct call and in a function call both is looking same but now the difference will start once I will explain you the second example now over here you can see so this is the response which I'm getting now let's try to extract the response so over here what I can do I can write it down this a contain and let's see what I will be getting over here so here is what here is my uh content which I want okay which I want to extract from here so let me copy it and let me paste it over here actually I want to extract the content so that's why I'm going to be write down response to Choice message and content so once I will done it and over here I will be getting this content so here I am getting this content now let me check over here okay actually see here actually we have to get the content from the function call so till message it's fine so let me check with the message till message I think it is fine now if I want to extract the content now so over here I will have to call this uh I will have to write it down this function call because before I was extracting the message because directly I did it directly I I called my llm model now here I'm calling it but by us using function so here I've defined the format in a function I have defined the format of the function and now by using this function I'm calling my API so the the API is hitting the model and whatever output desired output I want I'm getting it now over here what I will do so here I'm going to write it down this uh dot function call so let me copy and paste it over here function underscore call now over here guys you can see we are getting this particular value now let me write it the argument over here arguments and this is what this is my output now yes same thing we can do over here as well so here I can write it down this uh Json Json do loads and here what I can do I can write down the json. loads and now see I'm getting a same output but see guys here at this point of time definitely you are not able to find out a difference between the direct function call and between this uh direct call and this function call right now I will show you one Advanced example and by seeing that particular example definitely you will be able to discriminate getting my point so till here everything is fine are you able to do it don't worry I will give you the code and I will give you each and everything whatever I'm writing over here and uh this file and all it will be available inside my resource section so here is the resource section guys uh so just try to enroll into the course and uh yes definitely you will be able to get this particular file inside this resource section and this is completely free you no need to pay anything you no need to P you don't need to pay actually a single rupees for this for this particular dashboard so please try to enroll and try to download the resource from there so till here everything is fine please give me a quick yes then I will proceed with a further topic what is the difference between Json and function call so here you will find out so just check the type of this output so here you will find out the type of this output is nothing let me show you it's a string now here I have converted into a Json that's it okay I don't I I don't want to keep it in a a string because uh it's not looking good to me if you will print it now if you will print it guys see it's not looking good to me that's why I converted into ajason now if you will check the type of this particular output so here you will find out a Json let me write it down the type over here and let me print it now so here is what guys tell me here is nothing it's a Jon not dictionary got it so this is fine to everyone I think till here everything is clear great now let's start with the second concept so over here uh the first concept actually I shown you the basic use of the function and all now let's try to understand the advanced use of this function calling so over here guys see uh we have few more thing regarding these functions and all so first of all let me tell you that now let's say if you want if we are passing a description of two student all together so it can handle that thing also it can handle that thing also now over here let me show you that particular uh that particular thing also just a wait uh I have I have a code for that and I'm going to copy and paste see guys so what you need to do so over here I just written one for Loop and let me show you that particular for Loop and here see inside this for Loop what I have written so first of all I Define one uh list and inside this list we have a two description so the first one you know uh already I written this particular description now let me uh let me run it okay so what was the name of that so just a wait let me check um okay where I have written this student I think this one so that name the name of the variable is student description so let me copy and paste over here let me copy and paste this student description so this is what this is the student description this is the first one so let me write it down student description over here now let me keep it over here now student description now I'm going to Define one more so here I'm going to create one more variable and here student description two and here guys what I will do again I'm going to copy and paste a same thing so this is the value which I'm going to copy and paste and I'm going to do some sort of a changes over here so instead of this s Savita I'm going to write down something else so let's say I'm going to write it down Krish n so and here Krishna is a student of a compter computer science I uh maybe instead of this delh let me change the name so here is what here is Mumbai now here he is a cgpn so he's having more than 9.5 cgpa so let me write down this like cgpa as well and here let me change the name so instead of Sunny what I'm saying I'm saying Krish is known for his programming skill and he's a member of here I can write down DS Club data science club data science club so here I am giving an information regarding two student now here see he hopes to pursue in a career in artificial intelligence after graduating something else right so now what I will do let me run it and let me keep this particular description over here so here what I'm going to do I'm going to keep this particular description now what I will do so over here uh I I'm just going to run the for Loop and here you can see one by one the description is coming and it is going through this particular uh completion API this Chad completion API and I will be getting a response so let's try to make some changes over here because it's a like old code let me give the latest one over here so this is the latest let me copy and paste the latest function so here is what here is a client chat completion. create now over here the model name is what model name is same now here message uh it's the same this one now let me write down the student so it will be more uh like clear to all of you so here here uh you can see we are calling a function now here guys see we are calling which function this particular function let me copy the same name so here the function name is what student custom function so here I'm going to copy the name of the function and let me paste it over here so this is what guys tell me this is my function name and here is function call is auto right automatically the function is going to be called now what I want tell me I want a response so over here I'm going to print this particular response and let's see we'll be able to get a correct response or not so if I'm going to run it guys so you will be able to find out a response regarding two description so it is saying that check completion is not a subscribable okay so over here I think I will have to paste this thing now let me copy it and let me paste it over here so this is the one I think it is fine now and this is going to be a response so response whatever response we are getting there is a choice and inside that we have a message and finally function call and from there we are going to collect a argument so once I will this argument actually this arguments you can map this argument with this thing this uh thing basically which I have written over here inside the function name College grade and Club getting my point so here what I'm going to do now here I'm going to run it and let's see what I will be getting so once I will run it definitely I will get a response great so here it is giving it has given me a response regarding the first uh description and now guys you can see it has given me a response regarding the second description so the first one is s sabida and the second is kishna you can give as many as uh like description in all so over here let me take the third one and let me keep it over here and here I can say so here student description three three now over here instead of this krishak let's say I'm going to write down one more name let's say sudhansu Kumar and here I can say that he's a student of IIT Hyderabad or I let's say uh Bangalore now over here he's a Indian he's having a cgp around let's say 9.2 and he's programming skill and he's a active member of mlops club now let me write it down over here mlops Club so now yes I have given this particular description over here and if I'm going to copy it and let me paste sit over here so regarding this description also definitely we'll be able to call our model we'll be call our API and finally we'll be getting a output it's doing the same thing which our chat completion API is doing directly without function right now we are doing along with a function along with a multiple description getting my point so here this is the basic use actually basic use of the function after this one I will come to the advanc use just wait now over here see if I'm going to run it so let's see what I will be getting uh so here I will be getting a First Response yes this is my first response now this is the second response and here you can see there is the third response getting my point guys yes or no we can call our llm model we can we can call our API we can hit the model and we can summarize the result according to the prompt if this thing is clear to all of you then please write it down yes in the chat please do let me know in the chat guys if this part is clear to all of you yes it's a case sensitive whatever variable you are going to Define in the function col it's a k so please make sure that you are going to write it down the correct name after this one the use of the function call will be clear just wait okay fine now this thing is clear to all of you now let me come to the next point so here actually what we are going to do see uh we are going to call a single function right regarding this particular description uh this is my function but we can call a multiple function also we can call a multiple function also so here guys let's say if we are going to define a one more function here let's say if we going to define a one more function so you can Define any sort of a function over here let's say function two let me write it down over here function 2 function _ 2 you can define a second function and after defining see you will Define in a same format whatever format is there this one in this format itself so in this format whatever format I have written now the variable and the parameter and the description U and those thing will be changed but the format will be a same because the same format which you will be find out over the tell me over the open a API s they already have given you that so this is what this is my function two now you can like Define a function two whatever information you want so let's say I just want this grade and club or whatever so right so if I'm going to remove it you can remove it or maybe you can Define one more function for some other information right and now if you want to call it so how you will do that tell me so for that actually uh here I have created this uh list right here we have created a list of the student information regarding a different different description now here again I can create one more list the list basically the list regarding this function so here what I can do I can copy this code and I can paste it over here this particular code and here what I can do I can create one more list and inside this list what I can do I can write it down the function so here is what let me a copy and paste so this see this is what this is my function parameter now here we have a first function and we have a second function so this is this is my first function which I defined already this one so let me copy this particular name and let me paste it over here this one so this is what tell me guys this is my first function which I'm going to write down over here and this is my second function already I given the same name so like this you can call a multiple function also getting my point so here I have defined this function and according to that I'm getting my desired output desired parameter you can create one more function on top of a same description and here you just need to do one thing instead of this specific function you just need to write it down this function you just need to provide this list and you are done according to the definition you will get output so this is your assignment you have to do by yourself I have given you the way I have given you the path now just Define a second function regarding whatever information is there inside the description whatever you want to extract just Define a function and call it over here so here I can mention this thing as assignment don't worry each and everything I will provide you uh this notebook will be available in the resource section you can download from there this is what this is your assignment guys now here this part is clear that uh we are calling up llm so here directly we are calling llm then what we are going to do see we have designed a prompt directly we are calling llm then what we are going to do we have Define a function then uh like we are getting that particular output that is also fine now we are going to call our llm by using openi with respect to different different description that is also fine means regarding a like different different description on the same time now we can Define two function as well more on more than two function that is also fine now what is the actual use of it still we are not able to find out the actual use of this function everything is looking same now let me uh explain you that particular part I'm coming to the advanced example now so over here what I'm going to do I have written one Advanced example and uh let me copy and paste uh the code basically which I have written step by step I will copy and paste don't worry okay so here guys see again I'm going to start from scratch now Advanced example of function call Advanced example of function calling okay now over here guys see uh what I'm going to do I'm going to call my chat GPT so here I'm going to copy and paste one code now this code actually we have defined something over here so here I'm saying uh what I'm asking I'm asking to my llm that what is the next flight from so here I let me change the name let me write it down Delhi to Mumbai so here I'm going to write it down what would be the next flight from Delhi to Mumbai this is my prank now just tell me guys will my Chad GPT able to answer for this particular question my CH chat G is able to answer for this particular question the question which I'm asking over here I want your uh like p uh like I want your opinion on that please write down the chat I'm asking to all of you can my chat GP answer for this particular question no why why it cannot be answer because like this chat GPT has stayed on the limited amount of data right so not a limited amount of data it has stay on uh the data basically which is available till September 2021 getting my point if you look into the chat GPT if you look into the open a just just go with the open AI uh not this one so where it is this one so here guys just just uh go over here and uh what you can do you can go into the models now over here just click on this GPD 3.5 and uh just look over here training data so it has trained up to September 2021 data up to this particular data that's why it won't be able to answer for this particular question whatever I'm going to write it down here now let me run it and let's see the response that what response I will be getting so over here uh yes it is giving me a response let's wait for some time I got a response now and here I'm going to run it so see what it is saying that it is saying that as an AI language model I don't have a realtime information however you can easily find out next flight from Delhi to Mumbai by checking the website or mobile apps of Airlines so that operate the route such as air india indigo spice jet vistara go Additionally you can contact travel agency or use online flight scratch engine for up to date now just tell me if you are going to create if you're going to create any chatbot by using this open API so will you give this type of answer to your user if your user is going to ask you that what is the next flight from Delhi to Mumbai definitely you will have to do some sort of a jugar right you will have to extract the information from somewhere you you cannot give this type of answer right so you will have to make your chatboard that much of that much capable you you have to make your application that much capable so it can answer for this type of question as well okay now let me tell you uh the use of the function calling over here that how function calling can help to us so over here what I'm going to do here I'm going to Define one function what I'm going to do guys here I'm going to Define one function so this is what this is my function just like observe step by step don't run anything don't write it down any sort of a code just observe whatever I'm explaining to you that's it so here is what here is my function function description now we have a name of the function get flight info we have a description get flight information between two location now here we have a parameter and inside parameter we have two things so the first one you will find out that is what that is a location origin and location destination so in my case what is the origin delhi now here in my case like whatever prompt or whatever question I'm asking in that case the destination is what destination is tell me Mumbai so there is two parameter I have here is a type here is a description here is a type here is a description that's it so let me let me change something inside the description also so here I'm I can write it down Delhi d e l and here let me write it down the Mumbai mu M mu M so this thing is fine now here if you will observe so I have mentioned one more thing I have mentioned one more parameter over here the parameter name is what the parameter name is required now what is required location required origin location required and destination is required two things is required over here okay that is fine till here everything is fine we are able to understand but still we didn't get a complete idea how you will get it first of all let me run the entire code right so here you can see we have a description so let me run it and this is fine this is like perfectly fine now here I have a prompt so let me copy The Prompt over here I'm not writing from scratch because it might takes time so I already return in my notepad and all somewhere so I'm just going to copy and paste that's it so here guys um I'm asking to my chat GPD or sorry I'm asking to my GPD model when is the next flight from New Delhi to Mumbai this is my question now over here if I'm going to run it so here guys you will see that okay so this is my this is my user Prem now what I'm going to do now I'm going to copy it now I'm again I'm going to copy the same thing this one and I'm hitting this particular prompt so here is what here is my model here is my role role is what role is a user and here is my prompt getting my point now here now I'm passing my function just focus over here just focus now over here I'm passing passing my function function underscore description this is what this is my function description now see over here uh this is my prompt and if I'm going to run it now if I'm going to run it now now you will see the response that what response I will be getting before actually I was getting this particular response before I was getting this response now just look into the response that what will be the response over here so here what I'm going to do I'm going to copy the same thing uh this particular thing and here I'm going to write it down response to response to choice choice message and contain so once I will run it so here you can see it's not giving me anything okay so why it is not giving me let me show you because there is no such content there is no such content that's why it is not giving me anything now let me print till message only and you will find out the uh the like values over here so over here guys see if I'm going to print till message so it is giving me a message whatever message I'm getting step by step we'll try to understand it don't worry now here let me copy this thing and let me check with this particular argument so here I'm going to copy this argument and let's see what argument we have uh so over here it is saying okay first of all I need to call this function call and then only I can call this argument uh not an issue fine now over here we have a argument see we have two argument first is loc uh location origin that's a Delhi and location destination that's a vom getting my point guys see it is going to extract from here location origin and location destination and here is Delhi here is Mumbai this is a location origin location destination now it is not giving me answer but it is going to it is it is it is able to extract something right from this function call and here you can see these are this is two argument right there you will find out two argument this is the argument basically which we are able to get it from here because we have already defined it over here this thing okay that is fine this is clear to all of you now guys see how you will uh give this uh like flight actually so for that you will have to call any third party API then only you will be able to provide the information now right so let's say if I'm talking about the make my trip so what it does it is having access of a different different API if I'm going to book any train ticket so is calling the IR CZ API and is giving me the entire detail make my trip is not a owner of the Railway where it is having the entire data entire information of the Railway Indian Railway no IRCTC actually it's a organization actually that is a portal which is like governed by the uh Indian government and like it it is having some sort of apis and all which is being called by the make my trip or any other website and because of that only you are able to get an information whatever rails and all whatever flights and all you are going to find out over there or maybe some other website right so here what you will do for getting this information you will call the API any third party API now here see I'm not going to call any sort of API I'm giving you as assignment this thing so you can call any sort of API you can explore a different different API and you can accept the information from there I'm uh I can uh give you the very basic name rapid API just go through go and check with the rapid API there you will get the each and every API related to the weather related to the different different thing as of now what I did actually I created my own function which is working as a API I created my own function which is working as a API now let me give you that uh let me show you that particular function so here what I did I have created my own function which is working as a API you can think this working as a API but you can call your real time API for extracting a real data don't worry I will show you that thing I will uh show you how you can call the Sur API in my next class when I will discuss about the agents in a lang chain there I will discuss about the Sur API and all so over here you can see guys we have a uh I have created one function get flight info location origin location destination now here I'm going to be uh like here I written some sort of a code that is what that is nothing as a flight information and it is in a dictionary format so here we have a location origin destination date time Airlines and flight this is the airlines time and this is the flight number and all now here this function is working as a API you can think like that now if I'm going to run it so over here uh it is working fine now guys see what I'm going to do here so this function is working fine now here uh I'm going to collect this origin and this destination so first of all let me show you this particular thing uh argument I already shown you this one this is my argument and over here uh what I'm going to do I'm going to be convert this argument into a Json so json. loads now over here what I'm going to do so let me run it and here I am I having two argument uh first is Delhi and the second is Bombay this is my origin and this is my destination so this thing this information I'm going to collect in my like a variable that is perams now over here we have a variable that is perams now from here I'm going to extract few more information I want to extract the origin and the destination so for that I already written the code let me copy and paste so this is my origin so I'm calling this get uh method on top of this uh dictionary actually this is my dictionary and I'm extracting a value of this particular key as like this I'm extracting a value of this particular key you you can see over here let me show you so this is what this is my dictionary now on top of this dictionary if I will call this get method now uh by using this uh key so get and over here what I will do I'm going to write it on the key so the key name is what location uncore origin now over here see if I'm going to run it now you will find out this Delhi so this is my origin and here you will find out the destination similarly I can get the destination also now it's not a big deal see now over here I can call this a destination why I'm doing it entire thing will be clear and I will give you the quick revision also just wait for some time just wait for more 5 minute everything will be fine so Delhi is there Delhi and Bombay is there so here we have origin and destination now we got both origin and destination right so parameter is uh we are able to get a parameter we are able to get origin and destination now let's try to find out the flight detail right so let's try to fly find out the F flight detail so for that basically what I'm going to do here I'm going to call one uh so here I'm going to call one method that is a a right so what this a will do so here actually I'm going to pass the name so let me show you this particular value what is happening over here so just a wait let me copy and paste over here so this is what this is the name this name is what this is the function name get flight information right now I'm giving this uh function name uh this uh function name this GL get flight info which is a string as of now let me show you the type of this function over here so over here what I'm going to do here I'm going to write it down type of this function so this type of the function is nothing it's a string only so let me uh keep it inside the bracket so this is what this is a string now if I'm passing this thing to my eval function eval method so you will get the actual function this eval is doing nothing this EV is giving you the actual value that's it this is what this is the function now we have defined get flight information it will give you the actual value that's it so here you can see it is giving me the function only this is what this is my function this get flight info is what it's a function now it's not a string we have already defined it over here see this one so this is doing nothing it is just giving me actual value okay now let me show you one example very basic example let's say if I'm going to write down and here if I'm going to write down two now tell me what is this two if I'm going to write down like this uh type and here I'm going to write it down two just tell me what is this it's a string but two is a string no it's an integer right it's a integer so if I'm I'm going to write it down like this now if I'm passing to my so it will provide an integer see this is what this is an integer if you check with the type so type the type will be an integer only so it is converting whatever value we are passing into the well method now it is converting into a original format into a original form so here we are getting a function so this is what this is my function which I collected over here now I just need to call this particular function so here I'm going to call this function now after calling this particular function I will be get see here I'm going to pass the parameter keyword argument keyword par like this this particular parameter params this one okay location origin and location destination this two thing we want over here this one right now once I will run it so here I will be getting my details so let me run it first of all uh where is a perms here is a perms and here is what here is my flight details so name date time is not defined let me Define the date time over here so from date time on of date time import date time and it is done I think now let me run it time Delta is not defined let me check what all import statement is there just a wait time Delta also we can import from here itself so this is going to be a time Delta great now let me run it and over here you will find out a detail see so actually what we are going to do uh this function actually uh you can think it's a it is working as a API got it now here what we are going to do so we are extracting a information from the uh like whatever prompt and all we are passing now so from there basically we are extracting an information and we are collecting a detail of the flight okay from U like this is the response actually see first what I did I defined a function this is what this is my function this is what this is my function right after that we are calling the uh after that we are hitting to the uh like model by by using this open API now after hitting it so actually whenever we are checking with a response so in argument actually in a function argument we have this two thing now by using this two thing now what we are going to do so we are uh like extrating the information from here so as of now this is this function actually you can think it's my API but you can call actual API by using this particular information that is what I'm doing over here just just think over here that is what I'm doing so now what I did what I got tell me guys so I I collected the information whatever see I Define the thing inside my function inside this particular function okay this one this is the value this is the like parameter which I defined now I uh I like called my model I called my open API and it is hitting the model right so whatever response I'm getting now from that particular responses I'm getting this particular argument because my chat GPT is not able to answer for this particular question and by using this argument I'm hitting my API I'm hitting my API and after hitting the API guys you can see this is the detail this is the information I'm getting okay by using those particular argument now let me show you the complete one so once we are getting this particular information the flight information regarding those particular argument okay you can create an end application here I'm showing you in a notebook itself so here see guys what I'm getting now give you the final code so we are getting this particular information and is done now let me uh go for the final call so here you can see uh I can keep it as a uh response three client chat completion create now here is what here is my model and here is what here is my user prompt whatever prompt I I'm passing now see guys over here see role is what role is a function now I have changed the role okay uh here is a role role is a user now role is a function function now this is the value I'm extracting from the function whatever function I'm defined and here is what here is a like content basically which I'm passing this is what this is a flight right so this is the argument which we are extracting from the function whatever function I have defined right and then this is what this is my function description that's it right so here see guys uh my role role as a user as a role as a user basically what I'm asking to my uh chat GPT or sorry to my GPT model let me show you that so over here what I'm going to do I'm going to print it this user prompt this is my question this is my prompt this is what basically which I'm going to ask right now over here roll again I Define one more role that is what that is a function right now over here I'm going to pass the name and here I'm going to extract the like function the the ex exact function over here you can check over here you can like copy it and you can paste it over here this one so just just paste and you will get this function called now just collect the name name of the function do name so what is the name of the function get flight info right now here is what content is nothing content is a flight now as soon as I will run it so here you will be able to find out that we are able to extract the information now let me show you this response three so here is what here is my response three and guys see what I'm getting over here so let me print the final one and here you will be able to find out a detail so let me run it see guys so now let me call the uh this uh function call just a second function uncore call function _ call and over here guys you can see we have argument and actually we have a message over there just a wait let me show you that also uh function call and argument okay just a wait oh message inside the message message itself I will be able to get it uh where my message is coming inside a choice and here okay I need to call a Content actually just a second message function call this is my function call that is fine now here Choice uh just a second choice what we have inside a choice okay it is a response three fine fine fine I was checking with a response two uh yeah this was a response now it is fine it was a response three I was checking with a response two it's my bad it's my bad uh okay now let me collect the message from here so here is what here is a zero and uh now let me call this message so here is my message and let me collect the content tent and here is what here is my content guys so did you get it what is the use of this function calling now let me give you the definition of this function calling in a single line so just a wait I'm giving you the definition definitely you will be able to relate now so if we are talking about this function calling now so here is a definition of it let me copy and paste so what is our definition of the function calling so function calling is nothing learn how to connect large language model to the external tool that's it we can define a function we can Define the parameters we can Define the values and according to that we can get our responses from the third party API and here I have defined this particular function M function is a third party API but you can call the realtime API and you can get the information you can get the exact information this thing is clear to all of you yes or no how many of you you are able to get it how many of you you are able to understand this thing if you can let me know in the chat so I think that would be great again I will try to revise it uh I will give you the quick revision of it and then I will move to the link chain will you revise it please do let me know in the chat will you revise this concept I'm waiting for a reply if you can answer me in the chat I think that would be great yes I'm going to revise it just wait just give me a second first of all uh do let me know how much person you got so if you can tell me uh in a percentage also so that would be great I will get some sort of idea that okay you are getting something from here whatever code I'm writing you're getting from here so please uh do let me know 80% great 70 70 80 yeah if you're getting 70 or 80% now so I think rest of the thing like you just need to revise Sor is saying sir I'm just getting 10% so Sor in that case you need to follow from a very first session just check with the very first session and then come to the second one and then come come to this third one if you are near to 70 to 80% now then you just need to revise it once that's it yes correct uh your understanding is correct here we are extracting value from given prompt using function call what is the meaning of the role is equal to function which one here we are defining now see we have a user so user is asking a question and rest of the information we are going to collect from here we are defining one more role we have we can Define many roles over here um we can Define uh like uh we can Define the system we can Define role as assistant we can Define role as a user user we can Define role as a function user is asking something and uh and uh from wherever basically we are going to be get output or we are getting a uh we are we trying to exct the information regarding this particular prompt so we are defining as a rle over here that's it great so let's revise it now and then I will go for the Len chain so we'll try to understand the langen chain and all already I have installed this L chain and try to hit the open API and tomorrow we'll understand the lch in a very detailed way uh today uh just a quick uh understanding quick uh uh first of all I will give you the quick recap of all those all this thing and then I will come to the lon part so let's understand this function calling one more time from scratch great so over here see we are talking about this uh we are talking about this chat completion API and I think you know about it how many time we have discussed so we're passing the prompt here is my prompt and we are getting the output now Today I Started from the like a different type of prompt so uh today I have started from the function calling so here I have defined one description and here I'm writing uh the prompts my prompt is saying that uh here you need to extract this information from the given description that's it now here you can see uh this is my client this is what this is my client now here I'm going to call my chat GPT and sorry I'm going to call my GPT model so after that what I'm getting I'm getting my response I'm going to convert into a Json and this is fine right this is fine anything you can ask to your model and you can print as a response you just need to define a prompt that that's it now here the same thing I'm going to do by using this function so here I'm going to do uh the same thing by using this function now here I'm going to define a several parameter so this is my parameter name College grade and Club it should be a same similar to this prompt itself whatever prompt I have defined I have written right so just look into the prompt I will share this notebook then you can check it should be similar to that only this particular properties this particular values now over here uh you will find out that okay I again I'm going to call it again I'm working I'm like role I've defined as a user there's a Content prompt and you are getting a response and here you are getting a response now guys here you can see we are going to print a message and finally we are getting a same thing by calling this uh by using this function call as well now here actually once you will look into the prompt we have defined one thing over here we we are saying that uh return it as a Json object return it as a Json object so whatever response you are getting now from from the openi side also I tested the same thing of the CH GPT see I given the description this was my description and CH GPD has given me output is a Json format so if you are calling it now uh this uh like a GPD model so it will give you the output in a Json format this one so here it is giving you the output this particular output in a Json format this one actually it's a string but yeah we can convert into a Json and that is what I did now the same thing why we are doing by using this function now over here H it's fine it's clear now here I've given you a few more uh like functionality regarding this function I can call it for the several description in a single sort I just need to keep the for I just need to write down the for Loop over here so I'm getting a multiple responses for sun for Chris for sansu right so here I'm getting a multiple responses now here I given you an assignment so here I told you that you can call a multiple function also don't call a single function here I'm getting an information from the single function but you can call a multiple function and here I shown you the way you just need to define a function in a list and that's it so here is a function you just need to define a function in the list and just pass it over here and according to that only you will get a response getting my point now here I've shown you the advanced example of function calling and that's a real use of the function and here if you want to Define this function in a single word in a single line if you want to understand this function in a single line so here you can see this is the definition learn how to connect large language model to the external tool so here what I want to do so here let's say uh this is my model and here I'm going to write down some sort of a prompt where uh like it is going to be a request and here I'm getting a response now this prompt actually it's something uh related to a real time I'm asking a real time question that just give me the flight just tell me like what all matches uh we have in upcoming days or uh just tell me the weather okay something like that so I'm asking a real time information it won't be able to provide it to me in that case what you will do so you are not going to call your llm now because it is not trained on that uh on it it has not been trained on top of that data actually if you are talking about this GPT so this GPT actually train on this uh till actually till September 2021 so this GPD train till uh 2021 only now in that case whatever prompt you are going to be write it down you won't be able to get a response right so here this function calling comes into a picture so once you will Define the function now so here what you will do you are going to define a function you are going to different Define a different different arguments and all each and every information you are passing to this function that's it now you just need see here this argument what you will do by using this particular argument you will call a third party API third party API third party API now you will call this third party API here or whatever function you are going to Define and whatever prompt you are writing according to that you will get a response because this llm is not able to provide you the response right and the same thing the each and everything you can do by using the chat completion API only chat completion method you can say chat completion API or chat completion method both are fine by using this chat completion method now let me show you in terms of coding so over here if you look into the code so I'm doing the same thing here I have defined a function see this is what uh first of all I'm asking to my first of all I'm asking to my uh llm model it is not able to answer now after that what I did I defined the function got it after that I defined a prompt I'm passing to my model I'm passing to my actually uh this uh like chat completion method so here is my user here is my prompt and here is my function description by doing that what I'm able to do I able to extract few of the uh few value whatever is there inside this function whatever I have defined over here because here I'm writing in this function description now after that this value I'm using and this is what this is my API okay this this is my like it's not a real API it's like a virtual API whatever you can say now whatever value I'm passing whatever uh thing I'm collecting from here I'm passing to this API and I'm getting a response over here this is the response this is my response got it now what I will do here now I compiled each and everything over here inside this chat chat completion method so how I compile this is my model this is my prompt this is my user this is my prompt this is my function call this is my function call along with the argument and over here this is my function that's it if I'm going to run it now it is going to extract the information from the third party API which is my function as of now now you can take as assignment you can call the real time API you can use the rapid API you can do that you can call a real time API so now this function calling is clear to all of you yes or no correct ran your understanding is correct now your understanding is correct and I think you are able to get it now let's start with the length chain so we have a a 10 minute uh now we can understand the concept of the length chain and then from Tomorrow onwards I'm going to start with the Len chain now first of all let me write it down the uh code for the Len chain so here I'm going to write it down Len CH and here uh you can I can mark down it and uh so first of all guys what I need to do so I'm going to start from the Len chain uh so the first thing very first thing uh I need to import it so let me give you the entire code okay so step by step let me write down each and everything so first of all I have to import the Len chain so here I'm going to write it down import length chain now here I have imported the Len chain now from this like in this lure actually we have a different different modules we have a different different module and inside that we have a different different classes so as of now we are going to use the open AI so here I'm going to write it down from Len chin from Len we are going to import this open AI so lenin. llms and here I'm going to write down this open AI okay so we are able to import this open AI now what I will do so initially I told you that this lenon is nothing it's a wrapper on top of this open AI so you can think that this is my open AI right this is what this is my open AI now on top of this open a on top of this open API this lench is nothing it's a wrapper okay so this is what length chain now here whatever request we are making whatever request we are making right so now we are not directly using this open a now we are not directly using this open API instead of that we are using this L chain so our request is going through to this a len chain and then it is hitting this open AI but this Len chain it is not restricted to till here itself we have a many uses of the Len chain getting my point this Len chain is not restricted to this one only we have a many uses of the link chain I will talk about those uses and this Len chain actually it's a very powerful uh it's a very powerful application it's a open source I will show you the source code as well uh even we can search about it so let me show you that uh let me show you the source code of the Lenin so here I'm going to write it down Len Chen Len Chen GitHub so here is what guys here is a len Chen GitHub uh just a second yeah so this is a lenion GitHub now you will see the number of folks the number of star number of folks number of start number of watching right so number of watching in a real time and this length chain is really amazing let me give you this link inside your chat please try to uh explore it by yourself and it's a very uh Power powerful and very important as well if you want to build any llm based application so you can use this length chain it's a it's completely op source and here you can see used by 40,000 people and here is a number of contributor you can also become a contributor if you like to contribute in a open source now here you can see the commits 7 hour ago they committed something just just go through with this commits and check what thing they have committed what what changes they have made over here try to understand it and this package actually it is available on the pii repository so just go over the pii repository pii Len chain and search about the Len chain and here you will find out this Len chain this is what this is a len chain guys this is a like they have hosted the package on pii repository and it is a latest version of The Lang chain now here also just just uh scroll down here also you will find out the same thing uh deployment so they are doing a deploy here is a package package see this is the release so 0.0.3 46 0.0.3 46 this is the latest uh version which you can see over here as well this one is uh so far they did 297 release total 297 release see this is the total release actually total number of release now you can see over here as well just go inside the real uh just go just click on this release history and check the uh entire uh like release related to the length CH got it right so here is a latest version of the Len chain similarly we have a llama index two also and this Len chain is a open source and the Llama index 2 it's a framework from The Meta we can do a same thing by using this llama index 2 also I will come to that I will come to the Llama Index right now over here see we have this Len chain we have this openi now let's try to create now let's try to create object of this open Ai and here what I need to do guys tell me here I'm going to here I'm going to pass pass my open a key so first of all uh I will have to pass the parameter now let me um give the parameter over here and here I need to write it down this my key and here is what here is my client right now I just need to call one method and my method is going to be a predict right so my the method name is going to be a predict so let me write it down over here Cent c l i n t dot predict now here what I need to do here I just need to pass the prompt prompt is what prompt is a input whatever input we are passing to the model that's it so let me Define The Prompt so here I'm going to write it down the prompt and this prompt let's say I'm going to ask to my model what I can ask so I can ask can you tell me total number of country total number of country in Asia so here is my question so I just asked a little tricky question not a tricky actually it's a straightforward so uh here is my question my question is what my question is can you tell me total number of country inia now this is called guys zero short prompting what is this tell me this is called zero short prompting this is what guys tell me this is a zero short prompting now here if I will run it and here if I will pass my prompt to My Method client don't predict so here you will get output so here it is saying that there are 48 country in Asia if you would like to uh if you want to name then here you can mention can you give me can you give me top 10 country name so here uh I have extended the question now and now see over here I will be getting a name of the country so it is giving me the sash slash sash is nothing it means it means that if I'm going to print it now so it will print after two line so for that what you can do you can just call this a strip SD and it will strip your output so here you will find out the correct output so there are 48 continer isia the top 10 country by population in Asia these are the country now here if I'm going to write it on print so you will get a output in a correct format so here guys you can see you will get output in a correct format so there are total 48 country in Asia and these are the top 10 countries China India Indonesia Pakistan Bangladesh Japan Philippines Vietnam Iran and turkey got it guys how to use lch I just given you the introduction of that but there are many more things so all the things uh uh the remaining thing definitely we are going to discuss in next session as of now just think that this uh lench is nothing it's a rapper on top of the open AI but it is having a lots of uses it can call any third party API it can call any sort of a data resource it can uh like uh it it it is having a power to read a different different documents it's a having a power to making a change to making a memory it is having a power it is uh it is not only for the open AI we can use this lenen for any open source model any open source llm model and tomorrow I will show you here I have used so let me write down tomorrow's agenda what all thing we are going to discuss tomorrow tomorrow uh tomorrow's agenda so we are going to uh cover hugging phase hugging phase API with Len chain uh and we'll try to understand the use of the Len chain use of the length chain so we'll try to understand this use of the Len chain in very detailed way so this will be the agenda for tomorrow's uh like this this is the agenda for tomorrow's class and after that I will directly jump to the project we try to create one project and with that your understanding will be clear and rest of the topic we'll cover after uh after the project and all so tell me guys how was the session did you like this session uh did you uh did you got everything yes or no whatever I have explained yeah meanwhile you can explore it by yourself that is a good idea tell me guys fast uh did you like the session please do let me know in the chat if you are liking the session if you're liking my content I have WR and I I created each and everything from scratch by myself only and believe me if you are following this notebook if you are following my content you won't face any issue and even in our interview also you can answer in a better way okay so I think uh now uh we have covered all the thing whatever I told you and uh yeah all the resources and all you can find it out over the dashboard so we are uploading each and every resources in a resource section so just visit the dashboard and here uh we have all the videos videos and quizzes assignment each and everything we are going to update over here so along with the session you can and practice now here uh we have our resources regarding the first session so all the all the PDF and all all the PPT so at least you can revise the thing you no need to go through with the video again and again you can directly uh download the resource and you can look into that if you have attended my live session and here we have a IPO NV file also so just visit this uh resource section and this is the IP VB file now I will update this IP VB file in my day three video and along with that we'll be having some quizzes assignment and don't worry I will give you more assignment more quizzes and see in between whatever I'm leaving so here I told you that you need to create your own API this one uh in an advanced example of function calling so just use any API okay just search over the internet I told you you can use Rapid API and try to get a realtime data instead of this uh dummy function which I created over here you can take it as assignment here I told you that you need to you can use multiple function right in a single shot just try to create one more function define it in your in your own way and then uh run it and uh get an information so here I'm getting an information regarding three user you can add more user and you can add multiple function over there so now let's start let's begin so in the previous classes uh in the uh previous three classes actually I have talked about the generative Ai llm and then I came to this open Ai and yesterday I have I did the detailed discussion on top of this open Ai and I have introduced the Len chain to all of you uh so guys this is the notebook inside this notebook I have kept each and everything whatever notes whatever code and all whatever thing I was doing all right so uh in terms of code and all so each and everything I have kept inside this particular notebook and this notebook is available inside your resource section so from where you will get a resource guys so for for that uh you need to go through with the dashboard so here is your dashboard here you will find out uh here you will find out all the recordings U Day One recording day two recording day three recording so just try to go through with the day three you just need to click on the uh day three and here uh check with the resource so go inside your resource section and this is the dashboard guys generative AI Community Edition English so here you will find out uh two dashboard uh the two Community dashboard one for Hindi and one for English so this is for the Hindi one U actually I'm taking a same classes on a Hindi uh Channel as well I on Hindi I on teag Hindi you can search over the uh YouTube and the uh it's it is your one this English one so just go and check with your dashboard you will find out all the recordings and all so click on this day three and here check with your resource section so okay so resources is not there I have already given to my team but don't worry I will check and here is what guys here is a a notebook so uh definitely I will provide you this particular notebook inside the resource section so you all can run it you all can run it and by running it you can uh revise the thing and all and apart from uh this notebook apart from this resources you will find out the quizzes and assignment also so please try to enroll to this dashboard try to visit the Inon website sign up over there login and then uh enroll into this community session for this commun session you no need to pay anything it's just it's a free one okay so just just go through with the Inon website and login um after sign up do the login and you can access this particular dashboard and you will find out the same dashboard in a description also so just just try to check the description of this video of this live section you will find out the dashboard or else you can check with the previous Live recorded session also which is already available on the over the Inon YouTube channel got it so this uh resource uh part is clear to all of you now in today's session what all thing we going to discuss so guys first I will will start from the Len chain first I will explain you the complete Len chain that what is a len chain what all things we have inside the Len chain why we should use it why it is too much powerful each and everything we'll try to discuss regarding the Len chain and after that I will come to this hugging phase I will explain you that how you can uh how you can use any any like open source model from the hugging face Hub got it yes or no so in the previous class I told you that whatever model whatever model is there over the open AI platform how you can use that by after generating a API key now in today's session after discussing this lench I will come to the hugging phas and I will show you I will show you that after generating a API key hugging face API key how you can utilize that particular model so each and everything uh we'll talk about in today's session uh whatever I have told you and after that we'll start with the project so in tomorrow's session or maybe day after tomorrow so I will start with the project end to end project I will use this openi concept hugging face concept linkchain concept and I will uh show you that how you can create a web application end to end web application and then we'll come to the advanced part like vector databases and some other topic so I think uh everything is fine uh the agenda is all clear uh so please give me a quick confirmation in the chat if we can start then and whatever I have explain you whatever I have explained you so far so it is clear or not so please do let me know in the chat uh if it is clear and if we can start then I'm waiting for your reply fine so I got the answer now great so let's start uh let's start with the topic so in this uh uh notebook itself I'm going to write it down the entire code uh of the Len chain so whatever thing is there regarding the Len chin I will try to do here itself and whatever thing uh things will come into the picture uh whatever other libraries and all so definitely we'll try to install all those library in the current virtual environment now here guys uh I told you that how to create an environment how to uh launch the Jupiter notebook how to install the openi over there how to uh like install the langen each and everything I have discussed in my previous session so if you don't know about it so please go and check with my previous session there I did a detailed discussion regarding the environment setup got it now here guys um already I have written some sort of a line some U like sort of a quotee for the L chain yesterday actually I I like uh I was uh I I have imported the Lenin and I have used the key the openi key and basically I have imported this openi class and I created a object then I uh written a prompt over here and here I was uh like giving this prompt to my open API and in the back end it was running the llm model and here you can see this is what this is my output got it now here I I had written actually this this this is the today's agenda whatever thing we are going to discuss in today's session so hugging face API use of Lang CH and all so each and everything we'll try to do here itself in the uh in today's class itself so first of all let me write it down each and everything over the Blackboard so with that you will get a clearcut understanding regarding the agenda and all that whatever the thing I am going to discuss and after that I will come to the code part code section so let's start uh with the agenda now in today's class guys we'll be talking about the Len chain so let me write it down over here in today's session we're going to start with the Len chain now what is a len chain why we use Len chain and what is a difference between this open a and this Lenin so each and everything we'll be discussing over here itself now the first thing the first thing which we going to discuss in the Len Chen the first thing how to use Len Chen or how to use open a uh how to use how to use open AI by a lang chin so how to use open AI via Len chain that's the first thing we'll try to discuss got it after that I will come to the prompt template prompt uh templating so how you can do a prompt templating by using this Len chin so the second thing the second topic which we're going to talk about that will be a prompt templating promp templating the third thing which we're going to discuss inside the Len chain that will be chains we'll talk about the chains that what is a chains uh how we can utilize this chains what is the meaning of the chain how uh what all the different different type of chains is there each and everything we talk about over here then we'll talk about the agents that what is the agents okay so we'll talk about the agent that what is the agent and what we can do by using this agent so each and everything we'll try to discuss regarding this agent and here if uh so here I will show you that how you can use the Google API so by using the Sur API so what I will do so by using the surp API I will try to I will try to use the Google API Google API Google search API so in the agent section I will explain you this particular thing and after the agent the fifth one the fifth topic which we're going to discuss that's going to be a memory so we'll let you know that how we can retain the memory how we can retain the memory like chat GPD is doing how we can do the same thing if we are using this open API so we will try to discuss this memory uh memory part as well and which is a uh like which is available over here inside the lench and by using this Len Chen we can implement this particular feature after this memory I would come to that uh document loader so uh how we can load our different different type of documents so document is nothing documented just a file like PDF file CSV file tsv file or any other file how you and load that particular document so we'll talk about a document loader as well so here let me write it down document loader after completing all these thing then I will come to this hugging phase hugging phase I will show you how you can I will show you that how you can uh generate a hugging face API key hugging face API token and how you can utilize any sort of a model whatever model is is there over the hugging face Hub so how you can use that particular model so I will talk about the hugging face after that and finally we'll move to the project section so uh this is the agenda for today's session for today's class and apart from this each and everything I have explain you how to generate a open key how to uh like use a open a what is chat completion what is a function calling and all even I have talked about the basics of the langen as well so if this part is clear to all of you so please do let let me know in the chat if till uh like if the agenda is clear so I just want quick yes in the chat and please do let me know how many of you you are writing a code along with me because today I will go a little slow so you also can write it down the code along with me please do let me know guys please write down the chat good I think many of you you are writing a code mhm uh just a wait just uh give me a second fine so let's start with the uh agenda now so here guys you can see I have written a agenda and first of all uh let me explain you that what is a len chain why we are not using this openi API why we are using this Len chain and uh why it is too much important this Len chain and this llama index to so first of all let me talk about uh the differences between this open Ai and this Len chain and then I will come to the implementation part so here uh first of all let me write it down the limitations of the chat GPT sorry limitations of the open a API uh limitations of open AI API now here guys see uh if we are talking about this open API so here you won't be able to find out a free model so the first thing actually the first thing uh in the limitation uh like which we are going to talk about so here open a model is not a free one so here let me write it down open AI model open AI model open AI model is not a free now let's see uh let's assume that okay so the model is not a free one and if I want to use the llm uh like if if I want to use the llm capability or that AI capability in my application I if I don't have a budget so what I will do I will go with the other option other free option open source option okay so let's say some XYZ organization some XYZ organization created one llm now I want to use this particular llm so yeah definitely what you can do you can use the uh API whatever API this XYZ company has given to you and by using that particular API you can use this particular llm right now let's say you don't want to use this llm you want to use some other llm now how you will access it by using the different API now let's say if you want to use some other llm whatever llm is there let's say uh one LM is over the hugging phas Hub right if you want to use that particular llm large language model from the hugging phase right if you want to use it then definitely you can use it by generating that particular API key but guys just think over here uh yes we are using a different different API over here first of all uh we were using this openi API but as you know that openi model is not a free one for uh uh like if you want to use it so definitely we'll have to pay something and how we're going to pay it so based on tokens yesterday actually uh day before yesterday I shown you the uh the token price and all that how much you will be a charge if you are going to use this openi API if you are going to use a different different model over there I told you regarding the input tokens output tokens each and everything I have discussed so just go through and check with the previous session okay so if you are not aware about it now let's say if I want to use any XYZ llm or any other llm so how you can use it by using their API key but just think that uh just think on top of it if why not like if we have any one solution so the one solution actually it can interact with several apis right so here I'm using this open API I if I want to access this particular model definitely I'm using this XYZ API or let's say some other model for that I'm using this XYZ API or maybe I'm downloading it but just think on top of it if we have any single solution for all the llms with that particular solution if we can access all the llms to that will be well and good now so lenen provide you that capability Len chain provide you that capability so by using this Len chain you can access any sort of a llm right I will let you know that uh what all llm and let's say this openi is not a free one now let's say if you want to access a model from this hugging phase let's say you want to access one model from the hugging phase so this length chain gives you that particular capability by using the Lang chain you can access the model from the hugging face also and from a different different apis I will show you what all apis this Lang Chen is having I will come to the documentation so Lang Chen is not restricted till this open AI it is having an access of a multiple API that is the first thing here is a limitation and here I told you the advantage of the Len chain I think you got my point now the second thing if we talking about this GPD model uh if we are talking about the GPD model you know this have been trained till September 2021 data this train till September 2021 data if I'm going to ask anything to my chat GPT or if I'm going to ask anything to my GPD model definitely it won't be able to reply me and you all agree with this thing getting my point so if you will ask to the chat GPT that uh just tell me who won the recent Cricket World Cup will the chat GPT uh able to answer this particular question no it cannot answer to this particular question because this have been trained till September 2021 data so for that what I will have to do I will have to call any third party API for extracting the information yesterday I was doing by using the function C in op open a right but here by using this length chain we can do in a more efficient way getting my point why we use this length chain because here if we are talking about if we are talking about this uh like if we are talking about the limitation of the GPT so I can write it down over here uh it is uh it is having limited knowledge so let me write it down over here it is having it is having it is having a limited knowledge a limited knowledge till 2021 so if I want to extract something if I want to extract something if I want to exess some extra if I want to exess something which is which happened uh recently or uh any like real time information so for that also like we use this length chain and apart from this you will find out uh like different different like function or different different functionality inside the Len chain this Len chain actually it's a more powerful so here there I have given you two main reason that why you should use the length chain now here by using this length chain so let me write it down over here by using the different color so we are talking about this length chain so by using this length chain what you can do you know so you can access any model okay so you can access different llm model different llm model by using by using different API whatever API this lenion support by using different API second thing you can access you can access you can access uh uh private data resources private data sources you can access uh any third party API so here let me write on the third point you can access you can access any third party API got it so this is the uh like some features of the length chain now if we are talking about this length chain so let me do one thing let me create one Circle here what I'm going to do so here I'm going to create a circle now here I can write it down inside this particular Circle I can WR write it down this length CH so what I'm doing here I'm writing down uh just a second so here I'm writing down length chain now what this length chain can do so this lench actually it is having a chain so it can create a chain I will tell you what is a chain it can read the documents okay so document loader it is having a document loader now here I can write it on the third one so it is having a concept of agent for accessing any third party API agent now this can access any sort of llm so let me create Arrow over here so here I can do one thing I can uh give the arrow so what it can do so here uh let me keep the arrow so it can access any sort of a llm large language model from a different different API whether it's a open AI or any other API I can give you the example of two as of over here hugging face hugging face and open Ai and open AI and it it is having a access of a different different apis as well so it is having agent it is having a chains it is having a document loader and it can retain the memory as well so we are talking about the fifth one so it it it can retain the memory so let me write it down over here what it can do guys tell me so it can retain the memory it can retain the memory I will uh come to that memory part so this one langin actually it can do a multiple things it can perform of multiple things and here I have written a couple of limitations of the openi API and this is a limitation which you will find out inside the openi API openi model is not a free one and it is having a limited knowledge so here guys you will uh so what is this what is this Lang chain so here this Lang chain actually it's a open source framework which provide you a multiple functionality with that you can create a agent you can connect with any third partyy API you can create a memory you can retain a memory you can uh read a different different kind of documents like CSV tsv PDF or whatever and here you can create a chain you can create a prompt template also I forgot one thing so here I can write it down you can create a different different a prompt template so let me write it down over here different different prompt templates got it are you getting my point so if we are talking about so see if we are talking about in terms of openi the code basically which I have written inside uh my previous class this one so what is this it's nothing now instead of using open API directly I'm using one wrapper on top of that that is what that is a len chain so over here let me write it down one more thing one more point so just just think over here that this is what this is my open API let me let me draw it over here so here is what guys tell me so here is my open AI API this one now here we have a L chain sorry uh here actually see this is open a API and how we are making a request to this open API so this is what this my Lang chain now if we are going to run any sort of if if we are passing any sort of a prompt right so just just think over here if we are passing any sort of a prompt so we are running it we are running it through this Len chain okay so we are passing a input this is what this is my l Len chin Lenin and here this prom is going through now to this open API open AI API and here is what here is my llm if we are talking about with respect to this openi API so like this it is working it's nothing it's just a wrapper it's just a wrapper on top of on top of open API on top of open a API it is what guys tell me it's just a wrapper on top of this open AI API and not this open a API actually it can do a multiple thing so it can do a multiple thing right so let let me tell you what thing it can do let's say this is your application so here what I can do so let's say this is what this is my application and here is what here let's say I have used this Len chain this is what guys tell me let me change a color so this is what this is my Len chain now if I'm us using this SL CH so it can interact with many it can interact to a many uh like apis like hugging face open or with any third party like API so let me draw it over here this one this one okay now let me do one more thing so over here let me draw uh one more Circle and with that maybe the thing will be more clear now here what I can write it down let's say this is what this is your application okay so over here I can write it down this is what this is your application so this is this is your app now it's making a request so this request is going through this Len you can uh think that it just it is nothing just a prompt is we are passing we want to interact with llm actually large language model so here we are passing a prompt so first it is going through this Len chain this is what this nothing this is my Len chain now this Len chain actually it can it can interact in a many ways so over here I can write it down some sort of API so here I can connect with the open AI open API I can connect with the hugging face hugging face API I can connect with a bloom API and I can access a different different llm I can access what I can do I can access a different different large language models getting my point yes or no and apart from this this Len can connect with a other data resources also with some third party API like Google like we Wikipedia and some other data sources now tell me guys this length chain is clear to all of you what is the length chain here I have uh here here I created like each and every diagram and with that particular diagram I have I I try to explain you each and everything regarding this Len chain so please do let me know in the chat if this thing is clear or not I'm waiting for your reply please do let me know yes I will share this PDF note with all of you don't worry uh I will keep inside the resource section please do let me know in the chat guys if this thing is clear then I will proceed further I will proceed with the Practical great so if you are liking the content then please hit the like button also so I will get some more motivation so yeah guys please hit the like button and please be interactive if I'm asking something then please try to answer please please write down the answer in the chat uh that will be a great motivation for me okay now let's start with the Practical implementation so over here you can see I uh started with a len chain so let me uh run it first of all so here is what here is what here is my Len chain now uh here I'm going to be import my open a uh this uh each and everything I have explained in my previous class itself now let me uh import first of all let me check with my key this uh I will have to generate a openi key if I want to access the open API now now I'm not directly going to hit this open openi API I am hitting by using this length chain getting my point so here I will have to mention the open API key so let me take my open API key just a second uh so here I can keep it somewhere just wait uh so here is my openi key now let me paste it over here this one so yes I have created my client means I have created my object now here is what here is my prompt here is what guys tell me here is my prompt now what is the prompt guys tell me the prompt is nothing in whatever see prompt is nothing it's just a sentence which we are passing to to our llm as a input it's nothing just a collection of words collection of tokens so word itself is called a token that's it that's is a prompt now over here if I'm going to run it so let me run this particular prompt and here you can see I'm asking to my chat GPT sorry I'm asking to my GPT model can you tell me total number of country in the Asia can you give me top 10 country name yes it is able to give it it is it is able to like provide a name basically now let's start from here because still here I've explained you each and everything in the previous class now let me give the next prompt the second prompt so over here I can ask something else to my uh GPD model now tell me guys what should I ask any uh any question anything which uh you would like to highlight uh which should I return return over here good so over here I didn't get any okay so let's uh ask like any uh basic question so can you tell me can you tell me a capital of India so let's uh search about this capital of India and here what I can do I can run it and uh let me uh give this particular input uh let me give this particular prompt to my uh uh to my model and I just need to call this client. predict and here I need to provide the prompt so client. predict and here I just need to provide the prompt so it is giving me answer it is saying that the capital of India is New Delhi now here let's try to strip this uh particular output strip means it it will remove the slend from here so I'm going to strip it and here you can see it is giving me an answer so I am getting answer without this selection now I think it is clear to all of you now one person is asking that what exactly tokens and Vector uh so here let's Ty to ask this same question uh to the GP or uh to the jpt model so what I'm going to do here I'm going to uh keep same question from the chat itself and the question is what is a token and a vector you can ask anything to your chat GPT and behind the chat GPT actually this uh behind the chat GPT the GPD model is working so let's uh ask about the tokens and the vectors and let's see uh what will be the answer uh which I will get from the GPD side so let me predict this a prompt three and here the answer is client. predict prom three and see the answer tokens are individual unit that a computer program used to perform operation they can be words symbol or numbers so the same thing I told you now this tokens is nothing just a words right that are used in programming language to represent a specific intersection Vector is data structure that is store a elements of the same time it is used to store sequence of el such as number of character so a vector is nothing what is a vector vector is having two unit now magnitude and the direction so how we represent the vector in our algebra in our algebra if you are like little familiar with the algebric uh algebra concept um algebra Concept in the mathematics so we open the square bracket we write it down some sort of a number and we close the square bracket that is the representation of the vector and along with that maybe the direction uh might be involved that's it so here uh you you can see definitely we are able to call the openi API now let's try to understand few more thing related to this length chain now here let's start to talk about the prompt template the very first topic which we're going to talk about uh we want to talk about related to this prompt template so first I will show you the example of this prompt template that how you can create a prompt template and after that I will um I will try to explain you that what is a prompt template first let me run the code so here is here is what uh we are going to discuss about this prompt template now I'm going to write it down from length chain from length chain and from here I'm going to import prompts prompts and let me import this prompt template class so prompt prompt uh p r o m PT prompt templates so I'm going to import this particular class what is the name of the class prom template okay it's not a temp templ actually a template so prom template now if I will run it so definitely I will be able to import it so here my spelling is wrong so let me correct it first of all and here you can see we are able to import this particular class now after that what I will do so here actually I want to create my prompt right I want to create my prompt now let me do it first of all and then I will come to the explanation so here what I'm going to do so I'm going to create an object of this prompt class so here is what here is my object so I'm saying that it is nothing it is my prompt template name so here I'm going to write it down prompt template this is what this nothing this is my variable prom template name got it I have created my object now inside this object I have to pass some parameter so let's try to pass few parameters over here the first parameter which I'm going to pass over here the parameter is going to be input variable so here the parameter which I'm going to pass over here that's going to be an input variable in input variable and the second parameter which we're going to pass over here that's going to be a template so how my prompt will be looking like so here I'm going to write it down template and is equal to right now in the variable actually I'm going to write it down the name what will be my variable so here I'm saying city city will be my variable and here I'm going to write it down my template now in the template actually I'm going to write down that uh can you tell me the capital of so here I'm just saying that can you tell me the capital of and here on a in a curly braces I'm going to write it down the city right City so c i t by so here whatever uh this is what this city is nothing it's my input variable so here I'm going to write down the city so this is what this is my object this is what this is my object for the plum so here I can put the question mark as well and if I'm going to run it now here you will be able to find out it is giving me an error why because I didn't put the comma over here now here you will you can see this is what this is my prompt template now what is the issue over here input variable okay so the so the parameter name is what input variable now I think everything is fine everything is clear now here what I will do I will call one method I will call one method just just be careful over here right so here I will call one method now here I'm going to write it down format and here what was my variable what was my input variable input variable was City now if I'm going to write down City so here let me write it down this uh Delhi so here once I've have done it now so it is giving me a specific prompt that can you tell me a capital of Delhi automatically right now here see again I'm going to ask the here again I want to create a prompt for uh for a different country let's say I want to ask a capital of China c i n now here you can see it is saying uh it is uh giving me a prompt that can you tell me a capital of China can you tell me a capital of China so what is the meaning of this prompt template what what what is the use of it now I think you can understand so by using this prompt template we can construct The Prompt based on a input variable now let's say you are going to create an application I can give you very uh good scenario now here is your application right here is what here is your application now you you have created this application by using the flas now here you are ask asking to the user just a city name just a city name or just a country name actually and based on that city of based on that country you want to provide a specific information and here you are using any sort of a llm whether it's from hugging face or open AI now guys over here uh you don't want to be here actually you don't want that that your user is giving a entire prompt you just want to take take a you just want to take a city name you just want to take a variable like we do in a python you know in a python we we have an input function yes or no but and by using this input function we take a like input from the user and let's say we have to uh showcase the addition uh divide or maybe uh multiplication whatever on top of those input variable we can do it similarly over here let's say we are taking just a city name so by using this city name we can construct our prompt and that particular prompt we can pass to the llm and Leng chain gives you this particular functionality we don't have this thing inside open AI API getting my point now so here I have created my prom now let's try to pass this prompt to the length chain so what I can do here I can write it down this is what this is my prompt first p o p Mt prompt first this is what this is my prompt first and here I can write it down prompt second this is what this is my prompt second and here is prompt second now let's try to pass this particular prom to my to my llm or let's let's try to call the API open API for that already we have a method client predict so let's try to call this particular prompt now here I'm going to call the prompt first this is the prompt which I'm going to call and here uh I'm going to call I'm going to write down this strip function also so I won't get any sort of slash or whatsoever right now here you can see the capital of Delhi is India the capital of New Delhi is India okay so here I need to write it down just just let me redefine it instead of the city what I can do I can write down the country right now uh this is what this is my country and here instead of the city let me write it down the country one more time and here I can write it on the India I think now it is it is a meaningful now here I can write it on the country one more time uh country c u okay c u n c o un n and here the same here is a same and here is also same now it's a meaningful and let me run it and see what I will be getting over here so prompt one prompt second and here is uh like a it's a New Delhi and let me check with a prompt two so guys here what I can do I can pass the prompt two and let's see the output it is saying the capital of China is a Bing so this prompt basically this prompt template will help you a lot whenever you are going to create any sort of application where you just required a single word from the user this thing is clear to all of you if yes then please do let me know in the chat please do let me know in the chat if this part is clear to all of you please write it on the chat I'm waiting for your reply are you liking the session are you liking the content so please hit the like button as well if you are getting everything if you are able to understand whatever I'm explaining to all of you please do let me know in the chat and yeah and whatever questions you have you can write it down the chat I I I'm monitoring the chat don't worry wait S I will come to that again I will try to explain the L and Advantage first of all let me uh complete the code part otherwise we won't be able to complete all the thing within R yes correct Vishnu your understanding is pretty much clear now since open AI model is not free uh so we Len access all API all other API as well like uh uh hugging face API it can access the hugging face API it can access the bloom API or different different API I will come to the documentation let me uh clarify the basic basic thing uh whatever is there inside the Lang chain I will come to the uh documentation great now here everything is clear everything is fine so here we have this uh here we have this object name prom template uh name and here is what here is my method that is what that is a format now what I'm going to do here H so here actually we have a second method also which is doing the same thing let me show you that at many places you will find out that particular method also I written it somewhere uh just give me a second yeah this one so it is working in a similar way langen has given you the two ways actually for creating this prompt so first of all see we have this promp template class we can create object and we can call this method format method got it now we have a second way here you can see this one prompt template. from template you can call this particular method also and it will work in a similar way both are same don't ask me sir why we are using this that Lenin is giving you the two option for creating a prompt template right now here you can see prompt template prom template what is the good name of the company that makes product I can write it on any like name uh any uh product name so here uh what I can say I can give this particular uh okay first of all let me run it and here is what I'm going to call this format method over here so from template do from temp prom template. frommore template and here is what here is my template template and here is what here is my tell me what is this this is my key now input variable now right now now let me show you what I will get over here so I will be able to construct my prompt what is a good name of the company that make a toys here is my key and here is my template it's going to combine both and finally I'm getting my prompt so over here what I can do so over here I can write it down my prompt so this is what this is my prompt number three and see guys if I'm going to run it so what I will get so here I'm if I'm going to run it this promt three ah it will give me a name it's not a 23 basically it's just a three so let me run it and let's see what would be the output so p r o p Mt p r o MPT uh it's a spelling mistake and now let me check it is working or not so toy makers unlimited so this is the company name actually which I'm getting if I'm giving this particular prompt to my GPT model you can test over the chat GPD as well so uh you will get this type of nam in the back end we are calling the GPD model don't forget over here don't forget okay so we are getting a uh GPT we are basically calling a GPT model over here so this part is clear to all of you and uh I think now this uh prompt part prompt section is pretty much clear I believe that it is clear yes or no this uh prompt template if it is then uh please confirm in the chat then I will uh explain you the second topic that is a agent agent in a lang chain and after that I will come to the uh chain and memory and document loader and finally we start with the hanging phase so tell me guys it is clear this uh prompt templating how we can create a prompt template great it is clear to all of you now let's understand the agent so what is an agent guys tell me so agent is nothing we use this agent in the L chain for calling any third party tool that's a simple definition of the agent if someone is going to ask okay just tell me who is a agent who is a agent in a real time let's say if I'm saying uh there is one agent uh let's say you uh went to the uh any uh you want to purchase any property you want to purchase any property and you went to the Builder and you are uh and uh once you visited the property and you have visited the Builder office or whatsoever there you will find out agent so who is the agent actually so it's a it will so let's say you are a main person and uh you want the information of the property so that you want a like the main person and you want the information from the of the property basically so this agent will help you this agent will collect the information of that particular property and it will provide you in a similar way the agent is working over here getting my point yes or no I think yes now let me run it and let's try to understand the agent so guys over here I will start the thing uh I will ask ask one question to my chat GPT so here I'm going to ask one question to my chat GPT just a wait great so let me open my chat GPT and here let me ask one question the question is very very simple so here I want to know that uh can you tell me current GDP of India so here uh I'm asking to my CH GPD can you tell me the current GDP of India now if I will uh run it so here it is saying to me I'm sorry I don't know in a real time as my training only include information up to the January 22 this that whatever getting my point yes or no tell me so it is not having uh this particular information if I'm asking to my CH gbt can you tell me who won the Cricket World Cup recently now here see what I will get so here it is saying guys I don't have a real time information only includes data up to January 2022 or 20 202 20 okay as my latest updated the most recent information World Cup was held in 2019 emerged as a champion defeating New Zealand in a thrilling final so is giving me an information from the 2019 match I think India again uh uh like uh they out uh I think uh they uh they they got defe from the New Zealand itself right in a knockout match in a semifinal itself uh yes I'm able to remember it so here uh it is not able to give me an answer now let's ask the same thing uh through the open so through the lench itself in my code I'm going to write down the same thing over here so here I'm going to create a prompt for so I'm asking to my model prompt 4 so here I'm asking to my model can you tell me who W the recent Cricket World Cup so this is the question and now let me ask it let me run it so what I can do I can write it down this client predict and here I can pass my prompt prompt four now see uh okay first of all I will have to run it p r o m PT p r o m PT now see guys uh it is saying that uh the 201 won by the England I'm asking about the recent World Cup but it is saying that uh the 2019 Cricket World Cup won by the England only it's completely wrong right now here what I can do I can ask one more thing can you tell me the current GDP of can you tell me a current GDP of India can you tell me current GDP current GDP of India so let's see what will be the answer so here is what here is my prompt five let me copy it let me paste it over here and here I can write it down this prom five so as of 2039 India GDP was estimated to be around 2.94 trillion actually it has been trained till 20 uh 22 data 2022 data right so till January 2022 data right so here it is not able to give me a proper answer uh it is not able to give me a real time answer so for that what I will do guys tell me so here I will use the agent I will use the concept of the agent which will extract the information from the third party API now here I'm going to use Sur API now here so for for extracting extracting or real time info real time info I'm going to use I'm going to use Sur API Sur API Now by using the Sur API Now by using now by using this Ser API I will now by using the Ser API I will call Google search engine and I will extract the information in a real time so here I have written this particular uh like a statement so I hope it is clearly visible to all of you now let me keep it in a mark down and it is clear so for extracting a real time info I'm going to use Sur API Now by using the Sur API I will call Google search engine and I will extract the information in a real time let's see how you can do it so here what I'm going to do so first of all I will have to install this particular Library pip install Google search result that is the first thing now install this library inside your current virtual environment so here what I'm going to do here I'm going to install this particular here I'm going to install this particular liity in my current virtual environment where guys tell me in a current virtual environment clear fine now after that what I will do so after that I will create my Sur API key Sur API key because uh with that only I can access I can access a different different API now let me show you the surp API so just open the Google so here just open the Google let me show you from scratch so over the Google what you need to do you just need to uh okay so here what I'm going to do I'm going to write down the surp API so let me write down this Sur API so once I will write down surp API now now here you will get this very first link so what is a Sur API like uh we have a rapid API now in a similar way we have a Sur API so Sur API is a realtime API to access Google search result not from the Google actually and from any search engine Bing or maybe some other search engine even we can access the Wikipedia also right I will show you how so here uh if I will open it now so you just need to do sign in first you need to do register and then you need to do the sign in I already registered so that's why it is giving me this particular page now just scroll down over here just see over here API documentation now in a over here you will find out a different different documentation related to Google search API Google Map API Google job API Google shopping API Google image API now apart from the Google you will find out the Bing Bing search API also by do also BYU also it's a Chinese search engine now Doug du go search API Yahoo search API yendex search API eBay search API YouTube search API any API you can call by using this Sur API now just click over here API key and here is what guys here is my API key now you have to generate your own API key this is my API key now let me copy this API key from here and it is having some sort of a limitation actually you can just do a 100 search in a free version but in a paid version I think uh you can uh like increase the number of search so just see over here just open it and you will be able to find out entire detail so plan is a free plan price per mon zero uh total plan s 100 plan search left 995 5 I already did it and yeah this is it in a free version you can check check with the plan so just go in the change plan and here you will find out the entire detail so production plan developer plan big data plan all the plans you'll find out over here and by using this API you can access the Google search engine you can access the Google search API inside your application right now here what I need to do I just need to paste this API key in my I just need to keep this APK in my variable till here everything is fine everything is clear now what I will do guys so over here I will I I have to like import few uh I have to import few uh like import uh statement basically uh I have to import few packages so agent type load tools and initialize agent so these are the these are the like these are the packages basically which I need to import agent type load tool and initialize agent so see guys uh let me import this particular thing first of all and yeah it is working F now first of all what I will do first of all I will create a ag first of all I will create a client means here I've created now this open a uh client this one this one okay let me use this one or I can create one more time not an issue as many as time you can do it so here what I'm going to do so here I'm going to uh paste this particular code here I'm going to create my client so this is what this is my client now after that I have to load the tools which tool tell me which tool which tool like we are going to load Sur API now we are going to use the Sur API now so that that's the only tool right so here what I'm going to do I'm going to create a object of this particular method sorry this particular class so here is what here is my object now this is what this is my tool now here I will mention something inside this tool now let me do it over here so let me uh mention this particular thing so here I'm going to mention it so this is a thing basically which I need to keep Sur API uh first of all I need to P The Sur API key and llm so here is what here is my llm already I've created this client I'm using open still I'm using open okay I didn't uh explain you the hugging face so far so this is my Sur API key and here is the name which tool you are using that's it in our square bracket you need to write it down the name you can find out each and everything with the alen tuto lenion documentation everything is there everything is there I will come to that just wait so here is what here is my tool I created my tool now I have to inal I have to create my agent type so here what I want to do uh so here basically what I want to do guys tell me so here I want to create my agent type so U here what I will do I will uh create an object of this initialized agent let me create the object of this initialize agent and here is what guys tell me here is my agent this is what this is my agent now inside this initialize agent again I will keep something so first of all the first thing which I will keep that is going to be a tool so the tool basically which which I've created the second type will be a client means my model the third type will be a agent this agent this agent uh basically agent type actually and here we are going to talk about this zero short react description we are going to mention this zero short react description and verbos to means whatever information um what if I will run it now so whatever information will be in a back end I will be able to see not over the display there's the meaning of the bbos right so here I mentioned three parameters the first is tool the second is client the third is Agent and the first fourth is barbos great now let me run it so this is what this is my agent now what I will do so here I will write it down agent and I will run so run now here I will ask the same question so my question was let me take this particular question from the chat jpt can you tell me the okay so can you tell me who won the recent World Cup so if I'm going to ask the same question now to my agent so here what I'm going to do I going to ask it and let's see what I will be what I will be getting so it is executing the agent and here is search here is action who won the Cricket World Cup and here you can see Australia won the Cricket World Cup it's a recent information it's a real time information which I'm getting now it is giving me many given me some other thing as well links and all because it is calling the Google API Google search engine actually in a back end and here you can see it is giving me answer a on the recent World Cup you can ask anything you can ask anything guys just just uh write it down over here so you can say that uh can you tell me five current can you tell me five top current affairs a f i i RS so if I will learn it now it will hit the Google search enger and here it is saying that see uh so it is saying that top five current affairs and still it is running so read is not available tool try to open I should search engine to find out observations see here it is giving me some like top five current affairs International breaking news uh affairs from us Europe this is the second one a current affairs Subs is one of the best known as a improved life jagaran Jo affairs.com okay it has given me a different different website maybe or uh it here is a news Okay so actually it is giving me a different different name it it is not giving me a proper current affairs I will have to mention that I will have to write uh that particular prompt basically so let's do one thing now let's understand the Wikipedia also so how we can uh like call the Wikipedia so here what I will do I will be writing down pip install pip P install Wikipedia now I will have to install it in a current virtual environment now if I will run it now pip install Wikipedia so let it run uh so here you can see I've installed the Wikipedia now what I will do first of all guys see tell me what is the first thing I have to load the tool so let me load the Tool uh so here is what guys see here is my tool and here is my LM means my client open a client that's it now my tool now what I have to do I have to create an agent so here is what here is my agent this is what my agent I have initialized the agent here is my tool here is my like model and here is my agent type zero short react I will come to that what is this react description and BOS equal to two once I will run it and here whatever I will run now see I'm going to write down uh agent dot run and here I'm asking can you tell me more can you tell me about this re uh okay can you tell me more about this recent Cricket c i c k e Cricket World Cup so if I will run it now it is going to extract the entire information from the Wikipedia okay it is it is taking from the 2019 World Cup okay it is taking from the 2023 World Cup itself the World Cup for the 39 Cricket World Cup which was H in India 5th October November 23 Australia won the tournament great so it is excting a information from the uh recent one itself now here I can ask one more question to my just a second what I can do I can copy it first of all let me copy this particular thing and here what I'm going to do here I'm going to pass a next question so the next question is so let me keep the question over here uh let me run it it is taking the information from the Wikipedia itself are you getting it guys yes or no yes surf I explain you everything regarding the surf API s if you are here if you look into the surf API right so each and every plan I have shown you and it give you the free uh access also but up to uh like it is having some limitation over there you can just hit 100 search you can just hit the 100 100 search in a free version if you're going to take a plan so in that case uh there will be a different uh number of search actually search plan is there different different plan is there see Di okay $2,500 per month $8,000 per month Cloud for plan many plans is there see guys how much plans is there uh which you will find out just go through with it I let me give you this particular link inside the chat and don't worry each and everything will be available inside the resource section at the single place uh at the single place I will keep all the thing and I will give you that don't worry so now see it is extracting the entire information from the uh like uh it is going to extract the entire information from the vikkipedia so final answer the total National dep of the this one and here you can see this is the GDP of the uh USA and here observation and all everything everything now see action Wikipedia input GDP of United State observation p economy of United States summary this is the complete information complete information which is going to fetch which it is fetching from the Wikipedia itself now tell me guys how many of you you are able to understand the concept of the agent so please let do let me know in the chat and then again I will revise it and I will explain you uh through the lench and documentation please do let me know in the chat first if you are how many of you are able to understand the concept of this agent here from here I have started this agent tell me guys fast by using the Sur API we can uh access uh we can access a real time information and it is possible in a is possible in a len chain please do write it down in the chat if you're liking the uh session so please hit the like button also and I'm waiting for your response guys please please do let me know sir please explain the logs which is coming from the agent so here I can explain the log so here is what here is my logs what is this uh what is it uh just check over here so it is saying entering new agent executor chain so after this I'm coming to the chain concept chain and memory two thing is remaining and the document loader three is remaining uh uh then uh you will be able to understand this chaining and all in a better way now here entering a new you execute a chain so action is what it just want to search now action input top current affairs so it is making observation it is searching everything from the Google then it is thinking something I need a narrow down the list of top five internally it is doing everything internally it is doing everything and it is giving you the final answer this one finished chain actually each and everything has been coded in the form of chain llm chain I'm coming to that chain and once you will understand that particular chain now this thing will be are like pretty much clear to all of you believe me just just read it by yourself as well what is the use of client in this what is a just it's just a name now what is a client see I told you please learn the python first if your python uh topic is clear then definitely you will be able to understand this line of code see someone has created openi class somewhere in openi P you just downloaded that you just downloaded that particular package by using pip install openi and now you are creating a object of that it is just is just a class and here is a object this is the object name you can keep it anything here you can give your name like whatever name your name just write it down your name this is what this is nothing this is the object of the openi class and here you are passing a different different parameter someone has created a class and you are just using it that's it nothing else so this is what this is my client and I think this is clear to all of you now coming to the next part so here first of all let me show you the Lenin documentation so I'm going to write it down over here Lenin documentation now over here uh like uh you can see this is what there is nothing there's a Lenin documentation and here is an introduction so they have given you the complete introduction of the lenen over here Lenin Library lenen template Lang server Lang Smith everything you will find out over here and this document is a amazing one similar to this open a uh so yesterday we have seen the open a documentation right so this length chain documentation is similar to that openi documentation it's a pretty amazing each and everything you will find out over here itself each and everything you will find out over here itself now let's start with the installation so how you can do that it is very very easy pip install length chain and pip install and all what is the meaning of this pip install hyphen e dot so this thing we'll try to understand in our upcoming session once I will start with the end to end project now L server we try to understand this also what is the Lang server all L CLI so many like they have given you over here as of now this lch package is required that's why we are going to download it now over here we have a quick start so here you will find out the quick start so you can go through with this quick start and you can uh like you can take a glimpse of this Len CH so everything you will find out over here in a quick start itself pip install lch pip install open a you can export the open a key key and then you can use it and here is a different different thing which you will be able to find out whatever thing we are running so open a you can uh create object of this chat openi also now here is llm model here is U you can use this particular class also chat open AI now human messages lch schema human message there you can check with this what is this now you can create a prompt templates already we have created now just see over here what is a what is a PR prom template most llm application do not do not pass user input directly into llm most of the application you will find out you just require a single word I given you the example yes by using this prompt template you can achieve that particular functionality and here is example for that got it now here is a chat comprom template so each and everything you'll find out over here and uh as uh like you will find out the latest version so there might be some sort of a changes in a code and all but don't worry the concept ccept will remain same we'll find out some changes in a code in a classes the name of the classes but the core concept will same if you're getting any error in a new version then check with the like documentation and try to rectify it that's it so here is a quick start and you can go through with this quick start and you can understand a different different things now security wise they have given you the different different thing now let me come to the next part so over here just click on this G to started again they have given you the different different uh thing prompt is there model is there which model you going to use output parser entire pipeline okay R they have included their R also now okay so retrieve augumented generation so you can go through with this and you can understand what is this R but don't worry I will cover this in my uh next class this RG it is I'm having this R in my pipeline so I will try to cover it this U uh in a live class itself in a Jupiter notebook itself I will write it on the code now over here you can understand about a different different thing different different concept just just go through with this document it's amazing one now interface is there so prompt chat model llm out part are retriever tool these are the things just just go through with this try to understand it now how to so here is a different different thing which they have mentioned Right add fallbacks bind R time runable Lambda many things right so here you will find out the cookbook so inside the cookbook everything they have given you everything prompt plus LM so the thing basically which we are going to do over here uh which we are going to do as of now they have mentioned it over here R RG this was this was not there previously when I had checked recently they have added in a new version so R is there so here you will find out the code related to the r see this one now here multiple chains chains I will come to this chains after this one I will explain this chains right so here you can see the change and all so each and everything they have given you but as of now we are trying to understand this particular part we are trying to understand this agent and we are trying to understand this model input output so prompt already we talked about chat model already I shown you by using the open so this is like pretty amazing document guys so once you will go through with this document now you will find out uh it is having so many things and they have given you the code and all each and everything they have provided you believe me guys so just go through with this one and try to understand uh different different thing or whatever thing basically is there so we going to understand this chains now and we'll be try we'll try to understand this memory but apart from this chains and memory it is having lots of thing which uh we might uh we might use in our application if if you are creating application now so this concept uh like might come into the picture regarding the RG or regarding a different different one different different topic basically which they have included but over here I would like to tell you one thing whatever I'm explaining you in a Jupiter notebook U if you are a beginner that definitely it's a more than uh it's more than enough for all of you and uh in the next class once uh when I once I will implement the project now then uh you will find out the importance of it and don't worry I will uh keep some latest thing also like R and all inside my project and inside my uh future classes and you will get to know that so here uh I have given the overview now let me talk about this uh agent type so there basically you have seen one thing that was the agent type now let me talk about this agent type what is this so here you can see guys in a agent itself you'll find out the agent type see agent type just just click on this agents and here you will find out the agent type now we have a different different type of agent zero short Agent Zero short react agent structure input react agent openi function yesterday I have talked about this openi function and now it's a legacy people are not using it people are using this agent concept from the lench and directory people are not using this open function uh but still I have explained you that so here you will find out the conversation self ass react documentation and all and this zero short is nothing it's a basic one so if you're going to ask something to your LM model to your GPT model so you will use the zero shot react now here you will find out this this agent use a react framework to determine which tool to use based on a solar on the tools description so whatever tool description you are giving based on that it will search the uh like compatible tool and it will provide the prompt to that particular search engine or to that particular tool and it will give you the out that's it zero short react now here this is the most general purpose action agent you can see the node so this thing is clear to all of you now let's start with the chains so are you comfortable till here and if you're not able to write it on the code along with me sometimes it happens in the live session don't worry just listen to me just listen to my words whatever I'm saying and practice after the class practice after the live session recording will be there and resources also will be there so let me write it the chain over here and let's start with the chain now so first of all tell me guys this part is getting clear how many days you will take to come up with an end to end project one day only one day I will take to come up with an end to end project so lench is only made for the NLP use case or any other compete capabilities also it is having as of now I have used this for the NLP use cases I will have to explore the recent uh thing whatever is there inside the Lenin maybe uh we can use it for the other uh like for the other task also but I haven't explored it for the other task I just use for the NLP once I will explore it I will let you know that whatever recent update is there but if you want to know about it just go through with the recent documentation all the llm has only text or code generation capability yes but you can do many whatever NLP task is there now you can do by using the llm because it is having the code generation capability with that it can understand the pattern inside the data so you can fine tune it it is uh possible you can fine tune inside your CPU Itself by using your CPU I will let you know uh otherwise I will share the resources with all of you uh don't worry we we'll come to that and uh we'll try to talk about it uh not as of now later on but yeah uh I will give you the glimpse of that great uh I think uh now people are getting many things we are using uh not completely actually if you don't know about those thing you won't be able to understand this particular part that's why first I started from the basic from the open itself otherwise directly I can start from the lch and then uh again you will ask to me sun what is this uh what is this open Ai and what is this llm what is this genitive AI I can even I can start from here itself from the Leng chain so but I started from the very basic okay so let's start with a a new topic uh that's a chain so what is a chain so let's understand the chain so first of all I can uh show you the documentation and uh just a wait great so here actually what I did I kept one a simple definition of the chain and let me copy and paste it so here is a definition just try to read this particular definition and try to understand the meaning of chain and it will be more clear once I will write it on the code so Central to length chain is a vital component uh known as a lang chain chains forming the core connection among one or several large language model in certain sophisticated application it become necessary to chain llm together either with each other each other or with other element so if you're not able to understand by this particular definition so let me open the documentation for all of you so here in the go inside this more uh just click on this more and here is a chain just uh read about this chain so using an llm in isolation is fine for a simple application but more complex application require chaining llm either with each other or with other component now what is the meaning of it so just uh okay so I have uh explained you the agent that's why I explain you the agent at the first place and then I came to this chain now tell me guys this llm was not working over there so I changed what I did now I Chang I changed the terminology so what I did guys now I so this LM was not working for that particular prompt so after coming to this llm means let's say if I'm not getting any sort of output so I came to to this chain and this chain actually it was connecting to me it was connecting to me to The Sur API through the surp API basically it was connected to me Google search engine getting my point so here what is the meaning of chain so chain is nothing okay if if you're talking about chain in journal so let's say this is a chain so something like this you will find out so what is this what do this guys tell me so chain is nothing which is uh like connecting a several components which is connecting a several component getting my point yes or no I think you are getting try to understand it what is a chain so chain is nothing it is just connecting a several component so here they are saying using llm in isolation it's fine but in complex application require chaining that the example I shown you by using the agent if you will read it if you will read the answer of the if you'll read the answer of the agent agent I'm running agent don't run and you are getting an answer so if we'll read that you'll find out it is chaining means for is trying to find out somewhere else it's not able to get then again it is going to somewhere else and it's going to take a information then again it is going to call some other prompt and it's going to take a information so what is a chain so chain is nothing it's a collection of component now which component what component whatever component maybe inside the uh like uh uh like whatever let's say we are using length chain and inside that we have a different different component I'm going to chain to those particular component and maybe I'm going to uh like connect with other llm so I can do that as well or maybe I'm going to connect any third party API I can connect that as well so I'm doing a chaining if I'm running chat agent. run now internally it is doing a chaining getting my point I think you're getting now let's try to understand in terms of python code so here first I will start with a very basic example so what I can do here so here uh first of all I can write it on my client so here is my client guys c r i e n t this is what this is my client now what I will do guys so here I'm going to import The Prompt template so this is what this is my prompt template and by using this prompt template I'm going to create I'm going to create uh I'm going to create one prompt so here is what here is my prompt so what is a good name for a company that makes a product so here I can run it and let's say uh I'm going to write it down any company name so okay I'm going to write down the uh actually I want a company name what is a good name for a company that makes a product so I'm just asking to my chat GP okay I I'm making this particular product just give me a good name for this particular company so here I'm going to write down let's say wine so wi so here I uh I'm uh just just think that uh just think like that that I'm going to open a company uh and here I'm going to produce a wine and all uh okay so I want a name any creative name okay that I'm asking to my LM model now here if I will uh like close it so what I'm going to do so here I'm going to run it so uh prompt. format so this is what this is my prompt what is a good company name for a what is a good name for a company that makes a wine so that's going to be my prompt p r o p Mt so this is what guys this is my prompt now what I will do so here actually I'm going to import the chain here I'm going to import this llm chain here I'm going to import the llm chain just just be with me just for uh next 5 minute everything you will get it's my promise to all of you I have simplified every thing every uh like uh every line of code just be with me next for 5 minute so here you can see we have a llm chain now what I'm going to do I'm going to create a object of this llm chain now guys uh here I'm not going to call a predict method I'm not going to call a predict method what I'm going to do so here in this llm CH what I'm going to pass guys I'm going to pass client right and I'm going to pass my prompt that's it this two thing I'm going to pass so llm llm is what c l i n t and here I'm going to pass my prompt so p r o p Mt prompt is equal to prompt so I passed the client and I passed the prompt here now this is what this is my llm Chen right I'm going to connect both component LM and my prompt now over here what I'm going to do so this is what this is my chain this is the object basically which I have created now here you can see it is saying that uh it is giving me a why I'm getting it let me check with the prompt so here uh let me run it first of all what is a good company that makes a wine okay from template uh I think I will have to use format uh I think I will have to use this particular prompt only uh this one this only uh let me delete it because it is asking I need to provide in the form of dictionary so I cannot pass a direct prompt over here what is a uh because uh here whenever I'm running this uh whenever I'm calling uh the run method Now by using this chain then automatically it will uh like take the name from here itself so let me delete it let me delete this particular line I'm going to delete it guys this one so here is what here is my prompt now Len chin llm chain and here now it is fine now what I will do here I'm going to write down chain and chain. run and here actually I need to pass the value so here I'm going to pass y now if I will run it now see it is giving me answer the name of the company is what it's a uh sdip strip and is the name of the company is what Vintage Wines Winery so it it has given me a name of the company like I want to create this particular product and here it has generated answer now I'm going to change I I'm making a chain by using two components the first one is llm model that is that I'm getting from the openi and which is available inside my client and the second is what second is a prompt which I'm passing over here so now I can directly run it by giving the keyword and here you can see I'm getting answer so I'm changing this two thing this is the simple this is the simplest uh like uh there simplest example I've given you now let come to the second example so over here what I'm going to do so here I'm giving the the second example example two example two so I took one more example to for explaining uh this chaining part actually so here uh let me copy and paste so here is what guys here is my prompt template this is what this is my prompt template now here I'm asking uh this is what this is my template I want uh to open a restaurant for cuisin Indian cuine Chinese cuisine Mexican Cuisine Japanese cuisin American Cuisine whatever for that I want a f see name this is my prompt template let me run it here I'm running it now if you will find out the prompt template so here you will find out the prompt template so this is what this is my prompt template got it now what I will do guys here I will make a chain so what I'm going to do so here I'm going to make a chain so let's say uh this is what this is my chain so llm chain and I'm going to combine two thing first is client and the second is what the second is promt template now if I will uh run it so so here I'm getting my chain then I will write it down chain do run now I'm uh let's say I'm giving something over here let's say I'm giving uh Chinese so according to that it will give me answer so the answer which I'm getting the golden dragon dragon place so here what I'm getting guys I'm getting this Golden Dragon place so the emperor's kitchen that's the name okay if I'm writing over here uh Indian let's say what I will be getting so Indian so here actually I'm getting Maharaja Delight so just the name it is suggesting me one name which I'm asking to my llm model that's it now let me show you few more thing over here now so here I'm getting a a response and the response is fine now let me uh come to the second thing second example so here what I'm going to do so here let me show you something so now over here if you want to see the detail actually so for that I have mentioned one more thing that is a verbos parameter as I told you earlier if I want to check all the detail whatever is happening in back end so for that there is a parameter verbos is equal to true now if I will run it now see what I will find out uh let me predict with some name so let me uh check uh chain. run and here I can write it down let's say America so here it is saying that entering new llm chain prompt after formatting I want to open a restaurant for American food suggested a fancy name for this and here is a name American spice Visto so you can see the complete detail over here what is happening by using the barbos true until here everything is fine everything is clear now guys here uh this is the simple chain basically which I have created by using this two component now let me explain you One More Concept over here so here actually I have written one definition or I have written one text uh just let me explain you the this particular part and then uh again I will try to revise you so here I'm going to mark down it and here guys see what I'm saying if you want to combine multiple change and set a sequence for that we use Simple sequential chain simple as simple as that right so if you want to combine a multiple chain if you want to combine a multiple chain and set a sequence for that we use a simple sequential chain so let's try to use the simple sequential chain and let's understand what is it so for that basically I have designed one prompt okay just just understand over here so step by step we'll try to understand see Ive already written a code in my doc I'm just copy and pasting so that I can save my time that's it everything is same see I can write it now the code in front of you also but it will take some time for writing this particular uh statement on all it's the same thing okay wherever I have to write from scratch I will do that now over here see uh let's try to understand step by step now over here this is what this is my uh second prompt so in the first prompt see in the first prompt The Prompt template which I have defined what I'm saying over here I'm saying uh I want start a startup right I want want a start a startup and suggest me a good name so here is my prompt now here you can see this is my input variable that is what that is a startup name yeah it's fine it's clear to all of you now here I've created a chain by using this a model this is my model and this is my prompt template okay this is the first shap now here I have created one more prompt now here I'm saying uh suggest some strategy for the name so whatever name name whatever name I will get from here startup name for that what I want I want some sort of a strategy let's say I'm going to open or I'm going to start my atte startup so for that what I require tell me so I for that basically I require audience I required my team I required my Marketing sales team if I want to open any fintech startup or if I want to start any consultancy or whatever right whatever uh like company which I want to start so regarding that what I want I want some sort of a strategy getting my point here yes or no so now what I will do I will combine this two change see here this this is my first change this this this is what this is my first chain this one and this is my second chain now I will combine this both Thing by using simple sequential chain I will making I'm making a sequence I'm trying to make a sequence between these two chain okay before I I was just running with a single uh like uh with a single chain only and we we are having only two component llm and my prompt now here I'm going to come my true chain now just tell me guys here I'm using this particular llm can I use a different llm over here I can try with that I can check right so here I'm using a same model now I can check with a different LM also in this particular case so this chain is a pretty amazing thing it is connecting a homogeneous component or it is it can uh we can connect a hetrogeneous component also means some other model as well you can test it with the other model uh so here you can see we are able to do it now guys here what I will do so here is my first template this is my first chain this is my second template this is my second chain now what I will do over here so here I'm going to import a sequence uh so here I'm going to import a simple sequential chain here I'm going to import this simple sequential chain now once I will run it so here I imported now let me create a now let me create a object of it so here guys here is a object now inside this object inside while I'm creating object I will pass some sort of a parameter so it will call my init method okay in a back end now here I'm going to pass some sort of a parameter and that's going to be a very very easy and here is the parameter name so chains first is name chain and the second is stategy so automatically see what will happen actually first it will call to this one it will uh generator startup name automatically it will give uh it it will give name to this particular uh like a to this particular template automatically it will fetch from there itself and I will be getting this strategies I will be getting this particular strategies automatically chaining automatically chaining is happening okay this one now let me show you how so over here uh what I will do so let me uh create object and here I just need to call a method so here I'm going to call uh method that's going to be a chain. run now here I want to open a startup let's say the startup related to the artificial intelligence so here I'm going to write it down artificial intelligence now here once I will call it so let me run it and let's see what I will be getting over here so I'm making a sequence guys between a prompts so it is saying that uh develop a strong marketing strategy and and some sort of a information let's let me print it uh so that I won't get this lesson so here is my strategies stay informed and up toate on a latest AI train develop a comprehensive uh AI strategy utilize AI tools utilize data driver inside so these are some sort of a strategy actually see automatically I'm getting see this name now which which we have defined see startup name which is coming over here okay then whatever name is coming from there automatically is going over here this inside this name and we are getting a strategies we are chining we are chining right now this is a simple sequential chain now here uh here we have one drawback actually uh we it is giving me a final answer it is not giving me a answer uh it is not giving me answer related to the first prom it is not giving me it is not giving me that particular answer it giving me a direct uh the last one answer from the last uh like a prompt itself if you want answer like from the entire prompt so for that also we have one method okay uh sorry we have one more class let me show you that particular class now so here uh what we can do so I already written the name so let me give you that particular uh name and here is what here is a name guys so the name is what now let's try to understand the sequential chain so so far actually we have understand the simple sequential chain now we are going to understand the sequential chain and it is having a more power compared to this SE uh simple sequential chain where we can uh keep uh the sequence sequence of the different different prompts and the different different chains now uh let's try to understand this sequential chain and here what I'm going to do here I'm going to copy one more code now let me paste it over here so again I'm going to create okay already I have a client so let me move it it is not required at all so here is my prompt template and what I'm saying here I want to open a restaurant suggest me a fancy name now just see over here what I'm going to do I'm going to mention one key over here that is what there is my output key and what is my output key output key is nothing it's a Resturant name right now now just see over here where I'm going to use this output key so here I'm going to Define one more parameter one more prompt template and here guys you can see so in this particular prompt template prompt template name we have a prompt template and and here input variable kin and this is a template now here is my chain llm chain this is my model this is my prompt template and here we have a output key output key is what restaurant name so whatever name basically whatever name I will get from here I will keep inside this restaurant name and this restaurant name I'm passing over here this restaurant name I'm passing over here and here whatever thing I will get from here from this particular prompt I'm keeping inside the menu item and if you are going to create a next prompt you can mention over there now let me run it and let me show you what will be the final answer over here so here I'm going to import the sequential chain and here you can see so this is what this is my sequential chain and now let me copy it and let me paste the final code and here is my uh object of the sequential chain so let let me keep it in a single line so here sequential chain this is the object which I have created now change what I want to chain means like in terms of what I want to make a chain so this is the first name name chain this is the one now second chain is what food item chain means I want a food item regarding that particular restaurant now over here this is my input variable and here is my output variable restaurant name and menu items this one Whatever output I'm getting from here I'm keeping over here inside this variable whatever output I'm getting from here I'm keeping over here inside this variable and I'm going to mention inside the output variable if you want to make a further chain you can do it according to your problem statement now let me run it and let me show you the final answer and the final response so here I am going to call this method chain okay so this is about this is my chain and here let me run it and see what I will be getting so chain and I'm I'm passing cuisin Indian so it is giving me cuin is what cuin is Indian and here is a restaurant name there's going to be a Taj Mahal Palace Taj Maharaja Palace and here is a menu item now so guys this is the response which I'm getting over here can you see over here the response which I'm getting all the thing all the thing in a sequence now let me revise this particular thing revise me this particular concept so chain what is a chain which is going to connect two components so here what I did see here I have connected two component first is model second is prompt now in example two you can see what I'm going to do so same thing I'm going to perform now in the third one uh with the entire detail actually with our entire detail now in the third one I'm calling simple sequential chain in that I'm getting a output from the last prompt but if we are talking about a sequential chain instead of the simple sequential chain I'm using sequential chain so I'm getting a entire output over here means from first template uh from first prompt template to last prompt template and here you can see we are mentioning this output key so whatever answers I'm getting over here whatever answers I'm getting from this particular uh prompt right we are able to store it over here and we are passing to the we are passing to the next prom we are passing to the next uh like a prompt basically over here you can see this one same restaurant name and we are going to combine it finally so guys tell me do you like it did you understand it I will come to that the purpose and all everything will be clarified right so uh we will talk about because everything should be connected now to each see whenever uh like if you are going to ask to anything uh to your chat GP what do you think tell me so how this application is working we are are we are like uh what we are going to do guys so we are reaching step by step actually we are trying to reaching to our final application understand guys so here if someone has created this chat GPT it they have implemented everything whatever we are going to run by using this Len chain here you will find out the memory concept okay let me ask one question to my CH gbt so here here I'm asking can you tell me can you tell me about something Taj okay so here uh I'm asking this question to my chat jpd now here you can see uh uh like uh here is the answer now I'm asking to my chat GPT 2 + 2 how much so it is saying to me let me run it so here it is saying to me 2 + 2 is nothing it's a five okay sorry uh it's a four right now here if I will ask to my chat GPT how much 100 uh multiply by 1,000 now if I will run it so here you will get the answer now here if I will ask to my CH GPT who uh build the Taj Mahal can you who built the Taj Mahal so here if I'm going to ask this particular question so here you can see the Taj m b by the mul Emperor so actually it is not going to forget the context whatever you are asking now previously it is able to sustain the that particular memory it's a biggest power of the CH GPT so we are trying to reach uh like step by step we are going to we are trying to understand all sort of a thing by using this Len CH and then finally we will move to the uh the end uh like a goal the our end application now over here this chain actually is very important if you want to uh like a retain the information from the first prompt to the last prompt for that you can use this uh you can use this uh sequence chain I can understand you are uh trying to understand that where we are using in a real time in a application and all I will come to that part okay but just understand over here so I was running the Sur API so here actually once you will read the entire detail of the Sur API of this agent so you will find out that in like uh uh internally it is using the chaining it is trying to chain each and every thing back in a back end basically they have implement the chaining complete chaining so just just try to read it and finally it is giving me a the the like conclusion over here so in a similar way here I just shown you the example a very basic example but by yourself what you can do guys so by yourself uh like you can uh like create a different different prompts and you can implement this chaining concept over there and you can understand in a better way you can search about the applications and all getting my point yes or no tell me guys this thing is getting clear to all of you if it is getting clear then please do let me know in the chat so are you able to get it uh please do let me know in the chat guys if uh this thing is fine to all of you I'm waiting for a reply guys if you can write it down the chat and if you're liking the session so please hit the like as well great now let's try to understand uh One More Concept and then I will uh stop the session uh today I couldn't reach to the hugging phase but don't worry tomorrow I will show you that and memory also so One More Concept is there memory now let me show you the basic concept now the uh the very basic concept of the Leng chain which we are going to use in a future that is going to be a document loader so let me explain this document loader also so here uh what I'm going to do I'm going to uh show you that how you can read any sort of a document by using this uh by using this length chain now once you will search uh let me search over the Google Document loader document loader Lang chain documentation so simply I'm searching about this uh document loader on top of the documentation so here uh let me open this document loader so once you will come inside this module now and here is a uh here is a like option retrieval now inside that you will find out a document loader so CSV file directory HTML Json markdown PDF or different different document you can load and it is required it is required I will show you where it is required and once I will reach to the Practical implementation once I will create any sort of a project okay so there I will show you how you can read a different different files and how you can utilize let's say uh you have one information so some information inside the uh txt file or maybe in the format of HTML or Json or maybe CSV now you want to read it from there and you want to give it to you uh you want to give uh that particular information to your uh chat GPT or maybe GPD model so in that case you will have to use this document loader so let me show you how you can use this uh PDF loader so here is what here is a PDF loader so for that first the first thing what you need to do you need to install this P PDF so just open your notebook and here write it down this pip install pip install P PDF so once you will write it down this pip install P PDF you will be able to install this Pi PDF inside your virtual current virtual environment now after that you need to lo you need to write it down this particular command uh you need to write it down this particular import statement from lench do document loader import Pi PDF loader right from the documentary itself I'm going to take it I I'm I'm I'm not going to write down by myself here I'm showing you the power of the documentation so once you will explore it you will get a many more thing from here itself right whatever like you want so here I'm going to uh what I'm going to do guys so here I'm going to mention this import statement now we have one uh ex uh now here actually we have to call this particular method sorry we have to create a object of this particular uh class and here let me paste it down so this is the pi PDF Lo now I have to pass my PDF I have to give the uh I have to like write it down the my path whatever is there uh in my local system so inside my download let me check any PDF is there or not so let me check with the PDF LM here is a PDF machine translation attention so let me copy the path uh let me paste it down over there let's see it is able to read it or not so where is a path guys here is a path let me copy the path and I have copied the absolute path now where it is here is my code so here I pasted my path and let's see it is going to load or not it's showing a uni code error so let me put the r over here and it is done now let me check inside the loader that what I have so here it is created the object now let me I write it down the loader over here loader do loader so once I will write down this thing so here you will see that uh okay l a d r loader do loader P object no attribute loader uh what is this let me check the documentation here they are calling loader and split and that will give you the pages great so let me call this uh loader and split and here I have a Pages now let's see we have a Pages yes I got the entire detail so see I able to read the PDF by using this document reader why I've shown you this thing because uh it will be required we use now pandas do read CSV for uh like collecting any any sort of a data in the form of data frame right so if I want to uh take any data if I want to format any data in the form of data frame so so we use this pd. read CSV or we use np. aray similarly if you want to read any a document by using this L chain you can do it you can do it guys so here there is another one and uh you can take it as assignment you can read the CSV there is a complete code here is a uh code for the file directory here is a like HTML here is a Json markdown is there there's a different different uh like a uh different different document loaders you will find out now guys uh let's try to revise the thing let's revise the session what all thing we have learned in today's class in today's session and then I will conclude it and in tomorrow's session I will start from the memory memory and finally hugging face sorry actually I went uh into some depth Okay I uh I try to explain New Concept in a detail way that's why I couldn't start with a hugging face API but don't worry in tomorrow's session I will show you how you can uh how you can uh download any open source model how you can use any open source model model by using the hugging pH API and then uh right after that we'll try to create our application that is going to be a McQ generator we'll see that how you can generate McQ by giving any sort of a text and where this document loader where this chaining memory each and everything will come into the picture and even the prompt also prompt template right now let's revise the thing what all thing we have learned so let me revise it over here so in today's class uh we have talked about so where is my pen yeah so in today's class we have talked about this agent I have shown you that how to call a third party API so here we have seen how to call a Google search engine Google search engine API Google search engine API so let's say uh your chat GPT actually has been trained till uh September 2021 data so if it is not able to give the information in a real time in that case you can use this agent you can call you can can use the concept of chain right you can use the concept of chain in which scenario so where you have a multiple prompt which is connected to each other not a simple application not a simple prompt just for the testing I'm talking in a real time so I'm talking in a real time uh just a wait uh now it is fine so here I was talking about this uh Google search engine and uh yep and then we have talked about the change prompt template also document loader now this uh two thing is remaining so in uh tomorrow's session I will start from the memory uh in tomorrow session actually I will try to explain the memory concept and then I will come to this hugging phas API got it guys yes or no so how was the session uh did you learn something new so please do let me know guys uh did you learn something new from here whatever I have explained and uh how was the session how was the content uh please do write it down the chat should I add a few more things if you want then uh please do let me know please uh write it on the chat I I'm like waiting for your replies and you you can comment also so if you are watching rewatching the video and if you want something from my side you can write it on the comment section you can tell me over the LinkedIn and yeah that's it so I hope you are liking my session so please hit the like button if you liking the content if you're liking the session GB 3.5 get updated till yeah ah recently we have seen that today itself so why we are using Len chain and advantages over other API you will get to know more about it in tomorrow's session otherwise just try to revisit the session in a starting itself I have talked about the limitations of the openai and I talked about the advantage of the open a clearly I have written it over here so just try to revisit the session you will get it and here I have tried to explain you everything what is a lenen it's a rapper or the open Ai and uh your app here is a lenen which is a rapper now you can hit a multiple Thing by using this Len chain yes day three not day three notebook will be available in your resource section soon it will be available don't worry uh yeah so this is it guys from my side I hope uh like uh I already told you the tomorrow's agenda uh memory and the uh hugging phas right so thank you guys thank you byebye for joining the session if you have anything any doubt or any concern or anything in your mind so just uh do let me know please uh write down the uh please write down your thoughts in a comment section and you can ping me over my LinkedIn as well okay so let's start with the session and today is a today is the day five day five of this community session Community session of generative AI so uh I already uh covered um most of the thing actually in a in with respect to this open a and this Lin and uh in total I took four session uh here you can see all all these four session uh where I have started from the introduction of the generative AI then I came to the introduction of the open Ai and we we have understood we have understood the concept of the open API then I have discussed about the Len chain and yesterday also I was talking about the Len chain in today this class uh I will be talking about the memory Concept in the Lang chain which was the remaining one and after that I will start with the hugging face API and then uh from next class onwards we'll try to uh Implement our first end to end project by using this linkchain and this open AI so uh guys here we have uploaded all the sessions all the lecture you can go through with this dashboard which is already there over the Inon platform you just need to sign up and after the sign up you need to login over there and you will get this particular dashboard uh over the in youron platform so already we have given you the link uh in the chat so please try to uh enroll yourself if you are new in this particular session uh this enrollment is completely free you no need to pay anything for this uh for this en for this particular session uh so you can down uh you can enroll inside the course and you can access all the uh lectures and here you will find out the resource section inside that all the resources uh is up to date whatever thing I have discussed in the live classes each and everything you will find out over here so let me show you yesterday I have discussed about the lure so this file is already there you just need to download it and you can uh run inside your system you can run inside your system you can run over the Google collab anywhere you want so I shown you the setup in in the local system itself you can go through with my previous session and there you can understand how to to do a local setup how to do a h setup with respect to open Ai and Linkin how to run a code regarding this open Ai and Lenin each and everything I have explained you in the previous classes so please go through with my session and uh like uh try to understand at least till here till this L and this open I so uh you can implement the project along with me whatever thing I'm going to explain from next class onwards uh because in today's class I will cover this lure memory and then I will come to this hugging face API and from Monday on onwards Monday onwards Monday to Friday so Monday onwards I'm going to start with the project Tuesday also I will take a project and then I will come to the vector database and then few more concept few uh like different different models uh some open source model and I will try to explain you this uh ai2 lab also that uh how you can uh access that Jurassic model uh which I told you in my initial uh like introduction so yeah I think everything is clear everything is fine to all of you so please do confirm in the chat if uh everything is fine everything is clear till here then we'll start with today's concept so I'm waiting uh for your reply please write it on the chat guys and you can find out the same session over the Inon YouTube channel as well so just try to visit the Inon YouTube channel and go inside the live section there you will find out this committee session already uh the recording is uh already we have upd the recording in the live uh section itself and in the description you will find out the uh you will find out this dashboard link as well uh let me show you that just a second yeah so here is Ion YouTube channel so just uh uh over the click over the channel and here go inside this live section click on this live section there you will find out all the recordings so uh this is the very first recording where I have discussed uh each and everything regarding the generative Ai and the second recording is this one the third one this is the third recording and here you will find out the fourth recording now just click uh any of them so after clicking just try to go through with the description and here you will find out the uh dashboard link and other details so each and everything you can find out uh over the Inon YouTube channel as well you you can find out this uh dashboard link over there just click on that and enroll yourself it is completely free now let's start with today's session so here I will be talking about the Len chain L memory in Len chain so how you can uh like uh how you can use this memory con concept by using this Len Chen but before starting with the Practical let me give you some theoretical explanation so what I'm doing here I'm going to open my Blackboard and here I will try to explain you the concept of the memory right and a what thing we are going to discuss that also I will be talking about here I will be writing in front of you and then finally we'll Implement uh those particular thing in a python now uh in the previous class I was talking about the Len chain and I given you the complete detail introduction regarding the Lenin that what is Lenin why we should use it what is the advantage on top of this openi API why we should not use openi API why we should use lenen each and everything we have discussed now in future session uh I will explain about the Llama index 2 so it is similar to Lenin and I will come to the Llama index 2 and it's a framework from the Facebook site so we'll try to discuss each and everything related to L related to this llama index 2 as well and I will give you the differences between Len Chen and Lama index 2 but as of now here I'm going to explain you the Len chain only and most of the concept I already discussed so if we talking about the Len chain so what all thing we have discussed so far let me tell you that so in the Len chain first I discussed that how to uh call the open a API by using this Len chain you can think that this Len chain is nothing it's a wrapper on top of this open a API and not only openi API we can access a various API by using this Len shed so here we have openi API we have seen that how to access and how to uh how to access or how to use the open API by using the there is just a simple import statement which I which we have to write it down inside the notebook or inside the code and we will be able to import it that's it now apart from that we have seen the concept of the agent I have explained you that what is the agent then uh I have explained you the prompt template that what is a prompt template prompt template how you can create a prompt template and all so we have seen each and everything regarding that now we have understood the concept of the chains that what is chains and what we can do by using the chains if we are going to define a chain right so uh what all thing we need to import what component is required what is the meaning of the simple uh sequential chain what is the meaning of the sequential chain each and everything I have discussed regarding the chains after that I came to the document loader I have discussed about the document loader if you want to uh load any sort of a document document is nothing it's just a like a files and all right so if you want to read the PDF PDF file if you want to read the Excel file CSV file HTML file or maybe any other file so you can um you can load that particular file by using this link chain it is possible now the fifth one now the sixth one which we're going to talk about that is going to be a memory so we'll uh discuss the concept of the memory first I will write it on the code and then again I will come to this memory part and try will try to explain you but before that uh I would uh I will explain this memory memory concept by using the chat GPD also before writing a code now this is all about the L CH these all are the thing basically which we need to discuss regarding the L chain and that's going to be a very important if you are going to implement the project end to end project now after that what I will discuss so here let me write down the topic name which we're going to discuss after this Lon so I will talk about the hugging phase hugging phas API how you can generate a token how you can generate a hugging phas API token and after that we'll try to access a open source model whatever model is there on top of the hugging phase so we'll try to access those particular model by using this hugging phase and we'll try to do a same thing we'll try to do a same thing basically which we are doing uh by using this open API but at this uh now at that time I'll will be using the open source model not this U uh like not this GPD model basically which is a uh which is a like model of the open a now will try try to access those open source model and then we'll try to understand that how uh we'll try to understand that how you can create a pipeline by using the hugging face so we'll try to understand the concept hugging face pipeline hugging face pipeline I told you this uh Lenin is nothing this lenen is a wrapper okay this lench is a wrapper on top of this uh open ey this lench is a wrapper on top of the hugging face so not only open AI we can interact with hugging face also uh by using this L chain and not even with hugging phase we can interact with many API in future I will explain you that I will come to that and if you if you want to know about it so you can visit the documentation yesterday I shown you the documentation of the Len chain and you can see over there not even open AI not even hugging pH we can access a multiple API by using Lang chain so Lang chain is nothing just a rapper on a different different uh on top of a different on top of different different API got it yes or no I think this thing is clear to all of you then we'll see how we can create a hugging face pipeline which we used to do by using the hugging pH Transformer now here also we can import the same thing we can import the hugging face pipeline by using the Len chain and we can create the pipeline and we I will show you so here uh by using the hugging phas API you can access the model by using the hugging face API you can access the model but you can install this model inside your local environment also inside a local environment also inside your local memory also so I will show you how you can perform the same thing by local llm local LM means what nothing I'm just going to be uh I'm just going to be download the model I'm just going to be download the model from the huging phase and that model itself I'm going to use similar to this uh GPT and all which I which I'm like accessing by using the open API or by using the Len Chen Len Chen and openi right so same thing I can do over here as well uh okay by using the hugging face API but if you want to download the model in your local memory in your local system that that also you can do that also uh you can do and that is also possible so I will explain you that part as well and finally we'll create a hugging phas Pipeline and from next class onwards we'll start the project implementation so uh if uh everything is fine until here then please do let me know if the agenda is clear to all of you and if you are liking the session then please hit the like button guys please hit the like button if you are liking the session I just started I I just given you the overview that what all thing we are going to discuss that's it I haven't started with the coding and all no we don't have a session on Saturday and Sunday uh we have a session from Monday to Friday great so let's start with the implementation so first I'm going to start from the memory that what is a memory inside the L chain and how we can use that so see first of all let me uh explain you the same thing by using the chat GPD so what I'm going to do here I'm going to open my chat GPD and let me write it down something over here so here I'm going to write it down that uh can you tell me uh can you can you tell me who won the first World Cup first Cricket World Cup so I'm going to ask to my Chad GPD that can you tell me who won the first Cricket World Cup so that this is my question which I'm going to ask to much chbd now let me hit the enter and let's see the reply so is saying that the first Cricket World Cup was held in 1975 and uh the Western de emerged as the champion they defeated Australia in the final which took place as a l uh Lords cricket ground in London on uh June 21 1975 so Western was the uh winner at that particular time now let's try to ask something to my chat gbt so here I'm asking to my chat GPT can you tell me can you tell me 2 + 10 so here it is giving me answer 2 + 10 is 12 now let me ask something else to my CH gbd can you tell me about the Indian GDP so here I'm going to ask my chat GPD can you tell me about the Indian GDP so it is uh saying that uh my knowledge up to date till uh U till January 2022 so I don't have a most recent data now it is giving up some more detail now you can ask the GDP you can ask like GDP the that what was the GDP in 2021 in 2022 something like that or whatsoever now here see what was my first question so here I asked the first question can you tell me who won the first World Cup who won the first Cricket World Cup now here see after writing this many of after writing a different different like a question now is still my Chad GP is able to remember this particular sentence this particular sentence because in back end actually it is using the memory concept it's able to remember the it is able to remember the conversation that whatever conversation is happening over here so here if I will ask to my chat GPT can you tell me can you tell me can you tell me the winning team captain so here I didn't mention anything and I'm just asking to my chat GPT can you tell me the winning team captain so if I will if I will hit the enter and here guys you can see the reply so it is saying okay captain as of my knowledge and I don't have information wining team captain uh can you tell me the winning team okay let me ask one more time is saying that uh can you tell me who won the first Cricket World Cup and here I'm asking can you tell me winning Captain uh winning team captain name so if I'm asking to my gp2 so it is saying that uh it seems like might be a slight spelling about the okay cap it's a captain I am writing a wrong spelling let me correct the spelling first of all so here uh the spelling will be a captain just a second let me copy the correct uh correct spelling and let me paste it over here and let's see I'm getting answer or not so here it is saying information the tournament okay so it is saying that uh uh just a second guys what I can do uh let me delete this chat or let me open the new chat and let me show you this particular thing oh yeah just a wait so it is able to remember the thing uh let me start from the new one uh first of all let me delete it don't know why it is doing like this just a second let me delete the chat okay now here is what here is my new chat now here uh let's start from the beginning so here I'm asking to my chat GPT can you tell me who won the first Cricket World Cup this is a SE uh like simple question which I'm going to ask my chat GPT so here uh you can see it is giving me answer okay no doubt no issue now here if I'm going to ask my chat GPD that what will be uh what will be 2 + 2 2 + 2 right so now let's see what I will be getting over here so here is saying that 2 + 2 will be four now let me ask my chat GPT what will be 2 * 5 now here it is saying that uh the multiplication will be 10 now I'm asking to my chat GPT can you tell me can you tell me about can you tell me who was the winning who was the captain d a i in captain of a captain of the winning team now let's see uh will it be able to answer or not it's taking time and let's see what will be the answer yes it is able to answer now see so here I asked to my C GPT who won the first Cricket World Cup so here is my like answer now I asked to my CH GPT what is 2 + 2 and the answer is this one now I asked to my CH GP 2 into 5 so this is the answer now again I asked to my chat GPT without giving any sort of an information regarding this Cricket World Cup and all and you can see the answer it is saying that Clive Lord was a captain uh clyve Lord was a captain of the West Indies cricket team that was was the Cricket World Cup in 1975 so here guys in a back end this chat GPT is implementing this memory concept now if you are accessing if you are accessing your uh if you are accessing llm uh this GPD and all by using the open AI or maybe by using the huging phase so how you can retain the memory because chat GPT chat GPT is application in backend uh this GPD model is running getting my point now if you want to implement a same thing let's say if you are accessing the model llm model by using the open API or maybe by using the Len Chen basically Len Chen is hitting the open API only so how you can retain this particular memory how you can do that so now let's try to understand that particular part that particular concept so if I'm using uh the open API that how I will be able to retain the memory and Len chain gives you this particular facility so by using the memory concept you can retain the memory like chat GPT so the problem statement is clear to all of you please do let me know in the chat if uh the problem statement is clear I'm waiting for your reply guys please do let me know what's the purpose of the Len chain so in the previous class I have clearly defined the purpose of the Len chain if you don't know about it so you must visit the previous class where I have um I did the detailed discussion about the Len chain great so everything is fine everything is clear now let's uh begin with the implementation so first of all guys what I need to do so first of all I need to import a different different uh first of all let me import the different different uh like a uh import a statement okay so here is my open Ai and okay it is fine now let me do one thing over here let me import the same file I already given to you you can check in a resource section from there you can download it's a same file which I'm using over here so it is for the asent type uh okay everything is fine now let me take a prompt template from here great so here what I'm going to do here I'm going to write it down the memory so just a second yeah so first of all let me write it on the memory over here and memory now let's begin let's start so here I'm going to import The Prompt template the first thing which I'm going to do over here so first of all I will have to uh create my a client right so for creating a client actually uh let me write another the code so here actually let me import one more thing I'm going to import llm Chen actually I restarted my kernel that's why I need to import it again and here uh let me do one thing so LM chain I already imported let me create a client first of all so for creating a client what I can do already written a code inside my file yeah so this is the code for creating a client so here uh what I'm going to do guys see here I'm going to create a client so this is what this is my client now open AI key is not defined okay first of all I will have to import the open a so from length chain Len chain do open and here I'm going to import this open AI now let's run it again and it is saying open AI is not there so let me change the spelling of the openi I think it is capital no it is not like that so let me check with the correct import statement what is that yeah this is the okay I'm using the length chain just a wait so by using the Len chain okay from llm actually we have to import this open a uh it's my bad so now it is done yeah it is fine I created a CLI yep now everything is set so here I have imported three state M first is prom template second is llm chain and third is open AI I restarted my kernel that's why I uh got a a requirement to reimport it uh this particular statement now here I created a client now let's try to understand the concept of the memory so first of all guys what I will have to do I will have to create a prompt template and I will have to hit my model right so for that uh what I did I already written a code so let me uh keep the prompt template over here so this is what guys this is my prompt template I told you that what is the meaning of the prompt template and how to create a prompt template each and everything I have discussed in my previous classes if you don't know about it so please go and check with my previous s so this is what guys tell me this is my prompt template now here I'm uh not going to hit my model U like directly uh instead of that I'm going to use llm chain I clearly told you in my previous class that what is llm chain llm CH LM chain is nothing l l m chain uh is a like concept where we are going to connect two components right so what is the meaning of the chain so inside chain you will find out that we are going to connect a multiple component so here we have llm chain where we are going to connect a multiple component my first component is a client uh which is my object of the open a which I have created and the second uh the second component is prompt template let's try to use llm chain over here and let's see what I will be getting so for that first of all I'm going to create a object of this llm chain now let me create a object of this llm chain and I can keep it over here I can keep this particular object inside this chain variable now let me pass my llm llm is nothing it's a client itself because by using this client only uh we are getting a model we are getting a model from the open Ai and by default I think we are using text D Vinci uh and if you are going to mention the model parameter you can use your desired model as well so that is also possible now over here I'm going to write down this client and then what I will do guys so here I will mention my prom template so let me mention my prompt template let me write down the parameter prompt p r o m PT and here let me copy this name prompt template name and here I have this prompt template name so once I will run it so here you can see we are able to create a chain so this is what this is my chain now what I will do I will run uh uh I will I will like uh I will call the run method and here I will mention the name so I'm I'm asking over here what is a good name for the company that makes so I can uh so this product actually uh I can I can give any sort of a product name over here so let's say here if I'm saying uh if I'm uh asking to my uh like model so colorful colorful colorful uh cup so here I'm asking to my model colorful cup so if I will uh run it so here you can see so it is giving me answer so for if I want to like uh check that what is the answer which I'm getting over here so I can give it to my print statement and let's see what will be the final answer so here it is saying holder color cup Corporation something like that it is giving me a name so let me call the strip over here strip will remove unnecessary thing from here so it is saying cakes uh Sugarland sprinkle so this is the name basically which I'm getting uh if I'm asking this particular question to my to my model right to my llm model to my uh GPT model now uh till here I think everything is fine already we did uh uh like uh we did it so many times in our previous classes in our previous session now let's try to understand few more thing over here let's try to understand the memory concept that how the memory how this memory is working in terms of this uh Len chain okay and how we can uh sustain the memory basically the uh conversation whatever conversation we are going to do now here see guys uh I'm going to write it down uh one more time so let me create one more prompt over here so let's say uh there the same prompt uh same prompt template I have used now here what I'm going to do um here I'm going to ask to my uh here I'm going to ask uh again one thing so let me do one thing let me again create this chain over here and I'm going to copy and paste the same thing and let me run it so chain do run I'm going to call this chain. run and instead of this colorful cup I'm giving a different name so here I'm giving name let's say drone so drones I I want to ask a I want to ask a company name so which make a drones so here the product name is what the product name is drones I'm passing the product name inside this method inside this run method so chain. run and here I'm passing this drone let's see what will be the name so here it is giving me a name drone X technology so uh it is giving me a name that that uh don't ask technology okay so here I can call this a strip so it will remove the unnecessary thing uh from the a beginning so skyron technology so this is the name basically which is giving to me and I hope till here everything is fine everything is clear already we have learned these many things right now let me uh explain you the uh like memory concept so here uh if I'm going to call one parameter so let me write it down this chain do memory so here if I'm going to call this parameter chain. memory so here I'm not getting anything here I'm not getting anything so let's try to see the type of this chain do memory that what is the type of this chain do memory so chain do memory now let me show you the type of this chain do memory so here you can see it is giving me a non type means it is not going to return anything to me because here we are not going to sustain any sort of a memory whatever conversation we are doing to my model what whatever conversation is happening right so we are not going to sustain anything over here we are not going to sustain anything over here in terms of the conversation now let's try to understand how we can do it how we'll be able to sustain the conversation whatever conversation we are making uh like by using the API and whatever conversation we are making with respect to that particular model so here for that we just need to write it down one parameter so uh first of all let me write down the heading over here so the heading uh let me write down the heading The Heading is nothing heading is convers conversion buffer memory so here uh we want to save a memory we want to save a like conversation memory so here I return this conversation buffer memory we have three to four topic inside this memory so step by step I will try to explain you each and everything now first let's try to understand what is this conversation buffer memory so uh you can just think about uh this conversation perform memory uh just like a memory whatever conversation we are going to do with respect to our model right so is going to store all those thing right it it is going to sustain all those thing it's going to sustain the entire memory throughout the conversation that's it now here what I'm going to do so here let me uh copy and paste one more statement and let's see uh what I have written over here so here why we have I have written that uh we can attach memory we can attach memory to remember on the previous conversation I just need to uh mention one parameter the parameter name is what the parameter name is a memory so I just need to attach one parameter and we'll be able to remember all the previous conversation regarding this model now how I can do it so here uh let me first of all let me import this conversation buffer memory from the lenon itself and the uh and then I will show you the same thing by uh from the documentation also so each and everything I uh pick up from the doc documentation itself and again I will go through with the document again I will go through the documentation and I will show you the same thing over there as well so just wait for few minutes and each and everything uh each and every part will be clear to all of you now here uh you can see I'm going to import this conversation buffer memory now what I need to do here so this is the class so I need to create a object of this class so here I'm going to create a object of this class and I'm going to keep uh this object inside the variable so I've created a variable by name Memory so this is what this is my uh like variable where I'm going to keep a object of this conversation buffer memory now let me run it so here is what here is my memory now I just need to mention this particular parameter inside my chain that's it and my work will be done let me show you how so here what I'm going to do again I'm going to create a prom template so here is what here is my prom template as you can see this is what this is my prom template now here what I'm going to do here I'm I'm going to create uh here I'm going to write it down llm chain so let me write it down this llm chain and the first parameter which I need to mention over here that's going to be a llm and my llm is nothing it's a client itself so in the client variable I'm going to keep my llm so here you can write it down this CLI c l i n t and here you need to mention the prompt so here is what here is my prompt and to this particular parameter to this prompt parameter you just need to pass uh this particular value this prompt template name so once you will pass this prom template name and you will what you can do you can create a object of this Ln chain and then you can call chain do run getting my point chain is nothing it's a collection of component getting my point yes or no in a uh like uh in a sequence in a particular chronology so here you can see we have llm client prom template now if I want to retain all the conversation if I want to retain all the memory which I'm able to retain in a chat GPT here you can see so if I'm asking to my chat GPT can you tell me who won the first Cricket World Cup so it is answer like it is generating answer now if I'm asking to my chat GPD what will be 2 + 2 so here what will be 2 into 5 now again I'm asking to my chat GPD that can you tell me who was the camp of the winning team I'm not giving any such information in inside my prompt as you can see but is still it is able to give me an answer based on a previous conversation so if I want to do a same thing with my API how we can do it so that's a thing which I'm explaining you now let me mention one parameter over here that's going to be a memory so m m o r by and here let me mention me m o r by so once I will run it so first of all let me uh uh keep all the thing in a variable variable name is going to be a chain so here Ive created a object of this llm chain now here if I will run so let me run something over here chain do run so here I'm going to ask that uh I'm going to ask regarding the product so what be the good name for the company that makes a product let's say I'm asking about the wines so if I will run it so it is giving me a name so it is giving me a name it is generating a name over here now again what I'm going to do so again uh I'm going to ask to my uh again I'm going to ask to my model so here I'm asking to my model so what would be the good name for the company that makes let's say here I'm saying camera so here I'm asking a c like regarding a camera I just want a name so it is saying that camera Lum technology so it is giving me a name it is suggesting me a name now uh here is what here is my name now uh let me ask to something else over here let's say uh I want a company I want to create a company so the company related to a drone so I want a company name which create a drones so here if I'm saying that drones now here you can see is giving me answer drone craft so here I asked three question to my to my model by by hitting the API I asked three question to my model to my LF model now uh let's see it is able to sustain the memory or not so now if I will run this chain. memory now you will be able to find out yes it is able to retain all the conversation whatever conversation is happening because because of what because of this conversation buffer memory so whatever conversation we are doing right whatever previous conversation is there so each and every conversation we are able to sustain but previously we were not able to do it so here it was was giving me none type here it was not giving me anything but now you can see we are able to sustain the information and if I'm calling chain. memory it is giving me the entire detail over here now let's try to understand let's let's try to like uh uh let's try to understand a few more thing over here now here if I will run this chain do memory chain. memory and here if I will call this chain do memory. buffer so now you will find out that this is the entire conversation now let me uh print uh let me keep this thing uh in my print method so I won't get this selection over here instead of that I will get the new line because slash and me is what SL and me is nothing it's a new line now over here you will find out the entire conversation that whatever conversation is happening between me and model so here human is asking about wines so e is giving me answer now human is asking about the camera is giving me answer human is asking about the drones it is giving me answ so like this you can draw uh you can create your prompt template and you can ask to anything to your model and you can sustain the entire memory you can sustain or you can uh keep the en entire conversation with you getting my point guys yes or no are you able to understand it is getting clear so please do let me know if you are able to understand this particular concept I'm waiting for your reply in the chat please do let me know guys please write down the chat if you are getting it and please hit the like button so yeah I will get some sort of a motivation I are you able to understand the concept of the memory how to retain see here actually we are going to uh like retain the conversation and uh I will explain you the further use so uh I will I will explain you a few more concept over here just just wait step by step we'll try to understand each and everything so don't be in a hurry and try to understand the entire thing if you have started something then definitely I will end it okay so here people are saying that it is clear and you are able to they are able to understand the concept of the memory that how to sustain the conversation whatever conversation we are doing all the previous conversation now let's try to understand few more thing over here so uh yes we are able to uh maintain the previous conversation by using this conversation buffer memory we just created a object and we are just going to keep it over here in our chain that's it now guys here let me show you one more thing so here here what I'm going to do so here uh I'm going to introduce you with the New Concept that's going to be a conversation chain now let's try to understand what is this conversation chain each and everything we'll try to understand by using this conversation chain so here uh I'm saying that here I'm going to uh like write it down some sort of a statement and the statement is something like this so here uh let me mark down it and let me show you so conversation buffer memory goes growing endlessly means uh whatever conversation you are doing uh so you will be able to sustain all the conversation by using conversation buffer memory No Doubt with that but just remember last five conversation chain or if you want to remember just last 10 to 20 conversation chain in that case what I can do what should I do over here so here L chain has given you few more method now let's try to understand regarding uh let's try to understand those particular method that what is the use of this conversation chain and we have one more me method now let me uh give you that particular method also try to understand about it so here is my second method see each and everything I kept it somewhere in my notepad I'm just going to copy and paste so try to understand please because I'm doing it uh because I want to save my time and uh in a short uh amount of time I want to deliver uh like uh more and more thing so here you can see uh there is one more concept that is conversation buffer window memory so there is two concept which we need to understand now here first let's try to understand this conversation chain that what is the meaning of it so here uh what I'm going to say that uh let me keep it in a single line and if I uh if just remember let's just remember 10 to 15 convers and that would be great now what I can do here I can write down some sort of a code regarding this conversation chain so first of all guys what I need to do here first of all I need to import it so let me import this conversation chain over here so from uh the link chain itself from the link chain do chains I am going to import this conversation chain now let me run it and yes we are able to do it now here what I'm going to do I'm going to create object of this conversation chain now if you look into the if you look into the object so here I'm going to keep a couple of thing here I'm going to write down a couple of things so here the first thing see uh this is what this is the object this is the object and inside this object I'm going to mention few parameter the parameter nothing here I'm just is going to mention this model LM model and here I mention open a I can write it down the client directly or else I can write it down like this open a and here is my open a key and this is the temperature you already know what is the temperature in the previous session in my uh day two actually I have uh explained you the concept of the I have explained the concept of this temperature what is the meaning of the temperature and the value you will find out of this temperature between 0 to 2 if you are keeping it zero so you will get a straightforward answer but you have like increasing the value of this temperature so it's going to be this model is going to be a more creative it will give you the creative answer so here you can U maintain the temperature of the answer whatever answer basically you want whatever output basically you want you can maintain a temperature you can maintain the creativity of that particular answer now here uh to this particular method to this conversation chain I'm just going to pass this llm and here is what here is my object open Ai and there's couple of parameter which uh with that you are already familiar now let me run it so let me create a object of this conversation chain so here I created object of this conversation chain and the uh object name is what the object name is convo now I just need to run something over here so uh here what basically what I'm going to do here I'm going to write down convo convo do prompt so here if I will write convo do prompt so you will find out that this is nothing it is giving me a prompt template so here we have a input variable which is history and input template so it is a there is a template the following is a friendly conversation between a human and AI the AI is a tative uh provides lots of a specific detail from its context if AI does not know the answer to the question it truthfully say it does not know so here uh they have written by one by default message one by default prompt actually now let's try to see uh something else over here so here I'm going to write down con. prom. templates now uh let me extract this template and here you will see that uh here basically we have a template the same message which I was trying to read from there from here itself so now you can see the same message over here now if you will write it on the print so here you will get the clear cut message uh without the selection and all so just write down inside the print so this is the uh thing uh this is the message basically which I'm getting it's a by default message uh which I'm getting if I'm calling this con. prompt so here in the template it's a by default message now uh now let's try to understand that what is the use of this uh convo what is the use of this particular object now here what I'm going to do here I'm going to ask the same question to my chat GPD uh to my GPD model now here I'm saying that convo convo do run and here I'm asking to my uh model uh who won the first Cricket World Cup who won the first Cricket World Cup who won the first Cricket World Cup this is the question now if I'm going to run it so here you will find out it is giving me answer that the first Cricket World Cup won by the Western be in 1975 they beat Australia by 179 in the final so this is the information which I'm getting from the from my model now here what I'm going to do here I'm going to run uh convo convo do run now here I'm asking to my model that uh can you tell me can you tell me uh can you tell me how much will be 5 + 5 so it's a simple question which I'm asking to my model now let's see the answer the answer is 10 now let's try to ask one more question over here so let's try to ask one more question to my uh model so here what I'm going to do here I'm asking con can you tell me how much will be 5 * 5 so that's a question or let me keep something else over here let's say 5 + 1 and here and this is the expression this is the mathematical explation which I'm passing now let's see what will be the answer so it is able to answer me that the answer is 30 now let's try to ask uh uh the question to my model that uh who was the captain of the winning team the same question which I was asking to my chat GPT and it was able to answer now let's see uh will it be able to answer the same question or not over here if I'm hitting my API let's see now so here what I'm going to do so here I'm going to uh copy it conversion uh convo do run and I'm going to ask the question the question is nothing the question is uh very simple so who was the captain who was the captain of the winning team so I didn't give any sort of information what winning team which winning team I just like going I'm just going to follow the conversation now if I will hit the enter so here you will find out it is able to give me a reply the captain of the winning team in the first Cricket World Cup was the live lck so it is able to sustain it is able to sustain the conversation now how we can do it by using this conversation chain so first we have understood that if you want to get the if you if you want to get all the previous conversation so you can get it you just need to mention the memory parameter over here if you're not going to do it so in that case it will give you the none but if you're going to mention it conversation buffer memory so it will be able to retain all the previous conversation now here we are talking about this conversation chain so by using this conversation chain I will be able to retain the I will be able to retain the tell me I will be able to retain the memory and uh yes uh like you can ask anything let's try to uh again check with a different uh like uh let's try to check again with a different prompt so here I'm uh saying to my model so can you divide can you divide those uh can you divide uh the number numbers and can you give me answer can you give me a final answer so here I'm asking through my model that can you divide the number whatever number basically is using before actually it is using so can you divide those particular number and can you give me the final answer now let's see what what I will be getting over here so it is giving me the five okay so it is giving me a five uh which uh number is going to divide I uh so the answer is five which number it is going to divide I think uh 5 is six 5 / by uh five if it is saying like that maybe is going to divide this uh 30 by six so that's why I'm getting this five but yeah it is able to retain the memory it is able to retain the memory and it is working so uh I think uh you got to know that how to uh get all the previous conversation that is the first thing and how to retain the memory if you are using the API now guys see we have one more method over here the method name is what conversation buffer window memory now what's the meaning of that first of all let me show you first of all let me write it on the code actually and then I will explain you the meaning of this conversation buffer window memory so uh tell me guys still here everything is fine everything is clear that whatever thing my chat GPD is doing I able ble to do the same thing by using this Len chain this Len chain is too much powerful if you if I'm using my API so in that case how I can sustain the conversation how I can remember all those thing so here is a way you just need to import the classes and all in a back end already the code has been written by someone you just you are just going to use it and uh definitely you can uh create a application in that you can use the same concept got it so if this part is getting clear then and please do let me know in the chat no buffer this is a different object now we are just going to remember all the previous conversation here see we are able to retain the previous conversation this one is giving me all the conversation but here actually by using this conversation chain what I'm doing tell me so here by using this one I'm able to do like same this chat GPT okay okay so where we are able to retain the uh like where we are able to retain the memory so here I was asking this thing to my CH to my model to my API and then I I written this particular um like me I I written this particular prompt and then again I asked this question related to this one and it is able to give me answer so that's a difference try to understand try to observe it here conversation buffer memory this a different method by sustaining the conversation here you can see and conversation chain is doing a same Behavior Uh like which we are able to achieve in a chat GPT so somewhere in a in the chat GPT application also they implemented the same concept for sustaining the memory that's why it is able to do it we don't know uh uh What uh what type of code they have written a backend if you want to check you can check it you can go through with the Len chain so here uh you can search a len chain l a n g and uh just check with the Lenin GitHub so here you will get the source code code of the Lang chain and now you can uh check that what code they have written regarding a different different thing so here go inside the cookbook and there is like all the code regarding a different different thing and just try to read the lowlevel code that what all what Logics and all they are going to uh they have written over here actually so you just need to go through with the Len and uh GitHub and there you'll find out all the codes and all tell me guys now this part is getting clear to all of you please or do let me know in the chat if the part is getting if this part is if this part is getting clear or not this uh conversation chain and this uh conversation buffer memory now let's try to understand this conversation buffer window memory but that what is a meaning of it and then again I will uh I will try to revise it and I will uh I will be showing you the same thing by using the uh documentation so all the thing uh they have mentioned over there already uh each and every theoretical is stuff then uh I will try to explain you that uh from there itself now here we are talking about this conversation buffer window memory then what is a use of this particular method now let's try to understand it so here the first thing which I have to do so first of all I have to create a object of it now uh here let me create a object so I'm going to import it conversation buffer window memory now if I'm going to run it so yes I'm able to run it and I'm able to uh I'm able to like import this particular statement so here I'm going to create a object of it so this is what this is my like object and here I'm going to write down my object name is nothing it's a memory now inside this uh uh like object actually uh there is one parameter so let me write it on the parameter name so the parameter name will be a key right which I represent with which they represent with K so here I I'm going to pass one parameter the parameter name is what the parameter name is K now here I can pass any sort of a value regarding this K 1 2 3 4 5 6 7 8 9 10 11 12 whatever now what is the meaning of that so first of all let me write down that and let me run it in front of you and then I will try to explain you this thing so here I'm going to write it down K is equal to 1 now here I created a object so here I've created a memory now what I'm going to do I'm going to create a conversation chain again so the conversation chain which I uh uh which I imported over here now let me paste it over here this conversation chain conversation chain and now what I need to do I I'm just going to be mention one parameter over here so I'm going to mention memory parameter inside this conversation chain see this is my main U this is my main class this conversation chain which I'm using over here though uh along with that you'll find out two more so conversation buffer window memory and conversation uh conversation buffer memory so buffer window memory what is the meaning of that after this uh particular example you will get to know by yourself on only so here I'm going to keep it and let me uh write it on this memory over here and here what I'm going to do here I'm going to create a object so convo object so this is what this is my convo object now uh what I'm going to do I'm going to run it so here I'm going to run the same thing so now let me uh copy it and let me paste it over here so let me paste it over here uh this particular thing uh this particular sentence and here let's see what will be the answer so here if I'm going to run it so you can see that it is saying that the first Cricket World Cup uh was held in 1975 and it w won by the wested that is perfectly fine now again I'm going to ask to my model that convo. run convo do run and here I'm asking that what will be 5 + 5 now it is saying that 5 + 5 will be 10 now I'm asking to my uh now I'm asking to my model that who was the captain of the winning team so if I'm uh giving this particular code question now let's see what will be the answer so it is saying that I sorry I don't know I'm sorry I don't know because see uh if I didn't mention anything it is able to uh by default actually see there is a uh memory parameter see in a you can create this conversation buffer memory and if you are going to create a chain now if you're going to create a chain now there you can mention this memory and you can track the entire conversation that is perfectly fine now here uh if I want a same behavior like this chat GPT for that there is a main method conversation chain there's a main method so here conver here I created a object of the conversation chain and here is what here I'm going to call this run method now you can see it is able to sustain the memory it is able to sustain the memory now here you will find out one more thing uh like one more class conversation buffer window memory now here Ive created a object of this conversation buffer buffer window memory and I passed the key value key equal to 1 so key equal to 1 means what is the meaning of this key equal to 1 so it is just able to sustain or it is just able to remember all the thing uh like till the one prompt till the first prompt only after that it won't be able to remember anything if I'm writing over here K is equal to 4 now in that case just see the effect so here if I'm going to create K is equal to 4 so see uh convo is there now I'm going to run it okay great now I'm going to ask to my model okay now see see now it is giving me answer so I can Define the window size I can Define the number of prompt here if I'm saying uh K is equal to 2 so now let's see what it is giving to me so here I'm saying K is equal to 2 that's great this one is fine this one is fine now it is saying the first Cricket World Cup was held in 1975 now it will stop over here now if I'm going to ask to my uh like this one so here it is giving me answer because now I'm going to sustain this both both conversation see K is equal to 1 means what let me tell you that K is equal to 1 means what see k equal to 1 means what this one only the first one k is equal to 2 means what this both this both K is equal to 2 so if I'm writing over here K is equal to 2 so it is going through with this particular sentence and it's going through with this particular sentence and if it is seeing this sentence now so it is able to remember it is able to see this one now this one and this one so in that case it a it is able to generate answer but if I mention k equ Al to one so after this one is not able to remember anything that's the last one okay so I can select the window size over here you can select the window size if you're not going to select it will be tracking the entire conversation by default it will be tracking the entire conversation now let's try to see the same thing by using uh like on top of the documentation also so they have mentioned the same thing so let me open the Len chain documentation l n Len chain documentation and over here uh let me open it first of all so Lin memory where you will find out go inside more and here is a memory so let's try to understand uh about the memory that uh what all typee of memories we have and what all thing basically they have written over here let's try to understand that thing so most llm application have a conversational interface so an essential component of the conversation is begin a it's conversation uh is being able to refer to information introduced earlier in the conversation means uh whatever conversation we are making so it should be like uh like it should have a connectivity in between so at bare minimum a conversational system should be able to access some window of past message directly so a comp more complex system will need to have a world model that is constantly updating which allow us to do thing like Mentor information about the entities and their relationship so here they have given you the complete detail now building memory into a system how how state is stored how state is queried so there are like some sort of a theory they have given over here now here they have given that this get is started so let's try to read it from here so let's look at what memory actually looks like in L chain here we will cover the basics of interacting with the arbit memory class so here the same memory class uh which we were using so here I have created a like object of the memory class now here I'm asking so memory. chat. memory add user and what is up so something like that uh there calling basically this particular method over here which is there inside this conversational buffer memory itself now what variable get written from memory so here if you will load the memory you are getting this particular thing the same thing I was able to get by calling this parameter the parameter which I was calling chain. memory actually I'm not directly using this thing I'm not directly using a method from this particular class from this conversation buffer memory instead of that what I'm doing instead of that I've have created a object of this llm chain and here I'm passing my all the component I'm making a chain okay I'm stacking all the component and then basically I'm calling this chain. memory and I'm getting here I'm getting this particular output and the same output you can see over here as well you you you are getting the same output over here as well right so yes I'm able to get the same output by using that particular parameter chain. memory. buffer or chain. memory now here uh we have other one also so like you can give the key and all you can explore about it now there are few more parameter like return return message and all each and everything you will find out over here now end to an example so they have given you the endend example over here so open a prompt template conversation buffer memory now see I'm using the same thing I'm using a same thing over here I'm using the llm chain I'm I'm running the same example in my jupyter notebook so you can go through with the documentation and you can copy from there also and you can test it they have given you like a small small code is snipp it just for the testing just for the learning and directly you can integrate this thing inside your application got it now here uh you can see using a chat model so one more example they have given you and then next step inside that you will find out few more thing uh memory in llm chain memory types okay now customized conversation custom memory multi uh multiple memory classes there are so many thing you will find out so if you'll go inside this memory type so just just see uh with the memory types and and then conversation buffer conversation buffer the same thing um the entire code you will find out then conversation buffer window now let's see what is the meaning of the conversation buffer window so conversation buffer window memory keep a list of interaction of the conversation over the time it only uses the K interaction the number of interaction so this can be useful for keeping a sliding window of of most recent interaction so the buffer does not go too large so if we are talking about buffer so it is having a complete uh like a complete uh conversation whatever conversation we are doing but if you want to keep it short so you can mention the K over there so here I I was doing that so here if I'm writing K is equal to 1 so here if I'm writing K is equal to 1 in that case is not able to remember anything so simply it is saying that I don't know about it it it it is just going to stop over here itself so this one and this one now uh if I'm going to ask this uh particular thing so it is saying I don't know about it because after this one is not going to track anything K is equal to 1 means what just one sentence means it is not going to remember anything uh over here now if I'm going to write it down over K is equal to 2 in that case it will be able to sustain something right by using this two particular prompt and if I'm going to ask something after this one so it is saying that yes now it is knowing okay now it knows about it so here uh if you're not mentioning any sort of a window is is going to keep a track for the ENT entire conversation but if you are going to mention a window parameter over here in that case it will be restricted each and everything they have mention inside the documentation itself try to read it from here got it now how to use a chain means how to like uh uh like how to uh sustain a memory and all means if you're going to make any sort of a conversation and all so this conversation buffer memory conversation buffer window memory is just for sustain the the memory basically the conversation but actual conversation how you make the actual conversation which we are doing over here actually here so by using this particular class conversation chain class this is the main class and this two class for sustaining a conversation this is for the entire conversation and this is just for the limited window means a customized window whatever number you are going to write it down till that particular window now it is clear what is a memory yes or no please do let me know in the chat if uh this part is getting clear to all of you are you able to get it guys uh are you able to understand the concept of the memory how to do that how to make a conversation how to import the different different import statement how to like uh how to go through the documentation yes or no please do let me know in the chat if you're getting it I'm waiting for your reply clear clear clear great uh if you have any doubt you can ask me in the chat and then I will start with the next concept what is the limit of of memory Li limit you can Define now you can def Define the limit according to your problem statement you don't want to be create uh to Long buffer so in that case you can uh you can uh like uh mention this K parameter it's up to you it's up like uh up to your requirement up like how much what uh how much uh like your configuration and all what all resources you are using according to that you can decide where the memory concept used in a real uh life exam application so here what I explained tell me so it is not a real time explain this chat GPT so this chat GPT is a real time application now that that that's why first I have explained this one only so let's say if you are making a conversation to the chatbot if you're making a conversation to the chatbot and if you ask to the chatbot let's say you visited a website any website and let's say I your own website side there you are asking uh let's say we have a chatboard on in own website you are asking to the chatboard okay what is the price of this particular course then U like let's say you are getting some sort of a prize and then you are asking something else who was a mentor and all now again you are asking a question related to that course itself that what all thing you covered in this course now it is saying that which course I don't know about any course even though you mention the name over there gener course but it is saying no I don't know about it because is not able to S it is not sustaining the conversation the conversation is not in buffer so like there it can go and it can like read each and everything the model actually it is not able to sustain the context is able to sustain a context in terms of the a sentence but not in terms of the conversation so that's a real time example so that's why I have explained you this chat GPT at the first place and then I back to this uh I uh went to this uh like python implementation by us using like if we are implementing the same thing like by using the API by using the openi how we can achieve this particular thing how we can achieve the memory and all how we can sustain the memory so it's all about that only please try to run it by yourself please revise it you will be getting and one more thing uh before implementing with uh before implementing any sort of a concept from the Lan chain try to go through with the documentation theyve given you each and everything along with the theory so first read the theory and read the uh like uh code snipp it and all whatever they have given you and then you can uh run it inside your system and then uh basically you can run my file as well whatever like code and all I'm writing it don't worry I give you I will give you the each and everything in a resource section so from there itself you can download it okay so if this thing is clear do please do let me know because I'm going to start with a new thing uh with a new topic and now let me create a new notebook over here I think this Lang chain is clear in the Lang chain I have explained you five to six concept which is going to be a very much important once uh we'll start with the project you will get to know the importance of this thing this topic and inside this particular top inside this particular notebook I have kept everything related to this open API and this L chain so here let me rename it so test open AI API test open AI API and Link Chain so everything you will find out regarding this openi API and Lenin inside this particular notebook guys you just need to visit this notebook everything I have written over here along with the code so let's start with a new topic and the new topic is going to be a uh hugging face hugging face with Len chain uh hugging face with Len chain hugging face face is fce so can we start now have you open the new notebook yes correct aishu uh your understanding is correct tell me guys uh have you opened the new jer notebook so uh I can start with the thing I can start with a new topic hugging Faith with Lin and after this one after explaining you this thing I will move to the uh like I will move to the project I will I start with the project from Monday onwards and first I will explain you the use case and then I will code in front of you only first I will explain the use case and the project setup and all and then we'll start with the implementation of that so let's start with the hugging phase with lench it's going to be a new thing new concept so let's understand uh this uh particular thing so first of all guys what you need to do so first of all you need to log into the hugging face hugging face Hub so just search in your Google hugging face and you will get a very first website this is the website of the hugging phas sdps do hugging U hugging face.com so uh try to visit to this particular website and uh if you didn't uh sign up so first do the sign up and then sign in and after that you will be able to create your profile so first you need to do sign up and then do the sign in so automatically you will get your profile and this is what this is my profile I already did a sign up so no need to do anything you can do the sign up by using the Google s well by using your Gmail ID as well so just try to sign up first and try to like create your profile and then sign in automatically you'll find out your profile over here so after getting your profile guys see uh here they have uh see this is the uh like uh homepage now just click on this model so once you will click on the model actually you will find out so here it is saying no re uh activity display here we have a data set spaces papers papers collection Community there are so many thing right so if I'm following something so it will be visible over here now just click over here this one this model so what I can do I can click on this model so I will be getting all the model these are these are the model basically so just click on this all so here basically you will find out all the model and here actually it is showing you the trending model what trending model is there over here now uh directly you can search about this model so what you can do I'm not able to open let me check with this models yes guys so over here you can see these are these all are the model which is there over the hugging phase now you can uh short it uh which is a trending one which is a most download one which is a recently one recently updated most uh liked llm so there you will find out like all the llms and all now let's check with the most like so here I'm going to short all the model with this most like okay so stable diffusion is is a model which is the most liked one now you will find out Bloom is there uh okay so here orange mix is there a control net is there open journey is there chat glm is there star coder so there are so many model even Lama 2 is also there this one Dolly V2 it's a model from the uh data brakes this llama 2 it's a model of the meta it's a model from The Meta now stable diffusion is also there stability AI there's the organization name stability Ai and here you will find the table diffusion and here you can see the number of downloads as well so there you will find out the number of download now see llama this llama 2 how many times it has been downloaded 947k around 1 million now here you will find out gpt2 gpt2 is also there it has been downloaded 17 million times 170 million download is there okay so okay I think it's not a download it may be a size uh let me check with the download so most downloaded so here now I'm going to check with the most downloaded I think it's a download only it's not a size actually so 73.3 million and distal GPD is also there robot is there there are so many model you will find out and you can see the number 4 lakh 27,000 so if you are talking about the open API so you are restricted with the open API let me show you that what all model is there so if you search over the open a so just open the opena website and check with the models just do the login First and try to uh like click on this API and go inside this model now here you will find out all the model this all the model has been developed by the openi itself and you will find out a different different variants of this model like this chat GPT there are so many variant of this Chad GPT but if we are talking about this hugging face Hub so it's a open source repository anyone can contribute over over here so whoever has created their llm so they have uploaded to this hugging face Hub now you can see the number of model you can see the different different uh like a task over here that what you want to do feature extraction text to image or text to text image to video text to video whatever you want to do you will find it find it out over here let's say what I want to do let's say I want to perform text to text generation so if I will click on this one so you will find out so you will find out all the model from text to text generation you can perform text to text Generation by using this particular model let's say you want to perform a conversation so for the conversation basically there is a different model dialog GPD is there and go is there and you will find out other model as well so from a different different organization you you can go through with it and you can check got it yes or no so this part is getting clear to all of you you can check with the training you can check with the training and you will find out like which is a trending one now let's say I want to do a text to text generation so here I'm going to use this particular model FL T5 base so I'm going to use this particular model now how I can do that what will be the procedure if I want to use this open source model without any charges so here I'm not going to pay anything as of now for this particular model so how I can use it how I can like uh perform text to text Generation by using this particular model now let me tell you that so first of all what you need to do so just click on your profile and here click on the setting so once you will click on the like this setting so here you will find out the token access token so click on this access token so already I have created a token over here so you can click on the new token you can click on the the create token and you will be able to create a new token over here now this is going to be a API key this is going to be a token you can delete it you can recreate it whatever you want you can do it and here uh you will find out access token probability authenticated your identity to the hugging face Hub allowing application to perform specific acction specify the spoke of permission read write and admit so here you can visit the documentation and you can read more about it so first of all guys you need to sign up and then you need to log in and after that you will be able to create your profile and then you can go inside your profile and go inside the setting and there you will find out the token this access token this particular option and try to create the new token after creating a new token what you need to do you just need to copy this token and uh I will tell you step by step what you need to do so from scratch only I'll be writing all the code so first of all see before starting with the hugging face you need to install some Library some other libraries as well so let me give you the name of all those Library I I like kept it somewhere I'm just going to copy and paste all the thing now here are the first thing first Library which I'm going to be install that's going to be hugging face Hub the second one is a Transformer and the third one is accelerate and bit sendy bytes so here this is to the this two is not a mandatory one but yeah you need you can install it because I was getting some sort of a error and for that only I have used this I have like installed this libraries so if uh U like uh so yes please uh like download uh this thing this particular uh like packages accelerate and bit sendy by so you won't get any sort of error throughout this implementation but this two is a mandatory one the first one is a hugging ph up and the second one is a Transformer so you cannot SK skip this two thing and L chain should be there inside your virtual environment because this hugging phase actually we are going to access by using the Len chain only by using the Len chain only we are going to access the this hugging phase so I already did it I already installed it you just need to run it and uh if I already installed then it will uh it will give me the message that requirement is already satisfied so here you can see it is giving me that requirement is already already satisfi got it now guys what is the next thing which I need to do so step by step I have written each and everything I'm going to write it down over here as well so the step first what you need to do so in the step first you need to uh download all the required Library so let me write it down over here the step First Step first is nothing download all the required Library now let me keep it over here and see we are able to download now in the step two what I'm going to do here in the step two I'm going to import it so let me import all the required Library so I have written it over here let me import it uh over here so this is the library which I have imported so the first one is H prompt template hugging phase from the lenon itself of okay so I'm going to import this hugging face Hub and here is what here I'm having the llm chain I'm using this hugging face with Len chain I'm using this hugging phase with this L chain try to remember this thing guys okay so if you are implementing it by yourself please try to remember that we are using this hugging phase by using this Len chain I told you this H Len chain is a wrapper on a different different API not even op open AI we can access many API by using this Len chain many open source model and all it has been designed in such a way now here uh I have imported this thing now what I need to do guys so here I'm going to write it down the Third thing so the third one is what you need to uh like set the environment variable so for setting up the environment variable let me tell you what is a step so here is a like code basically which you need to run so let me copy and paste each and everything I have written uh somewhere so I'm just going to copy and paste the small small lines and all now you need to uh you need to set the environment variable and here first of all you need to import this opening system so import OS os. environment and here is what here is your hugging phase API token and set the environment variable set the environment variable by using this particular uh like a command now if I will run it so here I'm able to set the uh like hugging fish token okay this is my variable name and this is my value value of the variable now from where I got this particular value so I got this value from here itself from the token itself so just try to click on this access token and you will get this value you will get the value of the token got it yes or no now here guys just click on this hugging face and here I seted this token I set this token and this is the variable and this is the value now what is the fourth thing which I need to do so here let me write it down uh this particular thing so step by step I have written each and everything now the next thing which I'm going to do over here I'm going to do text to text generation I'm going to do text to text generation I'm using sequence to sequence model this Transformer is what it's a sequence to sequence model now if we are talking about the uh different different llm actually as a base archit Ure it is using the same Transformer architecture right so either you can say sequence to sequence model encoder decoder model anything anything will be fine for the Transformer also now I want to do a text to text generation so I shown you over here itself in the hugging face model so let me show you where it is so once I will click on this model and here let's say text to text generation I want to do text to text generation so this is a model this a flan T5 base it's a model from the Google side it's a Google model flan T5 base you can read uh everything about this uh T5 model for what this has been trained what uh which data they have used what is a model size 2848 million parameters is the it is having like 248 million parameter and here the number of here you can see the number of downloads here you can see the table of content each and everything basically they have defined they have written over here regarding this particular model and this is a Google model and yes you can uh check about it you can use use it actually uh how to use it uh let me tell you that but yeah you can check about it uh just go through the hugging face Hub hugging face model and click on this model click on this text to Tex generation and you here you will get this FL T5 base now guys what I need to do what will be the next thing so the first of all I need to Define my prompt and here what I'm going to do guys here I'm going to Define my prompt so let me copy The Prompt and here is what guys here is my prompt this is what this is my prompt now here I'm going to uh like Define the chain so let me create a chain over here now inside the chain just just try to focus guys what I'm going to do over here so here guys let me remove this max length I'm not going to write it down as of now so initially like uh not initially in my previous example just look into the chain uh what I was doing over there so if you look into the chain there I was writing there I was defining the model from the open a API so let me show you uh let me show you the chain prom template agent and here we have a chain so where is a chain where is a chain where is a chain this is a chain now see prom template is there chain and here I was I was defining a model from the opena itself what what I was doing guys tell me I was defining a model from the open itself now instead of the open now instead of the open now I'm using the hugging phas so what I did I created a object of this hugging face Hub and I given the repo ID means uh this is the ID of the model and here is a argument that U like I need to set the temperature and all so in this particular format let me take it in a different uh let me take it in a different cell let me show you so here I'm going to copy it and let me paste it over here so what is happening just see what is happening let me take it as a command so this is the code which I'm running see this is the code so here now I'm using now I am going to access the llm okay which llm this Google FL T5 large now instead of the openi I'm going to use this particular llm FL T5 large and this is the uh this is hugging pH actually which we already imported from the lenen itself this is the one and before that actually you need to install this hugging phase so what you need to do guys tell me you need to install this hugging phase pip install hugging phase otherwise you might face issues so here uh you have you are using this particular model this is some sort of argument uh which you need to mention now let's try to create a chain and here the same thing you need to pass the prompt only now see the power of the length chain what it is able to do now uh instead of the hugging open AI I'm able to connect with the hugging face also like likewise we will be able to connect with many apis just check with the documentation uh so now here you can see we are able to create a object I'm getting some sort of a warning you can ignore it because just a uh it's not an error actually it's a dependency warning that uh don't use this version that version what whatever now here I have created a chain now what was my prompt so here I'm saying what is a good name for the company that make a product whatever like uh regarding whatever product I can ask over here so here I'm saying that chain do run the same thing I'm going to ask over here chain dot run now here uh let's say I'm going to ask uh which product I want so I want uh let's say mic or I want camera again so if I'm asking regarding the camera so let's see so here it is giving me answer uh Nikon what is a good company name for a uh what is a good name for a company uh that makes product so it is giving me a neon regarding this camera Let's uh let ask to the different uh uh product let's say watch so here let's see it is giving it Tata now let's see uh here if I'm asking colorful cloths colorful cloths so here you will see that it is giving me a DE so different different name I'm getting in a similar way uh which I was getting by using this open API now instead of the open API I'm using this flan T5 large model you can use any sort of a model any other model as well there are like lots of model which you will find out regarding this text to text generation you can use this model also Mard you just need to mention the ID Mard this is the basically ID just open it and just copy it from here just copy it and keep it over here like uh keep it like this let let me show you that so here is your model name and what you can do just copy this hugging pH from here uh this the complete uh sentence and just change the name just change the name of the model just copy it and paste it over here that's it so just copy it and paste it over here and you'll find out this Facebook ambot large 50 now you can use this particular model if you want few more a few creativity over here you can uh pass the temperature M uh like temperature uh value 1.5 let's say so so this is what this is a model from the hugging face and now this time you are using a different model so the model name is what Facebook MB large 15 so like this you can access a different different model by using the length chain now what you can do you can create a one more chain so here I'm going to copy the same thing now let me change the envir variable name there's going to be a chain two and here what I'm going to do I'm going to copy this hugging face Hub so from here I'm going to copy this hugging face Hub and let me paste it over here so this is what this is my hugging face Hub this is my repo this is my model here I'm setting the temperature and this is what this is my prompt now if I'm going to run it so yes I'm able to create a object now here what you can do here you can call the method run so run and here you can ask anything so let's say here I'm asking uh which product so you can ask uh a mobile so here let's say regarding any sort of a product you can ask so it is running so what is the good name of the company that makes mobile uh it is saying that uh it is giving me a prompt only over here I think I need to follow something else uh chain do run let's ask regarding the same thing colorful cloths and let's see what will be the answer it is giving me a prompt only I think in between I need to run something over here that's why so Transformer this is a pipeline h okay tokenizer I think it is not giving me a correct answer what so so prompt is fine I'm passing a same prompt and this is the prompt now let's say I'm saying zero let's set the different value of the temperature or 05 and see what I am getting over here uh chain two what is a good company that makes a colorful Clause it's not giving me answer instead of that it's giving me a uh like a complete prompt itself so llm hugging face and M large 50 model is what there is a parameter okay no issue I will check with that if I need to mention something over here but that's a way maybe it is not able to uh like predict correctly whatever I'm asking but yeah it is giving me answer this flan T5 large model and even the CH GPD the GPD uh model also from the open AI but it is giving me something else it is running but uh I'm getting other answers or other answer over here not related to our related to our prompt I'm asking something El it is giving me the complete prompt over here okay so this is fine now tell me guys how to use any open source model did you get it please do let me know in the chat if you got this particular part that how to use a different uh how to use any open source model from the hugging phase because it is not a rulebased system now if I'm again running a query so it is not giving a same name because it's a AI based system again and again if you asked to the chat GP now it will do the same thing all right it won't repeat the thing it won't repeat the thing based on your uh like query it will give you the different different suggestions and all so that's why it is giving you the different name tell me guys fast uh it is free actually this hugging pH uh like token is free you can read more about it uh just go through the documentation there is some sort of charges and all U okay so but as of now it is free uh means uh like up to some sort of a tokens and regarding some sort of models it is free okay so here guys I think this hugging face part is clear to all of you please do let me know in the chat if this part is clear yes make question answer board will create in the next class first of all let let me explain you that how to use any uh open source uh model so here I'm using this open source model Google FL T5 large tell me guys fast uh so this part is getting clear to all of you if it is getting clear then please do let me know in the chat I'm expecting yes or no in the chat if you have any sort of a doubt you can ask me I try to clarify that and then I will explain you how to create a pipeline how to create a pipeline by using the uh Transformer so uh we can import the Transformer over here we can write it down Leng ch. Transformer and we can create a complete pipeline as well means we can uh download the model we can download the model in our local okay and in our local memory actually we can do it uh we can download it and then we can do the prediction and all the same thing which I'm doing over here by using the API I will show you the pipeline over here so first of all tell me till here everything is clear think is fine yes you can use the Lama 2 also here you will find out the Llama 2 just try to check with a different different model related to a different different task got it so here you will find out of different different model you can use the Llama 2 here is a llama 2 this one llama 2 B Lama 2 13 billion actually it's from the Billy U but you can check from The Meta also so here I think there was a meta you can search about it so here you can write it down Lama 2 so once you will search it so you will find out the Llama just a second uh you can use llama from the hugging phase I just seen that uh training lamba lamba where is a lamba oh I think I need to check with a different page So Meta Meta Nick snip Q see Stark why I'm not getting it just a second I think I kept this text generation that's why now yeah there there is a llama so here meta Lama so this is the model from the Facebook side from The Meta side and uh you will find out a different different variants of this llama just uh take it and use it and it updated uh 25 days ago this one got it guys yes or no I think you are getting it and you are able to get this particular thing this particular part now let's try to understand that how you can download this model in your local so for that there is a certain step so let me write it down those particular step and step by step we'll try to understand how we can create a pipeline and how we can in download this model in our local is whatever model we want to use it we can download it now for that uh I will have have to perform some sort of a step so here uh let me write it down the heading uh here guys this is the heading uh basically just a second uh let me copy and paste um so here what I'm going to do here I'm going to do a text uh here I'm writing text generation model decoder only model so now I will use the decoder only model any model where I I will just have a decoder so what I'm going to do here so the first thing again I'm going to create a prompt so there's my prompt a same prompt I'm going to use or maybe I written a different prompt over here can you tell me a famous fitw footballer so here I I will give the name so I I can remove this famous from here and see the prompt over here that what is my prompt so here I'm asking that can you tell me uh about a footballer can you tell me about the footballer and here I will just give the name so this is what this is my prompt actually now what I will do guys here I will create a chain now in the chain uh what I'm going to do so just a second fine so here uh let me do one thing for first of all so here I'm going to import some sort of a library otherwise I will get the issues I will get the error so here I'm going to import a few libraries so these are the name so these are the name hugging face pipeline which I'm going to import from the lenen itself actually this is available in a like if you are directly installing the hugging phas hugging face have in your system in your local environment so by using the Transformer also you can import this hugging face hugging face pipeline but as I told you this Len CH is a wrapper on top of this uh apis on top of this libraries so by using this lenon also you can use this hunging face pipeline now what is the meaning of the rapper so uh you know right so tensor flow so this Kass actually it's a repper on top of the tensor flow if you have seen the Kass so there you must have seen that uh like we are just going to call a Kass Dot and pipeline we are just going to write it down Kass ad and we are creating a number of note and then kasas or this that whatever so in back end this T the tens code is running but on top of this T tensor flow they have created one UI or they have created one interface now you are not interacting directly with a lowlevel API low level code you're not going to write it down that instead of that what you are going to do you are using the rapper Kass so it is easy to use for you so similarly see the similar thing you can see over here this Len is nothing it is a wrapper on top of the other apis okay on top of the other packages so over here you can see uh like I need to import this particular thing so the first thing I'm going to import that is a like Pipeline and the second thing which I'm going to import that is a auto tokenizer auto model uh for uh casual LM Pipeline and auto model for sequence to sequence llm I will come to each and every import statement uh once I will write on the code step by step I will try to explain you that why I writing this a particular thing right now here what I'm going to do I'm going to download the model the same model in the local instead of using this API I'm downloading the same model in my local local memory in my current uh memory in my volatile Ram actually so here what I'm going to do first of all I need to mention the model ID now model ID wise you will find out like I'm using a same model FL T5 large and this is a model from the Google side Google has given this model this particular model fly T5 large so this is what this is my model ID from where you will get a model ID you just need to click on the model name and from there itself you can copy this model ID so let's say I want to get a model ID so just copy from here just copy from here copy model name to the clipboard that's it so here's what here I'm having a model ID now guys what you want to do so here actually you need to uh like create a like a the object of this tokenizer and here actually you need to create one uh here you need to here you need to call one method from tokenizer it's a standard processor if you want to use this hugging face pipeline so uh at the first place you will have to perform the tokenization and uh here I'm going to do a same thing so whatever data which I'm going to pass right so this tokenizer will automatically uh take care of it and back end actually some mathematical like like some mathematical equations and all it's going on uh maybe like with respect to the tokenization uh you know like different different tokenization technique what is the meaning of the tokenization so whatever prompt you have that a text prompt actually are going to convert into a numbers so that is nothing that is my uh token means like uh the in a numbers itself so that is what that is your encoded value so by using this Auto encod auto tokenizer you are going to do the same thing you are going to encode the values got it yes or no I think you are getting my point so here uh you are going to use this Auto tokenizer and here I'm going to call this particular method so from uh model ID from pretrain from pretrain and this is what this is my method and here I'm passing this model idid so now what I'm going to do I'm going to keep this particular thing inside the variable the variable name is going to be a tokenizer so here is what here is my variable name so once I will run it now over here you can see we are able to create a object and we are able to call this particular method by passing this model ID now what I will do guys so here uh I will uh I will uh like uh call I will call this particular method let me show you the next one it's a standard procedure don't worry again I will give you the quick revision first of all let me run it the entire thing now over here I'm writing down Auto model for sequence to sequence LM and here I'm I'm calling this method from pretrain and here is what my model ID and here is device map is auto right just just like a like ignore this particular parameter just look into this model ID so here actually I'm passing this model ID Google fly T5 large so this model this is my model actually which I want to which I want to get so here I have a method Auto model here is I'm basically Class Auto model for sequence to sequence LM and from here I'm going to call this from prerain this particular method I'm passing this parameter model ID parameter now if I run it so here you will be able to see that we are able to run it so here we have created a object for this one also now guys the next thing what I have to do so here actually I'm going to create my pipeline so uh here uh I'm going to create my Pipeline and for this one uh I have written a code so this is a code this is what is my pipeline here I already imported it now here I'm going to pass the key text to text generation here is my model this is what this is my model now here is what here is a tokenizer this is a tokenizer and here is a max length so you can remove it you can uh remove the max length also not an issue with that so here uh I'm going to create my pipeline so for first thing what I need to do I need to create a tokenizer and the second thing I need to create a model I need to download the model see uh first time if you will download this model now you will get the uh the progress bar I'm not getting it why why because I I did it actually I was practicing with the thing so at that time I downloaded this I downloaded that particular model and this tokenizer and it is in a buffer itself so it is it is like taking from the caching memory so that's why you are not seeing this that particular progress bar but in your case if you're doing first time you will see the progress bar you will see the prog progress bar okay so here you are going to create a pipeline so this is what this is my Pipeline and here I passed the two thing the first one is a key text to text generation this is my key and here uh is what here I have written the model and here is my tokenizer that's it you just need to focus on this two part now here I'm going to create a pipeline so this is what guys this is my pipeline now after that what I'm going to do I have to pass this particular pipeline to my hugging phase Pipeline and here actually you will find out this is what this is my local llm means see what I'm going to do so this is my model this is my tokenizer which I'm going to download from the pretrain one from the pretrain one and this is the model ID the same uh tokenizer which has been used to this particular model from the pretrain see I'm calling this method so here is my tokenizer and here is my model from this particular ID I'm not getting any progress bar why because I already did it it is taking from a cachia memory okay but if you are doing it first time you will be getting a progress bar and you will be seeing that all the parameters getting installed over here right got it now here what I need to do I need to keep all the thing in a pipeline and then finally I'm passing it to the hugging face Pipeline and this is what this is my local llm now everything is done everything is clear now let me run this prompt so here is what here is my prompt so what I can do let me keep this prompt over here this is my prompt and here this is my prompt and this is what this is my local llm now let me run it and here what I will do guys so now uh let me call the chain and to the chain I'm going to do a same thing what I'm going to do guys tell me to the chain actually see what is a chain I told you chain is nothing it's a it's a like a collection of of the components right you are going to uh you are going to you are you are stacking the components a different different component have you seen the chain right so uh there I was stacking the llm and this prompt so I'm doing the same thing now see the power of the Len chain not even with the open AI we are able to use it with the different different apis with the hugging face also directly and even in the with uh with respect to the local one also with respect to the local LM also so it works with in every scenario this lenion works with every scenario okay now here if I'm going to run it uh so now I I'm able to create this chain now if I will ask anything to this chain so let me write it down over here chain do run now here what I'm going to do here I'm going to pass let's say Messi okay Messi now if I will run it so you will find out that it is generating a answer so Messi is a footballer from Argentina and I just asked what I asked guys so here I asked what was my prompt can you tell me about footballer so here is a name name which I'm passing now let me write it down some any Indian Indian like footballer name so Sunil Chri so let's see uh what will be the answer it is able to get it or not sonil chetri uh okay Sunil chetri born 24th August 1971 it's a former Indian Indian footballer who played up forward so great guys it is able to give me an answer and here you can see I have installed I downloaded the model in a local itself so tell me guys this part is clear to all of you how to use the hugging face API by using the lenen and how to download the model and how to use it please do let me know in the chat if this part is getting clear to of all of you so yes this is the number of tokens max length So within that itself within uh it is not going to exceed the answer and this is the max length basically it will be uh within that itself you will be getting an output tell me guys fast so is it clear to all of you if this part is clear then please do let me know please hit the like button and uh yes if you have any sort of a doubt then you can ask me you can ask about the vat kohi you can check over here so here you can write it down the vat kohi even though he's not a footballer let's see what will be the answer it depends on the model our GPT model is very much uh powerful let's see uh this uh Flame T5 large so okay so I'm getting verat kohi is a s linkan footballer who plays it is completely wrong now you can see so it is uh not giving me a correct answer let's try to design a different prompt over here so here I can uh do that let me this let me design one more prompt and can you tell me about cricketer so here I can write it down cricketer c r i c k uh cricket so this is the spelling now let me take this thing and here is going to be my chain two this is my chain two and this is my prompt two and I'm using a same llm over here so this is my chain two now what I will do here I'm going to run it and let's see will I will I get a correct information or not will this model is capable or not this uh which is a name what is the name flame T5 large so let's see it is a capable or not so chain two. run and uh if I'm running it so in the district of balut prad is giving me a wrong answer I think uh cricketer Koh he does not belong from the bhalpur it belong he belong or not I don't know about it let's uh talk about the suchin uh let's talk about the sain or Ms D so here I can ask about the MS Tony chain. run and let's see who play the Indian Premier League site Mumbai okay it is saying mson plays a cricket from the Indian Premier League from Mumbai Indian so it is like a completely it is giving a wrong answer this flain T5 so you should use a different model in that case actually see GPD is a better one it always gives a correct answer and and is like a much more capable that's why I started from the open a and that's why I didn't started from the hugging page but yeah according to the task according to data according to requirement so now that will be your responsibility as an NLP engineer as a generative engineer you have to check you have to like check with a model that uh like on which data it has been trained okay on which data has been fine tuned how many parameters is there what is a performance performance of that if uh like uh we are doing a text generation that what is a blue score like blue score with that we can identify the uh that like how much it is capable for generating a text so each and everything you will have to read about the model and then only you can use in a production not directly so there will be so many uh like uh uh uh there will be so many experiment which you will have to perform okay there will be so many back and forth you will have to perform before deciding any sort of a model and here I have given you the approach guys here you can append the memory here you can play with the chains here you can uh like play with a different different prom template you can download the document you can import the document each and everything I have shown you inside this two notebook now you are enough capable to implement uh for implementing any sort of a project now whatever project I'm going to teach you definitely you will be able to grab it and uh I will uh after the like jupyter notebook implementation of the project I will uh explain you that how you can convert into an end to endend one so uh from next class onwards we are going to start our Inn project by using this Len chain open ey hugging fish and all and apart from that we are going to use some other thing as well and I will show you the complete setup of the project the project name is going to be McQ generator got it yes or no yes you can fine tune the model as well if you want like if you want to find uh if you want the process of the fine tuning I will give you that also I will give you the fine tuning process also just wait for some time step by step we try to do each and everything if I'm going to explain you everything in a single class so it might be a difficult for you so uh step by step we'll try to do it don't worry we are not going to like conclude or we are not going to step stop this community session uh like uh we'll be continue this uh like in know next week also and there uh we going to talk about many you can use uh like which open stes model you can use for the machine translation you can check over here just go through with the hugging phase API and click on the model model uh just uh click on the model and here you will get the machine translation so maybe machine translation is there classification question answering yeah here is a translation so just see the model what all models is there just try to use this particular model open source model apart from that you'll find out other model as well so see llama 2 is a open source model you will find out a different different variants of this llama you'll find out a different different variants of this llama okay so you can use this llama 2 model for your image translation as I click on this translation here you can see the result got it now you can do your own research you can go through with the different different API as I told you if you don't want to use the chat GPT so here I have created one more API for all of you so like I have written a code regarding one more API that's going to be a AI 21 lab so in the next class I will show you means after the project actually after completing the vector databases and all I will come to some Mis mous topic there I will show you the code regarding this a21 lab okay so here actually uh like we'll talk about the Jurassic model uh which is a very powerful model with that also you can do a multiple thing Falcon is there you can use the Falcon so Falcon you will find out here itself you know uh let me show you where is a falcon so once you will search over here Falcon so it's a model from the Google yeah uh no it's a not of Google one it's a not of Google model actually it's a model from this particular organization I think it's a Chinese organization maybe and one more model let me write it on the name Falcon let me recall the name Falcon was there Bloom is there uh let me check with the bloom yeah Bloom is there and apart from that farm is also there p a LM Palm is also there it is not actually you won't be able to find out this pal over here uh you uh you will have to access it from the separate API so it's a Google model pal p a l m 2 Palm 2 API just search over the Google and you will find out it this Palm API so it's a uh model from the Google research Google researcher it's a model from the Google community so you can explore about the API and you can utilize this all you can see generate your API key just generate a API key and try to use this form model as well and after like so many back in fors after so many research and all then only you can decide that which is which is my best model which one I should which one should I productionize this is working fine or that is working fine but gpd1 is a like trusted one and here you we can you can see the clear application of the GPD model where they are using GPD 3.5 turbo and GPD 4 itself so many people are using the GPI even though it is a paid one but people are checking with the other open source model as well like this Palm Falcon Bloom and all okay Cloud a is one of the model you can check about the cloud as well so I think now uh each and every uh thing is clear to all of you so guys if you're liking the session if you uh like the content then please do let me know in the chat or please hit the like button if you are able to understand everything whatever I have explained you in today's session here I will explain you how to build the applications and all and from next uh class onwards I will give you the different different assignments also yes we can use the mlops tools now like we'll do the development now in between we can use any mlops tools ml flow we can use ml flow DBC or Q flow we can use the uh like other melops tools like Docker and all don't worry regarding that so once I will come to come to the development there I will uh do that okay great now yeah jimin also come you can check with that also recently Google has released the gemin fine so I think uh now we can uh close the session uh now we'll meet on Friday uh Saturday and Sunday we don't have any session uh the session is going to be from Monday to Friday only and the timing is 3 to 5 p.m. IST so let me write it down over here uh Saturday Sunday we don't have any session Saturday and Sunday there won't be any session s session will be continuing continuing uh from Monday onwards Monday onwards and the timing will be timing will be sa so it's going to be from 3 to 5 p.m. ISD so here guys it's a short notice for all of you uh we don't have any session on Saturday and Sunday day the session will be going on uh from Monday to Friday only and the timing will be same 3 to5 istd fine I think uh I have finished the data loader topic uh if you will check into this uh this particular notebook already I have uh uh like shown you this data loader and all now I told you now just try to check with the different different data loaders and all CSV tsv Excel or whatsoever just go and check you can do it by using the documentation but here I given you the example of the to data of this document loader so I have imported this uh PDF I think you missed the previous sess that's why you are asking this question fine so I think uh we can start with the session so welcome back to this community session of generative AI uh this is day six and today we going to start with our first end to end project that's going to be a McQ generator so guys uh this is this is our first uh like end to end project which we are going to implement by using this generative AI uh by using the LMS and all and in this particular project we'll try to use the all the concept basically whatever we have learned so far in our course in our committee session so first of all uh let me show you that uh where you will find out all the session all the uh resources and all because we have updated each and everything over the dashboard and each and everything you will find out uh in the uh resource section so let me show you that uh particular thing and for that guys you just need to visit the Inon website and after visiting the website you need to search about the generative AI so search about the generative Ai and there you will find out two dashboard so first One dashboard for the English and One dashboard for the Hindi so yes I'm taking a same session on my on the I on Hindi YouTube channel as well so you can search ion Tech Hindi so there I'm taking a same session and uh there also I'm uh explaining the concept of the generative a and all so guys here what you need to do here you need to click on this particular dashboard generative AI Community session and once you will click on that so it will ask you for the enrollment and here we are not going to charge you anything any cost so if you are new then please do sign up and then uh try to enroll in this particular course now here guys uh just enroll to this particular course and after that you will be redirected uh redirecting to the dashboard so after sign in you will get a dashboard uh here you can see this is uh this is a complete dashboard uh just a second let me show you that this is the one so this is the this is the dashboard guys and here you will find out all the recording so uh so far I took five session day one day two day three day four day five and in this particular session I covered each and everything regarding the generative AI whatever uh is required if you want to start with the projects and all so uh just go through with the very first session there you will find out complete introduction and in the second one so in the second session uh there I have discussed each and everything about the open Ai and in the third session I have discussed about the Len chin and then I talked about the a few more concept like Len chain memory and all even I have discussed about the hugging face API so if you want to use any open source model if you don't want to use a model from the open AI so uh you can access the model from the hugging phase also that thing also I taught you so if you will go through with my session each and everything you will find out now it's time to implement the project so we'll try to implement a project and and the project is going to be end to endend and not even single so uh not even this project so we are going to implement to more project with a few more advanced concept like vector databases and there will discuss about the r and there we are going to create our web API by using the fast API and flast so each and everything we are going to do here itself in a live session so please make sure that you enroll uh for this particular dashboard and please try to check with the ion YouTube channel as well there we are uploading each and every video so once you will search over the Inon so let me show you that so uh first of all you need to open your uh open your YouTube and there search about the uh Inon so here you can see so open the Inon YouTube channel and inside that uh like uh there you'll find out one live section so just click on this live section and you will find out all the recordings so here you will find out all the recording from day one to day five and uh today I'm uh teaching a project it's a day six and uh if you will open any sort of a video so here in the description also you will find out each and every detail so here you will find out a course detail here you find out each and every detail basically whatever is required so please make sure that uh like you are enrolling to the dashboard for the entire resources and all and yes recorded video is available over the Inon YouTube channel as well got it so I think uh this is fine this is clear now let's start with the project so as you have seen the uh the topic uh so the topic is what topic is the project name is what the project name is a McQ generator using open Ai and langen chain now why I took this a particular project because see uh we have learned each and everything we have learned each and every concept so far related to the open API related to The Lang chain now how we can utilize those information until we are not going to implement the project so in that case we won't be utiliz that particular information whatever we have learned even we won't we won't be able to relate those thing with a real time thing so that's why I kept this project for all of you in between and then we'll try to move into some Advanced concept like databases and all and we'll try to create a few more a few more project in our upcoming session but yeah so here uh we are going to start from the very basic project and then we'll go to the advanced label got it now what all thing I'm going to discuss in today's class in today's session along with the project so here I will teach you the entire setup of the project so here uh we are not going to implement this project in a jupyter notebook so for that we are going to create a complete development environment so I will show you how you can create a like and to and development environment and then we'll try to deploy this project as well so in tomorrow's session I will show you how you can deploy this project along with the cicd concept along with the continuous integration and continuous deployment concept so in today's session we'll try to see that how we can set up our uh development environment and then uh we'll try to uh implement the Jupiter notebook regarding a different different application and then we'll try to convert that jupyter notebook into a endtoend application got it yes or no so the agenda is clear to all of you please uh do let me know in the chat yes or no great so I think uh we can start and uh yeah if you are liking the session then please hit the like button and uh keep watching so guys uh the first of all let me write it down each and everything each and every step uh whatever we are going to do here and whatever uh we'll be doing throughout the session so for that uh I'm using my Blackboard and here itself I'm going to write it down the each and everything so first of of all let me remove it and yes uh I have opened the fresh one now let me write it down each and everything uh regarding today's session so guys see the first uh thing which we're going to do uh that is uh environment setup so at the first place uh we're going to uh set up our uh environment our development environment I will show you the complete a project setup so here let me write it down so setup development environment so the first thing which we're going to do uh we going to set the development environment now after that what I will do after setting the development environment then uh we'll try to uh run a few experiments run few experiments uh few experiment in a Jupiter notebook so we we'll run a few experiment in a Jupiter notebook after that we'll create a end to end will'll create a modular coding like by using this particular experiment and all so I will do a like modular coding I will create a several file and then I will uh try to segregate the code so uh after uh doing a few experiment in a Jupiter notebook I will convert this jupyter notebook into a modular one got it modular coding now after that after uh converting to a model one Modular One definitely uh like uh uh my code will be uh my code will be uh ready and then I will create my web API then I will create my web API by using the stream lid so here by using the stream lid I will be using I will be creating my web API and after uh creating this web API definitely for sure I will test it and finally we'll try to deploy our application on my cloud platform in my AWS or aor got it so these are few step uh these are the these are few things uh uh basically which we're going to perform uh regarding this particular project so today uh I will be uh cover this two point the first one second one and maybe the third one and tomorrow I will create a web API because we have a time restriction the session is just for the 2 hour otherwise I can complete this thing within a uh class itself so today I'm going to complete this two thing and tomorrow uh I will be converting uh the entire code in a modular one and then uh we are going to create a web API and finally we're going to deploy the application got it now after that now after that what uh we are going to learn so after completing this thing we're going to learn about the vector databases we'll try to learn a vector databases we'll try to see that what all options we have if we want to store the embedding not even the vector databases what all other options we have so we'll try to explore about the mongodb cassendra and we'll try to look into the SQL base database also and then finally uh we'll look into the vector databases different different options we have and then uh we'll try to use the RG concept on top of that and we'll create a few more project so yes uh from today's onwards our project journey is going to be start so don't miss it and within 2 week uh our aim to complete at least three and to end project in a live session itself got it so I hope this idea is clear to all of you now uh let's start uh first uh with the project setup so the implement impation the project basically I'm going to implement in a jupyter notebook so entire development setup I'm going to create in my uh sorry I'm going to create in my vs code so for the entire development I'm going to use my VSS code and today I will show you how you can set up your vs code for the end development got it so for that guys uh what you need to do first open your CMD uh uh Implement along with me because uh I will share the GitHub link with all of you so that you can uh write it down the code you can copy each and everything from there itself and along with the uh code I will I will be writing all the commands and uh all whatever I'm going to use in my uh in my project so in my project setup and all so each and everything I will be uh I will be writing in my GitHub U I will be writing in my readme file and then I will give you uh through my GitHub link so guys uh you can follow uh uh each and everything along with me so uh first let me start from the project setup so uh here here guys uh first of all what you need to do so in any directory in C directory in D directory in whatever folder you need to create uh one folder you need to create one fresh folder okay so go in uh go with any directory C drive uh C directory D directory C drive D drive e Drive and inside that you need to create one folder so here you can see this is my location C user sunny and here I'm going to create my folder one fresh folder so for create a folder there's a command like mkdir by using this particular command I can create a folder so here I'm going to write it down mqd and my project name so let's say my project name is what McQ generator so this is the like uh this is the folder name which I have written now uh yes I have created my folder now what I need to do I need to move into my folder now I need to change the directory so here I need to move into my folder I need to change the directory so for that we have a command like CD CD McQ generator this is my folder name now you can see I'm into my folder now I'm inside my folder and from this particular folder I need to launch my vs code so for launching the vs code from the command promp there is a command the command is called code dot code space dot so once you will write it down on this particular command code space dot so in that case you will be able to launch your jupyter notebook in a current for folder right so here is my folder name my folder name is what my folder name is McQ now here you can see I'm able to launch my j i I'm able to launch my vs code inside this particular folder now if you want to verify so for that what you can do you can go with your terminal so just click on the new terminal and here you will find out the same location which you are seeing over the command prompt so guys here you can see you are into the same location which you were seeing over the command prom got it now let's say uh if you don't have this vs code so from there you can install this vs code so for that you just need to go through the Google just search over the Google just search about the google.com and here write it down vs code download so write it down here vs code download so you will get a link for downloading the vs code and here uh this is the link guys I'm giving you this particular link inside the chat and here uh like you can go through with this particular link and you can download the vs code according to your operting system so if you are using Mac uh so you can download from here if you are using the Linux so from uh for the Linux you can download from here if you're using Windows so for the windows you can download from here you will find out all the three option for a different different operating system now uh once you are done uh uh like with the download and all so after that what you need to do so after that you need to install it so just try to do a double click and install this vs code in inside your system and then you can follow the same procedure so you can create a directory you can uh write it down this first and then you can change the directory and from on that particular directory you can launch the vs code got it now if you not able to do it by using this command line so by using uh by using the UI also you can do the same thing so for that uh just uh go inside your directory and here create a new folder so create a new folder and then do the right click and check with the show more option and here you will find out option for launching this vs code so by using this uh GUI also you can do a same thing and by using the command prom also you can do a same thing so I took this command promt approach and here you can see I'm able to launch my VSS code inside this particular folder so if you are done till here so please do let me know in the chat please uh tell me guys if uh you are done till here tell me first have you opened your vs code in a folder if you did it then please write it on the chat yes yeah I'm waiting for 1 minute so until you can open it yeah you can use the pyam also uh not an issue with that py Cham will also work any ID so here I'm using this vs code okay so I think uh now everyone is done so so let's start with a further step so after opening this vs code so F the first thing uh the first thing which you need to do you need to initialize the git so here guys uh what you need to do you need to initialize the git so uh here see we have a uh like a various option here once you will click on this drop down so here you will find out of various option like Power Cell G bash command prom Ubuntu Kali so in your case it there might be only G bash command prompt or Powershell but in my case here you will find here you can see I have a different different terminal right but maybe in your case you just have this git bash and command prom that's that's all fine right so either you can work with this G bash or you can work with the command prom but don't work with this poers shell because otherwise unnecessarily you will get uh uh errors and all so I won't recommend you to uh work with this poers shell and all so if you want to work uh with the like with the terminal so here either use this git bash or this command Pro don't select this Powershell so here I'm using this git bash so here I can easily run my uh like Linux command also so yes uh if you don't want to use this git bash so you can use this command prom also that is also fine now guys here uh you'll find out that okay so this is what this is my G bash now uh here if you are not able to see the base environment so for that what you need to do so just try to click on this View and go with the command pellet so here you need to go uh you need to click on The View and click on the command PL and then select python interpreter so here you will find out various interpreter so you need to select this base interpreter and after that you need to relaunch this git bash so in that case uh if if you are not getting that base environment in your uh G bad so after uh like following this step uh definitely you will be able to see that so here now you can see I have a Bas environment on my good bash now uh let me uh let me run the further thing so the first thing what you need to do over here like so the first thing you need to initialize the git right so inside this directory you need to initialize the git so for initializing the git I just need to write it down a simple command that is what that is git in it so by using this particular command I can initialize the git in my current folder in my local folder so now this local folder will be treated as a local repository and then I can uh I can upload this same folder on my uh GitHub and yes like that's going to be my central representing so GitHub is going to my central repository and as of now if I'm going to initialize the git in my local folder so this is what this is my local repository each and every thing each and every track actually I'm going to keep it keep over here itself in my local folder so that uh like the entire data you will find out inside the dogit folder I will show you that so here you need to write it down this git in it so once you will write down this g in it uh so you will be able to initialize the git inside this particular folder okay now uh here you can create a file so here I'm going to create my readme file so r e a d MD so readme.md so it's going to be a markdown file MD means what it's be it's it's a markdown file so here uh guys you can see I created my markdown file right now uh if I want to publish see as of now see if you will look into this particular folder so let me reveal it inside the file explorer so just try to click uh do the right click on this file and reveal in the file explorer so here you will find out this dogit and here you will find out each and every information so because of this dogit folder actually uh this a local folder is being treated as a local repository now here you will find out each and every metadata so regarding your commits and all so whatever codes you are going to upload whatever like changes you are going to made and all right whatever uh changes you are going to commit and add so each and every metadata you will find out inside this dogit folder and why we use this uh git guys tell me we use this git for the code versioning got it I think uh you have a basic idea about the git so I'm not going into the depth of this git and all as of I'm just like giving you the uh the high level overview that's it now here uh you can see I have create I have initialized the git and here you can see this do git folder inside my uh dogit folder inside my local repository so is it fine to all of you I think yes now what I can do here so here I can publish the branch so I can publish the this local repository to my GitHub so for that what you can do see you can use this uh terminal also and here this vs code has given you the GUI option so just click on that just click on this particular option and here you will find out uh the various thing right so uh here you will find out the various options and all now let me show you step by step so the first thing what you need to do so first you need to add your file so for adding the file you just need to click on this plus icon so uh if you want to add the file uh so for that you need to click on this plus icon and after that uh like you need to uh write it on the message so you write down now that first you run this git in it and then you run this git ad git ad and the file name so I'm doing the same thing over here so by using this plus icon I'm adding this particular file right so uh in my uh like staging area right so and then I will do the commit after writing a message so here I'm writing down writing the message uh this is my first commit so here uh my messages this is my first commit now after writing the message what I will do I will commit it after committing is uh after committing uh it okay so it will ask to me would you like to publish this Branch so I would say yes I would I want to publish this particular Branch so here it is asking to me how you would like to publish it so whether uh as a private repository or as a public repository is going to publish over the GitHub actually so here it is asking to me how You' like to publish it whether as a private repository or as a public repository so as of now I'm going to publish publish this particular Branch as a public repository so you can click on this public repository and yes it will publish a branch so it is uploading all the file here you can see and then it will give you this a particular popup so here it is telling you that please sign in with your browser so once I will uh click on this uh sign in with your browser so yes it is uh doing that and uh just wait it is publishing the branch so it has given me uh this particular page now let let me authorize it so here I need to click on this confirm and after that guys you can can see authentication succeed so now uh my branch is uh published let me show you that so here you can see you can open it and this is guys this is my Branch okay so I published this branch on my GitHub so I hope this thing is uh clear to all of you and you are able to publish your branch yes or no guys tell me are you able to publish your branch um just a second great so now let me give you this particular link and so that whatever code and all I'm going to write it down so directly you can copy and paste from here itself from my git so let me give you this uh particular uh link uh so that you can copy each and everything from here itself just a second so did you get it please uh do let me know in the chat if you got my code tell me guys fast sorry if you got if you got my link then uh please do let me know in the chat again I'm pasting uh this particular link so this is my GitHub link guys yes please do confirm if you got my GitHub I given you the GitHub guys yes or no I am waiting for a reply please check it check with the popup so first you need to sign in through the browser and then only you will be able to log in if you're not able to follow this GUI approach uh in that case uh what you can do so you can uh like uh push it through the command line also yeah if you are not able to log in so through this uh command line you can uh configure the username and the uh like email ID so for that there is a like command so let me show you that particular Command right just a second so what I can do I can show you over here itself uh so you can search over the Google how to configure how to configure get uh username so you can search over the Google and then you will get a command so let me give you those particular command if you are not able to uh sign in but please make sure that if you're getting the popup then then directly you can sign in but if you're getting any sort of error right so for that there is a command so get config hyphen global hyph iph global user.name and here you need to pass your username so like whatever username you have so you just need to pass your username and then you need to pass the you need to configure the email also so okay so here uh for the username and in a similar way you need to configure the uh you need to configure the email so let me give you this uh two command now here let me write it down that you need to write it down your your username your user name and here is a command guys so first try to configure your username and here again I'm giving you the same command along with the username you can configure your email also so let me write it on the email and in the double code actually you need to pass your email so here your email ID so guys uh run this two commands on your uh on your uh command line actually and then you will be able to sign in from here itself got it yes or no till here uh everything is fine everything is clear I given you the GitHub Link in the chat so so um you can click on that and you can uh like you can check with my repository each and everything I'm going to update over there itself so that uh you can copy and paste the code directly from there now guys uh here uh if you're not able to find out uh if you're not able to click on this link so you can search uh with my username also so or over the Google you can write it down s Savita GitHub you will get the GitHub directly it will give you the link link of the GitHub and this repository is a public repository so Direct you can go through with my repository and you will find out this particular project got it great yes uh from the same terminal you need to configure your username and email ID okay now here we have published uh this code as a uh like to my GitHub right this this particular repository this a local repository I publish to my GitHub now I need to follow few more step for setting up my environment so the next thing what I need to do here I need to create my environment because I'm not going to work in my base environment and I'm going to create a virtual environment over here okay so for creating a virtual environment there is very a simple command so let me write it down on that command so cond condu create condu create hyphen P okay hyphen p and here you need to write it on the environment name so here my environment name is going to be en EnV en EnV and then you can write down the python version python is equal to 3.8 so I'm using over here 3.8 and then hyphen y so this is my command uh which I'm going to run and by using this particular command I can create the environment in a current directory itself in a current repository so here you can see this is what this is my environment uh which is being created so just wait for some time it will take uh few second let it create so my environment name is what my environment name is ENB now here my environment is getting created and it is done now after that what I need to do guys so here I need to activate my environment so for activating the environment you need to write it down Source activate if you are using this git terminal so in that case instead of this cond you can write down this Source because sometimes this cond gives issue so I'm not going with this cond here so I'm using this source of over here so you need to write it down the source activate activate and here Dot dot means current directory and from this current directory there is a folder folder name is environment e andv right so here you can see I'm able to activate my environment and here you can see this is what this is my virtual environment got it now let me clear it first of all so here now you can see it is giving me a uh like uh it is giving me a how it is giving me so many files uh for adding right so U like here it is giving me more than 5,000 file but I cannot like add all all the files I cannot like add all the files on my GitHub right so for that what I will do if I want if I don't want to track it if I don't want to track this particular file so I can U mention this name this EnV name in in the file the file name is what the file name is dog ignore so here let me create one more file in this uh particular directory and my file name is what my file name is uh dogit ignore so here I'm writing this uh dot get ignore uh and the touch command is the touch command for creating a file so touch dog ignore now here you can see I'm able to create this particular file this dog ignore now inside this file you can mention the name the name of whatever file which you don't want to drag so here if I don't want to track this EnV folder right if you don't want to track these many file if I don't want to upload it in my cloud repository right or if I don't want to track it uh by using this git so so you can mention it you can mention this folder name inside this dot inside this dog ignore file so here I'm writing EnV uh EnV is nothing it's a folder name now once I return it once I return this uh EnV inside this do G ignore now you can see it is not going to track it at all so here uh it is not going to track uh this particular folder now and it is giving you only it is giving me only one file now yes I can uh add it so here uh first I'm going to add this file get add and this file name now here I'm writing my message so I have added I added my get ignore so this is my message and after that what I will do after after this after this one I'm going to commit it so edit my get ignore and then do the commit now uh you need to click on this sync changes your and your changes will be sync so the same file you will find out the same file you will find out in my G iub also so uh let me show you where you will find out that let me open my GitHub and uh here guys here is my GitHub let me show you the repository here is my all the repository and this is the uh like folder this is my like project actually now see uh I just added this dot get ignore now see see that uh commit just now just now I committed uh this particular file and here you can see my dotg ignore now once you will open it so here you will find out the folder name so the folder name is what EnV so I don't want to track this file throughout my process right so I uh if I don't want to track this file at all so yes uh for that I will mention it inside my dog ignore file got it now uh till here I think everything is fine everything is clear and I hope you are of you are able to follow me till here so please do let me know in the chat guys if uh uh everything is clear everything is fine till here what about 3.9 yes you can use 3.9 3.10 as well but don't use 3.11 3.12 or 3.13 till 3.9 and 10 it's fine but please make sure that uh uh please make sure that you are going to use the same version which I am using uh so you won't face any sort of a issue any you won't get any sort of error uh during the implementation got it yeah so if it is done then uh please do let me know guys please write it on the chat and uh please hit the like button if you are liking the session then done can I get a quick confirmation in the chat great so I think uh now everyone is done so here I have created my environment now guys what you need to do so after that you need to create your requirement. txt so inside the requirement. txt I'm going to mention the entire requirement right so for creating a requir txt so from here also you can create by using this particular icon other you can use the same command same a touch command by using that command also you can create the require. txt in a current folder in a current repository now uh for creating a requir txt so I'm using this particular icon and here I'm writing requirement R Qi r m m n ts. txt now in this a particular file I'm going to mention all the requirement whatever requirement I'm having regarding this project right so I'm mentioning all the requirement inside this require. txt so guys uh let me copy and paste all the requirement or whatever is there all I'm going to write it down here itself so the first thing which I'm going to use uh in my project that's going to be a open a so I'm using the open a API and for that this open a package is required already I shown you how to use openi API how to install this particular package because earlier we also we have created the environment and there also we have installed this open AI if you have attended my previous session then definitely you must be aware about this particular thing now here uh there's a open a now the second thing which I need to uh install in my local environment in my current virtual environment that's going to be a len CH so here guys let me write down the Lang gen so you need to install the langen CH in your current environment first thing is open Ai and the second thing is what the second thing is the Len chain the third one uh which I'm going to write it down over here that's going to be a stream L because here I'm going to create a API by using this stream l so here I'm going to like install the stream lit in my local uh like environment in my current virtual environment the second thing which I'm going to be installed over here uh that's going to be a python hy. ENB so I will tell you what is the use of this particular U like uh uh this particular package python hyon do EnV so I'm going to install this uh python hy. EnV package and I will tell you what is a use of this particular package and apart from that I'm going to use I'm going to download one more package that is going to be a pi PDF so Pi PDF two so these many thing I'm going to be install in my current virtual environment okay and apart from that I'm going to create couple of more folder right couple of more folder I'm going to create in my local repository in my local folder so uh couple of more uh files and folder not only folder files also so here uh uh requ txt is done now I'm going to create one more file the file is going to be setup uh setup uh setup.py file now why we use this setup.py file we use the setup.py file for installing a local package local package in my virtual environment if I want to install the local package in my virtual environment for that we use the setup.py file got it so I created the setup.py file I created the re. txt now let me create a one more file so here I'm going to create so not file actually I'm going to create one folder here my folder name is going to be SRC SRC means what SRC means source code now inside the SRC I'm going to create a one more folder and the folder name is going to be so first of all let me create a file inside this SRC the file file name is going to be dot uh sorry underscore inore dopy so here inside this SRC folder I'm going to create init file okay init file I will tell you why we create this init file inside the a folder what is the requirement of that and uh each and everything I will explain you don't worry so here uh you can see I've created this init file and inside this inside this SRC folder itself I'm going to create one more folder the folder name is going to be McQ itself so m McQ generator and this is what this is my project so McQ generator so this is what guys this McQ generator is nothing it's my folder and inside this also I'm going to create one init file so here let me create the init file inside uh this folder also so init init.py so what I did guys tell me so here if you will look into this uh if you will uh let me reveal it inside the file explorer and let me show you that what I did so here uh just look into the SRC folder so inside this SRC folder I created two things first I created this init file and the second one I created the McQ generator folder and whatever source code whatever source code I'm going to write it down throughout my project so I'm I will be writing down here itself apart from The jupyter Notebook so each and every line of code modular coding I will be doing over here itself inside my McQ generator folder got it now here uh what I did I created this init file underscore uncore inore ncore now what is the requirement of this init file why I did it because see if I let's say uh like here I want to consider this folder this folder as a package as a local package right this folder actually I want to consider as a package now what is the meaning of the package so the package is nothing it's a it's a folder itself folder which is containing a multiple python file and inside the python file you have a code you have a code like a classes functions and all right so you have a folder inside the folder you have a file and inside the file you have written a code right so now guys see uh let's say if you're installing pandas if you're installing numai if you're installing maybe open a or let's say if you're installing langen so what is this tell me it's nothing it's a full it's a package itself it's a package now and package means what package package nothing it's a folder right folder is what F the package is equal to folder right folder itself is called a package now inside the package or inside the folder what you will find out inside that you'll be having a multiple python files right and inside those python file you uh someone has written a code uh in terms of function and classes and that is what uh that only you are going to use right so this uh lenen this open this pandas napai someone already created it and they have uploaded over the pii repository and from there itself you are going to install it inside your project but here this McQ generator actually it is your local package where you are going to create a multiple folder mul multiple python file and uh if you want to treated if you want to treat this folder as a package so for that there's a convention from the python side you will have to mention this init file inside the folder right so here my folder is what my folder name is SRC SRC means what it's a short form of the source code SRC now this SRC actually I want to treat as my local package so there is a convention from the python side you need to mention this init file or you need to create this init file inside this folder then only it will be treated as a local package I think the idea is clear now so by using the setup.py file by using this setup.py file I'm installing this local package in my current virtual environment got it I think now each and everything is clear to all of you now let me back to my code so here is what here is my code so I created couple of a folder couple of file now guys uh let me create one more file uh like one more folder over here and the folder name is going to be experiment so here I'm going to be create one more folder and the folder name is going to be experiment and inside this particular folder I'm going to create my Jupiter notebook I'm going to create my ipb file okay so for creating ipb file inside this particular folder so you can click on this folder and click on this file icon and then you can write down your name so here I can uh write down the name any any name I can write it down here let's say McQ dot ipnb uh do ipnb so what is the meaning of this ipynb so ipynb means nothing uh I python uh notebook okay that's the full form of this IP YB now here you can see this is what this is my jupyter notebook now whatever experiments uh whatever experim experiments will be there throughout this project so I'm going to do my entire experiment over here in my Jupiter notebook and then I will convert into an end code into my end to end pipeline got it now here uh the first thing what you need to do so you need to select the kernel so just click on this select kernel and then click on this python environment then you will get all the python environment so this is your current virtual environment so this this the this interpreter which you can see over here the first place which is a recommended one so this is from your current virtual environment from the EnV itself here you can see EnV python.exe so here I'm going to select the same kernel so here I have selected this particular kernel now you can see uh I'm done with everything now I just need to uh I just need to like uh install the recom txt I will start by writing the code so let me give you this each and every file and folder so for that I just need to add it from here itself so I'm going to add all the files and all over here I think it is done now I will write it on my uh like message so my message is structure updated so here is what here's my message guys now let me commit it so structure s u c Tru structure updated now I have written my message after adding all the file now once I will do the commit and it will ask to my sync it will it will ask to me would you like to sync changes so yes I want to do it now I will click on okay so as soon as I will click on okay you will find out every file and folder in my repository itself so now let me show you uh every file and folder uh so here guys you can see I have a experiment folder now inside that there is my file ipv file that's what this this this file this particular file I'm going to use for my entire experiments and all and here you will find out my SRC folder inside the SRC folder you will find out the init file and one more folder that is what that the McQ generator and then you will find out this setup.py also so here I have the setup.py as of now you won't be able to find out any sort of a code over here but don't worry I will keep it uh inside my setup.py file and here you can see my require. txt so here I have mentioned all the requirements got it now let me uh give you this link to all of you so I'm pasting this link inside the chat and if you're not able to click on that so you can search over the Google let me search in front of you only so just go through the Google and search Sun Savita GitHub so once you will search it uh then automatically you will get a GitHub link just go through with the GitHub link and here click on the repository so here is a repository click on the repository and the Very first project this one McQ generator uh so just click on this uh this particular project and I have kept each and everything over here itself inside one folder so if you are done till here then please do let me know in the chat yes in my previous class I shown you how to use hugging pH API Hub don't worry uh after this project I will use the open source model only I w't going to use any uh like any model from the openi itself but yeah in today's project in the very first project I'm going to use the openi API along with the Len chain got it tell me guys uh is it fine to all of you are you able to create an environment and uh did you publish it have you created a environment did you created a GitHub um and sorry did you initialize the a git basically and did you publish your repository if everything is done then uh please do let me know guys I will uh move with a further step so please uh write on the chat if uh you are done till here then I will proceed uh with the further commands don't worry I will give you all the thing all the commands and all in our documented format so you won't face any such issues at all or in a single uh like go you can run like each and everything don't worry I will give you that first of all tell me uh if you are able to do along with uh if you are able to do till here if you are able to do these many thing then uh please give me a quick confirmation or if you are comfortable till here please do let me know fine so I think uh we can proceed now so uh here I have created uh you can see uh I created uh many files and folder now let me open this setup. py5 okay so here I have opened my setup.py file and here I'm going to write it down uh some sort of a code so what I can do let me copy the code uh there is only just one function and here I pasted the code got it now uh just look into the code so what I have written over here so here I have imported one uh statement uh the statement is what the statement is a find package so from setup tool I'm going to import the find package and here is what here is my setup here's my method setup method now here I have mentioned couple of thing uh so I'm calling this particular method setup a method and uh I have mentioned uh some parameters so the first parameter is a name so here I'm going to write down my here I'm going to write down the name of the package now here is a version version of the package now here is the author author is a sunny sun Savita author email sunny. Savita a and here is install requirement so these are the package which is like required okay now here is a package so find package so once uh see uh this find package actually this this particular method only it is responsible for finding out the local package for from your local directory so wherever uh it is able to find out this dot init file wherever it is able to find out this dot init file it will consider that folder as a package got it now uh here you can see so I have imported this thing find package setup uh find package find package and setup method and I have written all like these many thing over here right so this is the like name of my package uh which I have written over here right each and everything is clear each and everything F now see guys if you want to install this package so for that there's a command the command is PIP install package name right I think you all agree so if you want to install this particular package open a load Lang Chen stream late python python. EnV P PDF so for that there is a command the command is PIP install and package name if you want to install this re. txt so for that there is a command the command name is what the command name is PIP install hyr re. txt right but if you want to install this a local package into your current virtual environment so uh how we can do that so for that also we have a command the command is what the command is directly you can install the setup.py file you can write it down python setup.py install so in that case it will install or it will download all the current package from your folder into the virtual environment got it that's the first way the second way is what so here you can write it down in the requir of txc itself you can write it down hyph e do right so uh if you are writing this hyph e dot so in that case it will search all the local package all the local package into your current directory into your uh current folder and it will download or it will install it inside your virtual environment again I'm repeating see if you want to install this particular package so for that there is a command pip install re. TX Pap install package name if you want to install all the package by using the re. TX XT so there is a command pip install hyphen r. txt got it now but see let's say if you want to install this local package into your virtual environment so how you can do that so for that you have two ways the first one python setup.py install if you running this command so definitely you will be able to install it the second one is what the second one is you can mention this hyphen e dot inside your record. txt so automatically it will search this it will search out the packages into your current folder into your current repository and it will execute the setup.py in backend got it great now what I'm going to do here I'm going to be install this require. txt and so for first of all let me show you that what all packages we have inside the current virtual environment so if I will write it on the PIP list uh so here you will find out that we just have this three packages three to four packages into my current virtual environment how many packages this guys three to four packages only right which comes uh by uh which is a by default only which comes uh along with the environment itself whenever we are going to create an environment now if I want to install all these packages into my current virtual environment so how we can do that so uh if I want to like run this re. txt so how we can do that so for that there is a command let me write down the command pip install hyr requirement. txt so pip install hyphen R re txt so once I will hit enter so here you can see my all the packages is getting installed into my current environment so just wait for some time uh it is getting installed and uh it will take some time uh tell me guys are you doing a with me yes you can use it uh if you want to make a mini project so definitely you can use it and even you can create it uh here itself and you can showcase as a mini project tomorrow we are going to deploy it also after creating a web API and then uh by using the advanced concept we are going to create one more application so how's the session so far uh did you like the session tell me guys uh did you like the session did you like the U like content if you're liking the session then please hit the like button yeah still it is installing so it will take some time I'll let it install yes you can go through with my GitHub link so here is my GitHub link just wait I'm giving you that still it is downloading uh I think we should wait more yeah I think now it is done so uh first of all let me clear the screen and uh here uh you will find out that it has created one folder uh the folder name is what McQ generator. eggy info so so it has created one folder and this folder actually uh it is having the entire information regarding your local package so you can visit and you can check with the different different files over here so this is the package information metadata version this one this is the P package version right this is the package name author is sunny and author email ID reir txt so these are are these all are the requirements actually right along with the packages now you will find out all the like details inside this particular folder the folder name is what McQ generator. ayen info it has created a various file inside that which is keeping all the or which is uh like uh keeping all the like meta information regarding your project got it I hope uh this thing is clear to all of you now uh what I can do uh first of all let me close all the files from here now let me open my app IP VV file and here what I'm going to do here I'm going to here I'm going to like uh run my uh like import statement so what I can do I can run import OS so here I'm going to write import OS import Json import Os Os means what opening system and here I'm writing import Json import Json now here I writing import pandas as PD pandas as PD and here let's say I'm writing import Trace bag so these are a few uh uh like a few packages basically which I imported over here now if I want to run it now if I want to run this particular cell so for that I just need to press shift plus enter right just press shift plus enter and you will be able to run it now as soon as you will run it it will ask you would you like to install the IPI kernel yes I want to install it because without that I won't be able to execute this particular notebook so here you need to click on the install and my IPython kernel ipy kernel is getting installed guys so it will take uh some time so let it install and then I will explain you the further thing further concept I given you the GitHub Link in the chat uh you can search over the GitHub uh sorry you can search over the Google s with the GitHub and then you will get the GitHub link my GitHub link and check with the very first repository very first project that is the McQ generator itself the project name the folder name is same McQ generator here you can see this one McQ generator just search over the Google Sun Savita GitHub so here you can see my ipy kernel is getting installed so let it install and after that I will write it on my further code and uh let I will show you uh further concept as well uh regarding this um and entire project okay yeah so now it is done and here you can see uh we are able to import this a particular statement import Os Os means operating system Json pandas and traceback also now guys here what you need to do the next uh import statement which I'm going to write it down over here which is going to be a opena itself so here I'm going to use the Len chain and by using the Len chain I'm going to import this chat over open API right because I want to access the open API and by using this particular method only I'll be able to access the open a API now let me run it so it's the same method it's the same method which I have shown you in my previous classes so there I was using the lenin. llm opena now in the recent version in the updated version they have given you one more method it's a similar one only it's updated one and which is doing the same thing uh like like the previous one like the open a method and the method name is what the method name is chat open AI so yes uh we are able to import this method and now what I need to do so uh actually we this is a this is not a method this is a class so here what I'm going to do I'm going to create a object of this particular class now so for that let me copy it and let me paste it over here so this is going to my llm so by using this particular uh method itself I will be able to call my open API and I will be able to collect the llm model inside my llm variable right so for that I need to mention couple of uh couple of parameter so here I'm going to mention few parameter let me do it over here so these are the parameter guys which I have mentioned over here so the first parameter is going to be open a API key and here basically I need to mention the key key of the open a open API now after that uh there is a model name so here I'm going to use gpt3 .5 turbo model and then uh I I I have created one more parameter I I'm going to write down one more parameter that is going to be a temperature you know what is the meaning of temperature so here I'm going to set the value 0.5 so between 0 to two you can mention any value of the temperature so what is the meaning of that the meaning is nothing meaning is very very simple you are going to like you want to create a model if you are mentioning uh like if you're mentioning the value near to two right so the range is from 0 to two if you are mentioning the value near to two this will be more creative if the value is will be near to zero so the model will be less creative it will give you the state forward answer that's it now here guys this key will be required this open AI key will be required how we can get the open key I shown you how to generate open key in my previous classes right again I'm not going to show you that now here actually I'm going to collect my openi key but this time I'm not going to paste it directly over here instead of that what I'm going to do I'm going to use my OS module so here what I'm going to write it down I'm going to write it down this a particular uh method I'm going to call this os. get environment method that uh os. get environment key method so here I'm going to call this os. getv and here uh this is what this is my environment variable so what I can do guys I can create uh environment variable I can create one environment variable into my uh Windows environment variable and I can read it I can read my key from there okay I can read my key from there the second way I can export it temporarily right so here I can U on my uh terminal itself I can write it down export and here I can mention this a variable name open API key and I can pass the value in that case also I will be able to read it the third Third Way is there the Third Way is like you can create your EnV file right you can create your local environment file and there inside that particular file whatever a variable is required whatever important variable is there you can keep it over there itself right the first one is a global approach uh Global means what so here if you are going to search environment variable in your windows search box so you will get the uh you will get the uh environment variable all the list of the environment variable here you can see right so you will get the list of the environment variable this one right this one now here you can see I I created one key and I keept it over here so from there also I can read it from there also I can read it by writing a same thing I I just need to mention the key the key name over here the second way the second way is a temporary way temporary way means you can export the key over here Itself by using the export command you just need to write down the export and here you can mention the variable name and you can pass the value of that particular variable that's the second way now the Third Way is what here you can create EnV file so EnV file in your local repository itself so no need to create any sort of a variable in your environment variable here itself inside this EnV file itself you can keep your all the variable all your secret variable and by using the same command you can read it so that is the third way so I'm going to select the third way the third option so here I'm going to create the EnV file okay so EnV file uh so this is what this my EnV file and inside this EnV file I'm going to keep my key so I'm going to write down the key value and the variable name is going to be a same so let me copy the variable from here the variable is going to be open AI API key and let me keep the variable over here and here I I'm going to write down the value of this particular key so in the double code actually I'm going to write down the value so let me paste my key over here I already generated it uh I believe you know how to generate the key so let me copy and paste it over here so this is what guys this is my key which I already generated now let me open my file and here what I'm going to do I'm going to read my value the value of this key so you can treat this EnV file as your local environment right so which you have created inside the folder itself and there you can keep your all the secret variable right so now if I'm going to run this OS os. G EnV now if I will run this particular command now if I'm going to print the key so here you will find out my key value so here guys uh here is what here is my key open a key now let me show you and here it is giving me none uh let me run it again why it is not going to why it is not getting it now let me show you it is none wait guys let me restart the terminal it happens in this vs code actually sometimes I have seen but okay so fine I forgot to do one thing uh why I'm getting this none why I'm getting this none because I need to load this environment first all right so I need to load this environment first and for that uh I will have to import something see I already written one module python. EnV right so here I have written the module python hyen do T EnV let me show you this module so here uh let me open the Pi Pi first of all and here I can show you the module uh just a second Pi Pi now let me show you this particular module python hy. EnV uh see python. uh EnV reads key value pair from a EnV file and can set them as a environment variable right so it helps in a development M or application uh following the 12 Factor principle so here you can read everything about it if your application takes configuration from the environment variable it's a 12 Factor application launching it in a development it's not very practical because you have to set those environment variable yourself means you will have to set the environment variable in your local system um okay if you don't want to do it you can create the EnV folder in your local so that will be your local environment file local environment file itself which will be available inside your local uh like reposit itself in your local folder itself got it now here the first thing uh see first you need to import this thing this from. EnV import load. EnV and then you can you have to call this uh particular method so what I'm going to do here so I'm doing a same thing uh where is my vs code here is my vs code I'm going to do a same thing just a second I'm going to load it uh I'm going to load this uh EnV so here from EnV this is my EnV file from EnV I'm going to import a load. EnV and here is what here is my method so as soon as I will run it so here I will be able to load my all the values from this EnV file now let me run it h let's see whe whether I'm getting the value or not so it is saying this OS is not defined so first of all let me import the OS this is also fine this is also fine and now each and everything is fine now what I can do now I can call it and let's see whether I'm getting my key or not now see guys I'm able to get my key from from my EnV file so here is my EnV file and from here what I'm getting I'm getting my key right now let me keep this EnV in my do getting so I can push my changes in my ga in that case you won't get this uh key actually you you will just get like uh the other file so here I'm writing do EnV and once I return it now it you can see it is not going to track it uh at all so now uh you want you will find out that there is no such color anything and now what I can do I can give you all the files and all other files basically so let me click on the plus yeah now let me commit it so here I'm going to write it down of file updated file update and let me commit it and sync changes now click on okay and here guys you will find out my entire code Let me refresh it now and yes that is the entire code so I think uh you got the code over here set the print yeah so here is a key let me remove it from here just a second yeah now it gone so tell me guys uh are you able to follow till here here uh did you get the entire code the code which I shared with all of you please uh do let me know in the chat if you got the code then here I kept the entire code uh in my GitHub itself yes uh yes or no please uh write it down the chat guys please uh do let me know just search over the Google s Savita GitHub and there you will find out this McQ generator repository in my repository section and here is the entire code if you are done till here then please uh give me a confirmation so I will proceed with a further uh further concept done done done great fine so now let's start with the implementation so till here actually I just shown you the uh I just shown you the environment setup and all now we are ready for implementing the project okay so within uh this uh within this one hour actually I just shown you the entire setup now this is the onetime job I set up my entire environment now let's start with the Practical uh now let's start with the experiments and all and in tomorrow's session I will create uh the I will create the Modular One modular project and there I will create the steam allet application also and finally we'll try to deploy it now here uh you can see uh now each and everything is done let's try to call this a chat open a method and let's see we are able to access the llm on l so here you can see it is running and now it is done so if you will look into this llm llm now here you can see we are able to do it we are able to call it now here let's try to run the further code now we are going to use all the concept the entire concept whatever we have learned throughout the community session right throughout the throughout this community session in our open in the lch so we we are going to use those entire concept over here now uh for that basically what I'm going to do step by step I'm going to write it down each and everything so first of all I am going to import each and everything in a single shot right so here uh you can see I have imported all the statement so this Trace back and all I'm going to remove it from here which I already did it this is also I already imported now let me remove this also and here uh just chat open a also I already imported now uh here this open a prompt template l CH sequential and this get open a call back this is very important uh this is very important class which I imported over here uh I will show you the name I will show you the use of this particular class this C openi call back in a very detailed way because it's going to be very very important right so far I haven't discussed about it I discussed about the sequential chain I discussed about the llm chain I discuss about the promt template but I I haven't discussed about this get openi call back so now let me import import all the statements over here so you can see we are able to import it and yeah it is done now we already created a object of this chat open Ai and we are able to get my llm by using this open AI API till here I think everything is fine everything is clear now let's move to the next one now just tell me guys if we are talking about so here what I can do let me open my pen and let me ask a few questions to all of you so here uh what I'm doing uh just a second yeah so here uh just uh let me ask a few question so let's say we have imported the llm means uh we are able to access my llm this uh GPD model by using this uh open AI or API by using this L chain framework now to this llm what I will do what I will pass to this llm tell me so to llm to this particular llm I will pass my uh prompt right I will I will pass my input prom so here actually what I will have to do I will have to design my input promt right what I will have to do guys tell me I will have to design my input prompt and here as a output what I will get tell me as a output also I will get a prompt right so here what I will have to do I will have to design my input and output prom right so so whatever my whatever will my input so that particular prompt and here whatever will be my output that a particular prompt got it now let's try to design my input prompt and let's try to design the response as well then in which format I will get the response so here initially I clarified this thing the project is going to be a McQ generator right I am going to generate McQ McQ right whatever topic whatever uh subject I will give to my uh GPT model so So based on that particular subject based on that particular uh like based on that particular text is going to generate a McQ so let's say I'm giving my paragraph I'm I'm giving one paragraph to my GPT model So based on that particular paragraph let's say I given a paragraph related to our data science uh okay I I I given one a PDF file or text file or whatever file to my GPT model so in that inside that like you have a paragraphs you have a data So based on that data is going to generate a mcqs right so let me do one thing so here uh first of all let me design my prompt so here what I'm going to do guys I'm going to design my prompt by using this a prompt template I think you already know about the prompt template in my previous class I already clarify the uh the concept of the prompt template if you don't know then please go and check with the previous session so here what I'm going to do guys here I'm going to Define my prompt template so just wait uh let me copy and paste the code because already I written this uh like a single single line so let me copy and paste and I'm going to explain you so here my prompt is what so here my prompt inside the prompt actually you will find out in the prompt template you will find out two things first is a input variable and the second is template right so here you can see as a template I given this particular variable now to this particular variable I have to pass some sort of a text right some sort of a like a template and all I will pass it just wait right so here is my template variable and I will pass my template over here here I'm not going to write it down directly here I'm going to pass it to my variable and that variable I I'm passing inside my prompt template right now in an input variable you can see we have a couple of we have a couple of variable we have couple of parameter the first one is text the second one is a number the third one is a subject the fourth one is a tone and the fifth one is a response J so we have a five variable inside my input variable in my previous classes uh I shown you this prompt template along with the uh simple input variable along with the one input variable right now here inside this one I have written five input variable and here I'm going to Define my template now let's see what will be my template so from here basically I'm going to copy the template and let me paste it over here so I'm saying to my chat GPT so I'm saying to my chat GPT that uh you are expert McQ maker right so I'm giving my a text so on whatever text I want to generate an McQ I'm passing a text over here right and I'm saying to my chat GPT that you are an expert McQ maker given the abob text so whatever text we have given to you it's your job by using this particular text it's your job to create a quiz of number so how many quiz you want to create so five quiz six quiz seven quiz eight quiz you can pass a number over here so 5 six seven quiz eight quiz so you can pass the number and here uh you need to create a five multiple let's say I'm writing number is equal to five so five multiple choice question for the subject now whatever subject we are going to pass over here in tone so tone means what tone actually it is defining a difficulty level so here if tone is simple so it is going to generate a five simple McQ question if tone is uh intermediate so it is going to generate five intermediate question if tone is difficult it's going to generate five difficult in five difficult McQ question got it now here I'm saying make sure the question are not repeated and check all the question to be confirming the text as well so each and everything I'm telling to my GPD right so make sure to format your response like so here actually I have to for I have to pass the format also here I'm going to pass here I have to pass the format also like in which format you have to generate a quiz now let me give you the format now let me show you the format so uh which format actually I have designed over here so here what I'm going to do I'm giving you the format the format basically which uh I have designed so let me show you the response format now guys this is the response format just just see over here see so response or it's my response format so here I'm saying uh like there is my McQ multiple here I have written first okay this my first mean like it's a number itself that's it now here I'm seeing McQ multiple choice question now here is a option that uh you have a four Option 1 2 3 4 and here basically I will be getting my correct answer so it is this one this one actually this is my first McQ along with the number along with a question along with the number this is my first McQ first McQ now here will be my McQ now here will be my all the options and here will be my correct answer right so this is my response format and here is my template basically which I'm passing to my GPT model and here uh I'm going to create my prompt template that's it by using this particular template and these are the these are the variable which user is going to pass right which user is going to pass these are the variable now let me do one thing let me run it and here you can see we are able to create a like temp we have like written a template and this is what this is my prompt template which I created that's it I think this is fine now here uh yes once it is done uh like uh my template and all basically it will be created that is fine now after that what I'm going to do I'm going to create the chain right I think you already know about the chain llm chain I I explain you the concept of the llm chain that why we use llm chain we use llm chain for connecting a several component so here as of now I just have two component first is llm and the second is prompt so I'm going to connect both component all together and for that I'm going to use llm chain so let's try to use the llm chain and and here I have already written the code let me copy and paste it over here and so this is what guys this is my uh like this is my uh like llm chain so here I'm passing my llm model with whatever model I took by using the open API and here is what here is my prompt so prompt is what so quiz generation prompt so the prompt which I have created by using this particular template and by using this particular response right in this format basically I want a response now this is what guys this is the llm chain all the concept see whatever I have we have learned so far I'm going to use all those concept for creating this a particular project right so so at least you can understand that where we are using uh like those Concept in a real time right so here is what here is my question now let me run it and here I have created my question that is fine now guys just tell me uh here uh I'm creating my quiz right so here I'm creating my quiz now here actually see I created a quiz but this quiz is correct or not the basically in the at the end you can see in the format I have written this correct answer I want a correct answer from it so after analyzing a quiz actually I want a correct answer so for that also I have defined one more template now let me show you that template so what I did actually let me show you the template two which I have created uh so here I have created the second template now in the second template you will find out uh just a second let me copy all the like thing over here and see this is what guys this is my second template now here I'm seeing here I'm saying actually uh you are an expert English grammarian and writer I'm telling to my chat jpd I'm telling mypd actually so given a multiple choice quiz for this particular subject right this particular subject now you need to evaluate the complexity of the question and give a complexity analysis of the quiz right give that complexity analysis of the quiz only use at Max 50 words for complexity if the quiz is not at for the quantitive and the analytic ability of the student update the quiz update the quiz question which needs to be changed and change the tone such as uh such that it perfectly fits to the student ability so here I have written so here actually see here I'm passing my quiz whatever quiz basically I'm generating so in this second template I have written that uh I have written the like prompt regarding to the evaluation regarding to the quiz evaluation whatever quiz I am going to generate right first I will generate and then I will evaluate it here in the second prompt now let me run it and here I'm going to create my one more chain so here I'm going to create uh so here basically uh before create cre a chain basically uh let me create just a second so here uh what I'm going to do I'm going to create my template so here in the template you will find out only two variable first is subject and the second is quiz this two variable it is coming from the user side I will show you how like it is coming from the user side and how user will be passing once we'll be creating a end to end application got it now here we have a quiz evaluation prompt and this is what this is my second prompt and now what I will do regarding this prompt also I will create my chain right so here uh here is my quiz chain now I'm going to create one more chain that's going to be a quiz evaluation chain so let me uh like uh copy this particular code step by step I have written each and everything and that is what I'm going to show you so here is what guys here is my review chain right so in this one I'm passing my llm I'm passing my quiz Evolution prompt and here output key is What so whatever output I'm getting as a review so here I'm going to collect it inside this particular variable and verbos is equal to True means what means whatever ex means during the execution whatever is happening now each and everything I will be able to find out on my screen itself that's the meaning of verbos is equal to two that's it now here if I'm running this review a chain so I have created two chain now now after creating this th I have created First Chain quiz chain I created second chain review chain now I'm going to connect both chain right by using sequential chain so the same concept I taught you in my previous session so first I created one chain where I'm going to add two component llm and my uh prompt I have created second chain and now I'm going to collect both chain right both Chain by using the sequential uh by using the simple sequential chain now here what I'm going to do so here already I have imported this thing if you look into my import statement so I have already imported this sequential chain now let me create a object object of this sequential chain and then uh I'm going to write it down the both name over here so here what I'm going to do so let me uh create object of this sequential chain now so here guys you can see we have a sequential chain and to this sequential chain I'm passing the quiz chain I'm generating a quiz and I'm passing to my review chain right so from here I'm generating a quiz and I'm passing to my review chain and these all are my input variable and these all are my output variable and verbos is equal to True right clear so here I'm going to create a object of this same sequential chain I hope till here everything is fine everything is clear to all of you please do let me know I use the uh previous Concepts only I haven't I haven't taught you anything new uh I use the previous concept whatever I taught you in my previous classes so please do let me know if this uh part is clear to all of you yes or no it's very easy very simple don't worry at the end I will revise all the concepts uh whatever I'm using here whatever I'm writing over here but first tell me is it clear or not this one if you can write it down the chat I think that would be great you can hit the like button you can let me know in the chat so please do it guys uh I'm waiting for a reply because after uh this one the climax will come and in that like we are going to create a quizz and all whatever is there clear clear clear yes or no yes saan your understanding is correct first combining two template using llm chain and then two H chains we are going to combine by using the sequential chain okay okay now uh I think till here everything is fine everything is clear now let's see how we are going to gener a quiz from here after giving this many of things after doing this many of things so we are able to uh we are able to like uh here you can see we are able to create a sequential chain now the next thing is what here actually what I want guys tell me I want a text I want a data so if you have a data in PDF you can load the PDF if you have a data in txt file you can load the txt file right if you have data in some other file you can load the data from there from anywhere right so first you will have to provide a text you will have to provide a data on top of that data you are going to create or you are going to generate a quiz right so let me do one thing here I'm going to create uh I'm going to create one file the file name is going to be uh wait I'm going to create one file the file name is going to be data.txt so data.txt now what I'm going to do here uh I'm going to open my Google and from there uh I'm going to copy and paste some sort of a text so let's say I'm searching about the machine learning machine learning machine learning so here I'm going to search about the machine learning now here uh is what here is my machine learning now from here what I'm going to do so here I'm going to take all the data for this one right so I took this particular data I'm copy I'm going to copy it and let me paste it over here where I'm going to paste I'm going to paste in my data.txt so this is the complete data which I have pasted over here you can check it you can reveal this file in your folder so click on reveal in file explorer you will find out this particular file uh this data.txt right just open it and here is your data which I copy and paste it from the uh like Google itself from the Wikipedia right great now let me close it and here here is what here is your data now do one thing let's uh do one thing so let's try to read this particular data so here what I'm going to do so here uh let me open my file ipynb file and here I'm going to read this particular data so for reading a data actually we have a we have a like a code so let me write it down the code over here so I'm writing over here you need to open this file in a read mode and just read the data in this particular variable now here I need to provide the file path so for providing a file path let me write it down here file underscore path and here uh R means what R means read it and there I'm giving my absolute path so here I'm passing the complete path of the file so this is the file path guys which I have given or which I have written over here now let me run it and let me check with the file path that I got it or not so here what I can do I can uh check with the file underscore path now let me run it and see guys this is what this is my file path now I'm uh running this particular code and here you will find out inside the text what I got I got my data so here is what here inside my text you will find out you uh we have the entire data now let me print it let me keep this text variable inside the print method so see guys I got the entire data so whatever data I kept it inside my file inside my txt file so you can see all the data over here itself got it now after that what I will do see now there is a crucial part and there you will find out the new thing right and one more thing let me do one more thing over here so see I created a response I created a response here is what guys tell me here is my response now this response actually it's a dictionary this is what this is a dictionary right this one now over here if I want to convert into a Json serializer so for that there is a method json. terms and here actually I'm passing this dictionary now why I'm doing it so here if I want to serialize the python dictionary into a Json format so here U into a Json format is string so that's for that's why for that only I'm going to call this particular method json. dumps right so here uh I'm going to call this json. Dums and here you will be able to find out I'm going to convert this a particular dictionary this python dictionary into Json format his string right this is fine this is clear to all of you we got a text we got this dictionary and we got a chain now my final step will come into the picture now let me show you my final step so over here uh my final step is this one now just just be careful guys and after that my response will be coming and I will be able to generate my output so here guys see uh in the final response you will find out that we are going to call this get open Ai call back right right this is a new thing for all of you and here I have already imported this get open Ai call back if you will look into the import statement here a from blanchin do callback get open call back so here you will find out I'm U like calling a same thing I'm calling this get open Ai call back right now inside this get open a call back you will find out that we are going to call our generative evaluated generate generate evaluate change so this is the same thing basically uh the same variable over here you can see this one uh like after creating after creating this is the object actually generate uh generate evaluate chain this is what tell me this is the object object basically which I'm keeping over here sequential chain is a class right where I'm passing this particular argument and this is what this is my object this one generate evaluate chain now I'm calling this particular object over here this one right this this particular object I'm calling over here this is fine this is fine this you are able to understand and here we are getting a response after calling but what is the meaning of this C open Ai call back why we are using it so just see over here I have written something over here how to set up token uses tracking in L chain so if you want to understand the token uses if you want to track your tokens and all input token output token your pricing each and everything each and everything you will get by using this get openi call bag you can check it by using this link which I kept it over here here is a documentation link so let me copy and paste it over here over the browser and here actually you will find out a complete detail about this G openi call back so let me show you so here is tracking token uses so whatever number of uh token you are going to use what will be the pricing input token number output token number everything you will get it over here by using this get openi call back right so just see over here we are going to import it we are going to create our llm we are going to got get we are going to get our llm over here and here we are going to call this invoke method and there is my result now if I'm going to print the CV so here you will get the entire detail regarding the token let me show you in terms of my code right so whatever code and all whatever like project I'm going to create regarding that now before that just see over here uh generate evaluate chain this is what this is my object now here if you will look into this particular object so we are we have a couple of input variable the first input variable is text that is the same thing the text itself right text you know right which one uh what is the text like whatever uh which one this text actually so whatever uh like uh data right we are passing for generating a McQ right on whatever data we want to generate McQ this this this takes actually now here is a number how many McQ you want to generate subject tone simple Simplicity hard intermediate and here is what here is a uh like request response so I will have to mention everything over here inside this variable so json. dumps already we did it text we already did it now let me Define this number subject and tone so here let me take it as a a variable so here guys you will see that we have a number we have a subject and we have a tone so number how many uh quiz you want to generate I want to generate five quiz here subject let's say subject is machine learning let me change the subject I'm going to keep as a machine learning so here the subject name is machine learning now uh here Stone actually tone let's say it's a simple one simple McQ I want just like a simple McQ now if I will uh like run it so here I have initialized my variable now guys if I will run this one now you will find out that everything I'm going to get in my response itself so let me run it and see so it is running and guys over here you can see this is still it is running and it will take some time because it is evaluating each and everything in back end whatever template whatever prompts I have given and based on that it will generate a response it will generate a McQ so just wait for some time and it is working working working yeah now it is done guys see we we got a response and inside this response I have everything but before showing you the response let me show you something over here so here what I'm going to do here I'm going to show you the number of tokens number of tokens uh input tokens output tokens and the complete cost right so here what I'm going to do let me copy the code uh which I already written and it's a simple like lines and all I'm just copying pasting because I don't want to waste the time okay because if I'm writing it from scratch it it takes takes a time right so here uh I'm saying total number of tokens input token plus output token now here prompt token and prompt completion mean this is the input token and this is the output token and this is complete number of token and here there is a total cost now if I will run it guys so here you will find out that I this is my total number of token this is my input token this is my output token and this is the cost and it is in dollar so I'm able to track each and everything by using this uh open a call back getting my point now let's try to get a response so let's try to uh get a response from here uh so let's try to uh get a quizzes and all so first of all let me show you the response so if I'm going to print the response now so you will find out uh it's nothing it's the uh dictionary itself right so inside the dictionary uh you have uh different different key and value now in this dictionary you will find out one key quiz right so if I'm going to write it down here so here if I'm going to write it down response. response. getet quiz so if I'm going to write down here response. getet quiz now see guys here I'm able to get my quiz here I'm able to get my quiz right so what I'm going to do now I'm going to keep it inside my variable my variable is what quiz this is what this is my quiz right now what I'm going to do here I'm going to write it down Json json. load right Json do loads and here I'm passing my quiz q i now once I will write down like this so you will find out my all the quiz so here this is my first quiz and it is in the same format it is in the same format the response format which I have defined so this is my first quiz and here is McQ who coined the term machine learning so Donald have Arthur Samuel Samuel Walter pittz and Warren mlo right so here there is a correct answer now here the second quiz what was the earliest machine learning model introduced by the Arthur Samuel so speech recognization image classification so you can see guys your entire quiz over here whatever number I have given I have given five number I'm able to generate a five quiz from the uh from the GPT model by giving a correct prompt and by giving a correct uh like response format so there is uh you just uh required a python over here that's it nothing apart from that and you will be able to create the project a project according to your requirement and this type of project you can integrate everywhere let's say uh uh like in a dashboard itself in your dashboard you will find out the quizzes and the assignment so you can automate that project uh that process you can generate a quizzes and all from here uh right and then you can append it inside uh the dashboard and all so uh like something like that you can make a realtime connectivity I think you are getting my point now let's uh look into the uh let let's try to create a data frame by using this uh dictionary so for that what I'm going to do so here uh I'm going to create a data frame uh just a second uh first of all let me keep everything inside the list so for that I already written one code so here is the code guys uh here I'm going to create uh let me do one thing Let Me Keep It Quiz only so here is what here is my list and inside this list we have our items means uh my quiz and my uh basically value okay means my options now here actually I'm going to keep it in a particular format whatever string I'm going to to be collect from here I'm going to join in by using this pipe and here I'm going to append it everything now let me run it and you will get a better understanding so if I'm going to run it now see uh so it is giving me St Str object has no uh attribute items what is the issue over here okay so just wait uh let me keep it over here inside the quiz itself and now I think it is fine so just a second mm mhm yeah now is fine so if I'm going to show you this quiz table data now now you will get all the thing over here so yeah now I got each and everything in a list and see every value every option we are going to segregate by using this pipe and for that only I have written this code once you will go through it you will be getting it now I can convert it into a data frame so here uh let me convert this uh thing this particular thing in into a data frame so here if I'm going to write it down PD do data Frame data frame and here I'm going to say that okay I'm going to uh open the parenthesis and then yeah so here guys see this is my McQ means there is my question here is my choices there is four choices and here is a correct answer now let me keep this thing in my uh variable that is going to be a quiz and and now let me convert this uh data frame as a CSV file so here I'm going to convert this data this uh quiz actually into a CSV file so quiz do 2or CSV and here I can write it down the name and the name is going to be a machine learning quiz so machine uh machine learning. CSV right machine learning. CSV index is equal to false index is equal to false now if I will run it guys see in my current uh directory in my uh like current local directory you will find out this CSV file now let me open the CSV file and here you can see my quiz I just given the number of quiz how many number of quiz I want uh see uh if you will look into the code now now you will be getting that uh this this number actually this this thing basically which I will I was providing to my um like object this one number of quiz sub object and toone so this is the only thing which I want from my user and for this one only I'm going to create my web application as of now I shown you the simple implementation in the python notebook in ipb itself now in tomorrow's class what I'm going to do so here I have created the folder the folder name is what SRC folder and inside that I have a McQ generator now each and every line of code I'm going to write it down my py file I'm going to create a modular coding I I'm going to write down the modular coding here and then finally we are going to create a web API right web API and uh here U like yes by using the B API you just need to pass this particular value number of quiz you just need to pass this 3 to four value you need to pass the text this particular text you need to pass the number of quizzes subject and the tone that's it and you uh and after that once you will hit the button so the qu will be in your hand this one got it yes or no tell me guys so how is a project uh did you like this tell me do you like this Jupiter implementation yes or no tell me guys fast do you have any any like uh any um that doubts and all so please do let me know I will be clarify that and uh don't worry you won't face any sort of issue so whatever step I followed just followed those step and try to do this uh um this notebook implementation at least and tomorrow we'll convert this notebook implementation into an end to end project so let me give you this code now so here I can uh add it this file this file and this file also so I added this three file now let me write down the message all files updated updated okay so just a second all file updated and here let me commit it and sync the changes so now guys just check with the GitHub you will get the uh files and all right let me show you the GitHub now and here is my GitHub so guys uh just check with the G here you will find out the CSV file quizzes and all uh and here see quizzes Which I generated by using the GPT and here actually there is a ipv file where you'll find out the entire code okay yes it is generating a quiz from the text itself so let's say if you are giving this part let's say any different text so let me do one thing let me give the different text over here uh so just a second I'm going to generate a different text now uh so any topic uh uh any topic basically anything you can uh like search over here let's say you are going to search about the biology so biology uh Wikipedia so just search about the biology and here open the like Wikipedia page copy it from here copy it as of now and just keep it over here inside the text inside your txt file now see we'll automate this particular process so you don't need to paste it like this you just need to uh give your documentation to your streamlet application or to your flask application or Jango application we'll automate that particular process don't worry and even we can automate like many uh instead of providing this particular text and all right no need to provide this text by writing directly by writing the name also we can generate a quiz okay that is all also possible that is also possible as of now I'm giving my text and based on that see this is the biology text right now what I can do I can just need to open my uh IP VB here and after that I just need to load this text so here I'm going to load my text this one and I'm going to change my subject so instead of this machine learning I'm writing here biology right I have written biology over here let me run it so here I got uh the biology text this is the biology text and uh yes uh I think now everything is same this is fine this is fine now let me run it so here if I'm going to run it so now it is generating mcqs from those particular text whatever text I have given regarding the biology and all so it is taking that text and it is generating a uh mcqs and all so it will take some time let it run and then you can save uh this file over here so now it is done uh it is getting we are getting some issues incorrect API key provided okay it is saying incorrect API key provided I think some issues there with the API key but yeah the process will be same right I will check with the API key issues what is this uh now see guys uh I think you got my point you got the like concept and you got about the project also and today we are going to create in2 and one and we'll try to deploy it also so don't miss tomorrow's session tomorrow's class uh great so I think we can start with today's session uh now in today's session uh again uh we'll uh try to complete our project itself so in previous class uh we have started our uh end to end project uh in that I have explain you the uh Jupiter implementation so we did the entire project setup and after that uh we did the we implemented our jupyter notebook now in today's session we are going to create we are going to write it on the modular coding modular code and there we are going to create a several file and uh I will show you how you can create a different different file in a different different folder and then how you can create your streamlit application and if uh time will permit so definitely we'll try to deploy it also and for the deployment we're going to use AWS okay so uh don't worry I will write it down like uh each and every line in front of you only and uh and I will clarify the agenda but before that uh let me show you the resources and all so where you will find where you can find it out all the resources so for that uh let me go through with the Inon website and here you can search generative AI so just search about this generative Ai and there you will get the dashboard so here we have two dashboard one for the Hindi and the second for the English so just click on this English uh this uh this particular dashboard and here click on this go to the course so uh let's say if you are enrolling for first time if you are opening first time then it will ask you for the enroll uh for the enrollment and uh you no need to pay anything it's completely free so you can enroll to this particular dashboard and you can open it so let me open the dashboard so here is my dashboard guys uh you can see all the recording we have updated all the recording whatever thing I have covered so let me uh show you the resources as well I think day six recording is not available over here so don't worry it will be up uploaded along with the recording you will uh find out the assignment and the quizzes also and where you will find out the resources so let's check with the day five so uh here in this uh video right so once uh you will click on the video uh so here you will get a different different option related to the video so just click on this resource section and here you will find out all the resources so whatever thing I'm discussing in the class itself uh whatever uh like code and all whatever I'm writing here so uh I'm going to uh I'm going to upload each and everything here inside this resource section so from here itself from the resource section you can download it got it yes or no great so from here you will get the resources and all and yes U videos is available over here recorded videos is available over here and apart from that you will find out over the ion YouTube channel so just go through with the Inon YouTube channel U and there uh go inside the live section there you will find out all the recorded video so let me show you that so visit the Inon uh YouTube channel and here click on the live section this one so you will find out all the videos all the like lecture or the live lecture which I uh took so far and here is a day six lecture where I have started with a project so in this lecture till day five actually I have complet completed the Lin first I started from the introduction then I went to the open a and then I uh started with the different different concept of the Lang and then I move to this uh particular project the project uh which I have started that was the McQ generator by using open a and the Len chain so here uh you can see I have uh I shown you that how to do a complete project setup and even I shown you how you can push it over the GitHub and all how you can insize the gate each and everything I shown you over here and then uh I shown you the uh Jupiter notebook implementation so just go through with this particular video there you will find out uh like each and everything uh now uh what we can do we can start with the remaining part of the project so here in this uh particular project so we have created a several folder now in front of you only I'm going to create few more file and there I will be writing my code and finally we'll try to create a web application and if time will permit so definitely we are going to deploy it also so the agenda is clear to all of you yes or no please uh do let me know in the chat please do confirm in the chat yes how long this course is going to be so the course uh I I have planned two more end to project so I have to take few Advanced concept like uh Vector database R and few open source model and after that I have planned two more end to end project so you can assume that uh like more 8 to 10 days got it so um I I will take two more end to end project and this is just a basic project actually after completing all the concepts and all I taught you this one but yeah after that I will complete one project along with the flask API and I thought one more project along with the vector database R concept and the fast API okay great so let's uh begin with the project and here uh what I can do so just a second just allow me a minute okay so I already given you this particular project and if you want this project uh this project actually so from where you can get it uh let me show you so this uh project already I have uploaded on my GitHub so just uh try to go through with my GitHub and there you will find out this particular project and for that what you need to do just open your Google and search Sunny Savita GitHub okay so open your Google and search Sunny Savita GitHub and after that you will find out my GitHub so just click on that uh click on my GitHub and here go inside the repository here inside the reposit and click on this very first link this McQ generator so just open this one and here you will find out this particular project so whatever I'm uh doing whatever I'm uh whatever code and all I'm writing I'm pushing in my this repository so I'm giving you this repository in the chat section if you are able to click click on it so that is fine otherwise you can search over the Google and directly you will find out this repository in my uh repository section got it so from from here itself you can download the project so you can download it or you can clone it anything is fine now uh let's start with the remaining part of the project now here guys see I created a couple of uh folder I have created couple of like files but let's try to uh uh do something more over here so as I told you this uh project is going to be end to end so here actually see I created the ipv file so each and every experiment I performed over here so I I return like some sort of a line of code here and then uh I called my openi API and then I generated the mcqs and all here I have stored inside my CSV each and everything I did in my previous class now if I want to convert this project if I want to uh like uh convert this project into an end to end project so for that uh I will have to create few more file over here so here guys if you will look into this SRC folder so here I have created one folder that is what that is an McQ generator now inside this McQ generator I'm going to create few more file so you can do along with me if you have completed till here so uh here actually you can see uh like uh whatever thing I have done in my previous session so you can find out each and everything over here if you have completed till here then you can proceed along with me now what I can do so here uh let me create a few file inside this McQ folder inside this McQ generator the first file which I'm going to create over here that's going to be a logger file so here let me create the logger file logger py because each and everything uh let's say whatever code I'm running and uh whatever thing I'm going to execute inside my project so I'm going to log each and everything so for that this logger file is very much important so here I'm going to Define my logging object and directly I will import this logging object in any other file and then directly I'm going to uh like save the logs and all so I will show you how to do that first of all let's try to create the folders so here uh let's try to create the files and all so here I have created my logger file logger dopy inside this McQ generator folder now after that you need to create one more file over here the file is going to be a utils file so here uh let me write it down the utils.py now what is this util file why we should use this utils file actually this utils file is a helper file so whatever helper function is there whatever helper function and method is there so each and everything I'm going to write it down over here itself got it so what what is the use of this utils file so it's a utility file it's a helper file so what is a what whatever helping function and all whatever I have inside my code so each and everything I'm going to write it down over here itself now uh one more file I'm going to create inside this folder inside this McQ generator and the file is going to be McQ generator itself so inside this particular file I'm going to write it down my entire code got it now here I'm going to create one file the file name is going to be a McQ generator so here is the file name McQ generator. py so I have created three file inside my McQ folder inside my McQ generator folder so the first file logger file the second file is a utils file and the third file McQ generator. py5 fine so I hope till here everything is fine everything is clear now let me create few more file now in the root directory itself I'm going to create one more file that's going to be a response response. Json I will tell you what is the use of this response. Json because yesterday uh in the previous class uh if you will uh let me show you this ipb itself so here I have written one response here you can see we have uh I have written this response G and inside this response G I have Define uh the response basically in which format uh like uh the response should be generated so here I have defined the response Json now uh the same thing I'm going to Define inside the Json file and I will tell you what is the importance of that so if I want to create a Json file so for that uh what I need to do I no need to do anything so here uh click on this new file and after that uh write it down here response uh response do Json response. Json now here you can see this is what this is my Json file so uh till now I have created four file the first file was the logger McQ generator utils.py and apart from that one more file that's going to be a response. Json and this file will be in a uh will be in a root directory this one response. Json I think till now everything is fine okay where I have created it uh let me check once I think I have created inside this experiment no need to worry just uh drag and drop here yeah so now I got it in my root directory yeah so here is what here is my response dojon now let me create one more file over here and the file is going to be a streamlit app so actually I'm going to create my web app by using the stream l so here I'm going to uh create one more file and the file is going to be a stream L and that two you need to create in a root directed itself in a root folder itself so here I'm going to write down stream s e a m stream lit uh app.py so this is what this is my file now let me keep this L as a small one yeah now it is fine so streamlit do streamlit app.py so these many file I have created and now I think it is like enough now what I can do I can give you like this complete folder structure so for that U like I can commit from here itself uh so let me add all the files from here I'm going to add all the changes whatever I have done done inside my code and I told you how to do that uh in the previous class I explain you each and everything regarding the git and all so if you will go through with my previous uh session so you will get to know the uh like you will get uh you will get the idea that how to like uh how to uh create a repository and all how to publish from here itself how to publish a public repository each and everything I have discussed in my previous session now uh here you can see I have added all the changes now I just need to commit it in my staging area and then I will push it in my GitHub so here I can write down that uh I updated updated the folder updated the folder structure so now what I can do I can commit it and here I can sync the changes and then okay yeah so now let me show you did I get all the files and all here so here guys you can see I got all the files like streamlit app streamlit app.py and here in the SRC you will find out this uh in the McQ generator you'll find out this McQ generator. py logger py utils.py so each and everything uh you can uh you can see over here inside my repository itself so I hope guys you got this entire code yes or no this entire file now again let me give you inside the chat uh or else what you can do you can search over the Google as well so directly you will get it tell me guys uh till here everything is fine uh can we start with the code and all please uh do let me know in the chat I given you this uh link inside the chat I hope uh you are able to click it otherwise directly check with the Google you will get this project Raab please check with my GitHub repository check with a just search about my username this s Savita Sun Savita GitHub and then you will get my GitHub and then from U from there itself you can download this particular code front end and all we are going to handle by using this stream lead so stream will handle everything we don't no need to like create a front end separately uh in the next project I will show you that once I will use the flask maybe with the fast API I will show you the uh front end part as well but here uh if I'm using this stream L then front end is not required yeah you can use any ID even you can use the U Inon lab also so from next project onwards we are going to use the in neural lab yesterday actually I did the entire setup in my uh local vs code only so that's why I'm continuing from here itself but uh from next project onwards I'm going to use the neurol lab so U I think uh no need to set up in your local uh directly you can launch the lab and whatever experiments and all or whatever project uh like you have uh you can create over there itself okay if you're getting any error relative to the API key then try to generate a new API key and don't use my API key okay because after the class anyhow I will delete it so yeah don't use my API key uh use your API key try to generate your own API key from the open a i shown you how to do that so go through the uh openi website and from there itself you can generate an openi key so if you're liking the session guys then please uh hit the like button and and yes I think now we can start with the coding so if you will look into the project so here I have created a various folder so I have started from this uh logger if you will look into this McQ generator so I've created a couple of file the first file was the logger the second file was the utils file and the third file was the McQ generator now here uh no need to write it down the separate code for the separate code for the front end and all this stream lit will take care of it this stream late will take care of it we can create a basic BB application just to test our API and all so no need to write it down the code for the front end and all now guys uh what we can do here so let's try to uh write it down the code for the logging so here I'm going to write down the code for the loging now why the uh logging is required so see whenever we are going to execute a code so in the code actually we have a various step we have a various files we have a various method function classes and all right and each and every function has been defined for the particular purpose so let's say uh if I'm going to write it down any sort of a function inside the utils file or maybe McQ generator so the function which I'm going to create or which I'm going to Define I'm going to create it for the uh for the like Define purpose for a particular purpose right so uh if I if you want to log that uh information like so let's say this a function is going to execute and after the execution like what you are getting or maybe after the let's say you have completed the execution now you want to save that particular information software okay I have completed this particular step I have executed this particular function or method so that information you can log somewhere and there this logging comes into a picture so always make sure whenever you are going to create any sort of a project uh whether you are doing a development code development machine learning related development or whe whether you are going to write it down a code in a gener project or anywhere this loger exception you and all this uh this particular files and folder will remain same it's a part of the infrastructure got it now here uh let me write it down the code inside this logger do py file so here uh let me import the logging first of all so here I'm going to write it down import import login now uh here I have imported the login then after uh I'm going to import the OS and the third module which I'm going to be import over here that's going to be a date time so from date time and here I'm going to write it down import date time so these three import statement this three statement I have imported the first one is a loging the second one is a OS and the third one is a date Tye now let's try to create our logger file so for that uh what I'm going to do so here I have written one expression now let me show you how my logger file will be looking like so guys here is my logger file here is my log file actually and inside this file I'm going to log each and every information right so just try to uh look into this particular file so here what I'm going to do see here I'm going to collect my uh the real uh date time so by using this date time do now I'm going to uh I I I will be getting the real date time now I'm uh calling this particular method St strf time so I'm formating this particular time whatever date and time which uh which we are getting U and this is the real date time okay okay if I'm going to call it um as of now right so let me show you you can perform each and every thing each and every experiment inside this experiment uh inside this uh particular notebook So Yesterday only I have created so you can create it and you can perform like whatever experiments you want to do before putting into the pipeline now what I can do here I can copy this uh code from here now let me copy it and let me show you that what I will be getting from here so this small small experiment you can do inside your Jupiter notebook now from uh so here actually I need to import the date time so from date time what I'm going to do I'm going to import the date time itself so from date time import date time now uh let me do one thing let me run it and here you will find out the uh the current date and time now if you want to formate it uh so here uh for that actually we have a method so you can call this method St strf time now let me call this particular method and then let's see what you will be getting over there so I'm going to copy it and let me paste it over here now you will find out that I'm getting a date time in a particular format so here is month day year Edge means are minute and second now what I'm going to do so this will be the file name this will be my file name and here I'm going to put do log so do log is what do log is a extension so this is going to my file name and with that easily I can identify that at which particular time I have executed my code getting my point so that's why I'm writing this name I'm giving this name to my log file and this this will be what this will be my uh this current uh date and time will be my name of the log file and what is the meaning of the do log do log is nothing it's a extension so here uh you will see inside this uh logger file so this is what this is the name of the file uh by using this particular Name by seeing this name I can easily understand that at at which time I have executed my pipeline right so according to that I can collect the logs now here you will find out this is what this is my file name so I created a loog file and after that guys what I will do so after that let me create the path as well so where I'm going to store my log so for that also I have written couple of line and this two line actually I'm using for saving my log so in which directory I'm going to save my log okay now here I'm going to call this method os. path. jooin os. getcwd means what so os. get CWD means get current working directory so as of now um in I am in this a particular directory let me show you so let me open my terminal and here you will find out that I'm in this a particular directory so I'm in C user Sunny McQ generator so this is what this is my folder name so this is my directory path as of now I'm working in this uh directory so by using this particular method os. get CW you will get the current working directory and here is what here you are going to write down this log so it is going to combine this both path all right it is going to combine this both path so in a current working directory you are going to create one more folder the folder name is going to be a log and this is going to be your path now you will pass this path to your make directory meth method. make directory so what it will do so it will create a folder so here is your file name here is your folder along with the path where it will be available and here you are going to create that particular folder after giving a path right I hope this three line is clear to all of you now what I can do now inside this folder what I will do guys tell me now inside this folder I will now inside this folder I will create my log file the file basically the name uh which I have uh like given over here which I'm trying to generate from here so now in this particular folder inside the loog folder I'm going to create mylog file so let me do uh this thing and here you can see os. paath join now here is what here is my lock path this this particular path lock path where uh like we have a lock folder this logs folder and inside that I'm going to create this dolog file now now after that let me create a object for this loging so here I'm going to call this loging now now let me copy and paste uh inside that I need to write couple of thing inside this logging method inside this logging function now let me show you that what all thing we are going to write it down inside this particular method so here I have already written the parameter that what all parameter which we need to pass over here the parameter is going to be a very very easy so the first parameter is going to be a uh label so actually we have a different different label of the loging so here I'm going to mention this info label so loging doino this this is going to be my label actually we have if you will look into the uh logging documentation so P just just type python logger so there you will find out a documentation and just look into the label so there you will find out a various label regarding this logging so from where you want to so from uh which particular label you want to log your information so here I'm mentioning this uh info so info till info and above the info it is going to capture all the information it is not going to capture the information below the info right so let's say if we have let me let me show you the label of this uh logging so you can search about the python logger so let me write it down over here python logger and here uh let me search it and let me open the documentation and here you will find out the different different label of the logging so just a second let me show you that and uh label they haven't given over here let me search directly python loger label yeah so these are the label actually so nonset and debug information warning is there error is there and critical is there so we have uh how many labels we have six label actually so info so we are going to log all the information from here okay so we are going to write it down the label label is equal to logging doino and from here onwards we are going to capture all the information so information warning error and critical we are not going to capture this two information debug and nonset I think this part is clear to all of you that what is a label now here you can see we have a like a label and apart from that I have mentioned the file path so this two thing is clear to all of you now let's talk about this format so what is this format actually so in the inside the format you will find out I'm going to mention a various parameter so first parameter which I have mentioned that is going to be a ASD time uh that's going to be a current time now line number at which line number we are going to log the information then we have a name then label name and then we have a message so we are going to log a various parameter now let me run it and then you will get a a clearcut idea that how the thing is working so here is my logger file and by using this particular file I'm going to capture each and every information regarding the execution and in between I will be writing loging doino loging doino so whatever uh like information I want to capture so in between in my in between my execution I will be mentioning that thing and I will be able to capture all those information so here what I can do so if I want to test this logger file logger py so for that what I can do here I can write it down this uh test.py now I'm going to create one file the file name is what test.py now here inside this file I'm going to write it down let's say I'm going to import this loging first of all so where this logging is available so if you will look into this SRC so just go through with the SRC inside the SRC we have a McQ generator and inside the McQ generator you will find out this logger so you can write it down like this uh how you will write write it down your import statement so you will write it down from SRC do McQ generator. logger and you are going to import logging from here from this particular file so from SRC do McQ generator. loger import loging now here I'm going to write it down this a loging loging doino so here I'm mentioning this here I'm writing my login. info and let me write it down something over here so so hi uh I'm going to I'm going to start I'm going to start my execution so I'm going to start my execution now this is what this is my message which I have written over here now if I'm going to run this particular file so let's see uh will I be able to create the logger or not so for running this file what I need to do so first of all uh I need to open my G bash because either I'm going to work with my G bash or command line I'm not going to use this poers cell uh because it gives uh some sort of issues so I'm not going to use it now here what I can do guys I first of all I need to activate the environment so what is the name of my environment my name of my environment name is EnV so for activating the environment I just need to write it down here Source activate and do/ EnV now here is what guys here is my environment so EnV is my environment which I have activated now you can check that all the libraries is there or not all the thing uh we have upload we have installed or not inside this particular environment you can list all the import statement so for that there is a command pip list so just run this particular command pip list and here you will find out all the library all the library basically which we have installed and along with all the library along with all the packages you will find out my local package as well and the name of the local p and the name of the local package is what McQ generator so here guys this is the path where this package is available inside my directory inside my system and here you can see this is what this is the package name and how to install this package in my previous class I have clearly explained you that how to install this package inside the current virtual environment so for that either you can mention this Hy e do inside the re. txt or else you can use the setup. y file now let's try to execute the test.py file and let's see will I be able to create the logger or not so here what I'm going to do here I'm going to write down my python python test.py and here you can see it is saying that modu object is not callable but yeah I able to create my logger and inside this logger I don't have the uh I don't have the logger uh I don't have a logger log file actually so let's see uh what mistake we have done over here inside this uh inside this uh logger py so let me check with the logger py and here is saying that uh loging label loging doino um module okay so actually I haven't mentioned this uh I haven't called one method over here the method name is going to be a loging do basic info so basic configure actually so I missed uh that particular method now let me copy it and here I'm going to call it so my method name is going to be a basic configure so here is my method guys uh which I have copied now so let me do one thing let me remove it now everything is perfect so let me remove this part also yeah so here guys you can see my method name is what login. basic config this is my method and now I hope everything will work fine so what I can do do I can uh delete this particular module log mod sorry I can delete with this particular folder log folder and again I can run it so here let me clear the screen and let's see this time it will be working or not so I'm executing Python test.py and now you can see I'm able to uh run or I'm able to execute this particular file now just look into this log file and here uh log folder and inside this you will find out this uh particular file so just see the name just see the name of this file the file name is uh this is the date current date 12 1223 and here is a Time 347 and this is a second actually and do log do log is What DOT log is a extension now just look into the information that uh what information we are going to capture over here so here this is my current date time and here is my root actually root uh uh and here you will find out the information this is the information now this is my message so in whatever for see whatever format I have mentioned over here inside this format inside this basic config you can see in a similar format we are going to capture the information so just look into the format so here is a current time here is a line number here is a name so name is what name is a root I haven't defined any specific name so it's taking as a root line number U at which line actually uh I have mentioned this loging logging doino inside this test.py file so you can see at line number three so yes I'm able to capture line number three also now here is a logging information uh actually logging label that's going to be information and here is my final message so this particular information I'm going to log and in between I can mention this log uh like wherever I want to do wherever I want to mention it and then I will be uh log the information in this particular file I hope this logger is clear to all of you please do let me know in the chat uh please write down the chat if logger part is clear then I will proceed with the next concept okay so great I think uh this part is clear to all of you how to create a log and all and how many of you you are implementing along with me uh how many of you you are doing along with me great so what I can do here I can uh push this changes to my GitHub and then I will show you how you can do the entire setup in a lab also so before writing the further code uh so what I will do I will uh Lo the same repository in the lab in the neuro lab and I will show you how you can execute each and everything over there also okay so first of all let me commit it uh let me do it over here I'm going to add all the files just a second yeah it is done now here I can write it on the message I created a logger I created a loger now let me commit it and uh here okay a few more fil is remaining just a second now this yeah so here you can see so I created a log and you can see my log folder and here is my log file now guys you can do one more thing uh let's say if you are not able to set up this project inside the local see yesterday I started with my local setup and all so that's why I'm continuing uh here itself U but yeah from next uh class onwards I'm going to uh I'm going to shift uh this projects and all on my uh lab itself so what you can do so just uh open the inal lab and after opening the inal lab let me show you how you can U like clone this particular project in the lab itself how you can execute this uh this this entire project actually in the lab itself directly from the GitHub from here itself so what I can do let me open the lab and here uh first of all let me give you the GitHub link so what I'm doing I'm going to pass it inside the chat and here is my GitHub link now guys what you need to do see uh here uh how you can open the lab so after open the Inon website you just need to click on this neurol lab so just click on this neural lab and it will redirect uh to you on this particular page so this is the homepage of the lab I neural lab now click on this start your lab so once you will click on that here you will find out of various option so big data data analytics data science programming web development so whatever you want to do now let's say if I'm clicking on this data science now here also you will find out of various option so K is there Dash is there Jango is there flask is there Jupiter py toch my SQL python there are so many option you will get it now here I'm using this cond as of now so I'm not going to create my application in flask so I'm not using this dedicated uh lab okay this one uh I can use it if I'm going to create my application in flas Jupiter for the Jupiter only means here you will be able to launch the Jupiter this for the pyto this for the Python Programming this for my SQL with python so already you will get a like extension and all here itself inside the lab it has been configured in that particular way now let me open this cond and here what you can do so start your lab and here you can give the name so here you can write it down the name let's say I'm going to write down the name McQ gen project so this is what this is the name of the project now here uh what I will do let me write down the comp name McQ generator project and it is asking to me do you want to clone any GitHub repository so I would say yes I want to do that so it is asking to me a URL so uh like just just give your url just paste your url so here what you can do you can give uh this particular URL see here I have uploaded the my code actually here I have uploaded uh the entire code on my GitHub repository so first what you need to do either you can Fork it or else you can uh like clone this particular repository and then you can upload inside your repository right so as of now this code actually it is available in my repository I have created the repository McQ generator and here you will find out the entire code now in your case what you need to do you need to upload the upload the same code in your repository and that URL you need to pass okay that particular URL basically you're going to pass so here what I can do I can copy this URL I can copy this https URL just copy it from from here and pass it over here inside this enter repository URL now uh let me pass it and here you can see guys this is what this is My URL now proceed so once you will proceed so it will take some time for the launching and my entire code will be available inside this particular lab so just wait uh it is fetching the entire code from the GitHub and yes now it is going to launch it see guys see uh so here you will find out the entire code see this is what this is my entire code whatever code whatever development I'm going to do uh I I I'm doing basically uh which is available in my GitHub now uh what you can do see uh here let me show you so sttp github.com now this same thing actually you can see in your vs code here itself in your vs uh in your GitHub also so if I'm writing over here dab.com instead of this uh github.com it is not there I think I need to press dot just a second yeah GitHub do Deb see guys so this actually this vs code has been provided by the GitHub right this this one this uh which you can see over here you just need to press dot in your um like once you need to open your repository and press the dot so here you will get this vs code so in the same way actually see we are providing you this a particular lab now whatever thing now whatever thing thing actually we are doing in a local in our local actually this one this is what this is my local setup right so whatever code and all I'm executing I'm doing in my local but let's say you have a dependency issue you are not able to write it on the code in your local system your system is very slow you don't have that that much of configuration your system is lagging or if you're are installing or downloading any sort of a library is giving you the error so any type of issue so for that there is a one solution the solution is neural lab uh for so that uh you don't need to download or install anything you just need to visit the uron website after visiting the uron website click on the neural lab after clicking on the neural lab there is a various option you just need to select only one according to your requirement and then pass your GitHub URL there or maybe if you don't want to pass it don't pass it directly launch your lab it will be launching the blank lab in that case and there actually in that particular workspace you can create your own project so that that's uh that thing actually I'm going to do from my next class onwards and here you can see uh this is what guys this is my project the same project I have open in my uh the same project I have open in my neural lab now let me open the terminal and here is what here is my terminal this is what this is my terminal uh are you doing it guys are you doing along with me please do let me know in the chat if you are able to open this Nero lab and if you are if if you migrated your project to this nuro lab here is my GitHub so you will find out the uh entire project entire code in my GitHub itself you can Fork it you can uh clone it whatever you want to do you can do from here uh we are not going to use Google collab uh we are going to use the neural lab see Google Google collab it will just give you the notebook instance right so but here actually this lab is for the end to development so you can do end to development over here got it are you doing it please uh do let me know yes uh Google collab you can think it's a like a neural lab but it is for the an development and it is giving you like like lots of functionality great so this is what guys this is my uh project which I migrated to my neural lab now here see this is my base environment so in my base environment I can uh install this requirements or I can create the virtual environment also so for creating a virtual environment the command will same so let me create a virtual environment over here and let's see we are able to do it or not so for creating a virtual environment by using the cond there is a command the command is going to be cond cond and here cond create hyphen p and here you need to write it on the virtual environment name so my virtual environment name is going to be uh let's say I'm I can write any name over here uh ENB vnb your name my name or whatever now here the command is Conta create hyphen PB and uh then you need to mention the python version in whatever version actually uh with whatever version you want to create a virtual environment so here I'm mentioning python is equal to 3.8 now hyphen y okay so this is my entire command cond create hyphen PB python is equal to 3.8 hyphen y now as soon as I will hit enter so you can see it is creating a virtual environment in my local workspace so let's see yeah so it has created a virtual environment in my local workspace so just just look into the workspace here left hand side and here is your complete virtual environment now if you want to activate this virtual environment so for that there is a simple command you just need to write it down this Source activate dot means what dot means current working directory or current work working space do/ andv now as soon as you will hit enter so you can see over here that I have launched my virtual environment successfully so this is what guys this is my virtual environment this one EnV EnV is what EnV is my virtual environment and here you can see this virtual environment left hand side right now what I will do here I will install my re requirement. txt so whatever requirement is there U regarding this particular project I'm going to install those requirement inside my virtual environment now here is a very simple command for installing the requirements uh whatever like requirements I have mentioned inside the requir not txt and before that let me check uh what all uh what all packages we have inside this virtual environment so for listing all the package there is a command the command name is what the command name is PIP list so let me hit enter after writing this command pip list so here you can see we are able to list all the packages whatever is there inside this virtual environment now uh let me write it down here pip install pip install hyph R requirement. txt so now let's see uh are we able to install yes we are able to install this requirement inside the current virtual environment so are you doing it guys please do let me know in the chat if you are following this instruction if you want to set up the same project if you want to set up the same project in your neural lab so here I'm giving you the all the step uh that uh whatever you have to do so first you need to sign up uh sign in actually you need uh you need to open the neuro lab and after that go inside the start your lab there's a option right hand side you will find out and there you will find out the data science inside the data science there is a cond so just click on the cond and immediately you will be able to you will be able to launch your lab if you have kept your entire code in your GitHub then directly pass your URL and then uh like launch your lab that's it okay so I think it is done yeah so I install all the requirements over here now first I can check that uh my require whatever like packages I have installed it is working or not so here itself you can launch the python terminal and here you can see the environment python version 3.8.8 and here if I'm going to write it down import of Leng chain so let's see it is working or not c i yes my Lang chain is working now let me clear uh okay and here if I'm writing this Panda so import P PD so yes this is also working now everything is fine everything seems fine let me exit from here and what I can do now so here I have created the logger so if you will look into this uh SRC folder inside the SRC folder we have this McQ generator and inside this McQ generator we have have this logger now try to test uh this logger so it is working or not over here so for that what I can do I can run my test.py file so what I can do here I can change the message and my message is now I now I'm using now I am using neurol lab neuro lab so there is my message uh the message is now I'm using neurolab and let's uh execute this particular file python python test.py so if I will hit enter now let me check with the log folder yes uh so we are able to create this file and yes we are able to log the information also I hope this thing is clear to all of you how to log the information in all yes or no so the same thing which I was doing in my local now I'm easily able to do in my lab also oh yes we can change the theme also and for changing a theme there is a option let me check okay I think here you I will get the option command pallet color theme yeah so light is there now Dark theme yep so here you can see I have changed my theme also now if I if I want to zoom in then I can do that also just wait it is in my browser now so let me Zoom my browser yeah I think now it is perfect so guys uh if you are able to follow me till here so please do let me know in the chat then I will proceed with a further uh execution further code and all yeah you can upload your code over the GitHub and then you can clone this GitHub over here or else if you haven't created any GitHub then directly you can launch the lab and uh then you can connect to your GitHub from here also from the lab so that setup I will show you in my next class uh so in my next class when I will start with a new project so that I there I will show you if you are opening the blank neuro lab then how you can connect that neural lab with your GitHub got it even you can upload your code here also directly so just do the right click and maybe here you will find out the upload option see this one so just do the right click on this workspace over here here um anywhere in the uh and then you will find out this upload option so just click on the upload and here also you can upload your file maybe you won't get the folder option but yeah if you want to upload anything over here let's say data set or any any any file from the local system you can directly uh upload from here so just do the right click and here is upload option and then upload your file that's it great so I believe that uh everyone is a able to follow me till here now let's proceed with the further code so we have created a logger now it's time to write it down the code for the McQ generation so here I have created a file the file name is what McQ generator. py now uh before this one uh let me show you one more file this ipynb file which I have created in my previous class now here I have written the entire code of the open a for the Lang CH and all so uh directly from here itself I'm going to copy the code because already I have written it and uh yes I'm not going to write it down again so from here itself from the ipbb itself I'm going to copy and paste now uh there is my McQ generator. py file so at the first place what I need to do guys I need to uh at the first place I need to import the statement so let me import all the statement whatever statement is required for this project so here I have imported all the statement the first one is OS Json Trace bag is there pandas is there load. ENB is there now read file get file I will tell you uh like uh why I have written this read file get file so once I will explain you the U tools and here is loging so from where I'm going to import the login I'm going to import from this SRC see here uh I haven't mention the SRC so let me mention the SRC SRC Dot and here also let me write it on the SRC dot because uh I created uh like one more hierarchy actually this McQ generator folder it is available inside this SRC uh now I think this is fine now let's look into this particular import statement so here I'm going to import this Chad open Ai and then promt template llm chain and this sequential chain already I have explained you the meaning of this different different uh Imports that why we use this chat open why we use this prom template llm CH and this SQL uh and this like sequential check now uh what I can do here I can import my ID uh so actually I created my key openi key so let me import that openi key over here and then only I will be able to hit to my API so for that here I'm going to uh write it here I'm going to call this a load. EnV I told you why we use it uh if I want to if I want to if I want to create or if I want to keep my uh environment variable locally in my local folder in my local workspace so for that only we create this load. uh load. EnV uh now over here see if I'm going to call this method if if I'm running this method so actually it will look uh to this EnV file so it will it will try to find out the EnV file inside the current workspace now uh here what I can do I can create this EnV file so here I'm writing down uh do EnV so here is my file the file name is what the file name is do EnV so as soon as I am running this load. EnV so in back end actually it will try to search about this particular file so whatever variable whatever information I'm going to keep over here right whatever information whatever like variable I'm going to create over here so it will try to fetch from here wait let me show you how so uh what I can do now let me keep my key over here this uh like API key open API key I'm going to keep it over here inside this now what I can do now let me write down the further code so here uh once I will uh load this dot environment now here what I will do guys here I'm going to uh write down this dot get EnV so get environment variable so os. get En EnV and here inside this particular method I on uh like I will call it so I will mention the name of this uh key so what is the name of the key so the name of the key is open a API key so let me pass it over here this open API key now what I can do I can keep it inside the variable and my variable is going to be key now here what I'm doing guys I'm uh extracting my key I collecting my key by running this particular code by learning this particular line now uh here what I can do I can comment it out also so let me comment this particular thing I already WR the commment let me copy and paste so here what I'm saying load the environment with variable from the EnV file and here access the environment variable just like you would uh with OS environment so here you can see we are able to do it now let me follow the further step so after collecting the API key now what I will do I will call my open AI API for that we have a method the method name is chat open AI now let me call it and here let me show you that what all parameter we are going to pass while I'm calling this chat open AI so here you can see uh we are going to create a object of this chat open Ai and inside this one we are going to pass couple of parameter the first parameter is a key itself because without key we cannot call the API and we won't be able to uh get the model so here is what here is my API key now here is what here is my model name so this is the model which I'm going to use there are various model GPD 3.5 turbo or different different type of model you can go and check uh this uh I have already shown you in my previous session in my Open Session if you don't know about it you can go and check with my previous session now here is a temperature so temperature is just for the creativity if I want to so whenever I'm going whenever I'm calling my llm model so uh like whatever responses I'm generating so that will be a more creative if I'm mentioning uh if I'm writing the different different value of the temperature the temperature value from start from 0o to two so two means uh very creative zero means not at all it won't be a creative right so actually zero means it will give you the straightforward answer and two means it will give you the highly creative answer all it so between that I can set any sort of a value over here and according to that I will get the answer I will get a response so here you can see we have uh I'm able to call by API and I'm able to like U I'm able to get my model also now after that what I will do guys see I told you what I need to do I need to create my template I need to create my prompt template so here I'm going to create my prompt template now let me show you my uh template actually how it looks like so here is my template in my previous class itself I have shown you this thing I have explained you this thing now here you will find out couple of uh like variable also so variable like this number is there subject is there right we have tone we have n and this number so in between actually whatever thing you can see inside this curly braces that is representing a varable table now uh here what I'm going to do I'm going to create my input prompt I'm going to and this is what this is the template from the input prompt this is the template for the input prompt now here is what tell me guys here is my uh like a template for the input prompt now what I can do I can uh show you the prompt template and then I will explain you what is the meaning of uh this particular thing right this a particular template why I have written it again I will try to explain you even though I have explained you this thing in my previous class but again I will go through with that so here you can see guys we have a prompt template right so what we have tell me we have a prompt template and regarding uh see uh we have uh two variable inside this prompt template first variable is a input variable and the second variable is a template itself this one this one which I have defined over here now whenever we are talking about llm right so as I told you whenever we are talking about the llm so we have two type of prompt so the first one actually first one is called input prompt and the second one is actually it is called output prompt right so prompt is nothing it's a sentence itself uh it's a collection of the words it's a collection of the tokens right now here you can see we have a template and this is what this is my template the template is nothing so this prompt is nothing actually it is uh guiding to my uh it is guiding to my model is guiding to my GPT model GP we are using the GPT model now right so based on this particular prompt only is going to generate the answer so we have actually two type of prompts so we are talking about the prompt actually so measly you will find out two type of prompt so the first prompt first type of prompt actually is called a zero short prompt zero short prompt there we are not going to mention any sort of a context we are directly asking a question to my llm model the second type of prompt is called the second type of prompt is called few short prompt few short prompt so what is the meaning of the few short prompt so few short prompt is nothing there we are giving uh some sort of a direction actually some sort of a direction or some sort of an instruction in inside the prompt itself so this typee of prompt actually is called a few short of prompting now here we are giving an instruction to our llm based on this particular prompt now here you can see uh this is what this is my template uh and here I need to mention this particular template over here and this is what this is my input variable right this is what this is my input variable now we have H five input variable so one is text so whatever text on whatever text actually I want to generate McQ so that particular text I'm going to pass over here uh means basically based on the text itself I'm going to generate an McQ now there is a number of McQ there is a grade okay so to which grade actually uh the student belong now here is a tone tone means simplicity so means different different label of the quizzes so simple quiz or maybe hard quiz intermediate quiz and here is a response Jon so there you will find out the response and here in a curly bis actually I have mentioned this uh like uh I have mentioned this particular thing this particular variable now let me do one thing see uh here I have mentioned the subject and here I'm writing this grade so let me change this particular value here I can write on the subject so now everything is fine everything is clear so this is what guys this is my input prompt this is what what I have created I have created an input prompt now let me uh create a chain object so here already you can see I have like I have imported my llm chain and why we use this chain if we want to connect two component so we first uh at the first place we have a llm the second one we have a prompt template if you want to connect both uh this both component so for that we are using this llm chain so now let me create a object for this llm chain and for creating object for this llm chain so first of all let me assign to the variable quiz uh chain and here is this is what this is my object now in this particular object I'm going to pass two value two parameter the first value is going to be llm itself now here is what here is my llm which I already called which I already uh got from here and the second thing the second value is going to be a a prompt okay so here I'm going to be write the prompts and this is what this is my prompt quiz generation prompt so here I just need to uh here I just need to combine two component the first one is LM and the second one is a prompt so here is what here is my quiz chain got it so this is the first chain actually which I have created and this each and everything each and every uh like uh thing actually I have explained you in my previous classes even in my uh like yesterday's class now guys see whatever um output I will get after generating a quiz from here from the template so that thing I'm going to keep inside my uh inside my variable and the variable is going to be let me write down the variable over here so the variable is going to be output uncore ke is equal to and here let me write down the quiz so here I'm going to collect all the output inside this quiz inside this a particular variable now let me mention one more parameter the parameter is going to be a barbos so what is the meaning of the bbos barbos is nothing if I want to see the execution whatever execution is happening if I want to see on my terminal itself so for that we use this bbos parameter now let me write it down here verbos is equal to True veros is equal to true so here I hope each and everything is clear whatever I have explained you uh if it is clear then please do let me know in the chat are you following me are you following me guys tell me guys fast yes or no what was the command for creating a virtual environment so let me give you the command for creating a virtual environment cond create hyphone p and virtual environment name p EnV and here uh python version python 3.8 and here hyph y so this is the command uh which you can use for creating a virtual environment I given you the chat you can copy from there tell me guys first so if you are uh able to follow me till here then uh please write down the chat and if you are liking the uh if you liking the content if you are liking the class then please please hit the like button also if you have any uh sort of a doubt any type of doubt you can mention in the chat section you can uh tell me your doubt I will try to solve that particular doubt and then I will move forward please tell me guys I'm waiting for your reply so yes chat is open for all of you please hit the like button please ask your doubt and if everything is done uh then please say yes at least okay so let's move forward great so here uh you can see this is what this is my first template which I'm passing to my model now at the second place what I need to do so I I'm going to create one more template for evaluating this quiz so whatever quizzes and all uh basically we are going to generate so I want to evaluate a particular quiz now for evaluating the quiz here I'm going to create a one more template U Already I did it if you will look into my in uh this if you look into my ipnb file so yesterday itself I have I had created this uh like different different prompts and all so this was my first template this is my first prompt and this was my second one for checking the quizzes and all so whatever quiz and all which we are going to generate and here is a template now let me copy it from here and let me paste it down so where I'm going to paste it I'm going to paste it over here inside my McQ generator. py now this is going to my second template so let me keep it in a small letter itself so here I'm going to copy it and this is going to be my second template this one so just just read this particular template that what we are saying here I'm saying to my model that you are an expert English grammar grammarian and writer given a multiple choice question for this particular subject whatever subject I'm going to mention let's say data science AI machine learning so here I'm saying that you need to evaluate the complexity of the question and give a complete analysis of the quiz only use uh Max 50 words so 50 words for the complexity analysis if the quiz is not at p with the cognitive and analytic abilities of the student then update the quiz question which needs to be changed and change the tone such that is perfectly fits to the student ability now here here is basically here I have a quiz so uh which one this is this this quiz so this quiz actually I'm getting from here so whatever output I'm getting after the first after this uh after the first template so whatever uh like prompt I'm passing to my llm this first one so whatever output I'm getting I'm going to keep inside this quiz variable and that uh this variable I'm passing over here and based on this uh like quizzes and all right so based on this particular prompt we have a prompt and we have a quizzes now is going to check it's going to evaluate each and everything is going to check the complexity grammar each and everything is going to check over here so this is the additional prompt of which I have written over here now guys after that what I will do so here I'm going to Define my uh prompt template so let me do it uh let me Define my prompt template and my prompt template name is going to be a review chain so let me take it from here and this is what guys tell me this is my uh like second chain right so here I have created first llm chain and the name was quiz chain here I have created one more llm chain and the name is what the name is uh this one review chain right and here is what here is my prompt so prompt is going to be a quiz evaluation prompt sorry uh let me Define The Prompt uh before this one so here what I can do let me copy the code from The Prompt so this is the small small code and all so already I have written it even yesterday in my ipbb file I kept all the code right so you can go and check with my gith repository you will find out the entire code because yesterday I written from scratch and I have explained you each and everything so today I'm I'm not going to write it down here again um I'm just going to copy and paste and I believe if you have seen my previous session that definitely you will be able to understand it now what I can do so here I can write down this quiz evaluation prompt so we have this quiz evaluation prompt and here is my prompt template where what I'm doing guys tell me where is my uh input variable these are my input variable subject and quiz which you will find out over here subject and the second one is what the second one is quiz now here I'm going to pass my template and the name of the template is what template 2 so let me mention it over here let me write it down the template 2 so here is what here is my quiz evaluation prom and there is what there is my chain which I have created by using two component the first one is llm itself and the second is what the second is quiz evaluation prompt right and here whatever output uh we are getting so that output I'm going to keep or I'm going to collect inside this review variable right so just just try to understand how the thing is working it is very very simple if your python if if you know the python if your python Basics is clear the definitely you can understand uh this particular code got it now here we have written bubos is equal to true so this is what this is my review chain uh which I have created now after that what I will do see I have to combine this both chain the first is a review chain and the second one is what the second one is a quiz chain so for combining the both chain what I can do so here I can create object of the sequential chain right so now what I'm going to do guys here I'm going to create object of the sequential chain uh just a wait now let me create a object of the sequential chain and here is a object of the sequential chain this one now already I have imported the sequential chain this one this one L chain do change the sequential chain now here see we are going to create a object and what we are going to write down here we are going to define or we are going to write down the both name both chains first one is quiz chain and the second one is a review chain now we are going to connect everything all together here is and we are passing to this chain parameter now there is my input variable so these are input variable if you will look into the prompt if you will look into the prompt template there you will find out of various input variable various input variable which I'm going to take from the user side I told you I I explained you this thing in my previous classes just go and check with that now here is what here is my output variable so one output I'm going to collect inside this quiz and the second output I'm going to collect inside this review and here verbos is equal to True verbos equal to True means what whatever execution is happening in back so each and every execution the detail of the execution I will get onto my uh screen itself right so that's the meaning of the verbos is equal to true now this part is clear to all of you so we have a completed till here means uh we are able to call my API we are able to create we are able to call my API we are able to create a prom template and here we are able to create the chains now after this what I have to do see here in between you can mention the uh log also you can create uh we have created a loger now you can write down log logging doino and here you can collect all the information in a single file itself so whenever uh we are going to execute it so yes the loging U the log loging doino U basically logger file also is going to be execute and it's going to collect each and every information inside the dolog file got it now here uh this McQ generator is done now uh in the previous session uh actually what I did so over here uh if you will look into that so open eyes find this uh temp template and all everything is fine now just look into this ipynb after creating the chain actually we were calling this particular method right so uh the method name the method name was what get open a callbacks now why we use this U Get open a callback because if you want to keep a track of uh of the token right how many tokens is being used inside throughout the execution means uh let's say uh I'm passing a prompt input prompt I'm getting an output prompt so throughout this process how many tokens is being generated so that all the thing I can keep track by using this get open I call back and inside this one I'm calling I'm I'm I'm creating a object of this generative evalution chain itself so this is the one generative evalution chain and we are passing a different different value now where I'm going to do this particular thing see main code I have written inside the McQ generator. py now rest of the code whatever uh like utility code is there whatever helper code is there I'm going to write it down inside this utils.py so here I'm going to write down the entire code which is a helper one right I'm not going to mesh up my uh McQ generator file itself okay so here if I'm going to write it down like each and everything it is going to be a very clumsy so I'm not going to write down anything now over here uh till here everything is fine maybe so yes uh we have created a chain now inside the utils.py file let's see what all thing we have to like like uh we have to mention so the first thing first of all let me write down the import statement all the import statements so the first one is uh OS the second is pi PDF 2 the third one is going to be a Json and the fourth is a trace back so these are the import statement which I'm going to write down here now here what I will do guys see uh what I want I want a data right I want a data so for that actually uh I have defined two method so let me copy and paste all the method now just second I'm going to copy this two method and I'm going to paste it over here so here actually we have two method just just look into this method I I will tell you that uh uh why we should use it how we are going to use it so just a second yeah so here we have two method the first is going to be a read file and the second is going to be a get table data so there is two helper function which we are going to Define over here right now just look into this read file so this read file actually this this particular method we are using for reading the file right for reading the file whatever file we are going to pass actually so here actually I have written a code regarding two particular files so the first one regarding the PDF file and the second one respect to uh text files right so here I'm going to mention this P pdf.pdf file reader here we are passing file here we are getting file and here we are extracting all the data from the file itself in which variable in this text variable now here if you will look into this uh this particular code right inside this LF blog you'll find out file. name. ends with. txt so if my file is a txt one so I'm going to call I'm going to read this particular file and I'm going to keep all the information in my VAR so here from here basically I'm going to return all the information right got it now here just see this one so the second method G table data so why we are using this method G table data in my previous class if you will look into this uh IP VB file so where is the ipb file let me open it once more time so McQ do iyb file just scroll down till last so here actually I was getting a data I was getting my McQ now if you want to convert those McQ in a data frame so for that see this my this is my McQ which I was getting now if you want to convert this McQ in a data frame so for that actually we are using this a particular code this one this this particular code which I have written inside the utils.py so here I'm not going to mention everything in a single file instead of that I have divided a task right so whatever thing is required whatever is a main code main script I have written over here inside this McQ generator whatever like helping function and all like uh like this reading file reading and all or this get uh data as a table and all right so I have mentioned over here inside this U and already I have created a logger so there I am going to Define my uh there basically I have defined my logger so I believe until here everything is fine everything is clear to all of you please do let me know in the chat now one more step is there one more step is remaining now finally we'll create our application our streamlet application and then I will show you how to run it so first of all tell me if uh till here everything is fine everything is clear try to generate a new API key if you are getting any sort of error related to your API key delete it immediately and uh generate a new API keyy tell me guys fast I'm like up for the doubts and question so yes you can ask me and then I will proceed with the forther uh thing please increase the font size I think it is visible to all of you now let me increase few more just wait ah I think now it is fine what is a trace bag Trace bag actually it's a inbuilt function wait I will show you what Trace back does uh wait I will write down the code here itself inside my McQ IP nv5 if you have any type of Doubt any sort of a doubt then please do let me know please write down the chat uh I will try to solve your doubt and then I will proceed further no you no need to pay anything uh if you're using this neurol lab it is completely free uh just try to launch it again I think uh you can launch it yeah we can create a new template file also that is also fine but here we just have two templates so that's why I have written it inside my P file itself inside my python file but uh not an issue like you you can create a template file and there you can keep the all the templates and from there itself you can read We are following you but needs to revision from yeah definitely revision is required could you open the logging file whether it contains any log or not so here is a logging file and here we have two log file. log just open the file and here see we have a log I test it now I test it from here test.py so yes I'm able to see the log yeah so I think uh we can start now uh yeah so I think we have done almost all the thing now the next thing is what I need to create a streamlet application I think uh see uh regarding the code and all everything is fine everything is clear whatever I did in my previous session I I'm doing the same thing over here I just kept in my uh py5 that's it now see guys this uh project is uh actually it's a first project so that's why I kept I kept it uh I kept I kept it as a simple one only but uh from next class onwards uh I'm going to use few more files and folder inside the like project itself so the architecture which I'm going to make so it's going to be a little more complicated okay so this is fine this is clear now let's do one thing let's try to create okay response. Json is already there now let me keep the response over here inside this uh file inside this response. Json and after that what I will do so I will create my stream application so there is my response in which particular format I want a response so I kept it inside the response. Json so this is what this is the format which I want here is McQ question here is answer and here is a correct answer so in this particular format actually I want a response from my GPT model now this is this is what this is a response. Json now let me open this stream lit uh app.py file and here I'm going to write it down the code now first of all let me import the statement all the statement so there is all the statement basically uh here what I'm going to do so these are the statement which you already know now this is the statement read file get file from where from the utils itself now see I created uh like one more hierarchy so here uh let me write down the SRC so wherever you are able to find out this McQ generator just write down the SRC in front of that so uh here you can see we have I have written this SRC McQ generator. utils and inside that we have this read files get table data you can check it you can run it and it is working fine or not so definitely uh you can do it for that uh let me write down this SRC McQ generator. log. loging now here if I want to check this file so I can write it down one okay so here what I can do I can run it in front of you let me clear it first of all and here let me write down python python uh streamlet app.py so Python steamate app.py and if I'm running it so it is saying that this module is not available McQ generator let me check with the spelling is correct or not so the spelling is McQ generator g n Okay g n and here see guys the spelling is wrong so here I need to write down the correct spelling so this will be g e n e so this is the spelling of the generator G NE e generator and here also G G NE so this is going to be generator now let's see it is working fine or not now for that python streamate app.py so let me run it and module name SRC McQ generator not there so where it is at line number nine so line number line SRC McQ generator import generative evaluate chain so here we have SRC McQ generator is there inside this McQ generator this is the file so McQ g e n e again the spelling is wrong let me correct it uh let's see it is working or not so here I'm going to write on python stream tab. py SRC McQ generator utils so McQ G NE McQ g n r a is correct now right so why it is giving me this error SRC McQ generator do utils SRC McQ generator do utils import read file and get table data no modu SRC McQ generator I WR something wrong here McQ generator g e n e r it's fine now I S see just a second so here is fine now what I can do let me install this setup.py so python setup.py install because in my local system everything was working fine I moved to entire project project to this Nero lab that's why I need to check it first okay now let's see mCP P the spelling I need to save it first what so okay I think the file is different uh McQ generator. py line number 6 this one line number six yes so the spelling is wrong now it is perfect I believe right package rapper prompts extra field not permitted what is the issue here modle name McQ generator this is fine this is I have solved now stream lit line number nine there is line number line okay great now I think everything is fine I just need to pass the parameter over here but this uh logging statement and all everything is working fine over here see if I'm going to uh comment it down this one so I will be able to import it python stre late app. yeah now everything is working fine so I was getting the error because I need to pass the parameter to this particular uh like class okay to this particular object that's why uh it is giving me uh it is giving me I show so yes I'm able to import all the statement I was just checking actually because I migrated this project to my neural lab in my local I already tested and yesterday actually I shown you that but yeah I migrated to my uh to this uh neurol lab so that's why I was running it and now everything is working fine so let's try to create a stream streamlit application so here what I can do so for creating a streamate application uh this is the UT statement which I have imported now the first thing the first at the first place I need to load this uh response right so here what I'm going to do here I'm going to load this response so for loading the response actually see what I'm going to do I'm going to read the Json file the Json basically which I've created now let me do the right click and from here from here itself uh like from this uh neuro lab itself from the local workspace I'm going to copy my path right so because this is my local path actually this one that you can see over here the Json path now from here itself I'm going to copy my path so copy path and paste it over here right paste it over here this particular value now let me paste it and this is what guys this is my path right and here my Json file is available now uh what I will do I will read this Json and here you'll find out your Json response Json right in whatever like in whatever like Json whatever Json basically we have defined whatever response method we have defined in that particular like way only is going to data output now uh I have loaded the file I have loaded the Jon file now next thing what I need to do here so see a step by step I'm going to show you everything or let me copy everything each and everything in a single shot and then I can uh explain you right so here see what thing I'm going to do over here Ive already done the code now let me is explain you one by one so this is the first line this one st. Title St means what ST means streamlink here you can see this one s isans what streamlit and why we use streamlit for creating a web application right if you want to create a web application for for that we use this stream L and generally we use it uh for creating a rapid web application like we want to test our machine learning code like okay so we don't want to write it on the like long templates and all we don't want to create API by using Jango or flas so simply we can create a web app a small web app by using this stream lead and yes we can test our code we can test our application now here uh you can see this is the title which will be visible on top of my screen now here you can see we are going to create a form actually inside this stream lit we have a several thing right so what I will do I will create a short tutorial on top of this stream lit and I will upload over the Inon YouTube channel so from there you can learn the streamlit from scratch as of now I'm not going into the deep that what all method what all function it is having I'm just WR whatever thing was required over here and that is what I'm going to explain you got it now here see we have this streamlit st. form and here actually I'm mentioning user input right now I'm asking about the file so actually I'm asking about the file you need to upload a file and based on a file only uh I'm going to generate a mcqs now here you can see number of input so how many uh how many mcqs you want to generate so here McQ count now here McQ subject so like on which subject you want to generate McQ so here you will pass the subject now here is a input text input means here you are asking uh you want to keep it simple intermediate or the hardest one so here I'm uh setting the tone tone of the mcqs tone of the quiz now here what I'm doing here I'm giving a button so here I'm written St St is for the stream late. formore submit uncore button and here you can see create McQ this is what this is my message that's it nothing else so after that you can see I I have written a further code so this is what this is what guys tell me this is my form and inside form actually I have defined the entire template the entire UI so I have created a form s. form s. form means what stream li. form and here I'm asking to the user input so this first input regarding the file means on whatever like data we want to generate our mcqs here you will find out a number of mcqs here the subject of the McQ here the tone of the McQ whether it's going to be a difficult simple or intermediate and here I have added the button the button is nothing I'm going to submit this form so the message B by default message you can see over here that is what there is a create McQ that's it so this is what this is my form now after that I will write my main code main code over here see uh just just look into this particular variable upload file right this this varable upload file right and here I'm getting McQ count subject tone and button now here see this is what this is a respon just look into this particular variable because this is required very much this very much required over here now I'm saying over here if button and upload file is not none okay and McQ count and subject and this this thing is not none then what I need to do so here I'm writing this st. spinner it will be loading right and here see I'm uh reading this text file whatever uploaded file I got and how I can reading it how I am reading this particular file so for that I already WR the method inside the utils file utils.py so here I'm calling this method upload see uh let me show you this uh read file right read file and here you can see St um the stream. file uploader so here I get it I got the uploaded file now what I'm going to do here I'm uh keeping this file over here upload file and I'm giving to this read file right and this read file I already defined inside my utils.py this one see getting my point yes or no now if I have a PDF file then definitely I will be able to read if I have a text file then definitely I will be able to read so let's see if you're giving any other extensions so according to that you can mention the logic you can write down the code over here itself inside the read file now see guys here inside the stream app.py so this is what this is the read U we are calling this read file and here I'm getting this text okay this is fine now again I'm going to call this I'm going to call this uh get open call back if you have attended my previous session definitely you must be aware about this particular function this particular method in very detailed way I have explained you this thing get openi call back now after that you can see we are going finally we are going to call our object so here is my object generate evaluate chain and here we are going to pass a various parameter so the first one is a text so here I'm getting text McQ count or from the user I'm getting McQ count here is what here is a subject tone and here is my Json response everything I am getting over here you can see you can see over here guys this one now we are getting it and after that uh this is fine now in the else actually I have written something so you can see uh whatever number of token prompt and all I can I can print it actually this this particular thing right so inside this else block try accept and else so inside this else block we I have written this particular thing now any now this lse blog will run after this accept so yes you can see this is the thing which we have written now what we are going to do over here we are going to convert our data into the uh we are going to convert our data into our data frame so here actually this is the code see whatever data we are getting now so we are going to convert this data into a data frame this one and after that like yeah uh we are going to end it this particular code and once I will run it so each and everything will be clarified to all of you now what I can do I can run it and then again I can come to this particular code uh where again I can explain you the bottom part but yeah just look over here uh it is just printing the tokens and all now here we are getting a response and d means uh if is response as a DI actually this this particular response now what I will do here I will call this response doget quiz I will be getting the quizzes from there yesterday I run this particular function this quiz and after that I'm passing to this get table data the function which I defined inside the utility and it is going to return return me this table data which I'm passing to my data Frame pd. data frame and I will be getting the data frame over here and you can save it also so yesterday actually I saved this uh mcqs and all over here inside this experiment folder but you can save it you can save this data in the form of CSV file right now what I can do I can run it so here uh for running this particular application I just need to run it let me I just need to write it down one command let me uh give you that command here stream lit streamlit app sorry streamlit run and here I need to pass the here I need to write down the file name so streamlit run and then streamlit app.py soam lit streamlit app.py okay so this is the file where I have defined where I have created my streamlit application so streamlit run is stream lit uh app.py now as soon as I will hit enter let's see it is working or not so it is saying streamlit does not exist I WR a wrong spelling okay streamlit app fine so a will be a Capital One a a yeah now it's fine so see uh my application is running now if you want to run this application ation so for that just copy this URL and then paste it over here and here guys what you need to do just remove till till here this one just remove this up part okay just keep till app and then put the colon and from here just take the host uh this 8501 sorry Port actually this one so just see if you clicking on this one now it is not going to run because it is a uh like it's a local host right now uh actually my lab is running on this particular URL Somewhere over the cloud Somewhere over the server so till here I have copied the URL now put the colon and pass this particular port number 8501 so here I'm writing 85 01 and if I will hit enter so let's see whether I'm getting my app or not so it is not giving me the app let me check it 501 yes it is correct let me check with this link uh but I think it is not going to work are you follow me guys tell me are you follow me till here this is not giving me a URL when view stream browser 8501 right so this is a URL oh no it is not running just a second let me check with my Chrome it is working or not so if I'm passing over here this particular URL now let me put the colon 8501 uh let's hit the enter no it is not running but yeah my my server is up uh here you can see my streamlit server is up streamlit server is running on this particular Port 8501 851 it's a by default Port of the streamlet actually let me change the port just a second let me check uh I'm okay let's do one thing let's try to run on a different port so here what I can do uh I can mention the port just a second I can mention a different port number let be clear first of all I'm here Pyon stream lit run uh stream lit run and there is my app and then hyph iPhone hyph iPhone server and dobard so let's run out 8080 if I will hit enter now let's see it is running on on this 80 8 0 so it is running on this 8080 now let's check over here what I can do I can take this particular URL let me remove here 8080 yeah here it is working fine see I'm getting my application uh before uh it was not working with 8501 but it is giving to me not a complete one why is so just the second is there something wrong so guys see on 8080 my app is working fine this one I'm getting it but uh it should give me a homepage now the form basically which I have created over here this one title also I'm not getting Let me refresh it once no SD form user input this this is everything is fine no no no guys I'm not getting it let wait let me take a different port over here it's getting a stuck here actually let me check with the Chrome is giving me a same issue or what's no guys see it is giving me a issue this particular URL I don't know what is the issue there's a issue with the code or there is a issue with the stream R because I can see my code is fine and uh I just I checked it before right before the class also and it was working uh not an issue what I can do I can show you this thing in my local as of now and then tomorrow I will tell you that uh why it is giving me such issue I I will check okay so as of now see everything is working fine maybe I'm able to get the URL also but uh with 8 5 01 it was not giving me anything but with 5,000 or with any other Port it is giving me this type of page now let me check the same thing in the local it is uh working or not right so just take it just take this particular code and paste it over here inside the local means this is my local environment right now inside this streamlit app.py I pasted my code now inside the SRC we have H utils so let me put the code inside the utils also so from here itself I'm going to copy and paste let me copy and paste from the utils this one and here this is my local utils and let me paste inside the McQ generator is not there let me put inside the McQ generator also here is my McQ generator so this is my McQ fine so logar is there McQ generator is there and utils is there now streamlit is there everything is fine now let's run it so for running this application here is a command stream SD stream lit run SD stream lit app. stream lit app. P1 now if I will hit enter let's see it is working or not yeah it is working okay so here it is giving me one error the error is what PR required type missing prom extra field type quiz barbos just a second guys let me check the issue we uh to validation error evaluation chain yeah this is fine commed line number five Sunny stream L app okay McQ line number 242 McQ generator line number 42 okay boms output key is equal to quiz okay file load I think here we have some issue okay so I I think I'm getting some issue over here maybe it's a python related issue let me check where I'm running it I activated my environment rank chain 0.348 uh just a second so let me fix it don't worry it till be working so let's it yeah so now it is working and here you can see guys see uh this is the code and uh yeah it is working fine on this particular URL and it is uh the project B actually I'm running in my local itself in neuro lab also it is giving me a issue maybe there is some code issue uh which I tested in the local I will have to check because I was copy and pasting maybe in between I miss some line or I'm getting the issue because of the version uh basically the python version which I'm using now here uh you can see see uh my app will look like this the app which we have created now here you have to upload the file uh the file basically U on whatever file you want to generate a McQ and here you need to write down the number of McQ so let's say you want to generate 5 10 15 20 whatever number of mcqs now here you need to insert the subject and here complexity label by default the complexity label will be a simple one right now let me browse some file and let me show you that how the McQ will be generated and how the output will be visible to all of you so here what I can do I can go through with my project itself because already I kept one data file over there there one txt file now let me import the txt file from there and here is what here is my project in my local system just a second McQ generator and here is data open so this is the data guys which I uploaded over here now after that how many McQ you want to generate so here is what here is five now here is a subject let's say the subject was the machine learning so here let me check what was the data inside the file here so here the data which I had actually so let me check with the data it was the biology uh which yesterday actually I collected inside the file so the data was the biology data now how many what was the like complexity of the quiz the quiz you are generating so here I want to keep it simple you can write as simple also but by default it will be a simple only now if I'm clicking on this create McQ so it will will uh directly give me the mcqs now over here is giving me error let me check what is the error yeah API key error so let me keep the correct API key over here because the API key which I'm using just a second yeah now it is fine and now let's do one thing okay server is up and here let me refresh it yeah it is working fine now browse the file a data just upload the data here the number of quiz you can say 5 6 10 subject is what subject is biology uh b i o l o z and here the complexity label is going to be a simple then create mcqs now just wait for some time and it will create a McQ so just wait yeah it is running now and it got the response also yeah so here you can see uh we are able to generate mcqs so mcqs is which of the following is a unifying theme in a biology so these are the like uh you can see these are the options and which data I have use I have used a biology data so I can show you this particular data in the local itself so let me show you if you will look into this particular folder So Yesterday itself I collected a data inside this uh txt file so this is the file inside that from the Wikipedia I took the data in front of you only and here you can see the data you can uh pass any PDF or any txt file and based on that per subject based on that per data you can generate a McQ and here you can see the McQ and this is the like review the review actually right so uh we were evaluating the quizzes after generating a quizzes right so we have seted the limit in uh 50 wordss you have to evaluate the U the quizzes whatever quizzes basically we are going to generate so here you will see the review also on top of the UI so each and everything you will see uh inside the like uh inside the like front end itself here uh basically which we are using and if whatever number you are giving let's say 5 6 7 8 91 that many quizzes you will be able to generate now see uh before I was running this code in my local now let me show you both of the code so this was the code actually I was running in the local but uh it was giving me some sort of a issue uh don't know it was related to the maybe uh this library and all so see before the session itself I was testing with my uh same application actually uh like this is the same application only with uh with this particular application I was testing so I just run this one in front of you and I shown you how the output and all it will be looking like maybe uh in this uh application there is something wrong uh with respect to the library and the version or maybe I have uh given some wrong line and all I will have to debug it and the same I will uh I will uh like uh I will run inside the neural lab also but not today in tomorrow session and right after that I will deploy it but I just see I just want to show you the how the UI it looks like so here actually uh I run this particular application in front of you the same application the McQ application itself which I was I have created now how this looks like how the UI and all looks how the UI and all it looks like each and everything you can see over here and this is a by default Port where my streamlet application is running so 8501 right so whenever you are running your streamlit application so by default it will be running on this 8501 flask always take 5,000 port and this streamlit always take this 8501 Port right so don't uh do a mistake over here if you are running this application now how the answer will be looking like so it will looking like in the form of table and each and every code I have mentioned over here if you will go and check right inside the stimulate application now if you will look into the code so it will be more clear to all of you right so just looking into the code so here I'm say okay so this is the parameter basically which I'm going to print over here on top of the terminal and after that you can see I have mentioned one if condition so whatever response and the Dig right so is is response type is d i I'm saying yes so what you need to do in that case you need to exted the quiz then you need to pass this quiz to your get table data so from there you will get a table data now you are going to convert into a table and you are going to display that uh like you're going to dis see you are going to convert this table into a data frame and you are going to display it on top of the steam lit on top of the Steam on top of the basically uh UI so here uh this is the code this is the code actually this this one which you can see this one so display the review in a text box as well so here I'm going to display the output on top of the UI by using this particular code this particular line and rest of the code is a simple python code which I already explained you got it so this is the complete application now don't worry in tomorrow session uh again I will run it I just need to run it okay and again I will see I shown you the setup of the neural lab but in neural lab also I will run it and whatever project I'm going to build from now onwards I will be building in the neural lab itself so you can practice with the neurol lab and yeah tomorrow will be the deployment day and along with that I will explain you the concept of the vector databases so we'll try to discuss the vector database that what is a vector database and uh uh will try to understand the pine cone I will explain you the the pine cone actually how to uh like use that pine cone how to create a API key of the pine cone and how to store the embeddings and all what is the difference between normal databases and Vector based databases each and everything we're going to discuss in tomorrow's class in tomorrow's session okay and yes deployment I think it will take half an hour not more than 45 minute we are going to deploy it on over the AWS and and I'm going to use the ec2 instance uh I will show you along with the docker also so after creating a Docker image that how you can deploy that Docker image over the ec2 that process also I will show you regarding this particular application and yes right after that we'll start with the vector databases and uh then couple of Open Source model like Google pom is there Falcon is there or Jurassic is there so I will take one class for that and finally uh we'll start with more advanced project so one or two uh like other project actually which I have planned for all of you so uh with not with steam lit this is just a basic project which I shown you along with the flask and fast API also so um yeah stay tuned with us subscribe the channel like the hit the like button also if you're liking the content and if you are getting any sort of a issue then uh you can you can write on the inside the comment I'm monitoring each and every comment immediately I will reply to you uh resources wise you can check with the dashboard and uh yes video will be available over the dashboard as well as on a YouTube channel so you can uh watch on a both platform got it so how was the session guys uh are you able to run it or not don't worry I give you the complete code in a resource section from there itself you can download it here is my GitHub so here in the GitHub itself uh where is my GitHub where is my GitHub so this is my G so here itself I will upload all the code just uh forkit star it or or just keep it with yourself okay my just keep my username so from here itself you can download the entire code and don't worry the same link will be available in my resource section also got it yes or no tell me guys fast yes fine now uh here guys uh this is my project now first of all let me show you how this a project looks like um let me run this particular project so for running this project let me write it down here uh let me clear the screen okay now here let me write it down streamlit s r e a m streamlit run and here then I need to provide a streamlit file so streamlit dopy streamlit run streamlit app.py this is my file name now as soon as I will hit enter so my application will be running so here uh guys you can see my application is running just a second yeah so my application is running and this is my application just a second just uh wait yeah so this is my application guys now here you will find out we have a different different option so here you can upload your file and based on that data based on your uh based on that specific file you can generate a McQ you can provide a number like how many mcqs you want to generate here is a subject so whatever uh subject is there related to the data related to the file you can write on the subject and here is a complexity label so you would like to keep it simple hard or intermediate so let's try to upload one file over here so here already I I kept one file data.txt in my previous class only I shown you that now let me show you what we have inside this particular file so once you will open this data.txt uh so here actually this uh test.txt data.txt data.txt basically is what it was my in my another folder so I can take anyone or from anywhere I can take the data file so let's do one thing let's try to create one file okay from scratch data file and that to I'm going to create on my desktop so here uh let me create on new and here is my txt documentation now inside this particular file I'm going to paste my data so let's open the Google and here search about the AI so let me open my Google and let me search about the artificial intelligence now here I will get a article related to artificial intelligence let's say I'm opening this Wikipedia and I'm going to copy the article from the uh from the Wikipedia itself now I copied this article and I'm going to keep it inside my desktop inside my text one right now I can save it also so let me save as uh let me save as as a AI document right so AI doc so this is what this is my document which I saved now let's say if you have any sort of a information inside your text file inside your PDF so you can upload it over here so let me show you where you can upload you can upload lo you can pass it to my application now just click on the browse file and take a data from the desktop and here already I have this AI doc now open it and here guys you can see my file has updated now you can give the number of McQ now how many McQ you would like to generate so let's say I want to generate five McQ so here I'm giving number five so you can increase or you can decreas also from here itself now you need to provide a subject so here I'm writing artificial art artificial intelligence right artificial intelligence so here is what here is my subject okay so here is a restriction of the word so let me keep it like this in G and C so I can increase actually I can increase from the back end or otherwise I can write it down like this AI right so AI is fine my subject is what AI in a short form I have written it from back end actually I have given this restriction you can check with my streamlet file there I have already mentioned I can increase the number and then it's going to take like more than 20 words right 20 character actually now here I can provide the label so here the label is going to be a simple right I'm just going to create a simple uh simple McQ simple five McQ now once I will click on this create McQ so you can see my model uh is running in backend and here it will give you the answer so let's wait for some time and yes it will give me the answer yes Vector database Al Al will be covered in a live class yeah so if we are talking about the prerequisite right so I got one question actually so the prerequisite for the generative AI course is nothing just a python if you have basic understanding of the Python so just look into the project see guys here I'm able to generate a question so here I'm able to generate an McQ just just look into the McQ so uh it's a sens ible only right so what is the field of the study that develop and studies intelligent machine so here it has given you the various option like artificial intelligence machine learning computer science robotics now this is the second one which of the following is a example of AI technology used in a selfdriving car so it is giving you the various option right so uh chat GPT bimo right Vio or YouTube Google search so like it is a sensible one and here you will find out the a correct answer so it is giving you the correct answer and it is evaluating the quizzes quiz also so here you can see the quiz evaluation now uh one question basically I got and it's a good one so uh what is a prerequisite uh if you want to if you want to start with the generative AI so the just just look into the project guys what I have used over here just tell me if you have a basic knowledge of the Python if you just have a basic knowledge of the development so yeah um you can enroll into the generative a and even if you don't don't know about the python then don't worry our prerecorded session of the Python will be available over the dashboard from starting to end and apart from that like you can see regarding the development each and everything we are going to teach you in a live class itself from various skch from folder creation to deployment right so we are creating a folder in a class itself in a live session and we are doing a live coding in front of you and after develop after developing our application we are deploying it also so from starting to Advance right so from scratch to advance everything we are doing in a live class and the prerequisite is just a p just just python okay so don't worry about the uh this uh prerequisite and all already like uh the python and all will be available over there you can learn that first if you don't know and then you can proceed with the further thing right now here you can see this is the application which I'm able to create now what I want to do I want to deploy this application over the cloud right now here guys see this is the first application and many people are beginner one right and they don't know about the advanced concept Advanced mlops concept Advanced devops concept cicd and all so let's try to keep it simple let's try to deploy it over the ews there I'm not going to use a cicd concept in my next project I will show you how you can uh use the cicd a concept how you can uh create a like continuous integration continu deployment Pipeline and how you can deploy the application and even I will include the docker also here I'm keeping simple simply I'm creating a server on top of my AWS machine and there I'm going to deploy my application so let's see how we can do it so for that guys see the first thing what you need to do so the first thing you need to create your account on AWS the application we are going to deploy we are going to deploy on AWS so here what we are going to do guys tell me so here we need to create account on AWS now here you require a credit card debit card actually AWS does not ask you the credit card it ask it you can add the debit card also and it won't charge you anything directly right so believe me it won't charge you anything first it will ask you first it will tell you then this this this much of will like you have generated and like you can wave off also right or in the worst case you can delete the account so it won't like harm you it won't deduct any sort of a money from the account now the first thing which is required that is the AWS now here in the AWS we are going to use the ec2 server for deploying our application so first we'll try to configure the ec2 server and here uh for uh in ec2 actually we are going to use the Ubuntu machine right Ubuntu machine so that is the first thing basically which is required for the deployment now the second thing which is required that is a GitHub so just make sure that you have kept your project over the GitHub so what I'm going to do I'm going to upload my project over the GitHub I'm going to create a repository which I already did right I have like I have I have done in my previous session itself so there itself in my repository itself I have kept my project I have uploaded my project right so the first thing which is required which is a AWS the second thing which is required that is a GitHub that's it right so let me show you how to do how to deploy this application over the adws how to deploy this application or the ec2 instant where I'm going to use this Ubuntu Server right now uh GitHub so first of all let me give you the GitHub so at least you can follow me uh throughout this deployment process and here we have to run couple of command so I will give you those command also so at least you can run inside your uh instance inside your server right so here guys what I'm going to do I'm giving you this GitHub link just a second I'm going to paste inside the chat if you're not able to click on this link right so what you can do you can uh go through with the Google uh you can open the Google and you can search about s Savita GitHub so there you will get my GitHub ID and there just go inside my Repository and open this project open this gen AI project this gen AI so now guys see I already kept my project on my GitHub if you don't know about the GitHub and all then you must uh uh visit my previous session there I have discussed each and everything from scratch I'm not going to repeat those things otherwise we won't to Able we won't be able to cover the further thing further concept now here is what here is my uh here is my project right so I believe guys you all have you all kept the project in a GitHub itself you can uh download it from here as a jib you can clone it inside your repository everything is fine for me now but at least the project should be uh inside your system and then you need to upload in your GitHub right so this is my GitHub if you are opening it guys so this is my GitHub right so uh now what you need to do see if you're are going to Fork it that will also work okay that also you can do but the best thing what you can do just download it and keep inside your GitHub because uh whenever you are going to deploy it now so you're not deploying from my GitHub you are deploy from your GitHub so the project should be available over there because you will have to clone it now you will have to clone it right now uh here uh let me show you the ec2 instance right so how the ec2 instance uh looks like and all so the first thing guys what you need to do so I'm uh starting from very scratch no need to worry about it so just search about the EC tool so just open your uh AWS now let me show you about the AWS also um if you don't know about the AWS so here go open your Google and search AWS login so just simply search AWS login now here you will get a link so uh not this one actually this aws.amazon.com just open this aws.amazon.com just click on that and here guys here you'll find out your AWS right now it is asking to you uh would you like to create the account or you want to login so what I want to do I want to login because I already created an account and creating account is not a difficult task on a WS it's very easy it's very simple you just need to provide your detail over here whatever they are asking and simply create the account and it will accept your debit card also if you have enabled the international payment into your debit card so definitely you can add on over here and it won't charge anything first it will ask to you and you if you will approve then only it's going to cut it down cut down the payment but don't worry we can weev off also I will show you how you can weev off your money and you can delete the account if uh like you have launched so many instances and you generated like too long bill now here you can see this is what uh like this is a creating step like if you want to create an account now just click on the sign in Just click on the sign in and after clicking on the sign in right so here uh I already signed in so here it is giving me the homepage now guys uh what you can do so here you can search the ec2 instant just go inside this search box and here search the ec2 right right ec2 now click on this ec2 so after clicking on this ec2 right so it will give you the various this is the interface this is the home interface right of the ec2 so here it will give you the various options so no need to do anything just CL click on this launch instance right just just click on this launch instance so here after clicking in the launch instance it will give you one form right you just need to fill up this form and you will be able to launch your instance so you just need to provide some details over here and that's it so tell me guys how many people are following me please write down the chat and let me look into the doubt also so how much long this free generative AI boot camp will be so this a free generative AI boot camp uh like uh we are going to continue till next week so this week and the next week right so there is couple of concept which we need to discuss and couple of project as well so one basic project one advanced project and like few more concept do we need to learn ML and NLP learning for Gen VI please advise no ML and NLP is not see let's say there's different different kind of person so let's say if you're are beginner right and who don't know anything let's say who don't know anything and the person who want to start from the generative AI so for that person I already told you if you have a basic understanding of the Python then definitely you can start with the generative AI right so by learning the generative AI definitely you will be familiar with the basics of ml NLP and all automatically you will learn that but let's say there is one more person who is familiar with the ml statistic basics of ML and all right so yes the this is like a good thing he knows about the basics so definitely he can start with the generative a now there is one person who knows everything who knows about the ml DL NLP so that is well and good means um nothing can be better right so definitely the person uh can start with a generative AI so in every case you can start with a generative AI there you just required a python knowledge and if you are if you have a knowledge of the mlop if you have a knowledge of the NLP DL ml so yeah your understanding will be much clear over there getting my point so for every person the scenario is different so just think about your scenario but I would tell you that in every case in every scenario you can go with a generative AI right even nontechnical person can enroll who don't know about anything right anything about the programming and theend okay so guys uh how's the session so far are you enjoying it tell me did you open this AWS page if you have any doubt you can ask me in the chat and then I will proceed further do we cover any mlops topic yeah we are using the mlops concept only now tool wise yes we can use the tool so we can use DVC ml flow or different different tools like yeah we going to use Docker G already we are using right so uh whatever is required according to the infrastructure and all definitely we can use it right and don't worry in the upcoming project we'll show you that also yes you will get a python video over the dashboard yes uh Amrit fine so I hope uh here you can see uh like here I have the ec2 so here I have click on the ec2 and I click on the launch instance now here you just need to provide the name so if you like just provide the name any name over here so here I'm saying McQ generator right so here I'm writing McQ generator this is the name of my uh instance now once you will uh scroll down so here you will get a option uh like here they have provided you a different different machine right so they have provided their own machine own Linux system Amazon Linux they they are providing you the Macos they're providing you the Ubuntu Windows right redit is there so different different like variant different different variant you will find out of the Linux and even Windows server is there so here we are going to select this Ubuntu right so here we are going to select this Ubuntu so just click on this Ubuntu after clicking on this Ubuntu so here it is giving you the free tire but uh here my application actually I I cannot I cannot take a chance I'm not using the free tire over here so as of now what I'm going to do I'm taking taking any larger instance so here okay so free tire is fine now what I can do yeah free tire Let It Be Free Tire okay so uh how to select the major instance let me show you that so here is the architecture so keep it as it is and keep it uh like free tire this one now here guys just just see free tire eligible just just click on that just just click on this drop down right and here instead of the t2 micro just select anything right apart from this T2 micro you can select uh either this small or you can select this medium or large so here I'm going to select this large one because as of now I don't want to take any uh chance so let's say if I'm selecting this medium or maybe small so maybe uh with this particular system my uh like this app is not going to be launched or maybe if I'm installing the requ txt and all it is giving me some sort of error I'm not going to take any chance and here I'm selecting this T2 large but guys uh you can select U like this uh small one also and the medium one also right but in my case I'm I'm taking this large where it is giving me where it is giving me this uh 8 GB memory and here you can see the pricing and all but don't worry after the uh like after the session I will stop the instance right I will show you how to stop the instance now after selecting this instance okay after selecting the instance type what you need to do here you need to create a new pair right so create a new key pair so here for creating a new pair so once you once you will click on that it will ask the name right so here I'm giving the name so let's say the name is what uh McQ ke right so McQ key and here uh generate this a pem file right private key file format if you want to do SS or if you want to connect the this machine by using the puty or by using the SS so here this a key will help you right here this key will help you now create the key pair and it will ask you for the download so yes download it somewhere inside your system so I'm going to save it and I am done now you did two three things first you selected this ubu machine the second you selected this instance type and the third one you created the pair over here that's it now keep rest uh see here one more thing uh the fourth one actually you just need to click on this one right so just just click on this one just allow HTTP https and HTTP traffic also and keep it anywhere not no need to provide the specific IP address over here keep it 00000000 it's a global one and keep it anywhere uh you won't face any sort of a issue right so now guys this is done and one more thing I can do over here is asking to me a storage so I can increase the storage as well so instead of the eight I am going to take let's say 16 right so here is my storage right so here is my storage and I hope now everything is fine I just fill up the form and once I will click on this launch instance so it will be launching my instance so are you doing along with me are you launching the instance tell me guys now see guys it has launched the instance now once I will click on this one uh so it will show me the instance and here the status is pending as of now tell me guys uh are you doing it along with me are you writing are you doing are you deploying see I have already given you the code I already given you the GitHub you just need to download it and keep it inside your GitHub and then you can follow the steps I'm going very slow and don't worry I will give you all the step in a document format also yeah so let me refresh it and let me check it is working or not yeah it is running now so see guys my status is running right instant state is running now just click on this ID just uh click on this ID and here click on this connect button right so what you need to do here tell me guys so once uh so click on the ID click on the instance ID and click on this connect button after that here it will give you the uh like option so here again uh like it will give you it will ask you for the connect connection so just click on this connect and and now your machine has launched so this is the machine guys this is the machine which we have launched now we'll configure this particular machine according to our requirement right so this is a machine basically which I got from the uh AWS side which I launch over here now I will configure it right so for configuring this machine I have to run few step so the first step which I'm going to run over here the step is Pudo AP update right so here once I will write down the the Pudo AP update so my entire machine will be updated right so here my machine is getting update and don't worry I will give you all this command I will keep it inside the GitHub itself uh so let me do it first of all let me show you and then I will provide you the command right so here guys you can see I have updated the machine or what I can do I can open the txt and there itself I can write it down so all the commands which whatever I'm running now the First Command which i r that is that is what that is a suit sudo AP update so that was a command which I ran now after that I will run one more command uh so here on the terminal itself I'm going to run one more command that's going to be a Pudo Pudo a AP iph G update so this is a second Command right sudo AP hyen G this is nothing this is just a package manager right so this AP AP G so I'm updating it uh the machine so here now everything is up to date so sudo AP update and sudo AP hyphen get update now let me write it down here this two command so the next one was sudo AP hyphone G update right so this is the second command now the third command which I'm going to write it down here that's going to be a pseudo up AP upgrade okay upgrade upgrade hyphen y right so this is the third command which I need to run Pudo AP upgrade hyphen y now let me open the machine and here I'm writing Pudo AP upgrade gde upgrade hyphen y right so here you can see my um like machine is getting upgraded so this three command which whatever I have written over here you need to run it on your terminal for updating your machine right so yes it is running let's wait for some time yeah still it is running and it will take some time here is a command guys this one if you have launched the system uh if if you have launched the machine so you can execute this three command sud sudo AP update sud sudo AP hyphen get update sud sudo APD upgrade hyphen y right great so here my machine is updating and it will take some time until if you have any question anything you can ask me yeah so here actually I just need to hit the enter if you're getting this uh warning so just hit enter and again you need to hit enter over here right so once you will hit enter it will be updating it so what's the meaning of this three command so just look into the command what we are going to do I'm saying Pudo Pudo means for the root user APD update right so APD is a package manager and what we are going to do we are going to update our machine by using this up package manager right so here we are going to update and upgrade each and everything uh inside this particular machine and now everything is done now we have updated our machine here you can see we have updated our machine now I have to install something here right I have to install something over here now for that again we have a command the command is going to be pseudo AP install right pseudo a install I'm going to install this git I'm going to install the curl right I'm going to install this unip and here I'm going to install this tar make right and here I'm going to install this sud sudo Bim Bim is what it's a editor right now here does w get so these are the thing these are the like uh these are the thing basically these are the software we are going to install by using this sudo APD install we are going to install this git call unip tar make and this Bim editor and here is W get now once I will write down this hyphen y so here you can see everything is getting installed over here now here everything is done so now if it is giving you this particular uh window so you just need to hit enter and let me do one thing let meit enter yeah here also and yeah it is fine so it is done guys now let me check one more time let me copy and paste over here the same command and I'm checking everything is done or not yeah everything is done see here right this is giving me already the newest version newest version newest version right now see guys my machine is ready I have updated the machine I have installed every software whatever is required now what I will do here I will clone my repository right so here is my repository guys this one so here actually I kept the application the entire application whatever application I'm running inside my system now you just need to clone this repository over there on top of that server right so here is my ec2 instance and here if you will write it down this get clone right and just provide the link right just provide the link of your repository now here guys see uh here is a repository link and hit the enter so it will be it will clone your repository and you can check it also so just just type this LS and here you can see this is your repository now you will write CD here CD means what change directory so just write CD and check uh with this particular Repository so here guys you can see I'm inside this folder I'm inside my repository now WR LS so here you will find out out all the file so here we have a response streamlit experiment means one folder McQ generator my main file here you can see require. txt setup.py and test.py and test.txt so I have the entire file now guys see uh here actually we have we are using the openi API if you look into the EnV envir in file so here actually what I'm doing I am creating one variable the variable name is what open a API key but here one we have an issue right so what is the issue you cannot upload you cannot upload this open AI API key you cannot upload this open a API key on GitHub right if you're going to update it so automatically it will delete right so this open actually don't know like what type of codee they have written so if you're going to upload this uh like this key on any uh repository okay in any public repository automatically they will detect it and they will delete it right so actually we cannot upload this particular folder this EnV folder on my GitHub right so there is a issue there is a issue so what I will do here so I'm going to create the EnV folder EnV file over here itself in my machine so for creating a file there is a command the command is what don't worry I will give you all the command first let me show you first let me run it so here is a command the command is touch right so here if I will write it on this touch and here if I will write en EnV do EnV so you can see uh let me show you so here I have created this EnV file right so it is not visible let me show you with ls hyph a it is a hidden actually this do file actually it's a hidden file now you will find out this EnV yes we have this EnV file now what I will do I will open this file by using the vi editor VI or VI editor so once I will write down this VI and here I will write down this do e and V now here guys see I have opened this file now after opening this file you just need to press insert right in your keyboard there's a button the button name is insert just press the insert now you can insert anything over here now what I'm going to do so here actually in my local I have my openi key just copy the key from here and keep it inside your en so let me do it uh let me directly paste it over here after copy see guys so here open I key and I pasted it now after that what you need to do you just need to press escape button so press the escape button it will be saved now if you want to come out from here so for that you just need to press the colon colon and WQ so here you can see uh like in the bottom bottom left bottom so there I written cool and WQ now hit the enter and you will be out from the vi editor right so here I created a file the file name was EnV and inside that I kept my open key now now if I will write this cat Dov so here you can see whatever content is there inside the EnV file I am able to see on my terminal right so open a API key and this is what this is my API key now guys what I will do here I will install all the requirements into my machine so here we have a requir txt file so what I will do here I will write a simple command and see guys if you are using Linux machine if you're using Mac OS so instead of writing pip or instead of writing python you all you must uh uh you must write over here pip 3 right so here what I'm going to do I'm going to write down pip 3 pip 3 uh install pip 3 install hyphen R require. txt right so this is my file name now I'm installing all the requirement in my machine so here once I will hit enter so here you can see uh okay it is asking sudo AP install Python 3 fine guys so I forgot to install python over here it is giving me a command see as soon as I've return this P inst install hyphen ar. txd it is giving me an issue it is giving me an error that pip 3 not found because I forgot to run one command here the command was for installing the python so let me write it down over here Pudo Pudo AP Pudo AP install so here I'm writing sudo AP install and after installation after install what I will write I will write python python and Python 3 Hy pip okay okay so this is the command which you need to write it down Pudo APD install Python 3 hyen pip so once you will hit enter now here you can see now here you can see we are able to install the requirement so yes we are going to install this python now once I will press yes here so now I'm uh able to install it and it is installing in my system yeah so if you getting this warning just press enter and here also now everything is done so see guys uh here is what here is my complete python which I downloaded in my system which I installed now let me do one thing here what I can do on my machine itself I can install the requirement file so for that let me clear it first of all and here I'm writing pip install iphr requirement. txt now let's see okay pip install the command is PIP install inss install I think now it is perfect yeah so see I installing all the requirements over here what is the issue we faced yesterday on top of the neural lab there was not the issue actually if you will use my updated code right so I updated everything over there so uh like it will be running the issue basically it was the uh regarding dependency maybe it took python 3.8.0 because of that only it was giving me the library issue but if you are using uh now just do one thing use equal to equal to sign over there pip install sorry cond create hyphen uh cond create hyphen P environment name python equal to equal to 3.8 so it will take 3.8.8 right so it won't give you any such of uh any any issues and all right now here guys see I have installed the require. txt now what I will do here I will run my application right after setting up the machine after installing the python after installing the requirements and all now here what I will do I will be writing stre stream late right so let let me give you the command there is a specific command for that now here is the command so let me copy this command and let me paste it over here so this is the command guys don't worry I will give you all the commands and I will revise this thing uh then I will give you that so here is a command Python 3 hyphen M streamlit run and here I need to provide my file name I'm removing this app.py and here I'm going to write down streamlit app.py right so here is a like file name streamlit app.py so this is the complete Command Python 3 hyphen M streamlit run streamlit app.py right so let me hit enter now and here you can see my application is running now how you can access this application so for that let me show you so just go through with your instance right now here is the instance here you will find out the public IP address right so here you can see this public IP address just just copy this address and here just open your browser and um then paste your address after copying this address copy this U public IP address and uh put the colon and here you need to mention the port number so by default actually this uh this one this application ring on 8501 right on 8501 now if I will hit enter will I be able to run it no actually we haven't configured this particular port number right so what I need to do here let me open my application now here just go inside this security right and uh here just a wait so let me go back ec2 instance here is a instance yeah now open the instance by clicking on the ID now here guys you will find out so this inbound rule let me show you that inbound rule yeah so here just click on the security group right and after that you will find out the uh this particular rule so just click on this edit inbound rule this one after Security Group Security Group info and addit inbound Rule now here add rule right now just keep it custom TCP and here you need to write it down your port number so your port number is what 8501 and then keep it custom and click on this uh just select this one anywhere only now everything is done so here you need to keep it custom TCP then uh give your port number here and keep it anywhere that's it right now save the rules that's it okay and uh let me do one thing I think uh this is running so let me first press press control+ C and again I can run this particular application so yeah now it's perfect uh so just go through with your application here and here itself you will find out the here itself you will find out the IP address so let me open the IP address just a second instance running now this is your instance McQ generator click on that and here is your IP this one 52 this one this is your IP right 52. 20414 and 155 now copy this ID and paste it over here in your browser so now let me check 155 yeah it is correct so just uh press the colum and give 8501 now once you will hit enter so you will be able to find out your application over here just a second it is running let's see yeah so here guys you can can see I have deployed the application and now you all can access this particular application I'm giving you inside the chat and try to generate the try to generate the mcqs from here now let me do it I'm giving you this particular link inside the chat just click on that and try to generate it now here if I'm clicking on this browse file now it is asking to me it is asking me about the file so here I'm giving this a do just open it and give the number of cues let's say I want to generate four mcqs here uh write the subject name so my subject is going to be Ai and here write the simple and then create McQ and it is loading here you can see guys it is loading now see let's see it is able to generate or not are you doing it guys along with me have you uh like run any sort of a command don't worry let me give you all the command at a single place and then you can check you can run inside your system I will give you 2 minute of time yeah so here you can see I'm able to generate a quiz so what is the field of study that develops and study intelligence Machin so these are the choices and here is the answer right whatever correct answer is there now review is also their review about the McQ now click on this uh so just just go through with this URL and you also can generate now someone is asking me sir how we can save it right for saving the code prods for saving this McQ in a PDF file in a CSV file so already I shown you the code in my previous lecture if you will go inside the ipynb file so here I already kept the code so this is what this is what my code actually uh where is where it is where it is uh just a second just a second yeah so here was the code actually I converted into a data frame and here I converting into a CSV file now see uh I'm converting into a CSV file but you can convert the CSV file into a PDF or you can uh generate a direct PDF from here also right you just need to look into that and you can append this same functionality inside your end to application also so if you you you can give one option over there download option so whatever McQ you are getting now on top of your steamate application here itself see uh here uh whatever uh mcqs you are able to see over here right so you can provide one button over here right hand side download button so once the person will click on the download down the script will be running in a back end and you can download this McQ in a CSV file or in the form of uh PDF right so this you can take as assignment where you can append one button one download button and you can write it down the code write it down the functionality okay in a in a python actually you can uh like you can create one file or maybe inside that streamlet itself you can uh like append this download functionality right you can you can append this download over there and whenever someone is hitting the download this all the mcqs will be downloaded in the form of CSV right so just take it as a assignment and try to do it and you can send it to me on my mail ID or maybe on my uh yeah so you can uh ping uh you can ping me on my LinkedIn and you can post it over the LinkedIn also right so after creating this if you are going to post it over the LinkedIn I think that that is well and good so uh and uh yeah so let's say this is your first end project and let's say first time if you learning the generative definitely you should uh you must share the knowledge over the LinkedIn as well so you can uh post it over there and you can tag me and all you can tag the Inon I think that would be fine now uh here see we are able to create the application we are able to deploy it I haven't shown you the cicd one I this is the manual approach which I shown you I kept the cicd for the next project I can show you here also I don't have any issue I can write it on the workflow I can deploy the application that not going to be difficult but as a beginner first you should adapt the like basic approach you should understand the server and all and uh you should be familiar with the AWS and then in the next project we are going to do it from scratch right so I will show you the complete cicd and yeah definitely in our course uh we have included so many projects so there uh we are going to deploy it over the different different platform AWS a your gcp and we are going to use AWS ECR okay or this AWS ec2 app Runner and this uh like different different services like elastic code commit uh elastic be stall code commit even uh Lambda function right so different different uh thing different different Services of the AWS we are going to use and we'll show you how uh you can create or and an application in how you can create a production production based pipeline right so this thing is clear now if uh it is clear then definitely we can move to the next topic but before that let me give you all the command which is required and let me keep everything inside this uh txt itself so see the first thing what you need to do guys for deploying this application first login to AWS so first login to the AWS and here I'm giving you the link of the AWS so you can uh login with that particular link M just a second AWS login now let me give you the link of the AWS yeah so here first you need to uh log to the aw the second what you need to do guys you need to like launch the ec2 instance so search about the ec2 instance search about the ec2 instance now after search searching the ec2 instance what you need to do the third place uh you need to you need to configure configure the ubu machine ubu ubu machine machine right so that's the third thing now fourth one actually what you need to do after configure the one to machine launch the instance right launch the instance that's the fourth step after launching the instance what you will do after launching the one two instance so you need to update this by using a different command so I will give you all those command three command I have already written over here let me write it down the uh further command so here is the thing update the update the machine right so update the machine and here is all the command let me give you forur command uh here is upgrade now this is going to be a next one and here there is going to be next you need to clone your GitHub repository and after that there is a next command so sud sudo AP install this is the next now here uh pip install regard. txt and here this is going to be a next command for running your application so if you want to run the application now here is a command and the app name is what stream St stream lit app right so this is the command which you need to run right and then finally copy the IP and huh uh then what you need to do guys you need to add the environment file EnV file also so for adding that uh there is a command let me write it down over here if you want to add open AI API key so here the first thing create create Dov file Dov file new server right so create do EnV file in your server now here after creating this EnV file how will you will create it by using this particular command touch. EnV now here what you will do you will insert you will press insert so press insert insert and then write it uh no after creating that you need to open it and actually by using the vi editor so VI and that WR Dov then you need to write it down some command so press insert from your keyboard and after that after pressing the insert you have to write it down something so copy your API key and paste it there and paste it there the next one actually the next is going to be so after the copy you need to save it so press escape and then colon WQ so colon WQ and hit enter right so hit enter so that's going to be a step now after adding the API key what you need to do so yeah this will be done then uh this is the step for adding the API key now yeah inbound rule so go with your security go with your security and add the inbound rule right so here actually you need to add the inbound rule there add the port add the port 85 01 right this one so this is the complete detail of the deployment which I have written over here now let me copy it and let me paste it over here inside your inside my GitHub itself so here is my readme file uh I don't have readme file so don't worry I can edit create a new file my file name is what readme.md just readme.md and here yeah so this is the entire command which I kept over here now let me click on the commit changes and here I'm going to commit so see guys this is the entire process for the deployment okay now let me give you this link so you all can do it inside your system so this is the link guys uh which uh where I kept all the steps you can follow it and you can deploy your first and to and uh first application basically now tell me yes this file will be available inside the notes don't worry don't worry about it so let me check with more doubts this uh file you will get inside the dashboard see this is a dashboard guys this is a like Genera VI dashboard now again I can give you this link inside the chat and already you can see my team has updated right so inside the chat if you will check with the pin command so my team has updated the link of the dashboard right and just go through the Inon platform just just search about the Inon okay just open your Google search about the Inon and this is the homepage now here in the courses there is a section Community program so just click on the community program and here itself you will find out the category so just click on this generative AI so there you will find out all the dashboard so here you just need to click on the English one uh here we have a Hindi dashboard as well I'm taking the same lecture and On Hindi YouTube channel so yeah we we have a Hindi dashboard now here is a English dashboard and this is a community session of the machine learning so each and everything you can find out over the Inon platform let me give you the uh this particular link so that you can log in if you are new guys so that uh so please try to log in on this I own portal how how we can apply llm for business inside chat like interacting with DB and perform complex computation task yeah that only we are going to discuss now so we'll talk about that how we can uh like create a complex application here the foundation I think the foundation is clear to all of you now we'll come to the advanced part where we'll include the databases where we'll try to create few more application like chatbot and all and yeah that thing will be clarified to all of you just wait for some time so tell me guys how's the session so far do you like it so please hit the like button if you are liking the session uh and please do let me know in the chat also how's the session so far because we have completed a one phase now we are entering into the second phase yeah waiting for a reply so please write it down the chat you are not getting any link uh linkwise don't worry my team will give you that give uh that particular link inside the chat itself if I'm not able to paste it then but I past it actually I I can see here in my chat here we have already pinned one comment just just look into the Pinn comment so there you will find out a dashboard and you can navigate the entire dashboard and all entire website from there itself so just check with the pin comment so deependra has given to me this uh IP and this uh Port so let me check it is working or not he's saying sir I'm following you and this is my IP and my port actually no see it's a wrong I think just check once thein I think uh there is just like uh in IP V4 actually we have a four segment now so just look into your IP I think you pasted a wrong one see this is the correct right great so let's start uh with the next topic and that's going to be a vector database so we have completed a one phase of this uh Community session now it's a second phase of this community session where we going to start from the vector databases and then we'll try to do few more advanced uh like we'll try to solve few more advanced use cases so the first thing is basically what is a vector databases so how many of you know about the vector guys tell me do do you have a basic idea about the vector what is a vector and uh have you learned in machine learning in statistic great so I think uh we can start just allow me a minute great so let's start with the vector database few people are saying they know about the vector databases and the vector is nothing they have learned in a mathematic they have learned in NLP and all so uh let's try to understand the fundamental of the vector and the fundamental of the vector databases so if we talk if we talking about this Vector database so here you will find out that so we have a data right so this data actually we are going to convert into a vectors so Vector is nothing just a set of numbers right it's just a set of number geometrically I will explain about the vector in a lit term also I will about I will explain about this vector now here you can see this Vector actually we are going to store somewhere and that is called a vector database right so we have a data we are going to convert that data into a vectors and then uh basically this Vector we are going to store somewhere now here you can see one specific term the term is called Vector database now apart from that like we have other database also like SQL base database right we have no SQL databases so why we are not using those databases for storing the embedding for storing this data what is a disadvantage if directly we are storing this data into this SQL based SQL based database or maybe in no SQL database so what will be the disadvantage why we are converting this data into our vectors and then we are storing inside the vector databases so first of all we need to understand this a particular this this problem statement now uh for that what I can do let me move into the slide itself and here I have kept those uh thing now first of all uh let me uh show you that what all thing we are going to learn inside this Vector database so if we talking about the vector database so we're going to talk about what is a vector database why we need it what is the need of this Vector database how this Vector database is how will this Vector database work use cases of the vector databases some widely used Vector database that of like different different databases we have now so we'll try to understand the use of those Vector database will understand the Practical demo as well practical demo using Python and Lang chain so uh yes we are going to create an application there we are going to use different different Vector databases like pine cone and web chroma DV there are a couple of name and more than uh like uh this one actually three so we have other databases also one from the open a side so we'll talk about each and every database here so uh here guys you can see uh what we are going to learn so already I clarifi the agenda now see uh what is a vector database so a vector database is a data Bas used for storing high dimension vectors such as word iding or image aming right so either we can store images or we can store in in the form of we can store the images or we can store the text right so directly we are not storing over here we are storing in the form of Ming so first of all we'll try try to understand the meaning of embedding over here right so what is the meaning of the embedding which I have written now what I can do I can open my uh Blackboard and here I can explain you the meaning of the embedding which I was talking about so guys see whenever we are talking about Vector so let let me write it down the few thing over here so let's say uh here I'm writing one number right so here I'm writing let's say uh two so what is this two tell me so if I'm writing two over here so this is what this is the scale scal value right this is the scalar value now uh here if I'm going to write it down let's say uh something else let's say 100 so this is what this is also a scalar value right it's a single value it's a scalar value now if you if you want to like uh showcase this value in a geometrical in a geometry right in terms of geometry so what I will do I will uh create the axis so here let's say this is what this is my Axis and here somewhere actually my value will be available this data so here let's say there is a two there is a 100 something like that now uh here this is called the single value actually it is called the scalar value now if we are talking about the vector so what is a ve Vector so before explaining the vector actually let me uh talk about so here I can give you one uh example so what I can do here just a second let me draw the AIS so here I'm going to draw the first AIS this is my first AIS and here is my second now let me take this particular Arrow just a second yeah so this is what this is my first AIS this one and here is what here is my second AIS right now let's say uh here what I'm doing so I'm uh anting this thing this AIS with the uh direction right so this is my North this one and here this is going to be my South right this is my South Direction now here is what here is my East and this is what this is my West right so this is my East and here is what here is my West Direction right now let's say one person is here right so this one person basically one person is here right now how you will see uh let me show you one thing so let's say one person is going in this particular direction from here to here right so let's say one person is going here here here here here let's say there is some sort of a magnitude right so let's say the person is uh uh person is walking around 5 km right so this person is walking 5 km in which direction in East direction right so person is walking 5 km in each dire in each Direction so here we have a magnitude magnitude along with that we have a direction right so along with that we have a Direction so what is the definition of the vector so Vector in the vector actually we have a scalar value and along with the scalar value will be having a direction also right so this is what this is my magnitude and here is what here is my direction the direction is e East now let's say if I'm going in this particular direction so from here from my origin this is my origin right now from here I'm going in this particular direction let's say I'm going to travel 4 kilm right 4 km so here I can say that I traveled 4 km 4 km in North direction right so this is what this is my magnitude and here is what here is my direction right now let's say the person is going over here the person is here basically here here right so how you will calculate it right so how you will calculate the distance so simply I can do it by using the Pythagoras Theorem so what I will do if I want to calculate a distance from my origin to this particular point so what I will do I will uh like uh I will do it by using the Pythagoras thorum now here uh you will find out see this is what this is my 5 kilm and here is what here is my 4 km this is my 4 km now uh this is what this is my 4 km this one this this particular which I took from here and here actually tell me guys what will be the distance from here to here so here I will simply use the Pythagoras Theorem this is going to be a 5 + 4 is equal to how much tell me 25 + 25 + 9 so sorry 25 + 16 so here actually we'll be having a 16 now 25 + 16 how much U 35 and 41 iting right so underscore 41 now here actually this is the magnitude of the person means from here to here now if we are talking about the direction right so what will be the direction of this person so here I can write it down like this underscore underscore 41 and here I can write it down this northeast right Northeast Direction so this is what guys tell me this is my Vector in 2D so this is a vector in 1D this is a vector in 2D right so this is a vector in 1D this one this is also a vector in 1D and here you can see this is what this is a vector in 2D now here you can see this is what this is my magnitude magnitude of the vector and here is what here is a direction actually this is what this is the direction now you can see the direction any now let's try to understand this thing with our X and Y right so tell me guys this uh example is clear to all of you because I'm coming to the embedding and I I will explain you the embedding but before that the vector concept should be clear right if uh and if you are not going to understand the vector so definitely won't be understand the concept the embedding tell me guys this thing is clear to all of you are you getting the concept of the vector here which I drawn which I uh clarify tell me guys fast I'm waiting for your reply if you can write on the chat so that would be great and then I will proceed further yes the vector definition is clear to all of you great now here see let's try to understand the same concept by using the XY AIS so here what I'm going to do I'm going to draw the axis let's say this is my xaxis right and here is what here is my Y axis this one is what this one is my Y axis right this one now see uh what I can do just a second let me draw it one more time this is my y AIS now uh let me unoted this one so here is the X and here is what here is a y so this is my x one and this is my X y1 right so this is a negative this is representing a negative and this is also negative coordinate now see guys here uh let's say uh there is one point right at this particular location this is what this is my point right now will be having some coordinate regarding this point tell me x and y coordinate yes or no tell me yes so this coordinate actually this X and Y right in this 2D space right in this 2D space actually this coordinate is nothing this is a vector right this is the vector so if I want to represent right so if if I want see this is what this is my point in 2D in two Dimension space now from here to here there will be having some magnitude right so it is having some magnitude from here from Orizon to to this particular point so this magnitude plus this is what guys tell me this is the direction the direction which I shown you over here by using this north east west and by using this uh like north south east west right so here now instead of that I'm taking this X and Y just just look over here this is what this is my point and from origin to this particular Point actually we have some magnitude right so there is a distance and here is what guys tell me this is a this is what this is the direction this is a Direction X and Y so let's say let's say what I can do over here so this x and y coordinate I'm assuming that this x is around I think five and this Y is around let's say four so here I can write it down I can represent I can represent this particular Point like this I can write it down over here five and four and this is nothing this is my Vector so in mathematics what is a vector so in mathematics magnitude magnitude along with the direction right along with the direction now how we represent this a particular Vector technically so simply if I'm writing like this uh like if I'm writing like this X and Y right and whatever value we have of the X and and Y so this is what this is nothing this is my vector and it's a 2d representation of the vector now let's say in my Vector I have I'm having X Y and Z let's say I'm having this three thing x y z so this's a vector in 3D space right this is the vector in 3D space now instead of this one let's say if I'm writing uh X1 here I'm writing X2 here I'm writing X3 and up to xn so here I'm saying it's a vector in N Dimension space what is this guys tell me it's a vector in and dimension space now the term Vector is clear to all of you what is a scalar what is a vector and how to represent this Vector it's a representation of the vector right and I started from here from this a particular direction and I clarify clarify this thing over here right so how to represent the N Dimension Vector so this is this X and Y is nothing it's a 2d representation of the vector this XY Z is nothing it's a 3D representation of the vector and this this is nothing this is the and dimensional representation of the vector clear I think this part is clear to all of you now I'm coming to the next one here actually we are talking about the iding now what is this embedding so let's talk about this embedding let me write it down here the name is embedding okay now see guys whenever we are talking about a model right so here actually as a model I'm using the llm model which model U I'm using the large language model llm means what large language model there are several large language model from open a from hugging face from Google meta and all right you'll find out that now here actually I need to provide a data to this a particular model right let's say there is what there is my data which I'm going to provide to my model right now actually see this model is nothing it just done mathematical equations right mathematical equations so we are talking about the llm model so this llm model this large language model actually they are using a Transformer architecture they are using Transformer architecture as a base architecture which architecture Transformer architecture as a base architecture so here in the Transformer architecture we have two things one is encoder and the second one is called decoder right now just think about this encoder and decoder here actually what we are doing tell me here actually see we have a attention mechanism we have a neural network right we have a normalization so these all are nothing this is just a mathematical equations right ma mathematical operations we are going to perform now here the data let's say we are passing a text data right if are passing this text data to my model so my equation actually they won't adapt this text Data directly ly they won't adapt actually this text Data directly right they won't be adapting it actually this text data now uh in between actually what I I will do so in between I will encode it what I will do guys tell me I will encode this data right so what I will do I will encode this particular data now what is the meaning of encode so here in between actually I will perform the encoding now we have a various ways of encoding the data encoding is nothing it's just a numerical representation right it's just a numerical representation of the data right numerical representation of the data now we have two ways for encoding the data one is without so here uh the one is without without DL right which is simple frequency based method and the second is one with DL right with deep learning so we talking about without deep learning so there are couple of methods for encoding the data right so the first method which I can write it down over here that is I think you already knows know about this particular method the first method is a document Matrix document Matrix right so uh we create a document Matrix the second one the second method that is one that is called T tfidf method right so by using this TF IDF method also you can do the encoding so document Matrix is there this is also called like uh bag of words right bag of words now here you will find out the the third one let's say n g is there and the fourth one let me write it down here tfid is there andram is there document Matrix is there here you will find out one hot en coding right so this is also a technique now one more technique is the integer encoding integer and coding so this is actually uh like uh this is a without deep learning I converting a data into a so without deep learning I'm going to converting a data into a numeric uh I I creating a data into a u uh like I'm showing the data in a numeric U I'm doing a numeric I'm showing a numeric representation actually right so here we have a document Matrix DF IDF engram one encoding and integer encoding now there are several there are some disadvantage of this particular technique then I will come to this with DL okay let me write down the name also like with DL technique so here you will find out word to back right word to back is there which is very famous technique the second technique uh which has been prop proposed by the Facebook site that is a fast text now the third one you will find out that a Elmo right Elmo now here uh the fourth one what to back is there fast Tex is there Elmo is there even BT is there by using the B and and coding we can do that right so DL based technique now there is one more technique that is called this one glove Vector so actually glove is not DL based it's a metric Matrix factorization based right so Matrix factorization it's a matrix factorization uh method right so this glove Vector now we have so many technique for encoding data right now here if we are talking about this uh this particular technique where we are just like talking about the frequency of the data so there are several disadvantage of this right so definitely we are going to convert our data right from uh text to numeric uh text to numeric value right we are doing it by using this particular method but here are several disadvantage the first disadvantage actually which I can write it down over here that is what that is a uh like by using this technique right so at we we are by using this particular Technique we are ending up with the sparse Matrix right so we are ending up with the sparse Matrix what is the meaning of the sparse Matrix so in the sparse Matrix you will find out there are more number of zero there is less information right so that is called a sparse Matrix now the second is what this is here actually you won't be preserve your context right so here actually you won't be able to preserve context now you this this embedding this this number this a numeric representation basically which you are getting of your data this is meaningless right this is meaningless so here this is going to be a meaningless and you won't be able to preserve any sort of a context right so if you are going to convert your data right if you are going to convert your uh data into a numeric value by using this particular technique I'm not going to I'm not going into depth actually I I can show you the uh how to calculate and all but as of now I'm just giving you the overview advantage and disadvantage so by using this technique there is these U there is a different different like disadvantage of it there is two major disadvantage which I have highlighted one is sparse metrix and the second one is context contextless right so meaningless there is no there won't be any such meaning actually whatever vector and the numeric value which you are going to generate right now over here see if we are talking about our data let's say we are talking about the text here is a what here is a text so text is nothing actually here it's a collection of sentence right sentences now it's a collection of the phrases don't worry I will show you each and everything practically by using the python and here in the sentence phrases actually you this is the collection of words or tokens this is called word or it is called a tokens right fine now whenever we create whenever we perform this uh particular when whenever we use this particular technique so how we do that so let's say we have a data right we have a text so from that particular text what we do we generate a vocabulary right so we create our vocabulary and here let's say first what we what we do we create the vocabulary uh I hope the spelling is correct so we create our vocabulary and by using this vocabulary we perform the end coding right we perform the end coding so here we have a sentence we have a text we have a data now by using this data data after cleaning and all so we perform the cleaning so here we perform the cleaning and whatever data and all which I get and uh we collect the data we we we call it as a we call it vocabulary actually and by using this vocabulary we create the end coding right we create the end coding now over here see uh okay this is fine but here I shown you that we have a several disadvantage now um like there was several disadvantage of this particular technique and the major disadvantage was uh contextless okay contextless or meaningless because of that actually we were not able to retain the information so here a few more technique came into the picture this word two back actually it's a very famous technique this one okay is the old one also it's a famous one also now here the um the concept came into the picture the concept name was iding right so here see we were having the disadvantage inside this particular technique now the concept came into the P picture the concept was the iding concept so here what was the embedding concept so embedding also it's a numeric representation of the data so let's say we have a data now this data actually if I'm going to represent numerically so that is nothing that my embedding right so this embeding is nothing actually this was the vector right this is what this is a vector and what is a vector vector is nothing thing it's a a set of numbers right so we talking about the vector it is a set of number and how to showcase the vector how to represent the vector I already told you we represent the vector in this uh square bracket right technically if I have to represent the vector I represent like this and mathematically if I calculate it so yes so we talk about the direction plus magnitude so here m means what magnitude plus Direction so that is what that is a vector so we have a embedding so this embedding concept came into the picture now here also we are representing a data in terms of numeric value but the way was little different right so here actually we were able to achieve two things first one actually we are able to achieve the dense Vector right we are creating a dense vector and the second thing was the second thing was we were able to uh like sustain the meaning also so context full right context so context te X context full meaning right context full or meaningful meaningful right so we are able to achieve this two thing by using this embedding now let's try to understand this embedding by using this word to back so here again I'm not giving you too much detail regarding this embedding and all U regarding this word embedding es uh esip gr right or CBO method scheme gra method right so there are different different method we have inside the word itself but here uh let me give you the high level overview that how it was working why I'm doing that because the next concept is directly related to the embedding only if you're not able to get it uh if uh this Basics uh if the basics won't be clear here that definitely you will face a several issues so that's why first I'm clarifying this a basic thing so tell me guys are you getting it right so whatever I'm trying to explain over here regarding the vector embedding data different different technique of the embedding so are you getting my point yes or no tell me are you able to understand the concept if you are getting it if you are able to understand that please hit the like button please let me know in the chat yes tell me so I think people are writing now yes great okay fine so we are having the concept of the word to back now let's try to understand this embedding right now here uh what I can do I can give you one one example so let's say here is my sentence right so here I can give you one example actually so by using that you will be able to understand the meaning of the spark and the dense vector and you will be able to understand why we are not able to sustain the uh context also right so the example is very very simple let's say here I'm writing my my name is sunny right so here I'm writing my name is sunny now the next one is what let's say here I'm writing sunny sunny is a data scientist and here I'm writing Sunny is working Sunny is working for I neuron right so Sunny is working for I neuron so first thing what I will do so the first thing basically I will generate my Bo vocabulary right vocabulary so for generating a vocabulary uh so here I will find out the unique words so there is my first word second word third word fourth word fifth word sixth word right now here A S 8 n so here what I will do I will create my vocabulary so in my vocabulary I'll be having nine words so one is my one is name you can remove the unnecessary words and all by uh using the text cleaning techniques so here my name is sunny so this is my fourth word now here is a data science right now here word word and for and here we have a i neuron right here we have a i neuron so these are my vocabulary 1 2 3 4 5 6 7 8 9 right now let's say I want to create a one hot and coded Vector one hot and coded vector for this a particular sentence for which sentence guys tell me so I want to create it for this a particular sentence for the first sentence now if I want to represent the my inside this sentence what I will do here so here for my I will write it down the one and for rest of the value I will write down the 0o so 0 0 0 5 6 7 8 9 so this is the representation of my first word then I will write down the second word so here is name so here for the name actually there is 0 1 0 0 0 right 0 6 7 8 9 so this is my second word like like this there will be my third word so here let's say this is my third word so the third word 0 0 1 0 0 0 0 5 uh 4 5 6 7 8 9 and here is what here is my fourth word so fourth word is sunny so 0 0 uh 0 1 0 0 so 1 2 3 4 5 6 7 8 9 so this is a this is my one sentence actually this is my first sentence which I uncoded which I uncoded so let me write it down over here this is what guys tell be this first sentence which I encoded by using the what hot encoder now see guys how much sparse this is so how much sparse this is right and here there is lots of zero and this might a contextless in a longterm sentence right it might be a meaningless so here is a example of the one H and gon and whatever techniques you will find out yes a tfidf is a better one even Google was using this technique for a long time now it uh replace this tfidf technique by this embedding one only because this tfidf it's it's a research of the Google right document Matrix it also work in a similar way like this one hot encoding somehow right so somehow it works with a one hot n coding right this uh document Matrix now we have TF IDF TF IDF is a better one NR is also there I will talk about the NR and here is a integer n coding so we U like code this value with the integer number right now here is the example of the one hot and coding now I will explain you the concept of the embedding by using this word to back that how this word to back is working so tell me guys is it clear to all of you so far yes or no think it is fine so just a second great so I hope uh this still here everything is fine everything is clear and uh just a second yeah it is uh clear now yeah great so let's talk about this word to I'm not going into the detail of word to back I'm just trying to explain the concept of the embedding only here right so how it was working so here guys if we are talking about the word to bag see let me do one thing over here what I can do I can uh Show You by using the example one example right so see let's say we have some data right so let's say we have some data and from that particular data what I did I created my vocabulary this data is nothing it's a text data right it's a text data and from this particular particular data I'm going to create my vocabulary right so let's say this is what this is my data and here uh this is what this is my data data in the data basically you'll find out the vocabulary so we are going to generate our vocabulary so here will be my some words and all now see if we are talking about the embedding now inside the embedding what we are going to do so we are going to create some features right so the first thing actually the first thing is what the first thing we are going to create the vocab and second thing is what we are going to create a features right features from this VAB okay we are going to create a feature from this book app now let me give you one example that how the feature and the book app looks like so there is one famous example very famous example let me write it down over here so let's say there is my book app which I'm going to write it down over here uh in the book app let's say we have some data and from there I I have extracted this book right vocabulary so in the vocab actually we have some value let's say there is a king right let's say there is a queen this is very famous example that example only I'm going to write it down over here that uh we have a king queen we have a man right we have a woman and we have one more word let's say we have a monkey over here right so this is a like wab actually which I have extracted from where from my data itself right you can assume that we have a data this is what this is my vocab now here actually you will find out some feature right so my feature is what let me write down the feature also so the first feature actually uh that is what that is a gender right so here the first feature is what the first feature is a gender the second feature which I'm going to write it down over here that is what that is a weth right the third feature which I'm going to write it down here that is going to be a power right the fourth feature is going to be a weight right weight and the third fifth feature is going to be a speak now see this vocab right and this feature right so everything is being done by the neural network itself neural network will automatically take care of it right so actually we have to pass this uh bab and it will automatically look into the features right this particular feature actually the feature which I have written so here what I will do I will create my data in such a way there we'll be having a vocabulary and we'll be having a neural network we'll be passing that to my vocabulary and my feature will be create and in between basically whatever Vector I'm going to generate that Vector itself is going to be my embedding right so here how the vector looks like so this is the high level representation of that mathematical so whatever complex mathematics is there now it's a high level representation of that that's it now here let's say we have a king we have a queen we have a man woman and monkey this is my vocabulary and this is my uh feature now here see guys we are going to assign a weight right to this particular vocab right we are going to assign a weight the weight value will be from 0 to 1 right so here I'm saying King King is having a Zender right so here I'm saying yes it is having a Zender means one now Queen is also having a Zender right so here actually uh what I'm say say king is having a Zender now Queen is also having a Zender right uh here I can write it down the one now here I can write male also so you can say uh let's say the gender is going to be male female so you can specify you can specify let's say if the gender is going to be male over here this one now in that case what you will say so for King actually you will write it down one right so here let's say the gender is specified that is male so what you will do for the king you will write it on the one and and for the queen you will write down the zero right here the men yes it is one woman actually it's a zero and monkey let's say it's a one right I'm talking about the monkey it's a male one now if we are talking about the wealth right so again I will provide some sort of a number over here see to the vocabulary I will assign some number based on my feature okay so wealth yes King is having wealth so here what I will do I will assign one now Queen is also having wealth so I will assign one over here now if we are talking about the men so Men actually it's not a king right so men is not a king so they it might have a wealth or it might not have a wealth right so here I'm not going to assign a one so between this 0 to one I can assign any value this is going to work as a weight right so here I can assign 0.5 over here this woman also same right so it is having a less wealth compared to men let's say 0.4 and monkey is not having any sort of a wealth so here I'm going to write down the zero now if we talking talking about the power so definitely King is having a power Queen is also having a power but maybe less than to this King so here let me write down let's say 0.8 now here let's say this man is having a power let's say it's having very less power 0.2 this woman is having a power let's say 0.2 and monkey is not having any power now if we are talking about the weight definitely King is having a weight 0.8 now let's say woman this queen actually it's a more than this King in terms of weight so here I write down the 0.9 men also is having a weight right say uh is having 0.7 and this is 0.8 and monkeys also some weight let's say 0.5 right so to this vocab based on this feature I'm going to assign some sort of a numbers right and here let's say speak so yes King can speak Queen can speak man also can speak now here woman can also speak but monkey cannot speak so here is a zero so now you will see that this is my first Vector see this is the vector of the King right this is the vector of the king so here I'm representing the King by using this particular Vector now if we are talking about the woman so here is a vector of the woman guys this one sorry this is a vector of the queen this this particular Vector now if we are talking about the vector for the main this is the vector of the main I'm going to represent main by using this particular Vector now just look into this example where I was representing Sun by using this Vector now compare this vector and this type of vector see this Vector is actually this Vector is dense Vector right this Vector actually it's a dense vector and it is having more meaning right it is having more meaning it's not a meaningless it's having a meaning which I have uh which I can uh basically uh it is having a meaning which I can prove it also now this Vector whatever Vector I have designed over here it's a 5D Vector it's a five dimension Vector right now guys see I told you uh about the two Dimension Vector now let's say here uh if I'm going to draw the two Dimension Vector so this is my two Dimension Vector this one and how to represent this vector by using this x value and Y value now if I'm writing about the king let's say this is what this is my king right so here how to represent the king Now 1 1 1 0.8 and 1 so here is what here is my king Vector now tell me guys this King Vector actually it is in five Dimensions so we cannot draw it like this we cannot draw it like this so see the word to W model the word to W model which Google has strained it was a model from the Google right so this Google has Stained this particular model on a news article on a Google news article and actually uh the vector they have created the vector Vector which they have created over there the vector size was the 300 Dimension right so the vector size was the 300 Dimension so here I have just given you the Glimpse right with a few vocabulary and the feature now here uh if you will look into the real word to model which you can download from thei or maybe from any NLP Library like nltk and all so the dimension you will find out of each Vector which is going to be a 300 right which is going to be a 300 so this is called embedding now here here guys see whenever we are talking about whenever we are talking about neural network so in a neural network what we are going to do so in that actually we have three layer one is a input layer the second is called a hidden layer the third is called a output layer so here actually what is happening see we are passing a input we are passing input now what we are passing over here what we are passing to this uh what we are passing to this neural network so here actually we are passing this a particular feature right this a particular feature so we are passing this particular feature and we are assigning some weight and at the end actually at the end at this particular layer in the output layer whatever Vector I will get right whatever Vector I will get in the output layer so that itself is called is going to be my embedding right here I have given you the high level overview how the bend how the embedding is going to be generated but the same process is going to be Auto by using this neural network and here what feature we are passing which feature we are passing so what I will do I will create one recording right for the word to back along with the python implementation there I will show you uh like how this word to back is working in actually actually right so here U yeah this is all about the embedding so embedding is nothing it just a vector and what is a vector you already knows about the vector so here you can see I clearly given you the explanation about the vector so what is a 1D Vector what is a 2d vector and if here let's say we are going to write down the five value right so that is a vector in a five dimension so we cannot draw the five dimension that's why I'm not able to show you that a 5D Vector but yeah if we are going to represent it let's say uh here what I'm going to do so let's say if I want to represent this five as of now just going to draw it in 2D itself so let's say this is my king Vector this is my king Vector now this King Vector will be near to this queen vector and this monkey Vector actually it will be far from this king and queen now this king and queen so this man and woman right so this is what this is my king and this is my queen now here let's say this will be my a main vector and this is what this is my woman Vector so this will be near to each other this king and queen Vector will be near to each other and here this monkey Vector will be far from each other and here let's see if I'm going to uh what I'm going to do guys so here let's say I'm going to uh substract this king from this queen and we are going to add something let's say men right so just just look uh just see what you will be getting after doing uh this much of like calculation over here right so you can subtract the vector from each other you can add it and you can make a new meaning over there right so the new meaning also will be a vector which will be representing some sort of a information right so here is all about the word embed and all so I just given you the introduction because I want to make a foundation as strong as much and here uh you can see why we need Vector database here uh there are different different uh database name here is a example basically which I'm showing so in tomorrow's session I will continue with this particular slide and then directly I will move to the Practical implementation where we are going to talk about a two database so initially I will start from this chroma and this vient right oh sorry this spine cone so first I will try to discuss this coma and the spine cone and if time will permit then I will come to this F also this F is a uh this F actually it's a vector database of the meta AI Facebook AI so yes definitely two database we're going to discuss in the class itself chroma and pine cone and there what we are going to do we are going to store iming and you got to know about the Ming guys Ming is nothing it's just a vector it's just a number which is having some semantic meaning and how we are going to do that we are going to create a feature which we are passing to our neural network and some uh like mechanism is there and based on that we are going to uh generate the vector so tell me guys did you like the session whatever I explain you over here did you understand each and everything how much you would like to rate the session if you liking the session if you're liking the content which I'm showing you in depth so please hit the like button please support support the channel so it motivates to me also and please write your answer in the chat if you're liking the session if you're liking the content and even the explanation also tell me I'm waiting for your reply so please uh tell me guys uh write it down in the chat yes did you learn something new did you understand uh whatever I have explained you that deployment all and the what Vector databases and uh here uh you will find out the session after the uh like see here is a session guys on top of the dashboard so just enroll to the dashboard here is my dashboard this one just enroll to the dashboard and uh you'll find out the session over here itself and even along with the resources this handwritten resources and all everything will be over here and uh yeah and subscribe the on YouTube channel we are uh all the thing is getting updated and here uh the recording also will be here great so fine I think now we can conclude it so today we have talked about the deployment and the vector database okay just go through the dashboard and download it then to check with the so this assignment and all so just click on the assignment and uh try to solve this assignment and then you can submit it also after solving it so let me show you how the assignment and all it look like this one yeah so here is assignment guys see you can okay so you here on itself you can write down the answer uh whatever questions of we have given you and then you can submit it directly okay great so I think we can start with the session and in today's session we'll be talking about the vector database so we'll Implement also we'll discuss about the pine cone database Vector database I will show you how to do setup how to do setup of the pine cone database and uh I will try to create a small bot also and in the next class I will show you how you can Implement end to endend chatboard got it so we'll discuss two Vector database in today's session I will be talking about the pine cone and in the next class we will be talking about the chroma DV so so there is two database which I'm going to talk about and we'll try to discuss the concept of the embeding and all and I will show you how you can uh generate the API key regarding the pine cone how to create an index how to create a cluster each and everything we'll talk about in today's session so so far I discussed so many thing in this community Series so first of all let me show you all those thing so for that guys what you need to do you need to go through with the Inon website and here you need to uh go inside this course section just click on this course section and here you will find out this community program so just click on this community program there are various uh option you will find out like DSA generative AI machine learning and SQL so just click on this generative Ai and here here we have a dashboard for the generative AI now there you will find out two dashboard one is for Hindi and the second is for English uh so just click on the dashboard now here uh you need to sign in first so after sign in actually uh first need to sign up if you are new on this portal and then you need to login and finally you can enroll inside the course so this is completely free we are not charging anything for this particular course now here I already enrad inside this course so here I just need to click on this uh go to course so here uh guys uh let me show you the dashboard this is the dashboard so so far I covered uh eight sessions so far I discussed like so many thing and I this is Day N actually and here you can see the till day 8 and yesterday I talked about the vector database I talked about the deployment as well if you will go and check with this particular session so I discuss about the deployment as well in the initial in the initial class and after that I move to the vector database there I explain you the theoretical concept regarding the vector vector databases and all I talked about the embedding and now in today's class we going to implement all those things so here uh just click on the resource section you will find out the resources actually here u u okay I already shared the resources so in some time uh it will be available a over here but if you want the project if you want the resources so uh for that you can visit my GitHub also there I uploaded my uh there I uploaded the project the project which I have implemented and all the steps regarding the project so how to deploy that and also each and everything I have written over here inside the readme file so let me show you that where it is uh the AI yeah this one so just uh go ahead with this particular uh go ahead with this particular link this particular project so here you just need to search s Savita giab there you will find out all the repository you will get my repository uh and then uh just go ahead with this generative AI this is your project and there is all the steps regarding the deployment and all don't worry in sometime it will be available in the resource section also so I already share with my team and they will be uploading inside the resource section got it now here uh see uh this is all about the deployment but apart from that I talked about the vector databases now Vector database wise I have discussed the theoretical stuff only so what is a vector how the vector database Works what is the meaning of the embedding what is the pros and cons of the embedding and the uh like different different encoding technique each and everything I talked about over here now in today's class we'll see the implementation of it uh apart from this apart from this uh okay so here is dashboard now apart from this resources and the lecture you will find out the quizzes and the assignment also and after completing this course so which we are going to complete soon because this is just a foundation course so we are uh we'll be taking uh four to five more classes and after completing this course you can generate a certificate from here so just click on this particular option and you can gener generate the certificate after completing this course right so you will get get a certificate for the foundation generative AI uh so this is the name of this course and apart from this one uh so apart from this basic course you will find out one more course over the Inon platform so for that uh just go inside the course section right here itself and uh let me show you just uh click on this generative a right so once you will uh go with the course and here you will click on the generative AI now inside that right inside that you will find out on the paid course right which we are going to launch next month next month from 14th January onwards so our first class will be on 14th January onwards and here you'll find out like we are giving you the discount and all so 40% discount is there and uh the price is as of now 6,000 you can talk about talk with our sales team and all they will give you the detail uh they will give you the complete detail regarding this particular course now the timing will be from 10 to 100 p.m. IST in morning morning and here after the time after the like class we have a doubt session also which is going from 1 to 2 not 1 to 2 basically so until we are not going to solve all the doubts and all so definitely we'll be uh we'll be taking the doubts okay and that will be the live doubt session only where you can interact with the mentor whoever taking class at that particular time means um in a live class itself so yeah definitely you can ask the doubts in a live doubt session right after the class now this course duration is around 5 month and the mode will be in English uh okay so the date basically we have modified uh so the date is going to be uh this course is going to be start from 20th of June right now apart from that you will find out the instructor so here is the instructor of this course Chris sir sudhansu sir me and buy so these four will be your Mentor who is going to take this entire course and now here you will find out the curriculum also so this is the curriculum which we have divided into several mod modules so you can go through with the curriculum we have covered each and every each and everything which is like industry relevant and from basic to advance we are covering each and everything about the generative AI embeddings or a large language model different different Frameworks open source model fine tuning and apart from that U like there are so many things security comp compliances and all which you're going to talk about after creating a project uh evaluation matrixes of llm each and everything what whatever required on the industry level uh whenever you are going to work on any sort of a use case on any sort of a project which we are going to discuss over here right so here you can uh go with the website you can check about the curriculum and if you uh want something if you have any sort of a query you can directly ask me you can connect with the sales team they will be clarifying it now this is all about the uh course right so I hope guys uh you have seen on this particular course now coming to the the YouTube channel so uh where you will find out all the video apart from the dashboard so here let me show you let me search over the in neuron so this live is going on and here uh see guys uh once you will click on the uron YouTube channel uh go inside the live section there you will find out all the recordings uh like whatever uh we have discussed so far inside this community session so it is in a live section you can go and check and you can uh learn from here also and if you want a detail so each and every detail we have kept inside the description so once you will check with the description of this video you will find out all the details over here right so I hope uh this is clear to all of you now if you have any question you can ask me and then we'll start with today's topic so how work llm with insight and complex calculation on business data so definitely we're going to talk about it in our uh project right so there will solve a different different use cases and all here uh actually I shown you that how to call the API how to read the models and we have solved one basic problem statement that is McQ generator so uh business wise organization wise specific uh use cases wise also we can use this uh like llms and all and definitely be talking about in our different project in our other project and there will'll try to discuss more about use cases more use cases basically use cases application and their domains okay which one will be good for the streaming data Vector so as of now we going to talk about the Vector database and right after that I will discuss about more Vector databases and the graph databases also right so as of now uh the vector databases actually it is good right and I will give you the comparison and all uh while I will teach you that so don't worry just uh be in the class everything I will be clarify here itself in the live class okay so if you have any sort of a doubt guys you can ask me you can ask me in the chat I uh up for the questions and the s how to design the prompts and all so guys here if you will see uh if you will look into my session which uh where I have discussed I think each and everything right so on a foundation level so there I uh took a uh like a few specific time for The Prompt also right so how to design The Prompt what is the meaning of the different different prompt how to construct The Prompt what is a a few short prompting what is a uh like zero short prompting each and everything I have discussed inside my session now how to uh design The Prompt so you will definitely will get it once you will go through with my session so uh I would request to all of you if you haven't attended my session and if you are asking any question related to The Prompt LMS and all so first visit my session and then automatically this all the doubts will be clarified okay how organization has hesitant to adopt generative AI so just go and check with my first session uh where I have discussed the detail introduction of a generative AI why the organization should use the generative AI what is the pros and cons if we are going to train any model from scratch if you are using any pretrained model which has been uh trained on a huge amount of data how we can reduce the cost and how we can get Effectiveness each and everything you will get it in my first session so please please check with the day one after this session and there I discuss everything regarding to regarding to this generative AI okay great so now I think uh we can start with the yeah we are going to discuss about the chat interaction also chat interaction with the database and in today's class itself in today's session itself I will show you this thing got it so finally let's start with the session let's start with the topic now the topic is what the topic is a vector database don't worry guys here the project will be available here inside the resource section if you will uh check with the day eight so uh there uh I will give my GitHub link I already Shar with the team and within a uh like uh within few minutes they will upload it over there got it now uh let's start with the session uh so today actually we're going to discuss about the vector databases yesterday I given you the introduction of this Vector database now let's see how does it work now uh if you will look into this slide so here I have mentioned each and everything that what all thing you're going to learn so what is a vector database why we need Vector database how Vector database work use cases of the vector database widely used Vector database right and practical demo using Python and lenion and there we are going to use open AI as well so these are the thing basically which we need to understand related to this Vector databases and yesterday I already given you the introduction about it so here I I have written each and everything on top of the Blackboard and I try to explain you that how this Vector database works right so there are like so many technique okay so Vector means what Vector I here I explain you what's the meaning of the vector in a layment term and there I have explained you about here I have explained you about the vector right so how to uh Define the vector how to write the vector it's nothing just a set of value and how to write it down so we we write it down u in a square bracket right so here actually see this is what this is my Vector which I have written so there might be a column Vector row Vector each and everything I discussed in my previous session right now after that I talked about the encoding so let's say we have a data and that data we want to pass to my model now uh here uh in between actually we'll have to perform the encoding of the data because we directly cannot pass the data to my model right text we cannot pass to my model because model is nothing just a mathematical uh equations so uh yes definitely it won't be able to uh like calculate something by using uh those Text data so definitely we'll have to convert those data into a numbers so for that we have a different different techniques if we are talking about deep learning so where we have a two technique right so first is without deep learning the second is with the Deep learning now in the without deep learning you will find out like there are so many Tech so many like techniques so here I have written couple of which is very very famous like document metrics TF IDF NR one hot end coding and integer end coding which we generally use while we are doing a end coding and here right hand side I have written a technique which work along with the neural network so word to is there fast Tex is there Elmo is there b is there Transformer itself is there right glove Vector is there but it's not a dbased technique I told you that it's a metrix vector ition based technique so here I'm not going to uh explain you the mathematics behind uh such techniques whatever I have written over here uh here I'm just giving you the Glimpse I'm just uh talking about the vectors I'm just talking about the embedding that's why I given you this overview got it because uh if I'm going into the mathematics so uh only one week will be required for this and coding techniques for the word Ting and all uh along with the implementation so here I'm just giving you the overview and trying to explain you the meaning of the embedding and vectors so if I was talking about the uh like here I was talking about here the uh disadvantage of this uh frequency based technique which we are using without uh DL means without neural network so here actually see this was the disadvantage of this particular technique so first was the sparse metric if we are using any such metrics right so any such technique like document metrics DF IDF andr one hot encoding or integer encoding so they actually uh we are going to generate a sparse Matrix but let's say we are not going to generate a sparse Matrix but in a long time we are not able to sustain a context it is going to be a contextless or meaningless okay now here uh it's going to be a contextless or it's going to be a meaningless uh this particular technique so that's why this edding concept came into the picture it is also a vector but it's a dense Vector right and the uh way of generating this Vector is little bit different compared to this technique now here actually we are using a neural network we are going to design our data in such a way so uh we are having two column one is a uh like uh independent column and one is a target column and then we are passing that particular data to my model and automatically it is generating so automatically it is generating a vector right so how it is doing that how it is going to create a like independent column and how it is going to create a text uh this target column so that's a like uh uh itself U like uh there is a separate process for that and definitely uh I will uh record one video for that uh like one end to end video for the hand coding techniques and all and I will put over the Inon YouTube channel so you can go and check in uh detail right so there I will I will be writing all the mathematical equations and all as of now just giving you the intution so here I given you the intu intution one high level intuition how this uh techniques is working this award embedding technique so here is the sparse metrix or sparse sparse Matrix which I have created so uh here you can see this is what this is my data so from this particular data I want to I will generate the vocabulary and based on so this let's say this is what this is my vocabulary over here now from that particular vocabulary I'm going to generate my Vector so here I given you the example of the one h encoded vector and you can see here this is very sparse Vector right this is very sparse Vector which I have generated regarding this particular document regarding this particular sentence right now if we are talking about the word embedding now how it is generating a vectors right how it is generating a vectors regarding the data so see let's say we have a data and from that data I'm going to create a vocabulary and from those vocabulary I'm going to create a features so here let's say this is what this is my vocabulary and this is what this is the feature so we'll assign the value between 0 to one to each and to each and every vocabulary based on a feature so here you can see uh I'm talking about the king so King is having a gender yes so here is one Queen is having a gender so she's U she's female actually so here is a zero I'm talking about the male here so man is one woman is zero monkey is one so like this uh I will be giving a number and this is what this is my one vector this is my one vector which is representing this King based on this particular feature now if here if you will look into this particular Vector so this is a dense Vector right which is having so many information compared to this Vector which is a sparse one right and where we are not able to sustain any sort of a context so this is what this is called a word embedding now uh if we are talking about a word embedding technique so it has been invented by the Google and they have trained the neural network on a huge amount of data that was the Google new news article right so uh the model basically which they have trained if you will look into the model if you will download the model so there you will find out a vector which is having a 300 dimension in every Vector actually they have a 300 Dimension so you can use the pretrain embedding you can use the pretrain embedding if you are going to trainum model uh so you can pass the data to that particular model and automatically it will generate a aming based on a pretrade model or else you can create your own m meding as well both thing is possible so in our case actually we are going to use open Ming so I will show you how to use open AI eding open AI also is having one uh class so edding class by using that we can uh generate a embedding so whatever data we have we can pass to that particular model and we can generate a embedding right so don't worry I will show you that how to generate a embedding from the openi class from the openi model and here is just a glimpse of the word aming which I shown in my previous lecture so I hope till here everything is fine everything is clear now let's move to the vector database tell me guys everything is fine everything is clear yes or no yes it is possible to read Excel using Lenin without any data loss yes it is possible we can read the Excel and I think I shown you how to load the documents just uh check with the documentation they already given you the code snippet use that uh particular snippet okay code snippet can change timing for the paid AI course evening um I think the course timing is in morning I will have to check with my team related to that so yeah if there will be any sort of a changes then definitely uh like you will get to know about it okay and I will update you tell me guys uh till here everything was fine so can we start with A New Concept now because here I I have explained you something regarding to this Vector database and then only I will move to the uh then only I will move to the Practical implementation great so let's start with the session now so here in this PDF you can see uh I written something that what is a vector database now first of all let me open my open oh just a second great now here you can see guys uh I was I'm talking about that what is a vector database now a vector database is a database used for storing high dimension Vector such as word embedding or image embedding so we can convert our text Data into embeddings even we can convert our image data also into the embedding and this embedding is nothing it is a vector so it's a vector actually and it is not a twood dimension vector or one dimension vector or three dimension Vector it's a high dimension Vector as I told you uh I was talking about this word aming word two B actually this is a model this uh word to back has been trained by the Google and this trained by the Google on a news article right on a news article and uh they have generated the embedding from those particular data from that particular data and the embedding size was 300 so actually see the vector which they were generating the size was the 300 over there so here we talking about the word embedding so it is nothing it is just a vector and it's a high dimension Vector right so the size can be anything over here so once I will show you this open a vector open a uh like open a Ming Vector so the size of the open a aming vector around 1,600 right so there you will find out a 1,600 value inside one vector right okay so yeah and even over here see I'm I'm talking about the word embedding so it is not related to the text Data it is related to the image data also means regarding the image data also we can generate a Ming and yes it is possible so over here you can see so this is a dog images PDF whatever document we have so related to that particular document we can generate a embedding and this is nothing this is a vector which is and what is a vector tell me the vector is nothing it's a set of value and which we are going to store somewhere in our Vector database now here if we are talking about the vector database so there is two term one is Vector and the second is database so this database actually it's a very common term which we like I think we all knows about this database so uh if we are talking about this database so during our uh like during our semester or during our college or maybe if you are working in an industry so definitely once in a while we interact with this database right so if we are talking about the database so there you will find out two type of database so the first database is called SQL based database and the second type of database is called No SQL database right so where we don't have to write it down the SQL where we don't need to create any sort of a schema a pre defined schema so that comes under inside the no SQL database and there we have a different different type of the databases like key value pair graph based database and document based database right so there is a different different type we have of the inside the no SQL database and here we are talking about the SQL based database so there you will find out only one type where we can store our data in the form of in the form of predefined SCH schema in the form of table in the form of row and columns right now what is this ve Vector database so Vector database actually see uh if we are talking about the database so definitely some uh server will be required for the computation and all right and we are talking about the database definitely some space will be required for storing something if we are if we are installing the my SQL in our local system so have you seen that we are installing the MySQL server and it is getting uh it it is occupying some sort of a spaces also in our system right for storing the uh data in the form of physical file The Logical view is a table but yeah in the back end actually storing our data in some physical format so here see uh we have a database so definitely some computation will be required and memory also will be required uh so here uh we are talking about specifically this Vector database so we are storing a vector now so how this database this Vector database is different from the SQL and no SQ database now let's try to look into that and we'll try to understand the differences differences between this uh like SQL no equal and this Vector database and why we should use this database why we should use this Vector database uh why we should not use this SQL and no SQL database we'll try to understand that also so first of all let me do one thing let me move to the next slide and uh let me explain you so here you uh I have written that why we need a vector database see over 80 to 85 person data which is there in the world as of now so there is a unstructured data now what comes inside this unstructured data so unstructured data means the data basically which is not a structure one like images okay so we have a images we have a videos videos is nothing just the collection of images collection of the frames uh so uh if you heard about this FPS frame per second that is nothing that's a uh mejor uh measurement unit of this videos okay in 1 second how many frame is getting processed so uh here uh we are talking about the images so the image data actually comes under this unstructured data where we have a pixel right pixel which uh we are going to form in the which we are going to collect in the form of grid right so pixel value usually will find out from 0 to 255 got it so that is what there is an images right there is the images now if we talking about the unstructured data is text Data the text which I'm writing that also comes inside this unstructured data Text data is there voice data is there right so voice is there text is there images there videos is there so this is called unstructured data and most of the data which you will find out uh like uh which you will find out in today's world in today's era so that is a unstructured one only on a different different platform like Facebook Instagram what we are doing we are uploading a videos we are uploading the images we are uploading the reads this that whatever right so this platform this application are taking a data uh so we are uploading a like different different type of uh like data right like images videos and all those are called unstructured Data so I hope you got a clearcut idea regarding this unstructured data now let's move to the next slide that why I have written over here so if we talking about the uh SQL based data or relational data or traditional data so here is some example which is like uh uh which is a very famous database dbms actually MySQL is there post gr is there SQL light is there Oracle is there right there are different different relational data wayase you will find out uh which we have learned once in a while means u in our College days in our like uh in the organization itself in the company itself right or or during the training so we have interacted with this relational database and this traditional database and we have seen the SQL also like how the cql works how to write it on the syntax and all in a SQL so we know we all know about the basics of the SQL right if we are talking the relation datab with so we usually write the SQL query over there right for interacting with this relational databases now here uh I think you got to know the idea that what is a relational database and here we have a problem problem related to the data the most of the datab basically that is the unstructured data now just see over here let's say uh if we are going to store this data if we are going to store if we are going to store this a particular data like images videos and all inside the vector database right so uh not inside the vector database First Let Me Explain you inside the first let me tell you that inside the uh this traditional database or inside the relational database so what will happen see so let's say here we have a traditional datab datase like my SQL and here if I'm going to store the image inside the my SQL all right we have a image and that particular image I'm going to install or I'm going to save inside the my SQL now guys see definitely I can do that I will be able to do that I will be able to save the image so it is having this capability where we can uh store the binary object so uh there is one way actually we can convert this particular image in a vs4 string vs4 string and I can see save it but here guys see if we are going to save this particular image if we are going to save this particular image inside the uh traditional database so here I will have to define a schema right I will have to Define one schema there uh let's say if I'm going to store this image directly so we won't be able to get it now so this image belong to cat dog or which dog actually so if you will look into this dog so this dog is specifically is having some property right so this dog is specifically having some property some let's say this a dog belong to this particular breed that particular breed right now this um dog is a yellow brown or black something like that so this dog itself is having some property so if we are going to store this data directly in my SQL in that case let's say we are not passing any sort of a label any any anything over here right regarding this particular dog or directly we are going to store this dog okay dog image inside my my SQL now over here let's say I have converted into a b bs4 string or let's say I have just converted into a binary object uh so in that case I won't be able to identify it I won't be able to identify it this is the first problem the second problem basically so if you want to identify it so for that basically we'll have to create a proper schema so schema in case so let's say there is a image of the dog right there is a image of the dog then there is a color of the dog then there will be a breed of the dog right and there will be a lab label means this is the dog or let's say there's a cat something like that so if we are going to store this type of data in my SQL definitely I can do that but here is some problems we have first problem right if we are directly storing it so definitely we won't be able to identify it right so whether it's a dog cat or whatsoever the second thing we'll have to define a proper schema and the third thing is what so we'll have to define a proper schema where we'll be having a different different variable now the third thing is what so here actually see uh this SQL database let's say we are going to store it over there now uh whenever we talk about the text or images with respect to this uh generative AI or llms actually we have to perform an operation that is called similarity search right similarity search so I will show you what is this particular operation similarity search actually see whenever we are going to uh store this data this dog image inside the traditional database inside the relational database so the first problem which occur related to the identification if we are going to create a better schema that is also fine but we want we we cannot perform this similarity search actually means B let's say there is a dog now I want to find out the dog which is having a similar property right which is having a similar property like this dog so it is not possible in my SQL database right in in like traditional database or in relational database right so this similarity search or this query actually this will be a very very difficult if we are if we are going to query right after storing a data based on some property it's going to be a very very difficult so that's why we don't use this relational database and the same problem occur with the no SQL database also there also we can store the data we can store the Ming okay so we can use so I think today itself Chris has uploaded one video regarding the cassendra where we can store the embedding right we can do that but this Vector database which specifically designed for the like this edding and all so this gives you the better result compared to that right somehow we are able to achieve this thing means we are able to uh pass the label to the particular object whatever we are storing and we are able to search also right based on a similarity we are able to make a query we are able to perform the query but actually it is not that much efficient right whatever we want so for that only this Vector database has been designed I hope you got a problem and you are getting my point that uh why we are not storing this data inside the relational database got it now let's come to the next point and the thing will be more clear to all of you the next part over here if we are talking about the image so image looks like this only so where we have a three channel so the first one is a uh R then second is G the third one is blue means B so this is RGB means this colorful image actually it is having a three channel the first is called R the second is called G that is green and the third is called Blue right now uh here yes definitely if you want to perform the Ming right so here if you want to per if you want to perform the Ming we can do it by using uh so here we can use uh like different different embedding technique as I told you word to back Elmo or any pretrain embedding like uh which is uh available over the open a right which is available over the hugging phase so any embedding a model we can download and we can pass our object to that particular model right and based on a a training on uh like on whatever way basically it has been trained so it will give you the embedding right maybe you are not able to get this particular point but once I will show you right once I will do it in a python definitely you will be able to understand so what I'm trying to say over here you can perform the embedding related any unstructured object so here you can see we have a text we have a audio we have a image image embedding is also possible means we are going to convert images into a vector now here what I'm going to do so here I'm going to download any pretrain model any pretrain embedding model and yes by using that particular model we can convert our data into a vectors we can perform the embedding I hope this part is getting clear to all of you so whether we have a image or text or voice we just need to download the model pretrained model and based on that we will be able to generate an embedding if you want to train your own model right if you want to train your own model that is also possible that is also possible or let's say if you don't want to train your own model you just want to finetune the pretrain model that is also possible so everything is possible there is a three possibility first is what first is a you can directly use the train model the second is what second is fine tuning all right fine tuning and the third is what third is training from scratch so here let me write it down the third one third is nothing third is training from scratch right everything is possible related to the embedding and here it is nothing so at the end we are going to generate a back turn after passing the object now I hope you got a clearcut idea now if we are talking about the embedding see uh what all embedding I will show you what all U like Tech te basically uh which uh we have so the first one we can use this word to bag right directly we can use this word to bag for generating Ming the second one we have the Elmo right we can use the Elmo and we can generate a Ming right now the third one basically we have we have the hugging phas API also in that also we have a several embedding model so hugging phas API Now by using this API hugging face API we can uh we can download the embedding model model and we can pass our object to this particular embedding model and it will give me the embedding right it will directly generate the embedding the fourth one we have this open API so in the open a API itself so in the open a itself you will find out the embedding model right so there also we have a Ming here also we have a Ming right in a open a itself so we have a hugging face we have a Elmo word to bag and various model here I just written couple of name or two to three name but we have a various model if you search over the Google you'll find out the various way right to convert your data into a vectors to convert your your data into a ambed vector right now here hugging phase API is also very very popular for the embedding and all and I will show you what all models we have right what all models we have uh inside the hugging phase actually uh for converting our data to into the embedding right and here in today's session we are going to use this open embedding right we'll be talking about the open a embedding how you can uh how you can like get it how you can access this particular class and after passing a data how you will be able to generate the eded vector so each and everything we're going to discuss in the live class itself right so I hope this slide is clear to all of you and this slide whatever I discuss regarding this uh uh my SQL and the sorry regarding this relational database and the no SQL and the vector database that part is also clear now here Vector eming is fine so yes uh we have the vector database now why we should use it because uh here actually this similarity search operation is uh like uh possible we can perform the similarity search after storing the vector and all and yes U now here embedding example so for that uh I kept some sort of example uh basically we can uh do the similarity search by making this cluster and all there is a this is the mathematical process actually so Vector this is a 2d uh this is what this is a 2d example of the vector aming as I told you now so what is a vector vector is nothing it's a set of the value in a like n Dimensions so here if I'm writing here if I have written two value only so it's a set of uh so actually it is representing a two Dimension X and Y right this first value is from the xaxis the second value five is from the y axis now we can do a simility search uh we can make a cluster actually let's say this two vectors near to each other so we can say like they are having some similarity they this particular Vector is having some sort of a similarity like this this also this uh red one also see here is a vector this first one this this is my one vector this is my another Vector this is the third Vector so they are lying they are near to each other so here I'm saying yes this Vector is having some similarity this three Vector now this one also this also this also and this one so this Vector is is having some similarity this green one right this one so like wise actually what I can do I can perform this text similarity option text similarity option which is like uh which is little hard if we are going to store a data in my SQL post gray right or maybe in other databases so in that case like we won't be able to see in my square and post gr relational database it is like really hard right because we are going to store up data not in terms of embedding directly is going to store the object over there and uh for that only we'll have to do a we'll have to create a predefined schema so uh it's going to little hard over here actually we don't never use this relational database for this uh embedding and all okay so it's not our Perfect Choice yes we can use the no SQL database uh in the no SQL we can use the document with database uh or else what what we can do we can use this row columnar database that is also possible like cassendra and all we can use this uh graph based database right actually uh graph based database is not that much successful they also you will find out some sort of a difficulties in all I will tell you in further session but yeah we can use this raw column database and even the document database also but yeah the performance is like U uh it's not that much good and here also we'll have to label the data and all directly we can store the embedding uh but uh here actually along with the embedding there are so many things means we have to find out the similarity score then we have to perform the similarity search here you can see clearly in the geometry but mathematically how we can prove it so for that there are so many thing which we need to find out so there will be a similarity score right based on that similarity score we have to do a similarity search right similarity search so this is also there so similarity score similarity search this Vector database will give you everything Vector database will give you the everything so that's why we directly use this preconfigured Vector database and here also like it is running on some sort of a server and there are also some computation and all uh which is included which I let you know right so how to configure the cluster and all regarding this Vector database yeah so if we are going to store the data store this like embedding in a no SQL database so here also we'll have to make some configuration and it is not that much efficient but this Vector database actually it is giving us everything where we just need to store the uh value we where we just need to store the data in the form of vector that's it got it now here uh I hope this part is clear to all of you this vector embeddings and all now let me go through with the next slide so here again uh same thing is there so we have embeddings so we have a vectors and along with that there will be indexing as I told you now so if we are going to store this data if we are going to store this particular data inside the uh no SQL right if we are going to store this particular data inside the no SQL databases again we'll have to make like a some configuration and all according to the uh the vector which we are going to generate we'll have to conclude the we'll have to write down the indexing and all and uh maybe we'll have to write it down the label also to identify this embedding right so many things is there but we can do it by using the no SQL now here uh uh let's uh understand about the vector databases already I talked about it and here you can see uh we have a data which we are going to store inside the traditional data a vector database index and store Vector embedding for faster uh retrievable and similarity search right so for the faster retrieval and similarity search we always use this Vector database instead of the traditional database we never use this for storing the vector for restoring the this vector and all now use cases of the vector database so here longterm memory for llm semantics s similarity search recommendation is that the main thing is this one only the semantic search and the similarity search this concept uh initially this concept has been introduced by the Google itself if you search about this Vector database now it become too much popular after coming like different different llms and all and like this type of operation actually there are like uh you will find out so many operation like where you have the similarity search and the semantic search semantic meaning and all and where you have to sustain the longterm memory right so because of that this Vector database become too much popular uh I hope this thing is clear to all of you about the vector database now we we have couple of name uh now this Vector database this F from the openi side right so you will find out this F over the openi website actually it's a research of the meta now here is a webb8 here is a choma DB pine cone is there redus is also there there are so many database or so many Vector database you will getting you will be find you will be able to find out now uh we are going to use this Pine con and chroma DV and will show you the babyit also but uh not in today's session later on uh after this uh like chroma and pine con but in today's class first I will start from the pine con because it is a little uh simple compared to this chroma DB and the we8 if we are talking about this chroma DB and the we8 it is little uh tough to configure not tough actually compared to Pine con it is like little harder so first we start from the pine con itself and there we try to build our small uh U like QA system okay and here and later on we'll be talking about this chroma DB and the vate so let's start uh with the Practical demo so for that uh what we can do we can open our neural lab so guys uh tell me are you ready yes or no please do let me know the theory whatever uh part I have discussed whatever thing I have discussed through this PP uh those part is clear to all of you yes or no again I will come to this one after uh implementing uh in a python right after doing the Practical stuff and all and then again I will try to give you the revision and then the understanding will be more concrete to all of you okay tell me guys fast if uh you will say yes then I will proceed further great so let's start with the Practical implementation now so here you can see uh I opened my uh I opened my uh neurol lab sorry I opened my U ion website and here you will find out this neurol lab so just click on this neurol lab here uh which you will find out over the website just go and search the website ion. and there uh you will find out a option this neurol lab option just click on that and here you will get the interface neuro lab interface so uh what you need to do guys here after opening it you need to click on this start your lab okay so once you will click on this start your lab there you will find out of various option like big data data analytics data science programming web development and all so here click on this data science as of now uh like uh we are working in this particular segment data science so there you will find out all the related tool right whatever is required for the development so here you will find out all the tool whatever is uh like related for the development and uh here we are going to use this uh here we are going to use this jupyter lab so just click on this Jupiter lab after clicking on this data science just click on this Jupiter lab and here it will ask you the name you can uh provide your name also you can write it down your custom name so the name uh which I'm going to write it down over here so Vector database Vector DB okay now what I will do guys here I don't want to clone any repositories like I'm saying no I don't want to do it and then proceed so first you need to write down the name and then U like just select this particular option or no only just click on that and then launch your Jupiter instant so here you can see uh this instance is getting launched now this instance is getting launched and and here after launching this instance you can click on this Python 3 ipy kernel so just click on this particular option Python 3 ipy kernel and here you will get the file here you you will get the Untitled file so you can do the right click on that okay on top of this file and you can rename it so just do the right click on this particular file untitle do iynb and then click on this rename now here you can write down the name so let's say the name is what Pine con DB Pine con Vector DB Pine con Vector DB so here is the name the name is what the name is Pine con Vector DB now I am ready for my implementation I hope guys this is visible to all of you and you can clearly see this particular jupyter notebook please do let me know if you are able to do a setup if you are able to launch your jupyter notebook then please do let me know please write down the chat I am waiting for your reply do it guys fast yes or no I'm waiting for your reply if you have done all the setup entire setup then please do let me know in the chat sir show one more time yes I can show you one more time so click just open the neuro lab after opening the neuro lab here you will find out the option start your lab and my lab so don't click on this my lab because if you have already created a lab then only you will get your Labs the lab template over here so here what you can do guys tell me here you can click on this if you are using the first time right if you are creating your left first time or see we are doing first time now we are launching this jupyter notebook first time only throughout this uh throughout this geni commune session so click on this start your lab and here you will find out a different different template so just go with the data science and here click on this Jupiter template and then give your name or keep it by default only click on no and then proceed that's it that's a proed of that's that's a process and it's a very very simple so please do it guys and let me know then I will uh writing down the code over here waiting for your reply if you can write on the chat I think uh that is going to be great and let me share this uh link also okay I think let me check if I can share with all of you just a second great so now let's start with the session uh so let's start with the Practical implementation okay now here guys you can see so this is what this is my uh Jupiter lab now I will be writing the code from scratch and I will show you like what all whatever thing will be required so definitely I will show you in between and even I will show you that how you can generate an embedding how you can save it and we'll show you that how you can uh create a basic QA system right by using the openi Ming now here is what so here let's say uh so this is my blank notebook so first of all I need to install some Library so I'm I believe that you are uh doing along with me so please do it along with me because today I will go very very slow uh this is going to be a very important session for uh further projects the projects which we are going to do in our upcoming session so please guys do it along with me and I will be writing each and every line each and every code in front of you only so fine let's start now so here the first thing which we are going to install over here that's going to be a len chin so here I'm going to install Len chin let me write it down over here the second thing which we are going to install over here that's going to be a pine cone so here let me write it down pip install pip install pine cone so if you want to use the pine cone so you will have to install this pine cone client right I will come to the pine cone I will show you the pine con website also but first let's try to install this particular module so here the second thing is what Pine con cone client c e NT right the next thing which we are going to install over here that's going to be a p PDF so here let let me write it down Pi PDF okay Pi PDF py uh okay py PDF now the fourth thing which we are going to install over here that's going to be a open a so pip install open a right so pip install open and now there is one more Library which we need to install so here I can write it down pip install uh tick on so let me give you the name uh tick token so there is a library tick token so this is the library which you need to install take token so actually this library is a important one if we are going to call the open a embedding so it's a utility actually for that particular class for the embedding class got it now what I will do here so I will run it and it will be installing all the packages in my current workspace so here you can see guys my all the package is getting installed so meanwhile I can show you this Pine con so meanwhile uh I can show you the pine con uh just a second so just open your Google and here search about the pine just write it on the pine cone p i p i n e c o n e pine cone so once you will uh click on once you will like write it on this Pine con and you will hit enter so here you will find out the pine con website https www. pinec con. now click on that now open this particular website now here guys after uh clicking on that you'll find out this a particular interface this is the interface of the uh this is the interface of the pine con website so have you opened it guys tell me are you installing this uh are you installing all the library the library which I have written over here have you opened this Pine con website because from here I have to generate the API key if we are not if we are not going to generate API key in that case we won't be able to call this pine cone right so please uh do let me know if you have opened it so is it getting blurred or what so my screen is blood please do confirm guys please do let me know because I can see it is not a blood one it is a clear uh Crystal Clear actually and I can see in my screen please do confirm in the chat guys please write it down the chat if you have opened this uh pine cone and if you can clearly see this particular screen yes or no great now uh see here this is what this is my pine cone now what you will do see if you are uh if you are doing it first time then you need to sign up what you need to do you need to sign up so just click on the click on this sign up free and here you can and here you can uh basically you can uh sign up it will ask you about it will ask you the email ID username and it will ask you the like organization name and all it's a optional one only you just need to provide your email ID or you can directly sign up by using your email ID right you can directly sign up by using the email ID it is it is a very simple step just click on the sign up and uh then sign up by using your email ID and automatically you will be login so I already did it over here you can see I uh did it and this is what this is a interface which I will uh which you will get after the sign up right so first you need to open the website there you need to sign up right and after the sign up what you will do guys tell me after the sign up automatically you will be log in and you'll find out this particular page so if you are doing along with me so yes I can wait for you you can let me know in the chat and if you have done till here then I will proceed tell me guys first uh waiting for the reply so if you are hearing me if you are listening to me then uh please do let me know in the chat fine so let's start now here you can see see guys uh what you need to do uh here yeah in your case actually it is saying create the index now let me do one thing let me delete this index so I will show you from the starting so how to create the index and all and what is the meaning of it so let me delete this particular index and here guys you can see I deleted this index now in your case it is giving you the option for creating an index actually see if you are using a free version if you have created a free version right so in that case you can only create a single Index right if you're using a free tire free tire of this spine cone so in that case you only can create a single Index right so now uh the first thing what you need to do guys so here you need to click on this API key left hand side you can see this API key just click on this API key now once you will click on the API key so it will give you the option for creating a API key and one key you will find it over here by default so they have given you one key that's a by default key this one this one actually this one okay so this is the by default key which you can see over here uh which they which everyone will get it right and now here this is my key which I have created by clicking on this create API key got it so here this is my key which I have created or they will give you the by default key you can use this also otherwise you can create a new also both are fine right so if you have this by default key now you are well and good till here right you are fine till here so tell me guys are you getting this uh this key AR I think see there is some problem from your side because I can clearly see that everything is fine in my system and uh it is visible to all of other student so please check from your side as well it is working fine or not please check in your phone uh just try to refresh your system if you getting the blur screen because in my screen the feed is uh fine and I think no one is uh complaining about it so please check once yeah so if you are getting a default key then it is fine so if till here right if till here you proceed along with me then it is fine now let's go back to the code now here is my code guys here is my code file here is my ipb file so here guys you can see so I install this libraries pip install L chain Pine con Pi PDF open tikon I installed all the required Library is over here now let me do one thing let me write down the further code so here and the next cell after installing all the library whatever was there I'm running this uh like I'm running a further sale so here guys what I need to do so here now I'm going to import all the library so here already I have written the import statement now let me show you those import statement here is a import statement guys so the first import statement is pi PDF directory loader this is the first import statement the second four statement is recursively character text Splitter from the lenon itself now the third one open AI embedding right and the fourth one you'll find out that's the opener itself then we are going to import this spine cone from the vector store which is there inside the Len chain I'm using Len chain only and I told you this Len chain is a wrapper on top of each and every API right so whatever thing uh see better like you are if you're going to build this LM based application if you are using this Len chain so you will find out U everything inside the Len chain it's a wrapper on top of the every API on most of the API so here you can see you can import this pine cone from here itself from the Len chain right so from Len chain. Vector store and there is what there is a pine code now Len chain. llm here is a open a now Len chain chain here we have a retrieval QA each and everything will be clarified once I will write it on the code only now here you can see Len chen. prompt and here is what prompt template so you already know about the prompt template you already know about the open a you already know about the pi PDF directory loader this thing recursive character text splitter open a embedding and retrieval QA this thing is a new one so definitely I will explain you it don't worry so what I can do here uh let me do one thing if you are uh doing along with me I can give you this particular code and for that I what I can do I can share this uh Cod share. where I will be uh writing let me share with all of you this Cod share. okay just a second Cod share. yeah so here I can copy my entire code this is the code this is the input statement and here and here is what here is my all the library so which you need to install all the packages which is which you need to install now this is the just wait let me copy it from here this is the packages yep it is fine now and this is the import statement so import statement and here uh required package required package right now let me give you this particular link so here I'm giving you this link inside the chat just wait here it is here is the session which is going on now just wait here's the link guys here's the link of the here's the link of the Cod share. so please do confirm did you get it guys yes or no please uh do let me know inside the chat if you got this particular link yes or no I I given you this link inside the chat so please do confirm and don't worry my uh team will also give you that my team will ping you this link so inside the chat itself if I'm if I'm not able to do it just a second this one okay so I hope uh it is fine now yeah so now I hope you got a link please do let me know in the chat please do confirm I'm waiting for a reply and see guys just copy and paste the code don't remove from here right don't remove don't cut it from here just copy and paste yeah copy the entire code and run it inside your uh run inside your this uh IP VB yeah so I'm waiting uh please do it and then I will proceed further yeah this one okay proceed yes this uh file will be available over the dashboard Vishnu is karma is saying sir did not get a link I pasted now pasted inside the chat just look into the chat live chat check with your live chat we have we have given you that inside the chat itself fine so now let's uh move further here after installing all the library I need to import this statement so here you can see uh I'm able to import this particular statement okay so I have imported this particular statement now guys what I will do here here in this my in this my local workspace in my uh this workspace I'm going to create one folder right so I'm going going to create one folder and for creating a folder there's a command mkd so here I'm going to write it down mkd PDF right so here I'm going to create one folder the folder name is going to be a PDF so see guys uh left hand side if you will look into your workspace you will find out the PDF folder now inside this PDF I have to upload the PDF and from there itself uh see I can upload the text file or I can upload the PDF XL CSV so I just required a data right so I'm showing you this embedding and all I'm showing you this embedding and then I will store it then I will query it so on top of the uh real time PDF only I'm not going to create any dummy data over here right so in front of you only so here let's say h I'm opening my Google and from here I'm uh I'm searching about this attention all your need right so this is the Transformer research paper so let me open this research paper and let me me download it inside my system so here what I'm going to do guys so here I'm downloading this a particular yeah here I'm downloading this particular research paper inside my system right so see guys uh what I can do I can keep the name Transformer right so this is what this is my PDF now what I will do guys here uh let me check the size of this PDF uh if it is a huge one that definitely my neurol lab uh won't allow to me let me check if I'm able to upload it or not this Transformer in my neural lab so here what I will do I will click on this upload button here and I will click on my Transformer so as soon as I will click on this I will be able to select it then open it and here you can see my neural lab is saying entity is too large so what I can do here I can compress this PDF so for that I can use any uh online compressor so if uh your file size is little uh huge so in that case you can compress it if we are going to upload it inside your neural lab so here I'm writing about PDF uh compressor uh so here you can compress the PDF with any free compressor now here I'm using this particular uh website I'm opening my PDF and here it is giving the recommended compression now if I will click on the compress PDF so it got converted into a 137 MB from 2.11 MB now it is saying to me you can download it so I'm downloading this particular PDF and here Transformer compressor right so I got my compressed PDF it is very simple step you can open the Google and you can search about the PDF compressor if your PDF is too huge let's say see here we are using a PDF now for getting a data for collecting a data right real time data so for that only uh like I use this PDF compressor because this neural lab is not allying okay a file basically which is having the size around 2 MB 2.11 MB now let's see we are able to upload it or not so what I will do here I will use this Transformer compressed and if I'm going to upload it or still it is saying that request entity to larger okay just wait uh let me compress it again uh select PDF and here is a compress PDF because I want to make it a small only now extreme compressor okay this one only let's see what will be the size of it no just a second select PDF and here compress PDF extremely comparison uh the size is going to be 1.3 MB I don't think this lab will allow to me just a second otherwise I will have to use any other file um this just a second let me check so it is saying request entity too large no issue no worry uh see what I did actually let me show you my download section so here before the class itself I have uh I was exploring it and I downloaded couple of PDF so this was the PDF actually this was this is a YOLO research paper so let me show you this particular PDF this one see this is the YOLO research paper YOLO V7 okay YOLO V7 as of now I was trying to show you with attention all your need paper but it is not allowing because uh the size is a little huge see the size of this compressed file 540 KB only now here the size of this Transformer compress around 1,339 so actually it is not allowing to me to upload this particular PDF so in that case what you can do so here uh you can uh we can use this YOLO V7 paper now what I'm going to do let me first of all rename this particular paper okay uh I will have to close it from here just a second now let me rename this paper so here I'm going to write it down YOLO V7 so this is what this is my YOLO V7 paper and now let me upload it over there because I want a data and I'm going to read the PDF and from there itself I am going to collect my data for converting into a embeding so now see it we have uploaded this particular PDF so if your PDF is uh exceeding exceeding the size the size is around 1 MB so it won't allow to you you cannot upload the PDF in our neural lab so don't worry it will be solved in our near a future sessions so our team is working on that and it is U we are like uh making it more powerful as well so don't worry many more functionality will find out over here itself inside the lab now we got this YOLO V7 now what I will do guys so here I'm going to read this PDF so for that already I'm uh for that basically already I have imported this particular class so here I'm uh like passing it I'm copying and pasting over here and then here I'm writing PDFs right so once I will write on the PDFs so see it is giving me that PDFs is not defined uh PDFs where is a PDF okay so actually I will have to pass in a double code just wait let me take in a double code yes so I I'm able to load this PDF actually whatever we have inside this PDF folder now what I will do guys here I'm going to write down the loader so this is what this is my loader and now what I will do guys so here I will call loader loader. load right so by using this particular code I will be able to read my PDF see this is what this is my PDF now here I can collect this data so this is what this is my data which I'm going to be convert into a vectors with that I'm going to making a like embeddings and all and that embedding I'm going to store inside my dat database inside my Vector database which is a pine gon right so now let me show you this data so here is what guys here is my data which you can see over here and it is in a list format list form so here just press zero so you will find out all the data entire data basically uh whatever we have inside the PDF this is what this is my data right now here we are able to load the PDF now guys let me give you this particular code so at least you all can run inside your system so just a second uh here is a code guys this one for loading the PDF and here we have one more function that's going to be a data do load so loader do load actually just a second let me copy and paste over here this one so loader and here basically we have a PDF and we are able to load the data now uh yes we are able to get a data now what I will do guys so here I will perform the uh like a tokenization right right so here the next step is going to be a tokenization one let me show you uh The Next Step so what I'm going to do let me do one thing let me copy and paste and here is what here is my next step basically so just look into the step what I'm doing here I'm calling this recursive character text splitter right and here my chunk size will be 500 and chunk overlap will be 20 right so just just go through and check over the Google or what you can do directly you can copy this particular import statement open it just just copy it and open your Google and paste it over there then you will get the complete definition of it over here inside the lench documentation now just look into that just look into this recover split by character so this text splitter is recommended for one for generic text it is parameterized by list of character it is trying to splitting one of them in order to until chunks are small enough the default list is this one means uh if it is going to find out any uh character right so based on this particular character is going to divide the data into a tokens this has the effect of trying to keep all paragraph and the sentences and the word together as long as possible and those would generally seems to be strongest semantically related piece of text so it is going to create a tokens it's going to uh split the text right if we are passing any sort of a text to this particular method so definitely going to be splited now over here see we are going to open this particular text here is what here is my data now I'm going to create a I'm going to import this particular class and here I'm passing the different different parameter so there is a chunk size so set a really small chunk size just to show so here the chunk size what 100 chunk overlap 20 length function is length itself and is separator regx is equal to false right now here uh what I did so here I call this particular method create documented and here I'm going to pass my data so it will be able to create a chunks it will be able to create a chunks which is having a size of 100 and the overlap chunk overlap is equal to 20 right now let's do one thing let's try to do it by using R data now over here you can see we are able to create a object of it so Rec character text split chunk size 500 and Chun overlap is 20 now here I'm going to create a object of it so here is my object text splitter and after that guys what I will do I'm going to call one method over here so here let me show you the method this is what this is my method a text chunks to text splitter. split document this is what this is my method and to this particular method I'm passing my data right to this particular method I am passing my data now let me run it and here you can see we have the chunks of the text so text underscore chunks now here guys you will see so we are able to convert our text into a various chunks now let me show you so here this is inside the dictionary so let me do one thing let me first of all scroll down till last okay and here I'm going to pass this chance now here let me write down the zero so this is my first chunk right so we we have approximately 500 tokens right now of 500 chugs basically we have created from that and this is the like first one right now over here what I'm going to do see uh here I'm going to write it down the print statement right so I'm going to pass this value in a print function and here you will see that we have a data this is what this is my data now here textor chunks and in a square bracket we have a zero now what I will do I will call this page content right so pageor content so here guys you will find out this is what this is my content right so this is what this is my first one now let me show you the second one here is what here is my second one see uh the uh here if I'm passing first this is my second one right now this is what this is my third one right so here what I can do I can pass two and this is what this is my third chunk so we are going to convert or we are going to divide our data into a chunks right and this is the first chunk this is the second chunk now here is a third chunk this is what this is my chunk actually and from where from our PDF data right from our PDF data now if you will check the length of it so here let me do one thing let me check the length of this textor chunks right so here is the length of text underscore chunks Chu Ms now you will find out the chunks length is 152 means total 152 are like paragraphs you will find out from the data itself right so the chunks basically which we are making which we which we have made are from from the data itself the data which we have loaded right so here is what here is my 152 chunks and this is my first second third now you can print the 152 chunks as well so here what you can do you can write it down the 151 actually that will be a 152 chunks because the index is going to start from the zero so now let me print it and here you will find out the last one so former 4 and 2 and object detection in proceeding the International Conference or learning representation now if you want to do it see here uh I did it randomly means uh if you will look into the first chunk it is going to stop over here if you look into the second chunk it is going to be stop over here but if you want to do it based on any requirement right and based on any meaningful context which uh which is like required according to your problem statement so for that you will have to look into the data you will have to perform the text preprocessing over there right and then only you you will have to put some sort of a logic then okay if this thing is coming then only you have to cut the data if this thing is coming then only you have to cut the data right so here you will see guys uh like we are able to create uh like chunks over here right so um there is uh total 152 actually now what I will do after doing this thing uh I have shown you the chunks and all now let me show you the next one now what I will do guys here uh first of all let me uh open the openi openi API key now here I'm going to write it down this uh import OS and here OS do os. getb now here what I'm passing I'm passing this open API key right I'm going to set my open API key so all value will be in a cap so open AI underscore API underscore key got it now here I'm going to pass my API key now let me generate the API ke I think I already generated it let me copy it from there itself h let me open the open okay here it is this one this is the OPI key now what I can do I can paste it over here this one so yes I'm able to set my open AI API key right this is fine okay now get En the assignment what is this okay open AI which I don't want to fetch it actually I want to set it so there is a different uh like name in wire e NV R actually this is the name so I want to set the like API key in my environment variable in my system environment variable so this is the method got it now this is fine we have created a chunks and uh everything is fine now what I will do I will create a object of the open embeding open emding class so let me show you what I can do I can open my my open a let me open the open a itself just a second open AI right now here uh just go with the documentation just just click on the documentation over here yeah this is what this is your documentation just scroll down there you will find out the embeddings got it now click on the embeddings here is embedding now uh what you need to do guys here you need to import this embedding okay this this particular embeddings okay so if if I want to convert my data into a vectors if I want to if I want to make it like the vector actually the context Vector so I I'm going to use this embedding from the open a now how I can do that how I can use it let me show you so for that what uh you can do so here uh we have a class direct class actually open I aming which I which I have imported over here if you will look into the import statement right so already I have imported this thing and where it is let me show you over here see this one open AI right uh open AI M okay this one uh where it is open embedding so from Lang CH actually we are going to import this openi embedding now what I can do I can create a object of it so I'm going to create a object of the open a embedding and here what I'm going to do I'm going to keep this thing inside the embedding itself so this is what this is my embedding right open a embedding okay now the next is what so here I'm going to write it down I'm going to call one method so the method is what the method is nothing so aming dot and here I'm writing idore query so idore query and here what I will do guys here I'm going to pass something so here I'm passing how are you right so once I will run it so here I have passed how are you now see it will generate the embedding for it see guys it have generated an embedding if see I told you how it is going to generate embeding bding it's going to generate an amb bidding based on a features right based on a feature so I told you guys see uh when I was talking about the word to bag right just a second when I was talking about the word to bag when I was talking about the word to back so actually there was there was the vector that the size was the vector of 300 right 300 Dimension now if you will look into the open AI embedding so let's check the size of that so so uh this sentence actually they have converted into a vector now let's look into the size that what size I'm getting or for this particular Vector so over here I can copy it and what I can do just a second let me scroll down because the vector size is very very huge uh just a wait here is what here is my embedding okay just just wait guys so let me keep it inside the variable yeah here it is this one so what I can do I can directly call this length function over here so let me show you the number of embeddings over here so the number of embedding is 1 53 6 this is the length of the embeded vector getting my point guys yes or no so here is my sentence how are you I given this sentence and based on this sentence is it has generated one vector which is the size of the vector is 1 53 6 the size of the vector is 53 6 got it so I hope this part is clear to all of you now um I got the vector I got the length also now let's try to discuss so here uh we have this open AI right so we have this open a actually uh we have the open a API we able to call this open a embeddings everything is working fine everything is uh going seamlessly right now over here this is my data also so we have a data we have a open a now it's time to import this pine cone right so now let's uh like import the pine cone and whatever embedding we are going to generate from here so the embedding I'm going to store in my pine cone Vector database so for that basically what I'm going to do here uh here uh the first thing which I'm going to write it down that's going to be my Pine one API key right there is two thing two variable now what I can do till here I think everything is fine and please set your openi key and call the just just create this model let me give you this uh thing over here this one so you all can copy and you all can run along with me and this is also let me remove it as of now from here and Yep this is the one now you need to write it down your own so here is what here is the open AI key which you need to set right and the next one open a embedding and here if you're going to call it then everything is going fine right so just a second this is the length of the ambic now the next one basically what I can do here I can give you this particular code also so okay first of all let me remove this thing this particular thing and here let me remove this thing also so fine uh now it is clear and you can run along with me so please check out the link this Cod share. link inside the uh inside the chat box guys and please try to copy from there please try to copy this code from there right now uh see guys uh one more thing if you are liking the session then please hit the like button okay this motivates me a lot and please write down the comment please be active in the chat if I'm asking something see I've seen many people are seeing this this one many people are watching it in a live uh in a live mode but they don't interact actually please be interactive if you are interacting that definitely I will also get a motivation I will show you like two to three more new thing if you're not doing that in that case um it will be hard for me also I will stop it this session by explaining you one or two concept only if you are asking to me then basically definitely I will explain you few more thing few more concept got it so please be interactive please write down the chat and please hit the like button if you're liking the session so far now guys here what I need to do I need to set the pine con API key right Pine con API key so from where you will get it so just open the pine con website so here is my pine cone just go inside the API key and here is my API key so you can use the default also or you can create the new also so here I have created a new one so let me copy this particular key and let me paste it over here that is the first thing which I need to do right the second thing I need to pass pine cone API environment so where I will get it where I will find out this pine cone just click on the fine code website here is the environment name just copy this thing copy this gcp starter and here you can paste it inside the double code right so I think both thing is fine now let me set it okay this is fine this is clear now guys what I need to do here I need to import the pine C so here I'm going to import the pine C yes uh I imported it not an issue so there is no such issue with that now here guys what I'm going to do so I'm going to call one method and this method is going to be a very very important so my method name is what pine cone in it right see guys over here just just look over here uh this is not a typical at all what we are going to do see uh this is the method and which method we are going to call Pine con. init so here itself in a pine con documentation you will find out let me show you uh just just search over the uh just click on this document and here is what here is a pine cone documentation now just just click on the quick start uh once you will click on the quick start now so there you will find out the like all the thing right so here you need to import the pine cone here you need to set or you need to set your API key and your environment name everything is here everything over the like website itself in the documentation itself I'm taking a reference from the documentation now the next thing is what you need to call this init method so let me do it and let me run it yes this is done we are able to do it and here I can give you this code as well inside the code share. so this is the code guys which I'm going to paste and there is what there is an import statement also which I'm going to paste over here just a second so you can copy along with me and you can run it you can test it because it is going to be a more interesting now so this last 20 minutes is a climax of the session is going to be a more interesting so just wait for next 20 minute and you will see the magic right so how efficient it is how like it is working actually you will find out a final conclusion over here now we have initialize it now the next thing we have to initialize the index name so here is what here is my index name which I have to initialize so where I will find out the index name so just go through with your pine cone and here click on the indexes here right so click on the indexes and click on this create index see this uh actually this pine cone now it is running on top of the cloud once you will search over the uh once you will search about this pine cone just let me show you uh search about the pine cone so open open the website and here you will find out that it is working on top of the cloud so the server basically which is using Cloud Server the AWS Ser or a server anything we can use okay uh just a second guys just a second just a wait uh I think I'm getting some issue with the connection just allow me a minute just wait yeah now I think it is fine so yep now it is clear now it is fine so here guys you can see if we are talking about if we are talking about this pine cone right so if we if we are talking about this pine cone now so this actually it is being created on top of the Cloud Server so here they have given you the entire detail so just check with the product uh so each and everything you will get about this pine cone right and here you will find out that it is going to fully managed by the AWS server either you can use AWS or Google or Azure and here there is a pricing detail also so you will find out the pricing detail how much it's going to be charged for the specific P for the indexes the index which you are going to create how you can scale it right everything you will get it so as of now we are using a free plan free tire of the spine cone but it is getting uh it's a chargeable also so you will see the prices and all prices is 0.096 per hour 0.111 144r right this this for the Enterprise the standard this the like just a free version of it just just go through with the website everything you will find out over there itself now here I have to create the index name now how I can do it how I can create the index name so just click on the index this this particular index and here it will give you the option for creating index so just write it down your name let's say my index name is testing and here you need to mention the Dimension right so just look into the dimension that what was the dimension over there so let me uh do one thing let me show you the dimension of that so for that basically just scroll up see here 1 1536 so this was the dimension actually when I checked uh with the open I'm Ming so here you will find out that this is the dimension which I'm getting you you can check with regarding the other sentences also so here uh let's say if I'm saying something whatever uh let me do one thing let me copy and let me paste it over here here I'm saying uh I am fine right hi hi I am fine so this is what this is my like sentence which I'm writing over here now you will find out the embedding and let me show you the dimension of this particular embedding now here you will find out the dimension is around 1 536 it's the same one right so this Dimension is nothing it's a feature right so how many feature is there I I told you now uh when I'm talking about word to back there is 300 feature I shown you this example just just look into this particular example so we this is a vocabulary and we have five feature by using this five feature I'm representing my data so here actually in opena edding there is 1 5 3 six feature by using that they are representing a data so here the size of the embedding is going to be 1536 so what do you need to do guys here you need to write it down 1 53 6 now it will ask you about the metrix so what should be the metrix for the for the simulat search so here there is a three option dot product equan and cosine so here I'm using the cosine because the uh cosine is a uh like little impactful compared to this dot product and the ukan right so here just click on the cosign and here I'm using the free plan free plan of the pine cone right so now this is fine this is clear let's create a index over here if you are going to click on this create index so it is creating an index so index creating file to create capacitor is okay so I already created one index now see uh yeah now it is fine uh it is created and here you can click on the connect and there this will give you the all the details and all now this is what this is my index name testing is what testing is my index name I hope you are able to create this index and here you will get this Green Dot green icon now what I can do I can pass the name so here I can write it down the index this my index name that is what that is a testing right so here is what here is my index name that's going to be a testing now what I will do guys I will run this particular line This one this uh which I shown you uh this one pine cone do index and equal to index so let me copy it and let me paste it over here let me paste it over here and here what I need to do guys tell me here I need to pass my index name this one right so this this index name actually I can pass directly means I can pass this particular name or I can pass directly also both are fine right so I believe you are able to set your index now what I will do guys so here um just a bit okay so now guys you need to create an embedding for each uh text Chunk so let me copy it and let me paste it over here this one this is going to be here this one so this is what this is my markdown actually just let me write it down like this yes so now you need to create an embedding for each chunks okay so this is what this is my index and now till here everything is fine right now guys what I will do so I need to create an embedding right so for that let me show you the code so here is the entire code this one this is my entire code so till here everything is fine you just need to call this one you just need to set this one let me give you this code as well so from here you can copy from my uh from my code share. you can copy just a second just a wait let me give you this particular like line of code and here guys you will find out so now we have to create an embedding for each of the text Chunk so whatever uh Chunk we have created from our PDF I'm going to create an embedding for that now here I'm saying from text t. page see I'm taking a uh text actually uh this is a list now so here I'm uh using this list comprehension so so this is my list of the text junk this is a text which we are getting now from here we are going to get a page content what is a page content I shown you this is a page contain this one so I'm using this for Loop and I'm collecting all the page content over here and I'm calling this embedding I'm using this I'm using this embedding object and here is my index name index name basically which I'm uh like which I have created this one okay this is my index name okay testing is my index name so three argument we are passing over here so Pine con from text and this is what this the three argument which we are passing over here first is data first is what first is a data the second is embedding and the third is what third is a index name right this one now if I will run it so over here you will find out that it is saying embeddings is not defined okay my name is iding only now let me keep it iding yeah it is fine and it is working so here is clear to all of you uh guys can you see my okay so can you see my vs code uh it is visible to all of you uh just a second now it is visible yes or no just a second guys just a second let me check once wait wait wait wait I'm checking don't worry don't worry I'm checking right just just wait just allow me a minute yeah yeah wait guys wait I'm checking just allow me a minute just allow Me 2 minute I'm checking with that now it is working fine now it is coming to all of you now can you see my code screen this one yes or no don't worry I will repeat it I will uh revise all the thing don't worry right just a second just a wait don't worry I can revive why is the thing whatever I did over here so just a second now see uh what I was saying we have created an index right so till index I think it was fine now I just created a embedding for each of the text Chunk means whatever chunks we have created now for that I'm going to create a indexing means I'm going to create a emitting right now from here actually see this is my text Chunk this is what this is my text Chunk one uh like uh uh basically I'm iterating on top of that I'm iterating on top of the chunks so here right now I'm getting the uh like first chunk and then I'm collecting the page content similarly you can see over here this one I'm going to collect a chunk now I'm going to collect a chunk Now by using this particular list comprehension by using this particular list comprehension I'm going to collect a chunk now here is my embedding object which I have passed and here is my index name which I have created by using the pine cone website right now just look into this code share. there I have given you the entire code till here now let me give you the last line also which I have run uh which I have created over here so here let me give you this particular line and here is what here is my dog search this one now guys what I will do this is what this is my dog search right now I have to call something first of all let me show you that what we have inside this dog search actually you will find out one object this is what this is the object right this is what this is the object see uh here is what here's a pine code now from text actually what I'm going to do from text text I'm going to create a embedding so whatever text whatever chunks whatever chunks we have right whatever chunks we have regarding those particular chunks we are going to create a embeddings right so here uh you can see we are going to call Pine Cone Dot from text and here is what here is my text and here is my edding right and here is what here is my index name don't worry if you are not able to connect I will give you the quick revision at the end right first just just look over here and just see what what is happening over here right so this is what guys this is my dog search now what I will do let me show you the next line Next Step that what I'm going to do over here okay so here actually uh I'm going to find out a s see uh after running this particular uh statement this Pine cone. fromom text right so here you are going to generate an embedding now just look into the dashboard the dashboard basically which we have over here uh let me show you so once you will refresh it now this one so here you will find out all all the embeddings all the embeddings from our PDF from our text right so just wait let me uh show you that here guys see this is what this is all the embeddings here is my uh text which I tokenize which I converted into a small small phrases and regarding that here is a embedding this one just just copy it and check it is a embedding Vector so this this text actually we are able to convert into a embeddings we are able to convert into a vector vectors and here you will find out the score also so this is representing a similarity score right how much it is similar to other sentences to other phrases right here you can see uh this is what this is my Ming don't don't worry if you not able to correlate just wait for some uh just wait for few minutes I will give you the quick revision of it right I will give you the quick revision by writing each and everything and then definitely you will be able to get it now here uh you can see this is what this is my embedding related to the particular text right and here what we have we have a score right related to this particular text we have a score this is what this is the score now what I will do so yes we are able to create an embedding and that embedding uh here you can see uh like it is visible you can uh access here also right by using this dog search uh I will show you how so first of all let me show you one example one uh small thing so what I'm going to do I'm doing a similarity search now here I'm writing query actually in the in my query actually what I'm doing I'm writing uh one statement and let me do the similarity search over here so here is what here is my sentence guys which I have written over here YOLO V7 outperform which model right so this is what this is my question this is my sentence now here is what here is my query which I'm going to uh which I have written basically now what I'm going to do I'm going to find out a similarity search right so let me do one thing let me find out the similarity search Now by using this Vector so here in this particular object we have all the vectors now I'm going to call one method that's going to be a similar to suchar and here we are going to pass our query this this particular query which I have written now let me show you what I will get over here so here you can see as soon as I run this particular uh uh like uh line okay this particular code so in the docs what you will find out let me show you so in the docs actually you can see this is the similarity search right this is the similarity search basically which we are able to get but the thing is over here we are getting in the form of Vector in the form of numbers it is not a proper sentences right now let me show you how we can convert this number into a sentences right so I hope till here everything is fine don't worry if you're not able to correlate if you're not able to understand once we'll create a project or right after the session after this particular session I will give you the quick recap of it right so based on that based on the quick recap you can correlate this particular implementation and then you can revise it right and then you can revise each and everything so over here you can see this is what this is my embedding this is my similarity search which I'm able to generate by using this particular query now I'm getting a number but I want a sentence how I can get it let me show you that also so for that guys what you need to do uh you need to create a llm means you need to call the uh uh like open API so over here uh we have this open method open a and here I'm going to create a object of it so yes definitely I'm able to call my open a API this one by using by creating this particular class right so here is what here is my llm right step by step step by step I'll try to go ahead don't worry now what I'm going to do here uh here actually I'm going to call this particular method the method name is what retrieval QA right so this is what this is my method name retrieval Q QA so this is a method this uh actually this class actually this is not a method this is a class and inside that we have a method the method name is from chain type so this is responsible for question answering if I want to create a question answer system so here in the open a itself you'll find out this retrieval QA right retrieval QA and inside that we have a method the method name is what from Chen type so here what we are doing we are passing this l M we are passing this chain type is stuff retriever is dog search do as retriever right this uh dot s retriever here you will find out this particular method right don't worry again I will explain you this particular part uh first of all let me run it and let me show you that what I will get from here so here I'm running it and here you can see we are able to create this QA the object of this retrieval QA right now guys what I will do here let me write down the query again right so here is what here is my query this is what this is my query now what I will do I'm going to um write down QA do run right and inside this run I am going to pass I'm going to pass my uh like query actually this is what this is my query and let's see what I will be getting based on that so here if I will write it down this Q qa. run and inside my query so now see guys what I'm getting over here um see I'm getting a similar see I'm getting an answer regarding this particular question I'm getting a similar search right I'm getting a similar search over here regarding this particular question now if I want to create a QA the small uh QA system so can I do it definitely we can do it now let me show you how we'll be able to create a small QA session over here so based on the PDF basically the PDF uh which uh I I'm using uh for the data right and with that I have generated a vector I have created an embedding and now over here you can see we are able to do the query also here you will find out so we are able to get it we are able to uh we are getting this similarity search in the form of uh numbers in the form of vector but here once I call this llm once I call the openi API and here is what here is my llm so I uh just use this retrieval QA and there I passed my llm I passed my uh retriever that's going to be a uh doc search itself right doc search itself let me show you what is this doc search it's the same object basically where my all the embedding is stored right so here what I can do I can show you this uh doc search. as retriever now see guys here what we have we have the pine cone actually this is the vector database openi we are using openi embedding and here my all the embedding is stored inside this particular object right now you can see over the uh UI also so here is all the embedding this one right regarding the data now what I can do see I can create one small uh QA session U like QA system over here for that I just need to write it down the basic uh code so here is my basic code guys this one so let me import one module over here that's going to be a CIS now what I'm saying that uh here I'm asking about the input so whenever I'm going to write it down the exit so it will be exit right in this condition I have mentioned that but here if I'm not uh writing down anything right so here it will be if I'm going to write down anything apart from this exit it will be continue and here you can see what we are doing QA so here we are passing the query whatever query we are getting from here and finally we are printing the answer right finally we are printing the answer now let me show you how the thing is running this this particular thing basically so what I can do let me run it and here I'm passing my input prompt so my input let's say I'm asking about the YOLO what is uh YOLO so here see based on this particular query it is giving me an answer it is finding out the iding it is finding out the similarity search and it has generated an answer based on a PDF so this is a PDF question answering right we are asking a question from the PDF and based on an embedding it is able to generate answer now I think you are able to correlate it that how the thing is working I will give you the complete uh flow right don't worry now here I'm asking who is invented who is invented the YOLO right so this is what this is my question now let's see so here I got the name I got the name now uh can you tell me about the so here what was the accuracy what was the accuracy what was the accuracy of the YOLO right so YOLO 7 uh YOLO V7 now let's see what I will be getting over here so here it is saying that YOLO V7 accuracy was 56.8 and here 56.8 AP uh test /d and AP Min SL value right so the accuracy we are getting now if I will write down exit over here so from here I'm going to exit now right from this question answer system now guys tell me uh yeah now it is perfect uh please quick uh give me a quick confirmation in the chat if it is perfect now yeah there was a issue from the internet side uh from the system side I don't know what was the sh screen got a stuck in between itself okay so let's uh try to revise this session I can give you quick revision of that and then uh we can close the session within 5 minutes right so here uh guys uh first of all see I'm using a pine cone and pine gon is what it's a vector database right so there are couple of import statement which I imported now after that see what I want to do I want to perform the mding right I want to perform the mding so on top of the on top of the data only I will I I I'm going to perform now so I will be having a data the data is going to be Text data so from where I'm getting this data I'm getting this text Data from the PDF the PDF which we have imported right the YOLO PDF the YOLO PDF right now here is what here is my PDF after uh importing the data what I did right after that I converted into a chunks by using this text splitter so here one chunk size will be approx 500 wordss right inside one chunk we'll be having the 500 wordss and chunk overlap I've given the 20 it's just the score that how many any uh like words can be overlap in each and every chunk right the chunk has been created now this is going to be a chunk size this is going to be a overlapping now this value you will find out the value of this Chun overlap between 0 to 100 right you can mention the value according to that so we have created a several chunks this is the list basically which I got after the chunking so here we have total 153 chunk and the each chunk is having average 500 wats means the size is around 500 over here got it so this is what this is my chunk now you will find out the complete list and here you will find out 152 chunks right from the data I converted my data into a chunks and there is 152 chunks actually see over here now if you want to find out the content the data from each and every chunk so here is a like way so this is my first Chunk from that uh like on top of that I'm just going to be call this particular attribute page content and there is what there is my page content there is what guys there is my page content over here which you can see now guys uh here uh you can see this is what this is my page content now you can uh get uh like page content and all with respect to each and every chunk till 152 right over here now over here I have to set my open AI key first of all after chunking and all this is fine now I have to set my openi key and from there I have to import this Ming now the size of the mding is 1536 this is based on a feature right so this is the size of the embedding now this is fine so first I got the data the second I have uh imported the open a embedding the third one I have seted this key right so here I set the key key Pine con API key and pine con API environment so here I have to set two thing the first is what Pine con API key and the second is Pine con API environment is after that you can see over here I'm going to call this Pine con init now here I'm going to pass this Pine con API key and pine con API inv environment right I have initialized it that's it now here I have to create an index so for creating an index just go with a pine con and here you will get a option to create an index right you can create a new index but if you are in a free tire so in that case you will be able to create only single Index right and while creating an index you need to pass a index name you need to pass a embedding and to search the method cosine similarity dot product or maybe some other method is there so you can select a cosine similarity over there got it after that guys see so after that what I did so this is what this is my index basically this is the name of the index now what I did here I called one method Pine con from text and here is what here is my text and here is my eding and here is my index name getting my point then what I'm going to do I'm going to create a eding and that I'm going to store inside the database here here this one okay so here here I'm storing I'm here I'm storing my embedding okay here I'm storing my embedding into my Vector database at this particular line you can see over here just just open it and you will be able to find out the you will be able to find out the text and the vector along with that gotting my point now after that what I'm going to do see here uh I'm going to query actually here you will find out the similarity score also this one right so this is based on a similarity it is going to a similar not regarding the other vectors okay so this is the score which you can see now what I'm going to do I'm going to find out the similarity search so here it is giving me a similarity search but you will find out it is a vector it is not giving me a sentence so for that what I'm going to do here see I'm going to call my open API and here this is my llm GPD model text thein whatever model is there now here is my chain type it's a stuff means it's a normal one simple chain okay now here you can see retriever in in the retriever actually this is my all the embedding this is my all the embedding right so here I'm like calling this method retrieval QA means here I'm uh like calling here I'm creating object of this retrieval QA and there is what there is my method from chain type this is my model llm model and here is my embedding all the embedding from the vector database now this is what this is my QA right I created object of QA now here is my query I'm asking YOLO outperform which model so here I'm asking YOLO output of which model if I'm run qa. run and here is what here is my query it will give me an answer it will give me answer based on a similarity search and from where it is going to from where it is giving me answer how it is going to search so here you will find out inside the vector database we have a score we have a vector so it is checking with this particular score and based on a similarity search based on a cosine similarity it is giving me answer after searching okay after searching inside the vector database which is nothing which is a pine cone and here you can see the UI of that where I have stored the C where I have store the uh like edding along with the text here you can see each and everything over the dashboard itself now let me uh scroll down and here I have created a simple QA simple QA system so based on this particular PDF so you can say uh like QA uh QA like PDF QA you can you can give the name uh basically PDF question answering and all whatever so whatever PDF you are going to upload or whatever PDF you are going to so from whatever P PDF you are going to collect a data based on that you will be do a question answering and based on a similarity score it is finding out a vector and it is giving you the response and here you can see it is working fine for me and I hope it is working for you as well now everything is clear guys tell me whatever I have explained over here I hope it is clear and it is perfect now now once you will revise it by yourself once you will run this code by by yourself definitely you will get each and everything so I just want a quick confirmation and then I will conclude the session okay tell me guys fast and please hit the like button also if you like the session if you like the content and I have explained you from very scratch from very starting so please do let me know did you like it uh now if you are able to understand then please tell me sir how the score is decided of the chunk based on a cosine similarity so we have a vector and regarding that Vector we are searching the we are we are like collecting a cosine similarity we are finding out a cosine similarity while we are creating an index at that time we have uh like defined over there the vector search will be based on a cosine similarity so that is a score of the cosine similarity okay it can read all the pages it can read all the PDF pages and all you can read like entire PDF whatever pages is there not even single all the like pages okay you can check it you can run it you can take a like PDF where you have uh 10 to 15 pages and then uh then like try to uh read the PDF by using this PDF loader or you can use any PDF loader I'm not restricting you to the till this Len CH only any PDF is there just try to use that particular PDF loader that's it great fine uh so I hope you have you have entire code over here now let me give you the further code as well after this a pine cone that whatever I have written you can directly copy from here and don't worry my team will give you the entire file and all in a resource section it will be uploaded so here is a code for the QA so let me give you that uh inside this code search and apart from that we have a code for the open all so let me give you that also so Pine con is fine this is fine now yeah this is the doc search which is uh here now let me okay this is already here so now the next code is what retriever search this is there okay similarity search just just check with that check with the similarity search I think everything will be fine now the next is what so next is this uh this particular method and here is this particular method now what I can do open a yep open a is there and here okay open AI is there now we have the next also this is the method and here you can call this qa. run so let me give give you this and let me give you this QA do run this one so fine I think now everything is perfect now everything is clear tomorrow I will teach you one more Vector database the vector database concept will uh will more clear to all of you and then we are going to initiate one more project that we are going to continue in our next week uh so from Monday onwards uh we are going to start one more project but tomorrow tomorrow I will explain you one more V Vector databases and few more topic I will try to discuss with you and I will discuss one project idea as well the complete idea related to that particular project and from Monday onwards we can start uh with that particular project and we can Implement in a live class itself okay yeah good afternoon good afternoon to all so today is a today is the day 10 and we have completed day n u actually so nine lectures successfully related to this generative AI so we started last week uh last week on Monday and so far uh we have completed nine lecture and today is a is the day 10 so today actually I will be discussing about few more uh Advanced topic and then uh next week we'll try to complete one more project uh which will be related to the uh like which will be related to the to this today's topic this RG and this Vector database and all so we have started from very basic and then I came to the lenen and open and then I discuss about the hugging phase then uh I completed one project as well we deployed also and then uh I came to this vecta databases uh so now uh if you are following me so I have already told you regarding the dashboard and all so where you will find out all the dash all the materials and how to navigate to the dashboard okay so where you'll find out the recorded session here in the uh like uh this is the Inon YouTube channel so once you will go through with the Inon YouTube channel so just click on that click on the Inon YouTube channel here my live is going on as of now so just just click on this live section just go through the live section and here you will find out all the videos now uh if you will click on this particular video where I have discussed about about the vector databases so in my previous session I have discussed about the vector databases I told you that what is a vector database why why it is required and then we have created one QA system also based on the embeding so if you don't know about it if you have uh if you haven't seen this uh session so please go and check there uh your all the basics will be clarified and once you will go through with the entire session all the session if you are beginner so definitely guys this uh session is going to help you aot a lot related to the generative a and all so I would recommend uh this particular series to all of you uh because soon we are going to and and this one and next week actually so next week we will try to do one more project that is going to be end to end project which will be directly related to this uh Vector database and all there we are going to use everything and even we'll introduce the Llama model in that particular session in the in the upcoming session which is going to start from the Monday today I I'll be stuck with the vector database itself because there is one more database which I need to discuss Then I then only you can make a differences between uh different different Vector databases so that's why I picked one more database that's going to be a chroma DV so in today's class we're going to talk about the chroma DV how chroma DV Works how it is different from the pine cone and uh on which basis on which uh like uh on which basis actually we have to decide that uh what should be my database for my and project or for my uh indry ready project so each and everything we're going to discuss over here we're going to uh like uh I will tell you in a live session so here is Inon YouTube channel where you will find out all my recordings so guys please go through with the Inon YouTube channel and try to check with the description so in the description actually we have already given you the dashboard link so here in the DH uh in the description you'll find out the dashboard link this is the dashboard just click on that and this is a this is completely free right no need to pay anything for this particular dashboard I'm telling to the people who uh joined this session first time now here what you need to do here you just need to register yourself and after that uh you will get access of this particular course no need to pay anything you just need to sign up and login and then you can navigate to this particular course now once you will go through with the Course once you will go through with the dashboard so there you will find out all the recording now let's uh go through with the previous recording so here uh is is a recording of the day n so just click on that and here in the resource section you will find out all the resources so whatever resources I uh discuss in the class throughout the entire session so you will find out each and everything inside the resource section so I discuss this uh ipb file so the ipb file is available over here so you can visit the dashboard you can download this file and you can execute inside your system and you can revise your concept now here apart from this uh lectures and resources you will find out the quizzes you will find out the assignment so just visit this uh particular dashboard and there you'll find out everything and the link has been mentioned inside the description itself so just go and check in the description uh we have already given you the link here is a link so just click on that and try to enroll yourself uh uh in the dashboard now apart from that you will find out other social social media handles and different different channels of the I so please try to follow there we are uploading amazing content related to the uh like related to the different different topics so just just follow to uh just follow Ion on the Instagram and the other YouTube channel as well like Hindi YouTube channel see once you will check with the Hindi YouTube channel so here let me show you this Hindi YouTube channel of the Inon then you will find out a same playlist in the Hindi as well so there I have discussed each and everything in Hindi if you finding out a difficulty right say if you're finding out a difficulty uh like you're not getting anything in English so here you can cover a same thing right you can cover the same thing in Hindi as well here uh we have uploaded all the Hindi session right I'm taking the Hindi session uh so you can go and check this ion Tech Hindi Channel and here you'll find out the SQL series as well so we are taking live SQL classes now see uh this uh this is a sorab actually Sor is taking a live SQL classes and we are uh covering each each and everything whatever is required for the data science for the data analytics and for the data engineering job so guys please try to check with the Inon Tech Hindi there we are uploading uh like refined content or whatever uh is a trending thing in a Hindi itself and not even a single video we are uploading a complete playlist so you must visit this particular Channel and you should check with a Content now coming to coming back to my topic so here already we have discussed uh so many now today is day 10 of of this particular of this community Series so now let start with the day 10 where the topic will be a chroma DB so yesterday I have talked about the pine con so Pine con was a vector database so we use this Vector database for storing a vector right now here we have one more DB that's going to be a chroma DB so we'll try to talk about the chroma DB as well and we'll see the differences between this pine cone and the chroma DB that how it is are different from each other this pine cone and the chroma DB now one more thing which I would like to highlight over here see many people ask about the certificates and all so let's say if someone is going to complete the course right someone is going to complete the course so definitely in their mind there will be a like question so will I get a certificate or not so that thing also you will find over here over the LMS itself so you will find out three option on top of this uh dashboard the first is curriculum the second is analytics and the third is certificate so here you'll find out the entire curriculum here you'll find out your entire analytics so what all thing you have completed are you doing assignment or not each and everything you can uh track over here inside this analytics portal now the third one is a certificate so if you are going to complete at least 40% of the course right if you're going to complete at least 40% of the course then definitely you will be able to generate the certificate now how like the course uh that that uh that will be that how like the course will be completed right so how my system will get to know and then only you can generate a certificate see after completing a video after completing this particular video here you will find out the tick mark this this particular mark this blue tick mark so that mean the meaning is that so you are uh you have completed that particular video and the course name is what the course name is a foundational or generative AI Foundation of generative AI now uh once you will tick mark on this particular video it will be completed and now you can check inside the analytics also so here just look into the analytics so your video progress uh will be there right so you will find out the video progress over here so yeah this is fine this is clear to all of you now please go and check with the dashboard there you'll find out each and everything now apart from that one more thing which I would like to show you uh so uh I will uh I would like to introduce you uh with One dashboard one more dashboard so let me show you that particular dashboard so just go inside the course section and here uh inside the course section you will find out this generative AI right inside this boot camp now just click on that just click on this particular course so there is a course name is mastering generative AI with open AI Len CH and Lama index just scroll down till last and here you will find out a complete detail syllabus of of for this particular course now here actually we are going to cover each and everything related to the generative AI we are going to start from very basic from the foundation of a generative Ai and then we'll come to the like word embedding text reprocessing we'll talk about the llms we'll talk about the hung face API and other different apis as well and we'll talk about the L chain llama index these are the different different framework basically which we use for creating an llm based application and then you will find out end to endend project also so this entire curriculum is a industry ready curriculum and we have added so many things recent l or we are updating this particular cbus uh so there are so many things coming like day today actually so we are analyzing all those thing and we are finding out so whatever is required for the industry whatever is required for the community so definitely we based on that we are trying to update our syllabus so tomorrow itself if you will look into the syllabus you will find out a new changes right because many things is coming uh like dayto day right so regarding the fine tuning regarding the like evaluation of the model regarding the like Fast retrieval right so regarding the fast retrieval regarding the different different databases or different different llm So based on that only based on a current market we are updating this curriculum so just go and check uh over there just go and check with the Inon website and there you'll find out amazing curriculum and yes so this course is going to be start from 20 uh 20th of January right and here you will find out the language we have launched this particular course in English and here the duration is around 5 month and this is going to be a timing so timing is from 10 to 100 p.m. IST and this will be a live course right and here you will find out your instructor so Chris sir is there Sanu is there me uh is there and here is a buy so buy will also take a session uh means will also be a mentor along with me Sudan Su and Chris so guys uh please go and check uh with this particular dashboard with this particular course and for the further information you can contact with the sales team here you can drop your information so my sales team will contact to you fine so I hope I have clarified each and everything now if you have any sort of a doubt you can ask me and then we'll start with the Practical implementation tell me guys uh do you have any doubt sir where to find neurolab code for the McQ generator project it is not updated on GitHub so here is my GitHub which I already uh uploaded in my resource section you can go and check with a resource section let me give you that uh GitHub just a second and don't worry I will be pasting inside the chat also just go with my repository my GitHub repository there you will find out this McQ generator right this is the application not this one this one generative AI so let me open this generative Ai and yeah this is the app this is the complete application which I added in my uh resource section also let me show you where you'll find out that so Foundation generi course and here is the this is the just wait first let me give you this particular link and then uh I will show you so I'm giving to my team and they will uh directly P inside the chat okay just wait fine now I think we can start so guys uh all clear sir estra DV is a vector database or it's a no SQL database it's a no SQL database estra DV actually in a backend it is using the cassendra and cassendra is a no SQL database yesterday I discussed that whether you can use or not this estra DB this cassendra is a vector database I given you the each and every information regarding that just just look into that just go through with my previous session you will get to know uh great now I hope everyone is getting that so can we start here is a pine gon one so please give me a quick confirmation if we can start with the session then uh uh I will start writing the code so let me open my code share. also here I'm going I'm going to paste each and everything each and every line so I will okay let me give you this particular link also I'm giving you this code share. iio link just a second yeah this one so just a second guys you will get this particular link where I going to paste each and every line each and every line uh whatever I'm writing inside my Jupiter notebook so today uh we going to start with a chroma DB so for that guys what you can do so here first of all let me close everything and here is what here is my session which is going on so let me keep it somewhere and yes now it is perfect great so uh first of all what you need to do here here so first at the first place you need to launch your neural lab so just click on this neural lab guys just click on this neural lab and once you will click on this neuro lab so here you will find out this type of interface now there is two option the first option is start your lab and the second option is my lab so just click on this start your lab right if you have already created a lab if you have already uh created your uh jup instance definitely you can uh go inside my lab and you can launch the same jupyter instance and there you can write it down your code after creating the IP VB file that is also fine but I'm showing you from starting so here guys what you need to do you need to click on this start your lab so once you will click on that so it will ask you about the sign in and all so here you can sign in guys you can pass your email ID and it is completely flee no need to uh like pay anything for this neuro lab as of now so here you can see we have a different different stack so big data analytics data science programming and web development so what you can do here you can click on this data science so what you will click on that so here you'll get all the option whatever is required for developing a project in this data science if you are going to develop a project uh inside the data sence so here you will find out all the ID all the ID we have given you in the form of template you just need to click on that and you can launch your instance so now let me show you with this Jupiter so in today's session we're going to use the Jupiter and in the next session we're going to use this cond cond for end to end development and Jupiter just for the ipynb implementation right now here what I'm going to do so here I'm going to open my Jupiter so it will ask you the name so here I can write down the name chroma DV so today in today's class we're going to talk about the chroma DV which is nothing which is a database Vector database and here what I will do I will proceed it and then it will be launching the lab so guys please do it please please uh do along with me because today I'm I'm I will be going very very slow and each and every line of code I will be pasting inside the coda.io so that you can copy from there how many of you you are doing along with me please uh write it down the chat I'm waiting for a reply sir I have a interview for the gener position can give me some tips and project so if you are asking about the tips if you have a generative AI uh like if you have an interview to generative so first of all your foundation should be strong and there you need to discuss about the project right so the the pro whatever like practical implementation I have discussed throughout this commun series you can go through with that and you can prepare that so the question you will get around to that only so there will they will ask you uh are you using this API why you are why you are using it what is the cost of that can you prize it what all Alternatives we have so what is the concept of the vector database why we cannot use other database what is the concept of the RG how we can finetune the model what is the cost what will be the cost of the fine tune fine tuning of the model can be like can we like keep in keep it in a scal scalable mode or not right so uh can we do a uh like like CPU based finetuning right there is a like if the model is very very huge so in that case how uh if the model is very very huge so in that case how I can load it so in that case you need to say that I I can use the quantize model model so this type of question you can assume inside the interview right so don't worry I will share one PDF there I will keep all the interview question related to the generate Ai and it will be available on your dashboard got it don't worry got it raes Ramesh nangi fine uh I think it is taking time so let me refresh it and then again I will launch just a second guys I have refreshed it now let's see oh why it is taking too much time yeah now it's done so let me launch then uh I kernel let let me launch this IPython notebook so please uh give me a quick confirmation if you are able to see this tell me guys so here I can print all okay yeah so guys all okay no we are not going to do a fine tuning in a community session so we'll restrict this community session till uh the project itself till that end to end project where we are going to call the API that's it the so tell me guys all okay yes or no and I think everything is visible to all of you right so can we start and first of all let me save this notebook so here I can write it down this chroma DV so my notebook name is what my notebook name is a chroma DB so let's start uh let's start with the chroma DB so first of all guys uh let me give you the brief introduction about the chroma DB that what is a chroma DB and why we are using it so let's uh search together and here let's search about the chroma DB so once I will search uh here the chroma DB so here you will find out the very first website of the chroma DB just click on that and let me open it first of all so here is what here is a chroma DV guys now they have given you the different different option right so here you will find out a different different option on top of this website so the first one is a documentation the second is a GitHub the third one is a discard Community the fourth one is a Blog and here they have written that we are hiring and here launching multimodel so they have announced multimodel also now from here you can start here you can find out the demo as well so you can uh like check with the demo and here you will find out the the complete architecture which they have given to you and like what you are going to do here tell me you are going to convert your queries into a vector and that Vector basically are going to save it right that Vector that particular Vector you are going to save it now here uh let's try to discuss about the uh difference between this chroma DB and the pine but first of all let me go through with the documentation so here is a demo demo of the chroma DB which you will find out over here inside the collab notebook which they have provided you over the website itself now if you want to look into the source code so here they have given the source code as well this is the GitHub just click on that and here you will find out the complete source code of the chroma DB so the uh this chroma DB is a open source database and here you can see the number of contributor how many contributor is there 86 contributors is there like 10.7k people has already used this particular um database now here you will find out the 9 92 commits and if you will look into the package if you look into the pp package so let's see the first version and the last version the latest version of the chroma DB so here you can write it down this chroma DB chroma DB on top of the Google Now here you will find out the web this uh P by page so this is the latest version of the chroma DV 0.420 right now if you will look into the previous version if you want to check with that so just click on that just click on this release history you'll find out the entire history of this chroma version so how frequently they are updating the thing uh so they haven't completed even one year right and here you will find out that these many of version uh like you will find out you will get it related to this chroma DB because it is a open source now here you will find out so many contributor inside this chroma DB you can check with the contributor list you can check with the contributor name here and here you can see the entire community so guys uh this is the contributor now used by 10.7k people and here you will find out the fork number of fork and the star so just go through with this particular GitHub there you will find out the entire detail related to the chroma DV where you will get it so you will get this thing or the website itself so here on top of the website you'll find out a different different options so they have you there you will find out the GitHub and even you can join the community of this chroma DB so they have given you the option of the Discord so just click on that and you can join their community on Discord so whatever doubts and all you have so you can ask it over the Discord now coming to the documentation so here is a documentation of the chroma DB so just look into the documentation here you will find out each and everything whatever is required for understanding this chroma DB so let's start with the getting it started now here they have given you the two option the first one is going to be a python this one and the second option is going to be JavaScript right so the first option is a python the second option is a Java script now uh here you will find out the installation detail how to install this thing now here you'll find out how to create a client from the chroma DB so if you want to create a client of the chroma DB so here is a option for creating a client for the of the chroma DB now here uh how to create a collections and all so this is the collection and here how to add it now how to query The Collection each and everything you will find out over here so guys once you will install this particular package you will get everything over here this is not a cloudbased database it's a like a local database there if you will download this thing so everything you will get inside the local itself so there the first major difference between the pine cone and the chroma DB so chroma DB actually it's not a cloud based database and here actually see it's not a cloud base here everything you will do inside the local itself right so here you will do everything inside the local itself in your local workspace but if we are talking about the pine cone so it's a cloudbased database so in that you have seen you must have seen let me show you the pine con website as well so here if I'm writing down this a pine con so you will find out here over the pine con that it's a vector database for the vector search now just scroll down here so here you will find out a different different Cloud oper Cloud uh operator so it is fully managed by Google gcp AWS and AO anywhere you can create an instance and then you can utilize it after installing this inside your local system so everything will be available over the cloud after configuring this pine cone so that the first major difference between the pine code and this chroma DB now coming to the point so here uh we are talking about the chroma DB so let's try to check with the Google itself what is the difference between chroma DB and the pine con so uh everything is available to the Google so here actually I found out uh find out one article so let's try to look into this particular article and by uh like reading this articles and all you can understand because this is a recent thing Recent research okay it's not like that that people are working on this on top of this since last like 10 year or 15 years so you will find out that there is a recent active community so whatever you will find out you will find out on top of the Reddit on top of the strike overflow GitHub or you will get a knowledge from the documentation or from a different different blog so just try to read this particular blog and let's try to understand the difference between Pine cone and chroma DB now what is the pros and cons so with that you will get a some sort of idea that if you are going to decide about a database whatever database is there right so whatever database is there whatever Vector database is there so on which point right on which topic you need to select the database what all thing you need to consider over there that is a main point so let's try to discuss let's try to see over here so we are talking about the pine con guys so Pine con is a manage Vector database designed to handle real time search and similarity matching at scale right so here they have clearly mentioned that this uh pine cone data base it designed to hander realtime search and similarity matching at scale which we have seen in my previous class which we I have shown you in my previous uh like a lecture itself you can go and check it's B on a state of art technology and has gained popularity of its use cases of performance right so here uh it is easy to use and it is uh performing well because of that it gain the popularity now let's delay into the key attribute advantage and the limitation of the pine cone so here just look into the pros and here they are saying that it is for the real time search it is for the scalability definitely we are going to use the uh cluster on top of the cloud so definitely we can do a horizontal scaling over there right so this is the scalable B so architecture has been designed in such a way the installation and all the computation and the dbm database management is happening in such a way that it is a scalable and it's not a vertical scale right it we can do a horizontal scaling regarding this pine cone now this is for the realtime search here you will get the automatic indexing So Yesterday itself we have created one index and there you will find out along with the vector you will find out that we were having an index column there we are having the scoring and all so automatically indexing right you no need to write it down anything automatically you will get the indexing now here python support so this is a very important thing if if you are going to develop any application in data science in machine learning and deep learning where heavily we are using python so yes definitely it is supporting of python as well got it now what is the cons of it so cons wise here you will find out the first one is a cost right so cost is a like major disadvantage of this spine cone so we cannot use the spine cone freely so here if you will look into the pricing of this spine cone so there you will find out the different different pricing so if you are a starter if you are a beginner definitely you can go with a free tire but let's say if you're are not a starter if you're not a beginner you want to use it for some sort of application right where you are going to implement some PS and all where you want to uh Implement some realtime use cases for your organization for your project so you can take this particular pack where standard is there now here you will find out uh these many thing you can check according to your requirement and let's say if you want to productionize something right so let's say if you are working in a company and there you want to productionize something and here so what you can do you can take this Enterprise solution so there you will find out many more thing you can check with the pricing detail you can talk with the pine cone team right Consulting team they will guide you regarding each and everything so the first thing the first disadvantage you can see over here that is a cost itself the second disadvantage you will find out limited query functionality so while Pine cold Xcel as similar to search it might like some Advanced query capability the certain project required maybe the mathematical model they are using the different different meical medical model they are using behind that like like cosign similarity dot product so it is not working in that much effective way which people has uh felt right even I haven't checked with this particular cons right I haven't checked that this is uh having a limited query functionality because I uh just check with a certain use cases so guys if you are getting this particular con so definitely before starting with the Pyon before productionize it right or before uh like uh using inside your U like project definitely you should consider to this particular point where you have a limited query functionality right now how to use pine con I think I already told you how to use pine code I'm not going into that much detail now let's talk about the chroma DB so chroma DB is similar to pine go just just try to focus now just for 2 minute next for 2 minute and then I will go with the Practical implementation right so if we are talking about the chroma DB so it is similar to the Pine go and designed to handle Vector storage and retable means we can store the data and we can retrieve the data right so it offers a robust set of feature that creator that c various use cases making variable choice for many Vector application right so here uh clearly we are getting that that we we can use this chroma DB for storing the vectors right we can store the vector and we can retrieve the vector right now here you will find out a different different pros and cons so the first Pros is there that is what that is a open source right so open this chroma DB is a open source Vector database base here I have shown you the code of this chroma DB right you can you can like uh check with this particular code now here you can press the dot so this entire code will be available inside the vs code now you can go through with this particular code and you can check that what all files and folder they have created and what all thing they have written inside this particular project right so you can consider there's nothing just a project only now here you will find out a different different files and folder and now they are maintaining the this thing in the form of package also so on top of the pii repository you will find out this chroma DB in the form of package so from there you can install it by using the PIP install Command right now just look into this chroma DB that what they have written so here they have written of they have created a various folder so the first one is a API now here you will find out a different different API let's try to create click on this fast API just read the code from here and here you can see the all CLI so this is the real time project right which which they have deployed in a real time and which they are using right which everyone is using and there you will find out the number of force number of star number of contributor each and everything you can see so there's a first uh advantage of this uh chroma DB that is a open source now extensible query chroma DB allows more F more flexibility quering capability including complex range such and combination of vector attribute so here you can think that or here you can assume that uh this chroma DB is working well right compared to the pine cone where I have to do a similar search right so here they have clearly mentioned inside this particular block based on their own experience that this chroma DB is working well for the similarity search if you want to find out some sort of a combinations and all in that case it is going to work very very well now Community Support is very very high as I told you that it's a open source right so here you will find out the complete Community just go back and check with the GitHub itself so here is a AT3 contributor 86 contributor and if you will look into the website if you will look into the website so there you will find out the Discord GitHub slack everything they have provided to you uh for uh connecting with the community so if you want to connect with the community so there they have given you the different different ways right so this community the community of the chroma DB is a very very strong now let's look into the cons so here I told you that this chroma DB uh set this chroma DB is not for the deployment deployment complexity is there because you won't be able to find out this chroma DV on top of the cloud right so they uh the pine cone basically already it is running on top of the cloud there you just need to consume it by using the API right there you need to use this chroma DB there you need to use the pine cone by using the API but it is not same with chroma DB actually this chroma DB whenever you are going to use it it is not available in the form of API because it's a open source package you need to install it inside your local workspace space and you need to use it right you need to install it inside your local workspace and you need to use it so if you're going to deploy it right if you're going to deploy it so there you will find out a complexity so here just read U the complexity Point setting up chroma DB chroma and managing it scale might require more effort and expertise compared to many solution like pine cone because in the pine cone you're just consuming the API right you're just consuming the API everything is there on top of the uh third party server everything is running over there you just need to consume it by using the API but here in the chroma DB the thing is not same deployment complexity definitely will find out because there is a no like Cloud support as of now for the chroma DB you will have to install inside your local workspace and you will have to set up each and everything got it now performance consideration yes uh definitely this thing also will come into the picture if we are talking about regarding the realtime use cases so performances also might be here and there so there are some points you can uh search about more regarding a different different like regarding a different different Vector database and from there you can uh like pick out you can pick up this particular points this particular heading and you can do your own research so whether it's a scalable whether it's a whether there is an indexing for the fast retrieval whether there is a python support or it is fine for the deployment so you can pick up this point and based on that you can make a differences and based on that you can understand actually right so I hope guys you are getting it now uh the differences is clear so please do let me know in the chat if uh the differences is clear to all of you then we'll uh go for the coding yes or no yeah thank you Sati so sa saying Sun sir I have enrolled for the Gen 10% discount got the python free recording with that that's a big surprise great great satis congratulation so yeah now uh I hope this part is clear to all of you now let's start with the Practical implementation of this chroma DB so here uh for uh implementation actually first of all we'll have to install some Library so whatever code whatever code I'm pasting over here in my jupter notebook the same code I will provide you in my code share. I also so here is my code guys which I'm going to run now the same code I am pasting in my Cod share. so that you can copy from there so did you get a link of this Cod share. IO please do let me know in the chat please do confirm guys if you got the link of this code share. iio so don't worry my team will give it to you inside the chat and from there you can copy the entire code how to find tune the question answer data using lar 2 model and I don't have context but I have only uh question answer and I have so that is that the the fine tuning also we can do that but for that we required a huge amount of resources and based on a Model also like which model you are going to use so as of now I'm not going giving you the detail regarding the fine tuning and all I understand that's going to be an important topic but yeah so here I'm talking about the vector database and then we'll start with one more project and after that maybe we'll take few more classes we'll try to discuss about the concept of the fine tuning right but as of now you can think that uh like if you have your own question answering data right so there might be a different different technique right different different technique for the finetuning the recent technique which I was searching the recent technique name was the parametric effective fine tuning so what's the meaning of that parametric effective fine tuning so there you have the question answer there you have your data now based on that you have to train the model which will be required a huge amount of resources and you can do over the uh like C CPU also on like on a low cost also but for that you will be required a quantise model so that is a different thing how you can quanti your model and then how you can do a find Uni there are some uh more techniques comes into the picture like Laura and Cur that is also a technique a different different technique regarding this uh parametric effective fine tuning so we'll try to discuss it right and for that only we have designed the course just just look into that each and everything we have mentioned over there where we are going to discuss everything you know very very detailed way got it now here uh I have given you this particular link and here is a installation statement pip install chroma DB open Lang and Tik token you need to install this for library now here guys uh let me install this library inside my inside my environment just a second are you doing it can I get a quick yes or no in the chat if you are doing along with me and please hit the like button guys please hit the like button if you're liking the session because I can see uh you have joined the session but uh you're not writing anything inside the chat and you're you're just watching don't don't do like this hit the like button guys and if you have any sort of a doubt just just uh write it on the chat just cheer up okay so let's make it more interactive got it yeah it is installing now let me give you few more libraries so just a second I can give you few more Library which I kept somewhere okay that is fine now after that you can check with this particular command so here is a command guys this one so let me give you this particular command PIP show chroma d DB just uh check with this command that your chroma DB successfully installed or not here's a command the command is PIP show chroma DB yeah it is perfect now it is done so have you installed it having installed uh this all the library tell me guys fast then I will proceed further now you can check with the chroma DB then you will find out the detail of the chroma DB so it is giving you the it will give you the detail of the chroma DB there is a simple command PIP show chroma DB so we have installed the chroma DB on the uh workspace in the latest workspace and here you will find out the detail of the chroma DV this is the latest model this is the latest model Vishnu I have already shared the code please go and check with the code share. okay join the session on time because again and again I won't repeat a same thing so please we aware V Active I'm sharing everything that's why there is a like cod share. which I have shared with all of you okay just copy from there and paste it inside the Jupiter notebook yes we have a gen related project just check in a commune session also we have completed a project and even in the course also we have a project so rames please check with the course please check with the dashboard now I think uh till here everything is fine everything is done see the first thing what I need to do so here actually I need to I need to uh like uh I need to get I need to download a data so from here from this particular link I'm going to collect a data right let me show you uh what we have on top of this part on over here actually at this particular link so for that just copy it and paste it inside your Google so just just paste it over here open the Google and paste it in your Google now just a second yeah so here is a Dropbox guys so in the Dropbox actually you will find out this particular data right so just a second uh let me show you this data m specifically we have this data just a second guys so here in the URL box I can paste it yeah so here is a data guys so the data actually it's a news article so just just see the article uh it's a news article so AI powered supply chain startup pendo lens 30 million investment txt just open it and read it right this data is already available somewhere where in the Dropbox so I just shown you this particular link and we are going to like use this data for creating embeddings and for like uh and then we'll uh then we'll store the embedding inside the then we'll store the embedding inside the vector database so this is the data basically which we are going to use here we have a several text files so just go through with the data there you will find out the entire detail related to the data uh so here is a one more article replace TB writers strike. txt so go and check with this particular artic article now here is one more article just go and check with that particular article so this is the article everything you need to know about the AI power chb right so different different article you will find out over here check the AI power data protection project right so there are so many article which we are going to use which we are going to use for our uh like this this is the article which we are going to use for our embeddings and all by using this data by using this text data by using this particular data text Data what we are going to do we are going to to first we are going to convert a chunks right and then we are going to convert those chunks into a embedding by using the embedding model I will show you which embedding model we're going to use so we are going to use the openi model but there are so many embedding model you can use the buttu bag there are so many model you will find out over the hugging phas also so it's up to you you can do a Google search I will show you how to do that and then you can select your model as per your requirement right now here this is the data now let me give you the data link over here by running this particular command so this is the data link and by running this particular command here is a command guys where is a command this is the command so by using this uh particular command you can install the data or you can load the data or you can download the data into your local workspace so let's see let uh me show you the data basically so here you just need to run this command so just press shift plus enter and see left hand side your data is is getting installed and yes it is done now here is a j file see guys there is a j file news article J file left hand side in the left hand uh in the workspace basically you you will find out this news article. jip but if you want to unj this data so for that also we have a command now let me give you that a particular command so the command is what command is nothing unip hyphen Q news article you need to be uh like unload it uh you need to be like unloaded right you need to be unzip it uh and here you will get this data inside this particular folder now let me show you let me run it and here you can see we have our data inside this particular folder so I'm giving you this command I'm giving you this particular command just a second you can check and you can run inside your system so here is a data guys here you will find out the data now let me unnoted uh this particular thing this is the data data is about the news article so news article data and here you will find out the command which you can run and with that you can install you can install this chip file install the chip file in your local workspace where you need to install guys tell me need to install this work file you need to install this file inside your local workspace so let me write it down here local workspace and with this particular command you can unip it so so by using this particular command you can unip it so each and everything I have written over here you just need to copy and paste inside your Jupiter notebook that's it right great so please use the if see someone is saying ra is saying Sir W get is not working so here W get is working now this use this with escalation mark right and use the neural lab I haven't shown you this thing by using the collab or maybe this local setup I'm see in Linux environment definitely it will work but if you are using the Windows system so in in that case it might not work so use the Linux environment and this lab actually has been configured on top of the Linux environment in a production you will find out the Linux environment only because for that you no need to pay anything it's a open source right so just like required a small amount of the Linux server but yeah if you are like using a Windows server in a production so definitely it's going to charge you very very much so here is a Linux environment which I'm uh like where I'm executing all this command so w Is there anip is there now let me run the next command so here the next command is what what so here I need to set my open a API so I got the data here you'll find out basically I got the data this is what this is what this is my data which I got in my local workspace now after that I'm going to set my I'm going to set my open a API key you know it how to set the openi key many time I have shown you in my lecture so for that you just need to go through the open website open the open website and here search uh just click on that the and then click on the login you'll find out two option the first option is the API and the second is a chat jpt so just click on the API and then click on the API key so here you will find out the API key so this is the API key basically which I have generated and here I have passed it inside my note book also so just if you will see into this API key so here I pass this API key into my notebook this is what this is my API key right now what I can do guys see uh just a second let me pass the correct one because I'm using the old API key over here just a second just allow me a minute okay I kept it somewhere I kept it uh and you have to generate your opena API key I'm not giving you that uh because for that I have paid actually so please use your API key uh there are so many person which join the session so if they are going to use my open key definitely it will be rushed out so please use your op key please generate it by yourself initially it will give you the $20 credit so you can use it now here uh there is what there is my open a API key now it is done tell me guys still here everything is fine everything is clear to all of you please uh do let me know in the chat if everything is going well so far so I'm waiting for a reply and I'm giving you this particular command there you can paste your openi key and you can run it so this is for the openi key tell me guys fast waiting for a reply if you are done till here then please do let me know then only I will proceed sir I for the P can I my I on team yes Sati you can ask your doubt uh to the Inon team they will assist you regarding your all the doubts all the concerns so please give me a quick confirmation guys if uh you are done if you are able to follow me till here then I will proceed further tell me guys fast waiting for your reply please or do let me know and please hit the like button guys uh if you're liking this session and yeah you can write down the chat chat also whatever doubt you have while you are implementing it and don't worry today the understanding will be more clear regarding this database regarding this Vector database compared to the previous session because today uh because already we have learned it now right so today is a kind of revision so don't worry we have uh created Creed one project also and after the after this Pro after this like implementation I will show you the project architecture also so uh in the next class we are going to discuss about that particular project we are going to implement from a scratch and there you will get to know that how this Vector datab base is being used right so we are going to create one chatboard and the chatboard is going to be a medical chatboard we are specifically going to train on top of the medical data right so just stay tuned with us uh in next class uh we'll create one more project and we'll try to use it the we'll try to use the flask over there and fast API and we'll deploy it also right got it great now here after that I have imported few libraries now let me give you this libraries inside the uh like cod. I so there what I can do guys here I can uh write it down you need to import this a particular Library so here I have written you need to import this are libraries libraries so just just copy it guys and after copying it you can uh uh run inside your system so see guys if I'm running it then definitely uh where is my not yeah this one so here you can see after running it uh after basically importing it what I need to do I just need to run it so see I'm able to import each and everything now let's try to understand each and every detail about this libraries about this import statement so for that uh just a second I can open My Epic pen and that there I can explain you each and everything sir can I exp experience certificate with a paid course yes definitely in certificate and experience certificate will be available right so actually you can generate it um I given you the walkth through in my previous session just just check and uh check with those particular like session just go through with the introduction itself uh so there I have discussed about the internship portal as well if you don't know don't worry again I will open that and I give you I will give you the walk through so how you can complete the internship on top of the generative AI because we are going to add more and more project related to the generative AI with a different different uh like domain so you can complete your project in a multiple domains right so don't worry uh like I will show you that is still it is in a pipeline uh the project will be uploaded Maybe not today in the next class definitely we'll be talking about it right so let's try to discuss about this Library so here is the library the first one is the Len chain do Vector store and here is a chroma right so chroma it is this for the chroma DB this for this is what this for the chroma DB now here this is for the open a embedding and as I told you right so uh we can generate a embedding right we can generate the word embedding and this word embedding is nothing this word embedding is nothing it's a vector only so what is this tell me this word embedding is nothing it's a vector it's a vector right so here actually this open I already uh trained so they already took the data and they already trained one model and by using this particular model they have generated a Ming now how to do that so how to do that tell me guys so here regarding this particular data regarding this particular data definitely they must be having the uh like vocabulary they have generated one vocabulary and for this particular vocabulary they must have created the features right so features and they are passing each and everything to their model and this model is nothing that's going to be a neural network right this is going to be a neural network and yes based on that they will they are going to generate the embedding right so I told you that how to generate embedding and all if you will go and check with my previous session there I have discussed about this embedding open AI embedding now here we have one more package open AI this is for the this we calling this open a API so by using this one we can call the open API directory loader we can load the directory text loader we can load the text and all whatever uh like files we have now we have in a text format so by using this uh text loader we can load that particular data that particular file so let's try to uh load it now so for that also we have a code for loading a data and here is a simple code let me copy and paste it over here and along with that let me copy and paste inside your uh inside the inside the Cod share. also so please copy from here each and everything I'm giving you uh so you just need to copy it and you need to paste it inside your system so here what I can do guys here I can write it down for loading the data and guys believe me after completing this much of thing the understanding will be more clear to all of you so for loading the data let me write it down over here uh just copy from here and paste it inside your system now what I can do here I can load and inside this news article so Globe is for what Globe is for all the text files so whatever text file is there so is going to read the data from the entire text file right so it's going to read the data from the entire text file for that you just need to mention one parameter the parameter is going to be Globe right dot means current directory SL star means what so here we have written the star so what is the meaning of the star so star is nothing star is representing the entire directory right so whatever file name is going to start from this txt we are going to load the entire file we are going to load all those file that's it that's a meaning of the simple code now if I'm going to run it you will find out that we are able to create a loader over here I just need to call one method now I just need to call one method and the method is going to be do load so let me run it and you will find out that it is giving me a syntax error now let me show you that yes we are able to load the data so it is saying that the file is not there okay let me remove it and here is this home Joy on news article is not there why it is so oh just a wait let me copy the path to sharable link should be treor news article so is this a path just a wait just a wait guys just a wait let me check once lab directory okay why it is giving me this issue copy the path and paste it over here that's it are you facing the same issue my open is expired you can generate a next one now you can generate a next API key uh it is giving me a issue guys just a second let me delete it and let's see whe whether I will get up so this is the directory actually see home Jan just copy this directory and just copy this complete directory and dismiss it and keep it over here now let me check yeah now I'm able to do it so guys here see once you will do the right click and just click on the delete just click on the delete so it will give you the complete uh directory I don't know why I was not getting by using this copy path but yeah now I getting it so are you do it are you able to do it are you able to load the data are you able to load the document please do let me know yes or no so here is what here is my uh document please again give me a quick confirmation guys if you able to load the document so just wait let me give you this line also this uh loader. load and please try to load the data by using this loader. load tell me guys if you are able to load the data then please write it down the chat I'm waiting for your reply tell me first are you enjoying the session do you like the session guys tell me do you like the session so far all all your all the doubts and all is getting clear yes or no tell me oh great so I think till here everything is fine everything is clear now we got our data right so we got our data now what I will do here so just a second let me show you so first of all we have a data now guys tell me after getting a data what I will do any guess any any guess anything just wait just wait yeah so after getting the data what I will do so after getting a data I will create a chunk right so let me copy and paste this particular code over here what I can do just a second this data is very very huge so actually it is taking time if I'm scrolling down just a second yeah now it's perfect so here actually you will find out a data related to all the text file right so you got a data related to all the text file now here you need to create a chunk so for that basically I'm going to use this particular library and here we have few more code right few more code few more thing uh so let me give you this particular code and then I will explain you the meaning of it because yesterday also like many people were asking to me sir what is the meaning of this particular Cod code why we are using it uh like what we are doing over here what is the meaning of this uh text splitter split document and all each and everything we going to discuss over here now uh let me open my Scrabble link right and here we going to discuss about each and everything so what I can do let me zoom in first of all and now it is perfect so let's try to understand so guys at the first place what I did just tell me guys so at the first plate at the first place we have uh we have generated a data right so here actually we have a data so we got a data from somewhere this is what this is my data right after getting a data after getting a data what I what I'm doing guys tell me so after getting a data I need to convert this particular data into a embedding right so what I need to do I need to convert this particular data into embedding now here I got a data and I'm going to convert this data into embedding can you tell me which model we are using for this embedding can anyone tell me which model we are using for this embedding anyone fast which model so we are using open AI embedding model open AI open AI edding M bidding model right we are going to use open AI edding model now guys here we are talking about this open a embedding model so just just look into that just just open the model here what I can do uh let me show you the open models here I'm searching about the open models right so you will get all the models over the whatever model is there over the openi platform so these are the model Guys these are all the model which you can see here right so GPD 4 is there GP 3.5 is there Delhi TTS whisper embedding is there so just click on this embedding right so just click on this embedding and here you will find out the embeddings and all right so uh text generator uh text uh moderation latest model max token you can pass 30,000 right 32,000 now here is a GPT based model So weage based model so there is like you can pass 60 16,000 token there uh is a d Vinci model there you can pass 16, 384 token now there is GPD 3 based model so there you can pass 2,000 token right this this is the token now actually in our case we are going to use the GPT based model this this GPT based model so we are going to use GPT 3.5 turbo right so here which model we are going to use we are going to use GPT 3.5 turbo right so here GPD GPD 3.5 basically we are using so now just just look into this in a GPD 3.5 uh this this model by default actually we are going to use this particular model now tell me guys what is the total limit here what is the total limit the total limit is 4,960 right and here if you will look into your data so this is your this is what this is your data now just look into this particular data now here are guys there are so many tokens there are so many words if you will calculate the words so definitely is going to exceed 4,000 right so definitely is going to execute 4,000 exceed 4,000 now let's say let let's talk about that if you are working in a real time so you will get a very huge amount of data you are you will be getting a very huge amount of data and here if the sentence is going to be a very long in that case there might be a chance that my model will not be able to sustain the context right my model will not be able to sustain the context and here you can see the there's there are like two long text right and here by defa which model we are going to use we are going to use this GPT 3.5 turbo this this particular model uh basically whenever we are going to use the llm right we are going to use this particular model which is going to be a gbt 3.5 turbo and here you can see the tokens limit 4096 tokens right 4096 tokens now here the data which we have in inside that we have a lots many tokens right so we have a tokens which might exceed more than 4,000 or let's say this is not going to exceed more than 4,000 but let's say if you are working on some realtime data and there there you are getting a data which is very very huge and which is exceeding the number of tokens right whatever model you are using let's say you are using a topmost model where you can give 30,000 token but still it is exceeding the limit in that case what you will do so you will provide your data in terms of chunks what you will do tell me you will provide your data in terms of in the form of chunks right so that is what we are going to do over here so over here guys what I'm going to do see uh here is what let's say here is my data right and here is what here is my Ming I want to perform the Ming now what I will do here I I will keep one thing so in between this data and this Ming right so actually after that after this eding and all what I will do tell me I will pass my model now I will pass this thing to my model right so I cannot deny with this thing so I'm going to pass this thing to the model and here we have a data right we have a data and in between actually what we are going to do we are going to do a chunking right what we are going to do we are going to do a chunking now let's try to understand what is the meaning of the chunking so let's say we have a data right so what what I have guys tell me let's say we have a data now what I have to do I have to do a Chun right I have to convert this data into a chunks now here in the library which I have imported there you will find out two thing two words so let me do one thing let me copy and paste this thing from here so here what I can do what is happening okay where is this oh just a second guys just a wait yeah here is a code guys see so what I'm going to do from here I'm going to take uh I'm going to copy this particular line this this particular line right now let me copy it and let me paste it over here so here is what here is my dis link so here I'm going to paste this a particular line and now guys here actually you'll find out two thing the first is a chunk size and the second one is what overlap right so what I'm going to do so here I'm going to copy and paste some data from here itself right just just focus everything will be clear over here so here is what here is my data now let me copy this particular data this is my data this one page content now I'm going to copy this particular data and I copy let's say till here right this just for the demo this just for the demo nothing else right so here is what guys here is my data which I kept over here right now just just looking into this data so here's my data which I just took for the demo so the first thing which I have defined that's going to be a chunk size right chunk size now what is the meaning of that so here actually let's say uh I'm going to divide my data into chunks what I'm going to do tell me I'm going to divide my data into chunks so I want that I want 100 tokens over there here here I have written thousand right let's say I'm giving 100 tokens so what is the meaning of that means let's say there is first Chun one Chun in that until I'm not going to complete 100 tokens let's say from here to here from here to here we got 100 tokens right so I will stop over here and that data so that is what there is my first chunk now again there will be a second chunk so it's going to start from here and let's say till here so here I'm going to complete my 100 tokens so this is going to my third chunk now there is a third uh third chunk basically so in the third chunk you will find out we are going to start from here and let's say till here so this is going to be my third chunk where I'm able to complete my 100 tokens and what is the meaning of the tokens so tokens is nothing it's going to be a word so what is the meaning of the tokens tokens is nothing the word itself is called a token right so if you are going to complete 100 words in that case I'm able to generate my first chunk I'm going to generate my first chunk and why I'm doing that because let's say data is very very huge so I cannot directly pass that particular data to my model it will Ex the limit so the better thing is what I'm going to provide my data in terms of chunks in terms of small small chunks right so it will be able to sustain the context also and my limit is not going to exceed got it now here you have a three chunks regarding this particular data let's understand the meaning of this chunk overlap right so let's say instead of this uh 200 I'm just writing 20 right so now guys let's say uh my first CH is going to start from here to here right to here now second chunk is going to start from the from this if from here to here right here now let's say uh I'm writing 20 so what will happen you know what will happen so it will take 20 wats this this second this second chunk this second chunk it will take it will take 20 words it will take 20 words from the previous sentence so let's say this is a 20 words this this is a 20 words now this 20 words will be carry forward to my second chunk now here we are talking about the third one third one so here let's say from here to here from here to here this is my third chunk now if I'm writing chunk overlap is 20 so from the previous sentence from the previous chunk my 20 words is getting overlap mean means it is going to forward is it is carrying forward to my next chunk getting my point what is the meaning of this chunk size and why we are doing that what is the meaning of the chunk size chunk overlap what is the meaning of Chunk I hope everything is getting clear now I have given you the clearcut explanation so let's try to do a chunking regarding my data so over here if you will find out let me show you the chunks and all and how we can do that actually what is the purpose of the overlapping just just think about it just think about it what is the purpose of the overing we want to sustain the information from the previous sentence from the previous chunk that's it right that's it now my data is little smaller in that case uh I'm not able to create so many chunks what I will do I will perform the overlapping getting my point right yeah to maintain the context to maintain the length whatsoever now here I'm passing my document I'm passing my document and here I'm going to create a chunk so guys over here you will find out inside this particular variable there is my chunk so here if I want to extract the first chunk so this is what this my first chunk as you can see now I can call the page content so here if I'm going to call this a page content so you will find out this is what this is my content right now here I can take the second chunk also so here is what here is let's say is my second chunk so you will find out this what this is my second Chun now here you will find out the third chunk so this is is going to be your third chunk now let me show you the third chunk so here actually you will find out all the Chunk in the list so I can get the length of the list also so just uh call this length and this text so here you will find out total 233 chunks got it yes or no now let me give you this particular code and here is what here uh I have a code let me close it first of all this is what this is my code let me paste it over here so just copy from here and try to extract right so try to extract so here actually uh you have a text right and from there you can extract the content now trial Junction is saying explain so then you can visit ion Tech Hindi Channel there I'm explaining everything in English sorry in the Hindi right so this is the channel for the English and the channel will be for the Hindi so just go and check then you will find all the content in Hindi otherwise just wait for one more hour from 6 p.m. onwards I'm going to start a same class in a Hindi also right on Inon Tech Hindi got it great now here you can see we are able to get a content from the page from the data now uh this is the data which I got I'm able to do a chunking now it's time to do a now it's time to do a tell me it's time to perform the eding now let's try to do a eding and let's try to do a a further thing over here so the next thing is going to be embedding itself just a second let me do the embedding uh let me give you the code basically so here is a code for the chunking yeah so guys the next step is going to be a very very uh the next step is going to be a very very crucial just just focus on that and within a 15 minute we'll try to complete it so here my next step is what so here my next step is creating a DB so let me remove it first of all and here I'm going to create my database so what I'm going to do guys I'm going to create my database so for creating a DB actually there is a is a like certain thing there is a certain code which I need to write it down over here so the first thing uh the first thing basically what I need to do I need to import the embedding so first of all let me give you this entire code and step by step one by one I will try to explain you so just a second I'm going to paste the entire code in my Cod share. so here uh you can paste it you can copy it from here from the codeshare doio I'm giving you each and every of code each and every line so at least you can run along with me if you are running inside your system so you can run along with me here is the entire code guys from 41 to 48 just copy it and run inside your ipv file now let me show you that what thing we are going to do over here so here is a embedding let me copy it from here let me paste it so this is going to my embedding and let's run it yes we are able to uh import it now the second thing is what I told you uh I told you initially that we are not not going to maintain any such information or we are not going to store any such information on cloud right we are not going to store any such information on cloud because here this chroma DB is a local DB right where you won't be able to find out any server on top of the cloud any cluster on top of the cloud everything will be happening in a local itself in our local workspace so purchase directory there I'm going to store my all the embedding here is a fer this is what this is the directory now let me run it and here is a directory now what I will do guys so here I'm going to create an embedding right so here I'm going to create an embedding just a wait so this is going to be my embedding open embedding means uh it's what it's my class right for generating edings which I'm going to import from the openi yesterday also I shown you this thing now here this is the crucial step just just focus over here guys just focus and don't worry I'm giving you the link again so just uh call okay I'm giving you to my giving it to my team and they will paste it inside the chat so here you will get it uh within fraction of second just wait so guys uh here I given this particular link inside the chat now you can check you can copy it and you can copy you can open it and you can copy the entire code from here itself so within a second you will get a link inside your chat now let's try to understand the further things till here everything is fine everything is clear everything is a perfect now here is what here we have a method here actually we have a like class chroma and inside that you will find out a method from a documents right now here we are passing three things the first thing is what the first thing is text the second thing is a embedding and the third thing is what the third thing is a directory right first thing is text the second thing is a embedding model and the third thing is a directory now as soon as I will run it let's see what I will be getting so it is running and it is creating a embedding it is generating an embedding and I will get that inside my DB folder inside my database folder just wait and just look into this DB folder guys so here actually uh it is running still it is running and now open this DB so just just refresh it and here inside that you will find out the m now guys see there is uh one cons there is one disadvantage of this chroma DB So Yesterday itself I shown you the pine con there you will able to see the there you were able to see the embedding and all on top of the screen but here whatever embedding you will get you will get in the form of binary file getting my point so here you will get all the embeding in the binary file in the bin file right here is the extension you can see do bin getting my point yes or no so now let's try to decode this thing what I can do now let's try to decode this thing this particular thing where I got my eming now everything is going to track by using this uh SQL 3 right so in back end it is using the SQL 3 and it's trying to store the embeding because it is required some sort of a server now chroma DB is not a database right it's just like a just a basically you can think it's just a wrapper kind of a wrapper basically so back in back end it is using this sql3 server and it's storing the embedding but not like we are not going to interact with this SQL 3 and all with SQL and all right no it's not like that right we are storing this vector and in back end it is using a sql3 server got it now if you want to understand more about the chroma DB you can read about you can go and check with the documentation and all then you will find out a depth intuition regarding this chroma DB now here I think this is clear this is fine now let's do one thing let's try to understand few more thing over here after storing the data in the form of uh embeddings inside this DB folder now what I need to do next so here uh you can see so we have the U directory so let me show you okay just a wait Vector DV data M ready okay so here guys you can see uh we are going to call this particular method Vector db. pures right now here I'm saying that purses the DB to the dis so here I can call it I can call this a particular method which is there on inside the vector DB so here actually you will find out you this is the object right so which you got which you are getting over here you can call this particular method persist now if I will run it so here you will be able to persist this thing inside your uh local disk itself right this one now here you can see so Vector database is done we can assign this also now guys here one more thing which I would like to show you which I would like to write it over here that is what that is this uh like chroma itself right so here we are saying now we can load the purs database from the disc and use it as a normal one so what I can do here so here I call this pures now I'm going to assign this none now what I'm going to do here see uh I'm going to use this Pur directory means in whatever directory you want to keep the database so there is a DB itself This One DB and here I'm calling embedding function is equal to embedding right so here itself like here my embedding function will be this embedding and here is my Pur directory right now what I have written over here see now we can load the purs database from the disk and use it in a normal fashion right over here we can uh do that so let me run it and here you will find out so this is what so here actually you will find out the database so inside this itself uh okay it is getting updated just a second now let me yes read me new article yeah so here basically in this particular Vector DB you'll find out a database now now see guys what we are going to do so we have created a chunks right now we have we have created a chunks after that this is what this is my embeddings which we are going to import from the lenon itself now here is my directory VB itself now here you will find out the open AI embedding right so this is what this is for calling the embedding uh embedding like class which is there inside the openi platform now here what I'm going to do I'm going to call this chroma right chroma is there which I imported just just look into uh this chroma okay which uh I had imported somewhere let me show you and we are consuming uh this as a object this chroma just wait so somewhere I have imported this thing M where it is where it is imported chroma import chroma yeah PIP show chroma DB I think I have imported somewhere in between you you can check in a file itself I have imported now here after that what I need to do I need to call this particular method from document right now here I'm going to pass the text this is my embedding and this is my directory right in which I want to process the m so here Ive created this Vector DV right so as soon as I did it now here you will find out we are going to create this we have this particular directory inside this we have this uh we have this bin file there you will find out there you will find out your embeddings and all right and it is using the sql3 server in back end right this is fine now purs the DB to the disk if I want to purist I'm just going to call I'm just going to call this Vector db. pures right now here if you will look into that so here I'm going to call this chroma right Pur DV this is my directory now here is what here is my embedding okay now if I'm going to run it so here I'm getting my Vector DB right so from the dis itself I'm able to get this Vector DB so here actually we have the dat see if I will run it now if I will show you this Vector DB this one so there you will find out this is what this is my database means I'm able to persist okay I'm able to purs this data I'm able to purs this data in my local disk and by using this particular object we can access that now let me show you how you can do that okay just wait so here I'm writing uh the next thing which you want to do so here I'm writing this make retriever so just a second here I'm going to write it down this make retriever now you want to make a retriever basically and for that what I'm going to do so here I'm going to call this one more method uh which is uh which this function is having the method name is what as retriever right so there is what this will what this will my retriever now what I can do guys just wait I can give you this entire code so you all can run inside your system so I'm passing or I'm giving you this on the like codes share. so you can get the entire code from from there itself so just a second I passing it over here I'm giving you inside my uh I'm giving you this inside the Cod share. just just copy from there and here the last method which you need to call this is going to be a as retriever so just a second now we just need to cover few of the few thing and then I'm going to wrap up it so here guys you can see we have a retriever we after calling this particular method we are able to click we are able to create a retriever now what I will do here just just focus right just focus so here I'm going to run this particular method by using this Retriever get relevant document right so here I'm going to run this uh this particular method the method name is what the method name is get relevant document and here I am going to pass one question the question is that how much money did Microsoft raise right how much money did Microsoft raise so this is the question based on article if you look into the article if you will try to read the news right so there you will find out somewhere related to the Microsoft and related to the different different startups so here I want to here basically I have created a retrieval right which is there uh we have a function actually this method Vector DB do as retrieval so this is what this is my retrieval now here I'm going to call this get relevant document so what it will do so it will uh search inside the entire DB and based on that it will generate an answer so let's see what I will be getting over here so yes if I'm running it and now inside the docks right now let me show you inside the docks that what I have so here you can see I'm getting a document right I I'm getting a answer here I have created a retrieval and whatever question I'm asking right so it is matching it is checking and here I'm getting answer how this thing is happening let me explain you so what I can do I can open my uh Blackboard and there itself I can explain you about it so so just a second uh what is happening see what I'm going to do here so let's say we have a data right just a second guys yeah so we have a data and the data actually what I'm going to do tell me so this data I'm going to be uh this data actually whatever data is there I'm going to convert into embeddings I'm beding by using what tell me so by using this opening API so here I can mention the open a API now let's say we have this open AI API got it now this open by this this basically this embedding whatever embedding I'm going to generate I'm able to keep inside my inside my tell me guys inside my chroma DB right from here to chroma DB let me create one more box over here so here actually what I'm going to do I'm going to keep inside my chroma database got it right now this is fine this is perfect okay and this chroma DB actually it is available in the local dis space it is available in my local disk space now it is using this SQL light server it is using the SQL light server in backend right and here it is storing the data in the form of binary file got it now here whatever data which we are going to store inside my chroma DB now I want to retrieve it means I want to make a request from this D right so what I want to do guys I want to make a request from here so what I will do for that uh so actually see I want to make a request so the request will work in which way so let's say we have created a retriever right let let me create a retriever over here so let's say we have created a retriever now just a second here is what here is what here is my retriever now let me write it down the retriever over here this is what is my retriever now I want to retrieve the data so here let's see this is what chroma DV is having a database so this is what this is my database right okay great great great so this one this one and this one right so this is the database where we are going to store the embedding now what I will do I'm going to retrieve the data so with that I have created object of the retriever now I make a query so from here basically I make a query so here let's see this is what this is my query okay just a second let me Define the query over here query okay query now I made a query and this query actually see the request is going the request is going from here from here from here to this database right this one and from here actually what I'm getting in response if you will look into the response so in the response actually I'm getting a output right so the response will be coming from here and it is going like this this one and this one right so this is what tell me this is the response which I'm getting so here I'm making a request from here this is what this is my request this is also my request right and here what I'm getting I'm getting a response right this is what this is my response got it now here actually what I'm doing so here I'm going to perform the similarity search right so in this requency response actually the thing which we are going to perform we are going to perform the similarity search and based on that based on a similarity search itself based on a semantic meaning it is generating a final output right so as a retriever actually what I'm getting I'm getting a final output and based on the semantic search it is generating that a final output I hope now the architecture is pretty much clear to all of you let's start with the coding again so here I'm getting uh all the like whatever a question I've asked so based on that it is going to generate output and here you can see the first output second output now let's check with the first output so it has generated uh like a different different output not a single one and here if I'm to check the page content so you will find out that we have the entire detail right so here you will find out the entire detail regarding this particular question so in this particular question you'll find out the entire detail now you can check the length of the document also so what I can do here so what you can do here so here you can write down this dogs and there you'll find out it is generating a four answer by default it is giving me a four answer got it now this is fine this is clear now what I can do I can uh like I can call one more method just a wait so here actually in the retriever itself we have a different different method sorry in the vector database we have a different different method so here I have called this uh as retriever right as retriever now here is what here is my retriever Now by using this retriever I'm going to call this get relevant document everything you will find out in inside the document itself just go and check with a chroma DB documentation we have uploaded or sorry not basically we so they have uploaded everything over there in a very detailed way just go and check every function every method I'm going to take from there itself right so I I'm going to take from there itself just go and check with the documentation now over here guys see uh we have a retriever now here I can Define the key also so search KW KW R GS k equal to 2 there will be only two output now here if I'm going to call it now you will find out what I'm going to do so I'm going to call this a particular uh keyword s retriever dok search a w RGS so you'll find out two so we'll be getting two output only so if you are going to search it now if you're going to search any sort of a question so let's say here is my question is what here is my question uh retriever do get relevant document and here how much uh did Microsoft raise so let's see in the document two what I will be getting so here in the document two let me show you first of all let me show you the length of this document two so here is the length of the document will be two so I'm getting only two document I'm getting only two document as a relevant one means it is performing a similarity size so in a back end itself in a back end itself there is a vector and there will be also a vector each and everything is going to be uh like each and every permutation is going to be form and based on a similarity search Okay based on a similarity search is providing me a output so here you can see it is giving me a two output as of now now if you will look into this doc two so there you will find out only two output right so here you can see you just have to Output so initially actually by default it was giving me four so I hope this thing is clear to all of you now here I want to do one thing I want to make it more realistic right what I want to do guys tell me so first of all let me give you this particular code so at least you can also uh generate some limited output Vector DB as a retriever and here is the next one is what so just a second Vector DB retriever so this is for the by default and here this next one actually it is for the two only right so here we have Define the two so get how much Microsoft money so here actually this is what this is my docs tool got it guys yes or no tell me did you got it yes yes or no guys guys tell me please copy the code from here please be active I understand it is like it is it is about to hour now so so please be active guys see I I have a same energy now you have to keep you have to learn with the same energy okay I I haven't down my energy and I'm I'm like explaining you with the same energy I understand initially thing will get in a more effective way but as we are pro progressing with the session so we lose our like Focus we lose our like focus and all and so don't do like that okay so just be active just be active for for more 10 minute and yeah we are going to wrap up this thing so you will be ready with the vector databases now in the next class easily we can implement the project right easily we can implement the project and we can perform the RG retrieval argument generator so this Vector database we use for the RG only for the retriever agumented generation and is going to play a very important role if you are going to create create any sort of a application related to the llms right related to the generative AI where you are going to use llm so please guys be take a take it serious and yes in interview they will ask you the same thing right I have seen many require whatever requirements people are having right related to the generative to the llm and they are specifically they have mentioned chroma DB pine cone right because this is a trend actually right people are able to uh use it people are able to productionize it right people are able to achieve whatever they want right with respect to their use cases and all and yes as a techie you have to solve this thing you have to take care this thing so please be serious over here now uh here guys see we are able to retrieve the document a similar document by using this particular method right now everything you will find out over the documentation if you want to understand a more depth go and check with the documentation now let's try to understand the next concept so here you can see we have a doc two now let's do one thing let's make it more interactive and so for that here I have written something uh so let's make a chain now what I can do I can make a chain and here guys for that here is one Library you will find out inside the Len CH itself the library is going to be retrieval QA now let me run it and yes we are able to import this retrieval Q retrieval means you just need to retrieve it retrieve it you just need to get it right retrieve means response right so here you can see we have this retrieval QA now what I will do guys here I'm going to use my llm model so I'm going to call my open API because I want to I want to get uh see here if you if you will find out in the response so just just look into the response here so just just print this particular response um what I can do I can print it now see the response so they are giving you the response and they are mentioning everything over there now how to make it more interactive and how to work with it like a question answering right question answering so for that you'll find out this retrieval QA over here now here I'm going to use my llm now you will find out the use of the llm over here what is the use or I will show you one architecture so here I shown you the simple architecture which I created by myself only here you can see clearly you can understand everything I will show you one more architecture and I will show you what is the role of this llm over here what is the role of the llm over here right now just wait let me show you that or first of all let me run it uh here I have written couple of thing so let me show you the llm first see we have we are going to call open API and by default we have the uh by default we have the model GPT model cut it now what I'm going to do here I'm going to create a chain by using this a particular method so retrieval QA from chain type so LM open a model and here we have a retriever object retriever is there this one okay retriever is there and here you will find out the document so return Source document is true so we just need to pass two thing here the first is what up our model and the second one is retriever so retriever is here this one okay this one so we are going to collect it from the vector DB this retriever right so here Vector DB as retriever so this is my Retriever and by using this retriever only we are getting an information whatever we are passing as a question and we are using this method and this is what this is my docs so this retriever object also we are passing over here so we have a llm model we have a retriever and here two more parameter right now let me run it and here you can see we are able to generate or we are able to create a object and which I'm going to store in qhn right now guys here what I can do I have return one more method so let me copy and paste it over here and one more method and after that the thing will be more clear to all of you so what I'm doing over here see uh this is the two method which I have pasted right two uh two code two Cod code is snipp it basically which I pasted over here so here see we want to create a retriever QA so just just check what is the meaning of that just open the Google and uh search it over the Google Now paste it over here and search about the retrieval Q QA so what is this retrieval QA everything you will find out inside the Lang CH and guys believe me this langen chain is very much powerful right whether whatever like framework you are going to learn in future I don't care llama index and all but please try to learn this Len CH if you want to build llm based application so just take a Mastery on top of this Len chain it's a important one now here you will find out what is this retrieval QA this example so is question answering over an index right the following example combining a retrieval with a question answering chain to do question answering right so here I just want to make a question answering chain and here is a complete code snipp it here is a complete example which they have given to you now what I can do here I can uh show you that how that this uh two thing is working now this is what this is the from chain type which I called create a chain to answer the question now see process llm response so llm response is there right whatever L see first of all see this is a query now here we are passing a query now this is what this is the query which we are getting now llm response see here what we are going to do see this is what uh here from here basically uh what I see step by step let me show you so first of all let me run it right this one now what I will do here so this is what this is my query right so here is what here is my query how much money did Microsoft race right now what I can do here uh I can uh like call this particular uh method right so what is the method guys tell me here this one is qhn right so here is what here is a qhn this one this one so I'm passing this query to my qn right so let me run it and here you will find out the llm response so let me copy it and let me paste it over here so this is what guys see this is your llm response this one right so here what I'm doing I see uh retrieval QA right you you are talking about the r now retrieval argument generation so it is related to that only it is related to this only it's Advanced concept so this is a basic RG which we have created this is a basic RG which we have created where we are not going to generate directly answer from my llm no we are not going to do that here we are going to pass this retriever object this particular object and from there actually we are going to generate an answer from here see we have open AI model llm model we are not going to ask we are not going to generate a response from the open from the llm model right it is just for the refinement right it is just for the refinement or for the better understanding is not if you are not going to train it now if you're not going to train this model on top of this data and if you are passing this retriever if you are passing this retriever object over here means you are passing the embedding you are passing your database you are passing your data over here right so instead of instead of generating a data instead of generating answer from the model is it is it is giving you the answer from the embedding itself llm is here just for the refinement right just to understand it not going to generate answer and this is only called retrieval argument generator gener generator retrieval argument generator and here you are going to achieve this thing by using this Vector datab Base by using this Vector database so here you are going to call this llm right here is llm have you created a function calling have you created a function calling so it is working similar to that if you are aware about the function calling where I'm using a llm but llm is not generating answer some third party API is giving me answer right so it is working in a similar way here is my llm and this is what this is my retriever which is nothing which is my embedding so here I passed my query and it has generated answer this LM response now guys what I want to do I want a response so where it is tell me it is there inside the source document so here what I'm going to do so I'm passing my LM response over here and from the result so this is my result and this is my complete uh like answer which is which it is giving to me so here actually this llm we are using for the refinement for the refined answer see see over here now if I'm running it this one what I'm doing I'm going to run it see this I'm going to run this one so it is giving me a so it is giving me this a particular uh it is giving me this like a particular answer this is for the refinement llm is not for the generation answer generation answer this is the answer which we are generating from the document itself from the database itself based on a similarity search right and this is only called R A retrieval argument generation and here this chat GPD or this like a GPD model we are using for the refinement so it is giving me a final answer so already I have written a code over here so we are get extracting a result and we are printing a result and here is a metadata and all whatever is there so we can print that also so this is the metadata resources now guys tell me did you get the concept of the r did you get the concept of the vector database did you get that how to like uh do the question answering after generating a aming and all in my previous class also I shown you the same thing in the previous class I created a while loop and I was giving the queries and all and I was generating answer you can do the same thing over here and you can create your question answering system you can create your chatbot which we are going to do in the next class so this is just a like a basic introduction and the next class we are going to create a application by using this particular concept now tell me are you getting it guys yes or no tell me how many people are able to understand yes or no tell me fast whatever explanation I have given you regarding that how many people are able to understand yes sir uh we have existing qua system what is uh what is the difference between exis system and llm model exis system is this one now this is your data see let me revise this thing what I can do here uh where it is okay this one now what I can do here itself I can revise this thing just a second okay so I have one image let me show you that a particular image just a second so this is the image right this is the image can you see this image guys this one is it visible to all of you this this particular image tell me guys fast so this is the image actually which I created for uh for the project actually this is the project flow now let's try to understand what is happening over here right so I can explain you this thing in a like clear man manner just just see just focus over here right now what is is happening see uh do you have a data just say yes or no until you won't say Yes I won't proceed so this is the data right are we extract are we converting a data so are are we extracting a data yes so this is my first step this is my second step right now here you can see this is my third step now here you can see this is what this is my fourth step this one right this is what this is my fourth step now after that what I'm going to do so so here I'm going to save my data in my Vector store in my chroma DB so either I can store chroma DB or vector database tell me so here either I can store chroma DB or vector datab everyone so I think you all are enjoying s's class lecture okay so guys here you can see so this is what here we are going to store the data in a chroma DB itself right so in a chroma DB yeah here actually we are going to store the data in a chroma DB now see if user is going to query right if user is going to query now what will happen if user is going to query this thing now what will happen see uh here let's say this is what this is my user okay just wait let me remove it from here um yeah so this is the user right so we have a data over here we have created a data uh so this is what this is my data where I have saved my embedding right so here I have saved my embedding now here you will find out the embedding now here is a user this is what this is the user now here user is asking the question right user is asking the question now here we will search like query aming right and based on that so we'll go into the database and here see from the database will retrieve the answer and llm will refine the answer right llm will refine the answer just just look into the arrow so what is the role of the llm over here llm is just for the refinement because the mding we are going to the iding right so whatever iding is there right so this embedding actually uh this data we are going to fetch from the DB itself right so here is a see till here everything is fine see this is the work of the uh this is the work of the developer till here now let's say user will ask the question so the question will come over here it is going to do a semantic search and and is going to take a answer and here from here actually it is taking an answer and then it is going to rank the result so in that in my case I'm getting two result right or three result or four result now what I will do here so it will pass to my llm model and this llm model will give me a final answer now it is getting clear how the flow is happening how the how the thing is working over here tell me guys fast how the thing is working over here did you get it guys yes or no got it now so that is a thing which we have implemented in a Jupiter notebook Now by using that so this thing actually we can use this this particular thing we can use inside our application right and we can create one QA system so from the data whatever data we have from the data the data basically the files which we have our data from there basically we can get answer and llm can refine that particular answer I can give the direct answer also from the database or I can refine the answer so that's is a use of the vector database now in the next class we are going to create a in the next class we are going to create an application and that's going to be chatboard application and literally you will enjoy if you are able to understand this today's session so tell me guys how was the session how much you would like to rate to this uh application and and whatever I have done over here so tell me guys fast if you have any query any doubt you can let me know I will give you this entire code and here is the uh like I can give you this particular code as well I hope I have already pasted in the just a second so let me give you this uh two thing the first is going to be a qhn this one and the second is going to be this one uh just a second this okay so I given you the both code now what I can do here so this is the code and yeah now you can query you can ask anything whatever query whatever like uh data actually we have based on that you can query you can take a bigger database right and yeah now I think uh you are able to get it no this one so fine I hope uh this part is clear to all of you now please go through with the code please try to run inside your system just copy from here and run inside your jupyter notebook data and all each and everything I have provided to you I have already given you and uh yeah now if you want to see if you want to stop the database if you want to means uh the datab database basically which you have created right so if you want to stop it if you want to delete it if you want to like clean it so for that also we have a command let me give you uh those particular command so here you just need to so first of all let me write down the heading and the heading is what so heading is uh you can delete the database so delete the DB now you can see uh what you can do guys you can delete the DB and here uh what you need to do so you need to read this J you need to like uh create this jip file actually this jip by using first of all you need to jip it actually the entire thing is there just you need to jip it and after that what you will do you will run this particular command so let me give you this two command the two command the first one is delete collection and the second one vector. process right so to clean up entire thing you just need to call this two thing and here the last one you can delete this jip directory so here is the directory which you are going to delete means here is the folder the entire folder where you will be having the jip directory you are going to delete that and yes finally you will be able to delete your data base the data base basically which you have created by using this chroma DB so yes or no guys tell me um if you got everything then yes it is well and good if you if you didn't get then um definitely you should revise the thing everything will be available over the dashboard so just uh go and check with the dashboard let me show you the dashboard just a second so here the session is going on now let me show you the dashboard also this is the dashboard guys uh this one so just just check with the dashboard just enroll to this dashboard and apart from that you can explore the course as well the course which we have launched on a generative AI here is a Course and there you will find out everything the concept which I have explained you over here we are going to explain in a more detailed way we are going to clarify more thing regarding this RG or regarding this uh like different different uh tuning and all parametric tuning this that whatever everything we are going to clarify over here so just go uh go and check uh with this uh website with the uron website just go and explore the course this uh just go and explore this Genera course everything you will be finding out over here just just explore the syllabus okay this is the syllabus and if you want anything if you want any update anything let's say this is the new one right which we have launched right so if you want anything any recent thing which on which you are working in a market in your organization you can let us know you can let me know you can ping me you can uh write it down on my LinkedIn right so based on that um if there will that will be like uh that uh I I will consider I will think about that and if it is really going to be an important one so I will add on inside the syllabus okay immediately I will add on inside the syllabus and we are going to take it inside the live class so I hope uh this is fine to everyone now we can wrap up the session and from next class onwards we are going to start with one more project and that's going to be on Monday Monday 6 sorry Monday 300 p.m. IST and yes so I'm not going to take that session buppy will be available for that particular session buy will start with the project and all if you don't know about the buy so I can show you the profile of the buy just uh over the open the LinkedIn and search the search uh buppy okay now buy the full form name the full name is a b Ahmed buy just open the profile of the buy and he's like really good Mentor you can visit his YouTube channel as well this is the YouTube channel of the Wy there you'll find out the like content related to the computer vision and all so just go inside the video he's having a amazing cont content related to the computer vision and you can go and check you can check with the mlops content as well everything he he has kept over the YouTube so you can visit the YouTube channel so next class will be taken by the buy and yes in that we are going to implement one more project so Monday Tuesday and Wednesday fine so I hope guys this is clear to everyone now there is one question sir can you provide one end to end project for interview purp yes we are going to implement that in a next class in the next uh in the next uh basically class and uh don't worry you will find out a project soon in my internship on on the internship portal as well so let me show you the internship portal where it is just click on this click on the internship portal and here okay so you will find out all the project and all as of now we haven't updated related to the generative AI it is in a pipeline I already given to my team the work is work is uh going on on top of that so there's there are like couple of use cases related to the different different domain which is a which is directly related to the real world so you can explore that you can uh like go through with that and then you can start your internship and you can generate a certificate you can generate a experience certificate and you can uh write it down that particular project in a in resume also see one thing I would like to tell you let's say if you are uh like whatever I'm like telling you whatever I'm teaching you let's say I'm not able to teach 100% but I'm giving you the direction let's say I taught you 50% thing but rest of the 50% I've given you the direction right so rest the rest 50% thing I given you in terms of the direction and all so try to explore those Thing by yourself like anywhere you won't be able to find out that one Mentor is doing everything for you let's say you ask about the inter you ask about this uh like uh one project which I can show you in a uh in a like interview and all or which I can show you somewhere so guys I guided you up to certain point right now it's your chance you can find out the different different use cases and you can Implement those by taking my reference and in that you can add on few more things right then only you will be able to cck the interview if you going to take a same project from me and you are going to uh like you are going in an interview then you won't be able to crack it because you won't be having that confidence that knowledge okay which is required in an interview which you will get once you will do by your self okay so keep this thing in your mind and learn according to that and yes definitely you can crack any interview this is not a big deal you just need to represent yourself your work that's it okay so thank you guys thank you for attending this session from next class onwards we are going to start one more project and please do revise the thing whatever we have learned in today's session in today's class here is the entire file here is our entire content just go through with that and yeah thank you byebye take care if if you have any doubt you can write it down on the over the LinkedIn and please share your learning as well uh over the LinkedIn you can tag me I will look into that I will like it I will share it so my name is B Ahmed B and uh I'm working as a data scientist at Inon and I have more than two years of experience uh in the field of machine learning deep learning computer vision Genera and natural language processing and uh if you want to connect me anytime so this is my social media link I think some of them already have connected with me so if you have any issue u in the field of this generative a and all with the implementation of the projects so anytime you can ping me okay I will be happy to help you okay guys thank you so let me uh show you that agenda for today so today actually I'm going to discuss something called open source large language model so as of now I believe you have work with like open AI based large language model guys yes or no uh yes now uh can anybody tell me what was the difficulties actually you were facing whenever uh you are using this kinds of Open Source lar language model any anyone give me any response yeah mostly open a and a your open yeah I know that so what is what is your difficulty level there just can you tell me um resources uh it's not a major issue okay see the major issue is like uh the cost okay because I believe you onlyon be having like a paid account most of you and before starting guys let me tell you uh all the resources has been updated in that uh uh dashboard actually so let me show you the dashboard once so if you open that dashboard I believe guys you enroll for the dashboard and it is completely free without any cost yeah see guys all the video has been updated here and as well as I believe the resources also has been updated even maybe some quizzes and assignment has been also given there okay so you can go through that even it is also available in your YouTube live section okay and today whatever things actually I'm going to do everything would be shared in your resources section no need to worry about yeah so what I was telling guys uh see as of now you have used like open AI based large language model and the major issue was the like cost there yes or no because I believe you won't be having like paid account most of you if you are having also paid account so at the end of the month you need to pay okay for the model you are using from the open a yes or no yes okay now see guys U how to like track your cost like whenever you are using this kinds of open based like uh large language model okay if I'm talking about open based large language model so I'm mostly talking about something called GPT okay GPT Series so if you just search open AI pricing okay if you just search openi pricing on Google so there is a page actually you will get from the openi site and here actually they have already mentioned the cost okay they're taking from you so let's say if you're using GPT 4 Series model okay so in GPT 4 Series you have different version of the model so let's say you have GPT 4 Turbo okay so if you are using this particular model so this is the model name as you can see GPT 4 uh 1106 preview so this is the model and this is the cost with the input tokens okay so each of the model will have their input size okay what is the input size input size means the number of text actually you are giving as a input to the model okay and that can be calculated by this token okay so let's say if you're giving 1,000 tokens so it will charge you 0.0 $1 okay this is the charge and if your model is giving let's say one uh 1,000 uh like tokens output so it will charge around 0.03 now just combine them and just calculate the cost okay so this is for the GPT for Turbo now let's come to the GPT model and you can see whenever you are trying to use the core GPT model it will uh take you some more charge for me okay okay now see not only GPT uh 4 you have also GPT 3.5 turbo then you have assistant API fine tuning models even I think you already used embedding models in your vector database guys yes or no have you used this embedding model yeah okay see that's how you can calculate your cost like how much it will charge you whenever you are going for any kinds of model okay you can go through this pricing praise and you can understand this thing all right yeah see ADI is there DCI is there there are lots of model okay they have given just high level overview but maybe they have some more pages actually I think you can go through and like see the cost there all right now see why we need to use open AI uh sorry why I need to use this open source large language model okay first of all let me discuss then I will start with that uh like discussion okay what like today's discussion on the Lama 2 I will tell you how to use Lama 2 and all even I will show you some available open source model you can go through okay now see guys whenever I'm talking about open source model okay open source open source llm okay op source llm so the first thing uh you can consider you don't need to pay any cost okay so you don't need any no need cost okay the second thing you can talk about um it is completely free to use free to use for the research and commercial use cases okay commercial use cases all right but whenever I'm talking about open AI okay open AI open so so I'm talking about GPT series okay GPT Series so let's say if you want to use open a so the first thing actually will come you need to get the API key okay API key and if you need this API key you need to pay for okay you need to pay for you need to pay it's not a free all right but one advantage actually will get with this open AI one advantage actually will get uh from this open a which is nothing but uh it is completely API accessible okay API accessible okay so here you don't need to download that particular model to use so if I visit open a so let's say this is my open a website okay this is my open a so here I will just loging with this uh website and here I can generate the API keys I think you already done some of the projects and all right so here I can easily get the open API keys and what I will do I will open my local machine I can also open my Google collab I can also open my jupyter notebook and there actually I can start my development okay there is no issue with that so you don't need any kinds of powerful machine there because everything is running on the API yes or no guys tell me let's make this session interactive so that I can Al also understand like you are understanding my concept guys reply me in the chat yeah thank you so this is the idea of open AI so so openi what they did actually they created this beautiful website okay and they hosted their models U um to their server okay and they created some of the API and with the help of API we can send the request to the model and we can get the response okay let's so let's say this is my this is my model okay this is my model this is my model hosted on open okay it is hosted on open a now here user will give some query okay user will get some some quy okay with the help of the API key okay with the help of the API key and this model will give you some response okay this model will give you some response response okay and this uh request and response you are getting for this you need to pay you need to pay some money because this is not a free this model is hosted on the openi website and they have created the API key so for this API key okay to access the you need to pay something hi sir as you know Lama 2 is a heavy model and it's responsive time also High then how can we decrease the time to response the open source model so F we'll be discussing this one okay no need to worry about like how we can use this Lama to model in our CPU machine so we have a projects no need to worry about I will tell you okay so guys so far this understanding is clear like uh what is the advantage with the open AI okay why we usually use open AI is it clear if yes then I will move to the uh open source part like why we need to use open source okay and what is the difficulty level with the open source model okay can we set the limit of the uses tokens how we get idea about the pricing when the test out chatbot uh yes you can also set the limit uh limit of the pricing it is also possible let's say you can set the limit for the $10 so when it will uh come like close to the $10 so you will get the notification okay that can be also done all right now see so whenever I'm talking about open source model okay open source model open source llm okay so the first thing you need need to so so the first thing you need to understand uh see whenever I'm talking about open source it's not hosted okay it's not hosted not hosted anywhere some of the model might be hosted you will get API key but most of the model would be available on the hugging pH okay hugging face or different website okay so it's not hosted anywhere it's not host anywhere okay so what you need to do you need to download download that particular model download that model okay then what you need to do you need to load that model you need to load that model okay that's how you need to perform all the task manually okay so there actually you won't be getting any kinds of open kinds of API key so that actually you can hit the AP key request and you will get the response it's not like that uh guys my video is fine um or there is any lag you can feel uh video is fine guys yeah I I believe it is fine okay all right all right now see the main disadvantage of this open source llm is you need you need good configuration good fun configuration system okay so whenever I'm talking about good configuration system you should have at least Core i core i5 or let's say three processor processor and you should have at least uh 8 GB of RAM okay 8 GB of RAM and if you have GPU then it would be plus point for you okay because it needs GPU computation so whenever we'll execute the uh model it needs actually GPU computation but I will tell you also how we can execute the model on the CPU machine both can be done okay so uh and think see U today actually I'm not going to use this neural LA because I believe in the neural La we don't have any GPU integration there so I'll be using Google collab today okay so whenever I will be implementing the projects that time I can show you on the neural lab yes we have see we know that actually we all have mostly CPU machine okay we know that okay that is why I will tell you one like technique uh using that technique actually you can execute any kinds of llm model on your CPU machine as well it is also possible okay so these are the requirement actually you need whenever you are talking about open source large language model okay because this model you need to manually download okay manually download manually load and manually execute deser the model okay that you won't be getting any kinds of API kinds of thing okay so that is the thing and some if I'm talking about some advantage of the open open source model so here actually you don't need any kinds of cost okay without any kinds of cost you can use this model for the research purpose as well as the commercial purpose so guys uh is it clear the difference difference between our open AI model and our open source large language model yes or no uh see if you have 4GB of ram then I think you can practice on uh Neal lab it's completely fine but uh today actually I will show everything on the Google collab okay so you don't need to worry about the system configuration all right guys uh is it clear the difference between uh open a model and uh uh okay just a minute uh just a minute okay uh am I Audible uh please let me know in the chat am I audible guys okay okay thank you so now uh let's introduce our uh some open source large language model so here if you see there are like very popular and Powerful open source llm there okay so see uh there are very uh like there there are lots of actually open source large language model available okay over the internet you will find but there are some most popular uh open source llm I will introduce today so uh the first thing is like I personally like this one called meta Lama 2 okay so this is the model for from the Facebook so Facebook has trained this model and they named it as Lama 2 okay so there is another model called Google Pam 2 okay so this is another model called Google Pam 2 so the this model actually trained by the Google anyone used like Google B before Google B like chat GPT anyone used maybe you used also Google B like chat GPT yes or no okay do you know like which model uh is running in the back end of this uh U Google Bart the free free uh version you are using Okay so this this is the model actually they're using called pal 2 okay so in future uh we'll also see like how we can use Google pump to model okay and there is another model called Falcon okay Falcon has lots of variant like Falcon like 7B B okay then 13B so it has lots of variant not only this one so there is a uh GitHub actually you will get uh just search for open llm okay open llms so this is the GitHub and here you will see all the open source model are available over the internet and it is already integrated here see see this guy actually uh so this is this is the guy so he has actually uh created this repository and he has actually added all the open source llm here so we have let's say T5 and this is the release date and this is the model checkpoint okay and this is the paper and blog if you want to read this uh like U about this model and all so you can open this paper and blog you can read it okay then you have ul2 so this is one of the llm model then you have uh uh this uh care brace GPT so this is another llm model then you have pathia dolly then Delight then Bloom is also there stable LM Alpha okay then MTP uh MPT 7B is also there then you have Falcon okay see I already told you Falcon is also there see llama 2 is also there okay see lots of Open Source model are available here okay all the open source model so this is the like GitHub you can go through let's say if you want to learn any kinds of Open Source llm so you can go through this GitHub and you can read about uh see for object detection actually we have like lots of model OKAY already even see nowadays actually people are also inting computer vision with these kinds of large language model so both can be support uh yes I can share the link as well in the chat so this is the link you can go through all right okay so this is the actually GitHub actually you can go through to learn about open source llm so all the models are listed here H all right now see today actually I'm going to discuss something called U Lama 2 okay meta Lama 2 so this is the model from the Facebook so they have trained this model so uh the first thing actually uh uh in this session actually I'll be discussing the Llama 2 so first of all I will introduce Lama 2 what is Lama 2 and all about then I will show you like how we can execute the Lama 2 okay without like Lang chain because there is a library actually they have created called Lama CPP okay so using that Library actually I will uh first of all execute the Lama 2 model then I will show you like how we can execute the Lama 2 model with the help of langen because in future whenever you will be do doing the development you will be implementing any kinds of projects you should uh you need to use something called Lang Chen okay so you also need to understand how we can use Lang Chen uh with these kinds of Open Source llm as well okay so both I will show you and at the last I will show you uh one project implementation so mostly uh I will start the implementation tomorrow so we are going to implement one chatboard projects okay and this is going to be medical chatboard okay with the help of Lama 2 we'll be implementing end to end okay so this is the complete agenda now if you just search like lama lama to meta okay Lama to meta on Google so this is the website you will get uh from The Meta Ai and this is the Lama 2 actually website as you can see so they have already written about L 2 so lar 2 is nothing but it's a Next Generation open source large language model okay so previously it has actually another version called llama 1 okay so llama 1 llama 1 they have uh actually developed just for the research purpose okay so it was not for the commercial use cases so only for the internal use cases actually internal research purpose they created the Llama one okay but later on whenever actually they saw like GPD kinds of model came in the market so they so they introduced something called Lama 2 model okay and this is the Lama 2 and they have also tell uh to like Lama 2 is available for free and uh research and commercial use cases both and one thing actually you need to do to get the model uh if you want to get the model then you need to get the permission from The Meta AI okay this is the requirement so just click on this download model this button and here you just need to fill some of the information like your first name your last name then your date of birth your email address country and organization if you're working with then you just need to select these are the model okay then just submit the request so after uh 30 to 40 minutes actually they will accept the request and they will give give you the access okay so this is the requirement and if you're not getting the access as of now okay there is another alternative I will show you how we can use this model okay so no no need to worry so what you can do guys you can open this website uh Lama to meta and just apply for the permission here everyone okay apply for the per permission so let me share you the link as well so guys are you doing with me can you please confirm uh hello okay I already have the access okay so you already have the access then no need to worry about you can directly access the model and one particular things actually I just need to mention so whenever you are applying for the request okay so it will ask for the email address so I I I believe actually you all have something called hugging face account guys yes or no hugging face account maybe hugging face has been discussed previous session so make sure you try to use the hugging face email address the email address you used for the hugging face okay so this email address you need to give here because this model are available in the hugging face website so whenever you will uh apply for the access they will like U ask for this email address all right now let's discuss about this Lama 2 little bit more like what they are telling so if you just go below little bit so this is the Lama 2 so they're telling Lama 2 was trained on 40% mode data than Lama 1 I already told you there was another model called Lama 1 and what they did in Lama 2 actually they train the model of with the 40% more data okay 40% more data than your llama 1 and it has a has like double context length we can download the model into our local drive as well and can play with right yes you can do it I will show you like how we can download the model all right okay uh now see guys llama 2 has actually different variant so it has actually 7 billion parameter variant so this is the 7B model and it has also 13 billion model that means uh uh the model has actually 13 billion billion parameter and there is another model called 7 70b okay so this is like 70 billion parameter so if you want to use these two model you need like good machine configuration and uh I'll tell you like how we can use this 1B model and B model as well so first of all I will like tell you how we can use this 13B model okay what would be the approach to access this model okay I can't directly load the actual model because actual model you can't ever load in your low configuration machine okay you need some good memory some good GPU there uh but I will show you one alternative there we'll be using something called quantized version model okay yeah and now see guys this is The Benchmark so this is the data set on this data set actually they have 10 different different large language model as you can see M PT uh 7 me this this is the model and this is the accuracy score uh 26.8% and they also trained uh Falcon model falcon 7 7 billion parameter model and this is the accur accuracy score 26.2 and they also trained on Lama 2 7 7 billion model okay and this is the accy score 45.3% now see guys the accuracy Improvement okay isn't it good model guys what what you can feel like see llama 2 is uh claiming uh this is this model is better than your GPT uh 3.5 turbo anyone used GPT 3.5 turbo model before maybe you have used yes yeah so they're claiming actually uh this model is better than GPT 3.5 turbo okay so that's how actually they have also given the Benchmark here and see Lama 2 13 billion and this is the accuracy and they again trained on mpt's 13 billion parameter model and this is the accuracy they got okay now they also trained with the Falcon 14 billion parameter this is the model they got this accuracy they got okay 15 uh 55.4% then uh this is the Lama 1 model uh this is the accuracy and llama 2 7 billion model okay and see this is the highest accuracy they got uh 68.9% okay that's how they train on different different data set different different open source data set as you can see these are the data set actually data set name all right and um these are actually partners and supporters for this L 2 okay like hugging face Nvidia they're Intel they are also using these are the model all right now guys uh did you appli for the permission um here did you appli for the permission everyone uh if not uh no need to worry about I will show you one one alternative this alternative you can follow okay no need to worry about can we use llama 2 for translation of the codes into python code find tuning custom data yes you can do it okay Lama 2 has different different model variant I will tell you even in future we'll also see how we can fine tune the Lama 2 model as well it is also possible on your custom data even it is already included in our paid courses I think you know uh that is also one paid version of this course so there actually we have already introduced the fine tuning technique as well all right so guys uh so far everything is clear everything is fine you can let me know uh if you have any question you can ask me otherwise I will uh continue with the session what is the name of the course could you please give me the information run this model over the docker key see it would be also discussed okay it would be also discussed Asal okay in the paid courses actually we'll show the deployment we'll also integrate docker okay we'll also integrate cicd so everything would be discussed there all right now see if you want to play with this Lama 2 model uh as your chat GPT so there is another website actually hosted just search for llama Lama 2. a okay so now you will see something called uh this website and you will see it's like chat gbt like interface so let me also give you the link in the chat okay now here just click on the setting Okay now click on the setting and from the setting itself you can um like select different version of The L 2 model okay I already told you L 2 has different different version so it has 13 billion parameter it has 7 billion parameter and it has also uh 70 billion parameter okay now first of all let's select this model uh this is the smallest model model I will select because response time would be a little bit fast okay and if you want to use any system prompt your custom prompt you can give it so I'll keep this default Pro prompt which is nothing but you are helpful assistant so it will work as a assistant okay you can also set the temperature okay what is the temperature temperature means if you uh set this temperature to close to one that means your model will take the risk and it will give you some random output okay and if it is close to zero that means this model would be more strict to the authentic output okay it w be taking any kinds of risk so these are the parameter actually you can play with all right now let's say I have selected this model called llama to 7B now I can chat with this model okay now I'll just write hello so see it is giving me the response okay see it is giving me the response now you can do anything now let's say you are having one error okay you are having one error in your code so let me search for one error so so let's say this is the error I was having in my uh flash code so I'll copy this error and I will give it here so I am getting this error uh can you please uh fix it let's see what happens uh see guys this is the response uh it has given sh I would be happy to fix the error can you please provide more context about the error you are getting uh what the line uh of the code is causing the error so it is also uh uh like uh telling me to send some uh more uh information so what I can do uh I can tell I'm getting I'm getting this is the error in my flash code see now uh it has given me the response okay it has given me other response like how to fix it now you can also select different version of the model from here you can also play with 13 billion and 70 billion it's up to you guys are you able to execute this uh website this l2. a okay all right okay thank you now uh let me show you the GitHub repository of the Lama 2 as well see this is the Facebook research and llama repository they have created let me share you the link as well uh this is the link and if you come here so they have already given like where this model is available everything they have given so if you want to access the model so this model is available on the hugging face website okay just you can open the hugging face and you can visit the model see all the models are available okay different different version of the models are available and what is the chat model and what is this without chat model I will tell you okay so there are some like uh you can say difference between these are the model I'll tell you okay now see guys they have already mentioned here if you go below um here so Lama 2 actually has two different model one is like preend model and another is like fine tune chat model okay so what is the preend model first of all you need to understand so preon model is nothing but these model are not for fine tune for the chat or question answering okay they should be uh prompted so that uh the uh expected answer is the uh natural continuation of the prompt so basically let's say if you want to uh generate the text okay if you want to generate any kinds of text from the Lama to model then you to use this pretend models okay from the Lama 2 Series and there is another model called fine tune chat model what is fine tune chat model fine tune chat model is nothing but the fine tune models uh were trained for the dialogue application to get the expected features from the performance from from them specific formatting defined chat completion so here it is telling if you want to do let's say question answering system or chat operation so you can use this fine tune chat model okay now if I visit hugging hugging face again here now I think this should be very much clear like whenever they're defining like chat model okay whenever they defining chat model that means this is the model for the question answer or let's say chat uh I mean chat model okay and whenever you won't be seeing any kind of chat model that means this is for the Tex generation model is it clear why different difference model you can see in the hugging fish let me know guys yes one for chat another another one for like uh text generation great okay now let me close this other the tab H now first of all Let's uh play with this model called LMA 213 billion parameter model this model first of all I will tell you like how we can execute this model and if you have very low configuration PC so what you can do in this case okay first of all I will tell you this one then I will show you how we can execute this uh 7 billion parameter model with the help of the Lang chain as well both I will show you so for this first of all let's try on neural lab okay so if neural lab is not working then I will go to the Google collab so first of all I will be using the quantied model and let's see whether it is working or not so everyone you can open your neural app so let me open so so I'll loging with the website so here I can take I think jupyter notebook repter notebook I think I can take so everyone can open this uh neural lab with you also let me Zoom this screen now my screen is visible guys this text is visible you can confirm me in the chat all right so let me first of all test whether I have GPU here or not maybe there is no GPU here how can we uh check the configuration see here no need to check the configuration because this is like a remote server it is running uh okay this command is not found maybe no GPU okay then I will use quantied model let's see what happened and also let me share the code with you so what I can do I can open code share and I will share this link in the chat so whatever code I will be writing I will be just pasting here okay you can get from here all right now first of all let me show you the model actually I'm going to use uh so we'll be using some quantized model so this is the website of the Quant model and this Quan model is already available on the hugging phase okay so there are different different organization so they actually did the quantization of the model and they publish the model here okay see Lama 27b model Lama 23b model chat model OKAY different different models are here now do you know what is quantization guys anywhere here what is the quantization what quantize mean you can let me know in the chat if you're not familiar with quantization then I will give some idea how this quantization works model uh comparation technique yes you are right uh okay now see what happens actually so whenever you train your neural network okay so whenever you train your neural network so let me take um one just demo neural network here so let's say this is my network okay so this is my let's say Network so this network will have some of the weights okay let's say W1 W2 W3 and so on okay so each of the uh layer will have the weights okay each of the layer will have the weights yes or no guys do you understand understand this neural network concept maybe yeah now see what is this weight weight is nothing but it's a value okay it's a number only it's a floating number so it will have let's say 0.36 or let's say 0.46 it might be also 1.2 it might be also 0.88 any kinds of number okay it would be adjusted ining back propagation BP all right now one thing I think you already know uh whenever I'm talking about data type and data size okay so whenever I'm talking about character character data type okay so I can take uh 32 bit I can also take 64 bit okay character now can anybody tell me uh what is the character uh let's say size in the 30 32 bit anyone know what is the like character size okay in the memory for the 32bit anyone because whenever you will uh assign these are the number it will occupy the memory okay it will occupy the ram so what what would be the size there any anyone any idea idea for kilobyte uh no in 32bit actually it would be 1 BTE one bite okay and 64bit also it would be one bite and if I'm talking about short okay short or you can also talk about string okay then in 32 bit it would be 2 by and 64bit also it would be 2 by okay now if I'm talking about something called integer so 32 bit it would be uh 4 by and 64bit it would be 4 by okay and if I'm talking about long so long means it's a floating number okay it's a float you can talk about so float would be uh 32 bit it would be 4 by and 64 bit it would be 8 by and long long there is another data type called long long long long means it's a double in Python we call it double okay so mostly you will see in the weight initialization they will be assigning the double number okay instead of floating number so it would be uh in the 32 bit it would be 8 by okay 8 bytes and 64 bit it would be be 8 bytes okay now tell me uh which uh data type is taking more space in the memory U floating or integer tell me just reply me guys first in the chat which data type is taking more memory in the uh more space in the memory float yes you are correct float is taking more memory so now let's say whenever we are training any kinds of neural network so by default the weight initialization or weight adjusting is happening with the floating number now see you can also round the floating number let's say you you are having these kinds of number 1.22 okay or let's say 2.33 now if you just round it let's say 1.22 you can make it as 1 okay and 2. 32 you can make it as two now you just round the number and it has become in that means integer okay some data loss would be happened but again you are somehow trying to adjust it or let's say round it to the root root number okay so we call it a quantization technique so basically what you are doing uh the floating number you are having okay in the weight you are just trying to uh round it to the actual number okay you are just trying to convert the floating number to integer number okay now tell me uh previously it was having that uh floating number now it has become the integer number now is there would be any uh uh like changes in the memory yes or no okay now see memory size would be reduced because of this U integer number because we have done the quantization technique okay so this is the quantization idea basically uh you are just trying to convert your floating number to integer number all right yes and whenever I'm talking about models uh model will have l let's say billion million parameter now let's say if you have billion million parameter and you are converting everything to the integer now just think about how much memory will save let's say your model size is 30 GB okay your model size is 30 GB initially okay now after doing the quantization this model will have 5gb okay and we call it as quantized model and this is the actual model so some accuracy might be drop in this model but again this model would be fast and we can easily load this model in the memory okay in our low configuration PC got it so let's say this model needs actually 16 GB Ram but after done the quantization this model has become 5gb now I can easily run this model in the 8GB M Ram or let's say 4GB Ram it is also possible got the idea guys if it is clear just write clear in the the chat so that so that I can understand you are getting my point yes performance will reduce uh but we need somehow the faster inference okay but quantize model is also good it will give you like good responses okay now there are different types of actually quantization techniques okay so one of them is gml okay gml gml is the quantization technique or quantization Library you can talk about gml gml format quantization there are various kinds of technique but uh they have used something called gml okay gml quantization so today actually I'll be using one gml format model quantized model of that 13 billion parameter model and I will show you how we can execute the model all right okay now let me show you the model actually I'm going to use here so this is the model guys I will be using so let me give you the link so this is the link guys and L 2 13 billion chat okay because I want to do question answering with my model that's why I I'm using chat model but let's see if you want to generate text guys which model you will be using tell me chat model or without chat model no no no it is support Lama CPP I I'll I'll execute and show you Prashant yeah without chat uh yeah now see guys this is the chat model and this is the gml model and this model has different different variant as well see uh some of the model is like 5gb some of the model is 6gb okay 7gb so different different model we have so from these are the model actually I'll be using one particular model so this is uh your quantization Technique you can talk about quantization Library so Library they used for the quantization okay so uh so zml is the one of them and if you see this is the dot bin that means it's a binary model okay it's a binary representation all right now see guys uh if you want to use this quantized model OKAY gml version model then you need to use one Library called uh Lama CPP okay Lama CPP CPP okay this is the library let me show you um see that's how you can install this Lama CPP Library so these are the command you need to execute so cake so this is the command so it will install your Lama CPP and as well as Lama CPP python you need and this is the specific napai version you need and as well as the hugging face Hub also you need okay why you need the hugging face Hub because this model is available on the hugging face okay and to download this model from the hugging face I need this hugging face Hub okay this is the library now let me EX and see whether it is working here or not let me also give you the code in the code share guys you can let me know if you are able to see the code in the code share the code is accessible guys yes or no uh please give me some response so that I can get to know okay uh maybe installation is done uh okay fine so you can ALS also make the installation all right now I will be defining the model actually I'll be using okay so now let's define the model here so okay so see guys uh this is the model I'm going to use uh Lama 2 13 billion chat gml all right see this is the model uh Lama 2 13 so you just copy copy this name and just give it here copy this name and give it here and you also need to give the Bas model name because here you can see there are lots of model OKAY in binary format now which particular model you should be using here so I'm using this model so let me copy the name and searce it here see I'm using this specific model and this model model size is 9 76 GB actually okay this is the model so this model I'll be using so let me execute now first of all I need to import uh hugging face Hub to download the model as well as I will also import something called Lama CPP Library okay now let's download the model so let me also give you the code now here if you see I'm giving the repo ID so this is my repo ID model name or path and this is the base model I want to download okay and I'm using hugging face Hub to download the model now let me download so see it's downloading it's around 9.76 GB share the link I already shared this uh code shell link all the codes are available here let me share it again all the codes are available just copy paste uh in your notebook and ex Ute one by one so guys is it running so far everything is fine without any error and if you check the original uh this 13 billion parameter model it's like huge model okay you can't U download this model on this neural lab so you need a good uh instance there so that is why actually we are using this contest model almost done let's see okay it's done now if you want to check the model path actually where it has downloaded you can just uh uh see that see this is the path actually it has downloaded the model okay see we have locally downloaded our model now what I need to do I need to load my model okay so to load my model I will be using this Lama CPP Library okay and see I'm importing from Lama CPP import uh Lama now with the help of that actually I will load my model okay see uh if you have GPU in your machine then this would be quick response okay otherwise maybe it will take time let's see what happened on neural app because in neurolab it doesn't have any GPU so here is the model path I am giving and these are the parameter you need to give okay like uh threshold U number of threshold like CPU CES you want to use then number of B actually you want to use okay then number of GPU layers you have so by default keep this number and let's execute and see what happened loaded internal vocab okay so it has been loaded I guess let me execute it again it's loading so this is the problem with uh open source llm because here it it uh it needs actually some good instance okay to run the model okay done uh there is no error okay fine now what I can do let me give you the code now let's uh create one Pro prom template here uh guys do you know what is promt template anyone maybe uh you already learned this thing in your open a discussion just give me a quick response in the chat what is a prompt template what is prompt do you know why we use prompt in llm yes okay great see here we are writing one prompt here our custom prompt template so here I'm just telling as a prompt uh write a linear regression code okay and as a system prompt I'm giving you are a helpful uh and respective respectful and honest assistant always answer as a helpfully okay then user will give you the prompt and you need to provide the answer as a assistant okay so this is the custom prompt template I have created now let me execute and give it to my model also I'll paste it here h now finally I will give this promt template to my llm okay see I'm calling this Lama um that means this uh Lama CPP library and here I'm giving my prompt template okay see this is my prompt template I have created prompt template as well as I'm also giving the max token length okay that means maximum response okay maximum tokens actually it will give me as output and I'm also setting the temperature okay temperature top P then P penalty I think you remember if I open this one Lama do Lama 2. a now if I go to the settings now see these are the parameter you can adjust here got it guys what is this parameter see temperature max token top parameter okay see everything is there you can um change it here so by default keep this number and execute can you explain the penalty see uh penalty like see it's a parameter actually it helps to generate a like you can say uh actual response okay let's say if you increase and decrease this parameter so what will happen actually you will see your model will give some random response okay or let's say the response actually it is not relevant to your prompt you are giving so this parameter actually adjustable parameter so this parameter can be changes whenever you are changing the temperature parameter so here temperature parameter I kept as 0.5 that means I'm turning to my model uh sometimes just take a risk okay sometimes don't take a risk okay it just a uh I mean adjusted number I have given now let's say if I'm increasing the temperature value let's say close to one so what will happen my model will be taking risk okay let's say if I'm giving any kinds of prompt and if if it doesn't know anything it will give risk and it will generate some random response as well which can be correct which can be wrong as well okay and if you decrease this parameter close to zero so what will happen your model won't be taking any risk it will only give the authentic response you are expecting from your model okay so these are the parameter can be changed all together see again it is running on CPU machine that's why respond time little bit High here and again we are using 13 billion parameter model so that's why if you're taking 7 billion parameter model so respond time would be a little bit less so let me give you the code as well so it's still running let's wait for some times if anyone get getting response so you can let me know whether response uh unable to run in neural lab um see I think I'm able to run it's working for me so far so if you're not able to run in neural Labs what you can do you can open Google collab Iman okay and there actually you can execute maybe the same code you can copy paste there and make sure you selected GPU there it's taking time a lot guys so side by side what I can do I can also show you the collab execution because I don't know how much it will take I already have the notebook ready so let me just show you I'll share it with you so let me connect still running on NE lab okay so here I got the GPU Tesla T4 this is the free version GPU and let me install the libraries guys if it is taking time for you in La so you can execute on Google collab I think it you will get quick response there because again I need to cover that uh langen part so it will take time okay done now let me quickly execute because I already explained these are the code how it is working okay now let's load the model okay now if you want to check the GPU layers so you can check it out so I have 32 layers in my GPU and here is my custom prom template and now let's uh execute my llm and let's wait for the response okay done now this is the response I got now if you want to see the actual response so you need to uh call this one like Choice then I want to take the first uh list and this is the text okay it will give you now see it is telling uh I would be happy to help with that however I want to make sure we have the same understanding on the linear regression okay so basically if you're executing for the first time so it will give you this response okay now if you want to get the actual response then again you need to execute the same code so it's better better to use a 7 billion version model because it will give you quick response um than this 13 billion one so guys are you able to execute the code I shared with you this notebook okay done now this is the response and this is my final response now see uh is it correct code can anybody tell me uh I told my model to generate linear regression code for me now just see the code and tell me just give me quick response guys in the chat yeah so for this we need to use some smallest version of the model okay because if you don't have good configuration PC then this is the only option SAS all right now is it is it correct code just give me a quick response okay great now see you can ask any kinds of question okay like your chat GPT or what you have done so far okay now see without any cost we are able to also uh use these kinds of large language model okay yeah now you don't need to pay for anything if you don't have money okay if you don't want to buy open AI so it's completely fine you have different different uh large language model open source large language model you can use them for your development and tomorrow I'll be discussing one particular projects then it would be clear like how we can Implement any kinds of projects with respect to that okay yeah so this is uh the implementation of Lama 2 uh using the Lama CPP library now I'll show you how we can do it with the help of Lang chin because going forward all the application will be uh like uh developing with the help of Lin okay so first of all let me uh stop that uh instance I have opened okay now all right so can we try this free llm instead open Ai and make a uh practice with the Lang yes you can do it I will show you how to use uh with the l okay I'll show you everything would be cleared so see the same thing you need to do as of now you have done with the open AI only you just need to import this large language model open source large language model okay then you need to use that as llm that's it okay yeah all right now this code is working fine guys everyone are you able to get the response just uh give me a confirmation then I think I should start with the langen one if it is running fine for you just give me a quick response okay now let's see the Lang chain one so let me uh share you with this code so here I'm going to use the actual model OKAY actual model not the quantized model and I'll be using 7 billion parameter model and let's see how we can use it so this is the code actually you can refer yeah so here actually GPU is required okay GPU is required now first of all let me connect the notbook all right now if you want to check the GPU you got or not so this is the command so here again I got Tesla T4 GPU then I need to install some of the libraries here okay so first thing I need something called Transformers okay why I need to install Transformers because uh this model is available on the hugging face okay if you see here and I'll be using hugging face pipeline here to load the model that's why sorry not this one I think just just let me open this one yeah so I have the model here H so see this is the model on hugging F and I will be loading this model with the help of hugging fist pipeline okay so that's why this Transformer library is required then these are the like dependency you need with the this Transformer then I I'm also installing something called Lang chain okay then bits and bu and accelerate you need you don't you need to install for this Transformer now let me install them uh link I think I have already given just just a minute uh link would be shared just a minute okay then I need to loging with my hugging face okay to loging with the hugging face this is the command hugging face uh CLI login okay you need to do it it now let me execute now it will ask for the uh token okay secret token yeah so you can take time now how to generate this secret token just go to your hugging Fish account let me open my hugging Fish account hugging face now here just click on the profile and click on the settings okay and here you will get something called access tokens now click on the access tokens now here I already have some of the token so what I will do I will uh remove one of the token from here so let me delete it okay now I'll generate a new tokens so you can also generate a new tokens so give the name I'll give Lama and I will give only read access because I I only want to read the model okay not I I don't want to upload anything that's why read is fine now generate the tokens now this is my Lama uh tokens now I'll copy it so you need to generate your own token guys don't use my token I'll remove it after sometimes now here I can give the token and press enter now here just give yes and press enter done login successful now first of all I need to import something called hugging face pipeline because I already told you with the help of hugging F pipeline I need to uh like uh load the Llama 2 model okay now let me uh first of all imported from the langen see len. llms I'm importing hugging face pipeline okay now if you're using openi model U I think you remember you you used to import something like that uh from langen llm import openi yes or no can you can you recall that concept you learn in your openi so only difference would be like that now I also uh need to import tokenizer okay why I need to import tokenizer because yeah so link just a minute so link I will add in this uh code share okay see this is the link I have added at the last so you can copy from here now why tokenizer is required Auto tokenizer so whenever you will be giving uh the input to your llm so it would be a raw text okay but um see Auto tokenizer what it does actually it will take the raw text and it will clean up first of all it will do the preprocessing some of the preprocessing let's say if you if it is have some kinds of HTML tags and all it will remove then it will convert that uh uh like text to numbers okay automatically it would be converted using this Auto tokenizer okay Auto tokenizer class so I I need to import that I also need to import something called Transformers and torch and I will also import this warnings done now first of all I need to load the model okay I need to load the model now see guys here one thing you need to remember so I'm using this particular model let me show you so if I open this model on the hugging face so this is the model I'm using and this model is from meta Lama if you see here I'm not using any quantized model this is the actual model and see I already have the permission here okay I already have the permission you have been granted access to this model but for you this this will come like that let me show you so if I open my en Cito window and if I go to this link uh you will see this window guys can you can you see that can you check from your computer whether you are getting this one or not access Lama to on hugging P then you need to submit some form here you need to sign up just give me a quick response uh can you see this window guys okay so if you're getting this windows so what you need to do you need to log in okay you need to log login and submit that information I already told you so if you visit that one meta Lama 2 Meta Meta Lama 2 sorry it would be llama 2 now here you will get this this window okay here you need to submit your information and maybe if you have submitted for the first time uh initially I showed you then it's completely fine and make sure the email address you are giving the same email address you are using for the hugging face okay now see I already have the access uh to this model to The Meta this organization that's why I can access these are the model now see after some times let's say 40 to 50 minutes you will get one notification okay in your email so it will be looking like that let's say your name this let you know that your request uh access to this model has been accepted by the repo author okay so once you got this mail that means you would be able to access this model okay then you will able to to see you have the uh you you have been granted to the access to the model okay you will get this notification then you will be able to use the official version of the model and if you're are not getting the access as of now so what you can do you can activate this line of code and you can comment this line of code okay see this is another uh organization that means another guy he has cloned this meta model okay that means this model and he has already published this model from his organization that means from his Repository and this is completely public okay you can easily download the model no need any permission okay so this is the alternative way to use the model okay so I already have the permission so I will use the official model I will just comment this line but if you don't have the access you can uncomment this line and comment this line it's up to you now let me execute now first of all I need to load my tokenizer okay uh so tokenizer will use the same name to load the token tokenizer okay now let me load the tokenizer loaded now here I need to create the pipeline hugging face pipeline so what is the hugging face pipeline see um how this hugging face pipeline will work so let's say uh this is your model or let's say this is your pipeline this is your pipeline object you have created and this is the input you are giving input text input text okay so it will give you the response so in pipeline what will happen so first of all it will uh apply some preprocessing apply preprocessing preprocessing okay with the help of uh Auto tokenizer auto toen ner okay then second what it will do it will uh convert that number okay that means a text would be converted to numbers that means Vector okay then this Vector would be passed to my model okay then prediction would be happened then fourth it will give you the response okay so this is the pipeline task actually so this is the pipeline they have created so you don't need to take care these are the task automatically it would be done okay you just need to create this pipeline objects now here I already imported Transformers you remember and here I'm just calling the pipeline and here you need to give the name so here I'm performing Tech generation okay that's why I'm giving Tech generation because if you see the model it's a TCH generation model okay although it's a chat model but it's a tech generation model let me show you the model card if you see it's a TCH generation model okay this is the key you need to give so here here I already given the name Tech generation now here I given the model so this is the model I given and I also given the tokenizer I downloaded now these are the default parameter you need to give okay no need to change anything the default parameter you need to give now let me load my pipeline now see if this model is not available first of all it will download the model from the hugging P so it's downloading the model anyone doing with me guys so which one you are using the official one or this alternative one alternative one okay great so you can wait after applying this uh uh like you can say access permission you can wait for uh like 40 to 50 minutes or let's say 1 hour you will get the email definitely you will get the email then you can use the official one because in the hugging pH what happens actually um some of the organization uh will have their private repository okay and if you want to access the private repository you need the access from the author okay otherwise you can't use their model and all okay they will be uploading that's why we need to apply for the permission but most of the repository you will see it's public okay you don't need any permission but this is the meta organization that's why maybe they have uh given you that one maybe they want to uh take your information okay because whenever you are submitting the this request form uh they are having your name email address which organization you are working on so that they they will send you some mail regarding their product okay maybe this is the things they have developed see model has been downloaded now see guys this is the magic Now using hugging face pipeline you can easily create your llm see now as a pipeline I need to give this pipeline objects okay and this pipeline object is nothing but my entire uh Auto tokenizer and my model okay everything it is there now model uh you need to give some argument so what is the argument argument means the temperature okay the temperature value so we always give the temperature value because I want uh my model like how it will give me the response and all so as of now I just set this temperature as zero because I am telling to my model don't give any random output just stick to the response you are giving okay now see guys this is the llm I have developed now see those who have used open a maybe you just used open a here okay instead of llm like that maybe used like that so llm equal to open AI okay and here you you used model name let's say GPT uh GPT 3. 3.5 turbo yes or no please tell me got the difference uh how to use open open Ai and how to use open source one please give me give me a confirmation in the chat guys I can't see any response so please response me okay now let me uh remove this line and let me open uh load my llm okay okay now uh what I need to do I need to uh give my prompt okay so first of all I will be giving the prompt like that okay in just one shot so here I'm giving one prompt so what would be the good name for a company that makes colorful socks okay so this is the prompt I have given to my llm now let's see what is the response it will generate see 7me model is also very good model me I personally use this model a lot so you will see it will give you like very good answer and it's not a quantized model okay we are using the actual model see this is the response okay now it has given me uh some company name a good name for the company that makes colorful socks could be something playful and crashy uh now see this is the company uh uh sock tastic and then toys on fire color of fista then soulmates uh stre socks Hue and cry uh socktopia and souls uh session okay so these are the company you can use uh let's say if you are like stablishing any company so you can use this name this is a unique name actually now let's uh give another P so here I have given another P here I'm telling I want to open a restaurant for Indian food suggest me uh some fence name for this okay now let's see what is the name it will give me okay see uh it has given me so many name so tanduri kns spice route Mumbai street food uh then uh Rajasthani Royal then uh Tikka tandur Nan shop Biryani bazer Masala am menion and dosen it's taking more time to give the response yeah definitely it will give some time because we are using the actual model not a quantised model okay now isn't it good response guys what you feel like tell me isn't it good response okay now you can also uh create your prompt templates okay now here I have given the prompt directly now you can also create your own prom templates okay it is also possible so to create the prom templates you need to import the prom template from langen and langen I think it is already discussed like what is prompt templates what is prompt okay uh everything actually uh uh we we have already seen in the langin so that is what actually I'm using we are not playing right so we have to compromise yeah now let's uh import this prom template and this llm chain okay why I need llm chain because if you want to add your custom prom templates you need this llm chain okay with the help of llm chain you will combine your llm and your prom template together okay then you can execute now see the first prom template I have developed this is the first prom template and this is the prom template and input variable is kins okay now instead of giving the template okay in one chance I'm just I will give the name I'll give the cuine name and it will automatically take take the prom template from from here okay now see how it will work now if I execute it now see if I do format operation and give the kuin equal to Indian now see this is the prompt it will give me okay I want to open a Resturant for the Indian food see automatically it has taken the input okay now this is another prompt I have developed uh provide me a concise summary for the book name okay now book name us will give that okay instead of giving the whole template user will only give the Boog name and it will take the entire prompt now see this is the entire prompt it will make like that okay provide me a uh concise summary of the book of Alchemist see user is giving Alchemist and Alchemist will come here now I will execute my final Chen now see I'm calling my llm Chen and here llm is equal to G I'm giving my llm which I already created here this is my llm I think you remember and as well as I'm also giving my prompt template see prompt is equal to my prompt template so let's take the first prompt template first of all so I'll take this prompt template okay and baros is equal to true that means if you want to see the output as well like what is happening so you can give it as true otherwise you can keep it as false now let's give the uh prompt here so this is prompt template one means I want for the uh food purpose okay that means cuisin so let me give the cuisin name so I'll Indian now let's execute fcy Resturant thank you for Advance help best regard okay let me again now see first of all it will uh like make the prompt now see it will give give give you the response now see the response you got now let's say I want to use the prom template to so I'll copy the name and here I will give it and this is for the summarized book okay now here you can give any kinds of book let's give Harry Potter okay done now here is the uh Harry Potter uh you can see this is the summary okay like what is the Harry Potter book and all about so it will give you the entire summary okay so that's how actually you can use this open source large language model okay now you can try with different different variant so if you if you can visit here let me visit maybe this is the page see you have still lots of model you can explore okay uh side by side now I believe guys you are able to understand like how to use open source large language model yes or no so tomorrow we are uh going to implement one particular projects called medical chatbot then I will show you how we can uh execute on the CPU machine as well so guys everything is clear give me a confirmation because we are done with the session and one particular things actually uh you need to download for tomorrow so let me show you because we need this thing actually so this is the model actually I'm going to use tomorrow for the medical chatbot implementation so this model just try to download and keep it with you so I'll be using Lamas to 7B chat model gml again I will be using quanti model and from here and see this is the model you need to download so let me give you the link so copy link address so everyone you need to download this model and keep it with you okay so tomorrow this model is required I have shared the link so maybe you can get the link from here and you can download the model and it's around uh 3.79 GB you need to download this model no tomorrow is not a last uh class okay still some of the session would be there so link is there in the chat guys so you need to download this model and keep it with you okay because this uh download will take time so just try to download this model and keep it with you so uh how how was the session guys are you able to understand everything about this open source large language model and all and I already shared all the code and everything so you can execute from your site if yes then let's uh I think end the session I have done with the discussion okay uh so let's start with our session guys uh so today actually I was uh telling I will be showing you one project implementation so the project name is n2n medical chatbot yes and here I will try to integrate all of the like technology you have learned so far let's say Lang chain uh Vector database okay then I will also use like lama lama 2 model yesterday I think I was discussing Lama 2 how we can execute and all okay so we'll be combining this thing uh together and we'll be implementing this amazing projects so mostly uh today actually I will show you the notebook experiment okay and tomorrow I will show you uh the web app implementation at the modular coding implementation okay so today I'll be discussing the architecture overview and all and I will show you the notebook experiment like how we can develop this thing uh in our jupyter notebook because I know like most of you are like already familiar with jupyter notebook implementation I'll uh try to show you after implementing the projects on the jupyter notebook how we can convert to our modular coding okay so that should be our main objective so are you ready guys if you are ready just uh give me a quick yes in the chat so that I can start with the session okay thank you thank you everyone all right uh so first of all uh let me uh tell you the technology and the architecture actually I'm going to uh use in this projects uh then the implementation would be clear in your mind uh because uh I always like to discuss the architecture at the very first before implementing any kinds of projects okay so it makes me like uh to discuss the projects in a very easy way okay so let's do the architecture discussion at the very first all right um guys my screen is visible uh can you see that Blackboard and all you can let me know or should I zoom a little bit okay great all right now uh let's discuss with the architecture uh overview so the projects actually I'm going to implement called uh medical chatbot okay so here what is our idea so the first thing actually see uh the uh chatbot actually I'm going to implement so this would be only uh let's say depends upon our custom data okay the data actually I will show to my bot it will only give me the response uh with respect to that okay you can also like U integrate like U um all over the internet data it is also possible but uh first of all I want to show you let's say if you have some specific data if you have some specific let's say domain like that data how to connect okay with your Bot because we have seen like the chatbot implementation U like with the all over the data available in the Internet it's completely fine but we haven't seen like how to use our custom data okay so that is the main thing here so that's why uh so the first thing what I need to do in the data injetion part uh I'll be using my own component here okay so there actually I'm going to write one component called Data inje or you can talk about data integration so here you can use any kinds of data so here in this case I'm going to use something called PDF file okay PDF file PDF files so in this case actually what kinds of PDF PDF file actually I'll be using so I'll be using something called Medical medical book medical books okay so let me just show you the PDF actually I'm going to use here uh I will also give the PDF um no need to worries about so see guys this is the book actually I'm going to use so the book name is the G enyclopedia of medicine okay so this is one of the Great Book actually I found in the internet it has actually 637 pages and this book has been discussed all the disease with respect to the medicine as well okay if you go through this book so I was just going through the book and I was just checking what are the contents actually they have given see all kinds of disease actually they have mentioned with respect to the disease actually they have also given the medicine okay you need to use so this kinds of data actually I will give to my llm and I will teach my llm like uh this is my data okay and these are the disease with respect to that these are actually my let's say medicine okay so if user is asking any kinds of question with respect to that you should give the response okay so this is the data guys so I'll will share this PDF with you so you can open it up and you can go through okay you can go through like what are the disase actually it has discussed what are the medicine it has discussed uh okay everything uh you will get from here all right so this is going to be my data source here okay so the first component actually I'm going to implement which is nothing but my data integration all right so after after like uh data integration what I need to do because it's a PDF file okay it's a PDF file I just need to extract those data okay if I'm not extracting the data then how we will give to my model right so that is why the second thing what I need to do I need to extract the data so here I'm going to write another component and I will just name it as extract extract uh data or you can also tell content okay content so this is going to be my second component now after extracting the data what I need to do okay I need to create a chunks okay so let me just draw it here so what I will do here I will create different different chunks okay why this chunks is important I will tell you yeah so here I'm going to create text chunks text chunks okay so let me just copy this component okay so this is my Tex chunks okay now let me uh discuss what is this test CHS okay why I exactly need that so for this what I can do uh let's uh copy some of the content from this book so let's copy from here um let's say I will copy this content from here I'll copy let's copy this part I'll copy now I'll just paste this content here okay so let's say this is my data so let's say this is my data so let's say this is my entire book data I collected okay I extracted from my PDF book so this is my uh Corpus okay you can call it this is a corpus Corpus Corpus Corpus means your entire data okay you have currently but why we are creating the chunks okay so to understand this one first of all I will show you so if you search open a models okay let's give you the like demo with the open a only so I'll just search open AI model okay if I search it now we will get one page here now let me Zoom a little bit yeah now let's say these are uh these are the model are available okay here these are the model are available now let's say you want to use this GPT 3.5 okay if I click on this model now here you will see something called this model and this model description and the context window okay what is this context window cont context window is nothing but it's just a input token size okay so like how many tokens this model can accept Okay at a time as a input so this is the input token now let's say if you're using GPT 3.5 turbo okay so this is the tokens okay this is the tokens like 4,096 tokens it can take as a input okay now here in this case I I'm using something called Lama 2 model OKAY the model actually I'm going to use called Lama 2 model llama 2 model and uh this model actually uh has the Contex size that means the input tokens uh is nothing but 496 okay token limit token limit okay but if you see in this entire PDF okay if I extract the data okay if I'm extracting the data from this entire PDF I have around 637 Pages now just think about will it be like more than uh this token guys 4,096 token yes or no just tell me in the chat what do you feel like token means it's just a particular word you can talk about if you combine three character together you can call as one token uh making sense guys like if I am extracting the data from my entire PDF so it would be more than 4,096 token yes or no yeah so maybe you are getting okay so that is why actually what I need to do okay because see my input length is that means input limit is 496 token but whenever I'm extracting the data it might be more than it might be more than 4,096 tokens okay it might be more than 4,096 tokens so that is why what I need to do I need to just create a chunks okay instead of giving all the Corpus together to my model I'll be create a different different chunks what is the chunks guys chunks means like you will be taking some particular paragraph let's say I'll start from here okay now let's say I will assign this Chang size Chang size is equal to let's say I will assign as 200 so what it will do it will count 200 word okay let's say this is the 200 word I have here so it would be one CH okay this is my first chunks now again uh it will start from here again it will count 200 wordss and it will start uh like end here okay so this would be my second chance so that's how like all the data you have okay in this PDF it will be creating a different different chunks okay and now if you see one particular chunks have the token size of 200 okay now there won't be any input problem to my model okay so this is the idea of this creation of the chunks I think this part is clear why this chunks is important okay yes so there is another concept called chunks overlap okay I discuss whenever I will be assigning the chunks overlap I will discuss what is Chunks overlap s overlap is nothing but so whenever you will Design This chunks overlap par parag uh this parameter Chun overlap overlap let's say I will assign as 20 so what it will do whenever it will create the second chunks okay it will just go back to your first chunks and it will count 20 words again so let's say here is my 20 words okay so from here actually it will start the second chunks and it will end here okay it will end here okay so basically what is happening if you see here some extra word is also coming from my previous chunks as well okay so with that actually my model is getting the context that means after this chunks actually this chunks is starting okay got it so this is the idea of this chunks overlap so that's how actually we'll be generating our embedding Vector embedding then we'll be storing them to the vector DB got it yeah now let's go to our architecture and see our uh like uh fourth component what I will be do now fourth component wise I'll be creating something called embeddings okay so here after creating the chunks each of the chunks I need to convert as a number okay so we call it as embedding so just let me draw it this is my embedding now I'll just copy this component uh thanks Forman for your contribution thank you so this is my embedding so embedding is nothing but it's a a vector okay so it's a vector so let's say it can be any kinds of vector I'll just take some dummy Vector here so let's say this is my Vector okay so we call it as embedding this is my embedding okay now what I need to do see I have uh extracted my data as well as I have also created my chunks and I have also converted that chunks to my embedding that means vector now what I need to do I will be creating one semantic index okay what is semantic index semantic index is nothing but uh see it's a vector database concept I think whenever you learn the vector database so in Vector database we have two kinds of thing okay one is like my knowledge base and other is like like semantic index okay with the help of the semantic index actually it will build a cluster I think you remember so it will build a different different cluster so let's say king and queen would be appearing in the same cluster then man and woman will be appearing in the same cluster then Mony will appearing in the different cluster okay so with the help of the centic index that can be possible okay it will calculate the distance between all the vector and will create some like let's say like cluster here okay so this is the idea of this centic index so just let me draw it here so after creating my embedding so what I will do with the help of this Vector DB I'll be creating one I'll just build one centic index uh semantic index so I'll combine all the vector together okay and I will be building this centic index extra words are coming on previous chunks to make relationship the vector uh yeah so whenever I'm talking about this chunks overlap that means I'm taking some previous words as well okay in my second chance that means uh my model will able to understand after this chunks actually this second chance chunks is starting okay so because of this overlap overlap condition got it yeah now I have built my semantic index now what I need to do guys I need to build my knowledge base okay knowledge means I I just need to store these are the vector to my knowledge base so just let me create the component here so I'll be creating one knowledge base knowledge base okay so here knowledge base wise I'll be using something called pine cone Pine con um Vector restore uh so guys I think you are already familiar with pine cone I think this has been covered already how to work with pine cone and all how we can store the vectors in my Pine con database yes or no okay okay great now I'll be building my knowledge base all right now see this is the part actually my first part okay this is my first component this is my let's say uh this is my backend component you can talk about now I also need to build my front end component so this thing is my back end compon component the entire thing you can talk about this is my back end component this is my back end component okay now see what now user will do user will raise some query okay with respect to that I also need to provide the answer to the user uh I'll be using pine cone here okay you can also integrate chrb why I'll be using pine con because Pine con is the remote database okay it is already hosted in the website so I can store my Vector there but chroma DV is the local Vector DV okay so that is why actually I W be using chroma DV but you can also integrate chroma DB the same thing you can do it all right yeah now let's work with the user part now let's say this is my user let's say this is my user this is my user okay so I can assign this this is my user so user what uh actually he will do he will raise some query okay so let's say this is the question so here is the question is the question user will ask now first of all what I need to do I need to convert this question to the query embedding so here is the component I can call it as query embedding okay so this is the query embedding now this qu query embedding I just need to send to my knowledge base okay so here I can integrate like that so I will send this query embedding to my knowledge base uh thanks uh bright bright side I think what's your name I don't know but thanks for the contribution yeah thank you okay now this uh question I will send to my knowledge base okay because knowledge base has all of the vector okay all of the data now now what uh okay Karan thank you Karan okay for your contribution thank you it really motivates a lot thank you all right all right great now see this query uh actually I will send to my knowledge base okay now what this knowledge base will do actually it will give you some rank result okay what it will give you it will give you some rank result just let me draw this component this will give you rank result that means it will give you some closest Vector with respect to the query you have asked okay now what I need to do okay I will be intrig my large language model OKAY in this case I'll be using something called Lama 2 Lama 2 okay so this is my large language model so with the help of this large language model I'll just filter out my exact answer I'm looking for from this rank result okay so this llm will give me the response so this response I will send to the user okay I'll send to the user all right so this is the complete architecture of our medical chatboard so the first thing what I doing first of all I am integrating my data component which is nothing but PDF file in this case okay I'll be using PDF book now the second thing I need to extract the data or content from the PDF book then I need to create a chunks okay I need to create different different chunks because it might be more than my input tokens okay to my model so that's why this chunks creation is very much important so after creation of the chunks I'll be generating the embeddings okay embeddings means the vector okay that Vector I'll be combined together and I will be build one semantic index okay in the vector DB then it will be creating one uh like system called knowledge base okay this is nothing but our Pine con Vector history you can talk about now I'll be go going to the front end part so here actually user will give some question okay that question first of all I need to like convert to the query embedding that query embedding I will be sending to the knowledge base knowledge base will give me some rank result that rank results I'll be sending to my Lama 2 model my Lama 2 model will understand the question okay understand the like question so here I can I think draw one more line so whatever question user is asking first of all it will understand the query as well as the answer okay answer from your database that's that means the knowledge base so both it will do the processing and after that it will give you the correct response okay it will give you the uh actual actual response actual response okay so this is the complete idea so guys uh you can let me know whether this architecture part is clear or not everyone just give me a quick response in the chat so that I can go proceed how this entire architecture is working how we have we have created different different component right so now this this thing would be very much easy for us to implement the code right now because see what we usually do okay initially whenever I was in learning phase I also did the same thing let's say whenever I I got one projects I directly jump into the coding part okay instead of understanding the project architecture and all okay so it it was like very difficult me to complete the code because I don't know like after creating the data in where I need to go okay so that's why uh what I started actually I started creating these kinds of architecture so that see I have my architecture right now let's say I have completed this data data component part let's say I will again uh like do the coding tomorrow then I can see like I have completed this data like you can say integration part now I I I need to work on this extract data or content part then after that actually I need to work on this Tech chunks part okay so that's how I have the plan actually entire plan of my entire projects okay so that's why this like architecture creation is very much important what I feel like okay and don't need to worry about I will be also maintaining the GitHub and all like I'll be committing the code there so that you can also get the code from there everything I will show you okay great all right now let's try to understand what are the technology or what are the tech stack actually I'm going to use in this projects okay so let me just write here um I'll be taking a different color maybe I can take this color so take a stack take is Tech used so the first thing actually um as a programming language wise programming language I'll be using Python Programming okay now the second thing I'll be using something called A Lang chin okay langin as my um generative AI generative AI framework okay like uh in deep learning actually I think you know in DL actually we have different different framework let's say we have tensor flow we have tensor flow okay then we have something called P torch okay so we have then we have also something called MX net so these are the framework let's say we have different different in deep learning but whenever I'm talking about generative AI okay whenever I'm developing something in the field of generative AI I should use this langin or there is another framework you can use something called uh maybe I can name it as llama index Lama index okay so this is the alternative framework of the langen so whatever things actually you can do with the langen with the help of langen uh just a minute yeah so so whatever things actually you can do with the help of this langin the same thing you can also do with the help of L index okay and we have Au inte Lama index in our paid courses I think you can go to the syllabus and you can check it there okay we'll show llama index as well there all right all right now third thing maybe I can just uh just a minute okay so the third thing uh our uh front end front end or I can talk about our web app okay for the web app implementation I'll be using flask okay maybe I think you have already learned like how to use stream lit okay in your previous projects guys yes or no do you know how to integrate stream lead with our um application and all so that is why I have integrated flask okay I can um I just want to show you different different things actually you can integrate here all right now our model Wise llm Wise I'll be using meta Lama 2 all right and fifth vector be wise I'll be using pine cone okay so these are the tech stack actually I'll be using to implement this entire projects so far guys everything is clear you can let me know in the chat the take is stack and the architecture everything is clear here okay great all right now let's go to the our implementation okay now the first thing what I will do uh because you will be also doing the coding with me so it's better to use my GitHub maybe because from my GitHub actually you can get the code I think so what I will do first of all I will be creating one repository so let me create one repository at at the very first so here I'll be creating one repository so I'll just name it as end to end end to end medical uh chatbot using Lama 2 so this is the name so let's make it as public repo and I will add rme file G ignore I'll be taking as Python and license you can take anything so let's take MIT license H then I will create the Repository okay so I'm sharing this link guys in the chat so you can Fork it and you can also get the code from here so this is the public repo everyone can access so you can Fork it you can for forkit either you can clone this repository so whatever code actually I'll be writing I'll be committing here all right now let's clone this repository so I'll just uh click on code and copy this link address and I will open my folder and here let me open my terminal so get clone and let's past the link and clone it now I'll just go inside the folder end to end medical chatbot using Lama 2 now I'm inser my folder now let's open my vs code here so if you have pyam or any other code editor you can use it feel free to use it no issue um guys can you confirm my vs code is visible to all of you can you see the text and all clearly you can let me know okay so the first thing what I need to do I'll be creating one virtual environment okay so let's create one virtual environment uh yes yes uh we'll be doing on CPU okay that is why and yesterday I told you to download one particular model guys it's around 4GB I think you remember uh yeah see uh the same thing we can do it on the neural lab as well okay so you can also open up your neural lab and you can also do it there but the thing is like there actually I need to upload my model and it will take time okay it will take time to upload my model there so I will show you how to do it how to set up the environment here as well so let me open my neural lab because it's around 4GB model so if I want to like upload there so it will take time so that's why I'm showing on on local machine so start my lab so from here actually what you can do you can uh launch up this one python so this is my medical chat Bo so here also you will get the same environment as as your V code let me show you see all right okay but I have the model in my local machine I already downloaded but if I want to upload it it will take time so it's better to use my uh this vs code okay so now let me create the environment so just write the command cond create hypen in um I'll just name the environment as uh medical or I can just write M chatbot that means medical chatbot it's very EAS just open up your terminal and just write code space dot okay this is the command to open the uh vs code okay yeah and now let's uh take the python version equal to 3.8 hyen y so everyone you should use Python version 3.8 okay no you don't need to use uh like less than 3.8 otherwise you might face some issue okay you can also take 3.9 it's fine but I'll be using 3.8 this specific version also just let me mention the command in my rme file so here step to run steps to run the project so the first thing what I need to do I need to create one so I can just write this line I just need to create my environment now let me just quickly create it you can use it okay you can use it it's up to you what particular version you will be using it's up to you personally I like python 3.8 because it supports like B uh guys am I audible now okay uh sorry there was a small power cut from my side extremely sorry for that okay thank you uh yes uh okay see uh first of all you need to create one environment okay so this is the command you need to execute uh this is the command you need to execute just Conta create hypen in then your uh name of the environment then use Python 3 uh 3.8 okay and then create the environment then I just need to activate the environment okay so this is the command so just copy and paste it now it has been activated so let me also uh give the command here okay so environment creation is done now I need to install the requirements okay some of the requirements I need for this project so let's install the requirements so here I'll be creating one file called requirement. txt okay and now let's mention uh the requirements so the first requirement I need here uh something called C transform forer I'll tell you why this C Transformer is required um so the first thing I need something called C Transformer okay and I will be using this specific version of this C Transformer so you can uh use any of the version but I'll be using this particular version because I also want to show you like whenever you are creating any kinds of projects okay you also need to specify the version of the library you are using let's say this project you are sharing after let's say one year okay so what will happen at the Times uh some Library changes would be happen Okay and some of the functionality would be removed some of the functionality would be replicated so it's better to use a specific version always okay so that is why you can use specific version let's say if I search the C Transformer on Google C Transformer Pi so you will see different different uh version of the C Transformer Library so release story now see guys different different and this is the current one 0.227 C Transformers that means see the model actually I'm going to use it's a quantized model because we'll be running on CPU so that is why uh we need this C Transformer library to load the quantized model got it I think yesterday you saw like we are using something called Lama CPP library right but here we are using Lang chain and if you want to use Lang chain so you need to use the C Transformer Library then the second Library I need sentence Transformer okay because I want to download this uh model from the hugging face itself uh uh like which model I'll be downloading from huging face itself because here I need one embedding model because as the architecture I showed you here we'll be generating embedding okay we'll be generating embedding of our text SS and to generate this embedding we need one embedding model okay so we'll be using one free embedding model uh guys just a minute just a minute okay uh now I think my network is fine okay great okay fine so that is why actually uh for this embedding okay for this embedding generation actually I need one embedding model okay and that particular model I'll be downloading from the h face itself okay so that is why I need this seat uh Transformer sorry sentence Transformer Library got it thank you now let's uh see our third requirement actually I'll be using uh third actually I need to use uh this pine cone client because I want to integrate pine cone database okay Pine con Vector DB so that's why this pine cone client is needed then as I told you I'll be also using something called Lang chain so this is the Lang chain and and I also need flask to create my front end okay so these are the prerequisite I need as of now if I need anything else I'll add later on okay I'll add later on now just let me install them quickly so before that what I can do I can just quickly commit the changes in my GitHub so that actually you can also get the code from here so requirements added so it's already added let me check it so if I refresh yeah guys see already requirements has been added so you can you can just refresh the page of my GitHub and you can open up this txt file and you can copy paste the code uh yeah we'll be also adding Docker uh cic dependra okay this thing we have already added in our paid courses and projects and all okay we'll show that how we can do the deployment yes okay now let's install the requirements so I'll just write P install hypen R uh requirement. txt so it will take some time to install the requirements let's wait so in between what I can do I can write the command here P install ienr requirement. txt so guys are you doing with me this project implementation how many of you are doing with me you can let me know in the chat so far everything is fine everything is running okay okay great let me take some comments uh can we use Docker here cicd I already answered that okay now quid is great uh is it NE Neary to mention the version in the requirements uh yes I feel like it is necessary let's say you are sharing this code or let's say you are executing this code after one year so in that one year duration what might happen actually these are the library might upgrade right some of the let's say functionality would be deprecated now let's say if you're not mentioning the version specific version so what will happen actually it will install the current version okay it will install the current version andbody is installing the current version that means the upgraded version some of the functionality would be deprecated and this project will throw the error like this is not found here so that's why it's better to use the specific version let's say if you are executing this project after one year as well okay it will work fine please let me uh quickly ask did you not up with the generator projects we started last week you did not finish up uh McQ generator I think it was uh taken by San s maybe maybe he has completed the projects we been the deployment as well guys yes or no yeah McQ is already finished if didn't downloaded the llm model that still can I make this projects are still required to download you need to download ano okay without the model how you'll predict you can uh just make the download yesterday I think I shared the link and everything right or just let me also give you the model download link so here I will be creating one folder and just name it as model and here I'll just create one txt file I'll just write as instruction. txt and just let me give you the instruction so you need to download this particular model from this URL okay so this is the link uh let me visit the link and uh this is the name of the model if I do contrl F and crl V so this is the model you need to download it's around 3. 79 GB so let me just comit it as well so I'll just comit model instruction added so those you don't have the model you can download from this link okay I have already comitted the code in my GitHub you can check it out can I make this projects in desktop application and make it as uh MSI setup and run locally yes you can do it okay you can also create as a desktop application let's say you can use Tinker U framework to ment the desktop application and all okay I think my requirement installation is completed okay uh yes it is completed now here what I will do I'll just create one uh notebook so let's create one notebook um new file I'll just name it as trials uh Tri files. IP YB and let me select my kernel here so the environment I created uh it's m chatbot where this mchat bot just a minute yeah this one now let me test it if everything is fine or not I'll just write print okay uh yeah uh I will drop the GitHub link again so this is the GitHub link yeah some installation is going on let's wait for sometimes just a minute it's done now okay now everything is working fine yeah so everything is working fine guys how many of you have done guys you can let me know for me everything is working fine so far okay and uh in between I just want to tell you guys if you don't know uh we have launched one uh paid courses of our generative a you can explore this courses and we have added so many module here so basically we'll be covering like uh fine tuning part like how we can deploy it as a cicd okay how we we can integrate Docker even Lama index okay even we have introduced more open source large language model here like Google p to Falcon okay then uh we'll be discussing so many things here so you can go through this labus and if you're interested you can enroll for this course and here you will get uh lots of end to end projects implementation and it would be amazing implementation alog together all right now uh let's start the implementation of our notebook so just a minute so here I need to import some of the libraries first of all H okay now let's import some of the libraries so first thing actually I need some um I need promt templates so uh yes I think I can reduce the size it's not visible guys I think it's visible because I'm showing I think on top of my picture yeah all right now let's import some libraries so the first thing I need something called prom templates so from Lang Chen Lang Chen uh import promt template uh prompt prom template so as of now let's import I will discuss why I'm using these are the thing okay it would be clear now I need something called uh retrieval question answering uh class okay from Lang Chen so I'll just import it from Lang Chen uh dot chain import uh you have a class called retriever question answer okay just a minute I think I should move the camera here uh now I think the screen is visible okay fine then I also need to import uh the hugging face embedding so from Lang chain uh you have one function called embeddings and you need to import hugging P embedding hugging face embeddings all right then I also need uh pine cone so from langen it is already available in the langen so langen uh do Vector store UT uh I need pine cone you can also import Pine con from here then I need uh some more Library like directory loader and my uh PDF loader because I'm going to load my PDF here so let's import so I'll just write it from Lang chain uh here you have something called document loaders so from this actually I need to import uh Pi PDF Pi PDF loader as well as my directory loader okay now to uh convert my inter Corpus to chunks I need another uh class called recursive character text splitter okay so let's import so from langen uh do text splitter import recursive text uh character text splitter okay with the help of that we'll be creating the chunks then I also need prom template so from Lang chain do prompts I need this prompt templates okay it should be import import prom template then I need also uh C Transformer library because I'll be using quantized model okay so just write from Lang chain uh llms import C Transformer C Transformer yeah maybe everything I have imported now let me execute okay done now first of all let me move my data here so I'll create one folder here called data and here I'm going to move my data just a minute I think I already downloaded the data I'll also give you the data just a minute this is my data so let me just comment it dat add it okay now I think you can download the data from my GitHub okay I already uh push that PDF okay if I go to my GitHub yeah notebook is also available data is also available now you can get the data from here now I also need to move my model okay so I already downloaded the model just let me move it here this is the model okay fine what is the difference between from langin import fromom template and promt you can use any of them dendra okay I have showed multip like two things you can use any of them both are same okay now uh what I need to do I need to uh create my Pine con cluster okay because uh we'll be using pine cone Vector DB so let me just uh quickly show you yeah so just visit this pine website so let me just logging with my account all right so the first thing you need something called API key okay just click on the API key and uh just create a API key if you don't have any API key you can create from here so I already have one default API key I'll just copy this API key I'll just copy and I will open my vs code and here just let me write so pine cone Pine con uh API key so this is my API key don't uh use my API key guys I will be removing after the implementation so you can generate your API key then I need something called Pine con API environment so I'll just write pine cone pine cone API en EnV okay to get this Pine con API uh environment you need to create one index now let's create one index here so I'll go to the index and here I'll just click on create index you can give the index name so in this case I'll be give medical chatbot and uh Dimension uh it will ask for the dimension so what is the dimension Dimension means the like embedding model you'll be using it has some particular Dimension okay so the embedding model I'm going to use in this case let me show you the embedding model uh this embedding model is available on the hugging face so this is the name of the model guys all mini LM six uh L6 V2 okay so this is the embedding model I'll be using and this model returns uh this uh Dimension that means dimension of the vector of three uh 384 okay so this is the dimension let me just write here t 84 so this is the vector Dimension and I'll be keeping cosine Matrix and let's create our index now this is your environment API now I'll copy and here I paste it okay all set now let me execute yeah now first of all I need to load my data okay load this PDF from this folder so for this let's create one function so I'll just name it as extract extract data from the PDF so let me Define one function so I'll just name it as load PDF load uncore PDF so it will take the data directory then I'll be using this directory loader I think you remember we already imported this directory loader here directory loader okay with the help of this directory loader uh I load my data then I only want to load my PDF file okay so here you can set one parameter called Globe so here I only want to load my PDF file so start.pdf then you need to Define one uh class here loader class is equal to Pi PDF loader so with the help of this Pi PDF loader uh it should be Pi PDF yeah P PDF loader it will load load it so here is the P PDF loader by PDF loaded and this thing I will store in a variable I'll just name it as load up okay now once uh I will uh load my PDF uh so I need to call load functions so I'll just write uh loader do load and I will store these other data as a documents then I will return these documents H now let me commit the changes uh data loader added okay uh one thing so let me just stop it just a minute because uh here is my model as well so I can't uh directly push the model uh just a minute let me close the execution okay so in this dogit ignore I will uh add this model name yeah now it is fine now let me commit the changes okay so I'm getting an error because I terminated that uh commit operation that's why just a minute read add get commit should positive the POS okay uh so now let me open the code again so I'm having some issue with my GitHub just a minute yeah it's done so guys so far everything is fine for you yeah so whenever we'll be doing the deployment at that time I can get uh keep my model uh either in S3 bucket either in this one uh you can also use uh Google uh like bucket okay every anywhere you can store it no issue with that okay now let me execute them H done now what I need to do I need to extract my data so I'll uh I need to load my data so I'll call this function load PDF and here I'll give my data path so here is my data present and this variable I will call as my extracted extracted data now let's load it modle not found P PDF okay so what I can do I can install Pi PDF by PDF this is the modu P install no import I have imported but it is the dependency okay if you want to use this PDF loader you need this P PDF package that is why now I think it should work just let me restart my kernel h huh now it should work see now it is working now it is loading the data so you can also keep multiple PDF here uh it will also work let's say you have 10 different book you can keep it here and guys uh all the resources has been updated in the dashboard you can visit the dashboard yesterday whatever things actually I discussed everything has been updated here so this is the dashboard and here all the videos and materials has been updated so you can go through it now I think it's done yeah it's done now you can see the data see this is uh loaded as a document now let me comment out h okay now uh guys are you able to load the data yes or no is it working okay great now we have created this uh um extract data from the PDF now what I need to do now let's go back to my architecture so this thing we have done now what I need to do I need to uh create this one uh chunks okay chunks implement because I need to convert my Corpus to chunks T chunks okay so that's why now let's write this component so for this what you can do um let me just comment the name yeah so I can name it as uh split or create a text chunks create text trunks so here I will Define another function called def text splitter or text chunks you can name anything so let's name it as text split so this will take your extracted data because the data you have extracted that is your Corpus okay it will take and it will uh create a chunks so extracted data now here I'll call this recursive text splitter this function okay with the help help of that I'll be uh creating the Chun so here I need to like pass two parameter I think remember one is my Chang size one is my chunk uh underscore size okay so you can give any chunk size here so let's define as 500 I saw like people starting with 500 and chunk overlap chunk uncore overlap so chunk overlap I will be giving let's say 20 okay so this is the starting point you can give so I hope this part is clear what is Chunks size and what is CH overlap because I already discussed on my board here okay what is the chunks and what is the chunks of lab okay all right now let's uh store this thing in a variable I'll just name it as text uh splitter okay now after that what I need to do I need to split it so again I will just uh call my text splitter and uh here you have one parameter yes you can you can put multiple data it will also work okay I have only one PDF that's why I kept it here now split documents okay now here it will take your extracted data now this thing I will store so I'll just name it as textor chunks then after that I will return this Tech chunks Tech chunks okay so this is going to be my function all right now let's apply this function I'll call this function and here uh I will pass my extracted text okay I'm getting from from here and let me store it so I'll just call it as take chunks and if you want to uh see the length like how many chunks you got so you can also print it so length of my chunks okay now let's uh do it yeah so we got SE uh 7,020 chunks okay uh because we have a huge data and our Chun size is if you see 500 okay so what it is doing actually it is just counting ing the tokens as 500 okay and it is creating one particular chunks that's how it has created 7, and20 chunks okay 7,20 chunks if you want to see them maybe it would be big file see 720 CHS and all are documents clear guys now this 720 chunks actually I need to store in my Vector DB okay but for that I need to convert them to my Vector representation so we have completed till this point um till this point we have completed we have converted our Corpus to teex chunks now what I need to do I need to uh create another function here and that function will uh give me the vector embedding so let's comment here so download embedding model okay so download I can name this function Like That download huging Face embedding so this function will download the Hing embedding from the hangas itself so here embedding is equal to uh here I imported hugging face embedding and inside that you need to pass the model name you will be downloading so here is the model I already showed you so I'll just copy the name okay everything is fine then I will return this embedding okay it's done so uh see I already uh downloaded the model previously that's why it has been executed okay no I think I didn't call the function sorry sorry I didn't call the function maybe it will download again so let's download the model so I'll just uh call it as embedding and now let's download the model see guys now it is downloading so it will take some time uh because it is downloading from the HF itself now so far guys everything is fine are you able to execute see download is done are you able to download the model guys okay fine now uh I have my embedding model okay I have my embedding model you can also print this embedding object uh see guys this is the uh see the output Dimension it is also telling uh 384 I told you this is the uh like return uh like vector Dimension and uh this is the model name okay this is the model name okay great now what I need to do so let's just uh do it quickly because I think you got the concept what I I'm doing exactly yeah now I have downloaded by embedding model now let's test this embedding model okay now let's test this one uh whether it is uh giving me the embedding model or not embedding that means embedding on not so this is the code so here here what I'm doing I'm just calling this embedding objects and here there is a parameter called embed query now here I'm just giving one uh test word okay that means T sentence I'm giving hello word okay now if I execute this one see it will return return 384 and this is nothing but this is the vector representation of hello word clear guys yes or no now with the help of this embedding model we are able to convert our text to embeddings that means vectors and what is the dimension of that Vector is 384 four okay and this is the vector that's how this Vector looks like clear can I get a confirmation quickly now this technique I will apply on top of my data okay the data actually I have extracted okay from my PDF then I will be storting them to my Vector DB all right now for this actually I will just copy paste the code from your previous session because you already completed pine cone code like how to initialize the pine cone and all so this is the code we usually initialize our pine cone pine cone client see guys okay so here you just need to give uh this one uh your Pine con API key and pine con API environment which I have already initialized I think you remember here I have already initialized okay now here you need to give the index name in this case what is my index name I think remember we created one index let me show you this is the index name medical chatbot I'll copy the name and here I will give the name okay make sure you are giving your own index name okay don't try to use my index name if you haven't created this one all right then once it is done I'll call my Pine con and from text here you need to give your extracted text okay that means the chunks you have created and you also need to provide your embedding model okay and you also need to give the index name so what this Pine con will do it will take all your uh chunks as well as your embedding model as well as the index name okay it will take all together then what it will do it will apply the embedding model on top of the data you have it will convert that data to embeddings then it will automatically store that Vector to your Pine con that means this index the index the cluster you have created on the pine con okay now let me show you so let me execute this code not able to see the code sir please uh okay now I think you can see the code let me just see once maybe I can just a minute yeah now I think it is visible I can move my screen here just a minute H see now this is uh going on so it is converting my text to numbers okay and it is storing to my Vector DB now if I go to my Vector DB now if I refresh okay refresh the page here now you will see it will store the vector here you can also see the vector this is the beauty of this pine cone even I personally like see this is the vector okay this is the vector and this is this is the text actually it has converted the vector now how many Vector it has stored as of now it has VOR stored 800 Vector okay and how many like uh chunks we have guys here I think you remember how many chunks we have we have 7,020 chunks so it will uh create 7,020 vector and it will store there so you need to wait for some times for all the uh Vector U like conversion so again I will come here see uh it has been 1,536 no no no uh not full book it's just storing now see still execution is going on so it is storing like one by one one by one one by one okay that's how so it will restore till 720 because 720 chunks you have totally yeah each chunks corresponding to each Vector counts you can you are right now see uh 1,900 2, uh 240 so I need to wait for some times because it will store otherwise I can't execute so let's take some query guys you can ask me some query in the chat in between okay it's updating for you also okay great uh is there any alternative to Pine con uh to save Vector locally yes you can use chroma DB just SP you can use chroma DB uh otherwise there is another Vector DB called f okay this is from Facebook you can use as a locally and if you want to uh store data on the remote so you can use pine con either wave yet there is another Vector DB called wave yet you can also use radius so we have already showed uh integrated in our paid courses there will show but personally I prefer this Pine con because see here uh this is the beautification actually you can see the vector you can see the score as well see this is the semantic score like uh how much uh this uh Vector is similar to this Vector got it what is autogen autogen means I can't see any autogen here uh we can check different Vector database yes you can check maybe uh chroma DB has been discussed you can also integrate chroma DB Imran 3,936 as of now what is the difference between single and single agent and multi agent like uh what kinds of agent you are talking about because agent can be like many because uh in langin actually we have Al agent agent why we use let's say you don't have any um like the prompt you have asked this data is not available okay with the help of agent actually you can uh use some SAR API and you can search over internet 4,800 and 32 as of now is high St High stack uh I didn't use high stack I can't say whether it's similar to langen or not but I used Lama index maybe raish because these are some more popular tool okay langin lamex people are using broadly okay so let me see the vector count okay 2,000 Moree what about you guys how much okay it would be done in some time yeah uh 6,34 and tomorrow guys we'll be doing the modular coding and the web app implementation so please join the session tomorrow so tomorrow we'll be completing these projects okay so today actually I'm showing you notebook experiment uh because many of you have familiar with notebook experiment okay so that's why now tomorrow I will try to like convert this notebook to the modular coding okay 720 it's done guys it's done great see it's done all right now what I need to do guys I need to um you can also perform some uh okay so uh now you can also do some centic starts okay now we have stored our Vector okay I already told you we'll be building one centic index here see we have built our knowledge base now uh we have also our centic index now we can see our rank results now if you give any query so it will give you some rank results okay now let's test this one so let's say here I'm giving one uh here I'm giving one question what is allergies okay now if you open this book okay if you open this book see allergies has been also written in this book let me show you now if I crl F and contrl V maybe allergy allergy yes it is somewhere see it has also written about allergies okay see allergy like what is is allergy and all so one question I'm just giving what is allergies here now it is searing your knowledge base okay and it will give you top uh similar three result okay top similar three results and that results actually I'm just printing let me show you see this is the top uh three results but it's not readable because I told you if you see that U architecture it will give you rank results but it's not readable okay the answer we are looking for it should be need clear it should be correct answer and to get this response actually I will take the help from my llm okay I will give this rank results to my llm and I will tell it this is my question and this is my answer this three top answer now give me the correct answer with respect to that okay now let's generate our correct answer with the help of our llm so for this uh this is the code you need to write first of all I will Define one prom template okay because you know what is prom template you are just telling your llm like you need to do this thing so if uh use the following piece of information to answer the question if you don't know the answer just say that you don't know don't try to make up the answer okay so I just want the authentic answer from my LM that's why I'm giving the prompt so user will give the uh context and question and it should reply the answer okay so this is the template I have written you can write any kinds of promp template it's up to you what is the distance is used perform similarity cosine Matrix justel now this is my prompt now here I'll be creating the prompt template okay you already know what is prompt template even I yesterday I was also discussing I'll be creating this prompt template this prompt template I have added here and I created The Prompt and this thing I have created as a chain type arguments because I will be using chain okay question uh uh like retable question answering chain okay that's why now let's load my llama model so here is my model in the model folder as you can see so here I'm just giving the path and I'm just loading the L model with the help of this C Transformer library and this is going to be my llm now let's execute done now what I will do I will create my question answering object now see retrieval question answer I think you know what is Ral question answer from langen and here I'm giving my llm as well as my prompt template as you can see we have implemented my prompt template and some of the arguments that means dock string doers what is this docer doers is nothing but your knowledge base which is nothing but my Vector DB U representation okay and here I'm just giving uh I'm just telling it will give you two relevant answer and from this two relevant answer you should give me the correct response okay now this is my question answer object now let's finally ask some question so this is one for loop I have written so it will take the input from the user then it will ask the question to my llm and llm will give me the response now let me execute and show you see this is the input so I'll just ask what is let me show you which question I'm I'll be asking so contrl F I'll be asking something related acne maybe acne is there see acne okay so acne is a screen problem I think you know see this is the acne so let's ask something related to the acne like what is acne and all about so I'll just say what is acne now let's ask this question so again U response time would be a little bit High because we are using U um like model on our CPU machine that's why and again I am doing live streaming so for me it would be a little bit late okay but if I stop the streaming so it would be quickly and tomorrow we'll be integrating the uh like front end part and you will see the beautification of this projects okay it would be amazing completely so for this live streaming actually I'm uh having some uh slow time maybe so anyone running is it running for you okay see done now this is the response guys I got acne is a common skin disease character ized by pimples on the face chest and back that occurs when the uh pores of the skin becomes clothed with the oil dead skin cells and bacteria is it correct is it correct response guys just give me give me a quick yes in the chat how is the project you can ask any kinds of question guys any kinds of question from this book just go through the book get some idea what are the disease what are the med medicine you have okay and you can ask the question I'm not a doctor sir even I'm not a doctor but I have this bot right now I can ask any kind of question so how was the session guys Al together did you learn the entire concept like how we can integrate all the technology together and implement this kinds of projects no no fine tuning is a different friend benit fine tuning will show in our paid courses it available okay this is the existing model we are using with our custom data okay now let me stop the execution uh tomorrow I will show you the further part uh uh it is enough for today I think yeah and this code would be available in my GitHub the link I have shared with you let me share it again so I'll just comment the code after the session so you'll get from here so this is the GitHub link guys everyone you can yeah now let me take some question where did you get the data data I downloaded from the internet this book I downloaded okay data I've already shared and please and doer CD pipeline upcoming classes we'll be adding uh we have a projects in our paid courses dependra we'll show that how much data we can give uh terabyte you can give as many as data but uh you should have good memory condition okay if you are like very less memory then uh you can't load so so much data so guys uh let's start with our uh medical chatbot implementation so yesterday I was discussing the architecture and the uh notebook experiment part uh today actually I will show you how we can convert this entire things to modular coding even uh I will also show you like how we can uh create the web application and all using flas so it should be U totally amazing so make sure you are watching this live till the end okay guys so before starting with the session uh first of all I want to show you um your all of the resources has been updated in your dashboard so let me open my dashboard once um so guys here is the dashboard and uh if you see today is day 13 so till day 12 actually it uh it has updated already so all the resources all the like GitHub link everything has been updated here so you can check from your end and guys uh if I disconnect somehow so no need to worry about just stay here I will uh again reconnect okay I have backup all right so everyone is ready can I get a quick yes from everyone so that I can start with the implementation so just give me a yes in the chat okay thank you all right so uh let me open my uh project actually I created yesterday so this is my project guys even I have already updated the code in my GitHub as you can see uh this notebook I implemented yesterday so this is already updated here even the data is already available and model actually I can't upload in my GitHub because it's a huge model so what I did actually I just given the instruction okay so this is the instruction I have given like how to download this particular model from this URL okay so first thing what I will do uh I will try to upgrade this uh readme file once because let's say if you are referring this uh GitHub okay if you're referring this repository so how we can set up this projects and all okay first of all I will just write uh some STS in the rme file then I will try to start with our implementation okay so let me open my project with my vs code and uh what I will do uh I will also show you uh on the neural lab as well because neural lab I was trying to upload the model but it was taking time uh for me okay because this model is hug so I'll will also show you side by side implementation how we can do it so what you just need to do here you just need to upload the model here in the model folder okay and all the steps will remain same all right so I have this model in my local machine so this is the model now what I will do first of all let me open my uh vs code here okay so everyone you can open up your vs code or you can also do it on the neural lab and if you don't have the code you just clone from my repository once okay so I hope my screen is visible properly everyone just confirm in the chat or should I zoom a little bit maybe it's fine okay just a minute uh okay so first of all let me write down the steps what you need to do to uh execute this project so I can remove these are the steps maybe yeah so the first thing you need to clone this particular repository so let me just add this part so first of all you need to clone the repository okay so here I have just given like till github.com so what you need to do you need to just clone this particular repository the repository I have created Okay click on the code and click on this link address then uh the second thing you just need to create one virtual environment so we have already created the environment and the name of the environment was here uh this is the name so medical chat boo so I just written M chatbot okay I'll copy this name and here I'll just upgrade okay and I was using python 3.8 version okay so when the projects will be available uh in Inon uh this project is already available okay in my GitHub Raven even Inon website it is also available you can check it out and today we'll be completing this project implementation okay entirely because yesterday I was doing the notebook exper experiment only then I need to active by uh environment here so this is the name after that okay internship project you are talking about so internship project should be updated also okay raan just uh check the internship portal it would be updated then uh I just need to install the requirements actually so yesterday I showed you I was installing some of the requirements so this is the command to install the requirements all right then what we did exactly we just created Pine con uh API key I think you remember so let me open my Pine con once so pinec con. let me loging with my account so I'm going to use the same index because we have already stored our data yesterday okay so I'll be using the same index only so this is my index guys medical chatbot I created so here I think you remember we collected the API Keys as well as our environment okay this Pine con environment so both I need to add otherwise this project won't be working so that thing I will also mention in the rme file so here I'm just telling create aemv file I will tell you what is this EnV file file okay how we'll be managing this uh secret key and all okay so this thing you need to pass in the environment file then it will work all right and the last thing I downloaded my model so this is the step to download my model so you just need to download this particular model from this URL and need to Pro uh like keep that model in the model folder okay for us actually we already kept the model all right so these are the steps actually we uh completed yesterday and rest of the thing actually I will show you today now let me commit the changes okay done now if I go to my GitHub and refresh the page yeah it is updated now let me share the link with you again so here's the link all right so the first thing actually uh what I need to do I need to create my project template because yesterday I completed the notebook experiment okay so most of the thing I will copy from my notebook only so this is my notebook so most of the code actually I'll be copy pasting from here and the thing is like I just need to uh create a modular coding pipeline okay so that is the main thing here like how we can organize our code so for this uh instead of creating the folder manually uh so what I will do I will just create a template file here so that template file I will just write some of the logic like what are the folders I need and how it would be created with the help of python then if I execute that particular template file it will automatically generate the folder for me okay now let's say if I want to create the folders and file now what I need to do I need to manually create it let's say I want a file I will click here again I will name the file then I need a folder here I will again click here then I will just uh name the folder name that's how I will be creating manually but let's see if you're doing the uh like the same projects again and again okay similar kinds of projects what you need to do again you need to create those are the files manually so instead of that what I will do I'll create one template file and that should be one time effort okay and I will I will just write all the logic there like how we can create I will be creating this folder structure and all so every time if you execute that file so it will automatically create the folder structure for you okay so for this let's create this file and I will name it as template template. pipe okay so here first of all let's let's import some of the library so I need the operating system then I also need something called path from path Le I'll tell you why this path leave is required just let me import it first of all so uh it should be everything from so from path Le import path then I also need something called login okay so the first thing I just need to create one logging string here okay why I need to create a loging string so let's say whenever you will execute that template. Pi file so it will also show you the log on the terminal like whether this folder has been created or not okay if it is if it is created now why it is created it will also show you the location as well okay so to log these are the information I need this login string okay I hope you already know what is logging in Python guys yes or no if you don't you can search on Google like logging in Python so logging is a inbuilt uh modu inside python so maybe you already worked with login so this is the documentation of login guys all right so if you visit the documentation so you will see these kinds of loging string people are writing okay this is the loging string we usually follow so here we usually mention first of all our logging level okay so here the log level is like information uh like level log so basically I just want to save my information like why this folder is creating what is the path so these are the information actually so that's why here I have given login. info okay and you just need to uh mention also the format format of the loging like what particular message actually it will show you so the first thing I'm just saving my asky time that means the current time stamp let's say I'm executing the code at this time so it will save that particular time with respect to the the message actually you will be writing okay so this is the loging string so it would be clear whenever I'll execute the code and I'll I'll tell you okay how this log would be saved now here I need some list of the file okay so let's create a variable and I will just name it as list of file list of files is equal to so let's make it as a list now here first of all I need uh One Source folder okay so I'll just name it as SRC so inside SRC I'll creating one Constructor so underscore uncore unit I'll tell you why this underscore uncore init _ Pi is needed as of now just uh create the folder with me and then I will be creating another uh like file called helper. Pi in the same folder so I'll copy the same thing again and it should be helper. Pi then again I will be creating another file inside that and I'll just name it as prompt prompt. Pi okay then I also need one uh file called envv then I also need uh something called setup. Pi because requirements we already created I don't need it so I'll just write setup.py then I also need something called U one resource folder because I'm going to keep this file inside a folder called resource so let's name it research slash and here I'm going to create that trial. ipnb all right then I also need something called app.py then uh I need another file called store index store uncore index. Pi I'll tell you why this IND store underscore index is required okay I'll tell you now I think most of the things I have created okay so I will also integrate the flask so for this actually you need one folder called Static uh static and another folder you need something called template. Pi sorry templates so inside templates I will be creating another file and I will just name it as uh chat. HTML yeah so these are the folders and file I need as of now if I need it so I'll uh create uh later on okay so as of now let's create these are the things only now I have already listed down the files and folder actually I'll be creating here okay now how to create it okay how to create it so for this we just need to write some of the logic here so I'll be using simple python code only to create this folder structure and all so the first thing I'll be looping through this list okay so I'll just write one for Loop so for file uh path in list of the file that means this list actually I'm iterating through then what I need to do first of all uh the file path actually I'm having so first of all I need to convert them to path I need to convert them to path okay why I'm converting them uh like to path because if you see here the operating system actually currently I'm using it's Windows okay Windows machine I'm using but here if you see I'm using forward slash so I think you already know in Windows machine actually we usually use something called backward slash yes or no guys backward slash if you see any kinds of Windows path it would be backward slash instead of forward slash okay but here we are using something called forward slash okay so forward slash we usually use uh in the Linux operating system and Mac operating system okay but in Windows we usually use backwards slash so that is why to uh prevent this kinds of issue okay I need this path Library okay now how this path will be working let me show you let me give one demo so here I will activate my python so let's import W uh maybe I can import this path so from path leap import path so let's define One path so I'll just write path equal to so here I can give let's say test uh let's I will give uh forward slash here and here I will give U app. pi so let's say this is my path now what I will do I will just give this path in my path class okay if I give it now see what will happen just see that it will automatically detect it's a Windows path okay first of all it will detect my uh operating system I I'm using okay with respect to that it will convert that path okay so this is the advantage to use this path class okay so what will happen now if you execute this code in the Linux operating system as well Mac operating system as well everywhere it will work because with with the help of this path class it will first of all detect the operating system then it will convert that part with respect to the operating system we are using okay so that's why we are using this path from the path Li itself all right now here I got my file path again so I'll just store it okay now here what I need to do I need to separate out my folders and file because as you can see here this is my folders okay and this is my files so I need to separate them because as you can see here I can't directly create my folders and file okay all together so what I need to do I need to separate my folders and I need to separate my files okay in a two variable then I will be creating that so for this what you can do so first of all I will store my file directory then I will instore my file name okay so there is a uh method inside operating system package so just write OS do path uh os. path. split okay so this is the method you can use and inside that you just need to give the file path okay now what will happen let me show you so let's say this is my path I have so I will import o again now what I will just do I'll just write uh first of all uh yeah w dot path do split okay and here I will give my path so let's say this is my path and now see what will happen see it is returning the folder separate and it is returning the file separate okay now what I can do I can create a two variables here you can see I can I have created two variables so the first variable will contain the folder name and the second variable will contain the file name okay so this is the logic actually I'm just trying to write all right so once I got my uh file directory and my file name now what I need to do okay I just need to create my file directory at the very first so for this I can write one logic so I'll just write if file directory if file directory is not empty okay is not empty so I can write like that is not empty so what I need to do I'll be creating the uh file directory so I'll just write w. make D okay so this is the method actually you can use to create any kinds of directory okay and here I'll just give my file directory name I want to create then after that I need to give one parameter called exist okay is equal to true so what will happen if this file is already available if this folder is already available in your computer so it won't be creating okay otherwise it will create so with the help of this parameter you can control this thing okay now if you're not giving it so what will happen it will replace that particular folder let's say in the particular folder you have some files okay again it will replace that so you need to recreate it again so that is why you need to give this method okay so once it is done I also need to log the information I'll just write login doino and here I can give one log so creating creating F uh directory creating directory uh first of all I'll give the folder name uh folder name so this is my file directory and after that for the folder for the uh for the file and here I will give my file name so this is my file name okay that's it now once my folder is uh done okay let's say I have created my folder now what I need to do I also need to create the file inside the folder okay so for this I need to write another logic so here uh what I can do yeah I'll again write one if statement if maybe intention is not correct just a minute yeah so if uh not o do path uh do exist this file path okay this file path that means the file path actually I'm having so if it is doesn't exist okay in my directory so what I need to do okay I need to create it but instead of using one particular logic I'll be using another particular logic I will also check the size of the file so what I can do I can write another logic here so W uh dot path dot uh there is a parameter you will get called G size if you want to check uh any particular size of any any file so you can use this method actually get size now inside get size you need to give the file name file name and that uh if it is not let's say uh if it is not let's say uh equal equal zero that means if this file is not empty so what I need to do I need to create that particular file so for this I'll just use with open with open and here I will give my file path okay and here I just need to create it so that's why I need to open with write mode okay once it is done I'll just do the pass operation here because I'm not doing anything I'm just only creating that particular file here okay then I also need to log the information so what I can do here I I'll just write login login. info login. info and here I will give the log so I can just write creating creating empty file and let's give the file name here file path yeah and if it is already exist so what I will do I'll just write else so I'll just give the log message here so login do info um here I can give uh this file file name is already um created okay so this is the message I think I can give yeah so this is the simple I have written so guys this code is understandable for you yes or no give me a confirmation in the chat are you getting this code how I have written it's a simple python code only yes okay great now let's execute this particular template file and see what happens okay now if you see left hand side I I don't have these are the files and folder okay now once I will execute this template. Pi let's see what will happen so I'll open my terminal I'll exit from my python uh first of all let me uh activate my environment I'll just write cond activate M chatbot now let's execute this template. Pi so template. Pi see see the magic guys automatically all the files and folder would be created left hand side just see left hand side and see the log guys it is saving my Tim stamp the current time stamp I'm executing the code as well as the date and it is giving you the message like directory created SRC for the file of uncore uh init.py again creating an empty file inside SRC uncore init.py okay that's how all the file and folder has been created and see left hand side guys we are able to create our folder structure uh in just one shot okay now let's see you need some other files and folder okay in future so what you need to do you just need to give the list here let's say I need something called test. Pi I'll just give test. Pi here I'll save this one again if I execute the same template. Pi uh okay so it is telling this system cannot find the specific Pi okay I'm getting one error let me see test. Pi has been cre or not okay static it is throwing the error okay static should not be empty so here I can give uh uh CSS or I can give U just dogit ignore dogit keep let me remove this static file here now let me execute it again okay it's throwing error just a minute um file name St size not o. get software line five get size return file not found the system cannot find the file specified underscore uncore unit. Pi maybe my logic is correct okay now it's done I think yeah now if you see uh my static folder has been also created now here if I uh just uncomment this test. PI right now and if I again execute it see guys it has created okay now see you can create as much as file and folder okay it's up to you okay so in this case I don't need this test. Pi I'll just remove it and here I will also remove the test.py from here all right so in future let's say if you're developing any kinds of projects instead of creating the folders and file manually what you can do you can create this particular template file and here just write the logic okay it would be one time effort but this file you can use it okay in your every projects just uh execute this particular file and it will automatically create the folder structure for you all right now let me move that trials file in my resarch folder so I'll just move it I'll just cut it in my resarch folder yeah uh everything is done now let me just comment the changes in my GitHub quickly folder structure add it so guys so far everything is clear you can let me know in the chat like how we have created the folder instuction and all so far everything is clear okay okay fine now we are done with our uh project template creation so now second thing I just need to write my setup. Pi file okay why I needed setup. Pi file because as you can see now we have created so many file inside the folder okay now let's say I want to import something from this particular file let's say help .p I have written something now let's say I want to import that thing inside my app.py okay so what I need to do I need to write from SRC do helper import something okay so if you want to do this kinds of operation then you need to set up this particular SRC file as my local package I think you already familiar with what is local package okay in Python let's say whenever you install any kinds of like package from the piy website okay it is already hosted on the pii website but uh it can be also done we can also create our local package as well okay let's say here if I do uh pep list pip list so it will list down all of the package actually I have installed in this projects okay but here if you see this SRC is missing okay SRC is missing so if I want to import something from the SRC then it will throw error it it will tell SRC is not found okay so to prevent these kinds of error what I need to do I need to create this setup. Pi file and I need to set up this SRC folder as my local package no this is not a preinstalled this thing I have installed from the requirement. txt I think you remember Iman okay because this is my new created environment and inside the environment I install all the package actually I need for this project all right but here if you see SRC is missing SRC is missing now let's say if I'm writing something inside help .p let's say if I Define anything let's say import OS uh let's say I will write one function here uh let let's say main function I have written and I'll just doing some pass operation now let's say I want to import this main method inside my app. Pi now what I need to do okay what I need to do I just need to import it first of all so from SRC so SRC is my folder SRC do help part okay then import main import main getting my point so if I want to import like that now see this SRC is not present inside my environment okay it's not present as a package envir environment so it will throw error like SRC module is not found got it but if you want to install this SRC as your local package and if you want to keep it inside your environment okay just to prevent the error you just need to write this setup. Pi so this thing actually we usually use in our end to end implementation always because we write a modular coding here all right so now let's write our uh setup. Pi so I'll open the setup do pi and this code is very common so I already written this code let me show you setup. Pi code uh see guys here you just need to use one particular package called setup tools okay setup tools is a prebuilt package inside python from here you need to import two particular things one is like find packages and other is like setup now you need to create one setup object here so see here I have created the setup objects here you can give your project name so in this case I creating Genera VI projects okay that's why I given generative projects you can also give something called medical chatboard let's give medical chatboard medical chatboard all right you can also specify the version okay version of the package you want to create so let's say this is the initial phase I'm implementing the project so that's why the version I have used 0.0.0 okay now here you can give the author name so let's say I here I have given my name you can also give your name so let me give my full full name here so I'll just write B ah Bui okay this is my name you can also give the author email address let's say here I have given my email address you can also give your email address now here you need to call this find packages this uh method so what it will do it will look for this Constructor file in each and every folder and where it will get this particular file that folder would be considered as my local package okay so this is the idea to create our local package okay so that's why we created this uncore init.py because I want to make this SRC folder as my local package and how it will get to know with the help of this find package method okay so this find package method it will find everywhere in every folder and it will look for this particular uncore uncore dop file wherever it is present it will create that particular folder as my local package clear guys this concept is clear yes or no you can let me know in the chat if yes just write clear in the chat so that I can get to know okay great now how to install the setup.py how to install the setup.py for this I will be utilizing my requirement. txt file okay I'll be utilizing my requirement. txt file so here I'll just write one particular line I'll just write hypen space Sorry hypen space dot okay hyen eace dot if you just write this particular line automatically whenever you will be set uping that requirement text it will look for that setup.py file okay then it will open that setup. Pi file then it will install everything got it so whenever it will install everything that means you have done the installation of the local package now let me show you so I'll open my terminal again I'll clear it now here I'll just write python sorry uh peep install peep install hypen R requirement. txt okay I already added that uh hypen eace dot uh yes hypen e space dot in my requirements now it will work see now setup. Pi has been installed now if you see there would be a folder automatically created called medical cho. EG info okay if it is generating this particular folder that means you are done with the installation okay and inside that you will have some of the metadata okay no need to worry about some metadata related of your package you have installed let's say these are the package you have installed okay as a local folder so these are the information it will save here all right now if I show you peep list now if I do peep list operation in my terminal that means I want to see what particular uh Library I have now here you will see SRC would be present I can show you SRC SRC would be present setup Tool uh not SRC it would be medical chatboard the name of the package I have installed called medical chatbot in the inside the medical chatbot I have this SRC folder right now okay see this medical chatbot was not present and see this package is coming from my local machine itself okay so that's why this is needed now if I want to import something from my helper I can easily do it without any kinds of error all right now let me uh push the changes in my GitHub but before that I will remove these are the line so I'll just write uh setup file added and I'll comp it so you can refresh my GitHub and you can go get the code from there now same thing you can do it on the numeral app so let me copy this template file and I will go to the Neal app and here I will create one uh template file template. Pi file let me Zoom a little bit now I'll paste the code here save now if I execute the template. P file here so python template. Pi file see it has automatically created okay the same thing you can perform on the Neal lab okay only you just need to upload the model here upload the model that thing you need to do all right now we have generated our folders and file and uh everything is working fine so far now let's add first of all our environment variable okay so what are the secret key and secret uh API will be using so everything I'll be mentioning here so in this case guys what I need I think you remember so I need something called my pine cone API key the first thing I need my Pine con API key okay and the second thing I need something called Pine con API environment so where I will get it I already collected yesterday I think you remember so I'll just open my notebook and here I think I already mentioned yeah so this is my API key I'll just copy and uh I'll open my environment variable uh environment file and here I will just paste it and I will also copy my API environment here I will paste it okay now what you can do you can remove it from here okay no need to show like to your user or let's say if you are uploading this thing on your GitHub account so just try to remove them from here okay otherwise people can also access your credential I'm just keeping it here just for the reference just to understand the things I'll just remove these are the uh index okay after the yeah same same yesterday key because I'm using the same same index same index from my Pine con okay that's why if you're creating any new index so you need to collect that particular keys and paste it here okay all right now see I have already added this EMV file okay I have already added this EMV file in my code but I already committed my code in my GitHub now can you see this EnV file in my GitHub is it present guys no see it will automatically ignored okay it will automatically ignore by the help of this dogit ignore file because if you open this dogit ignore file and here they have already written this kinds of EMV file would be automatically ignored okay let me show you so I think I can search here envv uh where is EnV crl F do EnV see guys Dov VNV EnV VNV these are the files and for would be automatically ignored during committing the code need our GitHub okay so that's why we use this method to create any kinds of secret uh credential okay another thing you can do you can open up your environment variable environment variable so it is already available inside your system now here you can click on the environment variable and here you can create a in uh variable key as well as the value you are using so both you can do it but this is the method actually people uh usually use nowadays okay instead of reading the uh configuration file file from our system itself okay yeah and to read this file I'll be using one particular Library okay so the library name is uh python. EnV let me just write um I think I already added this thing okay so there is a library called EnV dot e NV Pi Pi yeah so this is the package name I'll just copy and here I will mention inside my uh requirement file now let me install it again okay done now we have also added our confidential secret as well okay now what I need to do I'll be start implementing the component one by one right now so the first thing what I need need guys if I open my notebook I think you remember uh the first thing yesterday we did we first of all uh worked with our data injection part that means data component so I will copy the same function okay I'll just copy the same function and here I think we remember we created one helper Pi inside SRC I will open the SRC folder and here I will open this helper. pi and here I will just mention this particular function okay so most of the code I'll just copy paste from my notebook itself because we have already done the experiment and we saw everything is working fine now what is our task I just need to convert everything to the modular coding okay so this is the thing I'm just showing that's why yesterday I did The Notebook experiment and today I'm referring that particular notebook and I'm just writing the modular coding okay all right now I need this directory loader package and as well as this Pi PDF loader so I can copy from here only so directory and Pi PDF loader I'll copy this thing and here I will mention and let me select my environment I think it is already selected my medical Chat bar yeah done now tell me what is the second thing you need to add what is the second thing you need to add just open the notebook and try to see here the second thing I need to add my uh uh text splitter okay I think remember we are uh converting our conver like Corpus to chunks why I I was converting our Corpus to chunks because of the model input model input token limit limit okay so that's why I was creating this particular function okay so I'll copy this particular function as it is I'll open my helper. pi and here I'll mention it and again I need one particular Library recursive character text splitter again I will open my notebook and from here I will copy now guys tell me this method is easy for you are are you are you getting like confident to write the code how to write the modular coding after doing the notebook experiment yes or no because same code I'm just copy pasting from my notebook only and I'm just arranging my folder structure yes or no guys you can let me know in the chat great now going forward whenever you are implementing any kinds of projects as end to end the first thing create the project architecture create the project architecture then try to implement these are the component in your notebook at the very first then try to convert that notebook as the modular coding I'm doing all right now again let's open my uh trials. ipnb and see our third component okay so third component was nothing but uh downloading the model from the hugging face I will copy this function as it is and here I will mention it here I will mention it now what I need I need this hugging face embedding package so again I will open my trials. ipnb and from here I will copy this code copy this import and here I will paste it done now anything I need let me see after downloading embedding uh no everything is fine everything is fine now uh your Pine code Cod code will start okay that means you need to store your vector right now so this code I can write in a separate file I'll tell you how to organize this thing so first of all I showed you the helper function implementation okay so this uh this file should be my helper file yeah now I'll be using this helper file and I would I would be able to import this particular uh function one by one okay whenever I need it instead of writing again and again okay inside my component just follow the architecture and following the uh code okay one one by one okay great all right now let me show you uh how we can store the data again so so I'll I'll what I will do I'll just again remove this index from my pine cone let's instore our index again so what I will do uh I'll just remove this index so I'll just click here and I'll just delete this index you need to give the name so it's medical medical chatbot you can also load the existing index it is also possible but I'm showing because I have done the modular coding now I just want to test it whether everything is working fine or not whether it is able to create the index or not okay that is why I'm just creating this thing so now let me delete index now it would be deleted after sometimes yeah it has deleted all right now what I need to do I need to write uh the data uh that means my uh data push uh I mean uh Vector Pusher code okay that means I need to convert my uh Tes two vectors and I need to push them to my Vector DB that particular code I need to write so I'll be again referring the same notebook I think I yesterday I already wrote that code this is the code I was initializing my pine cone that then I was just sending my data to the Pine con okay so I'll be referring the same code so for this what I need to do uh I'll be using one particular file here called store index. Pi okay this file I'll be utilizing to push my Vector to the vector DB okay so here first of all what I need guys if I want to push my Vector to Vector DV first of all I need to load my PDF file from the folder itself so let me import so from SRC do help part import first of all I need what I need this load PDF okay this function so let's import load PDF okay after load PDF what I need I need this function text splitter so let's import text splitter then after that what I need I I need this download hugging face model okay so this one so I'll just also import hug download huging Face model okay then I also need to import something called uh pine cone so let me import so that's how you can import Pine con you can either import from Lang either import directly okay then I also need to import my load EnV package okay so I'll just write from from EnV from EnV import load EnV okay load. EnV because I want to read this particular file Dov file and here I have my credential okay primon credential and if you want to access these are the secret key you just need to take the help from this EMV package okay and this thing I have already installed here let me show you as a python. ENB I already installed here okay python. ENB so this is the package now let me open this one yeah now first of all I need to load my EMV file so that's how you can load uh so for this I also need something called operating system package so import OS now let me show you how it will read exactly so what I can do I can open this EnV file and I will copy the API key first of all and here I will restore it so equal to I'll just write OS do environment doget and here I need to give the key name okay the key name you are using inside the EMV file okay this is the key name okay now once you have loaded I will also load my second one which is nothing but my Pine con API environment I will copy and I will give the name here again I'll give the name here now let me print and let me show you whether it is able to read or not I'll just print first of all my Pine con API key as well as I'll also read my Pine con API environment now let me execute this particular file so I'll just write python store index uh. Pi it should work see guys uh this is my API and this is my en environment key got it how I'm reading it okay now I need to create again one index because I deleted my previous index what I will do again I will go to my pine cone and here I will uh first of all copy my key I'll copy my key and here I will paste it so this is my key I think this is the same key this is my key and I also need something called my environment so I'll again create one index so create index and here you can give the same name medical medical bot and dimension it's uh 384 I think you remember the model actually you are using sentence Transformer model uh the output dimension of the vector 3 uh 884 and I'm using cosine metric then I will create the index now this is my environment name I will copy and I'll paste it here which is nothing but gcp starter done okay now first of all what I need to do I need to load my PDF so let me load the PDF so here is the code I think I already written yeah this is the code I'll copy and here I'll paste first of all it will load the PDF and PDF is is present inside my data folder now after that I need to extract uh sorry I need to apply the text splitter that means I need to create a chunks so this is the code I'll copy and uh here I'll paste it okay after getting the chance I need to download the embedding so this is the code I'll copy and here I'll will paste it embedding download is also done now uh what I need to do I need to initialize my pine cone okay so this is the code I think remember how to initialize the pine cone it will take your Pine con API key which you are getting from the environment variable and this is your Pine con uh API environment okay we have initialize the pine cone and now how to store the data so this is the code okay I'll copy the same code from my notebook this is the code so so here I'm using pine con. from text here I'm giving my text chunks and also need to mention my index name so index name is my nothing but my medical chat Bo so I'll copy the index name this is the index name done now it will uh convert your data to embeddings and it will store to the pine cone okay maybe that's it yeah now let me execute this file and show you whether it is able to uh push my data or not so I'll execute this particular file I'll clear and I will execute this particular file python store index dop so again it will take some time because how many chks we have guys yesterday you saw remember anyone remember remember the Chang size how many Chang size we use uh pushed yesterday in our Pine con database uh yeah 7020 7020 right no no it's 7 not 700 7020 7,20 20 chunks we had okay okay okay great now it will take some time first of all it will uh load the data then it will create the chunks after after that uh it will uh convert everything to the embeddings then it will push to my Pine con let me see it has started or not let me refresh the page not started yet let's wait for some times in between I will take some queries guys if you have some query you can ask me anyone having any query you can ask me in between okay uh should start huh see it started guys okay now it has pushed 576 vectors can we use this same projects template for creating Finance related project as well yes right side you can use it no issue G push error where is G push Adder maybe this is your problem with your git AR is you can check it uh no wores I will push my code you can get from there okay Karan Karan sorry Karan uh uh you can also use this template for your Finance related project as well okay this is the common template you can use it as it is uh when we are creating medical B Medical book chatbot uh will it response to the normal message like hello and how are you uh yes it can answer maybe yeah it can answer because you are using the Preen llm now so yeah it will answer I'll show you and if you want you can also uh like fine tune that particular model as well it is also possible okay and uh in our paid courses we have already integrated guys if you don't know so this is our paid version of this gentic B course so in this syllabus we have added so many topics let's say if you want to learn how to F tune and all everything we have added here even Lama index then uh we we'll be also covering like some more Vector DB okay we have some more interesting project here so everything would be covered detail here okay so if you are interested you can enroll for the course let me see the progress okay 2,680 it's taking too much time to give answer of any questions is my system I got response 6 Minute for this uh for allergies Anu what is your system configuration you can let me know because for me I'm using 16 GB RAM and code i7 processor uh yeah so if you want to uh decrease the response time so what you can do guys let me show you so I think I already showed you the model right so this is the model link so here I was using 4bit model maybe 2 bit model is also available let me see 4bit 4bit 8 bit 6bit huh 2 bit model is also aailable can you see Q2 kin you can uh download this particular model so this is the smallest version of the model and you can see the size so those who are having 8 GB of RAM and the Codi 5 processor you can go with this particular model um a 2 bit model OKAY in this case actually I'm using 4bit model you can see I'm using 4bit model Q4 yes definitely you need it uh you can also execute on the Neal LA but I'm not able to do because it's taking so much time for me to upload the model here okay so what you can do you can start uploading the model once this model is uploaded you can uh write the same code here also because Neal laab will provide more Rams and all if you are having less RAM and you can also do do it on the Google collab as well but flas code won't be running there you can only do the experiment part The Notebook experiment we did yesterday so these are the alternative you can follow I think uh you can see guys uh one thing actually you can do after the session those who are having low configuration PC you can go with this model two bit model no see here you don't use any pkl file okay ANUK it's a uh hello everyone am I audible uh give give me a confirmation guys am I audible to all of you okay sorry actually my system got hang and I got disconnected uh sorry sorry sorry because like too many software I opened that's why my OBS Studio got hang okay and I got disconnected connection was fine today okay there is no issue with the connection because live streaming like uh it takes little bit yeah okay fine so maybe my this thing has also stopped let me again do it okay now I think again it will start yeah so what I was talking about about I was talking about uh if you are having let's say less memory so what you can do in this case you can use this uh eight uh two bit model guys okay two bit model from the from here okay now maybe uh it is running okay let's store till this point I will stop the execution so let's say I have already stored my Vector so let's store till 5,728 okay so you can complete the uh like this Vector upload operation um until it gets over okay till your 720 fine now let me push the code so I'll quickly push the code so uh store store index edit now I think you will able to see the code or maybe I can what I can do um um whenever I'm implementing this thing so in between I can start my progress I'll upload all the data again just a minute or let's keep it let's let's try it if it is not giving correct response then I will again store it and guys uh if you don't know actually there is a webinar of the generative AI uh you don't know U or not let me show you so there is the webar guys so it would be happened this is the date so let me share the registration link as well so please join this webinar guys so Krish S and sudans S would be there so they will be discussing so many things about generative AI so this is the uh link I can give you so this is the webinar link so let me open this one so you can register here you can uh give your name email address mobile number and which state you are from and you can submit the form and here is the video you can go through all right okay now let's complete the project guys because we are almost done now what I need to do we have completed our store index okay now we are able to store our Vector to our Vector database now what I need to add I need to add my uh app component okay because I need to uh create my front end right now so for this actually what I need to do um just a minute uh yes so so I just need to uh first of all give the prompt here so I think you remember we created one prompt. Pi here so let me open this file and yesterday I prepared one prompt here so let me show you the notebook so here is the prompt I will copy this prompt as it is and in the prompt. pi I will add this one okay now what will happen actually U you don't need to directly write the prompt inside your code so instead of that what you can do you can mention it like that okay so it would be pretty much good for you now once it is done I will open my app.py and I will uh write the rest of the code here so I'll just copy paste the same code I created so inside app.py first of all let me import flask so from uh flask I need to import plusk then I also need something called render template I will tell you why you need random template why you need flask okay everything I'll be discussing about yeah now I also need something called Joni as of now let's import only Joni and I also need something called request okay then uh here I also need to load my uh embedding okay so for this I also need to import this embedding my download embedding uh method we created then I also need to initialize my pine cone because I will be loading that particular index and I will be extracting my Vector from there so that's why I need I need this particular Pine con package here then I think you remember yesterday I was importing some more things let me show you uh where is The Notebook let me open the notebook again uh this is the notebook and let me close these at the tab first of all template I don't need uh store index I don't need as of now helper I don't need okay here here is The Notebook so here if you see I was importing some of the more Library called question answer then C Transformer Ral question U and prom template okay so this thing I need to Al import here because I need to create my Ral question answer object okay to chat with my llm so let me import them so here is the code now I also need myv because I need to load my secret credential from that file then I need to also load my prompt okay this promp template so what I can do okay so maybe it should be hugging face sorry I deleted by mistake yeah now I also need to import this prompt template from my prompt so what I can do I can just write from uh SRC do prompt import Star okay that means whatever things actually I have inside this prom. Pi everything just try to import here okay now after that uh I also need something called operating system package so I'll just use uh import o now at the very first I just need to initialize my flask so app equal to uh how many of you are familiar with flask guys here have you ever worked with flask like how flask Works how we usually create the app with the flask and all if you have some like little little knowledge on this flask I think this should be pretty much Clear how I'm creating this application frontend application you can let me know guys in the chat anyone uh worked with flask before I think if if you have already worked with with machine learning deep learning so I think you know this flask little bit no not okay so no issue I will explain okay it's like very easy so flask is a like framework in Python it will give you uh the functionality to create the web application here okay yes and no need to worry about the like HTML code and CSS code that code you can copy paste from the website itself I will show you some of the website even I copy pasted the HTML and CSS code from the website itself okay because I also don't know like how to code in HTML and CSS no need to worry about so we usually Define the flask object like that now what I need to do I need to load my uh API environment so what I can do I can open the store index and this code I can copy and I'll paste it here then first of all I will load my embedding model okay okay now what I need to do I need to initialize my pine cone so I think you remember how to initialize the pine cone so here is the code initializing the pine con so let initialize our Pine con and it will take your Pine con API and pine con API environment so it is I'm reading already from here now here you need to give the index name so here this is my index name I'll copy and here I will give my index name done now if you have any existing index okay in your Pine con let's say you already have the index present and you already have the vector there so what you can do instead of creating it again because we have already executed our store index. pi and we have already stored our Vector there now I just need to load that I just need to load that and I will be using that okay so for this this is the particular code you can use load index from the pine con see Pine con do from existing index here you need to give the index name in this case this is my index name and this is the embedding model I'm using this two parameter you need to give okay once it is done you need to copy the same code yesterday you wrote here you need to create the prom template I think remember you need to create the promt template then you need to initialize your llm so now let's do it I will open my app.py and here is the code here is the code so this is my prom template and I'm just reading my prom template from where guys from prom. PI I think you remember because we have already imported this thing inside my app. Pi here okay now this is my prompt it is coming from here and this is the input variable user will give the question and it will return me the response and this is my model what is my model model is present inside the model folder and this is the location of the model model type is llama maximum new tokens it is uh just keep this default number and temperature I'm setting to uh 0.8 that means I'm just taking the risk and I'm taking also Randomness so whenever it will give me some response it will also take the risk and Randomness then it will give me the response so once I got this thing I need to initialize my QA bot that means QA object so this is the Code retrieval QA from chain type and here you need to initialize your llm chain type stuff and this is the doc uh Dockers so doers I'm getting from here my Pine con object that's it now you need to create the default route first of all of your flask so this is the default route I can create like that so here you need to in uh like give this decorator called app. route and if user is open your uh let's say host okay or let's say the URL you will be getting I will execute and tell you how this thing will work so it will open one particular HTML file which is present inside template do uh which is present inside template folder the name of the file is chat. HTML okay so here I need to write the HTML code as of now this file is empty but I need to write the HTML code like how your eyi will look like this particular code you need to mention here okay now let me show you how this thing will work so now I will initialize my flask so it will uh execute your code here now let's say inside the chat. HTML I can copy some basic HTML code welcome HTML page I can copy the code from here maybe example so this is the code I think I can copy let's see what is this page I'll paste it here then I will run run my app.py python app.py now it will tell you just open up your local host and port number 5,000 let's open my Local Host so Local Host port number 5,000 it's running on port number 5,000 uh see guys this is the screen I'm getting from this code itself so now we can also change the code now let's give this code uh let's give this HTML code what happens if you know HTML and CSS so you can create a beautiful website it's up to you now if I again refresh see guys coming soon I'm getting that means my web app is working fine and I got one API okay I got one API this is the API guys my uh like project is running on this uh host and Port okay this is the host and this is the port you can also change it so what you can do here you can give host uh host is equal to host is equal to uh you can give like that 0 point 0.0 uh zero and Port is equal to you can give let's say 8080 any kinds of Port you can mention let's give 80 80 now if I stop the execution again now if I again uh rerun my app. Pi you will see it will run on port number 8080 right now see guys it's running on port number 8080 now I'll give the permission now if I open and here I will give my port number 8080 now see guys your application is running here got it now here what you can do you can visit this website called bootstrap bootstrap uh sorry it should be bootstrap bootstrap so this is the website we usually copy any kinds of template so here I created one chatbot template so here is the example so in the example you will see lots of example would be there any kinds of template you can copy from here it will uh give you the HTML and CSS code with respect to that either what you can do you can search for chatbot HML and CSS template free okay so there are some website it will give you some of the template you can just download from here see this this kinds of chatbot actually templ template you will get so you can download it and it's completely free you don't need to pay for anything if we have to put this on any website uh then where we need to provide the details no see the same thing you can do the deployment okay I think you saw how we we we usually do the deployment on AWS so that time it will run on the AWS URL okay not in the Local Host we'll show the deployment Vic okay in our paid courses it already designed see these kinds of chatbot template actually will get okay so what I have done actually I already downloaded one particular template and I already copy pasted the HTML code let me show you how it will look like so this is the code and you don't need to worry about for the HTML code so this thing actually you can download from the internet if you don't know anything so this is the HTML code from the chatbot I'm using and with respect to that you have one uh CSS file as well so the name of the CSS file is style let me write style. CSS so let me show you the style. CSS so this is the CSS code okay so from that uh website you can download this particular thing now if I go to my website right now and if I refresh now see that's how my chat bot look like isn't it uh B beautiful app guys tell me uh how this template look like to all of you because I personally like this template uh actually I just copy paste the code from the Google itself so here you can give your input message and it will give you the response yes I will give the code no issue let me just comit the code as well so what I can do I can give templates added so this is the medical uh chatbot kinds of Bot I have added uh yeah so now see how to change the photo of this one so here is the like one Nar photo I have added how we can do it you can open the HTML code so here you will get one jpz file see guys this is the jpz file PNG file okay so this is the URL of the photo actually so what I did I searched the photo in Google and I just collected the image URL see copy the image address if you copy it now see you can use any of chatbot medical medical medical logo you can open and you can copy any kinds of photo URL and you can paste it here so that photo will appear here actually let me show you that photo will appear here uh yes you can use this code okay I already uh committed the codee in my GitHub you can uh clone from here you can copy this template as it is guys okay no need to worry about how to write this thing because this thing is already available on the internet okay if you look for lots of template people are giving free these are the free template you can use it as it is okay all right now we'll be writing our final route so basically I'll be taking the question uh yeah and and see guys if uh you can enroll for the courses and you can get everything for free because we have lots of template as well okay we'll also give that rebuild template okay now let's write our final uh route so this is the final route so here what I'm doing guys so whenever user is giving any kinds of masses okay so here whenever user is giving any kinds of masses I'm just taking the masses in the back as you can see I'm just writing request. form and it will give you the message and this message will come here then I'm saving the message to the input variable and I'm also printing in my terminal after that I'm just sending this input to the QA QA object okay because QA object we have already defined here okay then it will give you the response that particular response I'm printing in my terminal as well and as well as I'm also sending that particular response to my UI here okay now let me uh let me show you how it is working or not so what I will do I will stop the execution again I will clear the terminal and again let's execute my app.py sorry python it should be python app.py okay it's running now let's go back and refresh the page again uh I think I can open it again so Local Host port number 8080 see now let's ask some questions so here I can give uh what is acne so the same question I asked yesterday and let's see see I asked the question now uh it will take some time because I'm uh doing the live streaming and all so it will take some time to give me the response okay but if I stop the streaming so it will give me quick response and the same thing we can do it on the neural app so let me show you um so what I will do I will copy this HTML and CSS code uh let's copy this HTML code and open my Neal LA and here I can give this here also I need this static so inside I have style. CSS now let's copy the code done now let's uh write the route here and uh this is the final code Pyon app.py okay it's running now so now what you need to do you need to copy this URL and what is the port it is using uh let me see it again it's 5,000 okay just paste it and give the port is equal to 5,000 uh okay bad request it's telling I don't know because maybe my uh okay I got discon Ed maybe that's why okay I need to again rerun it let me see the execution here see guys it's giving me the response is it correct acne is the common skin disease characterized by pimples on the face chest and back it occurs when the uh porous of the skin becomes clogged with the well dead skin cells and bacteria see the guys eyi it is also extracting the time the current time actually you are asking the question is it great guys now you can ask any G of question here it's up to you why it's giving bad request let me Che everything is good okay I got the response see I think uh who has asked the question if I give any casual message whether it would be able to answer or not see I've given hello I happy to help however I don't have any access to the external information or context beyond what is provided uh the text you gave me without more information I can provide the definitive answer or to your question can you please provide the more context to clarify your question got it so basically here is uh the chatbot we have implemented this is already dependent upon my custom data I have given okay so here I haven't given any external data sources okay so this is only relying on this PDF file okay so that's why it's giving some warning before starting with the conversation got it now you can open this book you can open this book and you can ask any kinds of questions so let's ask another question so I'll find one dis is here evention not this one I'll take let's copy this disease okay I don't know what is this let me search on Google first of all okay this is a medicine actually so let's ask about the medicine so this is my bot tell me about this medicine so anyone is running with me guys anyone here everything is working so you can go through this book and you can ask different different question different different medicine like uh for this disease what would be the diagnosis okay everything you can ask here and make sure you are uh storing all the vectors because I already stored 5,000 something Vector here so make sure you are storing all the 700 uh 7,000 and20 all the victory here still running because my live streaming is going on that's why a little bit slow okay this is the response see this is used to rely many kinds of minor ax and pains include headache muscles ax back ax and tooth X so see this is one kinds of medicine actually people use for the pain okay now you can see also this medicine this is the medicine now tell me guys how is this project you like this project the medical chatbot your custom medical chatboard yes or no because we are done with the implementation how is this project guys you can let me know in the chat all right okay thank you thank you guys so you can try and uh those who are having uh less configuration you can use the 2bit model okay I already showed you the sources and uh please implement this particular project guys those who haven't implemented and you can tag me on LinkedIn so this is my LinkedIn profile guys so here you can also tag me after the implementation uh you can also tag ion so we'll be happy to see that like you have implemented something okay can I add this project in my resume yes vikash you can add it because this a good use cases okay in the generative AI uh like field you can add this project and please implement the project guys please implement this project let me commit the code as well and let me write down the further steps to run this project so let me complete the readme as well so first uh first of all you need to execute that stored index. Pi because you need to store your index first of all then after that you need to execute app.py okay then you need to open up your local host and Port then I can mention the take stack I used in this project now let me comit them done okay so guys yes this was our medical uh chatbot implementation and I have showed you the entire uh like process sir may I know prerequisite for this course please uh no need any prerequisite okay uh you can still uh still join the course if you don't know anything so we'll give all the idea and guys uh there is uh exciting news for everyone we are also coming with mlof session okay on this uh Monday from this Monday so please join the session those who are interested in mlops so you can join here and if you are interested in Hindi so in our Hindi Channel also uh this medical chatbot implementation will come so it will take by Sun sir so you can join uh today okay see you can uh just notify click on the notify button deep planning and machine learning fails under the data science uh yes this is under the data science yeah and guys yeah you can mention this project in your resume there is no issue with that because this is a good use cases yeah so MLF session actually it would be conducted on our this Inon Channel okay so here actually you will get the MLF session and uh the detail of this MLF course would be shared soon okay just stay tuned with our Channel everything would be shared here no this is not a last session maybe couple of session would be there after that small uh language model is different uh t0 llm small mod small language model is different t0 llm I didn't got your question uh okay so uh sorry guys so there uh today's the last last session of our generative AI okay because we have already covered everything okay we have already covered everything if you go here if you go to the live section so from the day one itself uh see uh from the introduction itself itself actually everything has been covered Lang chain covered Hing face covered openi covered uh n2n project has been also covered then Vector database covered then uh yeah open source llm is also covered then I also showed you the how use uh how to use open source llm and create the Inn project as well and uh and if you want to learn more about generative so that is a paid version of our course so there actually we have added so many things so let me again show you so this is the page guys so let me share you the link so if you are interested you can enroll for the course and here we have already covered uh we we'll be we'll be covering lots of things here let's say fine tuning llms and all so you can visit the syllabus here okay it's a big syllabus guys metal Lama API is free to use or paid like open meta Lama there is no Lama API okay we have downloaded the model because so link is uh in the chat guys so you can visit this courses you can go through the cabus and you can enroll for the course and uh why this course would be like more uh you can say interesting because we are also giving the job assistant if you see here if you go uh read this description and all about so it is starting from uh 20th January and uh this course version is English okay and duration is 5 month it would be conducted uh 10 to 1 p.m. okay IST Saturday and Sunday and this should be live course okay this should be live lecture actually and we'll be also providing the job assistant doubt clearing session okay so each and everything would be there so let's say if you having any issue okay with your like resume and all job and all so we'll be like conducting a session with you so we'll also build your resume we'll give you the carer advice okay everything would be done here is this course curriculum changes on a new model uh see if you go through the course we have added so many open source llm here also new model as well okay we have added f con Google Pam okay so we have also added this thing as of now you learn like Lama 2 model okay but there are also lots of Open Source model available let me show you if I search for open llm okay maybe I already showed you list of open llm so there are lots of llm there are lots of llm you can use so we'll be covering them also here and see guys uh here you you will get like one year dashboard access and uh assessment uh in all the modules okay you will be getting assessment for all the module and guidance by the expert and mentors as I already told you if you are having any issue with your career and all if you're not getting any jobs so we'll be giving the job assistant uh like opportunity as well then course resources definitely will get then live lecture okay like live lecture you will get from here and quizzes and assignment you will be getting from each and every lecture okay then you'll be getting free neural lab access as well so we'll also show like how we can use our neural lab efficiently here because many of you are having less configuration machine okay so we'll also show you like how we can use neurolab here as well then uh here you will get dedicated Community Support promise I'm in this course duration is 5 month so in a 5 month jna is boosting so much okay so we'll be taking care that yes so let's say in this five uh five month actually if any changes is there if any new thing is coming we'll also Showcase in front of you okay we'll also tell you that thing no issue with that yes we'll also integrate mlop Tool uh like we'll also show like how to integrate Docker this thing how to do cicd deployment everything will show there okay the efficient deployment process will show there and guys this course is uh also for students and working professional as well even if you are an enterpreneur okay who are looking for uh using this latest AI technology in your daytoday business okay so for you also you can refer this course okay so this course is for everyone if you are a student if you are job professional if you are let's say enterpreneur anyone can refer this course we'll be covering each and everything in the field of generative High guys okay after leing this course you will become a champion in the field of Genera VI this is the like guarantee I can give see building llm uh we don't do it usually okay building llm is not a easy easy task power okay see llm building is not a easy task for this you need resources you need cost you need a good configuration machine okay because we have already llm okay now we just need to use them we can fine tune them fine tuning we will show like how to fine tune on the custom data if this uh llm is not working for your specific task you can still fine tune that okay and guys please join this webinar everyone so there is the webinar actually conducted by creation sudans s so here is the link we have already given let me share it again please register uh of yourself here and please join the this uh uh like webinar okay so you'll be learning a lot lot from here and here's the video guys so what are the things actually he'll be covering and all so you can go through this particular video it is already available in our Inon Channel guys now if you are having any doubt you can ask me in the chat I'll be taking couple of Doubt then I will be ending the session any any doubt guys any question you you are having you can ask me then I will end the session so guys uh so far how was your session guys uh are you able to learn something in the field of generate because we have covered so many things like it's completely free even you won't be getting these kinds of content anywhere Jin if it is there okay if they already post the API and all okay we'll be also covering JY okay no need to worry about because this is the recent research uh recently it has came to the market okay they haven't announced so like yet yeah thank you thank you Karan and thank you for your contribution yesterday also yeah thank you thank you power also and if you have any query you can ask us anytime no issue okay perfect guys so let me talk about the agenda today okay now uh many people have been talking about generative AI they've been talking about open AI llm models they're talking about open source llm models like lama lama 2 you have mistol you have lot of different different models and every day probably someone is coming up with some good llm models right but when I talk about Google right Google recently came up with something called as gini right and uh it after seeing a lot of practical application after implementing multiple things uh I could see that it really have a lot of capabilities so that is the reason why I'm keeping this entire dedicated session specifically for gini and just to make you understand today what all things we are specifically going to do I'm going to write down the agenda what all things we are basically going to do today right so let me just share my screen and let me know whether you are able to see my screen or not okay just a second so just let me know whether you are able to see my screen just give me a quick confirmation just a second uh my face is not visible why I just try to change things okay so everybody's able to see my screen so which view do you like better this view or this View this view is different which view this view I hope everybody likes it better okay yeah visible so I'm going to basically talk about the agenda and uh so first of all we'll understand about what this Google gin llm model is all about okay so we'll understand this we also say this as multimodel okay why do we say it as multimodel we'll try to understand this multimodel um why it is good with respect to vision and all that also we'll try to discuss okay the second thing is that we'll try to see a practical demo so we'll try to see a practical demo using Google giny okay we'll try to see a practical demo using Google Jin Pro okay why Google G Pro right now Google has just provided this it also has huge capab abilities and with the help of this you can actually Implement both Text Plus Vision use cases okay so you'll be able to use both of them third thing after this we'll try to create an end to endend project okay and we'll try to see this end to end project ug Google gmany pro okay so we'll do all these things in this session we'll have a couple of hours session we'll discuss step by step what all things we are basically going to do and considering this we going to discuss more about this in terms of practical implementation okay um till now I think Google gini also like Google did not I don't know about his research paper that much information is not available but a kind of brief idea you can actually get it what exactly Google Gemini does okay so everybody clear with the agenda so please hit like if you are liking this video I really want people to be very much interactive right now okay uh because end to endend project everything I'll be explaining trust me at the end of the Days end of this session you will learn amazing things as you go ahead you know and you'll get an idea like how powerful this is and uh with respect to text and vision use cases this will be super amazing okay so hit like and yes share with all the friends out there if you have some of the friends who are interested in this things right so definitely do make sure that you ping them right and uh over there also you can actually do it okay so in insta also we are live so again for all the guys out there in insta and in Twitter so we are live in four to five platforms right now so please let me know like how whether you're able to hear me or not okay but all these things we are going to discuss so Mohammad mozak says hi Chris you're my role model and I follow your videos I'm currently working as an AI engineer UA Dubai amazing amazing congratulation uh mazak congrat I hope I'm pronouncing it right okay so let's go ahead and let's further discuss about the Google Gemini llm model and why it is so good uh you have to keep on motivating me to take more and more more and more right so definitely do hit like keep on putting up your questions I'll take up all the questions as once the session completes and if there is some important thing that I really need to answer it I'll answer in between the session okay so just give me a quick yes if you have understood the agenda what all things we are going to do in this session yeah I hope everybody's got this clear idea yeah everyone a quick yes thumbs up something okay agenda is very much Clear we'll understand about Google giny we'll see some demo then we'll do practical demo we'll see how we can set up the API keys and all and all these things okay great so let's go first of all you need to know about from where we are basically teaching okay so here is the entire in neuron platform uh if you don't know about in neuron for the people who do not know about Inon we do come up with a lot of different courses data plus web development every coures as such and if you're interested in learning any of the course from us okay you can see you can just go ahead with ion. just go and see different different courses over here like generative AI course we are coming up from this Jan then we have machine learning boot camp uh both English and Hindi and if I talk about data analytics boot camp and mlops production ready project so these are the four uh four important courses that we are specifically coming up with okay so mlops production ready projects data analytics boot camp machine learning boot camp and finally generative AI so if you are really interested to learn from us you can go ahead and check out all the courses okay um the other thing is that in this um if you do not have a a very powerful system what we will do also is that you can actually use neurolab okay because today I'm also going to show you the Practical implementation with the help of neurolab what we will do is that we will try to create our own environment over here you can probably do the coding that you specifically want okay so it it gives you a entire working development environment where you can write your code and this all code will be running in the cloud so if you do not have a powerful system I would suggest go ahead and check out about the neural laab itself it is very much simple go to ion. click on neurolab and start working on this because at the end of the day when I'm showing you practical implementation we may be doing in this okay perfect so welcome to the Gin era so I let me talk about the story because initially people made a lot of fun about uh you know Google uh because of the demo that was put up regarding gini Pro okay and I hope many of you have heard about this so gini's built from ground up for multimodality reasoning seamless across test images videos audios and code and this was a demo that they had actually put and I hope uh you have seen this demo right I think they should have removed this demo so this was the demo that they had actually put okay and this demo was not that true okay it was just like taking images by image frame and then probably combining and doing all these things okay but at the end of the day many people made fun of it you know uh they came up with something amazing and this was what they had the first impression wow this looks quite amazing it can probably do any kind of task you ask it map it will tell you about map it if you ask about any object it will tell you about that particular object like that right so still it is not that powerful right now okay considering the kind of demo they had actually shown but the most important thing that we really need to understand why we should think right this Gemini is an amazing model it can probably be the future of llms okay first of all whenever we talk about multimodality okay multimodality so here when we say multimodality okay so here one example you can see that it is being able to do the reasoning seamlessly across text images video audio and code okay recently if you probably talk about open AI gp4 model right now it has come combined everything di it has combined uh for the data analysis part also it has combined that code interpretor functionalities and all right and recently it was launched and over there you can probably do tasks that are related to images that are related to text okay here in gini when we see right you are able to combine everything text images videos audios and code today I will show you a lot of example with respect to text and images okay we'll see some amazing use cases you can also do it with the the help of PDF you can do with multiple things as such okay and all the task that are related to NLP like chat with your PDF and all you can also do with this now the most important thing why gini is the most capable AI model that is because of this result okay now see here you can see something called as human expert MML now what is this mmu okay if you probably search for what exactly is MML okay mlu if you see that it is nothing but massive massive multitask language understanding so with respect to humans right it is basically able to say that over here it has achieved see Gemini is the first model to outperform human experts on mlu massive multitask language understanding one of the most popular method to test the knowledge and problems solving abilities of AI and here it is also said that it has crossed the crossed the Benchmark of GPT 4 also right so if you probably see this see understand Guys these all are very important things to understand because benchmarking is done on which thing that you really need to get an idea about and because of this benchmarking you will get a clear idea and you can assume how good this specific model is and any model so tomorrow if you probably talking about Lama 2 if you're talking about Mistral it will be benchmarking based on this capabilities so if you probably want to work in the field of generative AI I think this benchmarking is super important and you should learn about this okay or get an idea about it because tomorrow if you're reading a research paper how can you say that this model is better than the other model okay so here you can can probably see in mlu it is nothing but representation of questions in 57 subjects right it has been able to get this accuracy 90% gp4 it was somewhere around 86.4 then in case of reasoning you can see some results where it was greater than GPT in two different things like in big bench hard drop in h Swag like in common sense reasoning for everyday everyday task it did not achieve that much accuracy when compared to gp4 Okay so the reason see I'm telling you why all these things you should know because you should get an idea about it okay the other thing is that with respect to ma maths right basic arithmetic manipulation final grade school math problem it was able to uh get a good accuracy of 90 4.4 but when you had challenging math problem it is not able to get that much accuracy right somewhere around 53.2 but it is far more better than gp4 gp4 was able to get somewhere around 52.9 okay similarly with respect to the code evaluation here you can also see that it has crossed this gp4 like python code generation python code generation new heldout data set human eval like not leaked on the web right so completely a new generated code right so in short it says that and this is completely from the research right gini surises the state of art performance on the range of multimodel benchmarks so you are getting this specific information and there are other information see this is something related to text okay this is something related to text now here if you go down it is something related to multimodel now whenever I say multimodel what does that mean it is basically talking with respect to images with respect to video with respect to audio and here also you can see that it has proven well with respect to all the Benchmark when compared to GPT 4V right so here you can see 59.4 4 77.8 82.3 90.9 80.3 53.0 and here you can see all the other readings right if you want to read the technical report here you can probably go ahead and read it entirely okay it will be talking about how it has basically done the fine tuning and all and all and all it's just like a research paper like why it is basically said as a so here you can probably see here is a solution of a physics Problem by a student uh the information is given over here that it was not able to get the answer whether the answer is correct or not all the information clearly you able to see right again it is based on Transformer only encoder decoder so that is the reason right why I say in the road map of generative AI if you want to learn something you really need to have a good base about Transformer and BT right if you understand what is encoder decoder how it works right then definitely all the further things you'll also be able to understand it right so guys till here everybody's clear right now we'll talk about what all different sizes are there and which model is available for us so if everything is clear please do hit like if you're able to hear me out and all so uh shini says sir what is the difference between B and gin see B like how we have chat GPT application similarly we have Google B in Google B in the back end we used to use pal to right now they can change Palm to Gemini right where it will also support images and text it's all together an application so can I get a quick yes if you able to understand yes something quick yes come on guys I should be able to hear I think there's a less energy over there come on let's let's make this session amazing see my main aim is to make this session a good one for you right you should be able to understand things your Basics fundamental should be strong tomorrow when whatever model you should see you should be able to understand so hit like okay hit like hit something give a smiley I'll feel happy more energy will come when I'm explaining because we also need to do end to end project right now okay now um so one question is that how to generate image data using Gemini still those features have not been exposed completely we'll talk about what all features it specifically have okay don't worry okay we'll be discussing about now Gemini comes in three sizes one is ultra our most capable and largest model for high complex task one is pro our best model for scaling around a wide range of task okay and the Nano part which is our most efficient model for on device Tas so if you are specifically working with gini Pro or gini in devices you can use Nano in this in for normal daytoday task or general task you can use gini Pro then you can use ultra right now Gemini Pro is available for everyone out there without paying anything you can use it and you can also hit 60 queries in a minute okay at a time you can hit 60 queries right now no charges are there later on when Ultra will come the API will be basically exposed okay and then you can also use now gini can generate code based on different inputs all these capabilities are specifically there so it is now better that we try to see some handson okay and all the other information you can probably check it out which is I don't think so it is very much important right now you can also check it out with respect to B now I'll give you a link okay I will give you a link everybody so let's take this link everyone and provide this link in the chat okay so please go ahead with this specific link okay I've given you the link over here okay and in this link you'll be finding this particular thing now we are going to see a kind of demo right kind of demo like how does geminii API work and we are specifically going to use AP gini Pro now in this first of all I also need to worry about the API key how do we create an API key gini Pro create an API key we'll discuss about that right second we will see multiple examples with text images okay so both these examples we'll see in this demo and finally once we see multiple examples then we will create an end to endend project where I'm going to write the code from scratch write the code from scratch okay I'll build a front end back end and then probably show you okay um sir a video called handson with Gemini interacting with multiple was fake yeah I told right uh they had actually integrated images to image but with respect to Performance I think it is very very much good okay so let's go ahead and now I will click on Google collab now see guys over here Google collab is there you can also work in neurolab okay if you want okay but always understand with respect to if you want to use gini Pro the python version that you really need to have is 3.9 and greater okay 3.9 and greater so we are still updating this neural lab right now by default when you open this neural lab it opens in 3.8 see 3.8.1 Z right so we will soon update this by default you can also get an option of changing this environment because today I was actually seeing this and it can probably also work in 3.9 okay so that is the reason we are probably finding it out so everybody got this link everyone did you get this link so I will post a comment just check whether you are able to get this link or not everybody got the link yeah so this is the link you have to probably go ahead with you know so you will get this page you have it all the options yeah you have all the options like for go you have for nodejs you have see it supports all everything right web if you want to probably working on web if you're working on Android device you also have that you have that client SDK right you have rest API right everything if you want to work along with rest API you can also get that as an example how to get an API key I will just go ahead and talk about it but now we are going to focus on python okay so with respect to python we are over here now do one thing first of all guys when you're running this before install installing first of all let's go ahead and connect to the GPU okay and again if you Al want to do the coding in neural La please go ahead and do it okay but as I said uh it may give you some issues because the bython default version is 3.9 with respect to gini Pro okay but again I would suggest try with this also good system all the code will be saved over here and it will not get deleted okay great now first thing first okay so we have connected let's before executing anything click on this get an API key so get an API key will be there somewhere like this and it will go to this link makers. goole.com slapp API ke so first of all we are going to create an API key okay for API key for a project okay so just give me a a confirmation if you are in this particular section because I'm going to show you everything from scratch how you can actually do it okay so please go over here in this specific link did you get that link did you get that link I hope right just click on this link in this particular uh notebook file you'll be finding this specific link get API key okay so click on that and it will open just give me a confirmation once this is open okay so see if you want to communicate with this llm model it will be exposed in the form of apis so when it is exposed in the form of API you'll be able to interact with it okay yes everybody got this link okay I have already created one so I'm going to delete this and I'll create a new one okay so I'm creating an API key now what happened let's see create a API key the caller does not have a permission I'm getting some error let me see okay my account was changed okay so I will just change my account so this is my account okay now I will try to execute it because if you doing with other other account then it will be creating a problem so let's go ahead and create my API key okay I will go over here now everybody just click on this create a API key still there is an issue why is everybody able to create an API key right now just check are you able to create an API key I will just open Google collab let's see okay okay it should not give an error I don't know why it is giving an error scholar does not have a permission just a second I think everybody should be able to create it just give me a second guys I'll just try to create one API key just give me a second okay I think there's some issues but I think everybody may have got created it I'm getting some error and I should know the reason just a second just a second the caller does not have a permission anybody facing this error I think it is due to I created did the multiple keys for the task I created the three app keys after that it is giving Mana I guess so uh just a second let me see I'll just sign out once close it and open let's see maker suit I got the create I was able to create it yeah everybody's able okay someone someone someone Someone okay someone anyone ping me the key over here I'll just have a look on this issue why it is Happ happening with my email ID okay I'll just get to know why it is probably a problem but anyone just give me an API key in the chat anyhow you can actually request 60 request so anyone someone give me the chat in the chat I'll just check because this is the first time I'm facing this error let's see what is the issue okay it should not give me an error someone just uh ping it in the chat let me see in whether any other user ID will I be able to do it or not think okay so please make sure that I think if you're able to create a multiple okay finally I it has got created I changed my login ID so now it has got created now what I will do I will go over here okay I will keep this API key somewhere here let me just keep it over here so I will say OS do or let's say I will write key is equal to and I will save it over here okay so guys please make sure that please please please make sure that don't create multiple multiple this one and delete keep on deleting it okay so do not do that okay so don't after creating one please save it somewhere let's say I am saving it in my notebook file okay so I have saved it over here in my notebook file so that you don't delete this okay don't delete it if you're deleting it I think after three times it will give you an is issue otherwise just change your email ID okay now let's start over here and let's start working on it okay so first of all I will go ahead and connect it okay and then we'll go ahead and discuss step by step okay so just let me know whether you have done all the steps or not you have everybody has created their keys yes yeah everybody has created the key okay now I have connected to my collab okay remember the requirements is that you need to have python 3.9 plus okay and installation of Jupiter to run the notebook so 3.9 plus is the minimum python version that it will work with now first of all we will go ahead and install this Google generative AI okay so this is the library we are going to create it okay so what I will do parallely let me do one thing parallely I will create a project okay let me let me create one folder so guys see I've created a folder gini okay and in my local I will open a VSS code because at the end of the day I also want to create an end to endend project okay so everybody follow along with my steps okay now first of all it is basically saying that I will be having one requirement. txt requirements.txt yes everybody so everybody has vs code can you give me a quick confirmation if everybody has a vs code yeah everybody has a vs code yes yes so how do you open this vs code just click in this particular folder open with code right so I hope everybody is basically having the vs code now I have opened the vs code now the first step over here you can see that we will go ahead and install Google generate ative AI right so I will copy this entirely and I will execute it because here I will show you the demo and there we will try to create an endtoend project okay so I will do this over here so here you can see the installation has taken place right and as you know the first thing that we need to install is Google generative AI so now I will go to my vs code and here I will write it as Google generative AI okay the next thing I will also be requiring streamlet so that I create my front end right so here I need to create my front end okay so these two libraries I'm going to specifically use it okay now as said what should be the python environment that you are currently working in what should be the python environment that you should be working in can anybody tell me so I'll say cond deac activate quickly tell me guys which python environment we should keep on working on it which python environment at least greater than 3.9 plus so what we will do we will try to create an environment so in order to create an environment I will write cond create minus P my environment name is V EnV and which environment I'm going to use Python equal to 3.9 or if you don't want 3.9 plus you want so I will say 3.10 right 3.10 and here I will by default give y okay so everybody clear I'm creating an environment so that I will also be able to work along with an end to endend project so once I execute this over here you'll be seeing this entire things will get executed okay and that is why you'll be able to see one environment V and be getting created see step by step we'll do and I'll be able to make you understand why I'm specifically doing this because I want an environment so if you're executing the local or in any Cloud minimum requirement is that you need to have python 3.9 plus that is the reason I've taken python 3.10 okay so here you can see that we noticed a new environment has been created do you want to select it for the workspace folder either you can select yes or if if you want to activate that environment what you will do you will write cond create sorry cond activate vnb Dash okay so now here is my activated environment perfect clear everyone can I get a quick yes yeah yes yes obviously you'll get the recording also don't worry so everybody if you are able to understand please hit like and let me know if you are getting all this information or not okay we will do this parallell step by step whatever things are happening we will work in that specific way okay great okay now here also we installed Google generative AI okay clear shall I go ahead guys shall I go ahead everyone shall I go ahead come on give me a quick yes great now what we are specifically going to do okay is that we are going to install and import some of the libraries for google. generative AI see this is what we had installed right Google Das generative AI right and the same thing we are importing over here import Google generative AI as gen all the functionalities Let It Be text let it be uh Let It Be regarding other things that is videos images audio this gen aai will be the allias name which will have all the functionalities and this is present inside google. generative AI okay now here you'll be able to see that there is something a way to secure your API data I will show you how you can basically do it but let's go ahead and create my API data so here I already copied my API so I will go ahead and say okay my API uncore key is equal to in this way I'll paste it over here okay so here I will give my API key which I had copied from there so this will basically have my API key okay so this API key I will further be using using okay so everybody just create your API key field and this is basically converting a text into markdown so that you get a good display in the jupyter notebook so not that important so that is what next thing we are basically going to do now understand this API key that we have created the same thing we'll try to do it in our end to endend project the name that we are specifically going to use is nothing but Google API key so here when I probably go over here and go to my here I will create a file okay a file okay soem file and here what I will do I will paste it Google API key and we will try to paste the API key over over here what was the API key that I got it was nothing but this entire thing okay so here it is okay so why we need to create an API key to play banga we'll do bhang with the API key Danes sa are you in the session or are you away from the session H do you want to play banga come on I I made you understand right why we require the API ke it is very simple to communicate with the llm models huh without the API key you'll not be able to communicate with the llm models right a better answer for you will be to play banga okay let's play banga in that okay come on guys please be serious with respect to all the sessions that we are doing right never never uh you know whenever we provide you free content you do not value that free content right please focus on the session try to learn along with me I'm going step by step I'm going slow I'm explaining you each and everything right please Focus right please Focus if you do not focus on the session if you're just watching it then it will become a problem okay so practice along with me so here I've created one API key that is Google API key h um one question was that sir at the end of the webinar could you please suggest some real use cases of gen VI in finance yeah today the end to end project that I'm going to do is an real use case only okay clear everyone so can I get a quick yes API key basically means we have gini llm models somewhere hosted in the cloud to access that you require some some some tickets let's say you want an entry ticket that entry ticket will be given by that API key itself right you if you have the right API key you'll be able to contact the Jin llm model you'll be able to get the result okay so clear everyone till here okay okay perfect now we will go to the next step and here I will go ahead and I'll just comment out this code okay I don't want this code okay and let's say I will write gen. configure we need to configure this key okay we need to configure the API key so I will just comment out this code and I'll show you in an end to end project how you can call this variable okay and I'm saying gen ai. configure API key will be equal to this key okay so once I actually execute it okay here you can see that now our API key is basically configured now we know our ke is over here but it is not a good practice to Showcase this API key like this that is the reason in my project you'll be seeing that I have created this file okay file and this file has this API key and this EnV is nothing but environment right when you go ahead and deploy this this environment file will not be visible okay and since it is not visible in the environment in the production you will not be able to see this key so over there in production also you have a different way of setting the API key okay perfect now here we have configured it okay now this gen AI after configuring it provides you two amazing models one is gini pro and one is gini Pro Vision gini Pro is is specifically for optimized for text only prompts and this is probably optimized for text and images prompts okay text and images so one is for text and the other one is for text and images I hope you able to understand it okay one is text and one is text and images so if you want to do any kind of work that is related to text and images let me tell you an example okay what kind of use cases you can probably get from it okay now see this guys if I have this invoice let's say I have this specific invoice now if I want anyone to probably take out information from this invoice what do you think I can basically do or let's let's take this invoice okay some some of the invoice EX example this invoice has some of the data okay invoice sample I will take okay let's say this is one of the sample invoice and if I probably save this image and I will save it in my downloads everybody's able to see this invoice now from this invoice I want my llm application to probably retrieve data from it okay if I probably ask who was this invoice buil to it should be able to take out this information isn't it an amazing use case just imagine as a human being will this be a very steady task means it'll be a very slow task right here you'll be seeing what information is there then you'll be writing all the information what if if I say my llm model and I give this image and I say that hey what is the date that is issued for this invoice and it should be able to give me the answer 263 2021 isn't it amazing tell me will this be an amazing use case to work on in a company where you automat all the invoices are automated automatically is it good or not tell me guys come on yes or no something I hope you are not sleeping I know it's late but I'm going to take the session till 10 so that is the reason I'm asking you are you able to hear me out or not right so just imagine if you want to automate the entire in invoice probably take out all the info yeah PDF is also supported not on images PDF is also supported PDF you can convert that into bytes you can take out the information you can even chat with your PDF do whatever things you want right so this is super right this is this is amazing thing right you will be able to get those information and just imagine you have a task where you need to automate all the data in an Excel sheet and probably push that data from into a different databases right so here you'll be able to see that yeah I hope you able to get an idea about it guys clear so let's automate this let's automate this entire thing where you can give an image and I ask any question any generic questions with respect to this you should be able to get an answer about that okay so this is just like an invoice extractor I'll say okay and in upcoming projects we'll see about PDFs we'll see about chatting with PDFs we'll see about multiple things okay then then you'll have a fun so this is what is the use case that I'm going to probably solve today okay now let's go ahead and let's go ahead and probably talk more about it okay now tell me one thing guys everybody's writing the code along with me I hope so if you are not writing I will give you the code anyhow okay but uh let's go ahead and do this okay now this is done my EnV is created okay my EnV is basically created I have my Google API key everything is there uh now let's go ahead and install these requirements okay so first of all what I will do I will go over here I will go ahead and install these requirements in requirements I have Google generative AI streamlet right so I will go and write pip install minus r requirement. tht right so now my installation is basically taking place please go ahead and do the installation everyone and once you do the installation in your vs code or in your neurol lab we will try to probably install all the libraries that are required okay because at the end of the day we are going to create an end to end project please do that okay guys and uh for the people whom I see lot of participation I will give them an opportunity to probably come along with me in this live session and talk with me okay so you really need to be activate Okay so I'll give a couple of people that specific chance okay so please Focus okay and please be active because this kind of session start valuing it okay unless and until you don't value it then it will not work out so hit like do multiple things keep on posting call your friends to join the session it'll be quite some amazing okay so right we are what we are basically going to do we going to do this specific installation it will take some time uh now what I will do I will create my app.py file Now understand one thing what we are specifically going to do I will see what is our plan that we are going to do I'll discuss about the architecture so I will create one front end application something like this okay I will what I will do I will upload an image so then image will upload over here okay and then I will write my own custom prompt so this will basically be my prompt prompt basically means I will ask who is this invoice will to I will ask this question over here the image will get uploaded over here and then I should be getting my output over here that saying that the image was built to someone like built to this particular company okay now this is super amazing see now as soon as I upload the image understand the architecture okay as soon as I upload the image right so this image will get uploaded then what I will do I will take this image I will take this image convert into bytes convert into bytes okay and then retrieve this image over here so I will be having the image info okay image info okay so this is First Step as soon as I upload it the image will get converted into bytes and we'll be having all the image info all the details inside the image because Gemini pro has a very strong OCR functionalities OCR functionalities okay so if you probably give this information of the image info now in The Next Step what I'll do I will take this prompt so I will add this along with my prompt and this entire info will be going to where where it will go bites basically I'll show you that bytes don't worry okay it is just like image information it will probably get converted into some encoded character okay now this image info plus prompt will now be we will hit it to Google gini we will hit it to we will hit it to gini pro llm model okay to gini pro llm model now once we head it to the Gin pro llm model it will look for two important information one is the prompt and one is the image info and through that OCR functionalities what this gin Pro it has an internal OCR functionalities it will try to compare this two information and it is able to get an output it will give an output saying that let's say I've asked the build uh who this invoice was built to it'll say that the invoice was built to so and so information that we are getting from the image okay and finally this will be my output and this is what we are specifically going to do we will Design this we will write the code for this and we will probably get this also okay so finally we'll do all this Steps step by step okay now let's quickly go over here and I've already done the installation let me clear the screen now you may be thinking Krish you are not a front end developer how will you write the stream late code on the Fly I will never write I will use chat GPT I will use Google B I'll say hey give me a stream L code where I have an image upload button where I have one text input box and I have a submit button I will write like that okay so let's go ahead and write my code okay so first of all I will write it over here invoice extractor okay now first of all tell me guys in my environment file I have my API key right how do I call this how do I call this environment variable right so for that I will be using from EnV import load uncore Dov okay so I require this load. EnV what this specifically does load. EnV it will help us to load all our environment variables right but for this I need to install it so here what I will do I will go to requirement. txt I will write python. EnV right and I'll save it again I will go to my terminal okay and I will say pip install pip install minus r requirement. tht so this installation will take place and finally you'll be able to see the python. EnV will get installed so here you can probably see the installation has been done now it will not give us an error whenever we try to load this EnV okay so we have specifically done this okay now after importing to load all the environment variables we will use this function which is called as load. EnV so here it will take load all environment variables from dot EMV okay clear everyone yes can I get a quick yes yeah I will show you everything don't worry follow along with me I will try to show you how you can convert image into bytes how you can get the image info everything as such I will show you okay okay everything I will show you but here till here I hope everybody's very much able to understand and they able to understand in a very good way okay clear okay perfect so let me go to the next step now and we'll discuss further like what we are specifically going to do now after this I will go ahead and import streamlet as St so we are going to use streamlet as we imported that okay we will import OS because I need to call my environment variables so here I'll be using OS and then since I'm using images I will use from P import image okay this image will actually help us to get the info from the image okay now as you know from the requirement. txt we have also installed Google generative AI right so we will be importing importing Google do generative AI as gen AI okay so we are also going to use this specific thing that is google. generative a gen now as usual first of all you know that we need to load our API key right and we need to configure it so here for configuring I will write over here configuring configuring API key okay and here I will basically write gen do configure API uncore key and now where is my environment variable it is basically present in this specific key right in this specific key so in order to call this I'm already calling load. EnV so here I will write OS dot get ENB that is get environment variable get environment variable here I will go ahead and use my API key done so this way I'm able to configure the API key right yes everybody clear here right everybody clear so I hope you're getting a clear idea what we are doing step by step I've imported all these things I imported streamlet I have imported Os Os why I had imported because I need to get the environment variable right and this G environment variable is basically present INB file whatever name it will go okay now here you'll be able to see that I have configured each and everything okay so along with me you can write the code if you liking the video please hit like uh share with all your friends as usual because all the steps I'm showing you completely from scratch Basics because once you understand this it's your idea do whatever things you can do image detection image classification whatever images you want okay you can basically do it now done now my next step will be that I will write a function so I will create a function to load Gemini provision model and get response okay so I will create this function so I will write definition get gini response okay response and here I will require two important information one is the input right what specific input that I am basically giving okay second is image and third is basically prompt I'll talk about this what is this differences between this input and prompt because both are almost similar but prompt is something different and image is something different this prompt or this sorry this input will be the message that the llm model will behave like okay this prompt will be my input that I'm giving what kind of information I want okay so this three information I'm giving it over here now I will go ahead and call my model so I will write model gen Dot and here I will call my generative generative model so inside this functionalities basically to call that gini provision model I have to use the gen. generative model and here I will call my Gemini Pro Vision okay so I'm going to basically call this right gini Pro Vision and finally once I call this this way I will be loading my model so I'll give you a message over here saying that loading the Gen AI model right the Gemini model I can also say it as Gemini model okay now after loading it I need to get the response so I will write response is equal to and I will say model dot generate model. generate underscore content and here in a list format this is how you have to basically give the input to the model so in the list format the first parameter I'm going to give is input images will be in the form of list all the information we'll get in the form of list so I'll write image of zero comma it it'll be in the form of list and then finally I'll write prompt so once I get this information then I will return response and there will be a parameter inside response which is basically called as text so all this information we are getting it from the Gin right so what we are doing in this specific function we are creating a function which will load a gity provision model and then model. generate content will take the input and it will give us the response so here we are getting three inputs I'll talk more about these inputs what all it is and then finally we will be getting the response. text everybody clear yes yes everybody clear can I get a quick yes if you able to understand till here come on yes or no give some heart sign give some symbols yes no anything it is up to you yeah learning is very much important as I said so please give your spread your love right everywhere learning will be fun great now what we are going to do next step okay next step what I said see as soon as see this part is done if I talk about this part hitting through the Gemini Pro with all the info image info and prompt this is done and I get the response this part is done but this part is not yet done image upload convert into bytes and probably get this info this is not done so what we will do we will go ahead and write that function so here I will write input image set up and here I will say provide my uploaded file so whatever uploaded file I'm going to get I'm going to give it over here the image I'm going to give it over okay now initially I did not know the code for this okay how to probably get the uh image data in the form of bytes something like that right so what I did I I I went ahead and asked chat GPT and then chat GPT gave me this solution okay I asked it that I'm giving an image okay uh just a second I'm giving an image so if uploaded file is not none then it took this data uploaded file and it did dot get value from the dot get value it got the bite data and then it gave me image Parts in two different format one is the mime type and one is the data okay so don't worry I will give you this entire code in the GitHub repository if you want the GitHub repository also I can give it to you okay so here is the uh I'm I'm putting the comment uh so everybody body will be able to see the comment over there in LinkedIn also I think I will go ahead and put it okay so this will basically be the GitHub file okay so everybody will be able to see this okay so what we are doing over here we are taking this image we converting that into bytes okay then the image part will be based on two parameters one is mim type where the uploaded file. type is there and the data by data I just asked it to chat jpt and it gave me this specific answer okay and then we are returning this image part so by this what is exactly happening this part that you have created is completed see step by step we created this gin Pro load it this part is created image info we are specifically getting it now we need to get prompt and we need to get input okay where it is pasted in GitHub link so in vision. piy file you'll be able to see that the code is given Okay so so you can actually use it from there perfect everybody clear so this is my second task that I have actually done shall I go with the third task yes or no yes or no third task is nothing but it is basically our streamlit app so here you can probably see I will now create my stream L app see initialize our stream L app we use st. page config the page title is gini image demo so let's say I'm going to write some other functionality over here I will go and say uh image or invoice extractor okay this is a Gemini application I use one text box the text box this text box is nothing but my input okay input that I'm getting I'm giving what kind of information I specifically want from my from what what kind of input I specifically want from my invoice yeah that information and then uploaded file will be st. file uploader now here I'm saying choose an image the type should be jpg jpg PNG if you want PDF you can also write PDF over there but the format will be little bit different so I have created a file uploader over here and I'm saying if uploaded file is not none then what will happen it will open the uploaded file and it will display the file over here it'll display the file over H image right so some amount of knowledge in streamlet is required for this if you don't have knowledge be dependent on chat GPT because this code entire code was given by chat GPT okay so here what I did I used an input box I created an uploader file for image and then I'm displaying the specific image as soon as the upload is done okay so this three input information I did it okay and finally I will create a submit button and I will say St do button and here I will say tell me about the invoice done and finally I will give some prompt I I I need to say I need to say how my Google Gemini pro model needs to behave so for that I will give some kind of input prompt and I'll say hey let's say I'm going to use multiline comment and here I'll say okay let's give a message a default message you you are an expert in understanding invoices okay you will receive you will receive input images as invoices I'm writing a message and you will have to answer questions B based on the input image so I'm giving some prompt right some prompt template like kind of stuff so that I'm saying hey you need to behave in this way okay you are an expert in understanding invoices you will receive an input image and invoices and you'll have to answer question based on the input image right so this is my in by default you can basically say a default instruction to the gini pro model that you need to behave like this okay now finally if submit button is clicked now what should happen now let's go ahead and understand with respect to this when this submit button is clicked first of all the image should get converted into bytes I should be able to get the image info then image info along with the prompt should hit the germini pro model right this is what we really want to do so here I will say if submit if I am submitting if the submit button is clicked first thing first what I will be requiring my image data the image data will call which function this function only no input image setup okay so here it will basically call the input image setup and here we will go ahead and write my uploaded file right the uploaded file that I get and now I got the image data right now all I to need to call is my response and I will go ahead and call my get gini response and and here I will give my three information what three information is basically going uh over here input image data and prompt so input is uh this input prompt so I will copy this then you have this image data image data okay this image data you have and third one is basically what is your input right so your input is over here so what whatever input you are basically writing in this okay so all this three information has basically gone right so I hope everybody's clear with this and finally I get my response right now once I get my response all I have to do is that display this specific response okay display this specific response so for this I will go ahead and write St Dot subheader and I will write the response is and here I will write ht. WR and here I will display the response okay whatever response is coming over here let's see excited so done the project is done so there is three functionalities one is this one is the image processing then one is simple streamlit app creating your input prompt and done now shall we run this how excited are you will we get an error or shall we just directly run it tell me should we run it or shall we run it everyone so let's go ahead and run it so here I will write streamlet run app.py so I'm running this allow exess and here we go do you see this everyone yeah now let me go ahead and browse the file one of the invoice that I downloaded it looks something like this see am I able to see the sample invoice right Cho let's see bigger information it will obviously be able to give it okay okay let's take out this information can we take out this information what is the deposit requested in the invoice let me ask what is the deposit requested come on you can see the answer what is the deposit requested okay so I will just go ahead and this is my prompt that I'm giving now I will go ahead and click on tell me about about the invoice now let's see whether it will run or not so it should be able to give me the answer it is running do you see the answer 169.99 yes or no right let's go ahead and see something who is this invoice build to who is this invoice build to and I will go ahead and click on tell me about the invoice so who is this invoice build to who is this invoice build to let's see it's running L by answer low see all the same information good now tell me how strong this is you see like do like Give Love share love spread love yeah any more question okay let's try multil language Hindi invoice format let's try some Hindi invoice no let's save this will it be able to work Hindi invoice let's go ahead and browse it yes we can also save the data anywhere we want in databases and all okay how many of you know Hindi response times took little long yeah we can optimize it it is a free API no okay let's let's ask some complex question in Hindi okay I will ask in English only what is the HSN see over here you find HSN HSN is over here right of Lenovo 5125 I okay what is the HSN of Lenovo Lenovo the item I'm writing in English see Lenovo 5125 I 5125 5 I let's try tell me about the invoice we can optimize this if this is the format right we can optimize it do you see this number is it same 301 0 yeah so I know in many companies they'll be requiring this see it is written in English Hindi okay let me just go ahead and write what is the billing address okay what is the billing address okay tell me about the invoice right tell me about the invoice take SCB building building defense State Gino Maharashtra see all the information is here good enough see Maharashtra also it is taken right okay see dinak is written now so let's see I will write what is the date of the invoice what is the date of the invoice tick 1227 0221 good now try any invoice let's see what is the cgst okay let me go ahead and write what is the cgst let's go ahead and see about the invoice there is no limit of the image you can upload as cgst is 80% where it is written okay it is given see okay GST 18% is the cgst is 18% okay okay uh let's see what I'll write what is the total what is the total bill what is the total bill I'm just writing anything let's see where it tries to yes yes you can do 500 PDF 100 PDF in my next session I will show you working with PDF okay 1 170 392 see guys amazing right so yeah 500,000 how much you all results got correct sir yes yeah nag as I'm saying any number of pages take one lakh pages also it is possible there we can use Vector database to save it so guys good video hit like shower Your Love share with all your friends and this was about today's session so tell me how was the session see at the end of the day okay one more thing that I really want to share so that you don't miss things so guys uh we are happy to introduce one amazing course for you that is regarding generative AI so we will be building this kind of application we show you how to do the deployments and all so this is the mastering generative AI course you can go ahead and check it out in ion. page okay so I'm giving you the link in the comment section if you like it please go ahead and watch it so here we will be developing all these kind of projects we'll be using Google gini we'll be using open AI Lang chain Lama index you can check out and again at the end of the day mentors you'll be seeing myself Sunny bappy so everybody will be taking a part of it if you have not seen the community sessions in Inon so definitely go ahead and watch out and see the talent of all the mentors that are there but at the end of the day the projects level that we going to develop is much more complex with respect to this so go ahead and check it out and if you have any queries please do call to our team counseler team which is over here in the bottom of the page you'll be able to see them right and uh anything that you have a queries regarding you can probably contact us okay so this was one of the thing not only that if you are interested in learning machine learning deep learning anything as such or data analytics we also have that there's also mlops production ready projects you can also join that okay so yes this was from my side I hope you like this particular session my final takeaway is that uh in the field of AI it is it is really really evolving every day you really need to learn if you think that you're just going to learn today get a job tomorrow and after that your learning stops that is not at all possible Right learning is continuous and you really need to learn continuous you need to find out ways you need to find of creativity in doing the projects and uh at the end of the day you work for the benefit of the society right so uh this is the main and amazing thing that I have probably seen in this AI field is that the amount of learning is amazing it is quite well and the kind of things that we have actually done right in the AI field like everybody throughout the world right it is amazing right I I can definitely say like it's wow okay so uh yes this was it from my side at the end of the day I would again suggest uh keep on looking on different things that you can do with this just imagine today we just did this entire invoice extractor tomorrow you can think of multiple use cases think in the different domain Healthcare domain right and uh let's see where you'll come and definitely do share this content everywhere in LinkedIn show your talent show your things what more additional thing you can basically do on top of it okay so yes uh this was it from my side guys I hope you like this particular session if you liked it all the recordings will be available also I would suggest please see in the description of the YouTube channel all the community link will be given over there uh and if you want to learn any qu any courses from us you can check out in. page and I will see you all in all the sessions and class till then I will see you all in Next Friday with one more amazing sessions where we'll discuss more amazing use cases this was it from my side have a great day byebye take care keep on rocking keep on learning thank you everyone and yes at the end of the day keep sharing your knowledge with everyone right uh okay so sir please tell me if there is any prerequisite for this course don't worry about any prerequisite it will get handled only thing that you really need to know about generative AI is about python okay so probably When You Learn Python if you uh you need to have some amount of knowledge of python for that also we have put recorded videos in the course so that you can actually check it out okay uh thank you so much for your wonderful efforts thank you thank you thank you uh how can we integrate into databases and then ret information that I will show you in the next class we'll use some kind of um uh we we'll try to use some kind of vector databases okay it'll be fun it'll be fun it'll be amazing okay okay let's see some more okay I'll take some more question sir every time we click on run it trains the model with the image provided then extract no it need not train itself the model is already trained so you give the necessary bite information over there it'll be able to extract all the details like OCR right excellent session thank you sir as I said how can we integrate with databases and we will be using Vector databases okay that I'll show you in the next class it'll take one hour session yes sir we have a lot of learned from Krishna thanks to give top knowledge sharing with us thank you I really enjoyed my Friday evening with this new learning every day like every Friday I will come over there and I'll teach you something okay it's okay so please try to learn from others also because there is some experience that is basically displayed over there okay NLP is important to learn generative AI yeah so let me just share my screen again so that you get an idea if you probably see what all things you'll be learning so if you go ahead and see our generative AI course sorry this is machine learning boot camp so in the generative AI course the prerequisits are uh only python is there and we will be teaching you all NLP so this is basically NLP we'll be teaching you all these things right uh NLP NLP NLP so basics of NLP then we'll go with RNN and and we'll try to learn this okay guys the team has shared some Link in the chat let's see so which are the best books for genda see guys I not suggest right now to follow any books because this is not fixed every day some changes are there right so guys there is a temporary URL link that we could see over there let's see I think uh NLP is important to learn generative AI new comments can you make an one end to tutorial on rag yes I will do that in the next class okay perfect so hit like guys if you like this session and uh there are lot many things that is probably going to come in the future okay sir say up data scientist B so this question is good enough sir dat SST this is just for testing purpose guys in front end there are lot many things other than this Okay click on the link and join the session with Chris sir link so this is the link right is this the link okay uh so we are not getting any notification about jobs see guys jobs uh things like how you can specifically apply And all I'll will be discussing more about it as we go ahead okay um just give me a day session time I'll probably talk about this with respect to resums with respect to building profile and all so all those things I will discuss okay can we do prediction using tabular data in gen what kind of predictions is it something related to text text you can basically do it okay anybody wants to join this session yeah prakash if you have any questions please do let me know you can you can un mute yourself if you want to talk yeah Prashant do you want to talk sorry prakash he got disconnected okay okay perfect uh are you adding feret in course I will just try to see that think the documentation that is available and I think this is an llm model from Microsoft I guess right so Mahesh has joined Mahesh do you want to talk anything yeah hi sir it's a pleasure to uh talk to you yeah hi hi mes yes please tell me you want to show your face you can also on your video uh so actually I'm not in a position to show my face uh I'm me outside uh actually I'm a student of in neuron and to be frank sir I'm just I was just clueless initially when I started to learn this uh data science part so again my education background is I'm from biology mhm okay so I don't have any background on mathematics but but to be frank when I just started to learn the things from in neuron so without any uh excuse me so without any um knowledge on mathematics also I still I'm able to learn lot of things and I can just I'm just getting more confidence when it comes to data science topic as well as I'm just getting more confidence so that I can just get play in future mhm mhm so you're saying that how first of all how is your learning things going on right now yes sir I'm just uh building in projects and uh I started to implement melops in my own architecture means like implementing the mlops from scratch sir I just did are you are you working somewhere right now yeah I'm working as a data analyst but my working nature is not exactly as data analyst but somewhat similar to data analyst okay my suggestion in this case right uh in your current company if you see any ideas and if you see anything that is probably coming up right try to participate in that try to see that what all things you can basically do over there you know try to see whether you can apply any data science knowledge because that is the experience that you can probably put as a p project in your resume right and later on with respect to with respect to that kind of work you'll be able to tell that in the interviews right in any interviews that you specifically go yeah yes sir and um I just want to thank you for uh being a good Mentor and I'm really thankful for anuron for giving me S such an good support in my career so I'm just always talk so I'm really excited I'm not able to talk okay no worries no worries so drink some water and be chilled okay and keep on working hard okay thank you sir thank you very much hello I am so much excited to talk to you uh your your videos are so much uh informative and uh I'm really uh glad to talk directly with you like this uh I used to follow your ml series and DL series and uh they're very informative I have enrolled to gender course also uh just I would like to uh know few questions sir um please kindly answer I'm um I'm poor at a data stres and algorithms uh will that be uh requ for this generate course may know please no no no no it's okay like basic inbuilt data structures will be sufficient um it's more about how you can use generative AI to solve applications right Basics that is specifically required you need to be good at that for cracking interviews okay okay I'm I'm six years of experience as a tester uh okay uh is it okay just means if I get into this field does companies accept my profile as a tester and switching to this uh transforming to this carer as a tester whatever projects you're currently doing make sure to apply some data science stuff over there it can be automation it can be anything as such because that same thing you'll be able to explain in the interviews okay yeah yeah okay sir thank you so much sir yeah thank you one more question fet Apple released one fet llm right are you going to add this in general a course uh fet right now the entire documentation is not available so once let's say once we probably go and we see lot of use cases then we'll try to add it okay okay sir any update that will probably coming then and there we'll try to add it okay okay sir yeah thanks yeah thank you yeah yeah Mahesh please unmute yourself yes sir sir is this session being recording yeah okay fine and uh sir is there is there any option for me to visit anuron so that we can just meet um yeah sure you can come Inon in the working days right yeah Monday to Friday anytime H yeah sure sir okay so that I can just uh talk to personally so uh maybe maybe within that within two or 3 months I might be getting uh place I'm applying for the jobs so once I just transing means I'm just placing in a new company so I'll be coming uh to IUN and directly meeting to you okay sure sure sure definitely okay you thank you much yeah Danish SA you can unmute yourself yeah hello sir yeah hi yeah yeah yeah please is it okay for students thank as a fresher M definitely sir I want to sir may defitely be there and thank you so much for sir thank you thank you yeah thank you definitely thank yes thank you sir thank you thank you sir yeah yeah thank you okay uh Joy rubul P questions please P Jo sir from past three years I'm following your YouTube channel sir M uh Mission learning I studied your mission learning sir my my aim is I'm following generative AI course now sir can you please provide a free in your YouTube channel sir 8,000 is too much sir for us so that's why I'm asking sir anyhow sir we have done live Community session about generative AI a lot of free content we have uploaded already and more free content whatever will be coming we still be uploading don't worry about it sir okay yeah but llama model these models is not uploaded in your YouTube channel right sir it will get uploaded sir give some time then we'll try to upload that also but it needs to take time no sir we also need to create uh we need to get time for recordings and all we'll be doing that kind in live session let's say next Friday I'll do about llama index and all okay sir uh M course era is there now sir which which course we want to follow out for generative AA llm models because I am the beginner of this I learn machine learning from your YouTube channel if I follow want to follow course era which uh because course era is offering for our University free so that's why I'm askre sir I did not check out corsera all the courses sir yet you know I did not check it out like which one is there but I think some or the other will you'll be able to find it over there sir okay but I did not check it out and that is the reason I I usually learn from documentation githubschool but I don't have any idea about corsera Sir okay sir thank you sir while you are while you are explaining in your YouTube channel sir first explain the documentation for me also so that next time we will read little bit the documentation while we are reading the documentation we did not get the content if you tell the keywords now then only we will understood that we will digest while we are I mean reading the research paper like that sir sure sir sure I'll do that sir sure thank you sir okay yeah next question yeah please go ahead yeah very big very big thanks for thanks to you uh so I I am your fan since you started I new run so after that only I come to know that you are teaching so many uh courses belongs to a machine learning everything so initially I'm worrying about which one I need to choose so whether I need to choose machine learning or whether I need to choose that and so I want to learn in multiple things but I cannot on single things okay by luckily uh my my in my work space I have a opportunity to work on gener P one years when the open a released okay sir so I know something about that so I I know something about the open a what are the features it can do so I have a handon training on that one so now you announce this generative a course so it will help me a lot so I'm choosing your way that I need to break a leg on this General ta so I admire you and I like your videos so I already purchased your course so I am excited to start on January 18 onwards so very big thanks to you but what you are um so I'm learning like a surviving language only so whatever the whatever the mean my Works needs so I'm go and picking those kind of stuff reading the stuff then I'm working on it like the way so whatever the things you example you saw in today's session I have have completed those scenarios when the J announced that you can use you can build this application on WE that you you put some video right the next day itself I explored all the things so only that I'm excted to do is that video part only but nobody I don't see any video video paring yeah video paring yeah yeah don't worry we will I'll create a video on that also so don't worry okay so exact exact to work on Inon no sir our data science team has already done that okay okay super passed 20,000 videos so we have created a support system which is pass 20,000 videos for the support Channel very great very great to know I ex from you yeah we'll speak to you sir thank you thank you thank you for yourk you thank you for your s and you are you are boosting our confidence more more thank you thank you prashan thank you yeah kimah yeah hello sir hello hello H hello sir I am from Pakistan yeah hi hi sir I'm your big p and I I have a question I am a student of electrical engineering and I want to learn machine learning and deep learning I want to Chase your course uh uh which course you would suggest for me sir just go to ion. website there will be a counseler number okay uh just try to contact them in WhatsApp they will help you out with all the information right there is a ml boot Cam that is probably coming up you can join that course that will be completely from Basics okay so there you can probably join that but again go to ion. for more better communication I think you can contact the there'll be a number for The Counselor or you just fill up the form the counselor will try to contact you sir oh thank you sir yeah thank you thank you yeah Dean josi sir sir hi uh sir I'm engine I'm btech engineering first year student and my specialization in AI n DS so I'm I'm asking with you that sir AI in the AI my college was not studying this AI specialization they were already uh the basic languages python uh C+ and this then sir I'm what language I'm beginning to start begin to start so uh are you guide me for the AI and DS and the best okay so python is the programming language you have to probably start with okay in this field because nowadays the cloud platforms everywhere the libraries everything is something that is related to Python and that is only coming up in the future okay yes sir sir can I speak in Hindi h z z I'm not in the proper way to speak in English yeah yeah it's okay Hindi a only in jaur skit College only a but I'm watching Dr starting beginning tops sir mainly basic B right okay sir yeah thank Youk thank you thank you yeah Aman Kumar Helm yes sir J sir J jind by dat science machine learning learning UK based remote job but machine learning deep learning basically data entry or some research work or LCA related basally data science machine learning full start applying for both preparing for government job I started learning about data science data analytics okay sir internship like we will get like free free internship 11a descrition okay sir sir okay thank you sir thank you sir hel yeah go ahead yes uh good evening it's good morning here in the United States I hope it's okay that I'm not from India I wanted wanted to thank you for the the videos you posted for Gemini Pro I I did all of them and I was on the road so I couldn't watch this one um or follow along but I will watch the recording and do it as well I subscribed or I enrolled to the class the master class that is coming up so wanted to ask if Gemini Pro will also be covered yeah yeah we'll add that up because see any updates that will probably come up with respect to any llm models we'll try to update that okay and which we feel that it is important and it can really be a breakthrough for developing my application we will keep on updating it wonderful one other question as far as machine learning deep learning NLP it sounds like NLP you're going in depth to some quite a bit will there be any machine learning or deep learning that we should study up on before the course uh whatever is the prerequisite we'll try to teach in the course whatever is necessary for that okay but again at the end of the day if you really want to become a fullfledged data scientist who has capabilities of machine learning deep learning and generi I think you need to also learn about machine learning and deep Lear SE okay to that point I'm I don't think I'm I want to become a machine learning engineer I want to more be on the on the front lines creating applications but I want to know enough with what I do I don't I don't have any uh computer uh programming background I just started learning pythons you know four months ago then this course will be perfect for you I think uh then then you don't have to probably work worry about that it depends on the kind of work that you're specifically doing okay wonderful well thank you very much again really appreciate it thank you thank you sir so when will the course start I think you can go ahead and check out in the course dashboard uh the dates are basically given it is 28th Jan 2024 ni okay guys so because of time constraint it's almost 10 uh this was it from my side I hope you like this session I hope you liked it uh please do make sure that you hit like share with all your friends share your learning develop the application from your side I will see you all in the next video next Friday session we'll do some more amazing things we'll try to use Vector databases we'll try to create more projects and we'll implement it some same thing so thank you have a great day and keep on rocking keep on learning and have a happy weekend that is coming up thank you guys byebye take care perfect uh now let's go ahead towards the agenda so what is the agenda of this particular session what are we specifically going to discuss right and uh what is the end to end project that we are going to develop over here so it is very simple the agenda is that we will be developing a text to sequal application or I'll say llm application now just by the name you think that text to sq may be simple here we will be having a specific database we'll write some queries we'll insert some records and then we try to develop llm application wherein the main task of this llm application will be that take the text whatever text or prompt that you give let's say I I ask uh hey tell me tell me in this particular classroom how many students are there right so this text will be sent to the llm model and here the llm model will be Gemini Pro okay and this Gemini pro model will specifically give you a query right and this query will try to execute and read from my SQL database okay so this is the entire project that we are going to do right we need to have a c database we need to have a table over there and this entire project will be buil in this specific way itself right so this text that you will be seeing this is nothing but it is a prompt okay so this will be my input prompt in English language and then this will be sent to the llm llm is nothing but our Gman pro model this will in turn convert this into a query and then with the help of SQL libraries we'll go ahead and hit the SQL database and get the response okay so this is the entire agenda of this specific project and we'll also try to see how we can actually deploy this okay so everybody clear with the agenda what you are going to do in this specific project itself yeah can I get a quick yes if you are able to hear me out I hope you are able to understand this project that we are going to do and this is is going to be done by Google gini pro okay we will do the line by line coding from scratch so just give me a quick yes if you got the entire agenda of the specific project yeah and we'll develop part by part so just quickly give me a quick yes guys come on come on be somewhat active you know you need to be active then only the session will be fruitful okay so I would suggest please be active and try to say yes give some symbol give some thumbs up that would be quite amazing okay perfect so let's go ahead and let's start this particular project now here how we are going to implement things right implementation part so the first step what we are going to do is that you can use any SQL database as such here I'll be suggesting to use sqlite so that we'll be able to show everything in the demo itself and this is just not restricted to sqlite or SQL database you can also do it in a no SQL database you can do it in Cassandra DB you can do it in mongodb whatever database you specifically want second uh we'll do this setup we'll insert some records okay we'll insert some records and again this all things will do with my Python programming language okay so Python programming language will be used to do this the second thing after we implement this we will start creating our llm application and inside this llm application we'll create a simple UI where you can specifically write the query and this llm application will probably communicate with gini Pro and then it will communicate to the SQL database to give us the answer okay I just written two steps over here so you may be thinking that this may be simple but it is not that simple you will be seeing there will be a lot many things that will probably be coming over here okay and uh uh again at the end of the day please code along with me uh see what all things we are specifically writing in this what all requirements are there you know and step by step we'll go ahead and do the implementation perfect uh so everybody has got the agenda and the implementation part so let me go ahead and open my vs code okay now for opening the vs code over here you'll be able to see the first step you know when we start any project is that what we really need to do please answer someone we really need to create a environment right now a interview question may come for you like why you specifically require environment or why do you create an environment for every project that you probably create right there's a simple fundamental in this is that every project has a different dependencies you really require different libraries over there right so that is the reason you have to create different different environment for this again create an environment I will just go ahead and open my terminal okay so this is my terminal you can also do it in Powershell you can do it in command prompt so the first prerequisite is that you really need to have Anaconda installed okay so here is my uh in this particular location I have my project so let's go ahead and quickly create my environment so go ahead and write cond create minus P VNV python okay always remember as I said that Google gini pro works well with 3.10 right sorry greater than 3.9 version so that is the reason I'm going to use 3.10 and it is going to ask me for a not request saying that whether it should go ahead with the installation or not so I give that preand that symbol AS why why basically means yes so let me quickly go ahead and create this so you also can parall start creating it guys okay go ahead and create it uh everybody go ahead and create the environment itself so be work along with me then you'll be able to understand everything go ahead and create the environment and let me know once the environment is created come on and hit like if each and every step you are able to work out and at the end of the day I will also give you the entire GitHub code so that you'll be able to see it okay so quickly just tell me whether you will you are able to create a new environment or not I'll wait I'll wait slowly uh like I want everybody to execute it and probably you can go along with me and you can actually execute each and every line of code along with the project okay so at the end of the day I don't want you to just see the code but also Implement along with me okay so perfect over here so nanu is along with me he's also implementing things that's great everyone come on create the environment along with me and give a quick confirmation if you are able to do it okay there are 64 people watching I want everyone of you to do it along with me come on quickly let's do this okay great so in M done okay okay sir yes yes yes okay so I hope everybody has done the first step now as usual I will go ahead and clear the screen and now what we are going to do in the next step is that here you'll be able to see my V andv environment is created okay in this specific environment we will go ahead and start installing all the libraries so for this we need to activate the environment so I will go ahead and write p activate VNV right so cond activate VNV I'm giving this specific folder location over here and once I execute it here you'll be able to see that my path has changed now it is inside my VNV environment okay so this is the second step step by step we are specifically doing it so please participate in this start implementing things you know give me a confirmation it would be really great okay sir can was this actually I could not complete ml it's okay you can also watch this the prerequisite is only python okay uh perfect so this is done which application you are using what do you mean by application I'm using a vs code so there only I'm probably writing the code itself okay perfect so done we have activated the environment now let's go ahead and create our requirement. txt requirements.txt file okay now requirement. txt what it says it it basically says that what all libraries I may specifically require you know so for this let me go ahead and write all the libraries that I'm actually going to use one is streamlet okay because we are going to create the front end with streamlet the other one is Google generative Google generative AI now this Library also we require because at the end of the day we are going to use Google gini pro the another one is python. EnV now why we require this Library so that we can load all our environment variables and as you all know that we are going to create a Google gini pro uh API and then we are going to insert that in our environment variable okay um along with this uh I think this three libraries will be more than sufficient to start with perfect okay great so this three libraries I'm going to use over here now once I have actually written all these libraries over here then what I'm going to do is that go ahead and write pip install minus r requirement. txt okay so once I go ahead and write pip install minus r requirement. txt you'll be able to see that all the installation of all these libraries will happen okay and this is actually happening in the v EnV environment so please go ahead and do this step create your requirement. txt and then after that start doing the installation and this is the basic initial step that we really need to do in every project so till here everybody's clear give me a thumbs up give me some symbol some something laughing emoji right hit like and if you have chances call all your friends in this live session okay come on this kind of sessions you'll not get it anywhere live that also I'm coding along with you live so that you understand all these things come on so great sir all of the requirements for this project are free yes absolutely free you don't even have to put credit card that much free okay so uh the installation is basically happening please let me know whether the installation is done from your end or not okay and hit like come on you need to probably see the entire session and code along with me that is the main purpose of coming life you have to code along with me okay so this was one of the question sir all of the requirements for the projects are free yes it is completely free I believe in open source so that you don't have to pay anything over there okay perfect the installation has been done we are good to go over here now great can you give me a thumbs up if the installation if you have done at least partially you have done the installation come on let me know great now we will go ahead and create ourv file now for our EnV file environment file we require Google gini pro API okay so what I will do I will quickly go ahead and go to this website which is called as maker maker suit. goole.com slapp API key okay I just change my email ID because I've created my API key and another email ID okay so go to this particular website which is called as maker suit . google.com /a/ API key okay all keys needs to be put yes so just go ahead and click on this create API key new project so this will basically create your API key for Google giny okay so go ahead and click this right once you probably click it you'll be able to see this kind that is getting created the API key I've already created it so I will go ahead and copy it from here okay so I have copied it from here okay so everybody are you able to do this step just let me know and if you're following let me know okay I want everyone of you to implement along with me please that is a request then this session will be fruitful okay if I keep on teaching like this if if you say that no I'll do the implementation later on trust me later on nothing will happen you not be able to do it you know if you give excuses and keep on postponing things uh that will not work out you know when you have an opportunity when you're seeing this live please go ahead and Implement along with me great so can you add the link okay perfect let me go ahead and add it over here let me go ahead and add from stream key okay so I am adding this link over there perfect is everybody able to see the link now yeah yes yes great now from this link you have to create your API key once this is done go to the environment variable now and now for this API key you really need to create a key itself right so how do you create a key over here so here I will keep it in the form of key value pairs so here you can see that I've use the key that is Google API key and then this is my key that I've actually copied it from there okay so please keep in this format with respect to the key value pairs okay and initially you definitely require this because if you don't have the right key your application is not going to work perfect great now this is done our environment key is set we have activated the environment we have installed all the requirements okay now let me go to my notepad now the first thing with respect to the implementation as I told you that we will take a database like cite right and we'll insert some records to just show that there are some records there is a table there is a database there is there is a sqlite over there you know so that you can query you can query from those particular SQL database itself okay so for this what I'm actually going to do quickly I'll go ahead and create one file let's say this file name is sqlite dopy okay so here I'm going to write my code and this code will be responsible in inserting any records in the sqlite database okay so I'm going to close this over here and now I'm going to start writing my code and remember one thing guys over here whatever code I'm writing this is something also this will also help you to understand how we can connect python with sqlite and how we can insert records and all okay so first of all uh to start with I'm going to import sqlite so sqlite is again a lightweighted database okay sorry sqlite right uh three so we are going to by default in Python 3 right you have this imported already okay now we will go ahead and connect connect to the cite database okay cite database now for this I usually write the code AS connection is equal to I will go ahead and write connection connection is equal to sqlite 3 do connect and the I will keep a database name let's say the database name is student. DB okay so this is my database name I'm going to create my database in this specific name okay so in short what we are doing is that we connecting to this particular database so if this database does not exist okay then it is going to create this new DB okay so this is the first step the second step is that we'll create a cursor object to insert records to insert and create tables let's say to insert records or create table because inside a database we going to create a table right so till here I hope everybody's clear what we are specifically doing because this will be a this will be another py file which will be responsible in creating your database it will also insert all the records okay so please do along with me so that you'll be able to understand perfect now what we are going to do over here is that quickly we will go ahead and create a cursor object so for this we will go ahead and write cursor cursor is equal to connection connection dot cursor so that basically means inside this particular V database connection right whatever I'm basically using this particular function this method will be responsible in traversing the entire table going through all the records and all whenever we try to insert or retrieve the records okay so this method will be responsible for doing all those things now we will go ahead and create the table right now with the help of this cursor object we will try to create the table now here will be my table info let me go ahead and create my table info and I will say this will be three columns okay and let me start writing my query name so here I will say create table student I'll try to write it in capital letter and inside this I will use first first parameter or first uh variable right name and here I'm going to use this as we care and let me go ahead and write to 25 character so that basically means name is a field okay and in that it supports variable character you can write numbers integers uh values string anything that you specifically want to write so this will be my first first First Column you can basically say in that way in that particular table second one is let's say I go ahead and uh go ahead and write something called as class okay so I'm writing the student information in which class he or she may study um and this class will also be a Vare and inside this I will go ahead and write this will be my two 2 25 characters okay and the third parameter I'm going to specifically use is something called as let's say I'm going to write this as section so this will basically be my section and here also I'm going to use my VAB and this will also be 25 character so once we do this we will close this entire command that the query that we specifically have so simple query initially we'll just go with simple one so that you'll be able to understand it so sqlite 3 wasn't in requirement file Yeah by default with python 3.10 cite 3 comes installed so this is going to work okay I've already tried it out fine we have done the table info over here and you'll also be able to see that now what I'm going to do is that I'm going to create this specific table okay so for creating this specific table I will go ahead and write cursor dot execute table okay so this this table info cursor do execute so as soon as this line gets executed this table is going to get created with the name of student okay perfect now we will go ahead and insert some more records okay now for inserting this records how do you write an insert statement so here I will go ahead and write cursor. execute okay let me go ahead and create this multiline comment and let me say that what is the command I will say insert into students student of student student values insert into student values inser into student values and the values will be the three parameters that I'm going to give name class and section okay so here I'm going to use the name as crish then let's say the section or the class that he is probably studying is data science okay and over here you'll be able to see I'm also going to use a section let's say section is a okay so this three information you'll be able to see as soon as I execute this will basically be inserting this record in the data science like with this information the name the class and the section okay so I will copy this entirely so this will be my first record second record third record fourth record five records let's let's go ahead and see with respect to five records okay here I will change keep on changing the data right now when I say I'll keep on changing the data that basically means I'm going to use my second record as let's say I here I will write sudhansu okay so Dano data science and I will say this belongs to section B okay uh let's go ahead and write more over here let me go ahead and write darus so Darius is also in data science SS and let's say he's also in section A okay I will go ahead and write one more record because let's say because is in another section which is called as devops and this is section A and let me go ahead and one more record like the I will go ahead and write thees and this time I will keep thees also in devops okay and let let it be in section A so this information I am probably inserting in in this specific table okay all this information will be basically inserted in the specific table now as soon as it is inserted we will display all the records okay here I will say print the inserted records are okay and let me go ahead and write data is equal to cursor. execute okay and let me go ahead and write this triple code statement so that it can be multiline also select star from student okay the table name is capital so once I probably execute this I will have all the information over here in the data and then what I will do I will write for Row in for for Row in data I will go ahead and print my row okay so this is what we are going to do so this becomes my entire query with the help of Python programming language where I am creating a database I'm creating a table I'm executing this particular table info I am inserting records I'm displaying all the records everybody clear with this can you get me can you tell me whether you're able to understand till here quickly come on let me know till then I I'll drink some water yeah everyone come on quickly yes or no sudu says yes Prashant says yes what about others come on guys you are not implementing is sad you know so if you do not show interest then there will be no of doing this live session right div also says yes what about others 84 people are watching please do hit like let's make it a target of at least 100 likes in this session you know because if this session we teach in some batch you know it'll be so fruitful for us come on we are doing this completely for free for the entire Community you really need to show some proactive measures okay either be active otherwise drop off if you feel that this is not important for you okay done perfect now let me go ahead and open the terminal and now this time what I will do I will execute this file and let's see once we execute this particular file that basically means uh we will be able to see our database that is created okay database that is created so in order to execute this file I will go ahead and write python sqlite dopy okay so if I execute this my data should get created my table should get created and at the end of the day so here you'll be able to see right at the end of the day One DB file should be created over here and the name should be student. DB okay so let's see whether we'll be getting any error or it'll just execute perfect the inserted records are chrish data science a sudu data science B Darius data science a vikash devops a the dev off say so student. DB file is also created that basically means my insertion has happened perfectly well right now all the data has been inserted into my DB and this is the student. DB file that you'll be able to see now this completes our sqlite insert some records Python Programming this completes our first step now in the second step we will try to create an llm application and now the same DB see that DB is already created now what my llm application should be able to do is that whenever I give some English text it should be able to retrieve the records from those database you may be thinking how that will be possible I will just show you just stay along with me and code along with me right step by step I will show you each and everything okay so just be along with me and just stay over here right so let me go back to my code and now I will start writing my code with respect to this uh in my SQL py file now this file will be responsible and again I'm repeating this file will be responsible for creating our llm application okay so let me go ahead and write first of all we will go ahead and import from EnV import load. envv okay and then to load all the environment variables I will go ahead and write like this and let me go ahead and write take environment or or load all the environment variables okay and that is the reason we have also installed those now the next thing is that we will go ahead and import streamlit as St we are going to import streamlit I'm going to import OS I'm going to import OS along with this I'm also going to import site 3 okay site 3 because we are going to specifically use this again and then I will go ahead and input from Google dot generative AI import gen okay so I'm going to use this gen and as usual first step is to set our API key so in order to sorry import as okay as J now in my next step what we are going to do is that we going to configure so here I'm going to write configure gen AI key okay so for this I will write gen do configure and here I'm going to specifically use my API key so here I will go ahead and write my API key is equal to OS do get EnV os. get EnV and here I'm going to give my key name okay so whatever is the key name and you know that my key name I've kept it as Google API key okay perfect everybody clear till here are you following everyone come on let me know whether you feel following each and every step yes yes or no so till here I have set up the environment variable okay now is the main thing that we will start our coding with so if hit like if you're able to understand till here and uh you're able to follow each and everything with respect to sqlite SQL everything that we have actually created okay perfect now let me go ahead and show you the next step what we are going to do over here now okay now we'll try to create a function function to load gen AI generative AI model or Google gin model Google gin model okay now one thing that you really need to understand two information will definitely go in this function right The Prompt that we are specifically giving and what the Google gin model needs to behave like right so over here I will create a function and I'll say getor Gore response and inside this response I will give my question and prompt like what what the gini pro model needs to behave like okay this prompt we will be writing question is the input that we are giving let's say if I go ahead and ask hey how many people are there in the data science batch right let's say something like this so so let me go ahead and create model is equal to gen do generative model so this will be my model Now understand one thing over here we're going to use gini Pro we are not going to use gin Pro Vision gini Pro is for text gini Pro Vision is for uh images video frames and all so here I'm going to specifically use gin Pro and then let me go ahead and create my response my response will basically say model dot generate content and now this is the most important thing I need to give two information to this right the first is that what the model should act like so for that I will go ahead and create my prompt I'll give the first parameter as prompt and this will go in the form of a list so prompt the second thing that I'm going to probably give is my question okay now I can also give multiple prompts if I want okay that also I will try to show you like how multiple prompts can also be given okay so this is what my model is B basically given so I will go ahead and write return response dot response. text okay so here this entire information so this model will be responsible in giving the query okay let's say if I say that hey how many people studies in the data science batch or data science class so this entire function will be responsible in giving you the query so function to load Google jiny model and provide queries okay as response so this is the function that it is going to do understand one thing right because first when we hit when we write any input our llm model should be able to generate the query and then that query will get go and hit to the cite database where you get this response right so I hope everybody is able to hear till here right so guys there is no such prerequisite for Google gin Pro you really need to know Python programming language and you should know how API is basically used over here right so can I get a quick yes if you're able to understand till here and why I have created this specific function okay just give me a go ahead and please keep on hitting like at least we'll try to make it 100 in the live session itself and understand at the end we are also going to have some live discussion you can come and ask me questions by voice and I'll be happy to provide a response to you okay now this is what we have done now second function that we are going to create function to retrieve query from the database okay so this is what we going to do in the second function so for this let me go ahead and Define my function so here I will write definition read SQL query okay the first parameter will be SQL right whatever SQL query this model gets create this model provides a response as and the second parameter will be my DB name right whatever DB that I have now if you really want to convert this into a rail World scenario we can just make sure that we can put our databases in the cloud and how to read it and all already so many videos has been created both in my YouTube channel and in ION channel also so you can probably go ahead and watch in that specific way but here the main idea is to integrate multiple tools and show you how powerful an llm application can be with the help of Google mini pro now the next thing will be that I will try to create a connection so sqlite 3 dot connect I will write and this connect will be with respect to my DB okay and then I will go ahead and create my cursor so let me go ahead and write con do execute sorry con do cursor I will try to create my cursor now this cursor will be responsible in executing our query right now what query the SQL query right and once I get all the results once I execute this uh uh you know the SQL query inside this itself C dot if I do fetch all it is going to fetch all the records with respect to that right so this is the prerequisite that you really need to know a brief idea about how you can work with SQL databases and this will basically be my row okay I will get all the rows over here now to retrieve or print the rows what I can do I can write for Row in rows I can print the rows so that you can also see the rows over here what all records I've been uh generated okay um the next thing what I'm actually going to do is that return all the rows okay return all the rows perfect everybody clear with this yeah yes so this is the the function which will be retrieving the query from the database so whenever I give a SQL so in short what is happening the output query that is getting generated by this model it will get sent to the database and from this database we will get the records okay so this is done now this is my function that is got created right now now the next step what we are going to do is that do our setup of a streamlet app now before doing our stre setup with respect to the streamlet app this will be the most important step that is defining your prompt so now we are going to Define your prompt now this prompt because of this prompt this entire application will work so efficiently trust me in that it will work very much efficiently right now what is the specific prompt that I'm going to create and as I said I can create multiple prompt so I will give it in the form of list okay so my first prompt let me go ahead and use triple quotes because it will be a multiple prompt itself okay I'm going to copy and paste one important prompt that I have written over here now this is the main game of the prompt guys without this you won't be able to write or you won't be able to make the llm work in a better way so here what is this prompt all about see you are an expert in converting English question to SQL code or I can also write SQL query okay converting a English text also you can write question also you can write to SQL query the SQ database has the name student and following columns name class and section for example example one how many entries of records are present the SQL command will be something like select count star from student right similarly I can go ahead and write example two let's say I go ahead and write example two so this is just one query understand one thing guys this is just one query right I can write like this multiple queries so this this is my example one okay let's say I copy this in a similar way and I go ahead paste it over here okay let's go ahead and write example two you can write many number of examples as such uh let's say how many how many people how many students study study in data science class if this is the query if this is my English statement query tell me what will be the command select count star from students or let me just change this okay tell me all the students studing in the data science class right so in this case what will be my query my query will be select star from student where class is equal to where class is equal to data science data science I have written it in small right where class is equal to data science so I will go ahead and write it over here okay so this becomes my query right and we will end this query also like how we have end it over here right like a colon something like this so this is also ending in this way right so now I hope everybody will be able to understand this yes you are getting it right and after this I'm also saying also the code SQL code should not have this kind of in the beginning at all I've given some more additional statement for the clean one okay does this make sense everyone yeah so this basically is your prompt okay and let me paste it over here so that you can also work accordingly with me so this is the entire prompt see okay this entire prompt has been divided into multiple sections okay just see to this okay but this is how things are I'll will give you some time go ahead and write this okay go ahead and write this because this will be the magic this is the most magical thing right and that is how you'll be able to see that how powerful these llm models are right so here you can see you are an expert in converting English questions to text or English text to SQL query the SQL database has the name student and has the following columns name class section for example this how many entries of records are present the SQL command will be something like select count star from student example two here you can specifically use in this particular way right clear everyone okay you want it in code share I will also do it in code share just a let me see whether I'll be able to see in code share or not but don't ch change the prompt okay and don't delete the prompt once I probably share it okay share so I will share the link everybody can copy it from there okay everybody got it in the code share yeah so in that code share I have given this entire thing you just can copy it from there and uh start seeing it okay clear everyone can I get a quick yes because this will be the most important step creating your own prompt right so please do hit like till here if you are able to understand each and everything trust me this is an amazing application by this you will get multiple ideas multiple ideas trust me in this okay so this becomes my prompt now the next step obviously the next step is basically to set up our our streamlit app so let's start our streamlit app and understand this prompt will tell Google J how it needs to add okay so first of all I will go ahead and create my std. Sate page page config and here I'm going to give my page title as text or I can say I can retrieve any SQL query okay so this will basically be my P page config and then I will go ahead and write s. header gemin app to retrieve SQL data okay now I've have given some examples guys see this prompt you can take it to any extent even write complicated queries you know once I probably show you the result you'll be able to understand why I'm saying like this okay now I will create a text box which will probably take the question from my side so here I will write question is equal to st. textor input and this will basically be my input let's go ahead and Define my input and key I'm going to write it as as input okay we can basically write any key according to you then we will go ahead and create a submit button only two things we specifically required submit button and let me go ahead and write St do button and here I can basically write ask ask the question done now if submit is clicked so I'm I'm using one field a text box and I'm specifically using one I'm using one text field text field and I'm using one submit okay perfect everyone yeah everybody good enough everybody can I get a quick yes if you're following everyone okay perfect simple now if submit is clicked I will go ahead and do all the activities that I specifically want okay great so let's go ahead and see the next step now in the next step if submit is clicked I will write if submit I will go ahead and write response is equal to get Gemini response and here I'm going to give my question comma prompt right now question comma prompt if I give this prompt is in the form of list so when I'm going over here I will just make this as prompt of zero the first prompt that I specifically want to give you can also give multiple prompts and by that you can give in that specific way let's say I have three buttons in the first button I want to behave it in a different prompt in the second button I want to probably behave it in a different prompt so here I'll write prompt of zero okay once I get the response I will say St do subheader the response is okay and then I will write for Row in response print row I'll print all the rows okay and if it is printing in my field let's say I will go ahead and write something like this St Dot header and I will display all the row elements over here done guys almost done now it's like whether this will work or not we need to check if it does not work we need to play with this prompt okay remaining all code you know see first step is probably taking with respect to get Gemini response based on question and prompt it will generate a SQL query and that same SQL query uh what will basically happen over here so question and prompt response what I'll get over here just a second I think um get Jin response generate content and then I have to probably go ahead and read my SQL query okay so just give me a second wait wait wait wait wait wait I will get the response and I have to probably call this read SQL query because here it is not getting called so I'll go ahead and write my response read SQL query now inside this SQL quy I'll give my SQL whatever SQL response I'm getting over here comma whatever is my DB name my DB name is basically what student. DB student. perfect now I should be able to get the response I guess does this look good everyone yep everyone second is the response of it response now let's see whether it will run or not DB is student. DB perfect now it is clear I guess response is also there this response it will go over here and do done now let me go ahead and run it and I hope so it runs absolutely fine if it does not run we'll try to debug okay so in order to run it I will write streamlet run SQL dopy so this will run let's see now here is the thing let me go ahead and write a require tell me the student name and data science class let's see I will go ahead and ask this question as you all know how many students are there over here in this particular class 1 2 3 so Kish soans and darus right so let me go ahead and execute this I hope so it works so I'm not getting the response so this is not good oh something is happening oh I did not receive anything why let me execute this once so the cursor did I execute SQL py so sorry it should be s equal py now just a second no it was working fine I guess let me see once again but last time we did not get anything tell me the student name in the data science class if this is not getting executed there should be okay operational where syntax the problem is coming let's see what kind of query it has generated let me print the query also print print print print the response okay I will go ahead and print the response let's see whether we are getting any error or we need to change okay so I'm just doing some kind of debugging guys so please be with me okay we will try to run this select the name of the student where class is equal to data science this looks perfectly fine select name from student name from student where class is equal to data science this looks fine when I executing this DB this DB is there student. DB response I'm giving it over here fetch all okay this is coming as an error let me see why this error is coming execute SQL current dot con. cursor SQL there's some error with the retrieving the query just a second guys connect DB DB name is this one let me see one second let me debug this the query is generated correctly when we hitting this particular database it is not working let me see test.py okay SQL dopy import sqlite 3 and I'm going to use this command let's see it will work or not cursor. execute select star from student let's see DB name is student. DB come on so some error in executing this let me open my terminal let's see whether this will get executed or not Python and once I execute this I will just go ahead and write this three records we'll just go ahead and print this records let's see python test.py from nothing is getting printed why is not getting printed now it should work let's see still not getting printed but it is getting executed select star from student but this record should be visible just a second I will just delete this once and let me go ahead and write python sqlite dopy the record is done student. DB oh student student student I'll close this requirement try printing line number five line number five oh this is fine now let me go ahead and write test.py still it is not getting printed that basically means is not able to read this why print rows let's try this also just a second can rows are coming as empty why student. DB is there I could see over here the insert statement has happened and is displaying all the records okay why it is coming as null select star from student is done while I'm reading what is the mistake over here select start from student I'll I'll try to fix it guys just give me a second select start from student c table info let's see no nothing is coming where did my database go select star from student is my student spelling wrong or what student we need to welcome this gu this helps us to the opportunity line by line yes student just a second guys let's fix this issue oh I feel there is one problem over here let me delete this once okay working for godam says working for me student. DB I will delete this let me create another DB over here wait I will go ahead and write test. DB let's see SQL py this is done now if I go ahead and execute test. py let's see python test.py okay sorry so this should be test. DB no it is not able to read why object is coming so some major error in connection. commit is that so oh is the cursor not closed so that I'm getting the problem I'll do one thing I'll commit the connection so print row and I will say okay I got a problem what was that commit your changes in the database con do commit so here I've have created my connection connection. commit now along with this I will also say CN do connection. close now I think it'll work so let me go ahead and delete this let me go ahead and delete this now I will go ahead and change my name to student now I think it should work I think I did not close the connection that is the main reason equal. py so this is done student. DB is created now let me go ahead and write streamlet streamlet SQL py no I think it should work definitely it should work tell me the students tell me all the students name from data science class let's go ahead and ask the question now let's see quer is Right 29th still I do not get the response now this is here also I have to probably close the connection I guess so let's close the connection here also so I did not close the cite connection at the end Connection cursor. close Okay cursor is over here we don't have to close the cursor connection if it is closed I think it is sufficient anybody prompt is giving the response from stimulate app this worked for me read the S rows for rows in print rows return rows so the same function I think I've written over here for Row in rows return rows so you have not close the connection now I've closed the connection I think now I think you should not have that issue anybody's facing this issue still now once I close the connection I have my student DB in my SQL I'm giving my student. DB cursor connection C for reading I don't have to probably do anything as such so this work for me yes still same data science Capital no no the query is getting created perfectly the problem is in this read SQL query I don't think so I need to write this but I'm just trying it out let's see sqlite May commit and close is done this is also done no no I have the data no so data is getting printed over here see so this was the data that was got printed right let's see once again rerun oh now finally now I get the response see so I just did this I just go ahead and write it okay so I have to close the connection over here also okay so now you can see Krish sudhansu and darus is visible minor mistake I can understand but again a good error to fix tomorrow if you get any error over here you can probably check it out okay everybody got this yeah all happy enough tell me any more queries tell me tell me the CL class where sudano let's say I'll say tell me tell me Sudan Shu I written his full name or not I think I've written just his single name right uh SQL py sqlite okay tell me sudano's class tell me Sano section let's say if I write like this ask the question see the b b section is coming over here and the best thing will be that you'll also be able to see what query it is generating select section from student where name is equal to sudhansu right and here you can probably clearly see right this is this is really really nice right so let's see what CL tell me the class of vikas and dpes whether it'll be able to write this queries also or not we'll see devops tell me the class of vikas and D devops devops see now how many queries see select class from student wear name in vikash and thees so this is good right see this kind of queries also it is able to generate now the more amazing thing we basically write in the prompt template right in the prompt more complex queries we specifically write and here you can probably see vas and thees was in devops right tell me the student name from section A Krish Darius vikash Dees everybody sudhansu is missing so sudhansu is another section I guess see sudhansu is in B section so did you like this project guys everyone so if you liked it please do make sure that you hit like and uh yeah between there was some challenges because I did not close the connection okay it is good to close this specific connection okay uh so close this connection make sure that you close this connection okay otherwise you'll get an error because see if you don't close this connection right the DB will be open right and uh there you'll not be able to do it now the most amazing thing is about how you write this prompt in a better way you can check with Google bar you can check with different different ways you know whenever you write a query you'll be able to and this definitely works for advanced advanc SQL queries Also let's say if there are two tables and all you can also probably write it over there tell me any query any complicated query that you feel that we can write and try it out um tell me all the students who are from class data science who are from section A and B let me go ahead and write in this way from section A and B I think this should this should be an easy one itself I don't think so it'll be the response is Krish sudans darus Vias dipes okay let's say if I probably go ahead and write one more column name like marks I can still write more complicated text over here right let's see okay fine marks also will do it okay so I will go ahead and create one more one more marks and this will basically be int and what I will do I will just go ahead and create this once again so let's say marks will will be over here as 90 100 uh darus I will write it as 86 because I will go ahead and say 50 the I will go ahead and say 35 okay so I will use this all and now let's see whether this will work I will delete this database control C C python site. py so the database is created now let's go ahead and run my SQL query so streamlet run SQL py now tell me what sentence should I ask tell me all the student name whose marks marks is greater than 90 so if I ask this query will it work sudhansu see sudhansu it is basically showing so let's go ahead and see the query greater than 90 how much I have got 90 see greater than or equal to 90 I sent and my name should also come right if I say greater than 80 uh there is one question hello from the generative AI course starting next week how often will the doubt section be checked I noticed the community version has not respond to often see right now we have come up with an amazing support uh system so every day within 24 hours you'll be able to get the response okay every day within 24 hours you'll be able to get the response so guys this is amazing right happy now you write any complicated queries just give some examples over here right so Kish sudans and Darius is having greater than 80 if I probably go and see what is the query that is generated here you can probably see select or I I I'll I'll just do something okay greater than greater than or equal to 90 and less than 50 let's see whether this query is also possible or not okay here now the problem is because we have not given those kind of scenarios I don't know what select name from student where marks is greater than or equal to 90 and marks is less than 15 this is good but the but the column name is is what let's see the column name marks I think this should have got executed oops select name from student where marks is greater than and marks is less than 50 okay both the condition is not getting matched less than 50 we had one right thees okay please ask to give rank on basis of marks tell me tell me let me do one thing Marx is greater than or equal to equal to 90 greater than or equal to 90 greater than less than 50 okay and uh less than so I have written the condition in a way that I have to reverse this okay till let's try this one tell me the student rank tell me the student name based on Marx rank let's see I try like this something like this again you can try multiple things so see sudhansu Kish Darius vikas and dipes this is nice let's see the query select name from student order by marks so previous condition I'll say tell me the student name where marks is lesser than 90 and greater than 50 see darus is there okay if I say marks is great greater than 90 or lesser than 50 let's try this also so danu should come and thees should come Perfect all good everyone tell me students having marks greater than also tell me the number okay yeah you can write this fetch me the topper of all the classes fetch me the topper of all classes see section B Sudan is the topper vikash why it is showing devops a branch yeah uh fetch me okay one more give me the third highest rank by sudano let's see give me the third highest rank third highest rank marks usually this is an interview question okay there is an error let's see what it has generated operational error mhm first I'll print the response wait over here some error has come over here so uh print response get Gin response select name from name section marks over by as marks from table as table where rank is equal to three so this is the problem guys right so let me write it in a better give me the third highest rank give me the name give me the student name of third of third highest mark something like this Darius right so here you can probably see Darius is coming now so this way so we also have to write prompt in a better way right so here you can see select name from student order by class limit 2 comma 1 so Q song says one more way of writing this query tell me how about tell me who is the third best student on marks Darius perfect so this is working really good oh my God this this is nice people are creative in writing prompts okay so this is can you provide a list of student categorized as first class if their marks are greater than 60 and categorize the second class if their marks are between 50 and 60 so let's ask this question first class Kish first class sudhansu first class Darius let's see the query the query is quite complicated in this so here oh big nested quer is there select case where marks is greater than first class then marks is between 50 to 60 second class else null nice see the output is coming up try to run the rank with the table name uh s give the query give the prompt it will be better but this is nice guys see this so complicated query it is being able to give the marks over here will this replace human why it is going to replace human see first class first class first class Vias is second class give me the second okay give me the give me the second last rank student name from student table so danu second last rank second last rank it should be select name from student why is giving error let's see if it's a let's run this give me the second last rank student name from student table near offsets I think some error is coming over here let's see now it is getting complicated writing so this query may not work select name from student Group by null order by count so this makes me feel I'm learning SQL for 3 months okay perfect anything other than this you want to try everyone one so hit like if you like this video and tell me how was it did you enjoy shall we do the deployment for this everyone wants to do the deployment so let's go to hugging face okay go to spaces and create a new space just let's go ahead and write text to SQL generative AI generative AI okay text to SQL generative AI license you can probably use Apache License streamlet I'm going to use and this provides you uh CPU basic uh 2 CPU 16GB free public and all I will go ahead and create the space now for this what you really need to do is that I will close this till then I will close this I will rename this particular file SQL to app.py app.py oops okay I'm just going to rename it because this takes app.py and requirement. tht is there okay I will go ahead and open in the reveal in the file explorer and I will go ahead and create this space please match the requirement okay text to SQL okay go ahead and H what is happening no spacer text to SQL generative AI let's create this space now after creating the space what we can specifically do so this is the space that has got created I will go to the files and here is my entire file so I will go ahead and upload this three files student DB this this this okay so I will go ahead and add upload files and probably drag and drop these three files okay so this is dragged and drop I will go ahead and commit the changes to the main so here it is now you just go to the app it will start running it internally creates a Docker the deployment of this llm app will be very simple uh the DB is there obviously in the real term scenario we have database is in some Cloud so when we are using Docker we have to probably give the IP address and all okay so here you can probably see that everything is happening in front of you the installation of requirement. txt and all so let's continue this very simple so guys overall everything is good did you enjoy the session yeah so application startup let's see if everything works fine this is getting builded once this building will be happening and you can probably execute it okay I hope it was fun okay now we'll have a doubt clearing as soon as this application works all good the streamlit app is running m is not running let's see so here it is now just let's go ahead and write the query what query was that last I had written okay everybody was giving so many different different queries right so we'll run one of the query let's run the more complicated query okay can you provide a list of student categorized In First Class second class and all I think this should work absolutely fine oh one thing is remaining this will not work I have to go ahead and put my API key okay so if you go down in the settings so just click on settings over here and there will be something called as Secrets right so I will go ahead and create a new secret my secret key name will be Google API key I will copy this paste it over here and we will go ahead and paste this also over here the value and I will remove the codes save it okay this is done now let's go back to my app now again it'll build and again it'll do all the installation again as soon as I probably do each and everything that is required okay so now this is my input okay now I'll paste it over here oh not this what I was pasting I will paste this query so this is the thing can you provide a list of of students categorized as first class so I will go ahead and ask this question it should be able to give me the response okay your default credential were not found to set up default credential this is that why this is not working let's see it should work my settings is there and Google API key save it over here let's see again let's see whether it will work or not till then uh my team will provide a link in the chat section if you want to join and ask any queries that you have you can specifically ask me okay so Prashant you can share the link in the chat okay okay perfect guys it's running so it's running in the hugging phas as I said in order to set up the secret key just go over here down there will be something called as secrets and variable create a new secret write the Google API key and write the value over there that's it okay and here is the entire app it is working absolutely fine okay perfect everybody yes yes yes yes yes yes yes yes or no please make sure that you write the quote over there okay okay guys so please join with me in the session and I will allow you to ask any queries if you have but I hope you like this session altoe guys yes or no so if you specifically want the code uh the GitHub link I will provide you the GitHub link of the code over here okay so go ahead and join the link guys if you have any question if you want to ask me anything and regarding all the paid courses in n neon you can probably see the description of this particular video so we are coming up with Gen AI course mastering generative AI machine learning boot camp uh in both in English and Hindi we are coming also with data analytics boot camp and mlops production ready data science project everything is basically coming up you can probably check in the description of this particular video check out the course and if you are interested right because this kind of projects what I have actually discussed right now this is still I will say basic to intermediate we'll still discuss more advanced project when we are doing in the course itself okay so yes this was it so how did you like the session first of all was it good bad yeah yeah Vishnu Khan please go ahead with your question mishuk Kant can you hear me unmute yourself vishant Vishnu Kant if you have any questions you can ask me okay what about next people who want to join hi sir am I audible to you yeah tell me sir my question is that how to fix that response error which you have fixed I was trying to fix that still it's not showing the response response first of all see whether your SQL quer is getting generated or not is it getting generated no sir then I would suggest just check the GitHub link that I've actually sent with the code okay try to run that code once okay okay I've sent you the GitHub link so this is the GitHub code that we have okay so just try to run this I will try to edit this over here itself in front of you sure whatever things we have ran everything I'm going to put it over here okay uh SQL light. py so this will basically be my insertion database I will commit this up I'll commit this changes and uh in SQL py I will go ahead and use this code that uh I have written app.py okay so you can go ahead and check it out okay sure sir yes please next question yes jbin AI will be able to generate images yes yes it will be we have discussed about that in the last session yes the session was informative live coding session helps us to understand in a better way I would appreciate if you could continue adding more interview questions and answering videos sure I'll do that any more question guys if you want to probably join please make sure that you join the link that is given by our team okay okay if you want to talk with me if you have anything as such you have to go to this link and you can join it along with me okay yes any more questions guys just go ahead and ask very good everything is fine so please create one more session for generative AI images okay fine I will try to create that in my next session we'll try to create a health management app okay and then we will work on that sir please can you tell gen is in job oriented course yes obviously whatever things are people are using in the industry that same thing we are teaching in the course okay is gini better than chat GPT I would still suggest I'll say suggest that many people we cannot just come to a conclusion right now okay we cannot come to a conclusion right now with respect to that but when the high Advanced model will come then we can probably see so guys use the link that is probably given over here we have put that in the comment section you can join directly to my streamyard and here I will allow you to probably talk with me and if you have any questions we can discuss please go ahead join the streamyard link and if you have any question you can ask me I said right what are the timings of the generative AI course so if you probably see over here if you click this link the timing is given 10 10 a.m. to 1 p.m. IST okay every Saturday and Sunday this course will go for five months yeah STI please uh tell me your question uh sir K great talking with you uh I enrolled for gender course uh for python uh actually as a beginner I just know till oops Concepts not much in data structures and uh much more advanced concepts uh even I'm not a developer I am from uh nondeveloper background and just doing some uh like manual testing and all uh will that help me this gener course can land me other than testing uh jobs just want to know yes ma'am so the thing is that the more first of all the prerequisite in our course is Python programming language so that is the reason we have given already recorded videos also in our curriculum okay the more you go become better in Python programming language the more better courses you'll be able to I mean the more better projects you'll be able to develop okay so I would suggest still focus more on python and then probably start learning all these things and how to create uh entire llm application which you need to focus in the class after that try to do some internships try to do try to see in in your work can you do something something related to that you know all those things will matter okay actually actually I enroll for this course because I don't want to be in testing domain anymore so uh if even if I am not a developer uh can I get some hands if I get handson in this project can I switch my from domain from testing to any other yes ma'am but again you need to follow some steps over there you know do multiple projects see currently in testing also many things can be used llm task can be used that is what I'm trying to say you know so if you're able to use this that experience you'll try to put in your resume okay if you already working that is what I meant but yes definitely there is an opportunity with respect to that okay if I if I am not able to understand how to put this knowledge in testing can uh get get can I get mentorship from Team uh so that I can implement this in the classroom we'll discuss of those kind of use cases see right now I did I I'm not a let's say I'm not a good SQL Developer but still I'm able to write queries right yes sir from this application you saw right now in testing also you you have you do manual testing you do automated testing right yes so in that also you can do something with respect to that there are lot of different different things which you can specifically do with this llm models okay sure sir sure daily I will be waiting for your videos okay today Chris will be giving new video on which topic I'm curiously every day waiting for your videos your videos are so great and helpful thank you ma'am thank you thanks Kish this mju here yeah hi mju yeah so what I'm looking for is like uh I required uh company oriented realtime projects for computer vision and large language which you already teaching but I I'm looking for a project which on computer vision uh thing so will your team will be helping on that already already in our data science uh full stack data science batch we are already doing all those things end to endend projects that are related to computer vision and everything if I want to get only the related to project because I know all the things which is required prequest for data sence I know all the stops in that so now I only want the project so so so so sir I I'll tell you what we have come up with okay so are you able to see my screen yeah yes I can see now here you are able to see my screen right so in I neuron right we have something called as one neuron okay now inside this one neuron we are creating this data science project neuron right so here you'll be able to see computer vision set of projects mhm right so this this entire neuron is specific to projects only right here we are not teaching anything from scratch but instead focusing on solving projects and these are like end to endend projects with deployment okay okay okay so just go to one neuron and there is a data science project neuron sir oh okay Kish yeah thank you for that yes please yeah more question guys I think mju had asked right right now hello yes yes mju okay any more question mju yeah but seriously one thing I want to tell you man you you are amazing honestly speaking like you are making the things like you know anybody can pick up things and become a know any any from any background and they can become a programmer and move to the carer so the way you are doing the way you are teaching is you know you are reaching to the worldwide you are not limited to India like across the world people are recognizing you that that is a level but you need to give one motivation speech like how you came from a know you are from Karnataka from Karnataka so how you grown up how you made yourself know that one kind of know motivation video you have to give like how you built your know profile to to this level like to you can reach out to the world that is really amazing I'm very proud that you are from my state thank you thank you Manju definitely we'll do a specific Meetup where in know closed audience specific office in Bangalore or anything yeah yeah so in Bangalore we have office so it's near uh this brigade and we our building name is Brig signature Tower oh okay okay yes try to come up see at the end of the day U again the main Vision over here is to democratize AI education you know uh the way that we are selling courses because this courses adds values right uh it helps you to get jobs it helps you to make Transition it help you joined multiple other I spent a lot of money and learning but I see always I get a very small like you always do in the jupyter notebook know jupyter notebook thing is a outdated stuff like where you cannot use it in the company now we are moving to the you need to build an app company is looking for that because I'm I'm working on that I'm already in the industry I have a 10 plus experience and I'm using it because you need to need to build a app end to end so that that is what industry is looking so there your you stand out from rest of the crowd which you are teaching so that is really amazing continue to do M see we are already coming from that background you know so we know see my total years of experience if I say it is somewhere around 13 to 14 years okay and uh if I talk about I we started at 2019 right so that till that experience we were already 8 to nine years experience specifically me now I know like what things are required in the company working in company getting into a company transition making a transition in the company what in a project what what skill sets you specifically require right so hardly you'll be seeing any Jupiter notebook session but instead we focus on creating an end to end project or a module you know which will be very much applicable in the sessions but thank you for your uh amazing words that you have actually said uh this is really Heartfield you know because I I hear from the people who are in us and Australia different countries right they they speak they watch your videos that's you know from such a background like where you are reaching today that is really amazing it's it's inspiration for everyone you know thank you thank you mju again at the end of the day I need to add values in others life and that is what we our team in auron are doing with the same vision we are working on thank you uh hello yeah yes sh sh yes sir actually uh so what we are doing is generally uh we are fine tuning the llm and based upon our own data set and we are getting that as some text okay so is it possible to integrate the uh you know so Panda's AI so to get that plots uh sir I will just have a look onto the Panda's AI I I've kept a point over here first let me explore that you know so once I probably explore that then I can definitely come with that thing okay so first of all let me explore because I've never explored that Panda's AI okay it is a kind of yeah sure sure thank you yeah yeah good evening next question sir can yeah sir can you create some Transformer projects or you explain the two hours transform how it is going on attention can you create some projects sir so I seen your YouTube channel because uh llm and lstm projects is not there in your playlist uh can you create some projects within two weeks I mean or else this month sure sir sure definitely I'll do that sir you are creating the so many projects right can I can I do that projects to I mean fin year projects like fin year projects yeah yeah you can do it you can do it I mean how to uh sir in my laptop you said that K python version 3.10 right K is not available in your laptop it you have to install sir I install anakonda sir but you have not you may have not set the path that may be the problem the default path will be there now that you have not can I use can I can I so without see if you try to do without K it is possible by using pip but again there'll be a lot of clashes within your environments it will not be at one specific place you know where all the tracking of those environment is done so it is a good idea to in your YouTube channel sir actually I did not see this actually I did not see this live uh you upload one video on the morning right I seen that two hours video uh I follow your YouTube channel very much as compared to this uh can I uh downloading that uh K it is there in your YouTube channel yeah it is there but don't worry I may also create another video where you can directly use Python and create an environment okay okay can I see the okay sir I'm not created yet I'll create those videos I'm saying yeah no sir you to this I struck in the starting only sir I entire thing I writing the notes because I struck there when I stuck there I did not come the interest to go further so I writing the notes so that's why I'm asking the doubt okay don't worry see it's more about creating python environment if you hm V see I'll I'll show you one link over here okay just give me a second sir one more idea is uh iuran you are connecting that 16,000 right sir mean gen CES mhm 16,000 5 8,000 huh sir that much money I did not bother sir because my friend also want to contribute me can I both join ion sir just talk to the just talk to the team like let's see what team can actually do okay just talk to our counselor team how how I want to contact to the team sir uh see in the website itself right you will have the number see over here talk to our counselor bottom their number is given you can talk to them okay so see over here creation virtual environment uh this entire documentation is given okay you can use this and create an virtual environment just follow the steps automatically you'll be able to do it okay okay sir I don't know the internal parts how YOLO is working from where I want to study that wo V8 that all I don't know I mean where I want to study see YOLO documentation is given in a amazing way over there if you have seen YOLO V8 right if you see this specific documentation right I think most of the things are given step byep installation everything is given over there but don't worry in ion no we'll be coming up with live classes with respect to deep learning also okay from YouTube paid live session in paid code also if you want to join there is already but in YouTube also we'll have live session going on okay yeah can you explain you sir how internal parts is working math behind that sure definitely okay thank you sir thank you yeah thank you yeah next question hi sir yeah hi Hari uh sir uh yeah nice to meet you sir sir uh I have a question so in machine learning and deep learning how we use uh graph modeling sir I mean uh I uh I mean I I saw the one article regarding graph modeling but depends on what kind of use case right graph modeling can be used in multiple use case uh it is AA fraud detection uh I mean like that so see again you can use this techniques but sometimes right you also need to think which algorithm is very much feasible to use with respect to a project okay okay yes your uh uh the algorithm with respect to this will speeden up the process but again try to understand this I've not yet created any videos with respect to that you know let me have a look onto that and see if I'm able to create one project I'll try to upload that in my channel okay okay sir actually uh I mean uh last couple of uh days weeks I watched your video sir and uh uh I uh mention those uh project Basics projects regarding the generate U uh in my uh resume and I I got a call I mean the interview call and I clear the first round I have technical rounds right now and so I I don't know exact exact I mean how how we'll go so can I get the some I mean like knows like how the interview is going to go always make sure that when you have a technical round prepare well your projects right it should be till deployment what all things you have done in that you have to explain that properly so that you know you guide the interviewer what what should be the next question that he should ask you know try to try to make sure that you have the control of the interview not the interviewer you know so the information that you have portraying in front of him right try to provide him some some things that you have actually done which may be something new for him because see interviewer would like to just understand that what all things you know so how well you specifically speak with respect to a project the more the better it is okay okay sir actually I uh I enrolled the I mean Genera a clause sir uh I mean the but I mean I I mean l i mean the S I mean sa also teaching the generate UI I mean the community section so I watched those videos and I took one project uh I mean he I mean what he's teaching and I uh mentioned that project in my resume and I'm not expert in a Genera right now so I'm very scared of that what how will go the don't be don't be scared of it see if you know how to use apis that's it you just need to be scared whether you know Python programming language or not the more better you know Python programming language the more better you'll be able to create this llm application okay okay sir so don't worry see anyhow you are in the course and uh when you are in the course you don't have to worry with us okay okay sir yeah thank you sir yeah next question please hi sir rendra rendra you're my inspiration basically to be frank sir can you make some in your playlist based upon llm sir large language modules with python custom gpts from scratch you're saying yeah yes sir see I will take llama 2 model okay so llama 2 is there it is a very good open source model on top of that I will try to show you fine tuning okay by using this or clor method okay yeah okay sir and I have one doubt sir regarding YOLO before doing NM I mean non maximum sub Su we do some something called we do sorting desing order before that we do something we give some threshold values and if it is less than 0.3 threshold threshold we we make it as zero Suppose there is a some small object tiny object is there suppose there's a tiny object which it has a score of 0.2 in the sense so we may lose the data in we may lose the data in that case so rinda just give some days okay what we will do is that we'll try to create a dedicated video for that okay I'll tell my team also with maths don't worry everything will broke break break into math smaller smaller parts so that you'll be able to understand okay directly explaining right now will be difficult so let's wait for one video okay from our end yeah I purchased the dlcv NLP from inur sir I have completed the course I have completed the course I have this this just have qued to the neuron support team and one small can you explain da data argumentation see data argumentation is like let's say you have one of my image okay now to train a model you know what I can do is that I can change my face like this like this and give the model give the model different different images to identify me data augumentation what it does is that it takes all the images it tries to horizontally rotate it vertically rotate it expand it zoom in zoom out so it tries to creat a variety of the same images so that the vision model whatever Vision model you are actually creating it'll be able to understand that image very much easily so you're just trying to create multiple images by applying some techniques some transformation techniques where it can probably zoom in zoom out horizontal flip vertical flip it can do multiple things in the image and create a new one okay uh the day before yesterday I was doing a project based upon deing sir I was trying to read I have created a folder and I created some dogs photos of dogs I have downloaded and some photos of cats when I was trying to read that in the collab it's not getting running it's showing an error for me sir why better drop US mail to the support provide the collab link over there okay and let them have a look with respect to that okay so we have a dedicated team who will take care of all these things okay try to do L from python thank you sir that's yeah thank sir I sir I have one question sir uh currently Vision language models are coming up are you going to include that in our course generative course sir mean I'm not sure whether the document papers released or not but Vision language models are coming up right so are you going to include that in generative course yeah sure see the thing is that at the end of the day whatever things are coming in generative AI let's say the vision language model you basically saying large image models right so uh the gini Pro Vision whatever functionalities whatever projects will be developing over there also we'll take that in the class H okay sir and I heard one of the uh student asked that about python may I know what level of python is required sir because as I asked you before data structures and algorithms I am very poor at data structures and algorithms until what level I have to Learn Python may please the python you definitely need to note in modular programming language you know oops inheritance classes all these things that is the reason we have given that as a prerequisite along with that we have given the entire recorded videos in the curriculum okay yeah I'm aware of till oops sir but data structures and algorithms like in advanced uh tree graphs and all uh is that will not be required to create projects okay that will not be required okay sir thank you and in in Project do we get some real time industry level uh how they are using all the deployment techniques we'll teach you all the deployment techniques you know what all things are currently happening and in the future let's say when the curriculum is going on when the course is going come when anything new comes we will also take care of that you are going to add in that course sir not add but at least we'll discuss that modules in the last okay first we'll complete the entire curriculum and then we'll try to include that yes definitely I want to get into this uh generative uh field because I have only the hope is about this only this course sir after this course I I don't have any other way to switch to in testing I have only hope is this gener course sir I try your best yes sir thank you sir thank you okay guys so it's already 10 so 2 hours of session I hope you like this session please do hit like uh and as usual uh keep on supporting and again I will be coming in the next week Friday live session we will be discussing more about amazing projects and all uh again let's see what all things are basically coming till the next week I'll come up with that and we'll have a good one so thank you this was it for my side so if you are new please make sure that you subscribe the channel subscribe all the Ion channel share with all your friends share share share the post like whatever things you specifically do tag me over there I'll be happy to answer or probably comment down like what kind of works you have specifically done uh yes uh at the end uh I would always like to say one thing guys uh see there are new things that are coming in the market right the reason why we are teaching all this new stuffs is that it actually increases your effic efficiency productivity at the end of the day the more you work the more you put effort the more you become a successful right you go in any company you go anywhere right the more knowledge you gain and trust me in anything that you do in your life if you spending two hours in learning if you are spending three hours in learning if you are not learning also right some or the other thing you specifically learn with respect to each and everything right and one more thing that if I probably talk about in neuron right so this in neuron support if you want to really see a real practical example okay so let me just show share my screen so in this example you'll be able to see there is something called as support system right the main llm we have integrated in this entire support application right so let me just go through this so that you get an clear understanding what all things are basically there let's say once you join a batch let's say you are in generative AI so mastering generative AI batch is over here you can join the group in this particular batch right so let's say I'm in machine learning boot camp okay or I'm in this particular boot camp in all the all the batches I've probably joined let's say there is data science interview batch going on okay now you may be asking various question like can we probably communicate with our team members can we have a onetoone session can I probably study in a group so for this let's say I in this specific batch if you go ahead and join over here there is something called a join group as soon as you join group right then here you'll be able to see that this group will be added right let's say over here the machine learning boot camp is over here I've joined this the data science interview back so all your team members will be in this specific group you can ask any question as like as you like you know you can ask any any question as you want right over here like you can probably ping hi all the members you'll be able to see you'll be able to ask any question if you want to probably do a group study everything will be in one platform itself right apart from this if you want to communicate with anyone right if you want to probably communicate with anyone here right you can also do that now see karik Kash basically says that why one 121 support is stopped because this was when we are developing things right so here you can probably see thanks Chris not sure if this is Chis in human or chish the chat bot I'm the human over here right now let's say if you want to get more queries and right now there are many people who pay some pay they pay $20 to chat GPT but by using this Megatron you don't have to pay anything you can directly chat it over here let's say give me the python code python code to create a floss cap okay if I write like this if I execute it I'll be able to get the entire code right so here what we have done by using see over here in the Megatron we have used llm but the other entire application looks more like a WhatsApp message right where you can probably do one to one group chat you can have any kind of discussion now see all the questions are basically there right not only that once you probably go to the knowledge ocean let's say if you have any query right you can go ahead and write the query right so it'll you have to probably select the batch where you are in let's say I'm in mastering generative Ai and I say hey what is generative AI right now before when we were giving the support sometimes because of huge queries we are not able to solve that in 24 hours but now by using the support system we'll be able to solve within 24 hours let's say I'm asking what is generative AI okay and I've asked this question and I post it over here right so here when you go to knowledge session you'll be able to see new to Old what is generative AI you'll be able to see over here wait new to Old this is old to new um let me just go ahead over here in the homepage so you'll be able to see all the queries that people have asked now this is where uh the most amazing thing will be that as soon as you probably click over here you'll be able to see all the responses from the students right large language models are this this this this let's say if some if none of the student provides a response over here then what will happen is that our our llm model will provide the response within 24 hours it will first of all go ahead and filter and see which question is not been answered and then we probably what we do is that we provide a response over here itself right normally none of the vendors allows to talk with other batment in the join course yes but we allow the reason is that people waste their time people waste their time joining multiple groups right someone will be joining telegram someone will be joining WhatsApp and other than studies other than studies you know they will talk all rubbish things right they'll not talk more about studies but other than that everything they'll talk right so this is one specific place where you can have a discussion about each and everything right and not only that let's say you want to provide if you have any queries and you want to probably write a mail to us you can compose the mail here itself you don't have to open a Gmail probably go ahead and write query at theate ion. a or support at theate ion. AI right everything and in the future what is going to happen right in the future you'll be able to see that right now we have this chat right in the future our Megatron will be so strong since we are processing with two 20,000 videos see we have highlighted over here 20,000 videos has been processed along with that it has generated 6,000 question and its answers so any question that you specifically ask either you can get a video or either you can get any kind of answer from our Megatron itself or from our this specific chat B right so that is how strong it is going to have become in the future so at the end of the day this we are specifically doing because you'll be able to communicate with your batchmates you'll be able to do group study you'll be able to do projects you'll be able to do internships multiple things all at one place and if I probably show you ion. every tab that you see over here every tab right this altogether has a complete different story let it be with respect to internship portal let it be with respect to job portal neuro laab neurolab why did we come with neurolab because many people did not have that strong laptop or machine to do the coding so that is the reason we came up with this Virtual Lab wherein you can go ahead and probably uh you know open any IDs probably work with flask work with python it provides you an entire development environment which is running in Cloud so you don't face that specific lag then support system was one of the challenges which you are trying to fix from past two to three years now this is completely fixed and still we are making it much more better you're going to provide lot of features as I said all these things are basically coming over here the best thing is that you don't have to pay any money for this right if you are part of a course you will be able to use this right that is the most powerful thing and again why we are doing this this is for our community we really want to build our community in such a way that you learn you learn in an amazing way and at the end of the day get placed somewhere make Transitions and yes obviously help others also whenever you get that particular opportunity okay so thank you uh this was it from my side uh I hope you like this entire things that I've actually shared okay and yes this was it for my side keep on rocking keep on learning um other than this please go ahead and check out all the courses in the Inon and will be provided in the description of this particular video uh and yes I will see you all in the next video have a great day thank you take care byebye everyone Tata at least say Tata I know you did not ask answer much question over there okay but yes a good happy weekend for all of you out there thank you guys thank you so if you able to see my screen just give me a quick confirmation everyone so we will go step by step we'll go with the agenda we will try to understand many things as such you know topic by topic I will be writing in front of you wherever Google is required I will take the help of Google I will show you research papers and many more things as well okay so let me just see in LinkedIn also whether I am visible or not so I'm just going to see in multiple places uh so I'm excited about this sir as an India llm for large language will be taking flight off yes many many companies are specifically using in use cases and all so it'll be quite amazing so let me see whether we are live ion LinkedIn page or not okay just give me a second okay perfect I can see myself over here there are chats there are messages that are probably coming up okay great okay let me hide the current comment okay so what is the agenda of this specific session what all things we are specifically going to discuss so the first topic as usual is to understand what is generating AI okay so we are going to first of all understand what is generative AI okay because you may have heard about machine learning deep learning you may have heard about natural language processing where does it exactly fit okay so we'll also be able to understand it then after completing this we will try to understand how llms model are trained so what what does llm model basically mean large language model okay we'll also understand what is large language model when we are discussing about generative AI so the third thing we will be discussing about open source we will be discussing about open source and paid llm models and which one you can specifically use if you don't have money enough what you have to really take care of see at the end of the day these all are models okay and uh if you have powerful gpus and is it possible that you can also train your llm model from scratch yes so everything is possible I will be taking up making sure that I'll explain each and everything okay right now the models that are very much famous that are in the industries right now right so you may be hearing about chat GPT right so chat GPT I will just write the model name let's say gp4 right we will discuss about some some of the good open source models like Lama 2 we will be also discussing about gini Pro right why gini pro why gini Google Gemini right I'm not talking about Palm or B Google BS and all right gini Pro um recently Google has launched this three amazing llm models right three versions of gini models right and geminii pro right now is available for everyone out there to use it to create an end to end project and it is completely for free right you can probably use 60 queries per minute you know you can you can actually give somewhere around 60 queries per minute for uh for using it in your use cases yes soon it will also be coming up with uh paid models uh if you want more queries to hit right so it is good to start with all these things I'm just given some list of llm models over here other than this there are a lot of llm models also open source llm models like Falcon Mistral right so I hope everybody has heard about all the specific things okay so let's see how many topics I will be able to cover step by step and if something is remaining again we will continue in the next week Friday session so first of all let's go ahead and understand about generative AI okay so the first topic we will go ahead and discuss about what is generative AI okay so everybody understood about the agenda what we are specifically looking at right agenda we'll also be discussing about large image models also that question will also be coming up okay so there's a question a little bit about llm models and open AI I will discuss about it okay um okay I have a good knowledge of python okay I'll take up questions okay so but I hope everybody's clear with the agenda that we are actually looking at so now let's go ahead and understand with respect to generative AI now before understanding generative Ai and where does it fall in this entire universe of artificial intelligence you know so if I probably consider this as an example let's say and this this diagram probably I've I've taught in many of the classes I've explained you all and all let's let's consider the entire universe and this universe I would like to say that this is nothing but this is this is artificial intelligence okay this is nothing but this is artificial intelligence right and what is the main of aim of artificial intelligence is that whether you work as a data scientist whether you work as a machine learning engineer whether you work as a software engineer who specifically wants to harness the power of machine learning deep learning at the end of the day you creating applications those are smart application that can perform its own task without any human intervention so that specifically is called as artificial intelligence right so what is exactly artificial intelligence it's just like creating smarter application that are able to perform its own task without any human intervention okay so that is what AI specifically means so tomorrow you work as a data scientist you work as a machine learning engineer or you work as a software engineer who wants to harness the power of machine learning deep learning techniques at the end of the day you will try to create an AI application only right some some of the examples with respect to this AI applications as I've already told earlier Netflix right Netflix is one streaming platform let's say movie streaming platform here an AI module is integrated right so there is an AI module that is integrated now this AI module I would like to say it is nothing but movie recommendation system right movie recommendation system movie recommendation right Netflix is already a software product it is a movie streaming platform but we are trying to make it much more smarter so that it will be able to give us or provide us movies right recommend us movies without any human intervention see our human inputs will get captured over there what movies you like like action movies whether you like sentiment movies comedy movies all those information is getting recorded right but we are not asking human to to to take some decision in short this AI app will take its decision by itself right so so this is what artificial intelligence is all about now coming to the second one if I probably consider the second one that is nothing but we basically talk about machine learning so what exactly is machine learning here I will be talking about ml okay now with respect to ml right what what exactly is machine learning machine learning provides you what it provides you stats tools stats tools it provides you stats tools to analyze data right to analyze data to to create models and these models will be performing various task it can be forecasting it can be prediction it can be feature engineering anything as such right but all these activities that you are specifically doing in this I would like to consider all those as stats tools it is provided ing this tool to do or to perform this work right so here you'll be seeing that we learn about different things like supervised machine learning unsupervised machine learning we learn about techniques wherein you create models that models are able to do classification regression problem statement forecasting Right Time series prediction right different different tasks can be performed with the help of machine learning right and machine learning initially what was famous if probably say five to six years back everybody used to probably use machine learning techniques and now also they use it for most of the use cases they use it right but now because of generative AI now they able to think much more with respect to different different business use cases right so at the end of the day with the help of machine learning we are trying to do that okay still now coming to the next one what about deep learning right so deep learning is another part of or I can also say it as a subset of machine learning now what was the main aim of deep learning over here here we had to create multilayered neural network multilayer neural network okay multilayered neural network now multilayer neural network why we specifically require multilayer neural network see we human being wants the application to perform like how we human being think right let's say I want an application to perform like how I am able to teach how I am able to study in that similar way if I want to make a machine also learn in a similar way I have to use multilayer neural network right and that is where deep learning was becoming famous and this is from 1950s but right now we have huge amount of data and if I compare the differences between machine learning and deep learning is that the more data I have and I train a deep learning model the performance also increases the same thing does not happen with respect to machine learning right so that is the reason we are discussing about multilayer neural network and this is where deep learning come into picture and again they are different techniques that we have already learned about you know Ann CNN RNN these are the basic building blocks other than this you have seen about many things like you have object detection rcnn you have YOLO algorithms in RNN you have lstm RNN Gru right Transformer B encoder decoder all these things you have specifically learned that all are are part of deep learning these are solving some specific use cases some specific use cases right these are solving some specific use cases right so this is again deep learning is a part or subset of machine learning okay now comes I hope everybody's clear till here because this I already taught it earlier also to all of you the reason why I'm teaching you over here is to make you understand where does generative I fall into picture so if you if you are able to understand till here please give me a confirmation by writing in the chat yes no something you're able to understand over here right so just give me a confirmation give me a thumbs up okay give me something hit like for this specific video so that it reaches many people to so that you'll be able to understand because nowadays from the students who have already made transition specifically in uron they're working on generative AI they're working on llm application they're creating some amazing application to solve different different business use cases so that is why I am basically discussing about all these things right so I hope everybody is able to understand tiia perfect so I I'm able to get the confirmation they good signs like this and all so everybody uh is able to understand it amazing now let's go ahead and understand where does generative AI fall into picture again guys now if I consider generative Ai and what exactly generative AI we'll discuss in some time but generative AI will be falling as a subset of deep learning okay as a subset of deep planning so this circle that I am considering is nothing but it is a generative AI okay now why it falls why it falls as a subset of deep learning because at the end of the day we are using deep learning techniques also most of the llm models that you'll be seeing is nothing but is based on two models one is Transformers another one is Bert okay these two models are super amazing models I hope you may have heard about something called as attention is all you need right attention is all you need right so attention is all you need there you have these amazing models Transformers and birds this are also called as encoder decoder sequence to sequence models these are the base of many many many gener AI models or llm models that we will be seeing okay so all these things you should definitely know it because these are the basic building block today we have so many models in the market we have chat GPT we have GPT 3.5 we have GPT 4 now GPT 4 Turbo is also coming right you have llama models you have Falcon you have Mistral you have gini right jini Pro you have Google B pal models many many models are there in the Market at the end of the day they most of them most of them I know most of them has this as the base model that is Transformers of bir right and many more things over here now considering this people or companies what they do they train with some different techniques they add reinforcement learning they do some type of finetuning to to make their model become much more better so that is the comparison that is basically made now recently Google came up with with gini Pro so it started making comparison okay it is so much better than chat GPT sorry GPT 3.5 it is so much better than this particular model it is it is able to uh reach mmu of this much accuracy right human understanding accuracy is this much reasoning accuracy is this much all this particular information is basically the metrics right at the end of the day the base that you're specifically using is either Transformer bird in short you're using this advanced architecture of the neural networks and you're training or you're pumping you're training this models with huge amount of data and that is where someone will come and say hey this model has somewhere around billions of parameter everybody will get shocked wow billions of parameter wow amazing nice great we are going to get a good model then right but understand the context when we say billion of parameters that basically means how much how much weights is basically considered how many weights parameter are there how many bias parameter there how many so many things are there there and many more things right I'll be discussing about gini Pro as I go ahead okay and I will be showing you some of the accuracy metrics also as we go ahead once I see reach the research paper but what exactly is generative AI I will discuss about it in some time now there is also one more thing which is called as llm models right where large language models see in generative AI also we have llm models we have large image models L IM okay llm and LM llm basically means large language models that basically means it will be able to solve any kind of use cases that is related to text very much simple so whenever I talk about llm in short we are talking about text whenever I'm talking about large image model we are talking about images okay any use cases with that is with respect to images or video frames or anything as such okay so this is nothing but this is called as large image models right there is one more thing where many people may have heard about it okay and recently gini Pro right it Google says that gini Pro is a multimodel what does multimodel mean multimodel what does it mean it basically means that it is able to solve use cases for both that is text and images text and images it is able to do both this task okay so that is why it is basically called as multimodel right most of the I hope everybody has heard about a tool called as mid Journey which is able to generate amazing images mid Journey right mid journey is what it is an Li large image model right mid Journey it is able to create image it is when you write a text it is able to create an image gin Pro what it does is that you give a image it'll be able to do all the object detection within then it'll be able to write a blog for you right so all amazing things are basically happening now why this is beneficial for companies because companies don't have to waste time startups don't have to waste time to quickly create some applications that solves a problem statement before everything used to happen from scratch they used to create projects they used to create models they used to do finetuning they used to worry about data they used to do multiple things but now it has really becomes simplified okay so I hope everybody is able to understand about generative AI what exactly is generative AI I'll just discuss about it understand this term generative okay and we will discuss as we go ahead di di is a large image model yes di is definitely a large image model yes perfect right so guys still here if you have understood please make sure that you hit like it will motivate me because you want me to come in the next week also right right every week Friday we will do a session where I will be teaching you all the specific things right so do hit like let's target that till the end of the session we should make the like button hit more than 500 okay I want that right more than 500 come on you can do it huh see so nice handwriting in front of you you should be motivated by seeing this handwriting not your like a college professor and writing right I'm using multiple cols making it much more interactive and the best thing is that everything will be available to you I will also upload this um if you Pro probably find in the description there will be a webinar link over there everything I will try to provide you over there itself okay so chat GPT is llm yes chat GPT is using GPT 3.5 GPT 4.0 those are llm models large language models if Chad GPT is using di that basically becomes a large image model okay perfect great now let's go ahead and let's talk about so this is what I gave a brief idea where does generative AI fit into okay now let's understand what exactly is generative AI okay still we are able to Now understand now what is generative AI okay let's let's go ahead I'll talk about Lang chain why Lang chain chain lit Lama index where does it fall first of all let's start with some Basics okay and here again two things are obviously going to come large language models and the second one is large image models okay so let's go ahead and let's discuss about this great now when we are discussing about large language models and large image models so first of all the question question that you should be asking fine Krish what exactly is generative AI why why the word generative why the word generative at the first instance so see some years back we used to use traditional machine learning algorithm see over here first of all we started with something called as traditional ml algorithms okay we started like this so in this ml algorithm what we did is that we had to perform feature engineering we had to probably create a model right train model right we had to probably do fine tuning right right and then as we went we finally did the deployment now from traditional machine learning algorithm why did we first of all move to deep learning algorithm again traditional I'm I'm writing over here as traditional DL algorithms okay now we move towards traditional deep learning algorithms okay why did we move over here we saw that when we were increasing the data set even though we increase the data set and the best way to show this diagram is basically to create like this see so this is my machine learning let's say this is my graph this graph is with respect to two thing data set and performance okay data set and performance now over here with machine learning algorithm with traditional machine learning algorithm you could see that when data was increasing after one point of time the performance of the traditional machine learning algorithm started bending in this way that basically means even though I increased the data at certain point of time right then also my performance was not increasing right but now this was the problem now with deep learning algorithms when I say deep learning algorithms I'm specifically using over here multilayered neural network okay multilayered neural network now with respect to multilayered neural network as I started increas increasing the performance or as I started increasing the data set the performance also started increasing and this was with DL algorithms and this was with traditional ml algorithms this was with traditional ml algorithms now that is the reason deep learning become became very very much famous so most of them started solving problems such as supervised unsupervised machine learning techniques or deep learning techniques or problem statement with the help of deep learning algorithms and now you know right from object detection to NLP let it be any task from computer vision to NLP to any task you're also able to do with the traditional deep learning algorithm right now till here everything was good companies were working nice hugging face had so many deep learning algorithms probably now it has deep learning algorithms for any task that you want any task let it be any any task for any task you have a traditional deep learning algorithm available where you can download the model where you can do finetuning where you can use transfer learning techniques and you can probably create your own application now this is where one amazing thing happened and I'll tell you that was the time you know uh where blockchain was also becoming very famous when blockchain hype was there you know mainly all the people were focused Mo most of the audience most of the people most of the researcher were also focused on web3 but they were also some good set of researchers who are focusing on something called as generative AI now now here is what I'm going to draw a diagram for you to make you understand what exactly is generative AI first of all I will go ahead and write deep learning over here as you know generative AI is a subset of deep learning right now in generative AI with all the traditional deep learning algorithms we usually say this as discriminative now you'll understand what is the difference between discriminative models and generative models so mostly all the Deep learning algorithms is divided based on these two important techniques one is the discriminative technique one is the generative technique okay now in discriminative technique which all task you are focused on doing first most of our task like classify predict right or object detection or any supervised unsupervised technique here the data set these models are basically trained on trained on labeled data set right and this discriminative is with traditional DL algorithms okay traditional deep learning algorithms over here we specifically use traditional deep learning algorithms now let's understand about generative model and this is where your I you will get a clear idea about it what exactly I'm going to talk about in generative models the task I'm just going to write the task here the task is just to generate new data trained on trained on some data okay here what is the main task of generative model is that the word generative now you'll understand the main importance of this word generative here you are generating new data trained on some data set okay example write a write an essay on generative AI if I ask this question it will be able to answer let's say it has been trained with some huge amount of data that is available in the internet now I will go ahead and ask write an essay on generative AI should be able to give me the answer now let me go ahead and talk about one simple example so that you get a clear understanding what exactly I'm talking about with respect to generative AI a real world example because people usually like this kind of real world example okay and with this real world example you will be also able to understand multiple things right so let's go ahead and understand it with real world examp example and that is where you'll be able to understand about generative AI so how does a generative AI task look like okay let's imagine okay Kish is over here okay let's imagine not let's not take Kish let's take some person is over here and this is relatable okay this person is in 12th standard let's say it clears NE exam neat exam and now it is basically doing mbbs mbbs mbbs is specifically for becoming doctor okay now over here you will be able to see that how many years this person will probably learn in the college 4+ 1 right I guess 4 plus 1 four years of learning learning one year of internship so after learning for 4 plus 1 years will it be trained or will it learn from multiple book sources at least thousands of books yes or no will it will this person learn from many books at not tell me guys just give me a quick confirmation can you just read one book and become a doctor no thousands of books right thousand of books right so this person will be spending those five years reading thousands of books and after reading thousand books okay don't fight on the number if I'm saying thousands that basically means many books okay I know some people will say sir how come thousands are in my whole life I did not learn thousand okay many books okay many books so once he or she or this person learns from many books spends those 4 plus one year one year here with internship so internship knowledge is also going to come over there now what is the final aim this becomes the this person becomes a doctor so let's consider this is my chat GPT with doctor doctor chat GPT okay now tell me if you go and ask this doctor any question any question related to any medical problem generic medical problem generic medical problem will you be able to get the answer will you be able to get the response yes yes or no now is it necessary the doctor will say only with accordingly to the books only no it can create his own answer you'll say that hey I'm feeling I'm not feeling well you know I'm having this kind of symptoms the doctor will come up with his own word because he has all the knowledge from all those books all those experience that he has put in his internship all the people he has actually treated in those five years right it will be able to provide the response right so what what what is this doctor right now can I say this doctor can act like an llm model now large language model who is an expert in medicine who is expert in medicine right this is just like a large language model who is an expert in medicine and this is what recently openi is trying to do right what is open trying to do over here openi is planning to come up with something called as GPT store have you heard about this GPT store GPT store basically means what you can now create your own llm models and train it with your own custom data right and on the go you can create this particular app right in open that option is already there right I have also tried it out and it works absolutely fine I will tell those model how it has to behave now here you're spending 4 plus 1 years and you are becoming a doctor now this becomes an llm model who's an expert in medicine now the next step of this doctor is to become an MD now there are some questions which this doctor will not be able to understand which the doctor will not be able to give the proper answer it may give you a generic answer so what we need to do we need to train this llm model again with more data and this time the specialization right you want to become an MD in cardiology you want to become a MD in Ortho you want to become a MD in some other field so that expertise will again G when this person will be trained with more three to three two to three years of books right along with experience where you given those kind of task I hope you're getting it right guys I'm trying to use many more examples that is the most important thing the more examples you see the more well you'll be able to understand so at the end of the day what this doctor is doing it is able to generate its own response based on the problem statement it sees yes based on the problem statement so this is how we are trying to learn it tomorrow all you have to do if you're working in any business in any companies tomorrow what you will do you will take any model you can f tune with your own data set and that particular model can behave accordingly based on the company's use case at once right so this is how things goes ahead right so if you have understood till here please give some thumbs up sign I hope everybody's able to understand please give it a thumbs up say something Krish I'm happy I want to see some happy faces please do hit like please do make sure that you subscribe the channel and I want from every one of you you have to share these videos everywhere right we are trying to democratize AI education over here everybody should know the importance of AI because tomorrow trust me you going to use it somewh the other way right anywhere you are going to use it no one is going to say that you cannot use it you have to use it right many people will say hey there is no job by use it in your personal personal daytoday activities and don't worry about job if you're good at something whether you are from any technology you will be able to get jobs all you have to do is that have that knowledge right if you're able to have that specific things trust me it is very good easy to learn and it is absolutely when you also try to convey this information to someone right then you'll be able to understand that how important all this technology is tomorrow in a company a business use cases getting solved and you provide a solution wherein you don't have to spend much money in those use cases right those people will keep you instead of anyone right and they'll give you most of the problems to solve right so in this way so please make sure that you hit like share with all the all the friends some or the other way someone it may be helpful for anyone who will be learning over here okay now let's go ahead to The Next Step where here we have understood about generative AI so what is the main aim of generative AI the main aim of generative AI is to generate some content now let me talk about some of the use cases right so use cases I will be talking about and use cases we will discuss with respect to both techniques one is discriminative technique discriminative technique whenever the name comes discriminative it is going to discriminate based on the data it will give you some kind of output right some classification problem regression problem something right so first technique is nothing but discriminative technique in this discriminative technique let's say I'm taking a use case I have a data set which which says types of music types of music so here I will try to create a discriminative ml discriminative model discriminative DL model and this work will be to basically classify whether this music belongs to rock whether this music belongs to classical or whether this music belongs to romantic right so this is basically discriminative technique right now coming to the next one which is B basically called as generative technique generative technique let's consider I have a music again same use case only we'll try to do let's say this is my music okay it looks like a hard bit but I'm considering it as a music and this music I will train it my my generative model how the training will happen I will talk about it so let's say this is my generative model and now the generative model will talk askask is to basically generate a new music this is just one use case of generative AI I'm not worried about whether it is large image model large language model and all I'm just showing you with respect to do same use cases what discriminative models will do and what generative models will specifically do right so in short we are generating new content this is super important this is what this is new content clear every everyone happy yes everyone just give me yes or no if you able to understand this things yeah so till here everybody's clear I hope you got an idea with respect to discriminative and generative technique okay now is the main question how llm models are trained now you'll understand this okay guys don't worry Lang chain Lama index I will teach what exactly it is okay how llm models are trained just wait B till the end of this session you'll understand all these things right and once you understand it it will be very good amazing you'll get a clear idea and that is what is my target Target today tomorrow if somebody ask a question related to generative llm models you should be able to understand it okay perfect now how are llm models trained so let me just go ahead and use one open source model llama 2 paper Okay so llama 2 is a model that is that is generated by meta okay So Meta has trained this model and this is the research paper okay this is this is the research paper the reason why I'm showing you this research paper because based on this model only I will teach you how this model may have also trained okay yeah yeah this video will be available in the future in the YouTube in the dashboard along with all the materials that I'm writing that I'm showing to you okay so don't worry focus on the class now over here see there are three important information that you can see from this content okay one is the pretraining right it talks more about the pretraining data it talks about the training data details and it talks about Lama to pretrain model evaluation the next one is it talks about fine tuning see fine tuning here we are going to discuss the supervised finetuning please remember this word okay supervised finetuning super important super amazing technique altoe and I will break down this technique and make you understand how training usually happens everything will be taught in this session then the third one is something called as reinforcement learning with human feedback R lhf please remember this techniques because same technique is also used chat GPT models supervised finetuning reinforcement learning with human feedback along with there is something called as reward system also which I will be discussing so the reason why I'm showing you this research paper because this research paper are very easy to understand if you have some prerequisite knowledge about Transformer about something about some accuracy concept some performance metrics concept if you know that much that will be more than sufficient okay so let me go ahead and show you so if I go to introduction see large language model that is talking about this this this Lama 2 now llama 2 has been it scales up to 70 billion parameter okay there was three specific models in Lama 2 which we'll discuss uh it is with respect to 7 billion 13 billion and 70 billion parameters here I am just trying to show you some important information and based on this only I will teach you okay now let's understand this so this is how entirely it happens you have pretraining data you have self supervised learning you have Lama 2 you have sft supervised finetuning you have rejection sampling proximal policy optimization because everything will be taught this is nothing but reinforcement learning with human feedback and based on this particular feedback we assign something called as safety reward model and helpful reward model everything I'll teach you don't worry just see the diagram focus on the diagram and try to just see this okay okay over here so every component that you're seeing I will break it down and I'll explain you now where does this model take the predating data from so here you can probably see our model right is everybody able to see this when we say it parameter train from 17 billion yes so everybody's able to see this yeah so on pretraining data includes a new mix of data from publicly available sources so from where they have taken the data from publicly overed sources which does not include data from meta products or Services okay we made an effort to remove data from certain sites known to contain a high volume of personal information about private individual so from where it has taken the data in short this is all lie I gu yes they have taken the data from wherever it is they are saying we made an effort they're saying we made an effort to remove data from certain sites effort you know how much effort it is there okay so understand okay efforts then we trained on two trillion tokens of data as provides a good performance cost trade up so two trillion tokens of data it has been trained in okay so here the next thing see see see see see we adopt most of the pretraining setting and model architecture from Lama 1 we use the standard Transformer architecture they by Transformer architecture see tomorrow if you give me a chance I can also create a I can also create an llm model creating an llm model is not very difficult but the main problem will be cost of the GPU how much cost of the GPU it will take what should be a team size to do reinforcement learning over there everything in that particular thing that cost will be doing so you'll be able to see only big companies can only afford all these things who have billions and billions of dollars in fundings and all tomorrow if you say whether I can also do it yes the answer is you should have just money to do it because you require those huge gpus the gpus cost training time it will cost how much data you require they will you'll also require people for working for you who will be doing that annotation task labeling task indexing task reinforcement task right but for this you require a huge amount of money tomorrow if someone comes and say hey take this much money create your own model we can do that no worries right but in India we don't Focus much on Research right we focus much on we focus much on what solving business use case and trying to earn Revenue out of it okay research I have not seen much companies who are doing research that much okay so infrastructure cost is there so see Transformer architecture so if anybody knows about Transformer architecture done you'll also be able to do it apply prenormalization some techniques will be there code will be available you can also do it okay now if Lama 2 is an open source you can also use the same code and try to do it okay then we trained using adamw Optimizer see these all videos I've already created explained you like anything what Adam Optimizer how does it work this this everything is Basics I'm not teaching I'm not showing you anything new right beta 1 is there beta 2 is there this is there we we use a cosine learning rate what is cosine learning warmup step DK final running rate everything is same nothing new it's like build sand sand sand and make a castle okay I have sand I have bricks I will combine them and make a uh make a five star hotel in short right and everybody cannot make a five star hotel right who has money they can make it who has money they can make a huge Bungalow right a Maharaja Palace something right they can do that so I hope you're able to understand all this things you need to have money for that okay so here are there Lama one had come up with 17 billion 13 billion 33 billion 65 billion now Lama 2 is coming up with 7 billion 13 billion 34 billion 70 billion now why this billion is increased inreasing why this parameters are increasing some f tuning will be done more data will be added more data will be included more reinforcement will be done multiple things will be put up over there and that is how your parameters will increase and there is no other way the parameter is not going to increase over there right parameter will increase over here itself right something you do in that more parameters will get added more weights more bias it's all about more weights and more bias okay less Dropout more Dropout more normalization less normalization that that way only parameters are getting added you may be thinking parameters is getting added I think they have put a rocket launcher inside that model no nothing like that just they have added more data set maybe more finetuning techniques and because of that more weights more bias are getting added that's it right don't think that no something is happening the model will now go to Mars no nothing like that okay so this is what is all about Lama 2 okay now this is my training loss you have seen in many many videos in deep learning how the training loss will be shown over here right so training loss is over here see training Hardware we trained our models on meta research super cluster meta research super cluster okay by this name only gpus both clusters use Nvidia a00 let's let's see what is NVIDIA a00 cost let's see okay Nvidia 800 powering many of this application this is just roughly $10,000 chip just $10,000 chip just imagine see 27 L 27 lakhs dollar is NVIDIA Amper 800 who will be able to do which startup will be able to do this much money will be able to invest this much money tell me the reason why I'm showing you this because the research paper talks more many things about it right so over here they have used Nvidia a00 you SE in the cost of it amazing right how much is this cost 27 lakh I guess sorry 27,000 and more chips if you try to put up more chips over there the cost will keep on increasing right we are still we are our laptop has RTX 490 that basically means we are our laptop is very powerful there will be electricity cost involved there will be multiple things involved right so everything is over here you can probably see with respect to this right it is somewhere around 27k sorry not 27 lakh it is 27k as as I just saw 0. I did not leave that part okay so but you can just understand the cost is keep on increasing okay so here you can see that RSC uses Nvidia Quantum in Infinity band where product cluster is equipped with Roc you can probably see this C see see see CO2 emission during pretraining you have to also give this information if you want to publish the research paper total GPU time required for required for training each model power consumption PE power Peak capacity per CPU device for gpus see how much carbon is emitted right 7B is this much power consumption 400 watt 400 watt 350 watt 400 wat total total GPU hours take 33 lakh 31,000 no no 33 laks 11,000 hours GP hours who has this much time guys if a startup in India will spend this much time in training done I don't know this is how many years let's say 24 into 12 uh 24 into 365 just do how many hours will be there how many years it has basically trained right carbon P for print pretraining and all these information are basically there right and then here also you can probably see the comparison size Code common sense reasoning World Knowledge reading comprehension math mlu mlu is basically human level understanding uh BBH and AGI right now I've have told all this information now let's understand how this models are basically trained how llm models are trained okay so till here everybody happy yes everybody happy with the teaching that I'm actually doing so now we are going to move towards how llm models are trained and we will discuss it step by step so guys clear or not clear or not just tell me give me a quick information so here I'm going to basically write the stages of stages of stages of training so first information here I specifically have I will just draw the stage one so this is my stage one based on that research paper I'm basically going to draw okay so this is nothing but generative pre tring okay generative pretraining second stage so second stage is nothing but supervised fine tuning which we also say it as SF the same information what is written over there that research paper same thing I'm writing third stage third stage is what reinforcement through human feedback this is my third stage Okay so initially in this stage in generative pretraining we give huge data so this can be so any any llm model basically takes internet Text data or any document Text data in PDFs in all all those formats and here we specifically create or use this generative pre technique now generative pretraining basically means here specifically we use transform architecture model Transformer of bir architecture model the outcome of this is what the outcome of this is the outcome of this is we basically say it as base let's say if I probably consider if I probably consider so I will write this is my base Transformer model what is this the base Transformer model okay now this base Transformer model is then base Transformer model basically means whatever Transformer I basically trained on I will basically say this as base Transformer model okay now the base transform model is in turn connected with supervised fine tuning because same model will be taken and and supervised fine tuning will be done on top of it okay top of it right now this understand this base transform model will be able to do various task like text classification text summarization multiple things it will be able to do okay now here only we will not keep it in case of uh llm model we will take it to the next step the next step is supervis finetuning now here what we are specifically going to do we are going to use human trainers also we are going to involve human trainers to put some kind of conversation some kind of conversation and here we will create some more custom data this is important to understand here we will try to create some more custom data right so some more custom data will be created in this case in this particular step and those custom data which is created it is created basically by whom by human trainers I will talk about what exactly is human trainer when I probably Deep dive more into it okay then it based on this custom data we will train the specific model and the outcome of this model outcome of the model will be okay just a second oops it got closed let's see whether it is saved or not I hope so it should be saved oh my God okay apologies the system got crashed I don't know what happened because of that the entire material got deleted sad can't help okay so how much content I had actually written I don't know whether it's the system got crashed or the scribble notebook automatically got deleted sad to hear about it but it's okay I don't think so anywhere it is okay I don't know generative AI the materials got deleted I'm extremely sorry I don't know what happened over here but I'm not able to see that materials got deleted yeah okay no worries anyhow you'll be able to see in the recordings so don't worry about that uh let me continue okay let me continue okay okay now let's go step by step I was just talking about some important things over there so first step I will go with respect to stage one okay so stage one generative pre training okay this is basically my stage one now what all things we basically discussed in this okay in generative pretraining what we specifically do is that we use Transformer architecture okay so here what we are doing we basically use Transformers Super beneficial for NLP task and then along with this we take Internet Text data and document Text data so this is nothing but internet Text data and document Text data okay and this is what is my stage one okay stage one now once we train with this specific Transformer we what we get we get base Transformer model we get base Transformer model now what this base Transformer model is basically is Cap capable of right what this base Transformer model is capable of you need to understand this specific thing okay this base Transformer model is capable of doing task here I will write down all the task number one text summary I will save this saving this is always better so that if it gets deleted I can open it so the task which is able to do is like task text summary sentiment analysis third task can be something like text uh word completion I'm writing some task fourth task is basically like text translation so all these things it will be able to do it all this task this model will be capable to do it but what is our maining when we make sure that we have a generative AI our expectation is basically to create a model which will be able to do chat and conversation right this is what is our main name right but what we have achieved we have achieved this right by using this technique we have achieved this but what is our goal our goal is to achieve this right this is my goal so that is the reason we just don't stop in stage one we go to next stage that is stage two now in stage two see stage one it is very much simple we have used amount of data we make sure that we do that labeling whatever is required we train it with the Transformer we create a base Transformer model this base Transformer model is able to do this thing but it is not able to do this but this is our goal goal of generative AI is this one right this is what is our main aim goal of generative AI right this is what a generative AI does agree everyone this is what generative AI does and this is what is my goal agree or not everybody do you agree if you AG agree please do make sure that you hit a thumbs up okay now to make a generative AI on top of this I need to do some more thing and that is where I go to my stage two so this second step is basically my stage two what exactly stage two now what exactly stage two stage two I've already told you it is nothing but from the research paper also I've told you it is nothing but it is basically super supervised fine tuning which we also say it as sft now what exactly supervised fine tuning what exactly this is this is the second round now in supervis fine tuning what happens now see this is the most important step okay we require humans in this step humans now in human what we do we create request we make some set of people sit over here so this will be my human agent this human agent will send some request just like in a chat bot how we send it and based on this request based on this request we generate an idle response and this idle response is given by another human agent it is just like a chat conversation let's say I have I have I've set I have made one person sit over here one person sit over here when this person asks a question this person will answer the question then similarly next request will be created then next response will be created then next request will be created then next response will be created so what is basically happening this human agent is basically giving the request this human agent is basically giving the response right idle response when I say idle basically means whatever is the question based on the question we are giving some kind of answers this way we will set up our sft training data set so this will be a label data set now this data set has what this is my request this is my response this is my request this is my response this is my request this is my response this is my complete data set yes or no this is my data set that we are going to create from this process request and response request to response request and response whatever these human beings have had a conversation with right now we going to take this data set and further send this data set to our base Transformer model base Transformer model along with this we will do some fine tuning or we'll use a optimizer let's say we have using Adam W Optimizer this Optimizer was done is in the Llama right in the Llama itself right and then finally I get a sft Transformer model why Optimizer is used to reduce the loss this is an Optimizer right this is specifically an Optimizer okay everybody clear so this is the step that is basically happening in the second one sft is done by real human being human agents right and that is how things are going ahead right and this way you are able to create your own data so this will basically be my data or labeled data during the sft process okay and the same data will be used to train your base Transformer model after training you will basically create a saf Transformer model okay now what will happen still this model you'll be thinking okay it'll be able to give me more accurate result but still this model will be facing hallucination it may not give you good correct accuracy because there may be also some kind of request and response which this model may have never seen it okay so for that case what we need to do we need to probably go with our next step or stage three and that stage three is specifically called as where we will be using reinforcement okay and that step is basically stage three in the stage three we use reinforcement learning through human feedback because we also need to do human feedback and without this reinforcement learning this model is probably it will face hallucination it will make give you rubbish answer and all okay now what happens in reinforcement learning let's discuss about this okay let's say this is my sft train model Okay so so this is my sft Transformer model now in this sft Transformer model what happens after training whenever a human gives any kind of respon request whether a human gives a request after the model is trained we can get a response from from whom from sft ch bot right we'll be able to get some kind of response the SF Transformer model okay now what we are going to do now based on this request I may also get multiple response now that is where you'll be understanding reinforcement okay let's say this sft chatbot we will try to record its multiple response let's say this is response a this is response B this is response C this is response D and this is multiple response like this okay now once you probably get this response so let's say this is my response a as said this is my response b as said this is my response C this is my response d right multiple responses there okay now for this response a human being will do some ranking and this is where reinforcement is applied ranking okay now this ranking of this response like for this request this should be given first rank that basically mean this should be the idle response this should be the second idle response this should be the third idle response like that a ranking is given by another user agent another user agent okay see this step by step First Step then Second Step then ranking is done okay and what this specific ranking is basically going to do just imagine this okay ranking is just going to say that my response a rank should be greater than response B rank should be greater than response D let's say d is greater than C okay so this ranking will get applied okay and once we specifically assign this kind of ranks these are my ranked responses what we can do we can train after this what this is done is that we train a fully connected neural network fully connected neural network in this neural network let's say these are my nodes like this and this is my output like let's say like this so here my inputs will be my conversation history my conversation history and my outputs the real outputs are my ranks ranks responses so based on this I will be training my entire neural network and this model is basically called as reward model okay so in this step in reinforcement what are specific things we are doing we creating an SF Transformer model based on multiple responses we are applying reinforcement where we are giving a human feedback so here in short we are giving a human feedback human feedback based on this human feedback Fe back we will be specifically getting which response should be greater than the other response we assign a rank and then we create a fully connected neural network with conversation history and ranks so that based on this ranks we will be able to provide rewards rewards to what this Transformer model I hope you're able to understand yes yes yes everyone yes if you're able to understand hit like please make sure this is the most important thing in generative AI right of creating this entire llm models right and trust me to understand these things because after understanding this reading research paper will be very very much easy okay and that is where my reward model is basically created in my stage three okay so this is the most important thing okay I will use one image to show you the next model okay and this is the most important one um just a second everyone just a second everybody I think my system is hanged okay okay till then let me go ahead and continue it okay so finally after we have this entire reward model and all okay we also make sure that we create some kind of models see at the end of the day once we create all these things that basically means what happen this three steps helps us to create any llm model as such what is the difference thing that is basically going to happen right your training data needs to be created right the more the training data the more better thing is second thing is the reinforcement learning reinforcement learning with human feedback right this is also important coming for the third thing the fine tuning part right the fine tuning part specifically with respect to sft what kind of request and response the human being are taking and reinforcement the most important thing is that how the ranking is done right these are the main things and obviously the architecture that we are specifically going to use over here is nothing but Transformers okay so this is very much important with respect to all the things that we have discussed how was was the understanding scenario guys with respect to all these things have you understood or not please do let me know please do let me know are you able to understand everything or not with respect to whatever things we have actually done or discussed over here just let me know guys got it got it yes yes yes yes yes yes so everyone is giving me a right answers over here great great great great great great now going forward what you really need to focus on okay what you really need to focus on see as a person who is interested to get into generative AI okay what are things you should basically focus on the road map if you really want to start the road map to generative AI road map to generative AI okay now in order to understand the road map of a generative AI or how you can also start the prerequisites prerequisites what are the prerequisite obviously one programming language okay one is python okay second you really need to be strong at NLP so when I say NLP machine learning concepts with respect to NLP right where you learn different texes of embedding techniques let's say what is embedding here you specifically learn how you can convert a text into vectors right now converting a text into vectors has many things in mind okay so guys there is also one St page uh that is after this okay probably I will explain you that because my another screen have got stuck okay so what I'm actually going to do is that probably one more thing is something called as proximal policy optimization I will create a a live video on this next week we basically say this as prox let me just write it down for you after creating the reward model we basically use this in proximal policy optimization we will discuss about this for this I will come next week live or probably in whatever next live session we will discuss about this entire thing this is an another important algorithm altogether okay but after this our final llm model will be cleared and this is super important because this will assign rewards this is responsible for assigning rewards based on various responses that we are giving or my llm model will give okay so uh I will probably cover this because this is another long topic uh in the upcoming classes we'll see any live sessions we'll discuss about this also okay now let's go ahead and understand the NLP now as as I said that right the prerequisite is that in machine learning you need to understand how a words are converted into vectors and they are multiple techniques uh I hope you have heard about bag of words you have heard about TF IDF you have heard about embeddings you have heard about uh word to right word to V so all these techniques are specifically used in converting uh the words into vectors so that the machine when it is trained based on input and output it'll be able to understand the entire context so basics of machine learning I still say this as basics of machine learning you really need to have a good amount of idea with some of the algor knowledge and all third thing when I say you really need to understand deep learning techniques also in deep learning you need to understand about uh Ann hown Works what are optimizers what is loss function what is loss function what is uh let's say what is uh overfitting right uh what is activation for functions what is multilayer neural network what is forward propagation backward propagation so many different topics are there so these are again the basic building block the basic building blocks okay so the basic building blocks with respect to all these particular topics is super important so please make sure that you have to be really good at this I'm not saying that someone cannot directly jump to generative a they can if you are a developer if you are developing some kind of application without knowing all these things any one programming knowledge you can directly go ahead and probably use the API consume it build application but these are for those people who specifically wants to work as a data scientist as a generative AI engineers in the companies right for them they really need to follow this without this basic knowledge they cannot probably learn generative AI why I'll tell you if you directly jump to generative AI you may be able to develop application but when you go ahead and with the interviews there people are going to ask you basic things right basic things over here and if you are not able to answer that they'll not directly start with generative AI first of all they'll see how good your basic skills is if you good at something then only they'll further go ahead and ask some more questions right so it is super important to understand you cannot directly jump it jump into things okay so the fourth topic that you will probably be seeing after deep learning uh is advaned deep learning techniques so here we focus on on RNN lstm RNN Gru so all these neural networks you really need to understand Gru uh encoder decoder encoder decoder Transformers as I said Transformer attention is all you need all these architectures you should be able to understand because in the interview again they are going to ask you this they'll tell you that design or write a code on a basic Transformer okay and they'll tell see how things are basically done whether you are able to write it or not all those information will be basically asked in the interviews because everything with respect to generative AI is built on top of Transformer right now the fourth Thing Once you this I usually consider as a prerequisite to get into generative AI right it's okay it's okay if you have some good some basic knowledge on all these things right but it is always good to have this so that you will be having an indepth knowledge indepth knowledge of working in generative AI okay then coming on to the fifth part right here where I'm going to focus on different different libraries open AI open AI has come up with this gpts model right GPT 3.5 GPT 4.0 GPT uh 4 Turbo all these specific models you can use to develop applications llm applications not only this you can also use other Frameworks like Lang chain Lang chain is quite popular right now because many people are using this to create llm application and the best thing about Lang chain is that it has created this framework in such a way that you can use paid apis also you can use open source uh open source llm models also and you can perform any task that is basically required along with prompt engineering there is one more framework which is called as Lama index so Lama index is also a very good framework and this is specifically used for quering purpose quering vectors right so this also is very important framework right now and as you all know right now Google gini gini has basically come up with this amazing model Google has come up with this and right now jini Pro is available so you can also use gini Pro it has its own libraries and you can specifically use for performing any llm applications right now we don't have the documentation of how fine tuning is done but in some days that too will also come right now in all these libraries all this open source open source as I said right open source models llm models in this open source models also you can also do fine tuning but again at the end of the day for finetuning you really need to have huge gpus it's see open source models are readily available you can directly download it you can quantise it you can make it in a form where it will be of less size you can directly find tuning with your own data set for that you require hug gpus for inferencing purpose also you require good machines in short right so in short if you are good at all these things trust me you able to work with generative AI but again it is a process where you have to probably learn all these things okay in the future we'll also try to uh I'll try to take a session where we'll discuss about all these prerequisites in depth and we'll try to understand all the mathematical intuition okay CNN is not at all required see CNN is required if you are interested in large image models but here most of the use cases that are probably coming up are on large language models right but if anybody's interested in this you can learn about CNN if you want but I feel uh if you are interested in Tech side llm you have to focus on all these things right so guys how was the session all together good enough good or not oh great just a second I will take up questions my screen has got stuck okay so let's take some questions till then uh yeah every week okay great you are able to hear me out so please uh let me know about more things how was the session if you liked it please make sure that you like it guys uh it takes a lot of effort to keep this kind of sessions and uh we are planning for every Friday this sessions so it'll be amazing to teach and all it'll be great okay got something new to learn great amazing sir salute valuable great great great great I I hope everybody's happy so uh please make sure that you share it with your friends in all the platforms that is specifically required because trust me at the end of the day these all are free content our main aim in in neuron is to democratize AI education we so at the end of the day please try to learn in that specific way try to understand these techniques and then try to build application okay can a nondeveloper also learn this yes anyone can learn this anyone okay anyone because it is very much simple with respect to coding okay what is the boundary of sft and interface for quering is only sampling so tell us about the course you're launching on generative AI on in neuron so guys uh we are launching generative AI course it is probably from next month you can find all the details in the description of this particular video or visit iron. page okay there generative AI course is basically coming up uh So based on that uh you'll be able to see to it and check it out okay check it out in the description of this particular video so video recording today's class yeah it'll be available in YouTube it will be available in the dashboard that is given in the description okay okay perfect so hit like guys any more questions any queries hi sir can you tell me about the differences great sessions are really and really appreciate so guys just give me a 5 minutes break and then we will be taking up the questions my system is hanged so I will restart the system till then okay so just give me another 5 minutes break uh we will go ahead and take a five minutes break so Prashant uh you can just uh stop sharing if possible I will just take five minutes break and okay and I will be talking about that thank you n e e e okay am I audible am I audible hello hello okay 2 minutes 2 minutes 2 minutes okay audible right perfect sorry okay so let's take so first of all people were saying about what is the differences between generative Ai and gini pro okay so generative AI as I said guys large language models are a part of generative AI similarly large image models are also part of generative AI okay so generative AI is already a subfield of deep learning our main aim is to create new content based on the data that we have trained right so we have all these kind of llm models okay okay let's let's take this questions so great session sir really helpful and really appreciate your initiative of democratizing gener uh generative AI learning thank thank you so going forward all ml or DL techniques will not be in use we will focus more on llm plus finetuning yes it depends on companies to companies right so if there is a company where we are focusing on creating use cases quickly and they don't have that cost issue they can directly use this because see at the end of the day if you're also creating any application with respect to machine learning or deep learning you have to do everything from scratch yeah okay let's take more question so how much large data set of request and response is created by human agents under sft as manually to create such large data set is impossible yeah if they put 100 people every day that many task is there then just imagine how much data we'll be able to create right huge amount of data you'll be able to create okay what all task we will perform from J Pro everything text summarization Q&A document text uh document Q&A embeddings everything is possible right so one session I also I'll plan for gmin pro okay why focuses more on llm in gen AI because you're able to do task you're able to create solve business use cases in a much more accurate way right so it is very good how can gender a used for solving real life business problem there are lot of real world business problem that is specifically required by companies from chatbot to text summarization to document classification to everywhere it is specifically used uh in in inur also we are trying to automate the entire support system along with human intervention both we are trying to include and over there also we will be using llm models too right for assignment generation we are planning to use llm models many as such so okay so in uron also we have built our own models itself right so can you show how to finetune a GPT model using API yes it is possible but uh again we need to make sure that we have some good configuration configurable system uh if you want to do it with open source llm if you want to go with paid that also we'll try to do it in the upcoming sessions okay okay tell us more about generative AI so here is my page I'm going to share my page over here ion website so if you are interested you can go ahead and so I'm going to share my screen okay so I hope everybody is able to see my screen please uh give me a confirmation can you see my screen give please give me a confirmation so I will just try to answer this specific question okay so here you'll be able to see as soon as you go to the homepage the first course that we are launching on generative AI mastering generative AI open AI Lang chain and llama index also from 20 January 2024 okay this will be a 3 to 4 4 months course altogether one year dashboard access is there this is for everyone out there whether you are a college student working professional along with this we will also be providing you access to the Virtual Lab of uron okay here what all things we are going to learn we are going to master everything that is related to open Lang chain and Lama index okay and specifically developing application end to end till deployment okay we will show you multiple things over there now when this batch is starting 20th Jan 2024 the language is English 5 months duration 10 to 1 p.m. Saturday Sunday class timing it will be live instructor lead okay uh you have onee dashboard access assessment in all modules the reason why we are putting one year dashboard access is that because this content will get upgraded every six months I guess right there are a lot of upgrades in the field of generative AI right so that is the reason is no use of giving you lifetime or anything as such okay so neural laab access is there dedicated community support these all things are there mentors will be myself sudhansu s Savita and bppi right so some portion I will be taking some portion Sanu will be taking some portion s Savita will be taking some portion bmed B will be taking okay and you have already seen they have they're doing the live sessions on generative AI in the in the in in in the YouTube channel of ion itself okay so you can definitely check it out over there then if you have any queries you can talk to a counselor or you can also contact the ivr number that is given over here right in the website itself so if uh any question that you have regarding counseling anything and this is the entire syllabus we are going to start from Basics what road map I have shown you today based on that road map only we are going to start see bag of words TF IDF word to F test engrs Elmo bird based right then large language model what is BD GPT T5 Megatron right GPT 33 3.5 how chat GPT train introduction to chat GPT 4 right and then we are going to probably learn about hugging pH we are going to see different different models open source then we are going to talk about llm power application we're going to create end to end projects then we are going to use open AI this this this all every everything that is available in open aai because many companies are also using it then we are also going to cover prompt engineering Lang chain Lang chain completely L chain in depth we'll try to complete then we will also be completing l Lama index all these Frameworks right so everything will be covered up and finally you'll also have lot of end to end projects in every section lot of endtoend projects is there and these all projects are with respect to deployment so all these things are there you can probably check it out in the cabus okay uh all the information will be given in the description of this particular video as I said if you have any queries talk to the counselor okay they'll help you out what Hardware is required to learn J no need of any hardware we will be in uron lab itself you'll be able to execute all your code you'll be able to do it if anything is required we'll let you know in the latest stages okay but whatever is in the flea platform available in uron Virtual Lab and all you'll be able to do this so please tell is there any prerequisite yeah Python programming language so for that also we are giving you prerecorded videos so python you should know only python you should know remaining all is fine Community Edition difference please uh Community session is only up to some level okay you can probably say 100% of what we are teaching over here it is hardly 10 to 15% okay will we require opening API key yes we will show you a way how to do that okay um but yeah at the end of the day if you want to do fine tuning and all you'll be requiring open API ke h so do you have projects HandsOn course for machine learning and data science so again I'll let me share my screen for that also we have launched it so let me share my screen so for project HandsOn course uh if you probably go over here we have also launched this one which is called as production ready data science project so if you click over here production ready data science project this is a one month course where we are solving end to end five projects five five and it includes machine learning deep learning natural language processing and generative AI so this is completely end to endend and this is with mlops machine learning operations right all the tools the timing again this is from 27 Jan the timing is 88 to 1100 p.m. Monday Wednesday Friday so in one week we will be completing one project okay three days and it will be live all the sessions will be live it is live instructor lead so again you can go to ion. a page check it out if you want to talk to the counselor talk to them mentors again all these things s Savita bapi will be the main mentors over here will will be taking this entire session Monday Wednesday Friday will be the session 8 to 11 at night now here what we have done is that best thing we have included mlops everything that is basically required right mops mlops mlops right let it be so what all things you'll be covering in this open a AWS GitHub Docker Azure lanin Jenkins along with this we will be seeing Circle CI we'll be seeing uh GitHub action cicd pipeline Dockers kubernetes everything that is required is covered in this so it is a complete mlops syllabus right DVC dockerization AWS Jenkin cicd pipeline so every project that you'll be seeing right you will be seeing over here we are using some some of the other things let's say Industry Safety here also we'll be doing dockerization AWS GitHub action cicd right and if I go with name entity here you'll be seeing DVC dockerization Azure Circle cicd so everything will be covered with respect to that and then I've also we have also included uh the generative AI project okay great so I'm stopping and anything any info that you require you can probably go ahead and ask ask in the uh just contact the ivr number over there okay okay perfect so how was the session all together did you like it so do we need to do projects on mldl to get job in gen aai yes obviously mlops mlops mlops see the generative AI projects also that we are going to do in gen AI course there we are going to include lot of mlop activities also it's more about creating applications okay okay perfect course fees and all you can find out in the course page itself okay perfect guys so thank you this was it I think we have completed the 2hour session uh from coming Monday we are also coming up with the mlops community series from coming Monday so please make sure that you subscribe the channel press the Bell notification icon that is super important um we will be starting from next week itself okay you can probably check it out uh all the reminders everything will be found out in the channel itself there will be dashboard exess materials everything that you actually require so thank you uh this was it from my side if you like the video please make sure that you hit like subscribe share with all your friends this was it from my side okay and I will see you all in next week Friday session we will be discussing more things but again we have lot many things that are coming from Inon itself we'll be having mlops entire Community session and it is from uh next week uh Tuesday is going to probably start and we'll be discussing about all those things how an end to end project is basically created Let It Be an LP project machine learning geni project how mlops can be used and many more things so thank you uh have a great day and keep on rocking if you like this session please do hit like and yes I will see you all in the next session so thank you guys have a great day byebye take care and keep on rocking thank you bye
